-e /gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary
-e /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023
/gpfs/u/home/PTFM/PTFMqngp/scratch/tools/torch-2.1.0a0+gita37b4fa-cp310-cp310-linux_ppc64le.whl
scipy
packaging
sentencepiece
ninja
charset-normalizer==3.1.0 # this version works as dependency of `datasets`
datasets
accelerate
git+https://github.com/huggingface/peft.git
evaluate
tokenizers
protobuf
transformers
huggingface_hub
openai
rouge_score
wandb
gradio
markupsafe
termcolor
jsonlines
unidic-lite
einops
auto-gptq
fire
flask
tensorboard==2.13.0
omegaconf
pynvml
openai
tiktoken
alpaca-eval==0.3.1

# ppc64le build fails
# https://github.com/SamuraiT/mecab-python3/issues/95

# ppc64le has V100 mostly, cannot use flash attention anyways.
# flash-attn
# triton-pre-mlir@git+https://github.com/vchiley/triton.git@triton_pre_mlir_sm90#subdirectory=python

# bitsandbytes has trouble setup cuda. didn't figure out how to compile from source either.
# bitsandbytes

# install deepspeed according to https://docs.google.com/document/d/136VZGFKlylkcKqXDZDIu1-584GWscYvn0n1oAik9qZs/edit if needed.
# deepspeed==0.9.1

