{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4b80c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/__init__.py:25: UserWarning: Install `torch` for functionalities dependent on torch\n",
      "  warn(f'Install `torch` for functionalities dependent on torch')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from rosemary import jpt_parse_args, jpt_setup, jpt_in_notebook; jpt_setup()\n",
    "\n",
    "if jpt_in_notebook():\n",
    "    import os\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[0] \n",
    "    # '0,1,2,3,4,5'\n",
    "    print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f65fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import argparse\n",
    "import json\n",
    "import pickle\n",
    "import string\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from note_pruning_analysis import get_lm_output, get_dataset, convert_example_to_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a5b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'all-mpnet-base-v2'\n",
    "model_name_or_path = 'results/baselines/sentence-transformers/all-mpnet-base-v2'\n",
    "\n",
    "dataset = 'wizardlm'\n",
    "input_file = 'data/processed/sharegpt/sharegpt_data.jsonl'\n",
    "input_file = 'data/processed/ultrachat/ultrachat_data.jsonl'\n",
    "input_file = 'data/processed/wizardlm/wizardlm_data.jsonl'\n",
    "n_clusters = 50\n",
    "batch_size = 128\n",
    "\n",
    "encode_fn_type = 'input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633f6c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-13 21:38:06,314] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModel.from_pretrained(model_name_or_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b9ac7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/data/processed/wizardlm/json/default-a3f71ae376e517fb/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dataset', 'id', 'messages'],\n",
       "    num_rows: 143000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = get_dataset(dataset, processed=True)\n",
    "\n",
    "if encode_fn_type == 'input':\n",
    "    def get_user_prompt_fn(example):\n",
    "        example['text'] = example['messages'][0]['content']\n",
    "        return example\n",
    "    ds = ds.map(get_user_prompt_fn, num_proc=16)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0831bfce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = get_lm_output(dataset, \n",
    "                  model_name, \n",
    "                  encode_fn_type=encode_fn_type,\n",
    "                  return_text_embedding=True,)\n",
    "X = d['text_embedding']\n",
    "X = X / np.linalg.norm(X, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05fae8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_N = 10_000\n",
    "ds = ds.select(range(first_N))\n",
    "X = X[:first_N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84d79649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration 0, inertia 13046.0478515625.\n",
      "Iteration 1, inertia 7963.150390625.\n",
      "Iteration 2, inertia 7823.3193359375.\n",
      "Iteration 3, inertia 7766.98486328125.\n",
      "Iteration 4, inertia 7734.853515625.\n",
      "Iteration 5, inertia 7714.99462890625.\n",
      "Iteration 6, inertia 7701.08349609375.\n",
      "Iteration 7, inertia 7689.7392578125.\n",
      "Iteration 8, inertia 7681.154296875.\n",
      "Iteration 9, inertia 7675.09619140625.\n",
      "Iteration 10, inertia 7670.427734375.\n",
      "Iteration 11, inertia 7666.078125.\n",
      "Iteration 12, inertia 7661.98974609375.\n",
      "Iteration 13, inertia 7658.16064453125.\n",
      "Iteration 14, inertia 7654.4638671875.\n",
      "Iteration 15, inertia 7651.60546875.\n",
      "Iteration 16, inertia 7649.08056640625.\n",
      "Iteration 17, inertia 7646.89208984375.\n",
      "Iteration 18, inertia 7645.1513671875.\n",
      "Iteration 19, inertia 7643.6064453125.\n",
      "Iteration 20, inertia 7642.0751953125.\n",
      "Iteration 21, inertia 7640.2158203125.\n",
      "Iteration 22, inertia 7638.42626953125.\n",
      "Iteration 23, inertia 7636.91845703125.\n",
      "Iteration 24, inertia 7635.8076171875.\n",
      "Iteration 25, inertia 7634.97607421875.\n",
      "Iteration 26, inertia 7634.2021484375.\n",
      "Iteration 27, inertia 7633.45654296875.\n",
      "Iteration 28, inertia 7632.7822265625.\n",
      "Iteration 29, inertia 7632.25927734375.\n",
      "Iteration 30, inertia 7631.8173828125.\n",
      "Iteration 31, inertia 7631.5439453125.\n",
      "Iteration 32, inertia 7631.31005859375.\n",
      "Iteration 33, inertia 7631.16796875.\n",
      "Iteration 34, inertia 7631.0576171875.\n",
      "Iteration 35, inertia 7630.96142578125.\n",
      "Iteration 36, inertia 7630.8896484375.\n",
      "Iteration 37, inertia 7630.82177734375.\n",
      "Iteration 38, inertia 7630.7421875.\n",
      "Iteration 39, inertia 7630.609375.\n",
      "Iteration 40, inertia 7630.39501953125.\n",
      "Iteration 41, inertia 7630.154296875.\n",
      "Iteration 42, inertia 7629.8095703125.\n",
      "Iteration 43, inertia 7629.3544921875.\n",
      "Iteration 44, inertia 7629.03564453125.\n",
      "Iteration 45, inertia 7628.775390625.\n",
      "Iteration 46, inertia 7628.552734375.\n",
      "Iteration 47, inertia 7628.4638671875.\n",
      "Iteration 48, inertia 7628.40673828125.\n",
      "Iteration 49, inertia 7628.37548828125.\n",
      "Iteration 50, inertia 7628.35693359375.\n",
      "Iteration 51, inertia 7628.3212890625.\n",
      "Iteration 52, inertia 7628.27734375.\n",
      "Iteration 53, inertia 7628.25146484375.\n",
      "Iteration 54, inertia 7628.2314453125.\n",
      "Iteration 55, inertia 7628.22314453125.\n",
      "Iteration 56, inertia 7628.21240234375.\n",
      "Iteration 57, inertia 7628.2001953125.\n",
      "Iteration 58, inertia 7628.17626953125.\n",
      "Iteration 59, inertia 7628.15087890625.\n",
      "Iteration 60, inertia 7628.107421875.\n",
      "Iteration 61, inertia 7628.04931640625.\n",
      "Iteration 62, inertia 7627.99267578125.\n",
      "Iteration 63, inertia 7627.9365234375.\n",
      "Iteration 64, inertia 7627.86181640625.\n",
      "Iteration 65, inertia 7627.8134765625.\n",
      "Iteration 66, inertia 7627.7802734375.\n",
      "Iteration 67, inertia 7627.7119140625.\n",
      "Iteration 68, inertia 7627.6396484375.\n",
      "Iteration 69, inertia 7627.58251953125.\n",
      "Iteration 70, inertia 7627.5546875.\n",
      "Iteration 71, inertia 7627.521484375.\n",
      "Iteration 72, inertia 7627.50537109375.\n",
      "Iteration 73, inertia 7627.50244140625.\n",
      "Converged at iteration 73: strict convergence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from note_pruning_analysis import (\n",
    "    clustering_run,\n",
    "    sort_cluster_results_by_cluster_size,\n",
    "    clustering_algorithm_scores,\n",
    "    clustering_dist_to_centroids,\n",
    ")\n",
    "\n",
    "sort_by = f'cl=kmeans_nc={n_clusters}'\n",
    "# sort_by = f'cl=kmeansminibatch_nc={n_clusters}'\n",
    "# sort_by = f'cl=kmeansminibatch_nc={n_clusters}_bsz=256'\n",
    "\n",
    "\n",
    "info = {}\n",
    "info['N'] = len(X)\n",
    "info['n_clusters'] = n_clusters\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "Y, C, clustering_model = clustering_run(sort_by, X)\n",
    "info['time_elapsed'] = time.time()-t0\n",
    "info['inertia'] = clustering_model.inertia_\n",
    "\n",
    "Y, C = sort_cluster_results_by_cluster_size(Y, C)\n",
    "info.update(clustering_algorithm_scores(X, Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "768663f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_ind</th>\n",
       "      <th>cluster_assignment</th>\n",
       "      <th>dist_l2</th>\n",
       "      <th>dist_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.848907</td>\n",
       "      <td>0.465920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.903208</td>\n",
       "      <td>0.562518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.812550</td>\n",
       "      <td>0.407720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852474</td>\n",
       "      <td>0.476840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0.848171</td>\n",
       "      <td>0.464556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>36</td>\n",
       "      <td>0.966166</td>\n",
       "      <td>0.707237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>9</td>\n",
       "      <td>0.918524</td>\n",
       "      <td>0.604532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>7</td>\n",
       "      <td>0.840771</td>\n",
       "      <td>0.457124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>30</td>\n",
       "      <td>0.732729</td>\n",
       "      <td>0.318054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>19</td>\n",
       "      <td>0.865857</td>\n",
       "      <td>0.497956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      data_ind  cluster_assignment   dist_l2   dist_cd\n",
       "0            0                  25  0.848907  0.465920\n",
       "1            1                  24  0.903208  0.562518\n",
       "2            2                  13  0.812550  0.407720\n",
       "3            3                   1  0.852474  0.476840\n",
       "4            4                  25  0.848171  0.464556\n",
       "...        ...                 ...       ...       ...\n",
       "9995      9995                  36  0.966166  0.707237\n",
       "9996      9996                   9  0.918524  0.604532\n",
       "9997      9997                   7  0.840771  0.457124\n",
       "9998      9998                  30  0.732729  0.318054\n",
       "9999      9999                  19  0.865857  0.497956\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what do I want to see \n",
    "#\n",
    "# - unsupervised scores for the clustering algorithm\n",
    "# - topic of each cluster\n",
    "# - top-k closest text/distance for each cluster.\n",
    "# - 2d tsne of clustering algorithm\n",
    "#\n",
    "# \n",
    "\n",
    "data = {\n",
    "    'data_ind': np.arange(len(Y)),\n",
    "    'cluster_assignment': Y,\n",
    "    'dist_l2': clustering_dist_to_centroids(X, Y, C, device='cuda', dist='l2'),\n",
    "    'dist_cd': clustering_dist_to_centroids(X, Y, C, device='cuda', dist='cd'),\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "import scipy\n",
    "info['dist_l2_and_cd_spearmanr'] = scipy.stats.spearmanr(\n",
    "    df['dist_l2'].to_numpy(), df['dist_cd'].to_numpy()).statistic\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99aff78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_ind</th>\n",
       "      <th>cluster_assignment</th>\n",
       "      <th>dist_l2</th>\n",
       "      <th>dist_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>5145</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922487</td>\n",
       "      <td>0.531328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6631</th>\n",
       "      <td>6631</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923893</td>\n",
       "      <td>0.537723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>4184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.930862</td>\n",
       "      <td>0.569574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>1144</td>\n",
       "      <td>0</td>\n",
       "      <td>0.935403</td>\n",
       "      <td>0.590459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>5748</td>\n",
       "      <td>0</td>\n",
       "      <td>0.939421</td>\n",
       "      <td>0.609022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>4076</td>\n",
       "      <td>49</td>\n",
       "      <td>0.905115</td>\n",
       "      <td>0.540195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>715</td>\n",
       "      <td>49</td>\n",
       "      <td>0.905965</td>\n",
       "      <td>0.541407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6388</th>\n",
       "      <td>6388</td>\n",
       "      <td>49</td>\n",
       "      <td>0.923375</td>\n",
       "      <td>0.566490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>810</td>\n",
       "      <td>49</td>\n",
       "      <td>0.949185</td>\n",
       "      <td>0.604552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351</th>\n",
       "      <td>4351</td>\n",
       "      <td>49</td>\n",
       "      <td>0.962864</td>\n",
       "      <td>0.625151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4983 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      data_ind  cluster_assignment   dist_l2   dist_cd\n",
       "5145      5145                   0  0.922487  0.531328\n",
       "6631      6631                   0  0.923893  0.537723\n",
       "4184      4184                   0  0.930862  0.569574\n",
       "1144      1144                   0  0.935403  0.590459\n",
       "5748      5748                   0  0.939421  0.609022\n",
       "...        ...                 ...       ...       ...\n",
       "4076      4076                  49  0.905115  0.540195\n",
       "715        715                  49  0.905965  0.541407\n",
       "6388      6388                  49  0.923375  0.566490\n",
       "810        810                  49  0.949185  0.604552\n",
       "4351      4351                  49  0.962864  0.625151\n",
       "\n",
       "[4983 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "topk = 100\n",
    "\n",
    "df_topk = df.sort_values(by=['cluster_assignment', 'dist_l2']) \\\n",
    "            .groupby('cluster_assignment') \\\n",
    "            .head(topk)\n",
    "df_rand = df.sort_values(by=['cluster_assignment']) \\\n",
    "            .groupby('cluster_assignment') \\\n",
    "            .head(topk)\n",
    "\n",
    "df_topk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "53fea5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completion_openai(\n",
    "    messages,\n",
    "    model='gpt-3.5-turbo-1106',\n",
    "    temperature=0,\n",
    "    max_tokens=256,\n",
    "    ):\n",
    "\n",
    "    import openai\n",
    "    response = {}\n",
    "    for _ in range(16):\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                n=1,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "            )\n",
    "            break\n",
    "        except openai.error.OpenAIError as e:\n",
    "            print(type(e), e)\n",
    "            time.sleep(10)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ce314f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a list of user messages, output 8 words to summarize a SINGLE central topic of the instructions or queries. Be concise and specific. Avoid repeating phrases with similar meanings. Your output should fit in a single line.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "\n",
    "\n",
    "prompts = []\n",
    "inds = df_topk[df_topk.cluster_assignment==i].iloc[:10].data_ind.to_list()\n",
    "prompts += [ds[ind]['text'] for ind in inds]\n",
    "inds = df_rand[df_rand.cluster_assignment==i].iloc[:10].data_ind.to_list()\n",
    "prompts += [ds[ind]['text'] for ind in inds]\n",
    "np.random.shuffle(prompts)\n",
    "\n",
    "\n",
    "prompt = (\"Given a list of user messages, use a few phrases to summarize a central topic \"\n",
    "          \"for all messages in the list in English. Your output should only include a single line. \"\n",
    "          \"Try to be specific. The topic should encompass \"\n",
    "         )\n",
    "prompt = (\"Given a list of user messages, output 8 words to summarize just one central topic of the instructions or queries. \"\n",
    "          \"Be concise and specific. Avoid repeating phrases with similar meanings. \"\n",
    "          \"Your output should fit in a single line.\")\n",
    "print(prompt)\n",
    "prompt = prompt + \"\\n\\n\\nBEGIN OF THE MESSAGE LIST\\n\\n\" + \\\n",
    "    '\\n\\n'.join([x.strip() for x in prompts]) + \\\n",
    "    \"\\n\\nEND OF THE MESSAGE LIST.\"\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {'role': 'user', 'content': prompt},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d68fd5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Creating a bash script to move modified files.\n",
      "2. Impact of forcing function on control system stability.\n",
      "3. Targeted delivery of therapeutic genes to brainstem.\n",
      "4. Improving UAV detection and tracking with OAO and TDOA.\n",
      "5. Incentivizing volunteers with C# code in non-profit org.\n",
      "6. Best practices for code refactoring in C#.\n",
      "7. Integration of Typescript to prevent type violations.\n",
      "8. Incorporating audio features and IP rating using Go.\n"
     ]
    }
   ],
   "source": [
    "model = 'gpt-3.5-turbo-1106'\n",
    "# model = 'gpt-4'\n",
    "response = chat_completion_openai(messages, model=model, max_tokens=256)\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c0870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a629170d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017730000000000003"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['usage']['prompt_tokens']/1000*0.001 + response['usage']['completion_tokens']/1000*0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fbd6cde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 86]) 1747637\n"
     ]
    }
   ],
   "source": [
    "from fastchat_topic_clustering import get_topk_indices, print_topk\n",
    "\n",
    "texts = [x[0]['content'] for x in ds[:len(labels)]['messages']]\n",
    "\n",
    "k = 200\n",
    "show_cut_off = 500\n",
    "topk_indices = get_topk_indices(centers, labels, embeddings, k)\n",
    "topk_str = print_topk(texts, labels, topk_indices, show_cut_off)\n",
    "num_clusters = len(centers)\n",
    "\n",
    "print(topk_indices.shape, len(topk_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53962e64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 476),\n",
       " (1, 310),\n",
       " (2, 307),\n",
       " (3, 295),\n",
       " (4, 276),\n",
       " (5, 274),\n",
       " (6, 265),\n",
       " (7, 262),\n",
       " (8, 250),\n",
       " (9, 245),\n",
       " (10, 239),\n",
       " (11, 228),\n",
       " (12, 227),\n",
       " (13, 221),\n",
       " (14, 218),\n",
       " (15, 217),\n",
       " (16, 217),\n",
       " (17, 217),\n",
       " (18, 214),\n",
       " (19, 211),\n",
       " (20, 211),\n",
       " (21, 204),\n",
       " (22, 204),\n",
       " (23, 203),\n",
       " (24, 201),\n",
       " (25, 200),\n",
       " (26, 194),\n",
       " (27, 188),\n",
       " (28, 181),\n",
       " (29, 180),\n",
       " (30, 177),\n",
       " (31, 176),\n",
       " (32, 168),\n",
       " (33, 168),\n",
       " (34, 168),\n",
       " (35, 167),\n",
       " (36, 158),\n",
       " (37, 155),\n",
       " (38, 149),\n",
       " (39, 149),\n",
       " (40, 146),\n",
       " (41, 140),\n",
       " (42, 137),\n",
       " (43, 137),\n",
       " (44, 137),\n",
       " (45, 125),\n",
       " (46, 124),\n",
       " (47, 101),\n",
       " (48, 97),\n",
       " (49, 86)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = dict(Counter(labels.tolist()))\n",
    "c = sorted(c.items())\n",
    "c\n",
    "\n",
    "# kmeans\n",
    "# [(0, 142),\n",
    "#  (1, 136),\n",
    "#  (2, 116),\n",
    "#  (3, 112),\n",
    "#  (4, 109),\n",
    "#  (5, 89),\n",
    "#  (6, 82),\n",
    "#  (7, 73),\n",
    "#  (8, 73),\n",
    "#  (9, 68)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efe89e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastchat_topic_clustering import get_cluster_info\n",
    "\n",
    "cluster_alg = 'kmeans'\n",
    "# Dump results\n",
    "filename_prefix = f\"results/clustering/c{n_clusters}_{cluster_alg}\"\n",
    "os.makedirs(os.path.dirname(filename_prefix), exist_ok=True)\n",
    "\n",
    "texts_np = np.array(texts)\n",
    "\n",
    "with open(filename_prefix + \"_topk.txt\", \"w\") as fout:\n",
    "    fout.write(topk_str)\n",
    "\n",
    "with open(filename_prefix + \"_all.jsonl\", \"w\") as fout:\n",
    "    for i in range(len(centers)):\n",
    "        tmp_indices = labels == i\n",
    "        tmp_embeddings = embeddings[tmp_indices]\n",
    "        tmp_texts = texts_np[tmp_indices]\n",
    "\n",
    "        scores = cos_sim(centers[i].unsqueeze(0), tmp_embeddings)[0]\n",
    "        sorted_indices = torch.flip(torch.argsort(scores), dims=[0])\n",
    "\n",
    "        for text, score in zip(tmp_texts[sorted_indices], scores[sorted_indices]):\n",
    "            obj = {\"cluster\": i, \"text\": text, \"sim\": score.item()}\n",
    "            fout.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# cluster_info = get_cluster_info(texts, labels, topk_indices)\n",
    "# with open(filename_prefix + \"_cluster.json\", \"w\") as fout:\n",
    "#     json.dump(cluster_info, fout, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_repr_examples = []\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fb07111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cluster_info = []\n",
    "for k in range(len(topk_indices)):\n",
    "    num_samples = torch.sum(labels == k).item()\n",
    "    topk_prompts = []\n",
    "    for idx in topk_indices[k]:\n",
    "        topk_prompts.append(texts[idx])\n",
    "    random_prompts = []\n",
    "    for idx in range(len(topk_indices)):\n",
    "        random_prompts.append(np.random.choice(texts))\n",
    "    cluster_info.append((num_samples, topk_prompts, random_prompts))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18ca8b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 86])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random.choice(text, size=100, replace=False)\n",
    "\n",
    "\n",
    "inds = np.random.choice(len(text), size=len(topk_indices), replace=False)\n",
    "random_prompts = [texts[i] for i in inds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d94b07c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Create an algorithm that identifies and categorizes each error message generated by a system and suggests potential solutions to resolve the issue. The algorithm should also provide a severity rating for each error based on its potential impact on the system's functionality.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2dabebdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 86])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# num_samples, len(topk_prompts)\n",
    "\n",
    "\n",
    "topk_indices.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "477abf91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {\n",
      "    \"dataset\": \"ultrachat\",\n",
      "    \"id\": \"ultrachat_113\",\n",
      "    \"idx\": 0,\n",
      "    \"n_turns\": 8\n",
      "}\n",
      "\n",
      "===============\n",
      "= USER        =\n",
      "===============\n",
      "Here is a piece of text: DUBAI, Aug 26 (Reuters) - Saudi Arabia’s stock market outperformed by a large margin on Sunday, led by petrochemical stocks, as Middle Eastern bourses reopened after a one-week break for the Muslim festival of Eid Al Adha.\n",
      "The Saudi stock index rose 1.4 percent, although trading volume was the lowest this year as some individual investors had not yet returned from holidays. Gainers outnumbered losers by 146 to 23.\n",
      "The market has been buoyed this year by inflows of foreign funds in anticipation of Riyadh joining emerging market indexes next year. Recent exchange data indicates those inflows have slowed but not halted as stock valuations have risen.\n",
      "Petrochemical makers were particularly strong after the Brent oil price rebounded above $75.0 a barrel last week. The top petrochemical firm, Saudi Basic Industries , added 1.8 percent and Saudi Kayan rose 3.3 percent.\n",
      "Arabian Shield Cooperative Insurance, which had been trading near 20-month lows, surged 2.5 percent after saying state utility National Water Co had engaged it to provide health insurance services to its employees for a year, a contract worth 104.5 million riyals ($27.9 million).\n",
      "Other regional stock markets were much more subdued, even though the MSCI emerging market index climbed 2.7 percent last week as Turkish markets stabilised after plunging because of the country’s currency crisis.\n",
      "Dubai’s index gained 0.4 percent as top bank Emirates NBD, which had been sliding because of its exposure to Turkey through an acquisition currently underway, rebounded for a second straight trading day, adding 2.0 percent.\n",
      "In Abu Dhabi, the index added 0.5 percent after Abu Dhabi Commercial Bank jumped in the final minutes of trade to close 2.3 percent higher. United Arab Bank soared 13.2 percent but trading volume was very low.\n",
      "Qatar’s index rose in early trade but closed 0.03 percent lower as real estate firm Ezdan, the most heavily traded stock, sank 3.3 percent.\n",
      "SAUDI ARABIA * The index added 1.4 percent to 7,979 points.\n",
      "DUBAI * The index rose 0.4 percent to 2,826 points.\n",
      "ABU DHABI * The index gained 0.5 percent to 4,910 points.\n",
      "QATAR * The index edged down 0.03 percent to 9,445 points.\n",
      "KUWAIT * The index fell 0.6 percent to 5,347 points.\n",
      "BAHRAIN * The index gained 0.3 percent to 1,352 points.\n",
      "OMAN * The index dropped 0.5 percent to 4,367 points.\n",
      "\n",
      "Based on the text material above, generate the response to the following quesion or instruction: Which regional stock markets showed subdued performance, and how did top banks in Dubai and Abu Dhabi perform?\n",
      "\n",
      "===============\n",
      "= ASSISTANT   =\n",
      "===============\n",
      "Other regional stock markets were much more subdued. In Dubai, the index gained 0.4 percent as top bank Emirates NBD, which had been sliding because of its exposure to Turkey through an acquisition currently underway, rebounded for a second straight trading day, adding 2.0 percent. In Abu Dhabi, the index added 0.5 percent after Abu Dhabi Commercial Bank jumped in the final minutes of trade to close 2.3 percent higher.\n",
      "\n",
      "===============\n",
      "= USER        =\n",
      "===============\n",
      "Can you provide more information on why petrochemical stocks were particularly strong in Saudi Arabia's stock market?\n",
      "\n",
      "===============\n",
      "= ASSISTANT   =\n",
      "===============\n",
      "Petrochemical makers were particularly strong after the Brent oil price rebounded above $75.0 a barrel last week. The top petrochemical firm, Saudi Basic Industries , added 1.8 percent and Saudi Kayan rose 3.3 percent.\n",
      "\n",
      "===============\n",
      "= USER        =\n",
      "===============\n",
      "Can you tell me which stock market had the highest number of gainers compared to losers in the recent trading day?\n",
      "\n",
      "===============\n",
      "= ASSISTANT   =\n",
      "===============\n",
      "As per the provided text, the Saudi stock market had the highest number of gainers compared to losers in the recent trading day, with gainers outnumbering losers by 146 to 23.\n",
      "\n",
      "===============\n",
      "= USER        =\n",
      "===============\n",
      "Can you provide information on the trading volume in Saudi Arabia's stock market during the recent trading day?\n",
      "\n",
      "===============\n",
      "= ASSISTANT   =\n",
      "===============\n",
      "As per the provided text, the Saudi stock market rose by 1.4 percent during the recent trading day, although trading volume was the lowest this year as some individual investors had not yet returned from holidays. Unfortunately, there is no information available on the actual trading volume during the recent trading day.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# t = dsf[i]['messages'][0]['content']\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(convert_example_to_str(\u001b[38;5;241m0\u001b[39m, dsf[i]))\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mt\u001b[49m))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(t)\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 12\n",
    "\n",
    "\n",
    "t = dsf[i]['messages'][0]['content']\n",
    "print(convert_example_to_str(0, dsf[i]))\n",
    "print(len(t))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ffa3adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664 32991\n"
     ]
    }
   ],
   "source": [
    "print(under_min_length, above_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e8b2b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)99753/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 5.74MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 1.65MB/s]\n",
      "Downloading (…)0cdb299753/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 84.0MB/s]\n",
      "Downloading (…)db299753/config.json: 100%|██████████| 571/571 [00:00<00:00, 5.29MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 1.08MB/s]\n",
      "Downloading (…)753/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 127MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 438M/438M [00:03<00:00, 117MB/s]  \n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 460kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 2.53MB/s]\n",
      "Downloading (…)99753/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 28.1MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 363/363 [00:00<00:00, 3.40MB/s]\n",
      "Downloading (…)9753/train_script.py: 100%|██████████| 13.1k/13.1k [00:00<00:00, 106MB/s]\n",
      "Downloading (…)0cdb299753/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 18.8MB/s]\n",
      "Downloading (…)b299753/modules.json: 100%|██████████| 349/349 [00:00<00:00, 3.84MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-08 00:02:46,673] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   4%|▍         | 53/1202 [01:36<34:53,  1.82s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method AutoreloadMagics.post_execute_hook of <IPython.extensions.autoreload.AutoreloadMagics object at 0x7f19c4a4e590>> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/minoconda3_x86/envs/open-instruct/lib/python3.10/site-packages/IPython/extensions/autoreload.py:715\u001b[0m, in \u001b[0;36mAutoreloadMagics.post_execute_hook\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m newly_loaded_modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(sys\u001b[38;5;241m.\u001b[39mmodules) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_modules\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m modname \u001b[38;5;129;01min\u001b[39;00m newly_loaded_modules:\n\u001b[0;32m--> 715\u001b[0m     _, pymtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename_and_mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pymtime \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reloader\u001b[38;5;241m.\u001b[39mmodules_mtimes[modname] \u001b[38;5;241m=\u001b[39m pymtime\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from fastchat_topic_clustering import get_embeddings\n",
    "\n",
    "\n",
    "embeddings = get_embeddings(texts, args.model, args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "210bbc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307563"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastchat_topic_clustering import get_embeddings\n",
    "\n",
    "\n",
    "embeddings = get_embeddings(texts, args.model, args.batch_size)\n",
    "if args.cluster_alg == \"kmeans\":\n",
    "    centers, labels = run_k_means(embeddings, num_clusters)\n",
    "elif args.cluster_alg == \"aggcls\":\n",
    "    centers, labels = run_agg_cluster(embeddings, num_clusters)\n",
    "elif args.cluster_alg == \"HDBSCAN\":\n",
    "    centers, labels = run_hdbscan_cluster(embeddings)\n",
    "else:\n",
    "    raise ValueError(f\"Invalid clustering algorithm: {args.cluster_alg}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
