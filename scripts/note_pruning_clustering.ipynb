{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5c801e",
   "metadata": {},
   "source": [
    "## submit jobs to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d98549b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"cluster.wizardlm.cl=kmeans_md=mpnet_dist=cd_emb=text+embedding_nc=[]\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 64,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python note_pruning_clustering.py --model_name all-mpnet-base-v2 --dataset wizardlm --encode_fn_type input --clustering_fn cl=kmeans_md=mpnet_dist=cd_emb=text+embedding_nc=[] --embed_type text_embedding --normalize_embeddings --save_dir /gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/clustering/input/all-mpnet-base-v2/wizardlm/cl=kmeans_md=mpnet_dist=cd_emb=text+embedding_nc=[]\n",
      "#cmds: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_in_notebook, jpt_setup; jpt_setup()\n",
    "from llm.submit import submit_job, multiline_to_singleline, shell_scripts_template_slurm\n",
    "\n",
    "first_N = None\n",
    "embed_type = 'text_embedding'\n",
    "log_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/'\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "####\n",
    "md = 'mpnet'; model_name = 'all-mpnet-base-v2'; encode_fn_type = 'input'; normalize_embeddings = True\n",
    "\n",
    "dataset = 'wizardlm'\n",
    "## \n",
    "clustering_fn_list = []\n",
    "# clustering_fn_list += [\n",
    "#     f'cl=kmeans_nc={n_clusters}' for n_clusters in [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "# ]\n",
    "\n",
    "clustering_fn_list = [\n",
    "    f\"cl=kmeans_md={md}_dist=cd_emb={'+'.join(embed_type.split('_'))}_nc={n_clusters}\"\n",
    "]\n",
    "\n",
    "# first_N = 10_000\n",
    "# clustering_fn = f'cl=kmeansminibatch_nc={n_clusters}'\n",
    "# clustering_fn = f'cl=kmeansminibatch_nc={n_clusters}_bsz=256'\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "cmds = []\n",
    "for clustering_fn in clustering_fn_list:\n",
    "    save_dir = (f\"/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/\"\n",
    "                f\"clustering/{encode_fn_type+'/' if encode_fn_type!='sft' else ''}{model_name}/\"\n",
    "                f\"{dataset+'(N='+str(first_N)+')' if first_N else dataset}/{clustering_fn}\")\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    python note_pruning_clustering.py \\\n",
    "        --model_name {model_name} \\\n",
    "        --dataset {dataset} \\\n",
    "        --encode_fn_type {encode_fn_type} \\\n",
    "        --clustering_fn {clustering_fn} \\\n",
    "        --embed_type {embed_type} \\\n",
    "        {'--normalize_embeddings' if normalize_embeddings else ''} \\\n",
    "        {'--first_N '+str(first_N) if first_N else ''} \\\n",
    "        --save_dir {save_dir} \\\n",
    "    \"\"\".strip()\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template_slurm.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.getcwd(),\n",
    "        cmd=cmd,\n",
    "        log_dir=log_dir,\n",
    "        save_dir=save_dir)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=f'cluster.{dataset}.{clustering_fn}', \n",
    "        nodes=1,\n",
    "        num_cpus=64,\n",
    "        cpu_mem=128,\n",
    "        num_gpus=1,\n",
    "        gpu_type='v100',\n",
    "        test_run=test_run,\n",
    "        job_duration=6,\n",
    "    )\n",
    "    print(cmd)\n",
    "    cmds.append(cmd)\n",
    "    \n",
    "print(f'#cmds: {len(cmds)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d45c068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cmds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnote_pruning_cluster_test.sh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES=1 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mx \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcmds\u001b[49m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cmds' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('note_pruning_cluster_test.sh', 'w') as f:\n",
    "    f.write('\\n'.join(['CUDA_VISIBLE_DEVICES=1 '+x for x in cmds]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2caf720",
   "metadata": {},
   "source": [
    "## analyze clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23810526",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>N</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model_name</th>\n",
       "      <th>encode_fn_type</th>\n",
       "      <th>clustering_fn</th>\n",
       "      <th>time_elapsed</th>\n",
       "      <th>cent_dist_l2_vs_cd_spearmanr</th>\n",
       "      <th>$\\text{inertia}\\downarrow$</th>\n",
       "      <th>$\\text{silhouette_score_cd}\\uparrow$</th>\n",
       "      <th>$\\text{silhouette_score_l2}\\uparrow$</th>\n",
       "      <th>$\\text{variance_ratio}\\uparrow$</th>\n",
       "      <th>$\\text{davies_bouldin_index}\\downarrow$</th>\n",
       "      <th>cluster_sizes_min</th>\n",
       "      <th>cluster_sizes_mean</th>\n",
       "      <th>cluster_sizes_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>1461456</td>\n",
       "      <td>ultrachat15</td>\n",
       "      <td>mistral-7b+lora:r=256:a=256</td>\n",
       "      <td>sft</td>\n",
       "      <td>cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text...</td>\n",
       "      <td>49.711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>485907.312</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.056</td>\n",
       "      <td>12885.864</td>\n",
       "      <td>2.982</td>\n",
       "      <td>5394</td>\n",
       "      <td>14614</td>\n",
       "      <td>33073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200</td>\n",
       "      <td>1461456</td>\n",
       "      <td>ultrachat15</td>\n",
       "      <td>mistral-7b+lora:r=256:a=256</td>\n",
       "      <td>sft</td>\n",
       "      <td>cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text...</td>\n",
       "      <td>71.390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>441442.531</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.050</td>\n",
       "      <td>7669.094</td>\n",
       "      <td>2.972</td>\n",
       "      <td>1339</td>\n",
       "      <td>7307</td>\n",
       "      <td>17643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300</td>\n",
       "      <td>1461456</td>\n",
       "      <td>ultrachat15</td>\n",
       "      <td>mistral-7b+lora:r=256:a=256</td>\n",
       "      <td>sft</td>\n",
       "      <td>cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text...</td>\n",
       "      <td>88.952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>419238.469</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.047</td>\n",
       "      <td>5591.206</td>\n",
       "      <td>2.982</td>\n",
       "      <td>1168</td>\n",
       "      <td>4871</td>\n",
       "      <td>22380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>400</td>\n",
       "      <td>1461456</td>\n",
       "      <td>ultrachat15</td>\n",
       "      <td>mistral-7b+lora:r=256:a=256</td>\n",
       "      <td>sft</td>\n",
       "      <td>cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text...</td>\n",
       "      <td>115.099</td>\n",
       "      <td>1.0</td>\n",
       "      <td>403325.531</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.044</td>\n",
       "      <td>4477.838</td>\n",
       "      <td>2.963</td>\n",
       "      <td>91</td>\n",
       "      <td>3653</td>\n",
       "      <td>7936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>500</td>\n",
       "      <td>1461456</td>\n",
       "      <td>ultrachat15</td>\n",
       "      <td>mistral-7b+lora:r=256:a=256</td>\n",
       "      <td>sft</td>\n",
       "      <td>cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text...</td>\n",
       "      <td>145.107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>391288.125</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.041</td>\n",
       "      <td>3765.166</td>\n",
       "      <td>2.973</td>\n",
       "      <td>385</td>\n",
       "      <td>2922</td>\n",
       "      <td>6845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>600</td>\n",
       "      <td>1461456</td>\n",
       "      <td>ultrachat15</td>\n",
       "      <td>mistral-7b+lora:r=256:a=256</td>\n",
       "      <td>sft</td>\n",
       "      <td>cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text...</td>\n",
       "      <td>174.779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>382027.375</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.041</td>\n",
       "      <td>3262.813</td>\n",
       "      <td>2.939</td>\n",
       "      <td>385</td>\n",
       "      <td>2435</td>\n",
       "      <td>6282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_clusters        N      dataset                   model_name  \\\n",
       "12         100  1461456  ultrachat15  mistral-7b+lora:r=256:a=256   \n",
       "13         200  1461456  ultrachat15  mistral-7b+lora:r=256:a=256   \n",
       "14         300  1461456  ultrachat15  mistral-7b+lora:r=256:a=256   \n",
       "15         400  1461456  ultrachat15  mistral-7b+lora:r=256:a=256   \n",
       "16         500  1461456  ultrachat15  mistral-7b+lora:r=256:a=256   \n",
       "17         600  1461456  ultrachat15  mistral-7b+lora:r=256:a=256   \n",
       "\n",
       "   encode_fn_type                                      clustering_fn  \\\n",
       "12            sft  cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text...   \n",
       "13            sft  cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text...   \n",
       "14            sft  cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text...   \n",
       "15            sft  cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text...   \n",
       "16            sft  cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text...   \n",
       "17            sft  cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text...   \n",
       "\n",
       "    time_elapsed  cent_dist_l2_vs_cd_spearmanr  $\\text{inertia}\\downarrow$  \\\n",
       "12        49.711                           1.0                  485907.312   \n",
       "13        71.390                           1.0                  441442.531   \n",
       "14        88.952                           1.0                  419238.469   \n",
       "15       115.099                           1.0                  403325.531   \n",
       "16       145.107                           1.0                  391288.125   \n",
       "17       174.779                           1.0                  382027.375   \n",
       "\n",
       "    $\\text{silhouette_score_cd}\\uparrow$  \\\n",
       "12                                 0.101   \n",
       "13                                 0.090   \n",
       "14                                 0.086   \n",
       "15                                 0.078   \n",
       "16                                 0.074   \n",
       "17                                 0.073   \n",
       "\n",
       "    $\\text{silhouette_score_l2}\\uparrow$  $\\text{variance_ratio}\\uparrow$  \\\n",
       "12                                 0.056                        12885.864   \n",
       "13                                 0.050                         7669.094   \n",
       "14                                 0.047                         5591.206   \n",
       "15                                 0.044                         4477.838   \n",
       "16                                 0.041                         3765.166   \n",
       "17                                 0.041                         3262.813   \n",
       "\n",
       "    $\\text{davies_bouldin_index}\\downarrow$  cluster_sizes_min  \\\n",
       "12                                    2.982               5394   \n",
       "13                                    2.972               1339   \n",
       "14                                    2.982               1168   \n",
       "15                                    2.963                 91   \n",
       "16                                    2.973                385   \n",
       "17                                    2.939                385   \n",
       "\n",
       "    cluster_sizes_mean  cluster_sizes_max  \n",
       "12               14614              33073  \n",
       "13                7307              17643  \n",
       "14                4871              22380  \n",
       "15                3653               7936  \n",
       "16                2922               6845  \n",
       "17                2435               6282  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from note_pruning_clustering import get_clustering_info_df\n",
    "\n",
    "dataset, model_name, n_clusters, clustering_fn = [], [], [], []\n",
    "\n",
    "df = get_clustering_info_df()\n",
    "\n",
    "dataset = ['wizardlm']; model_name = ['mpnet']; n_clusters = []; clustering_fn = ['cl=kmeans_']\n",
    "dataset = ['wizardlm']; model_name = ['bge']; n_clusters = []; clustering_fn = ['faiss']\n",
    "dataset = ['wizardlm']; model_name = ['llama']; n_clusters = []; clustering_fn = ['cd_emb=grad'] # 'cd_emb=text'\n",
    "dataset = ['ultrachat15']; model_name = ['mpnet']; n_clusters = []; clustering_fn = []\n",
    "dataset = ['ultrachat15']; model_name = ['mistral']; n_clusters = []; clustering_fn = ['cd_emb=text']\n",
    "\n",
    "def filter_fn(row):\n",
    "    b = True\n",
    "    if dataset:\n",
    "        b &= any(y in row['dataset'] for y in dataset)\n",
    "    if model_name:\n",
    "        b &= any(y in row['model_name'] for y in model_name)\n",
    "    if n_clusters:\n",
    "        b &= any(y in row['n_clusters'] for y in n_clusters)\n",
    "    if clustering_fn:\n",
    "        b &= any(y in row['clustering_fn'] for y in clustering_fn)\n",
    "    return b\n",
    "\n",
    "df = df[df.apply(filter_fn, 1)]\n",
    "df = df.sort_values(['n_clusters'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d0b488c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xs \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_clusters\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124minertia\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdownarrow$\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124msilhouette_score_cd\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124muparrow$\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "xs = df['n_clusters'].tolist()\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(10,5))\n",
    "for i, k in enumerate([f'$\\\\text{{inertia}}\\\\downarrow$',\n",
    "                       f'$\\\\text{{silhouette_score_cd}}\\\\uparrow$']):\n",
    "    ax = axs[i]\n",
    "    ys = [df[df['n_clusters']==x].iloc[0][k] for x in xs]\n",
    "    ax.plot(xs, ys)\n",
    "    ax.set_title(k.replace('\\\\', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9515deb5",
   "metadata": {},
   "source": [
    "## clustering code base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4b80c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/__init__.py:25: UserWarning: Install `torch` for functionalities dependent on torch\n",
      "  warn(f'Install `torch` for functionalities dependent on torch')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4', '5']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from rosemary import jpt_parse_args, jpt_setup, jpt_in_notebook; jpt_setup()\n",
    "\n",
    "if jpt_in_notebook():\n",
    "    import os\n",
    "    print(os.environ['CUDA_VISIBLE_DEVICES'].split(','))\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[0] \n",
    "    # '0,1,2,3,4,5'\n",
    "    print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f65fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import argparse\n",
    "import json\n",
    "import pickle\n",
    "import string\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "from note_pruning_analysis import (\n",
    "    get_lm_output,\n",
    "    get_dataset,\n",
    ")\n",
    "from note_pruning_clustering import (\n",
    "    pairwise_cosine_distance,\n",
    "    clustering_sort_by_cluster_size,\n",
    "    clustering_algorithm_scores,\n",
    "    clustering_dist_to_centroids,\n",
    "    clustering_knn_withincluster,\n",
    "    clustering_run,\n",
    "    clustering_compute_and_save_results,\n",
    "    sklearn_compute_inertia_dense,\n",
    ")\n",
    "\n",
    "from llm.submit import get_host_info\n",
    "if get_host_info()['arch'] == 'x86_64': import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7a5b259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpnet wizardlm cl=hdbscancd_md=mpnet_dist=cd_emb=text+embedding_ms=3\n"
     ]
    }
   ],
   "source": [
    "md = 'mpnet'; model_name = 'all-mpnet-base-v2'; encode_fn_type = 'input'; normalize_embeddings = True\n",
    "# md = 'bge'; model_name = 'bge-large-en-v1.5'; encode_fn_type = 'input'; normalize_embeddings = True\n",
    "# md = 'llama7b'; model_name = 'llama-7b+lora:r=256:a=256'; encode_fn_type = 'sft'; normalize_embeddings = True\n",
    "\n",
    "dataset = 'wizardlm'\n",
    "\n",
    "first_N = 10_000\n",
    "# first_N = None\n",
    "\n",
    "# clustering_fn = f'cl=kmeans_nc={n_clusters}'\n",
    "# clustering_fn = f'cl=kmeansminibatch_nc={n_clusters}_bsz=4096'\n",
    "# clustering_fn = f'cl=kmeansfaissl2_nc={n_clusters}'\n",
    "# clustering_fn = f'cl=kmeansfaisscd_nc={n_clusters}'\n",
    "\n",
    "n_clusters = 200\n",
    "\n",
    "embed_type = 'text_embedding'\n",
    "# embed_type = 'grad_rp_loraB'\n",
    "# clustering_fn = f\"cl=kmeansfaisscd_md={md}_dist=cd_emb={'+'.join(embed_type.split('_'))}_nc={n_clusters}\"\n",
    "# clustering_fn = f\"cl=kmeansfaissl2_md={md}_dist=l2_emb={'+'.join(embed_type.split('_'))}_nc={n_clusters}\"\n",
    "\n",
    "clustering_fn = f\"cl=hdbscancd_md={md}_dist=cd_emb={'+'.join(embed_type.split('_'))}_ms=3\"\n",
    "\n",
    "\n",
    "print(md, dataset, clustering_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51bad3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clustering/input/all-mpnet-base-v2/wizardlm/cl=hdbscancd_md=mpnet_dist=cd_emb=text+embedding_nc=200_test'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = os.path.join('clustering', encode_fn_type, model_name, dataset, clustering_fn+'_test')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b9ac7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/data/processed/wizardlm/json/default-a3f71ae376e517fb/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading cached processed dataset at /gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/data/processed/wizardlm/json/default-a3f71ae376e517fb/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-b089bdb80a735e3f_*_of_00016.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dataset', 'id', 'messages', 'text'],\n",
       "    num_rows: 143000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds = get_dataset(dataset, processed=True)\n",
    "if encode_fn_type == 'input':\n",
    "    def get_user_prompt_fn(example):\n",
    "        example['text'] = example['messages'][0]['content']\n",
    "        return example\n",
    "    ds = ds.map(get_user_prompt_fn, num_proc=16)\n",
    "elif encode_fn_type == 'sft':\n",
    "    def combine_first_turn_conv_fn(example):\n",
    "        example['text'] = \"[USER]\"+\" \"*20+example['messages'][0]['content']+\" \"*20+\\\n",
    "                          \"[ASSISTANT]\"+\" \"*20+example['messages'][1]['content']\n",
    "        return example\n",
    "    ds = ds.map(combine_first_turn_conv_fn, num_proc=16)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0831bfce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = get_lm_output(dataset, \n",
    "                  model_name, \n",
    "                  encode_fn_type=encode_fn_type,\n",
    "                  return_text_embedding=True,)\n",
    "\n",
    "if embed_type not in ['text_embedding', 'grad_rp_loraB']:\n",
    "    raise ValueError(f'embed_type={embed_type} not supported.')\n",
    "X = d[embed_type]\n",
    "if normalize_embeddings:\n",
    "    X = X / np.maximum(np.linalg.norm(X, axis=-1, keepdims=True), 1e-8) # possibly divide by zero.\n",
    "nan_rows = np.isnan(X).any(-1)\n",
    "if nan_rows.any():\n",
    "    print(f'Found {nan_rows.sum()} ({100*nan_rows.sum()/len(X)} pct) nan rows in embeddings. ')\n",
    "    \n",
    "if first_N:\n",
    "    ds = ds.select(range(first_N))\n",
    "    X = X[:first_N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "84d79649",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling a subset of 51200 / 143000 for training\n",
      "Clustering 51200 points in 1024D to 200 clusters, redo 1 times, 30 iterations\n",
      "  Preprocessing in 0.23 s\n",
      "  Iteration 29 (15.26 s, search 13.49 s): objective=21083.8 imbalance=1.102 nsplit=0       \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "info = {}\n",
    "info['N'] = len(X)\n",
    "info['dataset'] = dataset\n",
    "info['model_name'] = model_name\n",
    "info['encode_fn_type'] = encode_fn_type\n",
    "info['clustering_fn'] = clustering_fn\n",
    "\n",
    "t0 = time.time()\n",
    "Y, C = clustering_run(clustering_fn, X)\n",
    "info['time_elapsed'] = time.time()-t0\n",
    "info['scores'] = {}\n",
    "info['scores'].update({'inertia': sklearn_compute_inertia_dense(X, Y, C)})\n",
    "info['scores'].update(clustering_algorithm_scores(X, Y))\n",
    "\n",
    "df = clustering_compute_and_save_results(X, Y, C, ds=ds, save_dir=save_dir)\n",
    "info['cent_dist_l2_vs_cd_spearmanr'] = float(scipy.stats.spearmanr(\n",
    "    df['cent_dist_l2'].to_numpy(), df['cent_dist_cd'].to_numpy()).statistic)\n",
    "info['cluster_sizes'] = np.unique(Y, return_counts=True)[1].tolist()\n",
    "\n",
    "with open(os.path.join(save_dir, 'info.json'), 'w') as f:\n",
    "    json.dump(info, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11c47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c977d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc00100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
