{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e5bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import json\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rosemary import jpt_parse_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fff18ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--in-files\", nargs=\"+\", type=str)\n",
    "parser.add_argument(\"--out-file\", type=str, default=\"sharegpt_split.json\")\n",
    "parser.add_argument(\"--begin\", type=int)\n",
    "parser.add_argument(\"--end\", type=int)\n",
    "parser.add_argument(\"--model-name-or-path\", type=str, required=True)\n",
    "parser.add_argument(\"--max-length\", type=int, default=2048)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "cmd = \"\"\"\n",
    "--in-files ../data/raw_train/sharegpt/sg_90k_part1_html_cleaned.json ../data/raw_train/sharegpt/sg_90k_part2_html_cleaned.json\n",
    "--out-file ../data/raw_train/sharegpt/sharegpt_html_cleaned_and_split.json\n",
    "--model-name-or-path mosaicml/mpt-7b\n",
    "\"\"\"\n",
    "\n",
    "# --model-name-or-path huggyllama/llama-7b\n",
    "# \n",
    "\n",
    "args = jpt_parse_args(parser, cmd=cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca394199",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "for file in args.in_files:\n",
    "    content.extend(json.load(open(file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e8a4cee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76920\n",
      "dict_keys(['id', 'conversations'])\n",
      "12\n",
      "dict_keys(['from', 'value'])\n",
      "\n",
      "===== human =====\n",
      "Summarize the main ideas of Jeff Walker's Product Launch Formula into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...\n",
      "\n",
      "===== gpt =====\n",
      "Here are the main ideas of Jeff Walker's Product Launch Formula that can be applied by a growth marketing agency for their clients:\n",
      "\n",
      "1. Identify the target audience and their needs: Understand the ideal customer for the product or service, and create a messaging that resonates with them.\n",
      "2. Pre-launch: Build anticipation and excitement for the launch by creating buzz, gathering testimonials and case studies, and using social media to create awareness.\n",
      "3. Launch: Use a well-crafted launch sequence to maximize sales and conversions. This can include offering bonuses, creating scarcity, and using a deadline to create urgency.\n",
      "4. Post-launch: Follow up with customers, gather feedback, and continue to provide value to keep them engaged and loyal.\n",
      "5. Create a product suite: Once the initial product is successful, expand the offering by creating additional products or services that address other needs of the same audience.\n",
      "6. Continual optimization: Continually monitor and optimize the launch process and product suite to improve results.\n",
      "7. Build a community: Use the launch process to build a community of customers who are passionate about the product and can help spread the word.\n",
      "8. Use automation: Use technology and automation to streamline the launch process and improve efficiency.\n",
      "\n",
      "===== human =====\n",
      "Summarize the main ideas of Brendon Burchard's Experts Academy into bullet points as it pertains to a growth marketing agency implementing these strategies and tactics for their clients...\n"
     ]
    }
   ],
   "source": [
    "print(len(content))\n",
    "print(content[0].keys())\n",
    "\n",
    "i = 1\n",
    "conversations = content[i]['conversations']\n",
    "print(len(conversations))\n",
    "print(conversations[i].keys())\n",
    "\n",
    "N = 3\n",
    "\n",
    "for i in range(N):\n",
    "    print(f\"\\n===== {conversations[i]['from']} =====\")\n",
    "    print(conversations[i]['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ff0f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    padding_side=\"right\",\n",
    "#     use_fast=False,\n",
    ")\n",
    "\n",
    "# mpt-7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e02c0652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2149 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2932 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (12931 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2539 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2452 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4128 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2325 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2491 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2325 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2628 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5362 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2327 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2221 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2678 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2326 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  0%|          | 229/76920 [00:00<00:34, 2250.04it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (4253 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2803 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2801 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2465 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2351 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4353 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2071 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2450 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2201 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2293 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2602 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8912 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  1%|          | 540/76920 [00:00<01:42, 741.71it/s] Token indices sequence length is longer than the specified maximum sequence length for this model (2415 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3960 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2507 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  1%|          | 826/76920 [00:00<01:17, 978.09it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2179 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2380 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2086 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2678 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2184 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  1%|▏         | 965/76920 [00:00<01:16, 997.08it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2750 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6772 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  2%|▏         | 1201/76920 [00:01<01:00, 1247.52it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2091 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3654 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7233 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  2%|▏         | 1360/76920 [00:01<01:02, 1209.88it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2799 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2139 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2767 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1503/76920 [00:01<01:13, 1027.95it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2158 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2299 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2650 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  2%|▏         | 1623/76920 [00:01<01:40, 748.38it/s] Token indices sequence length is longer than the specified maximum sequence length for this model (2422 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2849 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2656 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2775 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  2%|▏         | 1717/76920 [00:02<02:03, 610.23it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3557 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2333 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2342 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2256 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2494 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3095 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  3%|▎         | 2223/76920 [00:02<01:13, 1015.49it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2065 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2267 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3063 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3356 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2462 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  3%|▎         | 2428/76920 [00:02<01:21, 915.78it/s] Token indices sequence length is longer than the specified maximum sequence length for this model (2557 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3328 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  4%|▍         | 3046/76920 [00:02<00:46, 1602.43it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2222 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3993 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  4%|▍         | 3334/76920 [00:02<00:42, 1736.09it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2343 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4234 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2382 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3384 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4286 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2773 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2484 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2189 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  5%|▍         | 3575/76920 [00:03<00:49, 1475.02it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3714 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2080 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4290 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  5%|▍         | 3757/76920 [00:03<00:50, 1449.19it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2829 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3717 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2311 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2119 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3176 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  5%|▌         | 3925/76920 [00:03<01:05, 1118.62it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2166 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2137 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2436 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2173 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3200 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2399 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2556 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3114 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2576 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  6%|▌         | 4241/76920 [00:03<01:13, 985.24it/s] Token indices sequence length is longer than the specified maximum sequence length for this model (2541 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3851 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  6%|▌         | 4432/76920 [00:04<01:13, 980.18it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2230 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  7%|▋         | 5097/76920 [00:04<00:39, 1815.03it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2780 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5313 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2728 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2076 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  7%|▋         | 5369/76920 [00:04<00:39, 1818.18it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2293 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2258 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2201 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2203 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  7%|▋         | 5614/76920 [00:04<00:53, 1340.32it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2333 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  8%|▊         | 5832/76920 [00:05<01:51, 639.33it/s] Token indices sequence length is longer than the specified maximum sequence length for this model (3020 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  8%|▊         | 6275/76920 [00:06<01:47, 658.82it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2256 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  9%|▊         | 6675/76920 [00:06<01:13, 961.34it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2085 > 2048). Running this sequence through the model will result in indexing errors\n",
      "  9%|▉         | 6947/76920 [00:06<01:00, 1158.84it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3763 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 10%|▉         | 7657/76920 [00:07<01:00, 1143.91it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (5753 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2152 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 10%|█         | 7847/76920 [00:07<01:03, 1086.49it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2054 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 11%|█         | 8083/76920 [00:07<00:53, 1292.79it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2313 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3564 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6688 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 12%|█▏        | 9024/76920 [00:08<00:49, 1385.38it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2763 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 12%|█▏        | 9196/76920 [00:08<01:05, 1036.40it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3628 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 12%|█▏        | 9521/76920 [00:08<01:07, 998.31it/s] Token indices sequence length is longer than the specified maximum sequence length for this model (5325 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2630 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 14%|█▍        | 11003/76920 [00:09<00:51, 1276.74it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2132 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3627 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 15%|█▍        | 11491/76920 [00:10<00:46, 1395.91it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3275 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 15%|█▌        | 11658/76920 [00:10<00:49, 1319.36it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2715 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 16%|█▋        | 12604/76920 [00:10<00:52, 1231.33it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2939 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 17%|█▋        | 13195/76920 [00:11<00:54, 1170.26it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2566 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 19%|█▊        | 14406/76920 [00:12<00:50, 1227.87it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2127 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 19%|█▉        | 14672/76920 [00:12<00:42, 1475.84it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2414 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 16510/76920 [00:13<00:43, 1382.73it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3125 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 24%|██▎       | 18207/76920 [00:15<00:42, 1368.50it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2314 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4969 > 2048). Running this sequence through the model will result in indexing errors\n",
      " 28%|██▊       | 21361/76920 [00:17<00:32, 1706.51it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2269 > 2048). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 76920/76920 [00:59<00:00, 1291.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from split_sharegpt_conversations import split_all, filter_invalid_roles\n",
    "new_content = split_all(content, args.begin, args.end, tokenizer, args.max_length)\n",
    "\n",
    "# len(new_content):\n",
    "# llama:  178604\n",
    "# mpt-7b: 168815\n",
    "#\n",
    "new_content = filter_invalid_roles(new_content)\n",
    "\n",
    "# len(new_content):\n",
    "# mpt-7b: 160564\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1157d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 76920, new: 160564\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"total: {len(content)}, new: {len(new_content)}\")\n",
    "json.dump(new_content, open(args.out_file, \"w\"), indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
