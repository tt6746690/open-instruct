{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a099bd",
   "metadata": {},
   "source": [
    "Goal\n",
    "- explore tulu paper's results and see if I could fit data mixture to eval results, visualize task input-output dependendices.\n",
    "\n",
    "\n",
    "some todo:\n",
    "1. think about how to normalize input/output.\n",
    "2. think about normalize w.r.t. number of training tokens, data points.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6299213c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/__init__.py:25: UserWarning: Install `torch` for functionalities dependent on torch\n",
      "  warn(f'Install `torch` for functionalities dependent on torch')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "from rosemary import plt_scaled_colobar_ax\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5406c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_datasets = [\n",
    "    # human-authored\n",
    "    'SuperNI',\n",
    "    'CoT',\n",
    "    'Flan V2',\n",
    "    'Dolly',\n",
    "    'Open Assistant 1',\n",
    "    # gpt-generated\n",
    "    'Self-instruct',\n",
    "    'Unnatural Instructions',\n",
    "    'Alpaca',\n",
    "    'Code-Alpaca',\n",
    "    'GPT4-Alpaca',\n",
    "    'Baize',\n",
    "    'ShareGPT',\n",
    "]\n",
    "\n",
    "p = len(instruct_datasets)\n",
    "\n",
    "def encode_input(dataset):\n",
    "    if dataset in ('LLaMa-13B', 'Vanilla LLaMa'):\n",
    "        return [0]*p\n",
    "    if dataset == 'Human mix':\n",
    "        # FLAN V2, CoT, Dolly, and Open Assistant 1\n",
    "        return [0,1,1,1,1,0,0,0,0,0,0,0]\n",
    "    if dataset == 'H+GPT mix':\n",
    "        # FLAN V2, CoT, Dolly, and Open Assistant 1, GPT4-Alpaca, Code-Alpaca, and ShareGPT.\n",
    "        return [0,1,1,1,1,0,0,0,1,1,0,1]\n",
    "    x = [0]*p\n",
    "    i = datasets.index(dataset)\n",
    "    x[i] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a119245f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Base Model</th>\n",
       "      <th>Instruction Dataset</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MMLU</th>\n",
       "      <th colspan=\"2\" halign=\"left\">GSM</th>\n",
       "      <th colspan=\"2\" halign=\"left\">BBH</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TydiQA</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Codex-Eval</th>\n",
       "      <th>AlpacaFarm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0-shot</th>\n",
       "      <th>5-shot</th>\n",
       "      <th>Direct</th>\n",
       "      <th>CoT</th>\n",
       "      <th>Direct</th>\n",
       "      <th>CoT</th>\n",
       "      <th>GB</th>\n",
       "      <th>CB</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@10</th>\n",
       "      <th>v Davinci-003</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama7b</td>\n",
       "      <td></td>\n",
       "      <td>31.9</td>\n",
       "      <td>35.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>39.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>11.6</td>\n",
       "      <td>18.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>SuperNI</td>\n",
       "      <td>44.1</td>\n",
       "      <td>43.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>47.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>CoT</td>\n",
       "      <td>41.3</td>\n",
       "      <td>42.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>27.5</td>\n",
       "      <td>33.7</td>\n",
       "      <td>31.3</td>\n",
       "      <td>44.4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>17.3</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>Flan V2</td>\n",
       "      <td>45.4</td>\n",
       "      <td>47.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.6</td>\n",
       "      <td>36.1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>Dolly</td>\n",
       "      <td>38.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>24.4</td>\n",
       "      <td>43.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>11.1</td>\n",
       "      <td>22.1</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>Open Assistant 1</td>\n",
       "      <td>32.9</td>\n",
       "      <td>29.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>20.4</td>\n",
       "      <td>29.5</td>\n",
       "      <td>26.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>10.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>47.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>Self-instruct</td>\n",
       "      <td>35.7</td>\n",
       "      <td>33.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>29.9</td>\n",
       "      <td>29.2</td>\n",
       "      <td>35.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>Unnatural Instructions</td>\n",
       "      <td>42.9</td>\n",
       "      <td>38.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>19.8</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>Alpaca</td>\n",
       "      <td>41.5</td>\n",
       "      <td>40.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>31.8</td>\n",
       "      <td>31.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>13.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>Code-Alpaca</td>\n",
       "      <td>34.7</td>\n",
       "      <td>34.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>29.6</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>16.5</td>\n",
       "      <td>29.2</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>GPT4-Alpaca</td>\n",
       "      <td>42.6</td>\n",
       "      <td>38.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>23.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>13.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>Baize</td>\n",
       "      <td>40.3</td>\n",
       "      <td>38.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>30.6</td>\n",
       "      <td>32.4</td>\n",
       "      <td>29.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>12.2</td>\n",
       "      <td>23.8</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>ShareGPT</td>\n",
       "      <td>44.3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>32.6</td>\n",
       "      <td>25.5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>10.9</td>\n",
       "      <td>21.6</td>\n",
       "      <td>58.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>Human mix</td>\n",
       "      <td>46.2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>35.6</td>\n",
       "      <td>34.8</td>\n",
       "      <td>42.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>20.2</td>\n",
       "      <td>29.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>llama7b</td>\n",
       "      <td>H+GPT mix</td>\n",
       "      <td>44.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>39.2</td>\n",
       "      <td>45.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>17.5</td>\n",
       "      <td>27.8</td>\n",
       "      <td>48.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Base Model     Instruction Dataset   MMLU           GSM          BBH        \\\n",
       "                                      0-shot 5-shot Direct   CoT Direct   CoT   \n",
       "0     llama7b                           31.9   35.2    6.0   9.0   34.0  33.3   \n",
       "1     llama7b                 SuperNI   44.1   43.4    3.0   4.0   38.4   1.9   \n",
       "2     llama7b                     CoT   41.3   42.5    6.5  27.5   33.7  31.3   \n",
       "3     llama7b                 Flan V2   45.4   47.1    3.5  13.0   38.6  36.1   \n",
       "4     llama7b                   Dolly   38.0   35.8    5.0   7.0   27.2  24.4   \n",
       "5     llama7b        Open Assistant 1   32.9   29.7    6.0   6.5   20.4  29.5   \n",
       "6     llama7b           Self-instruct   35.7   33.2    4.0   6.5   29.9  29.2   \n",
       "7     llama7b  Unnatural Instructions   42.9   38.1    3.5   5.0   31.4  30.0   \n",
       "8     llama7b                  Alpaca   41.5   40.3    7.0  10.0   32.6  31.8   \n",
       "9     llama7b             Code-Alpaca   34.7   34.5    6.5   7.5   29.6  30.5   \n",
       "10    llama7b             GPT4-Alpaca   42.6   38.3    6.5  10.0   28.5  32.3   \n",
       "11    llama7b                   Baize   40.3   38.6    3.5   5.5   30.6  32.4   \n",
       "12    llama7b                ShareGPT   44.3   40.0    8.0   9.5    5.2  32.6   \n",
       "13    llama7b               Human mix   46.2   48.0    4.5  26.5   35.6  34.8   \n",
       "14    llama7b               H+GPT mix   44.5   47.0    6.0  27.0   38.1  39.2   \n",
       "\n",
       "   TydiQA       Codex-Eval          AlpacaFarm  \n",
       "       GB    CB        P@1  P@10 v Davinci-003  \n",
       "0    39.1   9.5       11.6  18.3           NaN  \n",
       "1    47.9   7.1        7.0  11.7           5.7  \n",
       "2    44.4   8.5        7.4  17.3           4.2  \n",
       "3    45.0   8.3        9.6  12.9           4.6  \n",
       "4    43.6   8.7       11.1  22.1          12.7  \n",
       "5    26.8   7.8       10.1  20.4          47.8  \n",
       "6    35.4   8.7        6.2  12.1           7.5  \n",
       "7    36.3   6.5       10.3  19.8           8.2  \n",
       "8    31.2   7.2       13.2  22.0          21.1  \n",
       "9    36.7  10.5       16.5  29.2          17.5  \n",
       "10   23.6   5.8       13.2  25.0          57.0  \n",
       "11   29.8   7.9       12.2  23.8          23.5  \n",
       "12   25.5   8.9       10.9  21.6          58.3  \n",
       "13   42.2   7.7        9.4  20.2          29.4  \n",
       "14   45.7   7.7       17.5  27.8          48.3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    ['', 31.9, 35.2, 6.0, 9.0, 34.0, 33.3, 39.1, 9.5, 11.6, 18.3, None, None],\n",
    "    ['SuperNI', 44.1, 43.4, 3.0, 4.0, 38.4, 1.9, 47.9, 7.1, 7.0, 11.7, 5.7, 18.3],\n",
    "    ['CoT', 41.3, 42.5, 6.5, 27.5, 33.7, 31.3, 44.4, 8.5, 7.4, 17.3, 4.2, 22.4],\n",
    "    ['Flan V2', 45.4, 47.1, 3.5, 13.0, 38.6, 36.1, 45.0, 8.3, 9.6, 12.9, 4.6, 22.4],\n",
    "    ['Dolly', 38.0, 35.8, 5.0, 7.0, 27.2, 24.4, 43.6, 8.7, 11.1, 22.1, 12.7, 20.7],\n",
    "    ['Open Assistant 1', 32.9, 29.7, 6.0, 6.5, 20.4, 29.5, 26.8, 7.8, 10.1, 20.4, 47.8, 23.8],\n",
    "    ['Self-instruct', 35.7, 33.2, 4.0, 6.5, 29.9, 29.2, 35.4, 8.7, 6.2, 12.1, 7.5, 18.0],\n",
    "    ['Unnatural Instructions', 42.9, 38.1, 3.5, 5.0, 31.4, 30.0, 36.3, 6.5, 10.3, 19.8, 8.2, 20.0],\n",
    "    ['Alpaca', 41.5, 40.3, 7.0, 10.0, 32.6, 31.8, 31.2, 7.2, 13.2, 22.0, 21.1, 23.3],\n",
    "    ['Code-Alpaca', 34.7, 34.5, 6.5, 7.5, 29.6, 30.5, 36.7, 10.5, 16.5, 29.2, 17.5, 22.6],\n",
    "    ['GPT4-Alpaca', 42.6, 38.3, 6.5, 10.0, 28.5, 32.3, 23.6, 5.8, 13.2, 25.0, 57.0, 28.3],\n",
    "    ['Baize', 40.3, 38.6, 3.5, 5.5, 30.6, 32.4, 29.8, 7.9, 12.2, 23.8, 23.5, 22.6],\n",
    "    ['ShareGPT', 44.3, 40.0, 8.0, 9.5, 5.2, 32.6, 25.5, 8.9, 10.9, 21.6, 58.3, 26.9],\n",
    "    ['Human mix', 46.2, 48.0, 4.5, 26.5, 35.6, 34.8, 42.2, 7.7, 9.4, 20.2, 29.4, 27.8],\n",
    "    ['H+GPT mix', 44.5, 47.0, 6.0, 27.0, 38.1, 39.2, 45.7, 7.7, 17.5, 27.8, 48.3, 33.1]\n",
    "]\n",
    "\n",
    "evals = [\n",
    "    ('MMLU', '0-shot'),\n",
    "    ('MMLU', '5-shot'),\n",
    "    ('GSM', 'Direct'),\n",
    "    ('GSM', 'CoT'),\n",
    "    ('BBH', 'Direct'),\n",
    "    ('BBH', 'CoT'),\n",
    "    ('TydiQA', 'GB'),\n",
    "    ('TydiQA', 'CB'),\n",
    "    ('Codex-Eval', 'P@1'),\n",
    "    ('Codex-Eval', 'P@10'),\n",
    "    ('AlpacaFarm', 'v Davinci-003'),\n",
    "]\n",
    "\n",
    "cols = [('Instruction Dataset', '')] + evals + [('Average', '')]\n",
    "multi_columns = pd.MultiIndex.from_tuples(cols)\n",
    "df = pd.DataFrame(data, columns=multi_columns)\n",
    "df.insert(0, ('Base Model', ''), 'llama7b')\n",
    "\n",
    "## verify the numbers copied from pdf, processed by chatgpt is correct.\n",
    "avg_major_column = df[evals].groupby(level=0, axis=1).mean()\n",
    "avg_row = avg_major_column.mean(axis=1)\n",
    "assert np.nanmean(avg_row.to_numpy() - df[('Average', '')].to_numpy())<0.01\n",
    "df = df.drop(columns=[('Average','')])\n",
    "##\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1851231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'superni',\n",
       " 'cot',\n",
       " 'flanv2',\n",
       " 'dolly',\n",
       " 'oasst1',\n",
       " 'selfinstruct',\n",
       " 'unnaturalinstructions',\n",
       " 'stanfordalpaca',\n",
       " 'codealpaca',\n",
       " 'gpt4alpaca',\n",
       " 'baize',\n",
       " 'sharegpt',\n",
       " 'humanmix',\n",
       " 'h+gptmix']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def shorten_dataset_name(x):\n",
    "    x = x.replace('-', '')\n",
    "    x = x.replace(' ', '')\n",
    "    x = x.lower()\n",
    "    if x == 'alpaca':\n",
    "        x = 'stanfordalpaca'\n",
    "    if x == 'openassistant1':\n",
    "        x = 'oasst1'\n",
    "    return x\n",
    "df['Instruction Dataset'].map(shorten_dataset_name).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b72dd9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bab57_row0_col1, #T_bab57_row1_col2, #T_bab57_row6_col4, #T_bab57_row11_col3 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row0_col2 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row0_col3 {\n",
       "  background-color: #e16751;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row0_col4 {\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row1_col1, #T_bab57_row2_col3 {\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row1_col3 {\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row1_col4 {\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row2_col1, #T_bab57_row4_col3 {\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row2_col2, #T_bab57_row3_col3, #T_bab57_row12_col1, #T_bab57_row13_col4 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row2_col4, #T_bab57_row5_col2, #T_bab57_row6_col2 {\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row3_col1 {\n",
       "  background-color: #c83836;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row3_col2 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row3_col4 {\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row4_col1 {\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row4_col2 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row4_col4 {\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row5_col1 {\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row5_col3 {\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row5_col4 {\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row6_col1 {\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row6_col3 {\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row7_col1 {\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row7_col2, #T_bab57_row9_col2 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row7_col3 {\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row7_col4, #T_bab57_row9_col4 {\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row8_col1 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row8_col2 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row8_col3 {\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row8_col4, #T_bab57_row12_col3 {\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row9_col1 {\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row9_col3 {\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row10_col1 {\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row10_col2 {\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row10_col3 {\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row10_col4 {\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row11_col1 {\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row11_col2 {\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row11_col4 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row12_col2 {\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row12_col4 {\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bab57_row13_col1 {\n",
       "  background-color: #dc5d4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row13_col2 {\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bab57_row13_col3 {\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bab57\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bab57_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_bab57_level0_col1\" class=\"col_heading level0 col1\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_bab57_level0_col2\" class=\"col_heading level0 col2\" >GSM/CoT</th>\n",
       "      <th id=\"T_bab57_level0_col3\" class=\"col_heading level0 col3\" >BBH/Direct</th>\n",
       "      <th id=\"T_bab57_level0_col4\" class=\"col_heading level0 col4\" >Codex-Eval/P@1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bab57_row0_col0\" class=\"data row0 col0\" >llama7b (Paper)</td>\n",
       "      <td id=\"T_bab57_row0_col1\" class=\"data row0 col1\" >31.9</td>\n",
       "      <td id=\"T_bab57_row0_col2\" class=\"data row0 col2\" >9.0</td>\n",
       "      <td id=\"T_bab57_row0_col3\" class=\"data row0 col3\" >34.0</td>\n",
       "      <td id=\"T_bab57_row0_col4\" class=\"data row0 col4\" >11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bab57_row1_col0\" class=\"data row1 col0\" >llama7b+superni (Paper)</td>\n",
       "      <td id=\"T_bab57_row1_col1\" class=\"data row1 col1\" >44.1</td>\n",
       "      <td id=\"T_bab57_row1_col2\" class=\"data row1 col2\" >4.0</td>\n",
       "      <td id=\"T_bab57_row1_col3\" class=\"data row1 col3\" >38.4</td>\n",
       "      <td id=\"T_bab57_row1_col4\" class=\"data row1 col4\" >7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bab57_row2_col0\" class=\"data row2 col0\" >llama7b+cot (Paper)</td>\n",
       "      <td id=\"T_bab57_row2_col1\" class=\"data row2 col1\" >41.3</td>\n",
       "      <td id=\"T_bab57_row2_col2\" class=\"data row2 col2\" >27.5</td>\n",
       "      <td id=\"T_bab57_row2_col3\" class=\"data row2 col3\" >33.7</td>\n",
       "      <td id=\"T_bab57_row2_col4\" class=\"data row2 col4\" >7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bab57_row3_col0\" class=\"data row3 col0\" >llama7b+flanv2 (Paper)</td>\n",
       "      <td id=\"T_bab57_row3_col1\" class=\"data row3 col1\" >45.4</td>\n",
       "      <td id=\"T_bab57_row3_col2\" class=\"data row3 col2\" >13.0</td>\n",
       "      <td id=\"T_bab57_row3_col3\" class=\"data row3 col3\" >38.6</td>\n",
       "      <td id=\"T_bab57_row3_col4\" class=\"data row3 col4\" >9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_bab57_row4_col0\" class=\"data row4 col0\" >llama7b+dolly (Paper)</td>\n",
       "      <td id=\"T_bab57_row4_col1\" class=\"data row4 col1\" >38.0</td>\n",
       "      <td id=\"T_bab57_row4_col2\" class=\"data row4 col2\" >7.0</td>\n",
       "      <td id=\"T_bab57_row4_col3\" class=\"data row4 col3\" >27.2</td>\n",
       "      <td id=\"T_bab57_row4_col4\" class=\"data row4 col4\" >11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_bab57_row5_col0\" class=\"data row5 col0\" >llama7b+openassistant1 (Paper)</td>\n",
       "      <td id=\"T_bab57_row5_col1\" class=\"data row5 col1\" >32.9</td>\n",
       "      <td id=\"T_bab57_row5_col2\" class=\"data row5 col2\" >6.5</td>\n",
       "      <td id=\"T_bab57_row5_col3\" class=\"data row5 col3\" >20.4</td>\n",
       "      <td id=\"T_bab57_row5_col4\" class=\"data row5 col4\" >10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_bab57_row6_col0\" class=\"data row6 col0\" >llama7b+selfinstruct (Paper)</td>\n",
       "      <td id=\"T_bab57_row6_col1\" class=\"data row6 col1\" >35.7</td>\n",
       "      <td id=\"T_bab57_row6_col2\" class=\"data row6 col2\" >6.5</td>\n",
       "      <td id=\"T_bab57_row6_col3\" class=\"data row6 col3\" >29.9</td>\n",
       "      <td id=\"T_bab57_row6_col4\" class=\"data row6 col4\" >6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_bab57_row7_col0\" class=\"data row7 col0\" >llama7b+alpaca (Paper)</td>\n",
       "      <td id=\"T_bab57_row7_col1\" class=\"data row7 col1\" >41.5</td>\n",
       "      <td id=\"T_bab57_row7_col2\" class=\"data row7 col2\" >10.0</td>\n",
       "      <td id=\"T_bab57_row7_col3\" class=\"data row7 col3\" >32.6</td>\n",
       "      <td id=\"T_bab57_row7_col4\" class=\"data row7 col4\" >13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_bab57_row8_col0\" class=\"data row8 col0\" >llama7b+codealpaca (Paper)</td>\n",
       "      <td id=\"T_bab57_row8_col1\" class=\"data row8 col1\" >34.7</td>\n",
       "      <td id=\"T_bab57_row8_col2\" class=\"data row8 col2\" >7.5</td>\n",
       "      <td id=\"T_bab57_row8_col3\" class=\"data row8 col3\" >29.6</td>\n",
       "      <td id=\"T_bab57_row8_col4\" class=\"data row8 col4\" >16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_bab57_row9_col0\" class=\"data row9 col0\" >llama7b+gpt4alpaca (Paper)</td>\n",
       "      <td id=\"T_bab57_row9_col1\" class=\"data row9 col1\" >42.6</td>\n",
       "      <td id=\"T_bab57_row9_col2\" class=\"data row9 col2\" >10.0</td>\n",
       "      <td id=\"T_bab57_row9_col3\" class=\"data row9 col3\" >28.5</td>\n",
       "      <td id=\"T_bab57_row9_col4\" class=\"data row9 col4\" >13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row10\" class=\"row_heading level0 row10\" >11</th>\n",
       "      <td id=\"T_bab57_row10_col0\" class=\"data row10 col0\" >llama7b+baize (Paper)</td>\n",
       "      <td id=\"T_bab57_row10_col1\" class=\"data row10 col1\" >40.3</td>\n",
       "      <td id=\"T_bab57_row10_col2\" class=\"data row10 col2\" >5.5</td>\n",
       "      <td id=\"T_bab57_row10_col3\" class=\"data row10 col3\" >30.6</td>\n",
       "      <td id=\"T_bab57_row10_col4\" class=\"data row10 col4\" >12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row11\" class=\"row_heading level0 row11\" >12</th>\n",
       "      <td id=\"T_bab57_row11_col0\" class=\"data row11 col0\" >llama7b+sharegpt (Paper)</td>\n",
       "      <td id=\"T_bab57_row11_col1\" class=\"data row11 col1\" >44.3</td>\n",
       "      <td id=\"T_bab57_row11_col2\" class=\"data row11 col2\" >9.5</td>\n",
       "      <td id=\"T_bab57_row11_col3\" class=\"data row11 col3\" >5.2</td>\n",
       "      <td id=\"T_bab57_row11_col4\" class=\"data row11 col4\" >10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row12\" class=\"row_heading level0 row12\" >13</th>\n",
       "      <td id=\"T_bab57_row12_col0\" class=\"data row12 col0\" >llama7b+humanmix (Paper)</td>\n",
       "      <td id=\"T_bab57_row12_col1\" class=\"data row12 col1\" >46.2</td>\n",
       "      <td id=\"T_bab57_row12_col2\" class=\"data row12 col2\" >26.5</td>\n",
       "      <td id=\"T_bab57_row12_col3\" class=\"data row12 col3\" >35.6</td>\n",
       "      <td id=\"T_bab57_row12_col4\" class=\"data row12 col4\" >9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bab57_level0_row13\" class=\"row_heading level0 row13\" >14</th>\n",
       "      <td id=\"T_bab57_row13_col0\" class=\"data row13 col0\" >llama7b+h+gptmix (Paper)</td>\n",
       "      <td id=\"T_bab57_row13_col1\" class=\"data row13 col1\" >44.5</td>\n",
       "      <td id=\"T_bab57_row13_col2\" class=\"data row13 col2\" >27.0</td>\n",
       "      <td id=\"T_bab57_row13_col3\" class=\"data row13 col3\" >38.1</td>\n",
       "      <td id=\"T_bab57_row13_col4\" class=\"data row13 col4\" >17.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffd777a2f80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfc = df.copy()\n",
    "def shorten_dataset_name(x):\n",
    "    x = x.replace('-', '')\n",
    "    x = x.replace(' ', '')\n",
    "    x = x.lower()\n",
    "    return x\n",
    "dfc['Instruction Dataset'] = dfc['Instruction Dataset'].map(shorten_dataset_name)\n",
    "dfc.columns = [f'{x}/{y}' if y else x for x,y in dfc.columns]\n",
    "# dfc['Base Model'] + '_' + dfc['Instruction Dataset']\n",
    "dfc.insert(0, 'Model', dfc.apply(lambda r: f\"{r['Base Model']}\" if not r['Instruction Dataset']\n",
    "          else f\"{r['Base Model']}+{r['Instruction Dataset']}\", axis=1))\n",
    "dfc['Model'] = dfc['Model'].astype(str) + ' (Paper)'\n",
    "# dfc = dfc[dfc['Instruction Dataset'].isin(['', 'Human mix', 'H+GPT mix'])]\n",
    "dfc = dfc[~dfc['Instruction Dataset'].isin(['unnaturalinstructions'])]\n",
    "\n",
    "dfc = dfc.drop(columns=['Base Model', 'Instruction Dataset'])\n",
    "dfc = dfc[['Model', 'MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'Codex-Eval/P@1']] # 'BBH/CoT', \n",
    "#display(dfc.style.format(precision=1))\n",
    "display(dfc.style.background_gradient(cmap ='coolwarm').format(precision=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4406b109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMLU_0-shot</th>\n",
       "      <th>MMLU_5-shot</th>\n",
       "      <th>GSM_Direct</th>\n",
       "      <th>GSM_CoT</th>\n",
       "      <th>BBH_Direct</th>\n",
       "      <th>BBH_CoT</th>\n",
       "      <th>Codex-Eval_P@1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.9</td>\n",
       "      <td>35.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.1</td>\n",
       "      <td>43.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.3</td>\n",
       "      <td>42.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>27.5</td>\n",
       "      <td>33.7</td>\n",
       "      <td>31.3</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.4</td>\n",
       "      <td>47.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.6</td>\n",
       "      <td>36.1</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>24.4</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32.9</td>\n",
       "      <td>29.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>20.4</td>\n",
       "      <td>29.5</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35.7</td>\n",
       "      <td>33.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>29.9</td>\n",
       "      <td>29.2</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42.9</td>\n",
       "      <td>38.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41.5</td>\n",
       "      <td>40.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>31.8</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34.7</td>\n",
       "      <td>34.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>29.6</td>\n",
       "      <td>30.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>42.6</td>\n",
       "      <td>38.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40.3</td>\n",
       "      <td>38.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>30.6</td>\n",
       "      <td>32.4</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>44.3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>32.6</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>46.2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>35.6</td>\n",
       "      <td>34.8</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44.5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>39.2</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MMLU_0-shot  MMLU_5-shot  GSM_Direct  GSM_CoT  BBH_Direct  BBH_CoT  \\\n",
       "0          31.9         35.2         6.0      9.0        34.0     33.3   \n",
       "1          44.1         43.4         3.0      4.0        38.4      1.9   \n",
       "2          41.3         42.5         6.5     27.5        33.7     31.3   \n",
       "3          45.4         47.1         3.5     13.0        38.6     36.1   \n",
       "4          38.0         35.8         5.0      7.0        27.2     24.4   \n",
       "5          32.9         29.7         6.0      6.5        20.4     29.5   \n",
       "6          35.7         33.2         4.0      6.5        29.9     29.2   \n",
       "7          42.9         38.1         3.5      5.0        31.4     30.0   \n",
       "8          41.5         40.3         7.0     10.0        32.6     31.8   \n",
       "9          34.7         34.5         6.5      7.5        29.6     30.5   \n",
       "10         42.6         38.3         6.5     10.0        28.5     32.3   \n",
       "11         40.3         38.6         3.5      5.5        30.6     32.4   \n",
       "12         44.3         40.0         8.0      9.5         5.2     32.6   \n",
       "13         46.2         48.0         4.5     26.5        35.6     34.8   \n",
       "14         44.5         47.0         6.0     27.0        38.1     39.2   \n",
       "\n",
       "    Codex-Eval_P@1  \n",
       "0             11.6  \n",
       "1              7.0  \n",
       "2              7.4  \n",
       "3              9.6  \n",
       "4             11.1  \n",
       "5             10.1  \n",
       "6              6.2  \n",
       "7             10.3  \n",
       "8             13.2  \n",
       "9             16.5  \n",
       "10            13.2  \n",
       "11            12.2  \n",
       "12            10.9  \n",
       "13             9.4  \n",
       "14            17.5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evals_subset = [\n",
    "    ('MMLU', '0-shot'),\n",
    "    ('MMLU', '5-shot'),\n",
    "    ('GSM', 'Direct'),\n",
    "    ('GSM', 'CoT'),\n",
    "    ('BBH', 'Direct'),\n",
    "    ('BBH', 'CoT'),\n",
    "    ('Codex-Eval', 'P@1'),\n",
    "]\n",
    "output_names = [f'{x}_{y}' for x, y in evals_subset]\n",
    "\n",
    "dfs = df.copy()\n",
    "dfs = dfs[evals_subset]\n",
    "dfs.columns = output_names\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [encode_input(x[0]) for x in data]\n",
    "X = np.array(X)\n",
    "y = dfs.to_numpy()\n",
    "\n",
    "X_train = X[:-2]\n",
    "y_train = y[:-2]\n",
    "\n",
    "X_test = X[-2:]\n",
    "y_test = y[-2:]\n",
    "\n",
    "# `y` is the performance delta between base model and instruction tuned model \n",
    "base_model_perf = y_train[0,:].copy()\n",
    "y_train = y_train-base_model_perf\n",
    "X_train = X_train[1:]; y_train = y_train[1:]\n",
    "y_test = y_test-base_model_perf\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad8dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge, ElasticNet, Lasso\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso\n",
    "\n",
    "reg = MultiOutputRegressor(ElasticNet(\n",
    "    random_state=123, \n",
    "    fit_intercept=False,\n",
    "    alpha=1,\n",
    "    l1_ratio=.5\n",
    "))\n",
    "reg.fit(X_train, y_train)\n",
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rosemary import plt_kernel_matrix_one\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "print(f'MSE: {sklearn.metrics.mean_squared_error(y_test, y_pred):.2f}')\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,4))\n",
    "y_test_pred = np.vstack([y_test,\n",
    "                         y_pred])\n",
    "plt_kernel_matrix_one(fig, ax, y_test_pred, custom_ticks=False, annotate=True, cmap='bwr')\n",
    "ax.set_ylabel('y_pred           y_test')\n",
    "ax.set_xticks(list(range(len(output_names))), output_names, rotation=-45, ha='left')\n",
    "ylabels = ['human mix', 'human+GPT mix']*2\n",
    "ax.set_yticks(list(range(len(ylabels))), ylabels)\n",
    "\n",
    "ax.set_title('Compare `y_pred` and `y_test` ')\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.stack([reg.estimators_[i].coef_ for i in range(len(reg.estimators_))]).T\n",
    "b = np.stack([reg.estimators_[i].intercept_ for i in range(len(reg.estimators_))]).T\n",
    "\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "    print(W.shape, b.shape)\n",
    "    print(W)\n",
    "    print('intersept:  ', b)\n",
    "    print('base model: ', [31.9,35.2,6.0,9.0,34.0,33.3,11.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(4,7))\n",
    "im = ax.imshow(W, cmap='bwr')\n",
    "fig.colorbar(im, cax=plt_scaled_colobar_ax(ax))\n",
    "ax.set_ylabel('Input')\n",
    "ax.set_xlabel('Output')\n",
    "ax.set_yticks(list(range(len(instruct_datasets))), instruct_datasets)\n",
    "ax.set_xticks(list(range(len(output_names))), output_names, rotation=-45, ha='left')\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a56d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603eb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
