{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72539c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from open_instruct.instruction_encode_templates import encode_instruction_example, encode_few_shot_example\n",
    "from open_instruct.reformat_datasets import get_all_supported_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ead8c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "python open_instruct/reformat_datasets.py \\\n",
    "    --raw_data_dir data/raw_train/ \\\n",
    "    --output_dir data/processed/ \\\n",
    "    --dataset flan_v2_SirNeural\n",
    "\"\"\"\n",
    "\n",
    "raw_data_dir = 'data/raw_train/'\n",
    "output_dir = 'data/processed/'\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85b1b8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/raw_train/flan_v2\n",
      "data/processed/flan_v2_SirNeural/flan_v2_SirNeural/flan_v2_SirNeural/flan_v2_SirNeural/flan_v2_SirNeural/flan_v2/flan_v2/flan_v2/flan_v2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100000, {'fs_noopt', 'fs_opt', 'zs_noopt', 'zs_opt'})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def convert_flan_v2_data(data_dir, output_dir):\n",
    "subfolder = 'flan_v2'\n",
    "data_dir = os.path.join(raw_data_dir, subfolder)\n",
    "output_dir = os.path.join(output_dir, subfolder)\n",
    "\n",
    "print(data_dir)\n",
    "print(output_dir)\n",
    "\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "examples = []\n",
    "\n",
    "\n",
    "with open(os.path.join(data_dir, \"flan_v2_resampled_100k.jsonl\"), \"r\") as fin:\n",
    "    for line in fin:\n",
    "        examples.append(json.loads(line))\n",
    "        \n",
    "        \n",
    "\n",
    "len(examples), set([x['_template_type'] for x in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d115ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, example in enumerate(examples):\n",
    "    prompt = example[\"inputs\"]\n",
    "    if not prompt.endswith(\"\\n\") and not prompt.rstrip().endswith(\":\"):\n",
    "        prompt += \"\\n\"\n",
    "    completion = example[\"targets\"]\n",
    "    sample = {\n",
    "        \"dataset\": \"flan_v2\",\n",
    "        \"id\": f\"flan_v2_{idx}\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": completion},\n",
    "        ]\n",
    "    }\n",
    "    break\n",
    "#     fout.write(json.dumps({\n",
    "#         \"dataset\": \"flan_v2\",\n",
    "#         \"id\": f\"flan_v2_{idx}\",\n",
    "#         \"messages\": [\n",
    "#             {\"role\": \"user\", \"content\": prompt},\n",
    "#             {\"role\": \"assistant\", \"content\": completion},\n",
    "#         ]\n",
    "#     }) + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a27f903",
   "metadata": {},
   "source": [
    "### flan_v2_SirNeural\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5bd2282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cot_fs_noopt_train.jsonl',\n",
       " 'cot_fs_opt_train.jsonl',\n",
       " 'cot_zs_noopt_train.jsonl',\n",
       " 'cot_zs_opt_train.jsonl',\n",
       " 'dialog_fs_noopt_train.jsonl',\n",
       " 'dialog_fs_opt_train.jsonl',\n",
       " 'dialog_zs_noopt_train.jsonl',\n",
       " 'dialog_zs_opt_train.jsonl',\n",
       " 'flan_fs_noopt_train.jsonl',\n",
       " 'flan_fs_opt_train_part1.jsonl',\n",
       " 'flan_zs_noopt_train.jsonl',\n",
       " 'flan_zs_opt_train.jsonl',\n",
       " 'niv2_fs_noopt_train.jsonl',\n",
       " 'niv2_fs_opt_train.jsonl',\n",
       " 'niv2_zs_noopt_train.jsonl',\n",
       " 'niv2_zs_opt_train.jsonl',\n",
       " 't0_fs_noopt_train.jsonl',\n",
       " 't0_zs_noopt_train.jsonl',\n",
       " 't0_zs_opt_train.jsonl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "input_files = [x for x in os.listdir(data_dir) if x.endswith('jsonl')]\n",
    "sorted(input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ece0a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/data/raw_train/flan_v2_SirNeural/json/default-987f1825b8bed00f/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'targets', 'task'],\n",
       "    num_rows: 42881000\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = os.path.join(data_dir, 't0_zs_noopt_train.jsonl')\n",
    "\n",
    "ds = load_dataset('json', data_files={'train': input_path}, split='train', cache_dir=data_dir)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adbde707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/raw_train/flan_v2_SirNeural \n",
      " data/processed/flan_v2_SirNeural\n"
     ]
    }
   ],
   "source": [
    "\n",
    "subfolder = 'flan_v2_SirNeural'\n",
    "data_dir = os.path.join('data/raw_train/', subfolder)\n",
    "output_dir = os.path.join('data/processed/', subfolder)\n",
    "\n",
    "print(data_dir, '\\n', output_dir)\n",
    "\n",
    "\n",
    "#### \n",
    "\n",
    "input_files = [x for x in os.listdir(data_dir) if x.endswith('jsonl.gz')]\n",
    "input_files = os.path.join(data_dir, 'cot_fs_noopt_train.jsonl')\n",
    "\n",
    "input_path = os.path.join(data_dir, input_file)\n",
    "output_path = os.path.join(output_dir, input_file.split('_train.jsonl.gz')[0]+'_data.jsonl')\n",
    "\n",
    "if os.path.isfile(output_path):\n",
    "    continue\n",
    "\n",
    "print(f'Processing {input_file}')\n",
    "\n",
    "ds = load_dataset('json', data_files={'train': input_path}, split='train')\n",
    "# ds = ds.select(range(100))\n",
    "\n",
    "def convert_data_fn(example, idx):\n",
    "    prompt = example['inputs']\n",
    "    if not prompt.endswith(\"\\n\") and not prompt.rstrip().endswith(\":\"):\n",
    "        prompt += \"\\n\"\n",
    "    completion = example[\"targets\"]\n",
    "    return {\n",
    "        'dataset': \"flan_v2\", \n",
    "        'id': f\"flan_v2_{idx}\",\n",
    "        'messages': [\n",
    "            {'role': 'user', 'content': prompt},\n",
    "            {\"role\": \"assistant\", \"content\": completion},\n",
    "        ]}\n",
    "ds = ds.map(convert_data_fn, \n",
    "            remove_columns=[\"inputs\", \"targets\", \"task\"], \n",
    "            with_indices=True,\n",
    "            num_proc=30,\n",
    "            desc=f'Convert data for {input_file}',\n",
    "            keep_in_memory=True)\n",
    "\n",
    "ds.to_json(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c2a830e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples \n",
    "n = 0\n",
    "with gzip.open('data/raw_train/flan_v2_SirNeural/flan_fs_opt_train_part1.jsonl.gz', 'rt') as f:\n",
    "    for line in f:\n",
    "        if n%100000 == 0:\n",
    "            print(n)\n",
    "#         json.loads(line)\n",
    "#         examples.append(json.loads(line))\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b850cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d61bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "50 048 610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "81b165b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_file = 'cot_fs_noopt_train.jsonl.gz'\n",
    "input_path = os.path.join(data_dir, input_file)\n",
    "output_path = os.path.join(output_dir, input_file.split('_train.jsonl.gz')[0]+'_data.jsonl')\n",
    "\n",
    "ds = load_dataset('json', data_files={'train': input_path}, split='train', streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "28b13379",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "IterableDataset.map() got an unexpected keyword argument 'num_proc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m     completion \u001b[38;5;241m=\u001b[39m example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflan_v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflan_v2_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: completion},\n\u001b[1;32m     12\u001b[0m         ]}\n\u001b[0;32m---> 15\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_data_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtargets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: IterableDataset.map() got an unexpected keyword argument 'num_proc'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def convert_data_fn(example, idx):\n",
    "    prompt = example['inputs']\n",
    "    if not prompt.endswith(\"\\n\") and not prompt.rstrip().endswith(\":\"):\n",
    "        prompt += \"\\n\"\n",
    "    completion = example[\"targets\"]\n",
    "    return {\n",
    "        'dataset': \"flan_v2\", \n",
    "        'id': f\"flan_v2_{idx}\",\n",
    "        'messages': [\n",
    "            {'role': 'user', 'content': prompt},\n",
    "            {\"role\": \"assistant\", \"content\": completion},\n",
    "        ]}\n",
    "\n",
    "\n",
    "ds = ds.map(convert_data_fn, \n",
    "            remove_columns=[\"inputs\", \"targets\", \"task\"], \n",
    "            with_indices=True,\n",
    "            num_proc=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3d09ca96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python scripts/resample_flan_v2.py --flan_v2_data_dir data/raw_train/flan_v2_SirNeural --total_num_samples 1000000 --output_path data/processed/flan_v2_SirNeural/flan_v2_1m.jsonl\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
