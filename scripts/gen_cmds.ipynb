{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1027,
   "id": "3da1794b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'x86_64', 'cluster': 'ccc', 'queue': 'alt_7d'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "import re\n",
    "from llm.submit import (\n",
    "    multiline_to_singleline,\n",
    "    submit_job_ccc,\n",
    "    submit_job_aimos,\n",
    "    submit_job,\n",
    "        get_run_statistics)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import datetime\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import base64\n",
    "string_to_alphanumeric = lambda s: base64.urlsafe_b64encode(s.encode('utf-8')).decode('utf-8')\n",
    "alphanumeric_to_string = lambda a: base64.urlsafe_b64decode(a).decode('utf-8')\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm, shell_scripts_template_lsf, get_host_info, move_lsf_job_summary_to_save_dir\n",
    "from note_pruning_analysis import open_instruct_dir, assets_dir\n",
    "os.makedirs(assets_dir, exist_ok=True)\n",
    "\n",
    "import getpass\n",
    "\n",
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "info = get_host_info()\n",
    "info.update({'queue': queue})\n",
    "arch, cluster = info['arch'], info['cluster']\n",
    "print(info)\n",
    "\n",
    "os.environ['TORCHELASTIC_ERROR_FILE'] = os.path.join(os.getcwd(), 'torchelastic_error_file') \n",
    "\n",
    "## jobs submitted in notebook inherits env variables.\n",
    "cache_dir = os.path.normpath(os.path.join(os.getcwd(), '../../../../mitibm2023/cache')) \\\n",
    "    if arch == 'ppc64le' else '/dccstor/data-pruning/cache'\n",
    "os.environ['WANDB_DIR'] = cache_dir\n",
    "os.makedirs(os.environ['WANDB_DIR'], exist_ok=True, mode=0o777)\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_PROJECT'] = 'mitibm'\n",
    "##\n",
    "##\n",
    "\n",
    "shell_scripts_template = shell_scripts_template_slurm \\\n",
    "    if arch == 'ppc64le' else shell_scripts_template_lsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c421d1",
   "metadata": {},
   "source": [
    "# DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c09b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/oi2/llama-7b_sharegptv2_ep=2 using 6 GPUs, 1 batch size per GPU, 1 gradient accumulation steps, 30 effective batch size.\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp7pssto1b', 'job_id': 1354503}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2p8zx1bt', 'job_id': 1354504}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2_mpillk', 'job_id': 1354505}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm\n",
    "debug = False\n",
    "if debug:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'INFO'\n",
    "    os.environ['NCCL_DEBUG'] = 'INFO'\n",
    "else:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'WARNING'\n",
    "    os.environ['NCCL_DEBUG'] = ''\n",
    "num_cpus = 144 if arch == 'ppc64le' else 32\n",
    "cpu_mem =  650 if arch == 'ppc64le' else 64\n",
    "\n",
    "preprocessing_num_workers = 32\n",
    "report_to = 'wandb'\n",
    "mixed_precision = 'bf16' if arch == 'x86_64' else 'fp16'\n",
    "torch_dtype = 'bfloat16' if arch=='x86_64' else 'float32'\n",
    "gradient_checkpointing = True\n",
    "use_fast_tokenizer = True\n",
    "hf_models_dir = 'results/baselines/'\n",
    "resume_from_checkpoint = True # resume from latest checkpoint if exists, otherwise train from scratch\n",
    "num_train_epochs = 2\n",
    "checkpointing_steps = 300 # (50_000 / 32) * 2 / 6 ~= 500 (data size of 50k, bsz=32, ep=2, total save 6 times at most)\n",
    "max_train_steps = None\n",
    "subsample_inds_file_list = [None]\n",
    "dataloader_sampler = 'RandomSampler'\n",
    "overwrite_cache = True\n",
    "\n",
    "\n",
    "# #####\n",
    "# job_name = 'dpo1'\n",
    "\n",
    "# # model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-410m-deduped'; max_seq_length = 2048; abbr_model_name = 'pythia-410m'\n",
    "# # model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "\n",
    "# train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "# train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "train_file = 'data/processed/hh_rlhf/hh_rlhf_data.jsonl'; dataset = 'hh_rlhf'\n",
    "\n",
    "# M = 60_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 20_000\n",
    "# M = 50_000; pacing_fn_list = [f'prune_size={M}_ep=5']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "    (10_000, 10), # 1k\n",
    "#     (30_000, 3),  # 10k\n",
    "#     (60_000, 3),  # 20k\n",
    "]]\n",
    "\n",
    "gen_output_md = 'llama7br512p4096'\n",
    "# gen_output_md = 'llama7b+sharegptv2ep2+r512p4096'\n",
    "# gen_output_model_name = 'all-mpnet-base-v2'\n",
    "\n",
    "scoring_fn_list = []\n",
    "scoring_fn_list += ['random_s=0']\n",
    "# scoring_fn_list += ['random_s=1']\n",
    "scoring_fn_list += [ \n",
    "#     f'dppmap_k=vmf_gamma=1_kmd={gen_output_md}_kemb=grad+rp+loraB',\n",
    "#     f'dppmap_k=rbf_gamma=1e-3_kmd={gen_output_md}_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1_kmd=mpnet_kemb=text+embedding',\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'dpo2_{dataset}:{abbr_model_name}'\n",
    "    \n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12\n",
    "# nodes = 2; num_gpus = 1; gpu_type = 'v100'; job_duration = 6; cpu_mem = 100; num_cpus = 32; max_train_steps = 5; checkpointing_steps = 2; report_to = 'tensorboard'\n",
    "    \n",
    "#####\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs = 1 # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "use_deepspeed = True\n",
    "deepspeed_config_file = 'ds_configs/stage3_no_offloading_accelerate.conf'\n",
    "\n",
    "per_device_train_batch_size = 1; total_batch_size = 32\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"{effective_batch_size} effective batch size.\")\n",
    "\n",
    "# reference: https://gist.github.com/pacman100/1cb1f17b2f1b3139a63b764263e70b25\n",
    "launcher = f\"\"\"accelerate launch \\\n",
    "    --mixed_precision {mixed_precision} \\\n",
    "    --num_machines {nodes} \\\n",
    "    --num_processes {num_gpus*nodes} \\\n",
    "    {'--use_deepspeed' if use_deepspeed else ''} \\\n",
    "    {'--deepspeed_config_file '+deepspeed_config_file if use_deepspeed else ''} \\\n",
    "    {'--main_process_ip $master_addr' if use_deepspeed else ''} \\\n",
    "    {'--main_process_port $master_port' if use_deepspeed else ''} \\\n",
    "    {'--machine_rank $SLURM_PROCID' if use_deepspeed else ''} \\\n",
    "    {'--rdzv_backend c10d' if use_deepspeed and nodes>1 else ''} \\\n",
    "    {'--deepspeed_multinode_launcher standard' if use_deepspeed and nodes>1 else ''} \\\n",
    "\"\"\"\n",
    "\n",
    "cmds = []\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    subsample_inds_file_list,\n",
    ")\n",
    "\n",
    "output_dirname_list = []\n",
    "for (subsample_inds_file,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{dataset}\"\n",
    "    if any(job_name == y for y in ['dpo1']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "\n",
    "    if subsample_inds_file:\n",
    "        assert(num_train_epochs==1)\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                s = f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "\n",
    "    if subsample_inds_file is not None:\n",
    "        assert(dataloader_sampler=='SequentialSampler')\n",
    "        assert(num_train_epochs==1)\n",
    "    else:\n",
    "        assert(dataloader_sampler=='RandomSampler')\n",
    "\n",
    "    output_dir = os.path.join('results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join('results', job_name), exist_ok=True)\n",
    "    wandb_run_name = output_dir.replace('results/', '')\n",
    "\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {f'cd .. && CUDA_VISIBLE_DEVICES={os.environ[\"CUDA_VISIBLE_DEVICES\"]} ' if test_run else ''}{launcher}\n",
    "        open_instruct/dpo_tune.py \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --tokenizer_name {model_name_or_path} \\\n",
    "        {'--use_slow_tokenizer' if not  use_fast_tokenizer else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        --train_file {train_file} \\\n",
    "        --max_seq_length {max_seq_length} \\\n",
    "        {'--subsample_inds_file '+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        --dataloader_sampler {dataloader_sampler} \\\n",
    "        --preprocessing_num_workers {preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size {per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
    "        --learning_rate 5e-7 \\\n",
    "        --lr_scheduler_type linear \\\n",
    "        --warmup_ratio 0.1 \\\n",
    "        --weight_decay 0. \\\n",
    "        --num_train_epochs {num_train_epochs} \\\n",
    "        --with_tracking \\\n",
    "        {'--report_to \"'+str(report_to)+'\"' if report_to else ''} \\\n",
    "        --checkpointing_steps {checkpointing_steps} \\\n",
    "        {'--max_train_steps '+str(max_train_steps) if max_train_steps else ''} \\\n",
    "        {'--resume_from_checkpoint' if resume_from_checkpoint else ''} \\\n",
    "        {'--low_cpu_mem_usage' if not use_deepspeed else ''} \\\n",
    "        {'--overwrite_cache' if overwrite_cache else ''} \\\n",
    "        --logging_steps 1 \\\n",
    "        --output_dir {output_dir}\n",
    "    \"\"\"\n",
    "    # if test_run:\n",
    "    #     print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    if test_run:\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64': # ccc\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "        queue=queue,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda1f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prune: {1k@10, 10k@3}, datasets={dolly, stanford_alpaca}, scoring={random, dppmapx2}\n",
    "# need to gen curriculum for 50k sft datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b79b9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_dpo.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce604bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=5\n",
      "+ cd ..\n",
      "+ CUDA_VISIBLE_DEVICES=2,5\n",
      "+ accelerate launch --mixed_precision fp16 --num_machines 1 --num_processes 2 --use_deepspeed --deepspeed_config_file ds_configs/stage3_no_offloading_accelerate.conf open_instruct/dpo_tune.py --model_name_or_path results/baselines/huggyllama/llama-7b --tokenizer_name results/baselines/huggyllama/llama-7b --gradient_checkpointing --train_file data/processed/ultrafeedback/ultrafeedback_data.jsonl --max_seq_length 2048 --preprocessing_num_workers 32 --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --learning_rate 5e-7 --lr_scheduler_type linear --warmup_ratio 0.1 --weight_decay 0. --num_train_epochs 2 --with_tracking --report_to tensorboard --checkpointing_steps 500 --logging_steps 1 --output_dir results/dpo1/jpt_llama-7b_ultrafeedback\n",
      "[2024-01-08 20:41:08,547] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "[2024-01-08 20:41:17,396] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-08 20:41:17,400] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:662:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,611] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 1\n",
      "Local process index: 1\n",
      "Device: cuda:1\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 251.17it/s]\n",
      "01/08/2024 20:41:25 - WARNING - datasets.builder - Found cached dataset json (/gpfs/u/scratch/PTFM/PTFMqngp/huggingface_cache/datasets/json/default-201ebfceee303348/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 252.78it/s]\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:26,493] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 6.74B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.74s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:16<00:00,  8.11s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:43,556] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 13.48B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.60s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "01/08/2024 20:42:20 - INFO - accelerate.accelerator - Updating DeepSpeed's gradient accumulation steps to 16 from 1.\n",
      "[2024-01-08 20:42:20,382] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.1+23a11a39, git-hash=23a11a39, git-branch=master\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 1\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "[2024-01-08 20:42:20,751] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n",
      "[2024-01-08 20:42:20,779] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\n",
      "[2024-01-08 20:42:20,891] [INFO] [utils.py:786:see_memory_usage] Stage 3 initialize beginning\n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 14.16 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.9 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:118:__init__] Reduce bucket size 16777216\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:119:__init__] Prefetch bucket size 15099494\n",
      "[2024-01-08 20:42:20,995] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 13.64 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n",
      "[2024-01-08 20:42:21,139] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.76 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:21,240] [INFO] [utils.py:786:see_memory_usage] Before creating fp16 partitions\n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.4 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:23,090] [INFO] [utils.py:786:see_memory_usage] After creating fp16 partitions: 4\n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.4 GB         CA 14.6 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.99 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,190] [INFO] [utils.py:786:see_memory_usage] Before creating fp32 partitions\n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.39 GB         CA 14.6 GB         Max_CA 15 GB \n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.81 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,742] [INFO] [utils.py:786:see_memory_usage] After creating fp32 partitions\n",
      "[2024-01-08 20:42:23,743] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 26.61 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,744] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 116.15 GB, percent = 16.7%\n",
      "[2024-01-08 20:42:23,836] [INFO] [utils.py:786:see_memory_usage] Before initializing optimizer states\n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 25.94 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 117.28 GB, percent = 16.8%\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 1; 31.75 GiB total capacity; 25.93 GiB already allocated; 3.34 GiB free; 27.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 0; 31.75 GiB total capacity; 25.94 GiB already allocated; 3.21 GiB free; 27.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 409110) of binary: /gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/python3.10\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 964, in launch_command\r\n",
      "    deepspeed_launcher(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 687, in deepspeed_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "open_instruct/dpo_tune.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 409111)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 409110)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_dpo.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "f5886d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dataset', 'id', 'messages'],\n",
       "    num_rows: 96913\n",
       "})"
      ]
     },
     "execution_count": 946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from note_pruning_analysis import get_dataset\n",
    "ds = get_dataset('super_ni')\n",
    "ds\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c8b",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune_trainer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "19aebd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_theta=0.9_kmd=llama7br512p4096_kemb=grad+rp+loraB_q=alpagasus+rating_qmd=llama7br512p4096\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/baselines/huggyllama/llama-7b using 4 GPUs, 1 batch size per GPU, 32 gradient accumulation steps, Effective batch size 128\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi6_stanford_alpaca50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 64,\n",
      "    \"cpu_mem\": 384,\n",
      "    \"num_gpus\": 4,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi6_stanford_alpaca50k:llama-7b -mem 384g -cores 1x64+4 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=32 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi6_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:theta=0.9:kmd=llama7br512p4096:kemb=grad+rp+loraB:q=alpagasus+rating:qmd=llama7br512p4096_pace=prune:size=30000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/stanford_alpaca50k/dppmap_k=vmf_gamma=1_theta=0.9_kmd=llama7br512p4096_kemb=grad+rp+loraB_q=alpagasus+rating_qmd=llama7br512p4096/inds_prune_size=30000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi6_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:theta=0.9:kmd=llama7br512p4096:kemb=grad+rp+loraB:q=alpagasus+rating:qmd=llama7br512p4096_pace=prune:size=30000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi6_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:theta=0.9:kmd=llama7br512p4096:kemb=grad+rp+loraB:q=alpagasus+rating:qmd=llama7br512p4096_pace=prune:size=30000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1553551}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "add_hardwarespec_to_dirname = False\n",
    "save_strategy = 'steps'\n",
    "save_steps = 200 if getpass.getuser() in ('PTFMqngp', 'wpq') else 1_000_000\n",
    "save_total_limit = 1\n",
    "preprocessing_num_workers = 32\n",
    "evaluation_strategy = 'no' # set do_eval=False\n",
    "eval_steps = save_steps\n",
    "report_to = 'tensorboard wandb'\n",
    "suffix = None\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0.03\n",
    "dataloader_sampler = None\n",
    "hf_models_dir = 'results/baselines/'\n",
    "subsample_inds_file_list = [None]\n",
    "max_train_samples_list = [None]\n",
    "num_train_epochs_list = [1]\n",
    "scoring_fn_and_pacing_fn = None\n",
    "\n",
    "\n",
    "# ########### sft baselines\n",
    "\n",
    "\n",
    "# job_name = 'oi2'; num_train_epochs_list = [3]\n",
    "# # model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "\n",
    "# # train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca'; \n",
    "# # train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# # train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2'; max_train_samples_list=[100_000]\n",
    "\n",
    "# ## 50k sft datasets\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# # train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "# ## additional ones : {wizardlm50k, oasst2, lima, gpt4_alpaca50k, flan_v250k}\n",
    "# # train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "# # train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# # train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# # train_file = 'data/processed/gpt4_alpaca/gpt4_alpaca50k_data.jsonl'; abbr_train_file = 'gpt4_alpaca'; \n",
    "# # train_file = 'data/processed/lima/lima_data.jsonl'; abbr_train_file = 'lima'; num_train_epochs_list = [3]\n",
    "\n",
    "# # mix\n",
    "# # train_file = 'data/processed/mix/mix_all50k_data.jsonl'; abbr_train_file = 'mix_all50k'; num_train_epochs_list = [2]\n",
    "\n",
    "# ## additional ones \n",
    "# train_file = '/dccstor/data-pruning/data/processed/super_ni/super_ni_data.jsonl'; abbr_train_file = 'super_ni'; max_train_samples_list=[50_000]\n",
    "# # train_file = '/dccstor/data-pruning/data/processed/self_instruct/self_instruct50k_data.jsonl'; abbr_train_file = 'self_instruct50k'\n",
    "\n",
    "\n",
    "# # train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2'; max_train_samples_list=[100_000]\n",
    "# ###########\n",
    "\n",
    "\n",
    "############ pruning runs\n",
    "\n",
    "# model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048; gen_output_md = 'mistral7br512p4096'\n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048; gen_output_md = 'llama7br512p4096'\n",
    "\n",
    "\n",
    "# # 50k sft datasets\n",
    "# dataset = 'flan_v250k'; train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "dataset = 'stanford_alpaca50k'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# dataset = 'wizardlm50k'; train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "# dataset = 'sharegpt50k'; train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "# dataset = 'ultrachat50k'; train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "\n",
    "# dataset = 'flan_v2'; train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca';\n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# dataset = 'wizardlmv2'; train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2';\n",
    "# dataset = 'sharegptv2'; train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2';\n",
    "# dataset = 'ultrachat200kv2'; train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2';\n",
    "\n",
    "\n",
    "# dataset = 'oasst1'; train_file = 'data/processed/oasst/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# dataset = 'open_orca_slim'; train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; \n",
    "# dataset = 'tulu_v2'; train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2';\n",
    "        \n",
    "# M = 80_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 40_000\n",
    "# M = 40_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 20_000\n",
    "# M = 30_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [\n",
    "    f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "#         (10_000, 10), # -> 1k, 2%\n",
    "        (30_000, 3),  # -> 10k, 20%\n",
    "#         (60_000, 3),  # -> 20k, 40%\n",
    "#         (90_000, 3),  # -> 30k, 60%\n",
    "#         (120_000, 3),  # -> 40k, 80%\n",
    "    ]\n",
    "]\n",
    "#         + [running] 10k prune size. 4 datasets, compare {vmf,rbf} x {text,grad}\n",
    "\n",
    "\n",
    "# job_name = f'oi5_{dataset}:{abbr_model_name}'\n",
    "# kmd = 'llama7br512p4096'\n",
    "scoring_fn_list = []\n",
    "# scoring_fn_list += [\n",
    "#     'random_s=0',\n",
    "# #     'random_s=1',\n",
    "# #     'log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n',\n",
    "# #     'ifd_neg', 'log_pmi_neg',\n",
    "# #     'numtoks_input_neg', 'numtoks_output_neg', 'numtoks_total_neg',\n",
    "#     ## dedup\n",
    "# #     f'dedup_dist=cd_md=mpnet_emb=text+embedding',\n",
    "# #     f'dedup_dist=cd_md={kmd}_emb=text+embedding',\n",
    "# #     f'dedup_dist=cd_md={kmd}_emb=grad+rp+loraB',\n",
    "#     ##\n",
    "#     f'dppmap_k=vmf_gamma=1_kmd=mpnet_kemb=text+embedding',\n",
    "# #     f'dppmap_k=rbf_gamma=1e-3_kmd={kmd}_kemb=text+embedding',\n",
    "#     f'dppmap_k=vmf_gamma=1_kmd={kmd}_kemb=grad+rp+loraB',\n",
    "#     f'dppmap_k=vmf_gamma=10_kmd={kmd}_kemb=text+embedding',\n",
    "# #     f'dppmap_k=rbf_gamma=1e-2_kmd={kmd}_kemb=grad+rp+loraB',\n",
    "#     ## arccos kernel\n",
    "# #     'dppmap_k=acos0_kmd=llama7br512p4096_kemb=grad+rp+loraB',\n",
    "# #     'dppmap_k=acos0_kmd=llama7br512p4096_kemb=text+embedding',\n",
    "# #     'dppmap_k=acos1_kmd=llama7br512p4096_kemb=grad+rp+loraB',\n",
    "# ]\n",
    "\n",
    "\n",
    "job_name = f'oi6_{dataset}:{abbr_model_name}'\n",
    "scoring_fn_list = []\n",
    "# scoring_fn_list += [ ## alpaga w. numtoks\n",
    "#     f'dppmap_k=vmf_gamma=1_theta={theta}_kmd={kmd}_kemb=grad+rp+loraB_q=numtoks+output_qmd={kmd}'\n",
    "#     for theta in [0.03, 0.1, 0.3, 0.9] \n",
    "# ]\n",
    "\n",
    "scoring_fn_list = []\n",
    "# scoring_fn_list += ['alpagasus_rating_neg']\n",
    "scoring_fn_list += [ ## alpaca w. alpagasus rating\n",
    "    f'dppmap_k=vmf_gamma=1_theta={theta}_kmd={kmd}_kemb=grad+rp+loraB_q=alpagasus+rating_qmd={kmd}'\n",
    "    for theta in [0.9] # [0.1, 0.3, 0.6]\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scoring_fn_list += [ # vary kernel embedding model \n",
    "#     f'dppmap_k=vmf_gamma=auto{subset_size}_kmd={kmd}_kemb=grad+rp+loraB'\n",
    "#     for kmd in ['llama7br256p4096', 'llama7br512p4096', 'pythia1br512p4096']\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "############ \n",
    "\n",
    "\n",
    "    \n",
    "# add_hardwarespec_to_dirname = True\n",
    "# job_name += '_debug' # wpq debug\n",
    "# max_train_samples_list=[128*2]\n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "debug_mode = test_run\n",
    "\n",
    "if arch == 'x86_64':\n",
    "#     nodes = 1; num_gpus = 8; gpu_type = 'a100_80gb'; job_duration = 6\n",
    "    nodes = 1; num_gpus = 4; gpu_type = 'a100_80gb'; job_duration = 6 \n",
    "    num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus); preprocessing_num_workers = 128 # tok takes quite a bit.\n",
    "    per_device_train_batch_size = 1\n",
    "    gradient_checkpointing = False\n",
    "    mixed_precision = 'bf16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = True \n",
    "    save_model_torch_dtype = 'bfloat16' # typically save fp32 weights, but for disk space sake, convert to bf16.\n",
    "else:\n",
    "    nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_checkpointing = True\n",
    "    mixed_precision = 'fp16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = False\n",
    "    save_model_torch_dtype = None\n",
    "\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs_list = [1] # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "overwrite_output_dir = True if test_run else False # always continue from ckpt if run from cluster.\n",
    "\n",
    "total_batch_size = 128\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "optimizer = 'adamw_hf'\n",
    "\n",
    "deepspeed = ''; fsdp = False if num_gpus == 1 else \"full_shard auto_wrap\" \n",
    "if 'gpt2' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPT2Block'\n",
    "elif 'llama' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'LlamaDecoderLayer'\n",
    "elif 'mpt' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MPTBlock'\n",
    "elif 'pythia' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPTNeoXLayer'        \n",
    "elif 'mistral' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MistralDecoderLayer'\n",
    "else: raise ValueError('Not sure how to set `fsdp_transformer_layer_cls_to_wrap`')\n",
    "    \n",
    "# deepspeed = './ds_configs/ds_zero3_cpu_offload.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/ds_zero3.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/stage3_no_offloading.conf'; fsdp = False # error with loading... something wrong with the config.\n",
    "# fsdp = False; deepspeed = False\n",
    "\n",
    "if fsdp and deepspeed:\n",
    "    raise ValueError('either fsdp or deepspeed, not both')\n",
    "\n",
    "use_lora = False\n",
    "lora_rank = 256 \n",
    "lora_alpha = lora_rank \n",
    "lora_dropout = 0.05\n",
    "if use_lora:\n",
    "    abbr_model_name += f'+lora(r={lora_rank},a={lora_alpha})'\n",
    "load_in_8bit = False\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"Effective batch size {effective_batch_size}\")\n",
    "\n",
    "\n",
    "if nodes == 1:\n",
    "    exe = 'python' if num_gpus==1 else \\\n",
    "        f\"torchrun --nnodes 1 --nproc_per_node={num_gpus} --rdzv_backend=c10d --rdzv_endpoint=localhost:0\" # assigns random port. https://github.com/pytorch/pytorch/issues/73320\n",
    "else:\n",
    "    exe = f\"torchrun --nnodes={nodes} --nproc_per_node={num_gpus} --rdzv-id=${'SLURM_JOB_ID' if arch == 'ppcle64' else 'LSB_JOBID'} --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT\"\n",
    "\n",
    "if test_run:\n",
    "    exe = f\"CUDA_VISIBLE_DEVICES={','.join(map(str, range(num_gpus)))} {exe}\"\n",
    "if test_run and debug_mode:\n",
    "    exe = 'TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO ' + exe\n",
    "    error_file = os.path.join(open_instruct_dir, 'scripts', 'error_file')\n",
    "    exe = f'TORCHELASTIC_ERROR_FILE={error_file} {exe}'\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    raise ValueError(f'train_file={train_file} does not exists')\n",
    "\n",
    "options_list = itertools.product(\n",
    "    num_train_epochs_list,\n",
    "    subsample_inds_file_list,\n",
    "    max_train_samples_list,\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "output_dirname_list = []\n",
    "for (num_train_epochs,\n",
    "     subsample_inds_file,\n",
    "     max_train_samples,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{abbr_train_file}\"\n",
    "    if max_train_samples:\n",
    "        output_dirname += f\":{int(max_train_samples/1000)}k\"\n",
    "            \n",
    "    if any(job_name == y for y in ['oi2']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "        \n",
    "    if subsample_inds_file:\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                return f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            else:\n",
    "                return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "            \n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "            \n",
    "    if add_hardwarespec_to_dirname:\n",
    "        output_dirname += \\\n",
    "            ('_fsdp='+fsdp.split(' ')[0] if fsdp else '')+\\\n",
    "            ('_deepspeed='+os.path.basename(deepspeed).split('.')[0] if deepspeed else '')+\\\n",
    "            ('_gradckpt='+str(gradient_checkpointing) if gradient_checkpointing else '')+\\\n",
    "            '_mbsz='+str(per_device_train_batch_size)+\\\n",
    "            ('_dtype='+torch_dtype if torch_dtype is not None else '')+\\\n",
    "            ('_mp='+str(mixed_precision) if mixed_precision else '_mp=none')+\\\n",
    "            '_seqlen='+str(max_seq_length)+\\\n",
    "            '_nodes='+str(nodes)+\\\n",
    "            '_ngpus='+str(num_gpus)+\\\n",
    "            ('_fa2' if use_flash_attn else '')\n",
    "    if suffix:\n",
    "        output_dirname += suffix\n",
    "    output_dir = os.path.join(open_instruct_dir, 'results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join(open_instruct_dir, 'results', job_name), exist_ok=True)\n",
    "    if arch == 'x86_64':\n",
    "        wandb_run_name = 'ccc'+output_dir[output_dir.find('results'):][7:] # e.g., ccc/oi2/run_name\n",
    "    else:\n",
    "        wandb_run_name = output_dir.replace('results/', '') # e.g., oi2/run_name\n",
    "    \n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {'cd .. && ' if test_run else ''}{exe}\n",
    "        open_instruct/finetune_trainer.py \\\n",
    "        --model_name_or_path={model_name_or_path} \\\n",
    "        --tokenizer_name={model_name_or_path} \\\n",
    "        {'--load_in_8bit' if load_in_8bit else ''} \\\n",
    "        --use_fast_tokenizer=True \\\n",
    "        --train_file={train_file} \\\n",
    "        --max_seq_length={max_seq_length} \\\n",
    "        {'--max_train_samples='+str(max_train_samples) if max_train_samples else ''} \\\n",
    "        {'--use_lora' if use_lora else ''} \\\n",
    "        {'--lora_rank='+str(lora_rank) if use_lora else ''} \\\n",
    "        {'--lora_alpha='+str(lora_alpha) if use_lora else ''} \\\n",
    "        {'--lora_dropout='+str(lora_dropout) if use_lora else ''} \\\n",
    "        --do_train \\\n",
    "        --preprocessing_num_workers={preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size={per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
    "        --learning_rate=2e-5 \\\n",
    "        --lr_scheduler_type={lr_scheduler_type} \\\n",
    "        --warmup_ratio={warmup_ratio} \\\n",
    "        --weight_decay=0. \\\n",
    "        --optim={optimizer} \\\n",
    "        --evaluation_strategy={evaluation_strategy} \\\n",
    "        {'--eval_steps='+str(eval_steps) if eval_steps else ''} \\\n",
    "        {'--report_to '+str(report_to) if report_to else ''} \\\n",
    "        --run_name {wandb_run_name} \\\n",
    "        --logging_strategy=steps \\\n",
    "        --logging_first_step \\\n",
    "        --logging_steps=1 \\\n",
    "        --save_strategy={save_strategy} \\\n",
    "        --save_steps={save_steps} \\\n",
    "        --save_total_limit={save_total_limit} \\\n",
    "        --num_train_epochs={num_train_epochs} \\\n",
    "        --ddp_timeout=7200 \\\n",
    "        {'--fsdp=\"'+fsdp+'\"' if fsdp else ''} \\\n",
    "        {'--fsdp_transformer_layer_cls_to_wrap=\"'+fsdp_transformer_layer_cls_to_wrap+'\"' \n",
    "            if fsdp else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        {'--torch_dtype='+str(torch_dtype) if torch_dtype else ''} \\\n",
    "        {'--save_model_torch_dtype='+str(save_model_torch_dtype) if save_model_torch_dtype else ''} \\\n",
    "        --dataloader_num_workers=8 \\\n",
    "        {f'--{mixed_precision}=True' if mixed_precision else ''} \\\n",
    "        {f'--tf32=True' if use_tf32 else ''} \\\n",
    "        {'--overwrite_output_dir' if overwrite_output_dir else ''} \\\n",
    "        {'--deepspeed='+deepspeed if deepspeed else ''} \\\n",
    "        {'--subsample_inds_file='+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        {'--dataloader_sampler '+str(dataloader_sampler) if dataloader_sampler else ''} \\\n",
    "        --use_flash_attn {'True' if use_flash_attn else 'False'} \\\n",
    "        --low_cpu_mem_usage \\\n",
    "        --overwrite_cache \\\n",
    "        --output_dir=\"{output_dir}\" \\\n",
    "    \"\"\" \n",
    "    #  --overwrite_cache   # if delete a dataset and need to refresh cache\n",
    "\n",
    "    if test_run:\n",
    "        print()\n",
    "        print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64':\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        queue=queue,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12fc2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_sft.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed0c2894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ cd ..\n",
      "+ TORCHELASTIC_ERROR_FILE=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/error_file\n",
      "+ TORCH_CPP_LOG_LEVEL=INFO\n",
      "+ NCCL_DEBUG=INFO\n",
      "+ LOGLEVEL=INFO\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/oasst1/oasst1_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=32 --per_device_train_batch_size=1 --gradient_accumulation_steps=128 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=200 --report_to tensorboard wandb --run_name /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=200 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --overwrite_output_dir --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl --dataloader_sampler SequentialSampler --use_flash_attn True --low_cpu_mem_usage --overwrite_cache --output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10\n",
      "[2024-01-19 02:04:37,834] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Saving args dict to /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10.args.json\n",
      "01/19/2024 02:04:39 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "01/19/2024 02:04:39 - INFO - __main__ - Training parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=8,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_sampler=SequentialSampler,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=7200,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=200.0,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=128,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10/runs/Jan19_02-04-39_cccxc552,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1.0,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard', 'wandb'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=True,\n",
      "save_steps=200,\n",
      "save_strategy=steps,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=True,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "Using custom data configuration default-b03eccd42e843020\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Using custom data configuration default-b03eccd42e843020\n",
      "Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "[INFO|configuration_utils.py:715] 2024-01-19 02:04:39,135 >> loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "[INFO|configuration_utils.py:777] 2024-01-19 02:04:39,136 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3118] 2024-01-19 02:04:39,229 >> loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1222] 2024-01-19 02:04:39,229 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[WARNING|modeling_utils.py:1304] 2024-01-19 02:04:39,230 >> You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:39,230 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.07it/s]\n",
      "[INFO|modeling_utils.py:3950] 2024-01-19 02:04:41,778 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:3958] 2024-01-19 02:04:41,778 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:749] 2024-01-19 02:04:41,781 >> loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:41,781 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "01/19/2024 02:04:41 - INFO - __main__ - [wpq] model.dtype=torch.bfloat16\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1648] 2024-01-19 02:04:41,845 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spawning 32 processes\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Spawning 32 processes\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 0/33717 [00:Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 22/33717 [00Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   1%| | 361/33717 [0Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):   3%| | 1001/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   5%| | 1719/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   7%| | 2251/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):  12%| | 4021/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  14%|▏| 4841/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  18%|▏| 5957/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32): 100%|█| 33717/33717 \n",
      "Concatenating 32 shards\n",
      "01/19/2024 02:04:55 - INFO - datasets.arrow_dataset - Concatenating 32 shards\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - __main__ - Subsample dataset according to indices: /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl\n",
      "01/19/2024 02:04:56 - INFO - __main__ - subsample_inds_file has 10000 indices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[wpq] Example 0 of train_dataset: \r\n",
      "{'dataset': 'oasst1', 'id': 'oasst1_20480', 'messages': [{'role': 'user', 'content': 'Cómo manejar un carro manual'}, {'role': 'assistant', 'content': 'Lo primero que tienes que hacer, si nunca has conducido un coche manual, es familiarizarte con el embrague y palanca de cambios. Si conduces habitualmente un coche automático, estarás acostumbrado a no utilizar para nada el pie izquierdo ni la palanca del cambio. Encontrarás tres pedales, siendo el embrague el que está situado a la izquierda y el que tendrás que pisar cada vez que cambies de marcha. Por otro lado, la palanca del cambio se ubica siempre en la consola central.\\n\\nPara arrancar un coche manual, es necesario seguir una serie de pasos que, al principio, pueden parecer muchos, pero que, con el tiempo, acabarás haciéndolos sin darte cuenta:\\n\\n1) Comprueba que la palanca del cambio está en punto muerto\\n2) Coloca el pie derecho en el pedal del freno\\n3) Arranca el motor\\n4) Pisa el embrague con el pie izquierdo\\n5) Coloca la palanca del cambio en la primera marcha, sin levantar el pedal del freno\\n6) Suelta el freno de mano\\n7) Suelta el pedal del freno\\nYa estás listo para iniciar la marcha, soltando suavemente el embrague, a medida que aceleras.\\n\\nUna vez que ya estás en marcha, debes hacer un uso correcto del cambio manual para cambiar las marchas de forma correcta. Un uso incorrecto de la caja de cambios manual puede repercutir negativamente en tu seguridad y también afectar gravemente al embrague y a la transmisión, lo que se traduce en serias averías de coste muy elevado. Para evitarlo, te explicamos cómo debes proceder:\\n\\nUna vez que hayas arrancado, pisa el acelerador muy lentamente. Notarás que el régimen del motor aumenta. En ese momento, comienza a soltar suavemente el pedal del embrague. Verás que el motor vuelve a bajar de vueltas. En ese momento, puedes presionar un poco más el acelerador y el coche comenzará a avanzar.\\n\\nAhora llega el momento de meter la segunda marcha. Dependiendo del tipo de coche y combustible, podrás circular a un régimen de giro más bajo o alto. El régimen de giro en coche de gasolina, por lo general, oscila entre loas 2.500 y 3.000 vueltas. Si el motor está sobrealimentado por turbo, te permitirá circular por debajo de ese rango, ya que algunos coches turbos modernos entregan la totalidad de su par motor, incluso por debajo de las 2.000 vueltas.\\n\\nUn coche con motor turbodiésel te permite circular a un régimen muy bajo, por debajo de las 2.000 vueltas, ya que la entrega de par se produce antes que en un motor de gasolina.\\n\\nCuando el coche alcance un régimen de vueltas apropiado, suelta el pedal del acelerador y vuelve a pisar el embrague. Coge la palanca del cambio y baja para meter segunda. Suelta el embrague y presiona nuevamente el acelerador. A partir de aquí, cada vez que quieras cambiar de marcha, deberás repetir el mismo proceso: soltar el acelerador, pisar embrague, meter la marcha, soltar embrague y volver a acelerar.\\n\\n¡Buen viaje!'}], 'input_ids': tensor([    1,   529, 29989,  1792, 29989, 29958,    13, 29907, 29980,  4346,\r\n",
      "          767, 29872,  4758,   443,  1559,   307, 12219,    13, 29966, 29989,\r\n",
      "          465, 22137, 29989, 29958,    13,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'labels': tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:593] 2024-01-19 02:04:57,333 >> Using auto half precision backend\n",
      "[INFO|trainer.py:738] 2024-01-19 02:04:57,494 >> The following columns in the training set don't have a corresponding argument in `LlamaForCausalLM.forward` and have been ignored: messages, id, dataset. If messages, id, dataset are not expected by `LlamaForCausalLM.forward`,  you can safely ignore this message.\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1723] 2024-01-19 02:04:57,514 >> ***** Running training *****\n",
      "[INFO|trainer.py:1724] 2024-01-19 02:04:57,514 >>   Num examples = 10,000\n",
      "[INFO|trainer.py:1725] 2024-01-19 02:04:57,514 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1726] 2024-01-19 02:04:57,514 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:1729] 2024-01-19 02:04:57,514 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1730] 2024-01-19 02:04:57,514 >>   Gradient Accumulation steps = 128\n",
      "[INFO|trainer.py:1731] 2024-01-19 02:04:57,514 >>   Total optimization steps = 78\n",
      "[INFO|trainer.py:1732] 2024-01-19 02:04:57,515 >>   Number of trainable parameters = 6,738,423,808\n",
      "[INFO|integration_utils.py:718] 2024-01-19 02:04:57,519 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "  0%|                                                    | 0/78 [00:00<?, ?it/s][WARNING|logging.py:314] 2024-01-19 02:05:01,563 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,569 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,572 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,576 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,577 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 1.6425, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}         \n",
      "{'loss': 1.7168, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.03}        \n",
      "  3%|█▏                                          | 2/78 [00:42<26:54, 21.24s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash gen_cmds_sft.sh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:177\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:646\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGCONT)\n\u001b[0;32m--> 646\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_sft.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831fe55",
   "metadata": {},
   "source": [
    "# eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "id": "499d6f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('alpacafarm_ann=alpaca:eval:gpt4_chatfmt', 'results/oi6_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:theta=0.9:kmd=llama7br512p4096:kemb=grad+rp+loraB:q=alpagasus+rating:qmd=llama7br512p4096_pace=prune:size=30000:ep=3')\n",
      "#cmds:  1 \n",
      "\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=alpaca:eval:gpt4_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from gen_cmds_utils import remove_all_symlinks, create_unique_symlinks, get_chat_formatting_function, get_resource_for_task, OPENAI_MODEL_LIST\n",
    "\n",
    "\n",
    "create_symlinks = False\n",
    "include_checkpoints = False\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "use_slow_tokenizer = True\n",
    "launch_one_job_per_model = True\n",
    "\n",
    "task_names = [\n",
    "    'mmlu_s=0',\n",
    "    'mmlu_s=5', \n",
    "    'gsm_s=8',\n",
    "    'gsm_s=8_cot',\n",
    "    'bbh_s=3',\n",
    "    'bbh_s=3_cot', # max_datapoints_per_task=40 -> 40min.\n",
    "    'humaneval',\n",
    "    'tydiqa_s=1_cb', # 3min\n",
    "    'tydiqa_s=1_gp',\n",
    "    # 'toxigen', # ~1.5hr\n",
    "#     'alpacafarm_ann=gpt35:turbo:1106',\n",
    "    # 'alpacafarm_ann=chatgpt', # ~$1 per eval.\n",
    "]\n",
    "task_names_chatfmt = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "\n",
    "task_names_mtbench = ['mtbench_ann=gpt:4:1106:preview_chatfmt'] # ann=gpt:4, ann=gpt:3.5:turbo:1106, gpt:4:1106:preview (gpt4-turbo)\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:3.5:turbo:1106_chatfmt'] # for debug sake, prefer gpt4\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:4_chatfmt']\n",
    "# task_names_alpacafarm = ['alpacafarm_ann=chatgpt_chatfmt']\n",
    "task_names_alpacafarm = ['alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt']\n",
    "task_names_chateval = task_names_mtbench + task_names_alpacafarm\n",
    "\n",
    "\n",
    "# # ## baselines eval \n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "# #     'huggyllama/llama-7b', \n",
    "# #     'mistralai/Mistral-7B-v0.1',\n",
    "# #     'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "# #     'NousResearch/Llama-2-7b-hf',\n",
    "# #     'NousResearch/Llama-2-7b-chat-hf',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-beta',\n",
    "# #     'HuggingFaceH4/zephyr-7b-alpha',\n",
    "#     'HuggingFaceH4/zephyr-7b-beta',\n",
    "# #     'codellama/CodeLlama-7b-hf',\n",
    "# #     'codellama/CodeLlama-7b-Python-hf',\n",
    "# #     'codellama/CodeLlama-7b-Instruct-hf',\n",
    "# ]]\n",
    "# # task_names = task_names + task_names_chatfmt\n",
    "# task_names = task_names_mtbench\n",
    "\n",
    "# # oi5\n",
    "# exp_dir = 'results/oi2'\n",
    "# exp_dir = 'results/oi5_flan_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_dolly:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlm50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegpt50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b_debug'\n",
    "# exp_dir = 'results/oi5_stanford_alpaca:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlmv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegptv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_ultrachat200kv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_tulu_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_open_orca_slim:llama-7b'\n",
    "# exp_dir = 'results/dpo1'\n",
    "# exp_dir = 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2'\n",
    "exp_dirs = [\n",
    "#     'results/baselines/huggyllama',\n",
    "#     'results/oi2',\n",
    "#     'results/oi5_dolly:llama-7b',\n",
    "#     'results/oi5_flan_v250k:llama-7b',\n",
    "#     'results/oi5_stanford_alpaca50k:llama-7b',\n",
    "#     'results/oi5_oasst2:llama-7b',\n",
    "#     'results/oi5_wizardlm50k:llama-7b',\n",
    "#     'results/oi5_sharegpt50k:llama-7b',\n",
    "#     'results/oi5_ultrachat50k:llama-7b',\n",
    "    'results/oi6_stanford_alpaca50k:llama-7b', # diversity+quality\n",
    "#     'results/oi6_ultrachat50k:llama-7b', # redo- oi5 counterpart because i deleted the model weights \n",
    "]\n",
    "# exp_dirs = [\n",
    "#     'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2',\n",
    "# ]\n",
    "\n",
    "# subdir_filter_fn = lambda x: 'ultrachat' in x and 'size=30000' in x and 'acos' not in x and 'random' in x #'dpp' in x and 'vmf' in x\n",
    "# subdir_filter_fn = lambda x: 'stanford' in x and 'size=30000' in x and 'acos' not in x\n",
    "# subdir_filter_fn = lambda x: 'sharegpt' in x and 'size=60000' in x and 'acos' not in x\n",
    "# subdir_filter_fn = lambda x: 'qmd' in x and '0.9' not in x\n",
    "# subdir_filter_fn = lambda x: 'dppmap:k=vmf:gamma=1:kmd=mpnet:kemb=text+embedding_pace=prune:size=' in x\n",
    "# subdir_filter_fn = lambda x: 'ep=3' in x and 'lima' not in x\n",
    "# task_names = task_names + task_names_chatfmt;\n",
    "task_names = ['alpacafarm_ann=alpaca:eval:gpt4_chatfmt']\n",
    "# task_names = ['mtbench_ann=gpt:4_chatfmt'] \n",
    "# task_names = task_names_alpacafarm;\n",
    "# task_names = task_names_mtbench\n",
    "# task_names = task_names + task_names_chatfmt + task_names_mtbench\n",
    "# task_names = task_names\n",
    "# task_names = ['alpacafarm_ann=gpt35:turbo:1106_chatfmt']\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "num_gpus = 1\n",
    "if arch == 'x86_64': # ccc\n",
    "    gpu_type = 'a100_80gb'; num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus)\n",
    "    use_vllm = True; torch_dtype = 'bfloat16'\n",
    "else:\n",
    "    gpu_type = 'v100'\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    use_vllm = False; torch_dtype = 'float16'\n",
    "    \n",
    "    \n",
    "if len(subdir_path_list)==0:\n",
    "    subdir_path_list = []\n",
    "    for exp_dir in exp_dirs:\n",
    "        if create_symlinks:\n",
    "            remove_all_symlinks(exp_dir)\n",
    "        subdirs = list(os.listdir(exp_dir))\n",
    "        subdirs = filter(subdir_filter_fn, subdirs)\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(exp_dir, subdir)\n",
    "            if include_checkpoints:\n",
    "                subdir_path_list += glob.glob(os.path.join(subdir_path, 'checkpoint-*'))\n",
    "            if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "                continue\n",
    "            subdir_path_list.append(subdir_path)\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not os.path.islink(subdir_path) and \\\n",
    "                not os.path.isfile(os.path.join(subdir_path, 'eval', task_name, 'metrics.json')):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "                print((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "\n",
    "print('#cmds: ', len(list(task_name_and_model)), '\\n')\n",
    "\n",
    "if create_symlinks:\n",
    "    # create symlink for each directory.\n",
    "    symlink_path_dict = create_unique_symlinks(\n",
    "        list([x[1] for x in task_name_and_model]))\n",
    "    options_list = list(map(lambda x: (x[0], symlink_path_dict[x[1]]), task_name_and_model))\n",
    "else:\n",
    "    options_list = task_name_and_model\n",
    "    \n",
    "    \n",
    "dfo = pd.DataFrame(options_list, columns=['task_name', 'model_name_or_path'])\n",
    "model_and_task_list = dfo.groupby('model_name_or_path')['task_name'].agg(list).to_dict()\n",
    "\n",
    "\n",
    "info = {}  \n",
    "cmds = []\n",
    "for model_name_or_path, task_name_list in model_and_task_list.items():\n",
    "    num_tasks = len(task_name_list)\n",
    "    cmds_per_model = []\n",
    "    for i, task_name in enumerate(task_name_list):\n",
    "        queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else \\\n",
    "            ('alt_7d' if task_name.startswith('mtbench') else 'alt_1h')\n",
    "\n",
    "        use_chat_format = 'chatfmt' in task_name\n",
    "        chat_formatting_function = get_chat_formatting_function(model_name_or_path)\n",
    "\n",
    "        try:\n",
    "            with open(os.path.join(model_name_or_path, 'ft_args.json'), 'r') as f:\n",
    "                ft_args = json.load(f)\n",
    "            # note `model_name_or_path` could be anything, e.g., soft links with arbitrary names.\n",
    "            # but `ft_args_model_name_or_path` indicates the finetuned model name.\n",
    "            if 'model_args' in ft_args:\n",
    "                ft_args_model_name_or_path = ft_args['model_args']['model_name_or_path']\n",
    "            else:\n",
    "                ft_args_model_name_or_path = ft_args['model_name_or_path']\n",
    "        except:\n",
    "            ft_args_model_name_or_path = model_name_or_path\n",
    "\n",
    "        batch_size, job_duration = get_resource_for_task(\n",
    "            task_name, ft_args_model_name_or_path)\n",
    "\n",
    "        job_name = f'eval.{task_name}'\n",
    "        save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "\n",
    "        if task_name.startswith('mmlu'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 5)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.mmlu.run_eval \\\n",
    "                --data_dir data/eval/mmlu \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --ntrain {n_shot} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('gsm'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 8)\n",
    "            # open-instruct used 200 examples. use higher amount to get a more accurate number\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.gsm.run_eval \\\n",
    "                --data_dir data/eval/gsm/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_num_examples 500 \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('bbh'):\n",
    "            max_num_examples_per_task = 40\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 3)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.bbh.run_eval \\\n",
    "                --data_dir data/eval/bbh/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                --n_shot {n_shot} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--max_num_examples_per_task '+str(max_num_examples_per_task) if max_num_examples_per_task else ''} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('humaneval'):\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.codex_humaneval.run_eval \\\n",
    "                --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens 512 \\\n",
    "                --eval_pass_at_ks 1 \\\n",
    "                --unbiased_sampling_size_n 1 \\\n",
    "                --temperature 0.1 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('tydiqa'):\n",
    "            no_context = 'cb' in task_name\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot in [0,1])\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.tydiqa.run_eval \\\n",
    "                --data_dir data/eval/tydiqa \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_num_examples_per_lang 100 \\\n",
    "                --max_context_length 512 \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_context' if no_context else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('toxigen'):\n",
    "            # max_prompts_per_group=500 (out of 1000) is open-instruct default.\n",
    "            # eval batch size=1 much faster (llama-7b) not sure why.\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.toxigen.run_eval \\\n",
    "                --data_dir data/eval/toxigen \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size 3 \\\n",
    "                --max_prompts_per_group 200 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('alpacafarm'):\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            annotators_config = match.group(1)\n",
    "            annotators_config = annotators_config.replace(':', '_')\n",
    "            if not annotators_config in ['chatgpt', 'alpaca_eval_gpt4_0314', 'gpt35_turbo_1106', 'alpaca_eval_gpt4_turbo_fn', 'alpaca_eval_gpt4']:\n",
    "                raise ValueError('Just support 2 annotators_config.')\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.alpaca_farm.run_eval \\\n",
    "                --reference_path alpaca_eval_data \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --max_new_tokens 2048 \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --annotators_config {annotators_config} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('mtbench'):\n",
    "            assert('chatfmt' in task_name)\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            judge_model = match.group(1).replace(':', '-')\n",
    "            if not judge_model in OPENAI_MODEL_LIST:\n",
    "                raise ValueError('fastchat does not support the judge model.')\n",
    "            os.makedirs(save_dir, exist_ok=True) # since not using python file, make the directory now.\n",
    "            fastchat_mtbench_data_dir = os.path.normpath(os.path.join(open_instruct_dir, '../FastChat/fastchat/llm_judge/data'))\n",
    "            question_file = os.path.join(fastchat_mtbench_data_dir, 'mt_bench/question.jsonl')\n",
    "            rating_file = os.path.join(save_dir, f'{judge_model}_single.jsonl')\n",
    "            question_begin, question_end = (0, 1) if False else (None, None)\n",
    "            model_id = os.path.basename(model_name_or_path) if 'results/baselines' in save_dir else 'tulu'\n",
    "            cmd = \"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_model_answer \\\n",
    "                    --model-path {model_name_or_path} \\\n",
    "                    --model-id {model_id} \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --question-file {question_file} \\\n",
    "                    {'--question-begin '+str(question_begin) if question_begin else ''} \\\n",
    "                    {'--question-end '+str(question_end) if question_end else ''} \\\n",
    "                    --max-new-token 2048 \\\n",
    "                    --answer-file {os.path.join(save_dir, 'model_answer.jsonl')} \\\n",
    "                    --dtype {torch_dtype} \\\n",
    "                && \\\n",
    "            \"\"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_judgment \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --judge-file {os.path.join(fastchat_mtbench_data_dir, 'judge_prompts.jsonl')} \\\n",
    "                    --judge-model {judge_model} \\\n",
    "                    --mode single \\\n",
    "                    --question-file {question_file} \\\n",
    "                    --answer-dir {save_dir} \\\n",
    "                    --ref-answer-dir {os.path.join(fastchat_mtbench_data_dir, 'mt_bench/reference_answer')} \\\n",
    "                    --output-file {rating_file} \\\n",
    "                && \\\n",
    "                python -m fastchat.llm_judge.show_result \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --input-file {rating_file} \\\n",
    "                    --mode single \\\n",
    "                    --save-to-json\n",
    "            \"\"\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'{task_name} not supported.')\n",
    "            \n",
    "        if task_name.startswith('alpacafarm') and (getpass.getuser() not in ('PTFMqngp', 'wpq')):\n",
    "            queue = 'alt_6h'\n",
    "\n",
    "        if test_run:\n",
    "            print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd.strip())]))\n",
    "\n",
    "        cmd = multiline_to_singleline(cmd)\n",
    "        cmds.append(cmd)\n",
    "        cmds_per_model.append(cmd)\n",
    "        \n",
    "        if launch_one_job_per_model:\n",
    "            shell_scripts = shell_scripts_template.format(\n",
    "                conda_env='open-instruct',\n",
    "                cwd=os.path.dirname(os.getcwd()),\n",
    "                cmd=cmd,\n",
    "                log_dir=os.getcwd(),\n",
    "                save_dir=save_dir,\n",
    "            )\n",
    "            if arch == 'x86_64': # ccc\n",
    "                shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "            out = submit_job(\n",
    "                shell_scripts, \n",
    "                job_name=job_name,\n",
    "                num_cpus=num_cpus,\n",
    "                cpu_mem=cpu_mem,\n",
    "                num_gpus=num_gpus,\n",
    "                gpu_type=gpu_type,\n",
    "                test_run=test_run,\n",
    "                job_duration=job_duration,\n",
    "                queue=queue,\n",
    "            )\n",
    "        else:\n",
    "            if i + 1 == num_tasks:\n",
    "                assert(len(cmds_per_model) == num_tasks)\n",
    "                cmd = ' && '.join(cmds_per_model)\n",
    "                if test_run:\n",
    "                    print(cmd)\n",
    "                shell_scripts = shell_scripts_template.format(\n",
    "                    conda_env='open-instruct',\n",
    "                    cwd=os.path.dirname(os.getcwd()),\n",
    "                    cmd=cmd,\n",
    "                    log_dir=os.getcwd(),\n",
    "                    save_dir=os.getcwd(), # just delete afterwards.\n",
    "                )\n",
    "                if arch == 'x86_64': # ccc\n",
    "                    shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "                out = submit_job(\n",
    "                    shell_scripts, \n",
    "                    job_name=f'eval.{os.path.basename(model_name_or_path)}',\n",
    "                    num_cpus=num_cpus,\n",
    "                    cpu_mem=cpu_mem,\n",
    "                    num_gpus=num_gpus,\n",
    "                    gpu_type=gpu_type,\n",
    "                    test_run=test_run,\n",
    "                    job_duration=6,\n",
    "                    queue=None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_6b',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ea7ac978",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_eval.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b3939309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10 --max_new_tokens 2048 --save_dir results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt --eval_batch_size 10 --annotators_config alpaca_eval_gpt4_turbo_fn --use_vllm --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype bfloat16\n",
      "[2024-01-21 21:11:36,716] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:loading data and model...\n",
      "INFO 01-21 21:11:39 llm_engine.py:73] Initializing an LLM engine with config: model='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10', tokenizer='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO 01-21 21:11:39 tokenizer.py:32] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "MegaBlocks not found. Please install it by `pip install megablocks`. Note that MegaBlocks depends on mosaicml-turbo, which only supports Python 3.10 for now.\n",
      "STK not found: please see https://github.com/stanford-futuredata/stk\n",
      "INFO 01-21 21:11:53 llm_engine.py:222] # GPU blocks: 7451, # CPU blocks: 512\n",
      "Processed prompts: 100%|██████████████████████| 805/805 [01:01<00:00, 13.00it/s]\n",
      "INFO:root:Evaluating the llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10-greedy-long outputs.\n",
      "INFO:root:Creating the annotator from `alpaca_eval_gpt4_turbo_fn`.\n",
      "WARNING:root:Saving_path is given but not 'auto', make sure that it's different for different seeds.\n",
      "Annotation chunk:   0%|                                   | 0/7 [00:00<?, ?it/s]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:02<06:07,  2.90s/it]\u001b[A\n",
      "prompt_batches:   2%|▋                          | 3/128 [00:03<01:52,  1.11it/s]\u001b[A\n",
      "prompt_batches:   3%|▊                          | 4/128 [00:06<03:40,  1.78s/it]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/128 [00:11<02:02,  1.04s/it]\u001b[A\n",
      "prompt_batches:   9%|██▍                       | 12/128 [00:14<02:13,  1.15s/it]\u001b[A\n",
      "prompt_batches:  14%|███▋                      | 18/128 [00:14<01:00,  1.81it/s]\u001b[A\n",
      "prompt_batches:  16%|████                      | 20/128 [00:15<01:02,  1.73it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:18<01:16,  1.38it/s]\u001b[A\n",
      "prompt_batches:  18%|████▋                     | 23/128 [00:18<01:08,  1.52it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:21<01:29,  1.16it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/128 [00:21<01:17,  1.31it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:23<01:36,  1.05it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:25<01:27,  1.12it/s]\u001b[A\n",
      "prompt_batches:  25%|██████▌                   | 32/128 [00:29<01:47,  1.12s/it]\u001b[A\n",
      "prompt_batches:  30%|███████▋                  | 38/128 [00:34<01:27,  1.03it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/128 [00:36<01:25,  1.03it/s]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:38<01:15,  1.12it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▎                | 46/128 [00:46<01:56,  1.42s/it]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:47<01:01,  1.21it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▌              | 57/128 [00:49<00:49,  1.43it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▊              | 58/128 [00:50<00:54,  1.29it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 59/128 [00:53<01:04,  1.08it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:54<00:48,  1.36it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▊             | 63/128 [00:55<00:52,  1.23it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 64/128 [00:56<00:56,  1.13it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 65/128 [00:56<00:47,  1.32it/s]\u001b[A\n",
      "prompt_batches:  53%|█████████████▊            | 68/128 [00:58<00:39,  1.53it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [01:11<02:16,  2.36s/it]\u001b[A\n",
      "prompt_batches:  66%|█████████████████▎        | 85/128 [01:11<00:25,  1.69it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:13<00:21,  1.79it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:19<00:37,  1.02it/s]\u001b[A\n",
      "prompt_batches:  78%|███████████████████▌     | 100/128 [01:21<00:16,  1.71it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:25<00:17,  1.45it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:28<00:12,  1.55it/s]\u001b[A\n",
      "prompt_batches:  86%|█████████████████████▍   | 110/128 [01:28<00:10,  1.76it/s]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▎  | 114/128 [01:29<00:06,  2.21it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:30<00:07,  1.70it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 117/128 [01:32<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 119/128 [01:33<00:05,  1.66it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▋ | 121/128 [01:35<00:04,  1.46it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▍| 125/128 [01:36<00:01,  2.04it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 126/128 [01:36<00:01,  1.92it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:37<00:00,  1.31it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 97.8 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  14%|███▊                       | 1/7 [01:37<09:47, 97.89s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:05<12:20,  5.83s/it]\u001b[A\n",
      "prompt_batches:   5%|█▍                         | 7/128 [00:15<03:59,  1.98s/it]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:19<02:12,  1.16s/it]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:19<01:50,  1.02it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:20<01:07,  1.59it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:22<01:22,  1.28it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:23<01:03,  1.63it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/128 [00:24<01:05,  1.56it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:24<00:58,  1.73it/s]\u001b[A\n",
      "prompt_batches:  22%|█████▋                    | 28/128 [00:25<01:02,  1.59it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/128 [00:26<01:06,  1.48it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:26<01:08,  1.42it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▎                   | 31/128 [00:29<01:45,  1.09s/it]\u001b[A\n",
      "prompt_batches:  27%|██████▉                   | 34/128 [00:29<00:52,  1.78it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 36/128 [00:29<00:42,  2.14it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/128 [00:30<00:38,  2.34it/s]\u001b[A\n",
      "prompt_batches:  30%|███████▋                  | 38/128 [00:38<03:11,  2.12s/it]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:40<01:28,  1.04s/it]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:41<00:43,  1.79it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:42<00:36,  2.06it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▏              | 55/128 [00:43<00:40,  1.81it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▌              | 57/128 [00:46<00:54,  1.31it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:47<00:33,  1.97it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 64/128 [00:55<01:15,  1.18s/it]\u001b[A\n",
      "prompt_batches:  56%|██████████████▋           | 72/128 [00:55<00:32,  1.71it/s]\u001b[A\n",
      "prompt_batches:  57%|██████████████▊           | 73/128 [00:56<00:32,  1.71it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 74/128 [01:05<01:23,  1.54s/it]\u001b[A\n",
      "prompt_batches:  67%|█████████████████▍        | 86/128 [01:06<00:24,  1.71it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▋        | 87/128 [01:07<00:23,  1.74it/s]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▉        | 88/128 [01:07<00:21,  1.82it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:08<00:22,  1.76it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:12<00:43,  1.13s/it]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 95/128 [01:13<00:19,  1.67it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:13<00:20,  1.57it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:15<00:25,  1.23it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:17<00:18,  1.44it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:19<00:19,  1.31it/s]\u001b[A\n",
      "prompt_batches:  84%|████████████████████▉    | 107/128 [01:20<00:10,  2.09it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:20<00:10,  1.95it/s]\u001b[A\n",
      "prompt_batches:  86%|█████████████████████▍   | 110/128 [01:22<00:10,  1.67it/s]\u001b[A\n",
      "prompt_batches:  88%|█████████████████████▉   | 112/128 [01:24<00:12,  1.33it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:25<00:07,  1.82it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▋  | 116/128 [01:27<00:08,  1.43it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 117/128 [01:27<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 119/128 [01:28<00:05,  1.71it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▍ | 120/128 [01:30<00:06,  1.17it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:32<00:05,  1.03it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:33<00:00,  1.37it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 93.5 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  29%|███████▋                   | 2/7 [03:11<07:56, 95.40s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:03<07:34,  3.58s/it]\u001b[A\n",
      "prompt_batches:   2%|▍                          | 2/128 [00:06<06:45,  3.22s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/128 [00:07<01:14,  1.60it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/128 [00:08<01:16,  1.54it/s]\u001b[A\n",
      "prompt_batches:   9%|██▏                       | 11/128 [00:09<01:20,  1.45it/s]\u001b[A\n",
      "prompt_batches:   9%|██▍                       | 12/128 [00:10<01:29,  1.30it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:10<01:00,  1.89it/s]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:12<01:07,  1.65it/s]\u001b[A\n",
      "prompt_batches:  13%|███▍                      | 17/128 [00:13<01:10,  1.57it/s]\u001b[A\n",
      "prompt_batches:  14%|███▋                      | 18/128 [00:14<01:21,  1.35it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:15<01:08,  1.57it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:16<01:17,  1.36it/s]\u001b[A\n",
      "prompt_batches:  18%|████▋                     | 23/128 [00:17<01:23,  1.26it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:18<01:07,  1.53it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:20<01:06,  1.51it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:23<01:22,  1.18it/s]\u001b[A\n",
      "prompt_batches:  26%|██████▋                   | 33/128 [00:23<00:54,  1.75it/s]\u001b[A\n",
      "prompt_batches:  27%|███████                   | 35/128 [00:24<00:48,  1.93it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 36/128 [00:25<00:53,  1.73it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/128 [00:25<00:50,  1.82it/s]\u001b[A\n",
      "prompt_batches:  30%|███████▉                  | 39/128 [00:27<00:51,  1.74it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/128 [00:29<01:28,  1.01s/it]\u001b[A\n",
      "prompt_batches:  34%|████████▉                 | 44/128 [00:30<00:42,  1.97it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████▏                | 45/128 [00:32<01:06,  1.24it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▎                | 46/128 [00:32<00:55,  1.47it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▊                | 48/128 [00:32<00:37,  2.12it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▉                | 49/128 [00:34<01:00,  1.30it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:34<00:39,  1.95it/s]\u001b[A\n",
      "prompt_batches:  42%|██████████▉               | 54/128 [00:38<01:00,  1.22it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▏              | 55/128 [00:39<00:57,  1.28it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▍              | 56/128 [00:40<01:05,  1.09it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 59/128 [00:43<01:06,  1.05it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:43<00:40,  1.65it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▊             | 63/128 [00:44<00:40,  1.59it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 65/128 [00:46<00:46,  1.37it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 66/128 [00:46<00:38,  1.61it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▌            | 67/128 [00:46<00:34,  1.78it/s]\u001b[A\n",
      "prompt_batches:  54%|██████████████            | 69/128 [00:47<00:27,  2.11it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [00:49<00:48,  1.18it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▍           | 71/128 [00:50<00:50,  1.13it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▏          | 75/128 [00:51<00:25,  2.05it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▍          | 76/128 [00:54<00:45,  1.14it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████          | 79/128 [00:54<00:28,  1.72it/s]\u001b[A\n",
      "prompt_batches:  63%|████████████████▍         | 81/128 [00:55<00:25,  1.81it/s]\u001b[A\n",
      "prompt_batches:  64%|████████████████▋         | 82/128 [00:57<00:32,  1.42it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 83/128 [01:00<00:55,  1.24s/it]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▉        | 88/128 [01:01<00:22,  1.76it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:02<00:24,  1.60it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 91/128 [01:05<00:33,  1.10it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▋       | 92/128 [01:06<00:35,  1.03it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:07<00:19,  1.63it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:07<00:16,  1.85it/s]\u001b[A\n",
      "prompt_batches:  77%|███████████████████▉      | 98/128 [01:08<00:18,  1.62it/s]\u001b[A\n",
      "prompt_batches:  77%|████████████████████      | 99/128 [01:10<00:25,  1.13it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:11<00:20,  1.29it/s]\u001b[A\n",
      "prompt_batches:  80%|███████████████████▉     | 102/128 [01:12<00:16,  1.55it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 104/128 [01:12<00:14,  1.70it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▌    | 105/128 [01:15<00:22,  1.02it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:16<00:13,  1.53it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▎   | 109/128 [01:17<00:14,  1.33it/s]\u001b[A\n",
      "prompt_batches:  87%|█████████████████████▋   | 111/128 [01:19<00:15,  1.10it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:23<00:11,  1.16it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▋  | 116/128 [01:28<00:18,  1.51s/it]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:29<00:04,  1.36it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:32<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 92.2 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation chunk:  43%|███████████▌               | 3/7 [04:43<06:15, 93.97s/it]INFO:root:Annotating 127 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 127 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/127 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/127 [00:03<07:05,  3.38s/it]\u001b[A\n",
      "prompt_batches:   2%|▍                          | 2/127 [00:04<03:43,  1.79s/it]\u001b[A\n",
      "prompt_batches:   5%|█▎                         | 6/127 [00:04<01:06,  1.81it/s]\u001b[A\n",
      "prompt_batches:   6%|█▍                         | 7/127 [00:06<01:38,  1.22it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/127 [00:06<00:56,  2.05it/s]\u001b[A\n",
      "prompt_batches:   9%|██▎                       | 11/127 [00:10<01:59,  1.03s/it]\u001b[A\n",
      "prompt_batches:  10%|██▋                       | 13/127 [00:11<01:41,  1.12it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/127 [00:12<01:31,  1.24it/s]\u001b[A\n",
      "prompt_batches:  13%|███▍                      | 17/127 [00:14<01:24,  1.30it/s]\u001b[A\n",
      "prompt_batches:  15%|███▉                      | 19/127 [00:15<01:13,  1.48it/s]\u001b[A\n",
      "prompt_batches:  17%|████▎                     | 21/127 [00:15<00:59,  1.77it/s]\u001b[A\n",
      "prompt_batches:  19%|████▉                     | 24/127 [00:18<01:04,  1.59it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/127 [00:19<01:00,  1.66it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/127 [00:23<01:36,  1.02it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/127 [00:24<00:41,  2.16it/s]\u001b[A\n",
      "prompt_batches:  31%|███████▉                  | 39/127 [00:26<00:49,  1.79it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/127 [00:26<00:44,  1.94it/s]\u001b[A\n",
      "prompt_batches:  33%|████████▌                 | 42/127 [00:27<00:39,  2.17it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████                 | 44/127 [00:27<00:32,  2.56it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████▏                | 45/127 [00:28<00:28,  2.84it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▍                | 46/127 [00:28<00:36,  2.23it/s]\u001b[A\n",
      "prompt_batches:  37%|█████████▌                | 47/127 [00:29<00:42,  1.86it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▊                | 48/127 [00:31<01:08,  1.15it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▋               | 52/127 [00:32<00:40,  1.87it/s]\u001b[A\n",
      "prompt_batches:  42%|██████████▊               | 53/127 [00:34<00:47,  1.56it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████               | 54/127 [00:35<00:52,  1.40it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▎              | 55/127 [00:35<00:53,  1.35it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▊              | 58/127 [00:37<00:41,  1.65it/s]\u001b[A\n",
      "prompt_batches:  46%|████████████              | 59/127 [00:37<00:40,  1.68it/s]\u001b[A\n",
      "prompt_batches:  47%|████████████▎             | 60/127 [00:38<00:36,  1.85it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▋             | 62/127 [00:39<00:43,  1.49it/s]\u001b[A\n",
      "prompt_batches:  50%|████████████▉             | 63/127 [00:42<01:10,  1.10s/it]\u001b[A\n",
      "prompt_batches:  54%|█████████████▉            | 68/127 [00:43<00:28,  2.08it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▎           | 70/127 [00:45<00:41,  1.36it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▌           | 71/127 [00:51<01:21,  1.45s/it]\u001b[A\n",
      "prompt_batches:  59%|███████████████▎          | 75/127 [00:52<00:45,  1.15it/s]\u001b[A\n",
      "prompt_batches:  61%|███████████████▊          | 77/127 [00:53<00:37,  1.32it/s]\u001b[A\n",
      "prompt_batches:  63%|████████████████▍         | 80/127 [00:53<00:24,  1.93it/s]\u001b[A\n",
      "prompt_batches:  64%|████████████████▌         | 81/127 [00:55<00:32,  1.43it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 82/127 [00:56<00:34,  1.32it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▉         | 83/127 [00:56<00:29,  1.50it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▌        | 86/127 [00:56<00:17,  2.41it/s]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▊        | 87/127 [00:58<00:25,  1.54it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 90/127 [01:00<00:22,  1.64it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▊       | 92/127 [01:00<00:18,  1.90it/s]\u001b[A\n",
      "prompt_batches:  73%|███████████████████       | 93/127 [01:01<00:17,  1.94it/s]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▏      | 94/127 [01:01<00:17,  1.93it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▍      | 95/127 [01:02<00:15,  2.08it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 96/127 [01:03<00:23,  1.33it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▊      | 97/127 [01:03<00:18,  1.59it/s]\u001b[A\n",
      "prompt_batches:  78%|████████████████████▎     | 99/127 [01:04<00:15,  1.78it/s]\u001b[A\n",
      "prompt_batches:  80%|███████████████████▉     | 101/127 [01:06<00:16,  1.61it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 102/127 [01:08<00:21,  1.16it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▍    | 104/127 [01:10<00:20,  1.10it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 107/127 [01:10<00:11,  1.69it/s]\u001b[A\n",
      "prompt_batches:  87%|█████████████████████▋   | 110/127 [01:16<00:19,  1.13s/it]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 116/127 [01:18<00:07,  1.39it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 121/127 [01:19<00:03,  1.93it/s]\u001b[A\n",
      "prompt_batches:  96%|████████████████████████ | 122/127 [01:21<00:03,  1.47it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 123/127 [01:24<00:03,  1.10it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 127/127 [01:27<00:00,  1.45it/s]\u001b[A\n",
      "INFO:root:Completed 127 examples in 87.5 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation chunk:  57%|███████████████▍           | 4/7 [06:11<04:34, 91.46s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:04<10:20,  4.88s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/128 [00:07<01:36,  1.25it/s]\u001b[A\n",
      "prompt_batches:   7%|█▉                         | 9/128 [00:07<01:24,  1.41it/s]\u001b[A\n",
      "prompt_batches:  10%|██▋                       | 13/128 [00:08<00:53,  2.16it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:10<01:12,  1.57it/s]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:10<01:02,  1.80it/s]\u001b[A\n",
      "prompt_batches:  15%|███▊                      | 19/128 [00:12<01:00,  1.79it/s]\u001b[A\n",
      "prompt_batches:  16%|████                      | 20/128 [00:13<01:08,  1.58it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:13<00:59,  1.79it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:14<00:59,  1.78it/s]\u001b[A\n",
      "prompt_batches:  19%|████▉                     | 24/128 [00:16<01:22,  1.25it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:17<00:54,  1.86it/s]\u001b[A\n",
      "prompt_batches:  22%|█████▋                    | 28/128 [00:18<00:55,  1.79it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/128 [00:18<00:57,  1.72it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:21<01:35,  1.02it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▎                   | 31/128 [00:26<03:17,  2.04s/it]\u001b[A\n",
      "prompt_batches:  32%|████████▎                 | 41/128 [00:29<01:00,  1.44it/s]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:30<00:55,  1.52it/s]\u001b[A\n",
      "prompt_batches:  37%|█████████▌                | 47/128 [00:32<00:51,  1.59it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:33<00:38,  1.99it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▌               | 52/128 [00:36<00:51,  1.48it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:36<00:52,  1.43it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▍              | 56/128 [00:37<00:38,  1.85it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▊              | 58/128 [00:38<00:31,  2.20it/s]\u001b[A\n",
      "prompt_batches:  47%|████████████▏             | 60/128 [00:45<01:26,  1.26s/it]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 66/128 [00:46<00:42,  1.47it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▌            | 67/128 [00:47<00:47,  1.27it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [00:49<00:39,  1.49it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▋           | 72/128 [00:49<00:32,  1.72it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 74/128 [00:52<00:40,  1.35it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▍          | 76/128 [00:52<00:33,  1.55it/s]\u001b[A\n",
      "prompt_batches:  60%|███████████████▋          | 77/128 [00:55<00:46,  1.10it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████          | 79/128 [00:57<00:45,  1.09it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████▎         | 80/128 [00:57<00:42,  1.14it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 83/128 [00:59<00:34,  1.31it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▋        | 87/128 [01:01<00:24,  1.65it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:02<00:21,  1.80it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:02<00:19,  1.98it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 91/128 [01:05<00:39,  1.07s/it]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 95/128 [01:07<00:22,  1.45it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:08<00:24,  1.31it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:09<00:24,  1.27it/s]\u001b[A\n",
      "prompt_batches:  77%|████████████████████      | 99/128 [01:10<00:19,  1.47it/s]\u001b[A\n",
      "prompt_batches:  78%|███████████████████▌     | 100/128 [01:11<00:20,  1.38it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:11<00:18,  1.43it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:12<00:16,  1.54it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 104/128 [01:13<00:17,  1.41it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▌    | 105/128 [01:15<00:22,  1.01it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:18<00:18,  1.07it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▎   | 109/128 [01:20<00:21,  1.12s/it]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▎  | 114/128 [01:22<00:10,  1.35it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:26<00:15,  1.21s/it]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:26<00:03,  1.94it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 124/128 [01:28<00:02,  1.81it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 126/128 [01:29<00:01,  1.73it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:32<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 92.2 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  71%|███████████████████▎       | 5/7 [07:43<03:03, 91.78s/it]INFO:root:Annotating 124 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 124 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/124 [00:04<08:16,  4.04s/it]\u001b[A\n",
      "prompt_batches:   5%|█▎                         | 6/124 [00:05<01:25,  1.38it/s]\u001b[A\n",
      "prompt_batches:   6%|█▌                         | 7/124 [00:07<01:57,  1.00s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/124 [00:07<01:38,  1.18it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/124 [00:08<01:05,  1.73it/s]\u001b[A\n",
      "prompt_batches:  10%|██▌                       | 12/124 [00:10<01:38,  1.14it/s]\u001b[A\n",
      "prompt_batches:  12%|███▏                      | 15/124 [00:11<00:59,  1.84it/s]\u001b[A\n",
      "prompt_batches:  14%|███▌                      | 17/124 [00:13<01:13,  1.46it/s]\u001b[A\n",
      "prompt_batches:  15%|███▉                      | 19/124 [00:15<01:21,  1.28it/s]\u001b[A\n",
      "prompt_batches:  19%|████▊                     | 23/124 [00:16<00:56,  1.80it/s]\u001b[A\n",
      "prompt_batches:  19%|█████                     | 24/124 [00:17<01:09,  1.44it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 26/124 [00:20<01:18,  1.25it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 29/124 [00:20<00:57,  1.66it/s]\u001b[A\n",
      "prompt_batches:  25%|██████▌                   | 31/124 [00:22<00:59,  1.57it/s]\u001b[A\n",
      "prompt_batches:  26%|██████▋                   | 32/124 [00:23<01:08,  1.35it/s]\u001b[A\n",
      "prompt_batches:  27%|██████▉                   | 33/124 [00:24<01:03,  1.44it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 35/124 [00:26<01:11,  1.24it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 36/124 [00:27<01:11,  1.24it/s]\u001b[A\n",
      "prompt_batches:  32%|████████▍                 | 40/124 [00:28<00:42,  1.99it/s]\u001b[A\n",
      "prompt_batches:  33%|████████▌                 | 41/124 [00:29<01:00,  1.38it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▍                | 45/124 [00:32<00:54,  1.46it/s]\u001b[A\n",
      "prompt_batches:  39%|██████████                | 48/124 [00:33<00:39,  1.92it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 49/124 [00:36<01:05,  1.14it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▎              | 54/124 [00:37<00:37,  1.89it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▋              | 56/124 [00:38<00:35,  1.89it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 57/124 [00:40<00:53,  1.25it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▎             | 59/124 [00:40<00:39,  1.63it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 62/124 [00:41<00:31,  1.97it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 63/124 [00:42<00:35,  1.71it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 64/124 [00:43<00:35,  1.71it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▋            | 65/124 [00:44<00:42,  1.38it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▎           | 68/124 [00:45<00:30,  1.85it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▍           | 69/124 [00:46<00:27,  1.97it/s]\u001b[A\n",
      "prompt_batches:  57%|██████████████▉           | 71/124 [00:47<00:31,  1.66it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 72/124 [00:47<00:27,  1.87it/s]\u001b[A\n",
      "prompt_batches:  60%|███████████████▋          | 75/124 [00:54<01:06,  1.35s/it]\u001b[A\n",
      "prompt_batches:  61%|███████████████▉          | 76/124 [00:55<00:54,  1.13s/it]\u001b[A\n",
      "prompt_batches:  65%|████████████████▉         | 81/124 [00:55<00:22,  1.89it/s]\u001b[A\n",
      "prompt_batches:  67%|█████████████████▍        | 83/124 [00:56<00:24,  1.66it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▌        | 84/124 [00:59<00:35,  1.12it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 88/124 [01:00<00:22,  1.61it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▋       | 89/124 [01:00<00:19,  1.77it/s]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 92/124 [01:02<00:18,  1.74it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 93/124 [01:04<00:22,  1.36it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 94/124 [01:05<00:26,  1.12it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████▊     | 99/124 [01:07<00:13,  1.87it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▏    | 100/124 [01:07<00:13,  1.82it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 101/124 [01:08<00:11,  1.95it/s]\u001b[A\n",
      "prompt_batches:  83%|████████████████████▊    | 103/124 [01:08<00:08,  2.44it/s]\u001b[A\n",
      "prompt_batches:  84%|████████████████████▉    | 104/124 [01:09<00:08,  2.41it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▏   | 105/124 [01:12<00:19,  1.02s/it]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▏  | 110/124 [01:16<00:12,  1.11it/s]\u001b[A\n",
      "prompt_batches:  92%|██████████████████████▉  | 114/124 [01:17<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 115/124 [01:17<00:05,  1.62it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▍ | 116/124 [01:19<00:05,  1.40it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▌ | 117/124 [01:19<00:05,  1.38it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 118/124 [01:20<00:04,  1.36it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 120/124 [01:21<00:02,  1.79it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 122/124 [01:23<00:01,  1.27it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 124/124 [01:24<00:00,  1.47it/s]\u001b[A\n",
      "INFO:root:Completed 124 examples in 84.6 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  86%|███████████████████████▏   | 6/7 [09:08<01:29, 89.38s/it]INFO:root:Annotating 37 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 37 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                    | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   3%|▊                           | 1/37 [00:03<02:03,  3.43s/it]\u001b[A\n",
      "prompt_batches:  16%|████▌                       | 6/37 [00:04<00:21,  1.45it/s]\u001b[A\n",
      "prompt_batches:  19%|█████▎                      | 7/37 [00:05<00:19,  1.55it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▊                     | 9/37 [00:07<00:22,  1.26it/s]\u001b[A\n",
      "prompt_batches:  30%|████████                   | 11/37 [00:08<00:17,  1.46it/s]\u001b[A\n",
      "prompt_batches:  32%|████████▊                  | 12/37 [00:11<00:27,  1.08s/it]\u001b[A\n",
      "prompt_batches:  41%|██████████▉                | 15/37 [00:12<00:15,  1.39it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▊             | 19/37 [00:12<00:07,  2.40it/s]\u001b[A\n",
      "prompt_batches:  54%|██████████████▌            | 20/37 [00:14<00:10,  1.61it/s]\u001b[A\n",
      "prompt_batches:  59%|████████████████           | 22/37 [00:15<00:08,  1.77it/s]\u001b[A\n",
      "prompt_batches:  65%|█████████████████▌         | 24/37 [00:17<00:10,  1.28it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▉        | 26/37 [00:20<00:10,  1.03it/s]\u001b[A\n",
      "prompt_batches:  84%|██████████████████████▌    | 31/37 [00:21<00:03,  1.68it/s]\u001b[A\n",
      "prompt_batches:  89%|████████████████████████   | 33/37 [00:24<00:02,  1.36it/s]\u001b[A\n",
      "prompt_batches: 100%|███████████████████████████| 37/37 [00:26<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 37 examples in 26.8 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk: 100%|███████████████████████████| 7/7 [09:35<00:00, 82.20s/it]\n",
      "/dccstor/data-pruning/wpq/github/mitibm2023/external/alpaca_eval/src/alpaca_eval/metrics.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  series_preferences[series_preferences == 0] = 1.5\n",
      "INFO:root:Saving all results to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Price (per-example / total) = 0.0191 / 15.29\n",
      "Time  (per-example / total) = 0.7184 / 574.70\n",
      "                                                                                                                           model  win_rate  standard_error  n_wins  n_wins_base  n_draws  n_total       mode  avg_length  avg_output_tok_length  price\n",
      "0  llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10-greedy-long     19.32            1.39     153          647        5      805  community         607                 172.59  15.29\n",
      "Map: 100%|███████████████████████████| 805/805 [00:00<00:00, 2978.74 examples/s]\n",
      "Filter (num_proc=4): 100%|███████████| 805/805 [00:00<00:00, 4447.74 examples/s]\n",
      "Creating json from Arrow format: 100%|███████████| 1/1 [00:00<00:00, 178.53ba/s]\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3 --max_new_tokens 2048 --save_dir results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt --eval_batch_size 10 --annotators_config alpaca_eval_gpt4_turbo_fn --use_vllm --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype bfloat16\n",
      "[2024-01-21 21:22:39,160] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:loading data and model...\n",
      "INFO 01-21 21:22:41 llm_engine.py:73] Initializing an LLM engine with config: model='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3', tokenizer='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO 01-21 21:22:41 tokenizer.py:32] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "MegaBlocks not found. Please install it by `pip install megablocks`. Note that MegaBlocks depends on mosaicml-turbo, which only supports Python 3.10 for now.\n",
      "STK not found: please see https://github.com/stanford-futuredata/stk\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/eval/alpaca_farm/run_eval.py\", line 160, in <module>\n",
      "    main(args)\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/eval/alpaca_farm/run_eval.py\", line 38, in main\n",
      "    model = vllm.LLM(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/entrypoints/llm.py\", line 93, in __init__\n",
      "    self.llm_engine = LLMEngine.from_engine_args(engine_args)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 246, in from_engine_args\n",
      "    engine = cls(*engine_configs,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 109, in __init__\n",
      "    self._init_workers(distributed_init_method)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 145, in _init_workers\n",
      "    self._run_workers(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 750, in _run_workers\n",
      "    self._run_workers_in_batch(workers, method, *args, **kwargs))\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 724, in _run_workers_in_batch\n",
      "    output = executor(*args, **kwargs)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/worker/worker.py\", line 72, in load_model\n",
      "    self.model_runner.load_model()\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 36, in load_model\n",
      "    self.model = get_model(self.model_config)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/model_loader.py\", line 124, in get_model\n",
      "    model.load_weights(model_config.model, model_config.download_dir,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 335, in load_weights\n",
      "    weight_loader(param, loaded_weight, shard_id)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 303, in weight_loader\n",
      "    param_data.copy_(loaded_weight)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_eval.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859d6d6",
   "metadata": {},
   "source": [
    "# Visualize Eval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1b033ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move ./1397708.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/bbh_s=3_cot_chatfmt/1397708.out.lsf\n",
      "Job ./1388986.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/mmlu_s=0_chatfmt\n",
      "Job ./1389187.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=0_chatfmt\n",
      "Move ./1397603.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3/eval/mmlu_s=5/1397603.out.lsf\n",
      "Move ./1397594.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=5_chatfmt/1397594.out.lsf\n",
      "Move ./1398282.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp/1398282.out.lsf\n",
      "Job ./1397600.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_cb_chatfmt\n",
      "Move ./1397652.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/bbh_s=3/1397652.out.lsf\n",
      "Job ./1394502.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=0\n",
      "Job ./1396996.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "./1394831.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1396995.out exited with error code. --save_dir=results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Move ./1398502.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/1398502.out.lsf\n",
      "Move ./1397699.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/bbh_s=3_cot/1397699.out.lsf\n",
      "Move ./1397702.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_gp/1397702.out.lsf\n",
      "Move ./1398283.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_cb/1398283.out.lsf\n",
      "Job ./1397663.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/humaneval_chatfmt\n",
      "Job ./1388963.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/bbh_s=3\n",
      "Job ./1389159.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp\n",
      "Job ./1397561.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/gsm_s=8_cot\n",
      "./1388921.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1388458.out exited with error code. --save_dir=results/oi2/llama-7b_sharegpt50k_ep=2/eval/mmlu_s=0\n",
      "./1388192.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1397164.out exited with error code. --save_dir=results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/mmlu_s=5\n",
      "Move ./1397678.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/humaneval_chatfmt/1397678.out.lsf\n",
      "Job ./1397644.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/bbh_s=3_cot_chatfmt\n",
      "Job ./1397642.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/gsm_s=8_cot_chatfmt\n",
      "./1394835.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1393671.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/humaneval\n",
      "Job ./1397168.out exited with error code. --save_dir=results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/bbh_s=3_cot\n",
      "Move ./1397655.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_cb/1397655.out.lsf\n",
      "Job ./1397003.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Job ./1396671.out exited with error code. --save_dir=results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/gsm_s=8_chatfmt\n",
      "./1388919.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1397615.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3/eval/bbh_s=3_chatfmt\n",
      "Job ./1388463.out exited with error code. --save_dir=results/oi2/llama-7b_sharegpt50k_ep=2/eval/mmlu_s=5_chatfmt\n",
      "Job ./1397072.out exited with error code. --save_dir=results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3/eval/humaneval\n",
      "Job ./1388948.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/tydiqa_s=1_cb\n",
      "./1396744.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1389161.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/mmlu_s=0_chatfmt\n",
      "Job ./1388971.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/gsm_s=8_cot_chatfmt\n",
      "Job ./1393673.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_gp\n",
      "Move ./1397671.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/tydiqa_s=1_gp/1397671.out.lsf\n",
      "Move ./1397689.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/bbh_s=3_chatfmt/1397689.out.lsf\n",
      "Job ./1394503.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/mmlu_s=0\n",
      "Move ./1397648.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/mmlu_s=0/1397648.out.lsf\n",
      "./1396354.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1396997.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Move ./1398299.out -> /dccstor/data-pruning/results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/1398299.out.lsf\n",
      "Job ./1396413.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp\n",
      "Job ./1393687.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/gsm_s=8_cot\n",
      "Move ./1397703.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/mmlu_s=0_chatfmt/1397703.out.lsf\n",
      "Job ./1397014.out exited with error code. --save_dir=results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "./1397179.out does not have `--save_dir` specified. Probably still running.\n",
      "Move ./1397700.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/humaneval/1397700.out.lsf\n",
      "Job ./1388947.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/humaneval\n",
      "Job ./1389097.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/gsm_s=8_cot\n",
      "Job ./1388991.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/bbh_s=3_cot_chatfmt\n",
      "Job ./1397093.out exited with error code. --save_dir=results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/gsm_s=8\n",
      "Job ./1388976.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp_chatfmt\n",
      "Job ./1396720.out exited with error code. --save_dir=results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3/eval/humaneval\n",
      "Job ./1388969.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=5_chatfmt\n",
      "Job ./1396437.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/bbh_s=3_cot_chatfmt\n",
      "Job ./1397004.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Job ./1393700.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_cb_chatfmt\n",
      "Job ./1389178.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/mmlu_s=5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/model_outputs/sft/llama-7b+lora:r=512:a=11585+proj=4096;/1389415.out.lsf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:816\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './1389415.out' -> '/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/model_outputs/sft/llama-7b+lora:r=512:a=11585+proj=4096;/1389415.out.lsf'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# if job successfully ran, lsf system will generate a summary in log_dir,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# call this function to move lsf summary to save_dir if job is successful.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmove_lsf_job_summary_to_save_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/wpq/github/mitibm2023/src/llm/submit.py:464\u001b[0m, in \u001b[0;36mmove_lsf_job_summary_to_save_dir\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m    462\u001b[0m     target_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, save_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(out_file)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.lsf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    463\u001b[0m     target_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(target_path)\n\u001b[0;32m--> 464\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMove \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExited with exit code\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m t:\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:836\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    834\u001b[0m         rmtree(src)\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 836\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    433\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 434\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m             \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[1;32m    259\u001b[0m                 \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/model_outputs/sft/llama-7b+lora:r=512:a=11585+proj=4096;/1389415.out.lsf'"
     ]
    }
   ],
   "source": [
    "# if job successfully ran, lsf system will generate a summary in log_dir,\n",
    "# call this function to move lsf summary to save_dir if job is successful.\n",
    "move_lsf_job_summary_to_save_dir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "id": "4392e9ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_fmt=mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/3102683064.py:307: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_53e99 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_53e99_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_53e99_row0_col1, #T_53e99_row0_col2, #T_53e99_row0_col3, #T_53e99_row0_col4, #T_53e99_row0_col7, #T_53e99_row0_col9, #T_53e99_row0_col10, #T_53e99_row0_col11, #T_53e99_row0_col12, #T_53e99_row0_col13, #T_53e99_row0_col14, #T_53e99_row0_col15, #T_53e99_row0_col16, #T_53e99_row0_col17, #T_53e99_row0_col18 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_53e99_row0_col5, #T_53e99_row0_col6, #T_53e99_row0_col8, #T_53e99_row0_col19 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_53e99\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_53e99_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_53e99_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_53e99_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_53e99_level0_col3\" class=\"col_heading level0 col3\" >AcademicBench</th>\n",
       "      <th id=\"T_53e99_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_53e99_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4)/WR*</th>\n",
       "      <th id=\"T_53e99_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4)/WR</th>\n",
       "      <th id=\"T_53e99_level0_col7\" class=\"col_heading level0 col7\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_53e99_level0_col8\" class=\"col_heading level0 col8\" >AlpacaFarm(alpaca:eval:gpt4)/Len</th>\n",
       "      <th id=\"T_53e99_level0_col9\" class=\"col_heading level0 col9\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_53e99_level0_col10\" class=\"col_heading level0 col10\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_53e99_level0_col11\" class=\"col_heading level0 col11\" >GSM/Direct</th>\n",
       "      <th id=\"T_53e99_level0_col12\" class=\"col_heading level0 col12\" >GSM/CoT</th>\n",
       "      <th id=\"T_53e99_level0_col13\" class=\"col_heading level0 col13\" >BBH/Direct</th>\n",
       "      <th id=\"T_53e99_level0_col14\" class=\"col_heading level0 col14\" >BBH/CoT</th>\n",
       "      <th id=\"T_53e99_level0_col15\" class=\"col_heading level0 col15\" >TydiQA/CB</th>\n",
       "      <th id=\"T_53e99_level0_col16\" class=\"col_heading level0 col16\" >TydiQA/GP</th>\n",
       "      <th id=\"T_53e99_level0_col17\" class=\"col_heading level0 col17\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_53e99_level0_col18\" class=\"col_heading level0 col18\" >Average</th>\n",
       "      <th id=\"T_53e99_level0_col19\" class=\"col_heading level0 col19\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_53e99_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_53e99_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_53e99_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_53e99_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_53e99_row0_col3\" class=\"data row0 col3\" >22.8</td>\n",
       "      <td id=\"T_53e99_row0_col4\" class=\"data row0 col4\" >0.0</td>\n",
       "      <td id=\"T_53e99_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_53e99_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_53e99_row0_col7\" class=\"data row0 col7\" >2011.0</td>\n",
       "      <td id=\"T_53e99_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_53e99_row0_col9\" class=\"data row0 col9\" >31.8</td>\n",
       "      <td id=\"T_53e99_row0_col10\" class=\"data row0 col10\" >34.5</td>\n",
       "      <td id=\"T_53e99_row0_col11\" class=\"data row0 col11\" >5.4</td>\n",
       "      <td id=\"T_53e99_row0_col12\" class=\"data row0 col12\" >11.8</td>\n",
       "      <td id=\"T_53e99_row0_col13\" class=\"data row0 col13\" >30.6</td>\n",
       "      <td id=\"T_53e99_row0_col14\" class=\"data row0 col14\" >32.7</td>\n",
       "      <td id=\"T_53e99_row0_col15\" class=\"data row0 col15\" >9.6</td>\n",
       "      <td id=\"T_53e99_row0_col16\" class=\"data row0 col16\" >38.4</td>\n",
       "      <td id=\"T_53e99_row0_col17\" class=\"data row0 col17\" >10.2</td>\n",
       "      <td id=\"T_53e99_row0_col18\" class=\"data row0 col18\" >20.5</td>\n",
       "      <td id=\"T_53e99_row0_col19\" class=\"data row0 col19\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bbe100250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/3102683064.py:307: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_58136 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_58136_row0_col0, #T_58136_row1_col0, #T_58136_row2_col0, #T_58136_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_58136_row0_col1, #T_58136_row0_col2, #T_58136_row0_col10, #T_58136_row0_col12, #T_58136_row1_col1, #T_58136_row1_col2, #T_58136_row1_col4, #T_58136_row1_col7, #T_58136_row1_col8, #T_58136_row1_col15, #T_58136_row2_col1, #T_58136_row2_col2, #T_58136_row2_col3, #T_58136_row2_col9, #T_58136_row2_col11, #T_58136_row2_col12, #T_58136_row2_col13, #T_58136_row2_col17, #T_58136_row2_col19, #T_58136_row3_col1, #T_58136_row3_col2, #T_58136_row3_col5, #T_58136_row3_col6, #T_58136_row3_col14, #T_58136_row3_col16, #T_58136_row3_col18 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_58136_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_58136_row0_col4, #T_58136_row0_col5, #T_58136_row0_col6, #T_58136_row0_col13, #T_58136_row0_col14, #T_58136_row0_col16, #T_58136_row0_col17, #T_58136_row0_col18, #T_58136_row0_col19, #T_58136_row1_col12, #T_58136_row2_col7, #T_58136_row3_col3, #T_58136_row3_col8, #T_58136_row3_col9, #T_58136_row3_col10, #T_58136_row3_col11, #T_58136_row3_col12, #T_58136_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_58136_row0_col7, #T_58136_row0_col11, #T_58136_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_58136_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_58136_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_58136_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_58136_row1_col9, #T_58136_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row1_col18 {\n",
       "  text-align: left;\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row1_col19 {\n",
       "  text-align: left;\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_58136_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_58136_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_58136_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row2_col18 {\n",
       "  text-align: left;\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_58136_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_58136_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_58136_row3_col19 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_58136\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_58136_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_58136_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_58136_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_58136_level0_col3\" class=\"col_heading level0 col3\" >AcademicBench</th>\n",
       "      <th id=\"T_58136_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_58136_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4)/WR*</th>\n",
       "      <th id=\"T_58136_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4)/WR</th>\n",
       "      <th id=\"T_58136_level0_col7\" class=\"col_heading level0 col7\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_58136_level0_col8\" class=\"col_heading level0 col8\" >AlpacaFarm(alpaca:eval:gpt4)/Len</th>\n",
       "      <th id=\"T_58136_level0_col9\" class=\"col_heading level0 col9\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_58136_level0_col10\" class=\"col_heading level0 col10\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_58136_level0_col11\" class=\"col_heading level0 col11\" >GSM/Direct</th>\n",
       "      <th id=\"T_58136_level0_col12\" class=\"col_heading level0 col12\" >GSM/CoT</th>\n",
       "      <th id=\"T_58136_level0_col13\" class=\"col_heading level0 col13\" >BBH/Direct</th>\n",
       "      <th id=\"T_58136_level0_col14\" class=\"col_heading level0 col14\" >BBH/CoT</th>\n",
       "      <th id=\"T_58136_level0_col15\" class=\"col_heading level0 col15\" >TydiQA/CB</th>\n",
       "      <th id=\"T_58136_level0_col16\" class=\"col_heading level0 col16\" >TydiQA/GP</th>\n",
       "      <th id=\"T_58136_level0_col17\" class=\"col_heading level0 col17\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_58136_level0_col18\" class=\"col_heading level0 col18\" >Average</th>\n",
       "      <th id=\"T_58136_level0_col19\" class=\"col_heading level0 col19\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_58136_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_58136_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_58136_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_58136_row0_col2\" class=\"data row0 col2\" >10000</td>\n",
       "      <td id=\"T_58136_row0_col3\" class=\"data row0 col3\" >23.3</td>\n",
       "      <td id=\"T_58136_row0_col4\" class=\"data row0 col4\" >48.8</td>\n",
       "      <td id=\"T_58136_row0_col5\" class=\"data row0 col5\" >58.0</td>\n",
       "      <td id=\"T_58136_row0_col6\" class=\"data row0 col6\" >58.5</td>\n",
       "      <td id=\"T_58136_row0_col7\" class=\"data row0 col7\" >172.0</td>\n",
       "      <td id=\"T_58136_row0_col8\" class=\"data row0 col8\" >265.7</td>\n",
       "      <td id=\"T_58136_row0_col9\" class=\"data row0 col9\" >37.4</td>\n",
       "      <td id=\"T_58136_row0_col10\" class=\"data row0 col10\" >35.0</td>\n",
       "      <td id=\"T_58136_row0_col11\" class=\"data row0 col11\" >5.6</td>\n",
       "      <td id=\"T_58136_row0_col12\" class=\"data row0 col12\" >9.6</td>\n",
       "      <td id=\"T_58136_row0_col13\" class=\"data row0 col13\" >34.1</td>\n",
       "      <td id=\"T_58136_row0_col14\" class=\"data row0 col14\" >35.0</td>\n",
       "      <td id=\"T_58136_row0_col15\" class=\"data row0 col15\" >8.3</td>\n",
       "      <td id=\"T_58136_row0_col16\" class=\"data row0 col16\" >32.0</td>\n",
       "      <td id=\"T_58136_row0_col17\" class=\"data row0 col17\" >12.8</td>\n",
       "      <td id=\"T_58136_row0_col18\" class=\"data row0 col18\" >31.3</td>\n",
       "      <td id=\"T_58136_row0_col19\" class=\"data row0 col19\" >-3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58136_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_58136_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=mpnet:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_58136_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_58136_row1_col2\" class=\"data row1 col2\" >10000</td>\n",
       "      <td id=\"T_58136_row1_col3\" class=\"data row1 col3\" >23.3</td>\n",
       "      <td id=\"T_58136_row1_col4\" class=\"data row1 col4\" >45.0</td>\n",
       "      <td id=\"T_58136_row1_col5\" class=\"data row1 col5\" >57.5</td>\n",
       "      <td id=\"T_58136_row1_col6\" class=\"data row1 col6\" >58.2</td>\n",
       "      <td id=\"T_58136_row1_col7\" class=\"data row1 col7\" >170.0</td>\n",
       "      <td id=\"T_58136_row1_col8\" class=\"data row1 col8\" >244.1</td>\n",
       "      <td id=\"T_58136_row1_col9\" class=\"data row1 col9\" >37.4</td>\n",
       "      <td id=\"T_58136_row1_col10\" class=\"data row1 col10\" >37.2</td>\n",
       "      <td id=\"T_58136_row1_col11\" class=\"data row1 col11\" >5.8</td>\n",
       "      <td id=\"T_58136_row1_col12\" class=\"data row1 col12\" >11.4</td>\n",
       "      <td id=\"T_58136_row1_col13\" class=\"data row1 col13\" >33.5</td>\n",
       "      <td id=\"T_58136_row1_col14\" class=\"data row1 col14\" >34.3</td>\n",
       "      <td id=\"T_58136_row1_col15\" class=\"data row1 col15\" >7.9</td>\n",
       "      <td id=\"T_58136_row1_col16\" class=\"data row1 col16\" >30.2</td>\n",
       "      <td id=\"T_58136_row1_col17\" class=\"data row1 col17\" >11.6</td>\n",
       "      <td id=\"T_58136_row1_col18\" class=\"data row1 col18\" >30.8</td>\n",
       "      <td id=\"T_58136_row1_col19\" class=\"data row1 col19\" >-3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58136_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_58136_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_58136_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_58136_row2_col2\" class=\"data row2 col2\" >10000</td>\n",
       "      <td id=\"T_58136_row2_col3\" class=\"data row2 col3\" >22.6</td>\n",
       "      <td id=\"T_58136_row2_col4\" class=\"data row2 col4\" >46.0</td>\n",
       "      <td id=\"T_58136_row2_col5\" class=\"data row2 col5\" >56.9</td>\n",
       "      <td id=\"T_58136_row2_col6\" class=\"data row2 col6\" >57.4</td>\n",
       "      <td id=\"T_58136_row2_col7\" class=\"data row2 col7\" >180.0</td>\n",
       "      <td id=\"T_58136_row2_col8\" class=\"data row2 col8\" >253.9</td>\n",
       "      <td id=\"T_58136_row2_col9\" class=\"data row2 col9\" >36.5</td>\n",
       "      <td id=\"T_58136_row2_col10\" class=\"data row2 col10\" >36.0</td>\n",
       "      <td id=\"T_58136_row2_col11\" class=\"data row2 col11\" >5.4</td>\n",
       "      <td id=\"T_58136_row2_col12\" class=\"data row2 col12\" >9.6</td>\n",
       "      <td id=\"T_58136_row2_col13\" class=\"data row2 col13\" >32.0</td>\n",
       "      <td id=\"T_58136_row2_col14\" class=\"data row2 col14\" >33.6</td>\n",
       "      <td id=\"T_58136_row2_col15\" class=\"data row2 col15\" >8.4</td>\n",
       "      <td id=\"T_58136_row2_col16\" class=\"data row2 col16\" >31.2</td>\n",
       "      <td id=\"T_58136_row2_col17\" class=\"data row2 col17\" >11.0</td>\n",
       "      <td id=\"T_58136_row2_col18\" class=\"data row2 col18\" >30.3</td>\n",
       "      <td id=\"T_58136_row2_col19\" class=\"data row2 col19\" >-4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58136_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_58136_row3_col0\" class=\"data row3 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_58136_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_58136_row3_col2\" class=\"data row3 col2\" >10000</td>\n",
       "      <td id=\"T_58136_row3_col3\" class=\"data row3 col3\" >23.3</td>\n",
       "      <td id=\"T_58136_row3_col4\" class=\"data row3 col4\" >45.8</td>\n",
       "      <td id=\"T_58136_row3_col5\" class=\"data row3 col5\" >52.0</td>\n",
       "      <td id=\"T_58136_row3_col6\" class=\"data row3 col6\" >52.6</td>\n",
       "      <td id=\"T_58136_row3_col7\" class=\"data row3 col7\" >172.0</td>\n",
       "      <td id=\"T_58136_row3_col8\" class=\"data row3 col8\" >276.9</td>\n",
       "      <td id=\"T_58136_row3_col9\" class=\"data row3 col9\" >37.9</td>\n",
       "      <td id=\"T_58136_row3_col10\" class=\"data row3 col10\" >38.4</td>\n",
       "      <td id=\"T_58136_row3_col11\" class=\"data row3 col11\" >6.4</td>\n",
       "      <td id=\"T_58136_row3_col12\" class=\"data row3 col12\" >11.4</td>\n",
       "      <td id=\"T_58136_row3_col13\" class=\"data row3 col13\" >32.3</td>\n",
       "      <td id=\"T_58136_row3_col14\" class=\"data row3 col14\" >33.3</td>\n",
       "      <td id=\"T_58136_row3_col15\" class=\"data row3 col15\" >8.7</td>\n",
       "      <td id=\"T_58136_row3_col16\" class=\"data row3 col16\" >29.2</td>\n",
       "      <td id=\"T_58136_row3_col17\" class=\"data row3 col17\" >12.2</td>\n",
       "      <td id=\"T_58136_row3_col18\" class=\"data row3 col18\" >30.0</td>\n",
       "      <td id=\"T_58136_row3_col19\" class=\"data row3 col19\" >-3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bbe100250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/3102683064.py:307: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7ddda td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_7ddda_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7ddda_row0_col1, #T_7ddda_row0_col2, #T_7ddda_row0_col3, #T_7ddda_row0_col4, #T_7ddda_row0_col7, #T_7ddda_row0_col9, #T_7ddda_row0_col10, #T_7ddda_row0_col11, #T_7ddda_row0_col12, #T_7ddda_row0_col13, #T_7ddda_row0_col14, #T_7ddda_row0_col15, #T_7ddda_row0_col16, #T_7ddda_row0_col17, #T_7ddda_row0_col18 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7ddda_row0_col5, #T_7ddda_row0_col6, #T_7ddda_row0_col8, #T_7ddda_row0_col19 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7ddda\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7ddda_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_7ddda_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_7ddda_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_7ddda_level0_col3\" class=\"col_heading level0 col3\" >AcademicBench</th>\n",
       "      <th id=\"T_7ddda_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_7ddda_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4)/WR*</th>\n",
       "      <th id=\"T_7ddda_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4)/WR</th>\n",
       "      <th id=\"T_7ddda_level0_col7\" class=\"col_heading level0 col7\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_7ddda_level0_col8\" class=\"col_heading level0 col8\" >AlpacaFarm(alpaca:eval:gpt4)/Len</th>\n",
       "      <th id=\"T_7ddda_level0_col9\" class=\"col_heading level0 col9\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_7ddda_level0_col10\" class=\"col_heading level0 col10\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_7ddda_level0_col11\" class=\"col_heading level0 col11\" >GSM/Direct</th>\n",
       "      <th id=\"T_7ddda_level0_col12\" class=\"col_heading level0 col12\" >GSM/CoT</th>\n",
       "      <th id=\"T_7ddda_level0_col13\" class=\"col_heading level0 col13\" >BBH/Direct</th>\n",
       "      <th id=\"T_7ddda_level0_col14\" class=\"col_heading level0 col14\" >BBH/CoT</th>\n",
       "      <th id=\"T_7ddda_level0_col15\" class=\"col_heading level0 col15\" >TydiQA/CB</th>\n",
       "      <th id=\"T_7ddda_level0_col16\" class=\"col_heading level0 col16\" >TydiQA/GP</th>\n",
       "      <th id=\"T_7ddda_level0_col17\" class=\"col_heading level0 col17\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_7ddda_level0_col18\" class=\"col_heading level0 col18\" >Average</th>\n",
       "      <th id=\"T_7ddda_level0_col19\" class=\"col_heading level0 col19\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7ddda_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7ddda_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_7ddda_row0_col1\" class=\"data row0 col1\" >100000</td>\n",
       "      <td id=\"T_7ddda_row0_col2\" class=\"data row0 col2\" >50000</td>\n",
       "      <td id=\"T_7ddda_row0_col3\" class=\"data row0 col3\" >23.4</td>\n",
       "      <td id=\"T_7ddda_row0_col4\" class=\"data row0 col4\" >48.5</td>\n",
       "      <td id=\"T_7ddda_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_7ddda_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_7ddda_row0_col7\" class=\"data row0 col7\" >173.0</td>\n",
       "      <td id=\"T_7ddda_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_7ddda_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_7ddda_row0_col10\" class=\"data row0 col10\" >36.5</td>\n",
       "      <td id=\"T_7ddda_row0_col11\" class=\"data row0 col11\" >6.6</td>\n",
       "      <td id=\"T_7ddda_row0_col12\" class=\"data row0 col12\" >10.8</td>\n",
       "      <td id=\"T_7ddda_row0_col13\" class=\"data row0 col13\" >31.3</td>\n",
       "      <td id=\"T_7ddda_row0_col14\" class=\"data row0 col14\" >34.1</td>\n",
       "      <td id=\"T_7ddda_row0_col15\" class=\"data row0 col15\" >7.9</td>\n",
       "      <td id=\"T_7ddda_row0_col16\" class=\"data row0 col16\" >33.3</td>\n",
       "      <td id=\"T_7ddda_row0_col17\" class=\"data row0 col17\" >11.8</td>\n",
       "      <td id=\"T_7ddda_row0_col18\" class=\"data row0 col18\" >25.9</td>\n",
       "      <td id=\"T_7ddda_row0_col19\" class=\"data row0 col19\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bbe100250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/3102683064.py:307: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_28315 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_28315_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_28315_row0_col1, #T_28315_row0_col2, #T_28315_row0_col3, #T_28315_row0_col4, #T_28315_row0_col5, #T_28315_row0_col6, #T_28315_row0_col7, #T_28315_row0_col8, #T_28315_row0_col9, #T_28315_row0_col10, #T_28315_row0_col11, #T_28315_row0_col12, #T_28315_row0_col13, #T_28315_row0_col14, #T_28315_row0_col15, #T_28315_row0_col16, #T_28315_row0_col17, #T_28315_row0_col18, #T_28315_row0_col19 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_28315\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_28315_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_28315_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_28315_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_28315_level0_col3\" class=\"col_heading level0 col3\" >AcademicBench</th>\n",
       "      <th id=\"T_28315_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_28315_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4)/WR*</th>\n",
       "      <th id=\"T_28315_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4)/WR</th>\n",
       "      <th id=\"T_28315_level0_col7\" class=\"col_heading level0 col7\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_28315_level0_col8\" class=\"col_heading level0 col8\" >AlpacaFarm(alpaca:eval:gpt4)/Len</th>\n",
       "      <th id=\"T_28315_level0_col9\" class=\"col_heading level0 col9\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_28315_level0_col10\" class=\"col_heading level0 col10\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_28315_level0_col11\" class=\"col_heading level0 col11\" >GSM/Direct</th>\n",
       "      <th id=\"T_28315_level0_col12\" class=\"col_heading level0 col12\" >GSM/CoT</th>\n",
       "      <th id=\"T_28315_level0_col13\" class=\"col_heading level0 col13\" >BBH/Direct</th>\n",
       "      <th id=\"T_28315_level0_col14\" class=\"col_heading level0 col14\" >BBH/CoT</th>\n",
       "      <th id=\"T_28315_level0_col15\" class=\"col_heading level0 col15\" >TydiQA/CB</th>\n",
       "      <th id=\"T_28315_level0_col16\" class=\"col_heading level0 col16\" >TydiQA/GP</th>\n",
       "      <th id=\"T_28315_level0_col17\" class=\"col_heading level0 col17\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_28315_level0_col18\" class=\"col_heading level0 col18\" >Average</th>\n",
       "      <th id=\"T_28315_level0_col19\" class=\"col_heading level0 col19\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_28315_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_28315_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=3</td>\n",
       "      <td id=\"T_28315_row0_col1\" class=\"data row0 col1\" >150000</td>\n",
       "      <td id=\"T_28315_row0_col2\" class=\"data row0 col2\" >50000</td>\n",
       "      <td id=\"T_28315_row0_col3\" class=\"data row0 col3\" >22.9</td>\n",
       "      <td id=\"T_28315_row0_col4\" class=\"data row0 col4\" >52.5</td>\n",
       "      <td id=\"T_28315_row0_col5\" class=\"data row0 col5\" >63.7</td>\n",
       "      <td id=\"T_28315_row0_col6\" class=\"data row0 col6\" >64.2</td>\n",
       "      <td id=\"T_28315_row0_col7\" class=\"data row0 col7\" >176.0</td>\n",
       "      <td id=\"T_28315_row0_col8\" class=\"data row0 col8\" >236.0</td>\n",
       "      <td id=\"T_28315_row0_col9\" class=\"data row0 col9\" >39.1</td>\n",
       "      <td id=\"T_28315_row0_col10\" class=\"data row0 col10\" >36.6</td>\n",
       "      <td id=\"T_28315_row0_col11\" class=\"data row0 col11\" >5.6</td>\n",
       "      <td id=\"T_28315_row0_col12\" class=\"data row0 col12\" >10.0</td>\n",
       "      <td id=\"T_28315_row0_col13\" class=\"data row0 col13\" >30.7</td>\n",
       "      <td id=\"T_28315_row0_col14\" class=\"data row0 col14\" >33.4</td>\n",
       "      <td id=\"T_28315_row0_col15\" class=\"data row0 col15\" >7.9</td>\n",
       "      <td id=\"T_28315_row0_col16\" class=\"data row0 col16\" >32.5</td>\n",
       "      <td id=\"T_28315_row0_col17\" class=\"data row0 col17\" >10.4</td>\n",
       "      <td id=\"T_28315_row0_col18\" class=\"data row0 col18\" >32.2</td>\n",
       "      <td id=\"T_28315_row0_col19\" class=\"data row0 col19\" >-3.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bc10264d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_sort_rows_by_avg_ranking\n",
    "from llm.evaluate import EvalResults, get_eval_results\n",
    "from llm.evaluate import get_eval_results_with_useful_cols\n",
    "\n",
    "\n",
    "exp_dir = ''\n",
    "chat_fmt = None\n",
    "sort_rows = True\n",
    "use_normalized_preferred_metric = False\n",
    "\n",
    "\n",
    "# ## investigate code change / package update effect on eval baselines.\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# use_normalized_preferred_metric = False\n",
    "# sort_rows = False\n",
    "# save_dirs = [\n",
    "#     # llama\n",
    "#     ('llama-7b_12.13update_before', '../results/baselines/huggyllama/llama-7b_12.13update_before/'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('llama-7b_10.30update', '../results/baselines/huggyllama/llama-7b_10.30update/'),\n",
    "# #     ('llama-7b_09.23update', '../results/baselines/huggyllama/llama-7b_09.23update/'),\n",
    "# #     ('llama-7b_09.23update_before', '../results/baselines/huggyllama/llama-7b_09.23update_before/'),\n",
    "# #     # llama2\n",
    "#     ('llama2-7b_12.13update_before', '../results/baselines/NousResearch/Llama-2-7b-hf_12.13update_before/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('llama2-7b-chat', '../results/baselines/NousResearch/Llama-2-7b-chat-hf/'),\n",
    "# #     ('llama2-7b_10.30update', '../results/baselines/NousResearch/Llama-2-7b-hf_10.30update/'),\n",
    "# #     ('llama2-7b_original', '../results/baselines/NousResearch/Llama-2-7b-hf_original/'),\n",
    "# #     # mistral\n",
    "# #     ('mistral-7b_10.16update', '../results/baselines/mistralai/Mistral-7B-v0.1_10.16update/'),\n",
    "#     ('mistral-7b-Instruct-v0.1_12.13update_before', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1_12.13update_before'),\n",
    "#     ('mistral-7b-Instruct-v0.1', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     # zephyr\n",
    "#     ('zephyr-7b-beta_12.13update_before', '../results/baselines/HuggingFaceH4/zephyr-7b-beta_12.13update_before'),\n",
    "#     ('zephyr-7b-beta', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "\n",
    "# # baselines\n",
    "# save_dirs = []\n",
    "# save_dirs += [\n",
    "# #     ('gpt2', '../results/baselines/gpt2'),\n",
    "# #     ('gpt2m', '../results/baselines/gpt2-medium'),\n",
    "# #     ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "# #     ('llama2-7b+humanmix', '../results/llama2-7b_humanmix'),\n",
    "# #     ('pythia-1.4b', '../results/baselines/EleutherAI/pythia-1.4b'),\n",
    "# #     ('pythia-2.8b', '../results/baselines/EleutherAI/pythia-2.8b'),\n",
    "# #     ('pythia-6.9b', '../results/baselines/EleutherAI/pythia-6.9b'),\n",
    "# #     ('dolly-v2-7b', '../results/baselines/databricks/dolly-v2-7b'),\n",
    "#     ('mistral-7b-v0.1', '../results/baselines/mistralai/Mistral-7B-v0.1'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b+lima_ep=2', '../results/ft1_ep=2/llama-7b_lima/'),\n",
    "# #     ('mistral-7b+lima_ep=2', '../results/ft1_ep=2/mistral-7b_lima/'), \n",
    "# ]\n",
    "# exp_dir = '../results/oi2/'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "\n",
    "# exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# # exp_dir = '../results/ft2'\n",
    "# # exp_dir = '../results/ft1'\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# # save_dirs = [\n",
    "# #     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "# #     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1/'),\n",
    "# # ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'tuluv1m' in x]\n",
    "\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "# # exp_dir = '../results/oi4'\n",
    "# # exp_dir = '../results/oi4_perf_cross_time'\n",
    "# # exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'\n",
    "# exp_dir = '../results/oi4_flan_v2_vary_subsetsize'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi4_flan2022_1m'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #              ('llama-7b_flan_v2_ep=2', '../results/ft1/llama-7b_flan_v2'),\n",
    "# #              ('llama-7b_humanmix_ep=2', '../results/ft1/llama-7b_humanmix'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "# #              ('llama-7b_cot:flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_cot:flanv2'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# # exp_dir = '../results/oi4_tulu_v1_mix'\n",
    "# exp_dir = '../results/oi4_tulu_v1_mix_ep=3'\n",
    "# use_normalized_preferred_metric = False\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# ###### ultrachat\n",
    "# save_dirs = [\n",
    "#     # baselines \n",
    "#     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "#     ('mistral-7b_ultrachat200k_aftersplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k'),\n",
    "#     ('mistral-7b_ultrachat200k_beforesplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k_beforesplitlongconv'),\n",
    "    \n",
    "#     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     ('mistral-7b_sft-alpha', '../results/baselines/HuggingFaceH4/mistral-7b-sft-alpha'),\n",
    "#     ('mistral-7b-sft-beta', '../results/baselines/HuggingFaceH4/mistral-7b-sft-beta'),\n",
    "#     ('mistral-7b-sft-alpha+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-alpha'),\n",
    "#     ('mistral-7b-sft-beta+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "# # exp_dir = '../results/oi5_ultrachat:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_ultrachat200k:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# exp_dir = '../results/oi5_ultrachat15:mistral-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "# dataset = 'stanford_alpaca'\n",
    "# dataset = 'open_orca_slim'\n",
    "# dataset = 'sharegptv2'\n",
    "# dataset = 'ultrachat200kv2'\n",
    "# dataset = 'wizardlm'\n",
    "# dataset = 'wizardlmv2'\n",
    "# dataset = 'tulu_v2'\n",
    "# dataset = 'flan_v2'\n",
    "# dataset = 'oasst1'\n",
    "# dataset = 'dolly'\n",
    "# dataset_list = [\n",
    "#     'dolly',\n",
    "#     'oasst1', \n",
    "#     'flan_v2', \n",
    "#     'stanford_alpaca', \n",
    "#     'wizardlmv2', \n",
    "#     'sharegptv2', \n",
    "#     'ultrachat200kv2',\n",
    "# ]; finetune_type = 'sft'\n",
    "dataset_list = [\n",
    "    'ultrafeedback',\n",
    "]; finetune_type = 'pref'\n",
    "dataset_list = [\n",
    "    # add to get entire list of ep=3 full finetunes\n",
    "    'flan_v250k',\n",
    "    'oasst2',\n",
    "    'wizardlm50k', \n",
    "    'lima',\n",
    "    'gpt4_alpaca',\n",
    "    #\n",
    "    'dolly',\n",
    "    'stanford_alpaca50k', \n",
    "    'sharegpt50k',\n",
    "    'ultrachat50k',\n",
    "]; finetune_type = 'sft'\n",
    "dataset_list = ['stanford_alpaca50k']; finetune_type = 'sft'\n",
    "# dataset_list = ['sharegpt50k']; finetune_type = 'sft'\n",
    "# dataset_list = ['ultrachat50k']; finetune_type = 'sft'\n",
    "\n",
    "# dataset_list = ['mix_all50k']; finetune_type = 'sft'\n",
    "\n",
    "## older\n",
    "# dataset = 'tulu_v1_mix'\n",
    "save_dirs = []\n",
    "save_dirs += [\n",
    "    ('llama-7b', '../results/baselines/huggyllama/llama-7b'),\n",
    "#     ('llama-7b_lima_ep=5', '../results/oi2/llama-7b_lima_ep=5/'),\n",
    "#     ('llama-7b_lima_ep=10', '../results/oi2/llama-7b_lima_ep=10/'),\n",
    "]\n",
    "for dataset in dataset_list:\n",
    "    if dataset == 'tulu_v2':\n",
    "        save_dirs += [('llama-7b_tulu_v2:100k_ep=2', '../results/oi2/llama-7b_tulu_v2:100k_ep=2'),]\n",
    "    elif dataset == 'open_orca_slim':\n",
    "        save_dirs += [('llama-7b_openorcaslim:100k_ep=2', '../results/oi2/llama-7b_openorcaslim:100k_ep=2'),]\n",
    "    elif dataset == 'sharegptv2':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_sharegptv2_ep=2', '../results/oi2/llama-7b_sharegptv2_ep=2'),\n",
    "            ('llama-7b_sharegpt_ep=2', '../results/ft1_ep=2/llama-7b_sharegpt'),]\n",
    "    elif dataset == 'tulu_v1_mix':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "            # oi4_tulu_v1_mix_ep=3 models before transformers update.\n",
    "            # ('llama-7b_tuluv1m:50k_log_prob_decr_<10.16update', '../results/oi4_tulu_v1_mix_ep=3/llama-7b_tuluv1m:50k_log_prob_decr'),\n",
    "        ]\n",
    "    elif dataset == 'ultrafeedback':\n",
    "        exp_dir = f'../results/dpo1/'\n",
    "        if os.path.isdir(exp_dir):\n",
    "            save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "    else:\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=2', f'../results/oi2/llama-7b_{dataset}_ep=2'),]\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=3', f'../results/oi2/llama-7b_{dataset}_ep=3'),]\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=10', f'../results/oi2/llama-7b_{dataset}_ep=10'),]\n",
    "    \n",
    "    if finetune_type == 'sft':\n",
    "        exp_dirs = [\n",
    "#             f'../results/oi5_{dataset}:llama-7b',\n",
    "            f'../results/oi6_{dataset}:llama-7b'\n",
    "                   ]\n",
    "    elif finetune_type == 'pref':\n",
    "        exp_dirs = [f'../results/dpo2_{dataset}:llama-7b+sharegptv2ep2/']\n",
    "    for exp_dir in exp_dirs:\n",
    "        if os.path.isdir(exp_dir):\n",
    "            save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'dppmapbd' not in x and 'semdedup' not in x]\n",
    "    \n",
    "    if finetune_type == 'pref':\n",
    "        sft_model_dataset = 'sharegptv2'\n",
    "        save_dirs += [('llama-7b_sharegptv2_ep=2', f'../results/oi2/llama-7b_{sft_model_dataset}_ep=2')]\n",
    "# ## just compare dppmap grad vs. text\n",
    "# save_dirs = [x for x in save_dirs if 'prune:size=10000:ep=10' in x[1] and (\n",
    "#         'random' in x[1] or \n",
    "#         'dppmap' in x[1]\n",
    "#     )\n",
    "# ]\n",
    "save_dirs = [x for x in save_dirs if ('size=80000:ep=2' not in x[1]) and ('size=80000:ep=3' not in x[1])]\n",
    "save_dirs = [x for x in save_dirs if os.path.isdir(x[1])]\n",
    "#####\n",
    "\n",
    "\n",
    "###### \n",
    "\n",
    "from llm.evaluate import detect_oom_evals\n",
    "oom_eval_paths = detect_oom_evals([x for l in [glob.glob(os.path.join(x[1], 'eval/*/*.out')) for x in save_dirs] for x in l])\n",
    "if oom_eval_paths: print(oom_eval_paths)\n",
    "    \n",
    "\n",
    "# chat_fmt = False\n",
    "chat_fmt = True\n",
    "# chat_fmt = 'both'\n",
    "# chat_fmt = 'auto' # base model no chatfmt, tuned model with chatfmt\n",
    "chat_fmt = 'mix'  # non-alpacaeval no chatfmt, alpacaeval chatfmt\n",
    "\n",
    "alpacafarm_judge = 'chatgpt'\n",
    "alpacafarm_judge = 'alpaca:eval:gpt4'\n",
    "alpacafarm_judge = 'alpaca:eval:gpt4:turbo:fn'\n",
    "mtbench_judge = 'gpt:4:1106:preview'\n",
    "mtbench_judge = 'gpt:4'\n",
    "cols = []\n",
    "# cols += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/Len*', f'AlpacaFarm({alpacafarm_judge})/LenMed', f'AlpacaFarm({alpacafarm_judge})/Len', f'AlpacaFarm({alpacafarm_judge})/Rep2']\n",
    "# cols += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/WR', f'AlpacaFarm({alpacafarm_judge})/WR**', f'AlpacaFarm({alpacafarm_judge})/LenMed', f'AlpacaFarm({alpacafarm_judge})/Rep2']\n",
    "cols += [f'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*', f'AlpacaFarm(alpaca:eval:gpt4)/WR*', f'AlpacaFarm(alpaca:eval:gpt4)/WR']\n",
    "# cols += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/LenMed', ]\n",
    "cols += [f'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed',  f'AlpacaFarm(alpaca:eval:gpt4)/Len']\n",
    "# cols += [f'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed', f'AlpacaFarm(alpaca:eval:gpt4)/LenMed']\n",
    "# cols += [f'AlpacaFarm(alpaca:eval:gpt4)/WR*', f'AlpacaFarm(alpaca:eval:gpt4)/WR**', f'AlpacaFarm(alpaca:eval:gpt4)/LenMed']\n",
    "# cols += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "# cols += [f'MTBench({mtbench_judge})/Turn-1']\n",
    "# cols += [f'MTBench(gpt:4:1106:preview)/Rating', f'MTBench(gpt:4)/Rating']\n",
    "cols += ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1'] \n",
    "\n",
    "\n",
    "print(f'chat_fmt={chat_fmt}')\n",
    "df = get_eval_results_with_useful_cols(save_dirs, chat_fmt=chat_fmt, cols=cols)\n",
    "\n",
    "\n",
    "for model_name_contain in ['llama', 'pythia-1.4b', 'mistral', 'zephyr']:\n",
    "    dfc = df.copy()\n",
    "    dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "        lambda x: model_name_contain in x.lower())]\n",
    "    if not len(dfc): continue\n",
    "    from rosemary import pd_average_col_contains_substr\n",
    "    Ns = sorted(np.unique([int(x) for x in list(df['compute']) if not np.isnan(x)]).tolist())\n",
    "    datasets = sorted(np.unique([x for x in df['dataset'] if x is not None]).tolist())\n",
    "    for dataset in datasets:\n",
    "        for N in Ns+[None]:\n",
    "            dfc = df.copy()\n",
    "            dfc = dfc[dfc['compute'].apply(lambda x: x == N if (not np.isnan(x) or x is not None) else True)]\n",
    "            dfc = dfc[dfc['dataset'].apply(lambda x: x == dataset if x else True)]\n",
    "            if not len(dfc): continue\n",
    "            col_runname = 'run_name' if chat_fmt != 'both' else ('run_name', '')\n",
    "            substitute = True\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, '_random_', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=10000:ep=10', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=50000:ep=5', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=3', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=1', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=100000', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=200000', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=400000', substitute=substitute)\n",
    "            #     dfc = dfc.sort_values(['ranking'], ascending=False)\n",
    "            col = ('Average', 'chatfmt') if chat_fmt == 'both' else 'Average'\n",
    "        #     col = 'AlpacaFarm/WR'\n",
    "        #     col = 'MMLU/0-shot'|\n",
    "        #     col = 'GSM/CoT'\n",
    "        #     col = 'BBH/Direct'\n",
    "        #     col = 'TydiQA/GP'\n",
    "            dfc = dfc.sort_values(by=[col], ascending=False)\n",
    "            dfc = dfc.drop(columns=['model_name_or_path', 'dataset'], \n",
    "                           axis=1, level=0 if chat_fmt=='both' else None)\n",
    "            dfc = dfc.reset_index(drop=True)\n",
    "            display(dfc\n",
    "                    .style\n",
    "                    .applymap(lambda x: f'max-width: 60ch;', subset=['run_name'])\n",
    "                    .set_table_styles([{'selector': 'td', 'props': [('white-space', 'pre-wrap'), ('word-wrap', 'break-word')]}])\n",
    "                    .set_properties(**{'text-align': 'left'})\n",
    "                    .background_gradient(cmap ='coolwarm')\n",
    "#                     .applymap(lambda x: 'text-decoration: underline;' \\\n",
    "#                               if x in dfc[list(set(dfc.columns) & set([(x, '') for x in cols]))+[col] if chat_fmt=='both' else cols+[col]].values.flatten() and chat_fmt=='both' else '')\n",
    "                    .format(precision=1))\n",
    "\n",
    "# llama-7b_tulu_v1_mix(paper)\n",
    "# MMLU/0-shot, MMLU/5-shot, GSM/Direct, GSM/CoT, BBH/Direct, BBH/CoT, TydiQA/GP, TydiQA/CB, CodexEval/Pass@1, AlpacaEval(vs.Davinci-003)\n",
    "# 44.8       , 47.1       , 7.0       , 25.0   , 38.5      , 38.5   , 43.5,    , 8.0      , 18.6,           , 48.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef02eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot diversity vs. alpacaeval score\n",
    "\n",
    "\n",
    "dataset_list = [\n",
    "    'super_ni',\n",
    "    'flan_v250k',\n",
    "    'oasst2',\n",
    "    'wizardlm50k', \n",
    "#     'lima',\n",
    "    'gpt4_alpaca',\n",
    "    'dolly',\n",
    "    'stanford_alpaca50k', \n",
    "    'sharegpt50k',\n",
    "    'ultrachat50k',\n",
    "]\n",
    "save_dirs = []\n",
    "for dataset in dataset_list:\n",
    "    save_dirs += [(f'llama-7b_{dataset}_ep=3', f'../results/oi2/llama-7b_{dataset}_ep=3'),]\n",
    "save_dirs = [x for x in save_dirs if os.path.isdir(x[1])]\n",
    "\n",
    "chat_fmt = 'mix'\n",
    "alpacafarm_judge = 'alpaca:eval:gpt4:turbo:fn' # \n",
    "alpacafarm_judge = 'alpaca:eval:gpt4'\n",
    "cols = []\n",
    "cols += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/WR']\n",
    "cols += ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1'] \n",
    "\n",
    "df = get_eval_results_with_useful_cols(save_dirs, chat_fmt=chat_fmt, cols=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "id": "d9a9d443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlpacaFarm(alpaca:eval:gpt4)/WR* {'flan_v250k': 2.111801242236025, 'dolly': 13.167701863354036, 'stanford_alpaca50k': 21.304347826086957, 'oasst2': 49.93788819875776, 'wizardlm50k': 60.745341614906835, 'ultrachat50k': 63.72670807453416, 'gpt4_alpaca50k': 63.913043478260875, 'sharegpt50k': 67.51552795031056}\n",
      "AcademicBench {'oasst2': 22.217772301009884, 'ultrachat50k': 22.90774015084645, 'stanford_alpaca50k': 22.989997233965415, 'gpt4_alpaca50k': 23.189254803071105, 'dolly': 24.081346866510223, 'wizardlm50k': 24.222268910222496, 'sharegpt50k': 24.45554782583774, 'flan_v250k': 26.426821396438108}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in ['AlpacaFarm(alpaca:eval:gpt4)/WR*', 'AcademicBench']:\n",
    "    d = df.set_index(['dataset']).to_dict()[k]\n",
    "    d = dict(sorted(d.items(), key=lambda kv: kv[1]))\n",
    "    print(k, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "id": "0578e9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 8 artists>"
      ]
     },
     "execution_count": 903,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "d = df.set_index(['dataset']).to_dict()['AlpacaFarm(alpaca:eval:gpt4)/WR*']\n",
    "d = dict(sorted(d.items(), key=lambda kv: kv[1]))\n",
    "\n",
    "\n",
    "xs = d.keys()\n",
    "ys = d.values()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(20,2))\n",
    "\n",
    "plt.bar(xs, ys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81db2499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "id": "deeba0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_name',\n",
       " 'nonchat',\n",
       " 'sort_by',\n",
       " 'compute',\n",
       " 'AcademicBench',\n",
       " 'model_name_or_path',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4)/WR*',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4)/WR',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4)/Len',\n",
       " 'MMLU/0-shot',\n",
       " 'MMLU/5-shot',\n",
       " 'GSM/Direct',\n",
       " 'GSM/CoT',\n",
       " 'BBH/Direct',\n",
       " 'BBH/CoT',\n",
       " 'TydiQA/CB',\n",
       " 'TydiQA/GP',\n",
       " 'Codex-Eval/Pass@1',\n",
       " 'Average',\n",
       " 'ranking']"
      ]
     },
     "execution_count": 1021,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from rosemary import parse_kv_from_string\n",
    "from functools import partial\n",
    "\n",
    "def get_dataset_size(dataset):\n",
    "    if dataset == 'dolly':\n",
    "        return 14956\n",
    "    else:\n",
    "        return 50_000\n",
    "    \n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', ]\n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', ]\n",
    "\n",
    "N = 50_000\n",
    "full_sft_run_name_substr = ('_ep=3', '_ep=10')\n",
    "# full_sft_run_name_substr = '_ep=2'\n",
    "full_sft_short = '100% Data'\n",
    "\n",
    "label_dpp_vmf_grad = r\"$\\nabla_{\\theta} \\ell(x;\\theta)$-norm.\"\n",
    "label_dpp_vmf_grad = r\"LM-Weight-Gradient-norm.\"\n",
    "label_dpp_vmf_text = r\"LM-Embeddings-norm.\"\n",
    "label_dpp_rbf_grad = r\"$\\nabla_{\\theta} \\ell(x;\\theta)$\"\n",
    "label_dpp_rbf_text = r\"LM-Embeddings\"\n",
    "label_dpp_vmf_mpnet = r\"mpnet$(x;\\theta)$-norm.\"\n",
    "\n",
    "# label_dpp_acos0_text = r\"$\\text{DPP-}\\text$\"\n",
    "label_dpp_acos0_text = 'DPP-acos0-text'\n",
    "label_dpp_acos0_grad = 'DPP-acos0-grad'\n",
    "label_dpp_acos1_text = 'DPP-acos1-text'\n",
    "label_dpp_acos1_grad = 'DPP-acos1-grad'\n",
    "\n",
    "\n",
    "def compute_nonchateval_average_performance(row):\n",
    "    L = [row[k] for k in non_chateval_task_names if k in row]\n",
    "    return np.average(L)\n",
    "\n",
    "\n",
    "def parse_sort_by_from_run_name(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'score=([^_]+)', run_name)\n",
    "    if match:\n",
    "        sort_by = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(sort_by)\n",
    "    else:\n",
    "        if run_name.endswith(full_sft_run_name_substr):\n",
    "            kvs = {0: full_sft_short}\n",
    "        else:\n",
    "            kvs = {}\n",
    "    return kvs\n",
    "\n",
    "\n",
    "def parse_sort_by_type(row):\n",
    "    d = row['sort_by']\n",
    "    if not d:\n",
    "        return None\n",
    "    if d[0] == 'dppmap':\n",
    "        if d['k']=='vmf' and d['kmd']=='mpnet': #and (d['gamma']==1 or d['gamma'] == 'auto1000'):\n",
    "            sort_by_type = 'vmf+text'\n",
    "        elif d['kemb']=='text+embedding' and d['kmd'] == 'llama7br512p4096':\n",
    "            if d['k']=='rbf': return label_dpp_rbf_text\n",
    "            elif d['k'] == 'vmf': return label_dpp_vmf_text\n",
    "            elif d['k'] == 'acos0': return label_dpp_acos0_text\n",
    "            elif d['k'] == 'acos1': return label_dpp_acos1_text\n",
    "        elif d['kemb']=='grad+rp+loraB' and d['kmd'] == 'llama7br512p4096':\n",
    "            if d['k']=='rbf': return label_dpp_rbf_grad\n",
    "            elif d['k']=='vmf': return label_dpp_vmf_grad\n",
    "            elif d['k'] == 'acos0': return label_dpp_acos0_grad\n",
    "            elif d['k'] == 'acos1': return label_dpp_acos1_grad\n",
    "        elif d['kemb']=='text+embedding' and d['kmd'] == 'mpnet':\n",
    "            return label_dpp_vmf_mpnet\n",
    "        else:\n",
    "            return None\n",
    "#         print(d, d['kemb']=='text+embedding' and d['kmd'] == 'mpnet')\n",
    "#         print(d)\n",
    "        sort_by_type = f'DPP({sort_by_type})'\n",
    "        return sort_by_type\n",
    "    elif d[0] == 'random':\n",
    "        return 'Random'\n",
    "    elif d[0] == full_sft_short:\n",
    "        return d[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "base_model_perf = df[df['run_name'] == 'llama-7b'].to_dict(orient='records')[0]\n",
    "base_model_perf['nonchat'] = compute_nonchateval_average_performance(base_model_perf)\n",
    "\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "dfc.insert(1, 'sort_by' if chat_fmt!='both' else ('sort_by', ''), dfc.apply(parse_sort_by_from_run_name, axis=1))\n",
    "dfc.insert(1, 'sort_by_type' if chat_fmt!='both' else ('sort_by_type', ''), dfc.apply(parse_sort_by_type, axis=1))\n",
    "dfc.insert(1, 'nonchat' if chat_fmt!='both' else ('nonchat', ''), dfc.apply(compute_nonchateval_average_performance, axis=1))\n",
    "\n",
    "\n",
    "dfc = dfc[dfc['sort_by_type'].notnull()]\n",
    "startswithstrs = ('rbf+text', 'random')\n",
    "startswithstrs = (\n",
    "    full_sft_short,\n",
    "    'Random', \n",
    "#     label_dpp_rbf_text,\n",
    "    label_dpp_vmf_text,\n",
    "#     label_dpp_rbf_grad,\n",
    "#     label_dpp_vmf_mpnet,\n",
    "    label_dpp_vmf_grad, \n",
    "    ## dont worry about this.\n",
    "#     label_dpp_acos0_text,\n",
    "#     label_dpp_acos0_grad,\n",
    "#     label_dpp_acos1_text,\n",
    "#     label_dpp_acos1_grad,\n",
    ")\n",
    "dfc = dfc[dfc.apply(lambda x: any(y in x['sort_by_type'] for y in startswithstrs), axis=1)]\n",
    "dfc['subset_size'] = dfc['subset_size'].apply(lambda x: int(x) if x else x)\n",
    "dfc['compute'] = dfc['compute'].apply(lambda x: int(x) if x else x)\n",
    "# dfc = dfc[dfc['subset_size'].apply(lambda x: x>1000)]\n",
    "\n",
    "\n",
    "D = dfc.set_index(['sort_by_type', 'dataset', 'subset_size']).to_dict()\n",
    "from dataclasses import dataclass\n",
    "@dataclass(unsafe_hash=True)\n",
    "class DKey:\n",
    "    sort_by_type: str\n",
    "    dataset: str\n",
    "    subset_size: int\n",
    "def convert_key_to_dataclass(d):\n",
    "    return {DKey(*k): v for k, v in d.items()}\n",
    "D = {k: convert_key_to_dataclass(v) for k, v in D.items()}\n",
    "\n",
    "list(D.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "id": "41b95aee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "font_path = '/dccstor/data-pruning/miniconda3/pkgs/mscorefonts-0.0.1-3/fonts/times.ttf'  # Your font path goes here\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "prop = font_manager.FontProperties(fname=font_path)\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = prop.get_name()\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_task_name_display(task_name):\n",
    "    if task_name == 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*': return 'AlpacaEval\\n(Win Rate)'\n",
    "    if task_name == 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR**': return 'AlpacaEval\\n(Win Rate **)'\n",
    "    elif task_name == 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len*': return 'AlpacaEval\\n(Tok Length*)'\n",
    "    elif task_name == 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len': return 'AlpacaEval\\n(Tok Length)'\n",
    "    elif task_name == 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed': return 'AlpacaEval\\n(Medium #Tokens)'\n",
    "    elif task_name == 'MTBench(gpt:4)/Turn-1': return 'MT-Bench(GPT-4)/Turn-1'\n",
    "    elif task_name == 'MTBench(gpt:4)/Turn-2': return 'MT-Bench(GPT-4)/Turn-2'\n",
    "    elif task_name == 'MTBench(gpt:4)/Rating': return 'MT-Bench(GPT-4)/Rating'\n",
    "    elif task_name == 'nonchat': return 'NLP Benchmarks\\n(Average Score)'\n",
    "    else: return task_name\n",
    "        \n",
    "def get_dataset_display(dataset):\n",
    "    if 'dolly' in dataset: return 'Dolly'\n",
    "    elif 'stanford_alpaca' in dataset: return 'Alpaca'\n",
    "    elif 'ultrachat' in dataset: return 'UltraChat'\n",
    "    elif 'sharegpt' in dataset: return 'ShareGPT'\n",
    "    elif 'ultrafeedback' in dataset: return 'UltraFeedback'\n",
    "    elif 'flan_v2' in dataset: return \"FLAN\"\n",
    "    elif 'oasst2' in dataset: return \"OASST2\"\n",
    "    elif 'wizardlm' in dataset: return \"WizardLM\"\n",
    "    else: raise ValueError(f'{dataset} not defined display name')\n",
    "\n",
    "\n",
    "data_to_compute_dict = dfc.set_index(['subset_size']).to_dict()['compute']\n",
    "data_to_compute_pct = lambda x: data_to_compute_dict[x]/max(data_to_compute_dict.values())*100\n",
    "\n",
    "\n",
    "plt_base_model = True\n",
    "plt_full_finetune = True\n",
    "xaxis_type = 'data' # 'compute'\n",
    "yaxis_type = 'abs'\n",
    "yaxis_type = 'delta_fullfinetune'; \n",
    "assert(yaxis_type in ['abs', 'delta_fullfinetune'])\n",
    "\n",
    "if finetune_type == 'sft':\n",
    "    datasets = ['dolly', 'stanford_alpaca50k', 'ultrachat50k', 'sharegpt50k']\n",
    "    datasets = ['flan_v250k', 'dolly', 'stanford_alpaca50k', 'oasst2', 'ultrachat50k', 'wizardlm50k', 'sharegpt50k']\n",
    "    datasets = ['flan_v250k', 'dolly', 'stanford_alpaca50k', 'ultrachat50k', 'wizardlm50k', 'sharegpt50k']\n",
    "else:\n",
    "    datasets = ['ultrafeedback']\n",
    "# datasets = list(np.unique(dfc['dataset']))\n",
    "\n",
    "task_names = []\n",
    "task_names += ['nonchat']\n",
    "# task_names += ['nonchat', 'MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR*',]\n",
    "# task_names += ['MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1',]\n",
    "# task_names += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "# task_names += [f'MTBench({mtbench_judge})/Rating']\n",
    "# task_names += [f'MTBench({mtbench_judge})/Turn-1']\n",
    "task_names += [f'AlpacaFarm({alpacafarm_judge})/WR*'] \n",
    "# task_names += [f'AlpacaFarm({alpacafarm_judge})/WR**'] \n",
    "# task_names += [f'AlpacaFarm({alpacafarm_judge})/LenMed']\n",
    "# task_names += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/LenMed'] # , f'AlpacaFarm({alpacafarm_judge})/Rep2'\n",
    "\n",
    "label_baseline = 'Base Model'\n",
    "\n",
    "plt_settings = {\n",
    "    'color': {\n",
    "        full_sft_short: '#333333', #'#FFA500', # orange\n",
    "#         'Random': 'gray',\n",
    "        label_baseline: 'gray',\n",
    "#         label_dpp_vmf_grad: '#3498db', # bright blue\n",
    "#         label_dpp_vmf_text: '#1f618d', # dark blue\n",
    "#         label_dpp_vmf_text,\n",
    "#         label_dpp_rbf_grad,\n",
    "#         label_dpp_rbf_text,\n",
    "    },\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'axes.titlesize': 25,   # ax title\n",
    "    'axes.labelsize': 19,   # labels (x-axis and y-axis)\n",
    "    'xtick.labelsize': 14,  # xtick size\n",
    "    'ytick.labelsize': 15,  # ytick size\n",
    "    'figure.labelsize': 25, # \n",
    "    'legend.fontsize': 15,  # legend font size\n",
    "})\n",
    "\n",
    "markers_list = ['^', 'o', '*', 'x', 's', ]\n",
    "markers_list = ['o']*10\n",
    "lineplot_kwargs = {'marker': '.', \n",
    "#                    'markerfacecolor': 'none', \n",
    "                   'markersize': 8, \n",
    "                   'alpha': .8,\n",
    "#                    'markeredgewidth': 2,\n",
    "#                    'linewidth': 1.5,\n",
    "                  }\n",
    "\n",
    "w = 2.5; h = 2.5\n",
    "# w = 3; h = 3\n",
    "ncols = len(datasets)\n",
    "nrows = len(task_names)\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(w*ncols, h*nrows), sharey='row', sharex='col')\n",
    "\n",
    "xticks_data = defaultdict(list)\n",
    "\n",
    "for axi, task_name in enumerate(task_names):\n",
    "    d = D[task_name]\n",
    "    for axj, dataset in enumerate(datasets):\n",
    "        ax = axs.reshape(nrows, ncols)[axi, axj]\n",
    "        dataset_size = get_dataset_size(dataset)\n",
    "        is_first_subfig = (axi==0 and axj==0)\n",
    "\n",
    "        if plt_base_model and task_name == 'nonchat':\n",
    "            k = DKey(full_sft_short, dataset, dataset_size)\n",
    "            if k in d:\n",
    "                y_fullfinetune = d[k]\n",
    "                y_base = base_model_perf[task_name]\n",
    "                y = y_base-y_fullfinetune if yaxis_type == 'delta_fullfinetune' else y_base\n",
    "                ax.axhline(y=y, linestyle='--', color=plt_settings['color'][label_baseline], label=label_baseline if is_first_subfig else None, linewidth=2)\n",
    "        if plt_full_finetune:\n",
    "            k = DKey(full_sft_short, dataset, dataset_size)\n",
    "            if k in d:\n",
    "                y = 0 if yaxis_type == 'delta_fullfinetune' else d[k]\n",
    "                ax.axhline(y=y, linestyle='--', color=plt_settings['color'][full_sft_short], label=full_sft_short if is_first_subfig else None, linewidth=3)\n",
    "\n",
    "        sort_by_types = sorted(set(x.sort_by_type for x in d.keys()))[::-1]\n",
    "#         sort_by_types = list(set([x.sort_by_type for x in d.keys()]))\n",
    "        for i, sort_by_type in enumerate(sort_by_types):\n",
    "            xs = sorted([x.subset_size for x in d.keys()\n",
    "                         if x.dataset == dataset and x.sort_by_type==sort_by_type])\n",
    "            xticks_data[dataset] += list(set(xs) - set(xticks_data[dataset]))\n",
    "\n",
    "            ys = [d[DKey(sort_by_type, dataset, x)] for x in xs]\n",
    "            if yaxis_type == 'delta_random':\n",
    "                if not all(DKey('random', dataset, x) in d for x in xs): continue\n",
    "                ys = [y-d[DKey('random', dataset, x)] for x, y in zip(xs, ys)] \n",
    "            elif yaxis_type == 'delta_fullfinetune':\n",
    "                if DKey(full_sft_short, dataset, dataset_size) not in d: continue\n",
    "                ys = [y-d[DKey(full_sft_short, dataset, dataset_size)] for y in ys]\n",
    "            kwargs = {}\n",
    "            if sort_by_type in plt_settings['color']:\n",
    "                kwargs['color'] = plt_settings['color'][sort_by_type]\n",
    "            if full_sft_short not in sort_by_type and is_first_subfig:\n",
    "                kwargs['label'] = sort_by_type\n",
    "            kwargs.update(lineplot_kwargs)\n",
    "            kwargs.update({'marker': markers_list[i]})\n",
    "            xs = xs if xaxis_type == 'data' else [data_to_compute_pct(x) for x in xs]\n",
    "            ax.plot(xs, ys, **kwargs)\n",
    "            ax.grid(visible=True, axis='y')\n",
    "            ax.tick_params(axis='both', which='both', length=6) \n",
    "\n",
    "\n",
    "## left most subfigure set ylabel & yticks\n",
    "for axi, task_name in enumerate(task_names):\n",
    "    task_name_shortened = get_task_name_display(task_name)\n",
    "    ax = axs.reshape(nrows, ncols)[axi, 0]\n",
    "    ax.set_ylabel(task_name_shortened.replace('(', '(▲ ') if yaxis_type.startswith('delta') else task_name_shortened, va='bottom')\n",
    "    if yaxis_type == 'delta_fullfinetune':\n",
    "        if task_name == 'nonchat': yticks = [-3,-2,-1,0,1]\n",
    "        elif 'AlpacaFarm' in task_name and 'WR' in task_name: yticks = [-12, -8, -4, 0, 4, 8]\n",
    "        else: yticks = None\n",
    "        if yticks is not None: ax.set_yticks(yticks, yticks)\n",
    "    \n",
    "\n",
    "for axj, dataset in enumerate(datasets):\n",
    "    dataset_size = get_dataset_size(dataset)\n",
    "    xticks = np.array(sorted(xticks_data[dataset]))\n",
    "    ax = axs.reshape(nrows, ncols)[nrows-1, axj]\n",
    "    c = .05; ax.set_xlim((-N*c, N+c*N))\n",
    "    xticklabels = [f'{x*100:.0f}%' for x in xticks/get_dataset_size(dataset)]\n",
    "    ax.set_xticks(xticks, xticklabels, ha='center', rotation=45)\n",
    "\n",
    "    ax = axs.reshape(nrows, ncols)[0, axj]\n",
    "    ax.set_title(get_dataset_display(dataset))\n",
    "\n",
    "    if yaxis_type != 'abs':\n",
    "        axs.reshape(nrows, ncols)[0, axj].set_ylim((-3.5, 1))\n",
    "        axs.reshape(nrows, ncols)[1, axj].set_ylim((-14, 10))\n",
    "        \n",
    "        \n",
    "## data xlabel at the side s\n",
    "axs.reshape(nrows, ncols)[nrows-1, 0].annotate('Data', xy=(-0.3, -.15), xycoords=\"axes fraction\", ha='left', va='center', weight='bold', fontsize=plt.rcParams['axes.labelsize'])\n",
    "## legend at bottom\n",
    "fig.legend(loc='lower center', bbox_to_anchor=(0.5, -.12), ncol=6, frameon=True)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "save_path = os.path.join(assets_dir, 'fig_vmf_grad_vs_random_cross_datasets.pdf')\n",
    "fig.savefig(save_path, bbox_inches='tight', dpi=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "id": "2dd81658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Random', 'LM-Weight-Gradient-norm.', 'LM-Embeddings-norm.', '100% Data']"
      ]
     },
     "execution_count": 1024,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_by_types\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6878e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f365feb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
