{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da1794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/__init__.py:25: UserWarning: Install `torch` for functionalities dependent on torch\n",
      "  warn(f'Install `torch` for functionalities dependent on torch')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'ppc64le', 'cluster': 'dcs'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "import re\n",
    "from llm.submit import (\n",
    "    multiline_to_singleline,\n",
    "    submit_job_ccc,\n",
    "    submit_job_aimos,\n",
    "    submit_job,\n",
    "        get_run_statistics)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import datetime\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import base64\n",
    "string_to_alphanumeric = lambda s: base64.urlsafe_b64encode(s.encode('utf-8')).decode('utf-8')\n",
    "alphanumeric_to_string = lambda a: base64.urlsafe_b64decode(a).decode('utf-8')\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm, shell_scripts_template_lsf, get_host_info\n",
    "\n",
    "info = get_host_info()\n",
    "arch, cluster = info['arch'], info['cluster']\n",
    "print(info)\n",
    "\n",
    "## jobs submitted in notebook inherits env variables.\n",
    "cache_dir = '/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/cache'\n",
    "os.environ['WANDB_DIR'] = cache_dir\n",
    "os.makedirs(os.environ['WANDB_DIR'], exist_ok=True)\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_PROJECT'] = 'mitibm'\n",
    "##\n",
    "##\n",
    "\n",
    "shell_scripts_template = shell_scripts_template_slurm \\\n",
    "    if arch == 'ppc64le' else shell_scripts_template_lsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8323654",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850a84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_name = 'ft'\n",
    "# test_run = 1\n",
    "# test_run = bool(test_run)\n",
    "\n",
    "# queue = 'x86_12h' # 'x86_12h'\n",
    "# num_cpus = 20\n",
    "# num_gpus = 1\n",
    "# cpu_mem = 32\n",
    "# require = 'a100_80gb'\n",
    "\n",
    "# # model_name_or_path = 'mosaicml/mpt-7b'; max_seq_length = 2048\n",
    "# # model_name_or_path = 'gpt2'; max_seq_length = 1024\n",
    "# # model_name_or_path = 'gpt2-Large'; max_seq_length = 1024\n",
    "# # model_name_or_path = 'gpt2-xl'; max_seq_length = 1024\n",
    "# model_name_or_path = 'huggyllama/llama-7b'; max_seq_length = 2048\n",
    "\n",
    "\n",
    "# train_file = 'data/processed/oasst1/oasst1_data.jsonl'; train_file_short = 'oasst1'\n",
    "# train_file = 'data/processed/flanv2_cot_oasst1_dolly.jsonl'; train_file_short = 'human_mix'\n",
    "# # train_file = 'data/processed/flanv2_cot_oasst1_dolly_shuffled.jsonl'; train_file_short = 'human_mix_shuffled'\n",
    "\n",
    "# output_dir = f\"results/{model_name_or_path.replace('/', ':')}_{train_file_short}\"\n",
    "# if test_run:\n",
    "#     output_dir = 'jpt_' + output_dir\n",
    "\n",
    "# use_deepspeed = False\n",
    "# # deepspeed_config_file = 'ds_configs/stage3_no_offloading_accelerate_setauto.conf'\n",
    "# # deepspeed_config_file = 'ds_configs/stage3_offloading_accelerate.conf'\n",
    "# deepspeed_config_file = 'ds_configs/stage3_offloading_accelerate_setauto.conf'\n",
    "\n",
    "# use_lora = True\n",
    "# lora_rank = 4\n",
    "# lora_alpha = lora_rank\n",
    "# lora_dropout = 0.05\n",
    "\n",
    "# batch_size_per_gpu = 1\n",
    "# total_batch_size = 128\n",
    "# mixed_precision = 'bf16' # 'bf16', 'fp16'\n",
    "# checkpointing_steps = None # every n steps, where n='1' or every 'epoch'\n",
    "\n",
    "# gradient_acc_steps = int(total_batch_size/num_gpus/batch_size_per_gpu)\n",
    "\n",
    "# print(f\"Training {model_name_or_path} \"\n",
    "#       f\"using {num_gpus} GPUs, \"\n",
    "#       f\"{batch_size_per_gpu} batch size per GPU, \"\n",
    "#       f\"{gradient_acc_steps} gradient accumulation steps.\")\n",
    "\n",
    "# # do use fast tokenizer since mpt-7b does not have a fast tokenizer counter-part\n",
    "# #     --use_slow_tokenizer \\\n",
    "# # do not use flash attention, since having problem installing flash-attn with cuda 12.1\n",
    "# #     --use_flash_attn \\\n",
    "\n",
    "# cmd = f\"\"\"\n",
    "# {'!cd .. && ' if test_run else ''}accelerate launch \\\n",
    "#     --mixed_precision {mixed_precision} \\\n",
    "#     --num_machines 1 \\\n",
    "#     --num_processes {num_gpus} \\\n",
    "#     {'--use_deepspeed' if use_deepspeed else ''}\n",
    "#     {'--deepspeed_config_file '+deepspeed_config_file if use_deepspeed else ''}\n",
    "#     open_instruct/finetune.py \\\n",
    "#     --model_name_or_path {model_name_or_path} \\\n",
    "#     --tokenizer_name {model_name_or_path} \\\n",
    "#     --train_file {train_file} \\\n",
    "#     --max_seq_length {max_seq_length} \\\n",
    "#     {'--use_lora' if use_lora else ''}\n",
    "#     --lora_rank {lora_rank} \\\n",
    "#     --lora_alpha {lora_alpha} \\\n",
    "#     --lora_dropout {lora_dropout} \\\n",
    "#     --preprocessing_num_workers 16 \\\n",
    "#     --per_device_train_batch_size {batch_size_per_gpu} \\\n",
    "#     --gradient_accumulation_steps {gradient_acc_steps} \\\n",
    "#     --learning_rate 2e-5 \\\n",
    "#     --lr_scheduler_type linear \\\n",
    "#     --warmup_ratio 0.03 \\\n",
    "#     --weight_decay 0. \\\n",
    "#     --num_train_epochs 2 \\\n",
    "#     --output_dir {output_dir} \\\n",
    "#     --with_tracking \\\n",
    "#     --report_to tensorboard \\\n",
    "#     {'--checkpointing_steps '+str(checkpointing_steps) if checkpointing_steps else ''}\n",
    "#     --logging_steps 1\n",
    "# \"\"\"\n",
    "\n",
    "# # things to test to see its effects on (1) eval perf (2) runtime.\n",
    "# #\n",
    "# # - int8\n",
    "# # - mixed_precision bf16 or no\n",
    "# # - with/without LoRA\n",
    "# # - LoRA's rank/alpha (alpha typically set to 2*rank)\n",
    "# # - batch size\n",
    "# # - micro-batch size (largest without running out of memory)\n",
    "\n",
    "\n",
    "# cmd = multiline_to_singleline(cmd)\n",
    "# if test_run:\n",
    "#     print()\n",
    "#     print(cmd)\n",
    "\n",
    "\n",
    "# shell_scripts = shell_scripts_template.format(\n",
    "#     conda_env='open-instruct',\n",
    "#     cwd=os.path.dirname(os.getcwd()),\n",
    "#     cmd=cmd,\n",
    "#     log_dir=os.getcwd(),\n",
    "#     save_dir=output_dir\n",
    "# )\n",
    "# out = submit_job_ccc(\n",
    "#     shell_scripts, \n",
    "#     job_name=job_name, \n",
    "#     queue=queue,\n",
    "#     num_cpus=num_cpus,\n",
    "#     cpu_mem=cpu_mem,\n",
    "#     require=require,\n",
    "#     num_gpus=num_gpus,\n",
    "#     test_run=test_run,\n",
    "# )\n",
    "# if not test_run:\n",
    "#     print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c8b",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune_trainer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d611cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = '00:33:12'\n",
    "n = 15\n",
    "# total = 1515; nnodes = 1\n",
    "# total = 2083; nnodes = 1\n",
    "total = 1587; nnodes = 1\n",
    "# total = 1041; nnodes = 1\n",
    "# total = 4228; nnodes = 1\n",
    "# total = 4512; nnodes = 4\n",
    "# total = 4296; nnodes = 1\n",
    "# total = 2254; nnodes = 2\n",
    "# total = 1128; nnodes = 4\n",
    "# total = 1074; nnodes = 4\n",
    "# total = 1252; nnodes = 4\n",
    "\n",
    "l = [int(x) for x in t.split(':')]\n",
    "t = l[0]*60*60+l[1]*60+l[2]\n",
    "# t = t/60/60 # in hr\n",
    "\n",
    "print(f'{t/n/nnodes:.0f}s/it, {t/n*total/60/60:.1f}hrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51bf7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# how to sample mixture sample size?\n",
    "# \n",
    "# approaches: \n",
    "# (1) want sufficient coverage for #datapoints/dataset, #datasets used, total sample size.\n",
    "#  Use 5k as a unit of data, sample different #unit/dataset, and vary total units of data.\n",
    "# (2) specify a total sample size and a mixture weight. this answers the question, given a \n",
    "#  fixed compute budget, what is the optimal mixture. this seems to be a simpler approach.\n",
    "#\n",
    "# experiments\n",
    "# (1) first use samples from a single dataset for tuning. \n",
    "# (2)\n",
    "# \n",
    "\n",
    "\n",
    "datasets = ['baize', 'code_alpaca', 'cot', 'dolly', 'flan_v2', 'gpt4_alpaca', 'oasst1', 'self_instruct', 'sharegpt', 'stanford_alpaca', 'super_ni', 'unnatural_instructions']\n",
    "total_data_points = 200000\n",
    "\n",
    "subsample_mixture_list = []\n",
    "subsample_mixture_list += [\n",
    "    {k: 100000} for k in datasets if k != 'flan_v2'\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    {k: int(total_data_points/4) for k in ['cot', 'flan_v2', 'dolly', 'oasst1']}\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': 0.48785105, 'flan_v2': 0.48785105, 'dolly': 0.00732313, 'oasst1': 0.01697478}.items())\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    {k: int(total_data_points/len(datasets)) for k in datasets} \n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': .07678, 'flan_v2': .9137, 'dolly': .004471, 'oasst1': .009072}.items())\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': 0.1127, 'flan_v2': 0.8726, 'dolly': 0.01395, 'oasst1': 0.001391}.items())\n",
    "]\n",
    "subsample_mixture_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d47226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up checkpoints `optimizer.bin` to save disk space. \n",
    "# (e.g., 7b model, ~8*7=56GB for storing gradient/momentum in `optimizer.bin`)\n",
    "\n",
    "import glob, os\n",
    "\n",
    "def cleanup_checkpoints(save_dir, test_run=False):\n",
    "\n",
    "    checkpoints = glob.glob(os.path.join(save_dir, 'checkpoint-*'))\n",
    "    checkpoints = sorted(checkpoints, key=lambda x: int(x.split('-')[-1]))\n",
    "    checkpoints = checkpoints[:-1]\n",
    "    \n",
    "    if not checkpoints: return\n",
    "\n",
    "    for ckpt_path in checkpoints:\n",
    "        optimizer_bin_path = os.path.join(ckpt_path, 'optimizer.bin')\n",
    "        if os.path.isfile(optimizer_bin_path):\n",
    "            print(optimizer_bin_path)\n",
    "            if not test_run:\n",
    "                os.remove(optimizer_bin_path)\n",
    "        \n",
    "        \n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "exp_dirs = [\n",
    "    '../results/ft1',\n",
    "    '../results/ft2',\n",
    "    '../results/oi3',\n",
    "    '../results/oi4',\n",
    "    '../results/oi4_perf_cross_time',\n",
    "    '../results/oi4_tulu_v1_human_mix',\n",
    "    '../results/oi4_flanv2_prune_with_hmv1_model',\n",
    "    '../results/oi4_flan_v2_vary_subsetsize',\n",
    "]\n",
    "\n",
    "print('Remove extra files (e.g., optimizer.bin) for non-latest checkpoints:')\n",
    "\n",
    "for exp_dir in exp_dirs:\n",
    "    for run_name in os.listdir(exp_dir):\n",
    "        save_dir = os.path.join(exp_dir, run_name)\n",
    "        if os.path.islink(save_dir): continue\n",
    "        cleanup_checkpoints(save_dir, test_run=test_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19aebd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results/baselines/huggyllama/llama-7b using 6 GPUs, 2 batch size per GPU, 2 gradient accumulation steps, Effective batch size 120\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm:llama-7b\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 512,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=oi5_wizardlm:llama-7b --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmpzbfp8f6u', 'job_id': 1234057}]\n"
     ]
    }
   ],
   "source": [
    "def compute_mixture_num_samples(mixture, max_train_samples):\n",
    "    s = sum(mixture.values())\n",
    "    mixture = {k: int(max_train_samples*v/s) for k, v in mixture.items()}\n",
    "    return mixture\n",
    "\n",
    "add_hardwarespec_to_dirname = False\n",
    "num_cpus = 144 if arch == 'ppc64le' else 32\n",
    "cpu_mem =  512 if arch == 'ppc64le' else 64\n",
    "\n",
    "\n",
    "save_strategy = 'steps'\n",
    "save_steps = 100\n",
    "save_total_limit = 1\n",
    "preprocessing_num_workers = 32\n",
    "evaluation_strategy = 'no' # set do_eval=False\n",
    "eval_steps = save_steps\n",
    "\n",
    "\n",
    "dataloader_sampler = None\n",
    "hf_models_dir = 'results/baselines/'\n",
    "# model_name_or_path = 'results/baselines/gpt2-medium'; abbr_model_name = 'gpt2m'; max_seq_length = 1024\n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = 'results/baselines/NousResearch/Llama-2-7b-hf'; abbr_model_name = 'llama2-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = 'mosaicml/mpt-7b'; abbr_model_name = 'mpt-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-1.4b'; abbr_model_name = 'pythia-1.4b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-2.8b'; abbr_model_name = 'pythia-2.8b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-6.9b'; abbr_model_name = 'pythia-6.9b'; max_seq_length = 2048\n",
    "\n",
    "\n",
    "\n",
    "subsample_mixture_list = []\n",
    "# subsample_mixture_list += [\n",
    "#     {k: max_train_samples} for k in datasets\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     {k: int(max_train_samples/4) for k in ['cot', 'flan_v2', 'dolly', 'oasst1']}\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     ('humanmix', dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {'cot': 0.48785105, 'flan_v2': 0.48785105, 'dolly': 0.00732313, 'oasst1': 0.01697478}.items()))\n",
    "# ] # humanmix mixture.\n",
    "# subsample_mixture_list += [\n",
    "#     {k: int(max_train_samples/len(datasets)) for k in datasets} \n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {'cot': .07678, 'flan_v2': .9137, 'dolly': .004471, 'oasst1': .009072}.items())\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {'cot': 0.1127, 'flan_v2': 0.8726, 'dolly': 0.01395, 'oasst1': 0.001391}.items())\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {'cot':  0.13568177819252014, 'flan_v2': 0.3957784175872803, \n",
    "#      'dolly': 0.05964866653084755, 'oasst1': 0.4088916480541229}.items())\n",
    "# ] # gpt2-medium_humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {\"cot\": 0.360595703125, \"dolly\": 0.0021991729736328125, \"flan_v2\": 0.63037109375, \"oasst1\": 0.0016956329345703125}.items())\n",
    "# ] # pythia-1.4b humanmix_uniform:200k_doremiv1.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {\"cot\": 0.2254638671875, \"dolly\": 0.01409149169921875, \"flan_v2\": 0.1739501953125, \"oasst1\": 0.59423828125}.items())\n",
    "# ] # pythia-1.4b humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {\"cot\": 0.08563232421875, \"dolly\": 0.54296875, \"flan_v2\": 0.347900390625, \"oasst1\": 0.0103302001953125}.items())\n",
    "# ] # llama-7b_humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {\"cot\": 0.0316162109375, \"dolly\": 0.204833984375, \"flan_v2\": 0.40966796875, \"oasst1\": 0.40966796875}.items()\n",
    "#         )] # llama-7b_humanmix_uniform:600k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_normalized_list = []\n",
    "# subsample_mixture_normalized_list += [('uniform:1200k_doremiv2', # llama-7b_humanmix_uniform:1200k_doremiv2.json\n",
    "#                                        {\"cot\": 0.11419677734375, \"dolly\": 0.1024169921875, \"flan_v2\": 0.204833984375, \"oasst1\": 0.204833984375})]\n",
    "## 10 for trying out datamodels\n",
    "# mixes = [{'cot': 0.37664033529374275,\n",
    "#   'dolly': 0.0874640765523398,\n",
    "#   'flan_v2': 0.39740799933549775,\n",
    "#   'oasst1': 0.1384875888184196},\n",
    "#  {'cot': 0.23064419241874784,\n",
    "#   'dolly': 0.04693354147889885,\n",
    "#   'flan_v2': 0.72121745986295,\n",
    "#   'oasst1': 0.0012048062394032465},\n",
    "#  {'cot': 0.11244721555034376,\n",
    "#   'dolly': 0.21997027355988638,\n",
    "#   'flan_v2': 0.5826671754210359,\n",
    "#   'oasst1': 0.08491533546873392},\n",
    "#  {'cot': 0.27704626812045546,\n",
    "#   'dolly': 0.5712282144637615,\n",
    "#   'flan_v2': 0.024940119654536592,\n",
    "#   'oasst1': 0.12678539776124645},\n",
    "#  {'cot': 0.0024519793352964607,\n",
    "#   'dolly': 0.13274603201304974,\n",
    "#   'flan_v2': 0.012268378167304219,\n",
    "#   'oasst1': 0.8525336104843496},\n",
    "#  {'cot': 0.08065633865016615,\n",
    "#   'dolly': 0.41886215168938545,\n",
    "#   'flan_v2': 0.21723932820070485,\n",
    "#   'oasst1': 0.2832421814597436},\n",
    "#  {'cot': 0.13878643021160036,\n",
    "#   'dolly': 0.05686171157146557,\n",
    "#   'flan_v2': 0.6701353469446995,\n",
    "#   'oasst1': 0.13421651127223455},\n",
    "#  {'cot': 0.2461125374866837,\n",
    "#   'dolly': 0.09774240280444893,\n",
    "#   'flan_v2': 0.13974091986040005,\n",
    "#   'oasst1': 0.5164041398484672},\n",
    "#  {'cot': 0.4069781049152398,\n",
    "#   'dolly': 0.06318759506033228,\n",
    "#   'flan_v2': 0.09504719644992135,\n",
    "#   'oasst1': 0.4347871035745066},\n",
    "#  {'cot': 0.22379693013848484,\n",
    "#   'dolly': 0.30565901275011814,\n",
    "#   'flan_v2': 0.15457716965000887,\n",
    "#   'oasst1': 0.31596688746138824}]\n",
    "\n",
    "# mixes = [\n",
    "#     {'cot': 0.46638974, 'dolly': 0.01456044, 'flan_v2': 0.50886009, 'oasst1': 0.01018973},\n",
    "#     {'cot': 0.39744481, 'dolly': 0.00472114, 'flan_v2': 0.59104177, 'oasst1': 0.00679229},\n",
    "# ]\n",
    "\n",
    "# subsample_mixture_normalized_list += [('', d) for d in mixes]\n",
    "# subsample_mixture_normalized_list += [('humanmix', # humanmix\n",
    "#                                        {'cot': 0.48785105, 'dolly': 0.00732313, 'flan_v2': 0.48785105, 'oasst1': 0.01697478})]\n",
    "# subsample_mixture_normalized_list = [(x[0],  compute_mixture_num_samples(x[1], max_train_samples)) \n",
    "#                                      for x in subsample_mixture_normalized_list]\n",
    "# subsample_mixture_list += subsample_mixture_normalized_list\n",
    "\n",
    "\n",
    "subsample_mixture_list = [('',None)]\n",
    "subsample_inds_file_list = [None]\n",
    "\n",
    "\n",
    "train_file = 'data/processed/all.jsonl'; abbr_train_file = 'all'\n",
    "\n",
    "\n",
    "\n",
    "max_train_samples_list = [None]\n",
    "num_train_epochs_list = [1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def subsample_inds_file_abbr_fn(x):\n",
    "    s = os.path.basename(x).split('.pkl')[0]\n",
    "    if s.startswith('inds_'):\n",
    "        scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "        pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "        return f'score={scoring_fn}_pace={pacing_fn}'\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "# ##  ft1: reproduce open-instruct table with llama7b\n",
    "# # job_name = 'ft1'; num_train_epochs_list = [2]\n",
    "# # job_name = 'ft1_ep=1'; num_train_epochs_list = [1] # train for 1 epoch (baseline for comparison.)\n",
    "# # job_name = 'ft1_ep=2'; num_train_epochs_list = [2]\n",
    "# job_name = 'oi2'; num_train_epochs_list = [2] # 5, 10\n",
    "# model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# train_file = 'data/processed/wizardlm/wizardlm_data.jsonl'; abbr_train_file = 'wizardlm'\n",
    "\n",
    "# train_file = 'data/processed/lima/lima_data.jsonl'; abbr_train_file = 'lima'\n",
    "# train_file = 'data/processed/cot/cot_data.jsonl'; abbr_train_file = 'cot'\n",
    "# train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2'\n",
    "# # # train_file = 'data/processed/wpq/cot_flanv2_data.jsonl'; abbr_train_file = 'cot:flanv2'\n",
    "# # # train_file = 'data/processed/tulu/tulu_v1_human_mix.jsonl'; abbr_train_file = 'hmv1'\n",
    "# train_file = 'data/processed/tulu/tulu_v1_mix.jsonl'; abbr_train_file = 'tuluv1m'\n",
    "# train_file = 'data/processed/sharegpt/sharegpt_data.jsonl'; abbr_train_file = 'sharegpt'\n",
    "\n",
    "\n",
    "\n",
    "# model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048\n",
    "# train_file = 'data/processed/ultrachat/ultrachat200k_train_data.jsonl'; abbr_train_file = 'ultrachat200k'\n",
    "# train_file = 'data/processed/lima/lima_data.jsonl'; abbr_train_file = 'lima'\n",
    "\n",
    "# # max_train_samples_list = [120]; save_steps = 1; save_total_limit = 100\n",
    "\n",
    "\n",
    "\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly'\n",
    "# # train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1'\n",
    "# # train_file = 'data/processed/super_ni/super_ni_data.jsonl'; abbr_train_file = 'super_ni'\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca'\n",
    "# # train_file = 'data/processed/baize/baize_data.jsonl'; abbr_train_file = 'baize'\n",
    "# # train_file = 'data/processed/self_instruct/self_instruct_data.jsonl'; abbr_train_file = 'self_instruct'\n",
    "# # train_file = 'data/processed/code_alpaca/code_alpaca_data.jsonl'; abbr_train_file = 'code_alpaca'\n",
    "# # train_file = 'data/processed/unnatural_instructions/unnatural_instructions_data.jsonl'; abbr_train_file = 'unnatural_instructions'\n",
    "# # train_file = 'data/processed/gpt4_alpaca/gpt4_alpaca_data.jsonl'; abbr_train_file = 'gpt4_alpaca'\n",
    "\n",
    "\n",
    "# # ft2: test mixture weights\n",
    "# # vary mixture weights\n",
    "# job_name = 'ft2'\n",
    "\n",
    "# # oi3: instruction tuning performance w.r.t. steps.\n",
    "# job_name = 'oi3'\n",
    "\n",
    "# # oi4: data pruning \n",
    "# job_name = 'oi4_flan_v2_vary_subsetsize'\n",
    "# train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2'\n",
    "# subsample_mixture_list = [('',None)]\n",
    "# max_train_samples_list = [int(pct*100000) for pct in [.1, .3, .5]]; num_train_epochs_list = [2]\n",
    "# data_inds_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b/flan_v2/'\n",
    "# subsample_inds_file_list = [\n",
    "# #     os.path.join(data_inds_dir, 'random.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'prob_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'prob_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_k=Kcos.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_k=Kcosp.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_k=Kcos1np.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeanscd_nc=3000_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeanscd_nc=3000_decr.pkl'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# # oi4_perf_cross_time: perf cross time on flan_v2\n",
    "# job_name = 'oi4_perf_cross_time'\n",
    "# save_steps = 50; save_total_limit = 200\n",
    "# train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2'\n",
    "# subsample_mixture_list = [('',None)]\n",
    "# max_train_samples_list = [int(pct*100000) for pct in [.3]]; num_train_epochs_list = [3]\n",
    "# data_inds_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b/flan_v2/'\n",
    "# subsample_inds_file_list = [\n",
    "#     os.path.join(data_inds_dir, 'random.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=300_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=300_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=1000_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=1000_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'prob_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'prob_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'dppmap_k=Kcos.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'dppmap_k=Kcosp.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'dppmap_k=Kcos1np.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'el2n_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'el2n_decr.pkl'),\n",
    "# ]\n",
    "\n",
    "# # ## oi4_flanv2_prune_with_hmv1_model\n",
    "# job_name = 'oi4_flanv2_prune_with_hmv1_model'\n",
    "# save_steps = 50; save_total_limit = 200\n",
    "# train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2'\n",
    "# subsample_mixture_list = [('',None)]\n",
    "# max_train_samples_list = [int(pct*100000) for pct in [.3]]; num_train_epochs_list = [3]\n",
    "# data_inds_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b_ft=hmv1/flan_v2/'\n",
    "# subsample_inds_file_list = [\n",
    "# #     os.path.join(data_inds_dir, 'random.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'prob_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'prob_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_k=Kcos.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_k=Kcosp.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'el2n_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'el2n_decr.pkl'),\n",
    "# ]\n",
    "\n",
    "# ## tulu mix v1.\n",
    "# dataset = 'tulu_v1_human_mix'; train_file = 'data/processed/tulu/tulu_v1_human_mix.jsonl'; abbr_train_file = 'tuluv1hm'\n",
    "# job_name = f'oi4_{dataset}'\n",
    "# save_steps = 50; save_total_limit = 200\n",
    "# subsample_mixture_list = [('',None)]\n",
    "# max_train_samples_list = [30000]; num_train_epochs_list = [3]\n",
    "# data_inds_dir = f'/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b/{dataset}/'\n",
    "# subsample_inds_file_list = [\n",
    "#     os.path.join(data_inds_dir, 'random.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'prob_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'prob_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'dppmap_k=Kcos.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'dppmap_k=Kcosp.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'dppmap_k=Kcos1np.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_incr.pkl'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# ## \n",
    "# dataset = 'flan2022_1m'; train_file = 'data/processed/flan2022/flan2022_1m_data.jsonl'; abbr_train_file = 'flan2022_1m'\n",
    "# job_name = f'oi4_{dataset}'\n",
    "# save_steps = 50; save_total_limit = 200\n",
    "# subsample_mixture_list = [('',None)]\n",
    "# data_inds_dir = f'/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b+lora:r=256:a=256/{dataset}/'\n",
    "# ## full data\n",
    "# # max_train_samples_list = [1000000]; num_train_epochs_list = [1]\n",
    "# # subsample_inds_file_list = ['']\n",
    "# # subset\n",
    "# max_train_samples_list = [200000]; num_train_epochs_list = [1]\n",
    "# subsample_inds_file_list = [\n",
    "# #     os.path.join(data_inds_dir, 'random.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'prob_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeanscd_nc=3000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeanscd_nc=3000_decr.pkl'),\n",
    "#     # not that helpful\n",
    "# #     os.path.join(data_inds_dir, 'prob_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_decr.pkl'),\n",
    "#     ## gradnorm outputs\n",
    "# #     os.path.join(data_inds_dir, 'el2n_agg=mean_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_agg=l2n_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_agg=l2n_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'logit_margin_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'logit_margin_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'grad_loraB_l2n_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'grad_loraB_l2n_decr.pkl'),  \n",
    "#     ## random baselines.\n",
    "# #     os.path.join(data_inds_dir, 'random_s=0.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'random_s=1.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'random_s=2.pkl'),\n",
    "#     ## kmeans on grads\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=1000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=1000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=3000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=3000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=6000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=6000_incr.pkl'),\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# ## \n",
    "# dataset = 'tulu_v1_mix'; train_file = 'data/processed/tulu/tulu_v1_mix.jsonl'; abbr_train_file = 'tuluv1m'\n",
    "# # job_name = f'oi4_{dataset}_ep=3'\n",
    "# job_name = f'oi5_tulu_v1_mix:llama-7b' # re-run to see if transformers upgrade altered eval performance.\n",
    "# # save_steps = 50; save_total_limit = 200\n",
    "# subsample_mixture_list = [('',None)]\n",
    "# data_inds_dir = f'/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b+lora:r=256:a=256/{dataset}/'\n",
    "# max_train_samples_list = [50000]; num_train_epochs_list = [3]\n",
    "# subsample_inds_file_list = [\n",
    "#     # random baselines\n",
    "# #     os.path.join(data_inds_dir, 'random_s=0.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'random_s=1.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'random_s=2.pkl'),\n",
    "# #     # correlated statistics\n",
    "# #     os.path.join(data_inds_dir, 'log_prob_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'log_prob_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'logit_margin_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'logit_margin_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_agg=mean_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_agg=mean_decr.pkl'),\n",
    "# #     # grad norm\n",
    "# #     os.path.join(data_inds_dir, 'grad_loraB_l2n_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'grad_loraB_l2n_decr.pkl'),  \n",
    "# #     # kmeans\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=1000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=1000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=text+embedding_nc=1000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=text+embedding_nc=1000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=3000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=3000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=text+embedding_nc=3000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=text+embedding_nc=3000_decr.pkl'),\n",
    "# # #     # kcos only 50k data\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_emb=grad+rp+loraB_k=Kcos.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_emb=text+embedding_k=Kcos.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_emb=grad+rp+loraB_k=Kcos1np.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_emb=text+embedding_k=Kcos1np.pkl'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# oi5: try curriculum learning / pruning\n",
    "\n",
    "scoring_fn_and_pacing_fn = []\n",
    "\n",
    "# ###### 150k(ep=3) baselines on various baselines\n",
    "# model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# # M = 150_000; dataset = 'tulu_v1_mix'; train_file = 'data/processed/tulu/tulu_v1_mix.jsonl'; abbr_train_file = 'tuluv1m'\n",
    "# M = 50_000; dataset = 'tulu_v1_mix'; train_file = 'data/processed/tulu/tulu_v1_mix.jsonl'; abbr_train_file = 'tuluv1m'; pacing_fn_list = [f'prune_size={M}_ep=5'] \n",
    "\n",
    "\n",
    "# # M = 150_000; dataset = 'wizardlm'; train_file = 'data/processed/wizardlm/wizardlm_data.jsonl'; abbr_train_file = 'wizardlm'\n",
    "# # M = 150_000; dataset = 'sharegpt'; train_file = 'data/processed/sharegpt/sharegpt_data.jsonl'; abbr_train_file = 'sharegpt'\n",
    "# # M = 150_000; dataset = 'ultrachat200k'; train_file = 'data/processed/ultrachat/ultrachat200k_train_data.jsonl'; abbr_train_file = 'ultrachat200k'\n",
    "\n",
    "# scoring_fn_list = []\n",
    "# # scoring_fn_list += ['random_s=0', 'random_s=1']\n",
    "# # scoring_fn_list += ['dppmap_k=vmf_gamma=0.0315_kmd=mpnet']\n",
    "# scoring_fn_list = ['log_pmi_neg', 'ifd_neg']\n",
    "# # pacing_fn_list = [\n",
    "# # #     f'prune_size={M}_ep=3',\n",
    "# #     f'singlestep_size={M}_startingfrac=0.05',\n",
    "# # #     f'singlestep_size={M}_startingfrac=0.1',\n",
    "# # #     f'singlestep_size={M}_startingfrac=0.2',\n",
    "# #     f'fep_size={M}_nsteps=5_startingfrac=0.05_inc=1.5',\n",
    "# # ]\n",
    "# scoring_fn_and_pacing_fn += list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "# ######\n",
    "\n",
    "# ##### codellama on starcoder. 5k subset ep=5\n",
    "# model_name_or_path = hf_models_dir+'codellama/CodeLlama-7b-hf'; abbr_model_name = 'codellama-7b'; max_seq_length = 2048\n",
    "# # M = 25_000; dataset='starcoder_commentinstr'; train_file = 'data/processed/starcoder/starcoder_commentinstr.jsonl'; abbr_train_file = 'starcodercmtinstr'; pacing_fn_list = [f'prune_size={M}_ep=5'] \n",
    "# # M = 25_000; dataset='starcoder_commentinstr_cleaned'; train_file = 'data/processed/starcoder/starcoder_commentinstr_cleaned.jsonl'; abbr_train_file = 'starcodercmtinstrcleaned'; pacing_fn_list = [f'prune_size={M}_ep=5'] \n",
    "# M = 50_000; dataset='starcoder_commentinstrv2'; train_file = 'data/processed/starcoder/starcoder_commentinstrv2.jsonl'; abbr_train_file = 'starcodercmtinstrv2'; pacing_fn_list = [f'prune_size={M}_ep=5'] \n",
    "# scoring_fn_list = []\n",
    "# # scoring_fn_list += ['log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n', 'ifd', 'idf_neg', 'log_pmi', ]\n",
    "# # scoring_fn_list += ['log_pmi_neg']\n",
    "# # scoring_fn_list += ['random_s=0', 'random_s=1']\n",
    "# scoring_fn_list += ['dedup_md=mpnet_emb=text+embedding']\n",
    "# scoring_fn_list += ['dppmap_k=vmf_gamma=0.038_kmd=mpnet']\n",
    "# scoring_fn_and_pacing_fn += list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "# #####\n",
    "\n",
    "##### \n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# M = 150_000; dataset = 'tulu_v1_mix'; train_file = 'data/processed/tulu/tulu_v1_mix.jsonl'; abbr_train_file = 'tuluv1m'; pacing_fn_list = [f'prune_size={M}_ep=3']\n",
    "# M = 200_000; dataset = 'wizardlm'; train_file = 'data/processed/wizardlm/wizardlm_data.jsonl'; abbr_train_file = 'wizardlm'; pacing_fn_list = [f'prune_size={M}_ep=2']\n",
    "# M = 100_000; dataset = 'wizardlm'; train_file = 'data/processed/wizardlm/wizardlm_data.jsonl'; abbr_train_file = 'wizardlm'; pacing_fn_list = [f'prune_size={M}_ep=2'] # 6hr gpu ok.\n",
    "# M = 50_000; dataset = 'wizardlm'; train_file = 'data/processed/wizardlm/wizardlm_data.jsonl'; abbr_train_file = 'wizardlm'; pacing_fn_list = [f'prune_size={M}_ep=5'] # 6hr gpu ok.\n",
    "M = 10_000; dataset = 'wizardlm'; train_file = 'data/processed/wizardlm/wizardlm_data.jsonl'; abbr_train_file = 'wizardlm'; pacing_fn_list = [f'prune_size={M}_ep=10'] # 6hr gpu ok.\n",
    "\n",
    "\n",
    "scoring_fn_list = []\n",
    "# scoring_fn_list += ['log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n'] # 'numtoks_input_neg'\n",
    "# scoring_fn_list += ['ifd', 'ifd_neg', 'log_pmi', 'log_pmi_neg']\n",
    "# scoring_fn_list += ['dedup_md=mpnet_emb=text+embedding']\n",
    "# scoring_fn_list += ['semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=200',\n",
    "# #                     'semdedup_cl=kmeansfaisscd_md=bge_dist=cd_emb=text+embedding_nc=200'\n",
    "#                    ]\n",
    "# scoring_fn_list = ['semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=200',\n",
    "#                    'semdedup_cl=kmeansfaisscd_md=bge_dist=cd_emb=text+embedding_nc=200',\n",
    "#                    'semdedup_cl=kmeansfaisscd_md=llama7b_dist=cd_emb=text+embedding_nc=200',\n",
    "#                    'semdedup_cl=kmeansfaisscd_md=llama7b_dist=cd_emb=grad+rp+loraB_nc=200',]\n",
    "# scoring_fn_list += [\n",
    "#     'random_s=0',\n",
    "#     'random_s=1',\n",
    "# ]\n",
    "scoring_fn_list = [ \n",
    "    # ->1k\n",
    "#     'dppmap:k=lin:kmd=mpnet',\n",
    "    'dppmap_k=vmf_gamma=auto1000_kmd=bge'\n",
    "#     'dppmap_k=vmf_gamma=0.008_kmd=mpnet',\n",
    "#     'dppmap_theta=0.5_k=vmf_gamma=0.01_kmd=mpnet_q=log+pmi_qmd=llama7b',\n",
    "#     'dppmap_theta=0.3_k=vmf_gamma=0.01_kmd=mpnet_q=log+pmi_qmd=llama7b',\n",
    "#     'dppmap_k=rbf_gamma=0.0000007_kmd=llama7b_kemb=grad+rp+loraB',\n",
    "#     'dppmap_k=rbf_gamma=3.5e-8_kmd=llama7b_kemb=text+embedding',\n",
    "#     'dppmap_k=vmf_gamma=auto1000_kmd=llama7b_kemb=text+embedding',\n",
    "#     'dppmap_k=vmf_gamma=auto1000_kmd=llama7b_kemb=grad+rp+loraB',\n",
    "    # ->10k\n",
    "#     'dppmap_k=vmf_gamma=auto10000_kmd=bge'\n",
    "#     'dppmap_theta=0.5_k=vmf_gamma=0.043_kmd=mpnet_q=log+pmi_qmd=llama7b',\n",
    "#     'dppmap_theta=0.7_k=vmf_gamma=0.043_kmd=mpnet_q=log+pmi_qmd=llama7b',\n",
    "#     'dppmap_theta=0.3_k=vmf_gamma=0.04_kmd=mpnet_q=ifd_qmd=llama7b',\n",
    "#     'dppmap_theta=0.3_k=vmf_gamma=0.043_kmd=mpnet_q=ifd+neg_qmd=llama7b',\n",
    "#     'dppmap_k=rbf_gamma=7.5e-06_kmd=llama7b_kemb=text+embedding',\n",
    "#     'dppmap_k=rbf_gamma=0.001_kmd=llama7b_kemb=grad+rp+loraB',\n",
    "#     'dppmap_k=vmf_gamma=auto10000_kmd=llama7b_kemb=text+embedding',\n",
    "#     'dppmap_k=vmf_gamma=auto10000_kmd=llama7b_kemb=grad+rp+loraB',\n",
    "#     'dppmap_theta=0.3_k=rbf_gamma=auto10000_kmd=llama7b_kemb=text+embedding_q=log+pmi_qmd=llama7b',\n",
    "#     'dppmap_theta=0.5_k=rbf_gamma=auto10000_kmd=llama7b_kemb=text+embedding_q=log+pmi_qmd=llama7b',\n",
    "]\n",
    "                        \n",
    "## ifd & quality kernel as ifd\n",
    "# scoring_fn_list = [\n",
    "#     'ifd',\n",
    "#     'ifd_neg',\n",
    "#     'dppmapbd_nc=200_theta=0.3_k=lin_kmd=mpnet_q=ifd_qmd=llama7b+lima',\n",
    "#     'dppmapbd_nc=200_theta=0.6_k=lin_kmd=mpnet_q=ifd_qmd=llama7b+lima',\n",
    "#     'dppmapbd_nc=200_theta=0.3_k=lin_kmd=mpnet_q=prob_qmd=mistral7b+lima',\n",
    "#     'dppmapbd_nc=200_theta=0.6_k=lin_kmd=mpnet_q=prob_qmd=mistral7b+lima',\n",
    "# ]\n",
    "scoring_fn_and_pacing_fn += list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "####\n",
    "\n",
    "\n",
    "# ### mistral-7b on ultrachat15/200k\n",
    "# model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048\n",
    "# # M =  50_000; dataset = 'ultrachat200k'; train_file = 'data/processed/ultrachat/ultrachat200k_train_data.jsonl'; abbr_train_file = 'ultrachat200k'\n",
    "# M = 100_000; dataset = 'ultrachat15';   train_file = 'data/processed/ultrachat/ultrachat15_data.jsonl'; abbr_train_file = 'ultrachat15'; preprocessing_num_workers = 64\n",
    "# # M = 400_000; dataset = 'ultrachat15';   train_file = 'data/processed/ultrachat/ultrachat15_data.jsonl'; abbr_train_file = 'ultrachat15'; preprocessing_num_workers = 64\n",
    "\n",
    "# # scoring_fn_list = ['log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n', 'el2n_agg=mean']\n",
    "# # scoring_fn_list = ['numtoks_input_neg']\n",
    "# # scoring_fn_list = ['log_prob_neg', 'el2n_agg=mean', 'logit_margin_neg', 'grad_loraB_l2n',] #  'kmeansl2_emb=text+embedding_nc=3000_incr'\n",
    "# # scoring_fn_list = ['rhov1_log_prob', 'rhov1_log_prob_neg']\n",
    "# # scoring_fn_list = ['numtoks_input_neg', 'numtoks_output_neg', 'numtoks_total_neg']\n",
    "# # scoring_fn_list = [\n",
    "# #     'semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=200',\n",
    "# #                    'semdedup_cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text+embedding_nc=200',\n",
    "# #                    'semdedup_cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=grad+rp+loraB_nc=200',\n",
    "# #                   ]\n",
    "# # scoring_fn_list = ['dppmapbd_nc=200_k=lin_kmd=mpnet']\n",
    "# # scoring_fn_list =[f'dppmapbd_nc=200_k=vmf_gamma={gamma}_kmd=mpnet' for gamma in [.3, 3.]]\n",
    "# # scoring_fn_list = ['dppmapbd_nc=200_k=vmf_gamma=0.000035_kmd=mpnet']\n",
    "# scoring_fn_list = ['dppmapbd_nc=200_k=vmf_gamma=1.0_kmd=mpnet'] \n",
    "# pacing_fn_list = [f'prune_size={M}_ep=2']\n",
    "# scoring_fn_and_pacing_fn += list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "# ##### \n",
    "\n",
    "evaluation_strategy = 'steps' if 'ultrachat' in dataset else 'no'\n",
    "job_name = f'oi5_{dataset}:{abbr_model_name}'\n",
    "num_train_epochs_list = [1] # offload handling of epochs to `generate_curriculum`\n",
    "dataloader_sampler = 'SequentialSampler'\n",
    "\n",
    "## random baselines # 'random_s=0', 'random_s=1'\n",
    "# scoring_fn_list = ['random_s=0']; pacing_fn_list = [f'prune_size={M}_ep=2']\n",
    "# scoring_fn_and_pacing_fn += list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "subsample_inds_file_list = []\n",
    "for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "    if 'semdedup' in scoring_fn or 'dppmap' in scoring_fn or 'dedup' in scoring_fn:\n",
    "        if 'md=mpnet' in scoring_fn: md = 'all-mpnet-base-v2'\n",
    "        elif 'md=bge' in scoring_fn: md = 'bge-large-en-v1.5'\n",
    "        elif 'md=llama7b' in scoring_fn: md = 'llama-7b+lora:r=256:a=256'\n",
    "        elif 'md=mistral7b' in scoring_fn: md = 'mistral-7b+lora:r=256:a=256'\n",
    "        else: raise ValueError(f'md not found in {scoring_fn}')\n",
    "        data_inds_dir = (f'/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/curriculum/{md}/{dataset}/')\n",
    "    else:\n",
    "        data_inds_dir = (f'/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/curriculum/'\n",
    "                         f'{abbr_model_name}+lora:r=256:a=256/{dataset}/')\n",
    "    p = os.path.join(data_inds_dir, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "    if not os.path.isfile(p):\n",
    "        raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "    subsample_inds_file_list.append(p)\n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "# ##### code instruction tuning\n",
    "# model_name_or_path = hf_models_dir+'codellama/CodeLlama-7b-hf'; abbr_model_name = 'codellama-7b'; max_seq_length = 2048\n",
    "\n",
    "# job_name = 'oi6_starcoder_ep=5'; # 5k train for 5 epochs\n",
    "# num_train_epochs_list = [5]\n",
    "# # train_file = 'data/processed/starcoder/starcoder_commentinstr.jsonl'; abbr_train_file = 'starcodercmtinstr'\n",
    "# # train_file = 'data/processed/starcoder/starcoder_commentinstr_cleaned.jsonl'; abbr_train_file = 'starcodercmtinstrcleaned'\n",
    "# train_file = 'data/processed/starcoder/starcoder_commentinstrv2.jsonl'; abbr_train_file = 'starcodercmtinstrv2'; max_train_samples_list=[5000]\n",
    "# # train_file = 'data/processed/starcoder/starcoder_commentinstrv2_flppl.jsonl'; abbr_train_file = 'starcodercmtinstrv2_flppl'; max_train_samples_list=[5000]\n",
    "\n",
    "# # job_name = 'oi2'; \n",
    "# # num_train_epochs_list = [2]\n",
    "# # train_file = 'data/processed/starcoder/starcoder_commentinstrv2.jsonl'; abbr_train_file = 'starcodercmtinstrv2'\n",
    "# ##### \n",
    "\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "debug_mode = test_run\n",
    "\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12 # llama-7b on 100k. data\n",
    "nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6 # llama-7b on 100k. data\n",
    "# nodes = 10; num_gpus = 6; gpu_type = 'v100'; job_duration = 36 # llama-7b on 100k. data\n",
    "\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 18 # llama-7b on 400k data\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 30 # llama-7b on 600k data\n",
    "\n",
    "# nodes = 1; num_gpus = 1; gpu_type = 'v100'; job_duration = 6  # gpt2\n",
    "# nodes = 2; num_gpus = 6; gpu_type = 'v100'; job_duration = 6  # pythia-1.4b\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6  # pythia-2.8b|6.9b\n",
    "\n",
    "\n",
    "overwrite_output_dir = True if test_run else False # always continue from ckpt if run from cluster.\n",
    "\n",
    "\n",
    "per_device_train_batch_size = 2; total_batch_size = 128 # 128\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "\n",
    "optimizer = 'adamw_hf' # 'adafactor'\n",
    "\n",
    "deepspeed = ''; fsdp = False if num_gpus == 1 else \"full_shard auto_wrap\"  # full_shard, shard_grad_op\n",
    "if 'gpt2' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPT2Block'\n",
    "elif 'llama' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'LlamaDecoderLayer'\n",
    "elif 'mpt' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MPTBlock'\n",
    "elif 'pythia' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPTNeoXLayer'        \n",
    "elif 'mistral' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MistralDecoderLayer'\n",
    "else: raise ValueError('Not sure how to set `fsdp_transformer_layer_cls_to_wrap`')\n",
    "    \n",
    "# deepspeed = './ds_configs/ds_zero3_cpu_offload.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/ds_zero3.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/stage3_no_offloading.conf'; fsdp = False # error with loading... something wrong with the config.\n",
    "\n",
    "# fsdp = False; deepspeed = False\n",
    "\n",
    "if fsdp and deepspeed:\n",
    "    raise ValueError('either fsdp or deepspeed, not both')\n",
    "\n",
    "use_lora = False\n",
    "lora_rank = 256 # test {8, 16, 32, 128} # just [128, 8] for now.\n",
    "lora_alpha = lora_rank \n",
    "lora_dropout = 0.05\n",
    "if use_lora:\n",
    "    abbr_model_name += f'+lora(r={lora_rank},a={lora_alpha})'\n",
    "\n",
    "mixed_precision = 'bf16' if arch == 'x86_64' else 'fp16' # mixed_precision = ''\n",
    "torch_dtype = 'bfloat16' if arch=='x86_64' else 'float16'; torch_dtype = 'float32'\n",
    "\n",
    "gradient_checkpointing = True\n",
    "load_in_8bit = False\n",
    "\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"Effective batch size {effective_batch_size}\")\n",
    "\n",
    "\n",
    "if nodes == 1:\n",
    "    exe = 'python' if num_gpus==1 else \\\n",
    "        f\"torchrun --nproc_per_node={num_gpus} --master_port=10002\"\n",
    "else:\n",
    "    exe = f\"torchrun --nnodes={nodes} --nproc_per_node={num_gpus} --rdzv-id=$SLURM_JOB_ID --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT\"\n",
    "\n",
    "if test_run:\n",
    "    exe = f\"CUDA_VISIBLE_DEVICES={','.join(map(str, range(num_gpus)))} {exe}\"\n",
    "if test_run and debug_mode:\n",
    "    exe = 'TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO ' + exe\n",
    "    error_file='/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/error_file'\n",
    "    exe = f'TORCHELASTIC_ERROR_FILE={error_file} {exe}'\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    num_train_epochs_list,\n",
    "    subsample_mixture_list,\n",
    "    subsample_inds_file_list,\n",
    "    max_train_samples_list,\n",
    ")\n",
    "\n",
    "output_dirname_list = []\n",
    "for (num_train_epochs,\n",
    "     mix_name_and_subsample_mixture,\n",
    "     subsample_inds_file,\n",
    "     max_train_samples,) in options_list:\n",
    "    mix_name, subsample_mixture = mix_name_and_subsample_mixture\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{abbr_train_file}\"\n",
    "    if max_train_samples:\n",
    "        output_dirname += f\":{int(max_train_samples/1000)}k\"\n",
    "        \n",
    "    if job_name == 'ft2':\n",
    "        if subsample_mixture is not None:\n",
    "            assert(abbr_train_file=='all')\n",
    "            output_dirname += \\\n",
    "                '_mix='+','.join(f'{k}:{v}' for k,v in subsample_mixture.items())\n",
    "            \n",
    "    if any(job_name == y for y in ['oi2']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "            \n",
    "    if job_name == 'oi3':\n",
    "        output_dirname += '_'+mix_name\n",
    "        \n",
    "#     if job_name.startswith('oi4'):\n",
    "    if subsample_inds_file:\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "\n",
    "            \n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "            \n",
    "    # if not test_run:\n",
    "    #     output_dirname += \\\n",
    "    #         '_ep='+str(num_train_epochs)\n",
    "    if add_hardwarespec_to_dirname:\n",
    "        output_dirname += \\\n",
    "            ('_fsdp='+fsdp.split(' ')[0] if fsdp else '')+\\\n",
    "            ('_deepspeed='+os.path.basename(deepspeed).split('.')[0] if deepspeed else '')+\\\n",
    "            ('_gradckpt='+str(gradient_checkpointing) if gradient_checkpointing else '')+\\\n",
    "            '_mbsz='+str(per_device_train_batch_size)+\\\n",
    "            '_dtype='+torch_dtype+\\\n",
    "            ('_mp='+str(mixed_precision) if mixed_precision else '_mp=none')+\\\n",
    "            '_seqlen='+str(max_seq_length)+\\\n",
    "            '_nodes='+str(nodes)\n",
    "    output_dir = os.path.join('results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join('results', job_name), exist_ok=True)\n",
    "    wandb_run_name = output_dir.replace('results/', '')\n",
    "    \n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {'!cd .. && ' if test_run else ''}{exe}\n",
    "        open_instruct/finetune_trainer.py \\\n",
    "        --model_name_or_path={model_name_or_path} \\\n",
    "        --tokenizer_name={model_name_or_path} \\\n",
    "        {'--load_in_8bit' if load_in_8bit else ''} \\\n",
    "        --use_fast_tokenizer=True \\\n",
    "        --train_file={train_file} \\\n",
    "        --max_seq_length={max_seq_length} \\\n",
    "        {'--max_train_samples='+str(max_train_samples) if max_train_samples else ''} \\\n",
    "        {'--use_lora' if use_lora else ''}\n",
    "        {'--lora_rank='+str(lora_rank) if use_lora else ''}\n",
    "        {'--lora_alpha='+str(lora_alpha) if use_lora else ''}\n",
    "        {'--lora_dropout='+str(lora_dropout) if use_lora else ''}\n",
    "        --do_train \\\n",
    "        --preprocessing_num_workers={preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size={per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
    "        --learning_rate=2e-5 \\\n",
    "        --lr_scheduler_type=linear \\\n",
    "        --warmup_ratio=0.03 \\\n",
    "        --weight_decay=0. \\\n",
    "        --optim={optimizer} \\\n",
    "        --evaluation_strategy={evaluation_strategy} \\\n",
    "        {'--eval_steps='+str(eval_steps) if eval_steps else ''} \\\n",
    "        --report_to tensorboard wandb \\\n",
    "        --run_name {wandb_run_name} \\\n",
    "        --logging_strategy=steps \\\n",
    "        --logging_first_step \\\n",
    "        --logging_steps=1 \\\n",
    "        --save_strategy={save_strategy} \\\n",
    "        --save_steps={save_steps} \\\n",
    "        --save_total_limit={save_total_limit} \\\n",
    "        --num_train_epochs={num_train_epochs} \\\n",
    "        --ddp_timeout=7200 \\\n",
    "        {'--fsdp=\"'+fsdp+'\"' if fsdp else ''}\n",
    "        {'--fsdp_transformer_layer_cls_to_wrap=\"'+fsdp_transformer_layer_cls_to_wrap+'\"' \n",
    "            if fsdp else ''}\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''}\n",
    "        --torch_dtype={torch_dtype} \\\n",
    "        --dataloader_num_workers=8 \\\n",
    "        {f'--{mixed_precision}=True' if mixed_precision else ''} \\\n",
    "        {'--overwrite_output_dir' if overwrite_output_dir else ''} \\\n",
    "        {'--deepspeed='+deepspeed if deepspeed else ''} \\\n",
    "        {'--subsample_mixture=\"'+str(subsample_mixture).replace(': ', ':').replace(', ', ',')+'\"'\n",
    "            if subsample_mixture else ''} \\\n",
    "        {'--subsample_inds_file='+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        {'--dataloader_sampler '+str(dataloader_sampler) if dataloader_sampler else ''} \\\n",
    "        --output_dir=\"{output_dir}\" \\\n",
    "    \"\"\" \n",
    "    #    --overwrite_cache # if delete a dataset and need to refresh cache\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    if test_run:\n",
    "        print()\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831fe55",
   "metadata": {},
   "source": [
    "# eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e3fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_all_symlinks(directory, verbose=False):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files + dirs:\n",
    "            path = os.path.join(root, name)\n",
    "            if os.path.islink(path):\n",
    "                os.unlink(path)\n",
    "                if verbose:\n",
    "                    print(f\"Removed symlink: {path}\")\n",
    "                \n",
    "import uuid\n",
    "\n",
    "def create_unique_symlinks(file_paths, verbose=False):\n",
    "    \"\"\"Create symlinks for each `file` in `files` in the same directory, with a unique name. \"\"\"\n",
    "    dirs = [os.path.dirname(x) for x in file_paths]\n",
    "\n",
    "    symlink_path_dict = {}\n",
    "    for directory, path in zip(dirs, file_paths):\n",
    "        if os.path.isdir(path):\n",
    "            symlink_name = f\"symlink_{str(uuid.uuid4())[:8]}\"  # Generate a unique symlink name\n",
    "            symlink_path = os.path.join(directory, symlink_name)\n",
    "            try:\n",
    "                os.symlink(os.path.abspath(path), symlink_path)\n",
    "                if verbose:\n",
    "                    print(f\"Created symlink: {symlink_path} -> {path}\")\n",
    "            except OSError as e:\n",
    "                print(f\"Failed to create symlink: {path}. Error: {e}\")\n",
    "            symlink_path_dict.update({path: symlink_path})\n",
    "    return symlink_path_dict\n",
    "\n",
    "\n",
    "def get_resource_for_task(task_name, model_name_or_path):\n",
    "    model_name_or_path = model_name_or_path.lower()\n",
    "    if any(x in model_name_or_path for x in ['gpt2-medium', 'pythia-160m']):\n",
    "        return 50, 1\n",
    "    if any(x in model_name_or_path for x in ['gpt-xl']):\n",
    "        if any(x in task_name for x in ['bbh_s=3', 'mmlu_s=5', 'tydiqa_s=1_gp']):\n",
    "            return 16, 1\n",
    "        else:\n",
    "            return 32, 1\n",
    "    if any(x in model_name_or_path for x in ['llama', 'mistral', 'zephyr', 'pythia-1.4b', 'pythia-2.8b']):\n",
    "        if any(x in task_name for x in ['bbh_s=3', 'mmlu_s=5', 'tydiqa_s=1_gp', 'alpacafarm']):\n",
    "            return 5, 1\n",
    "        else:\n",
    "            return 10, 1\n",
    "    if any(x in model_name_or_path for x in ['pythia-6.9b', 'dolly-v2-7b']):\n",
    "        if any(x in task_name for x in ['bbh_s=3', 'mmlu_s=5', 'mmlu_s=0', 'tydiqa_s=1_gp', 'alpacafarm']):\n",
    "            return 4, 1\n",
    "        else:\n",
    "            return 10, 1\n",
    "    return 10, 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9af8b2a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('alpacafarm_ann=chatgpt_chatfmt', 'results/oi2/llama-7b_wizardlm_ep=2')\n",
      "#cmds:  1 \n",
      "\n",
      "python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path \"results/oi2/llama-7b_wizardlm_ep=2\" --save_dir \"results/oi2/llama-7b_wizardlm_ep=2/eval/alpacafarm_ann=chatgpt_chatfmt\" --eval_batch_size 5 --annotators_config chatgpt --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=chatgpt_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# exp_dir = ''\n",
    "create_symlinks = False\n",
    "include_checkpoints = False\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "\n",
    "\n",
    "num_cpus = 10; cpu_mem = 32 # mem usage quite small for llama7b+lora on bbh\n",
    "num_cpus = 24; cpu_mem = 64\n",
    "\n",
    "use_slow_tokenizer = False\n",
    "\n",
    "task_names = [\n",
    "    'mmlu_s=0', # \n",
    "    'mmlu_s=5', # ~1hr\n",
    "    'gsm_s=8',\n",
    "    'gsm_s=8_cot',\n",
    "    'bbh_s=3',\n",
    "    'bbh_s=3_cot', # max_datapoints_per_task=40 -> 40min.\n",
    "    'humaneval',\n",
    "    'tydiqa_s=1_cb', # 3min\n",
    "    'tydiqa_s=1_gp',\n",
    "    # 'toxigen', # ~1.5hr\n",
    "    # 'alpacafarm_ann=chatgpt', # ~$1 per eval.\n",
    "]\n",
    "# task_names = ['alpacafarm_ann=chatgpt']\n",
    "task_names_chatfmt = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "\n",
    "# # ## baselines eval \n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "# #     'gpt2',\n",
    "# #     'gpt2-medium',\n",
    "# #     'huggyllama/llama-7b', \n",
    "# #     'mistralai/Mistral-7B-v0.1',\n",
    "# #     'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "# #     'NousResearch/Llama-2-7b-hf',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-beta',\n",
    "# #     'HuggingFaceH4/zephyr-7b-alpha',\n",
    "# #     'HuggingFaceH4/zephyr-7b-beta',\n",
    "# #     'EleutherAI/pythia-1.4b',\n",
    "# #     'EleutherAI/pythia-2.8b',\n",
    "# #     'EleutherAI/pythia-6.9b',\n",
    "# #     'databricks/dolly-v2-7b',\n",
    "# #     'codellama/CodeLlama-7b-hf',\n",
    "#     'codellama/CodeLlama-7b-Python-hf',\n",
    "#     'codellama/CodeLlama-7b-Instruct-hf',\n",
    "# ]]\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# # ## baseline re-eval after merge upstream/main\n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "#     'huggyllama/llama-7b',\n",
    "# ]]\n",
    "# subdir_path_list += ['results/ft1/llama-7b_humanmix']\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# ## ft1\n",
    "# exp_dir = 'results/ft1'\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# ## ft1_ep=1\n",
    "# # exp_dir = 'results/ft1_ep=1'\n",
    "# # exp_dir = 'results/ft1_ep=2'\n",
    "# exp_dir = 'results/oi2'\n",
    "# # subdir_filter_fn = lambda x: 'lima' in x\n",
    "# # task_names = task_names_chatfmt\n",
    "# # task_names = task_names+task_names_chatfmt\n",
    "# task_names = ['alpacafarm_ann=chatgpt']; task_names = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "\n",
    "# ## ft2\n",
    "# exp_dir = 'results/ft2/'\n",
    "# create_symlinks = True\n",
    "# subdir_filter_fn = lambda x: any(y in x for y in ['llama-7b'])\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# ## llama-7b time-series 400k, 600k\n",
    "# exp_dir = 'results/oi3/'\n",
    "# include_checkpoints = True\n",
    "# subdir_filter_fn = lambda x: any(y in x for y in ['400k', '600k']) # , '600k'\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# # oi4 include checkpoints!\n",
    "# # exp_dir = 'results/oi4_perf_cross_time/'\n",
    "# # exp_dir = 'results/oi4_tulu_v1_human_mix/'\n",
    "# # exp_dir = 'results/oi4_flanv2_prune_with_hmv1_model/'\n",
    "# # exp_dir = 'results/oi4_flan2022_1m/'\n",
    "# # exp_dir = 'results/oi4_tulu_v1_mix/'\n",
    "# exp_dir = 'results/oi4_tulu_v1_mix_ep=3/'\n",
    "# # include_checkpoints = True\n",
    "# include_checkpoints = False\n",
    "# subdir_filter_fn = lambda x: any(y in x for y in ['random']) #$ ['log_prob_decr', 'el2n_agg=mean_incr', 'logit_margin_decr', 'grad_loraB']\n",
    "# # task_names = task_names+task_names_chatfmt\n",
    "# task_names = ['alpacafarm_ann=chatgpt']; task_names = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "# # oi4 without checkpoint \n",
    "# # exp_dir = 'results/oi4/'\n",
    "# exp_dir = 'results/oi4_flan_v2_vary_subsetsize/'\n",
    "# task_names = task_names_chatfmt\n",
    "\n",
    "# ## oi5\n",
    "# exp_dir = 'results/oi5_tulu_v1_mix:llama-7b/'\n",
    "# exp_dir = 'results/oi5_ultrachat:mistral-7b'\n",
    "# exp_dir = 'results/oi5_ultrachat200k:mistral-7b'\n",
    "# exp_dir = 'results/oi5_ultrachat15:mistral-7b'\n",
    "# exp_dir = 'results/oi5_wizardlm:llama-7b'\n",
    "# subdir_filter_fn = lambda x : 'ap:k=vmf:gamma=auto10000:kmd=llama7b:kemb=grad+rp+loraB_pace=prune:size=5' in x\n",
    "# task_names = ['alpacafarm_ann=chatgpt']; task_names = [x+'_chatfmt' for x in task_names]\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# exp_dir = 'results/oi6_starcoder_ep=5'\n",
    "# exp_dir = 'results/oi5_starcoder_commentinstr:codellama-7b'\n",
    "# exp_dir = 'results/oi5_starcoder_commentinstrv2:codellama-7b'\n",
    "exp_dir = 'results/oi2'\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "subdir_filter_fn = lambda x: 'wizardlm' in x\n",
    "task_names = ['alpacafarm_ann=chatgpt_chatfmt']; \n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "\n",
    "if len(subdir_path_list)==0:\n",
    "    if create_symlinks:\n",
    "        remove_all_symlinks(exp_dir)\n",
    "    subdir_path_list = []\n",
    "    subdirs = list(os.listdir(exp_dir))\n",
    "    subdirs = filter(subdir_filter_fn, subdirs)\n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(exp_dir, subdir)\n",
    "        if include_checkpoints:\n",
    "            subdir_path_list += glob.glob(os.path.join(subdir_path, 'checkpoint-*'))\n",
    "        if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "            continue\n",
    "        subdir_path_list.append(subdir_path)\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not os.path.islink(subdir_path) and \\\n",
    "                not os.path.isfile(os.path.join(subdir_path, 'eval', task_name, 'metrics.json')):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "                print((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "\n",
    "print('#cmds: ', len(list(task_name_and_model)), '\\n')\n",
    "\n",
    "if create_symlinks:\n",
    "    # create symlink for each directory.\n",
    "    symlink_path_dict = create_unique_symlinks(\n",
    "        list([x[1] for x in task_name_and_model]))\n",
    "    options_list = list(map(lambda x: (x[0], symlink_path_dict[x[1]]), task_name_and_model))\n",
    "else:\n",
    "    options_list = task_name_and_model\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "info = {}  \n",
    "cmds = []\n",
    "for task_name, model_name_or_path in options_list:\n",
    "    \n",
    "    use_chat_format = 'chatfmt' in task_name\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(model_name_or_path, 'ft_args.json'), 'r') as f:\n",
    "            ft_args = json.load(f)\n",
    "        # note `model_name_or_path` could be anything, e.g., soft links with arbitrary names.\n",
    "        # but `ft_args_model_name_or_path` indicates the finetuned model name.\n",
    "        ft_args_model_name_or_path = ft_args['model_args']['model_name_or_path']\n",
    "    except:\n",
    "        ft_args_model_name_or_path = model_name_or_path\n",
    "\n",
    "    if 'gpt2' in ft_args_model_name_or_path:\n",
    "        tydiqa_max_context_length = 400 # max ctx len without exceeding max_seq_len\n",
    "    else:\n",
    "        tydiqa_max_context_length = 512\n",
    "    batch_size, job_duration = get_resource_for_task(\n",
    "        task_name, ft_args_model_name_or_path)\n",
    "    \n",
    "    job_name = f'eval.{task_name}'\n",
    "    run_id = model_name_or_path\n",
    "    save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "    \n",
    "    if task_name.startswith('mmlu'):\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 5)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.mmlu.run_eval \\\n",
    "            --data_dir data/eval/mmlu \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --ntrain {n_shot} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('gsm'):\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 8)\n",
    "        # open-instruct used 200 examples. use higher amount to get a more accurate number\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.gsm.run_eval \\\n",
    "            --data_dir data/eval/gsm/ \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_num_examples 500 \\\n",
    "            --n_shot {n_shot} \\\n",
    "            --max_new_tokens 256 \\\n",
    "            {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('bbh'):\n",
    "        max_num_examples_per_task = 40\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 3)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.bbh.run_eval \\\n",
    "            --data_dir data/eval/bbh/ \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_new_tokens 256 \\\n",
    "            --n_shot {n_shot} \\\n",
    "            {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--max_num_examples_per_task '+str(max_num_examples_per_task) if max_num_examples_per_task else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('humaneval'):\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.codex_humaneval.run_eval \\\n",
    "            --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --eval_pass_at_ks 1 \\\n",
    "            --unbiased_sampling_size_n 1 \\\n",
    "            --temperature 0.1 \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('tydiqa'):\n",
    "        no_context = 'cb' in task_name\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot in [0,1])\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.tydiqa.run_eval \\\n",
    "            --data_dir data/eval/tydiqa \\\n",
    "            --n_shot {n_shot} \\\n",
    "            --max_num_examples_per_lang 100 \\\n",
    "            --max_context_length {tydiqa_max_context_length} \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            {'--no_context' if no_context else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('toxigen'):\n",
    "        # max_prompts_per_group=500 (out of 1000) is open-instruct default.\n",
    "        # eval batch size=1 much faster (llama-7b) not sure why.\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.toxigen.run_eval \\\n",
    "            --data_dir data/eval/toxigen \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size 1 \\\n",
    "            --max_prompts_per_group 200 \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('alpacafarm'):\n",
    "        match = re.search(r'ann=([^_]+)', task_name)\n",
    "        annotators_config = match.group(1)\n",
    "        annotators_config = annotators_config.replace(':', '_')\n",
    "        if not annotators_config in ['chatgpt', 'alpaca_eval_gpt4_0314']:\n",
    "            raise ValueError('Just support 2 annotators_config.')\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.alpaca_farm.run_eval \\\n",
    "            --reference_path alpaca_eval_data \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --annotators_config {annotators_config} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    else:\n",
    "        raise ValueError(f'{task_name} not supported.')\n",
    "        \n",
    "        \n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "    print(cmd)\n",
    "    \n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=save_dir,\n",
    "    )\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=1,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "358cd711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "\n",
    "with open('gen_cmds_run_cmds.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'][0]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4392e9ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_fmt=True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4db7c_row0_col0, #T_4db7c_row0_col1, #T_4db7c_row1_col0, #T_4db7c_row1_col1, #T_4db7c_row2_col0, #T_4db7c_row2_col1, #T_4db7c_row3_col0, #T_4db7c_row3_col1, #T_4db7c_row4_col0, #T_4db7c_row4_col1, #T_4db7c_row5_col0, #T_4db7c_row5_col1, #T_4db7c_row6_col0, #T_4db7c_row6_col1, #T_4db7c_row7_col0, #T_4db7c_row7_col1, #T_4db7c_row8_col0, #T_4db7c_row8_col1, #T_4db7c_row9_col0, #T_4db7c_row9_col1, #T_4db7c_row10_col0, #T_4db7c_row10_col1, #T_4db7c_row11_col0, #T_4db7c_row11_col1, #T_4db7c_row12_col0, #T_4db7c_row12_col1, #T_4db7c_row13_col0, #T_4db7c_row13_col1, #T_4db7c_row14_col0, #T_4db7c_row14_col1, #T_4db7c_row15_col0, #T_4db7c_row15_col1, #T_4db7c_row16_col0, #T_4db7c_row16_col1, #T_4db7c_row17_col0, #T_4db7c_row17_col1, #T_4db7c_row18_col0, #T_4db7c_row18_col1, #T_4db7c_row19_col0, #T_4db7c_row19_col1, #T_4db7c_row20_col0, #T_4db7c_row20_col1, #T_4db7c_row21_col0, #T_4db7c_row21_col1, #T_4db7c_row22_col0, #T_4db7c_row22_col1, #T_4db7c_row23_col0, #T_4db7c_row23_col1, #T_4db7c_row24_col0, #T_4db7c_row24_col1, #T_4db7c_row25_col0, #T_4db7c_row25_col1, #T_4db7c_row26_col0, #T_4db7c_row26_col1, #T_4db7c_row27_col0, #T_4db7c_row27_col1, #T_4db7c_row28_col0, #T_4db7c_row28_col1, #T_4db7c_row29_col0, #T_4db7c_row29_col1, #T_4db7c_row30_col0, #T_4db7c_row30_col1, #T_4db7c_row31_col0, #T_4db7c_row31_col1, #T_4db7c_row32_col0, #T_4db7c_row32_col1, #T_4db7c_row33_col0, #T_4db7c_row33_col1, #T_4db7c_row34_col0, #T_4db7c_row34_col1, #T_4db7c_row35_col0, #T_4db7c_row35_col1, #T_4db7c_row36_col0, #T_4db7c_row36_col1, #T_4db7c_row37_col0, #T_4db7c_row37_col1, #T_4db7c_row38_col0, #T_4db7c_row38_col1, #T_4db7c_row39_col0, #T_4db7c_row39_col1, #T_4db7c_row40_col0, #T_4db7c_row40_col1, #T_4db7c_row41_col0, #T_4db7c_row41_col1, #T_4db7c_row42_col0, #T_4db7c_row42_col1, #T_4db7c_row43_col0, #T_4db7c_row43_col1, #T_4db7c_row44_col0, #T_4db7c_row44_col1, #T_4db7c_row45_col0, #T_4db7c_row45_col1, #T_4db7c_row46_col0, #T_4db7c_row46_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4db7c_row0_col2, #T_4db7c_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row0_col3, #T_4db7c_row2_col3, #T_4db7c_row5_col7, #T_4db7c_row10_col7, #T_4db7c_row20_col12, #T_4db7c_row23_col7, #T_4db7c_row24_col3, #T_4db7c_row39_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row0_col4, #T_4db7c_row9_col4, #T_4db7c_row12_col4, #T_4db7c_row13_col8, #T_4db7c_row25_col4, #T_4db7c_row31_col2, #T_4db7c_row33_col4, #T_4db7c_row37_col3, #T_4db7c_row37_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row0_col5, #T_4db7c_row10_col5, #T_4db7c_row14_col5, #T_4db7c_row20_col9, #T_4db7c_row32_col5, #T_4db7c_row45_col3, #T_4db7c_row46_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row0_col6, #T_4db7c_row0_col12, #T_4db7c_row2_col13, #T_4db7c_row4_col10, #T_4db7c_row5_col4, #T_4db7c_row10_col2, #T_4db7c_row19_col5, #T_4db7c_row19_col11, #T_4db7c_row21_col7, #T_4db7c_row30_col3, #T_4db7c_row39_col8, #T_4db7c_row41_col9, #T_4db7c_row43_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row0_col7, #T_4db7c_row17_col3, #T_4db7c_row39_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row0_col9, #T_4db7c_row3_col10, #T_4db7c_row9_col10, #T_4db7c_row13_col10, #T_4db7c_row15_col10, #T_4db7c_row22_col2, #T_4db7c_row22_col6, #T_4db7c_row29_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row0_col10, #T_4db7c_row8_col12, #T_4db7c_row11_col6, #T_4db7c_row17_col10, #T_4db7c_row21_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row1_col4, #T_4db7c_row7_col11, #T_4db7c_row20_col4, #T_4db7c_row26_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row1_col7, #T_4db7c_row6_col9, #T_4db7c_row8_col9, #T_4db7c_row38_col7, #T_4db7c_row44_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row1_col8, #T_4db7c_row12_col5, #T_4db7c_row17_col5, #T_4db7c_row21_col3, #T_4db7c_row26_col5, #T_4db7c_row27_col5, #T_4db7c_row39_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row1_col9, #T_4db7c_row8_col13, #T_4db7c_row43_col7, #T_4db7c_row44_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row1_col10, #T_4db7c_row2_col4, #T_4db7c_row3_col5, #T_4db7c_row5_col10, #T_4db7c_row6_col4, #T_4db7c_row7_col2, #T_4db7c_row8_col7, #T_4db7c_row13_col4, #T_4db7c_row13_col5, #T_4db7c_row21_col4, #T_4db7c_row23_col10, #T_4db7c_row24_col8, #T_4db7c_row25_col5, #T_4db7c_row25_col10, #T_4db7c_row31_col10, #T_4db7c_row36_col4, #T_4db7c_row36_col11, #T_4db7c_row38_col10, #T_4db7c_row46_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row1_col12, #T_4db7c_row10_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row2_col2, #T_4db7c_row11_col12, #T_4db7c_row36_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row2_col5, #T_4db7c_row18_col8, #T_4db7c_row19_col6, #T_4db7c_row36_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row2_col6, #T_4db7c_row4_col11, #T_4db7c_row15_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row2_col7, #T_4db7c_row4_col2, #T_4db7c_row17_col6, #T_4db7c_row29_col6, #T_4db7c_row38_col8, #T_4db7c_row42_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row2_col8, #T_4db7c_row21_col2, #T_4db7c_row33_col8, #T_4db7c_row37_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row2_col9, #T_4db7c_row17_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row2_col10, #T_4db7c_row3_col12, #T_4db7c_row32_col2, #T_4db7c_row39_col10, #T_4db7c_row41_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d55042;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row2_col11, #T_4db7c_row3_col11, #T_4db7c_row4_col12, #T_4db7c_row5_col6, #T_4db7c_row5_col12, #T_4db7c_row21_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row2_col12, #T_4db7c_row6_col11, #T_4db7c_row8_col11, #T_4db7c_row14_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row3_col2, #T_4db7c_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row3_col3, #T_4db7c_row14_col9, #T_4db7c_row16_col9, #T_4db7c_row28_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row3_col4, #T_4db7c_row5_col5, #T_4db7c_row16_col4, #T_4db7c_row23_col5, #T_4db7c_row35_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row3_col6, #T_4db7c_row14_col2, #T_4db7c_row24_col11, #T_4db7c_row26_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row3_col7, #T_4db7c_row26_col6, #T_4db7c_row32_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #dc5d4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row3_col9, #T_4db7c_row16_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row3_col13, #T_4db7c_row39_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row4_col3, #T_4db7c_row6_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row4_col4, #T_4db7c_row10_col4, #T_4db7c_row27_col4, #T_4db7c_row45_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row4_col5, #T_4db7c_row35_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row4_col6, #T_4db7c_row8_col6, #T_4db7c_row10_col3, #T_4db7c_row13_col13, #T_4db7c_row39_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row4_col7, #T_4db7c_row18_col7, #T_4db7c_row28_col6, #T_4db7c_row35_col11, #T_4db7c_row36_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row4_col8, #T_4db7c_row16_col3, #T_4db7c_row23_col12, #T_4db7c_row27_col8, #T_4db7c_row28_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row4_col9, #T_4db7c_row44_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row4_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row5_col2, #T_4db7c_row24_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row5_col3, #T_4db7c_row12_col13, #T_4db7c_row34_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row5_col8, #T_4db7c_row23_col3, #T_4db7c_row25_col2, #T_4db7c_row42_col5, #T_4db7c_row42_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row5_col9, #T_4db7c_row15_col12, #T_4db7c_row23_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row5_col13, #T_4db7c_row9_col7, #T_4db7c_row16_col11, #T_4db7c_row43_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row6_col2, #T_4db7c_row30_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row6_col3, #T_4db7c_row10_col6, #T_4db7c_row18_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row6_col5, #T_4db7c_row37_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row6_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row6_col7, #T_4db7c_row8_col3, #T_4db7c_row11_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row6_col10, #T_4db7c_row7_col9, #T_4db7c_row11_col10, #T_4db7c_row20_col10, #T_4db7c_row26_col3, #T_4db7c_row31_col12, #T_4db7c_row45_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row6_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row6_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row7_col3, #T_4db7c_row18_col6, #T_4db7c_row25_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e16751;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row7_col4, #T_4db7c_row32_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row7_col5, #T_4db7c_row8_col8, #T_4db7c_row16_col5, #T_4db7c_row38_col11, #T_4db7c_row41_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row7_col6, #T_4db7c_row11_col4, #T_4db7c_row14_col4, #T_4db7c_row14_col12, #T_4db7c_row22_col4, #T_4db7c_row28_col4, #T_4db7c_row38_col4, #T_4db7c_row41_col4, #T_4db7c_row42_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row7_col7, #T_4db7c_row18_col12, #T_4db7c_row24_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row7_col8, #T_4db7c_row23_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row7_col10, #T_4db7c_row10_col10, #T_4db7c_row11_col7, #T_4db7c_row13_col7, #T_4db7c_row19_col7, #T_4db7c_row22_col3, #T_4db7c_row24_col10, #T_4db7c_row26_col10, #T_4db7c_row27_col7, #T_4db7c_row33_col10, #T_4db7c_row37_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row7_col12, #T_4db7c_row16_col6, #T_4db7c_row19_col4, #T_4db7c_row23_col4, #T_4db7c_row28_col8, #T_4db7c_row31_col11, #T_4db7c_row35_col4, #T_4db7c_row44_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row7_col13, #T_4db7c_row11_col13, #T_4db7c_row12_col3, #T_4db7c_row12_col12, #T_4db7c_row22_col11, #T_4db7c_row32_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row8_col2, #T_4db7c_row12_col6, #T_4db7c_row15_col2, #T_4db7c_row20_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row8_col4, #T_4db7c_row16_col13, #T_4db7c_row17_col4, #T_4db7c_row18_col4, #T_4db7c_row24_col4, #T_4db7c_row27_col12, #T_4db7c_row29_col3, #T_4db7c_row31_col3, #T_4db7c_row34_col4, #T_4db7c_row35_col2, #T_4db7c_row42_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row8_col5, #T_4db7c_row28_col5, #T_4db7c_row29_col5, #T_4db7c_row32_col9, #T_4db7c_row44_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row8_col10, #T_4db7c_row12_col10, #T_4db7c_row16_col10, #T_4db7c_row32_col10, #T_4db7c_row34_col10, #T_4db7c_row36_col10, #T_4db7c_row41_col10, #T_4db7c_row46_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row9_col2, #T_4db7c_row20_col3, #T_4db7c_row34_col7, #T_4db7c_row37_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row9_col3, #T_4db7c_row21_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row9_col5, #T_4db7c_row25_col6, #T_4db7c_row30_col12, #T_4db7c_row41_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row9_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row9_col8, #T_4db7c_row17_col8, #T_4db7c_row35_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row9_col9, #T_4db7c_row16_col2, #T_4db7c_row31_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row9_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row9_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row9_col13, #T_4db7c_row10_col12, #T_4db7c_row11_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row10_col8, #T_4db7c_row33_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row10_col9, #T_4db7c_row38_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row10_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row11_col5, #T_4db7c_row21_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row11_col8, #T_4db7c_row23_col8, #T_4db7c_row24_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row11_col9, #T_4db7c_row20_col2, #T_4db7c_row22_col8, #T_4db7c_row43_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row11_col11, #T_4db7c_row13_col11, #T_4db7c_row14_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row12_col2, #T_4db7c_row27_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row12_col7, #T_4db7c_row16_col7, #T_4db7c_row21_col6, #T_4db7c_row25_col8, #T_4db7c_row45_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row12_col8, #T_4db7c_row32_col12, #T_4db7c_row33_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row12_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row12_col11, #T_4db7c_row22_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row13_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row13_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row13_col6, #T_4db7c_row20_col7, #T_4db7c_row30_col4, #T_4db7c_row46_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row13_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row13_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row14_col3, #T_4db7c_row22_col12, #T_4db7c_row32_col6, #T_4db7c_row38_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row14_col7, #T_4db7c_row15_col7, #T_4db7c_row42_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row14_col8, #T_4db7c_row21_col13, #T_4db7c_row26_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row14_col10, #T_4db7c_row15_col8, #T_4db7c_row19_col10, #T_4db7c_row20_col8, #T_4db7c_row35_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row14_col13, #T_4db7c_row19_col2, #T_4db7c_row30_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row15_col3, #T_4db7c_row29_col7, #T_4db7c_row35_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row15_col4, #T_4db7c_row29_col4, #T_4db7c_row39_col4, #T_4db7c_row39_col12, #T_4db7c_row40_col4, #T_4db7c_row40_col12, #T_4db7c_row42_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row15_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row15_col6, #T_4db7c_row30_col7, #T_4db7c_row36_col7, #T_4db7c_row41_col3, #T_4db7c_row44_col6, #T_4db7c_row45_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row15_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row15_col13, #T_4db7c_row32_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row16_col8, #T_4db7c_row28_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row17_col2, #T_4db7c_row26_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row17_col7, #T_4db7c_row22_col13, #T_4db7c_row33_col3, #T_4db7c_row41_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row17_col9, #T_4db7c_row29_col2, #T_4db7c_row34_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row17_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c83836;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row17_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row18_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row18_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row18_col9, #T_4db7c_row37_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row18_col10, #T_4db7c_row22_col10, #T_4db7c_row42_col10, #T_4db7c_row43_col8, #T_4db7c_row44_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row18_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row18_col13, #T_4db7c_row19_col13, #T_4db7c_row28_col7, #T_4db7c_row33_col7, #T_4db7c_row35_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row19_col3, #T_4db7c_row40_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row19_col8, #T_4db7c_row33_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row19_col9, #T_4db7c_row24_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row19_col12, #T_4db7c_row28_col10, #T_4db7c_row34_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row20_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row20_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row20_col13, #T_4db7c_row34_col3, #T_4db7c_row45_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row21_col8, #T_4db7c_row24_col13, #T_4db7c_row40_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row21_col9, #T_4db7c_row36_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row22_col5, #T_4db7c_row45_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row22_col9, #T_4db7c_row33_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row23_col6, #T_4db7c_row27_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row23_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row23_col13, #T_4db7c_row26_col8, #T_4db7c_row30_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row24_col5, #T_4db7c_row34_col2, #T_4db7c_row34_col5, #T_4db7c_row36_col5, #T_4db7c_row38_col5, #T_4db7c_row38_col12, #T_4db7c_row43_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row24_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row25_col3, #T_4db7c_row33_col12, #T_4db7c_row42_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row25_col9, #T_4db7c_row34_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row25_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row25_col12, #T_4db7c_row31_col6, #T_4db7c_row33_col6, #T_4db7c_row46_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f2c9b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row25_col13, #T_4db7c_row35_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row26_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row26_col7, #T_4db7c_row31_col7, #T_4db7c_row46_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row26_col13, #T_4db7c_row28_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row27_col2, #T_4db7c_row28_col12, #T_4db7c_row29_col12, #T_4db7c_row40_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f1ccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row27_col3, #T_4db7c_row41_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row27_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row27_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row27_col13, #T_4db7c_row45_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row28_col2, #T_4db7c_row30_col13, #T_4db7c_row32_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #b3cdfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row29_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row29_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row29_col11, #T_4db7c_row34_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row29_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row30_col5, #T_4db7c_row31_col4, #T_4db7c_row36_col2, #T_4db7c_row40_col13, #T_4db7c_row41_col7, #T_4db7c_row41_col11, #T_4db7c_row43_col3, #T_4db7c_row43_col6, #T_4db7c_row43_col9, #T_4db7c_row43_col10, #T_4db7c_row45_col8, #T_4db7c_row46_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row30_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row30_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row30_col9, #T_4db7c_row41_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row31_col5, #T_4db7c_row40_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row31_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row31_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row32_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row33_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row34_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row35_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row35_col13, #T_4db7c_row38_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row36_col3, #T_4db7c_row45_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row36_col9, #T_4db7c_row42_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row37_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row37_col6, #T_4db7c_row43_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row37_col7, #T_4db7c_row37_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row37_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row38_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row38_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row39_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row39_col11, #T_4db7c_row39_col13, #T_4db7c_row42_col11, #T_4db7c_row42_col13, #T_4db7c_row44_col11, #T_4db7c_row44_col13, #T_4db7c_row45_col11, #T_4db7c_row45_col13, #T_4db7c_row46_col11, #T_4db7c_row46_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row40_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row40_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row40_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row40_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row40_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row43_col13, #T_4db7c_row44_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row44_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4db7c_row44_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row46_col3, #T_4db7c_row46_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4db7c_row46_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4db7c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4db7c_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_4db7c_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_4db7c_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_4db7c_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_4db7c_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_4db7c_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_4db7c_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_4db7c_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_4db7c_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_4db7c_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_4db7c_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_4db7c_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(v.Davinci-003)/WR</th>\n",
       "      <th id=\"T_4db7c_level0_col12\" class=\"col_heading level0 col12\" >Average</th>\n",
       "      <th id=\"T_4db7c_level0_col13\" class=\"col_heading level0 col13\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4db7c_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.5:k=vmf:gamma=0.043:kmd=mpnet:q=log+pmi:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row0_col1\" class=\"data row0 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row0_col2\" class=\"data row0 col2\" >38.77</td>\n",
       "      <td id=\"T_4db7c_row0_col3\" class=\"data row0 col3\" >34.45</td>\n",
       "      <td id=\"T_4db7c_row0_col4\" class=\"data row0 col4\" >5.00</td>\n",
       "      <td id=\"T_4db7c_row0_col5\" class=\"data row0 col5\" >11.80</td>\n",
       "      <td id=\"T_4db7c_row0_col6\" class=\"data row0 col6\" >35.37</td>\n",
       "      <td id=\"T_4db7c_row0_col7\" class=\"data row0 col7\" >28.43</td>\n",
       "      <td id=\"T_4db7c_row0_col8\" class=\"data row0 col8\" >9.02</td>\n",
       "      <td id=\"T_4db7c_row0_col9\" class=\"data row0 col9\" >35.60</td>\n",
       "      <td id=\"T_4db7c_row0_col10\" class=\"data row0 col10\" >14.02</td>\n",
       "      <td id=\"T_4db7c_row0_col11\" class=\"data row0 col11\" >53.29</td>\n",
       "      <td id=\"T_4db7c_row0_col12\" class=\"data row0 col12\" >26.57</td>\n",
       "      <td id=\"T_4db7c_row0_col13\" class=\"data row0 col13\" >-14.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4db7c_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm_score=dppmap:k=rbf:gamma=7.5e-06:kmd=llama7b:kemb=text+embedding_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row1_col1\" class=\"data row1 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row1_col2\" class=\"data row1 col2\" >39.66</td>\n",
       "      <td id=\"T_4db7c_row1_col3\" class=\"data row1 col3\" >34.60</td>\n",
       "      <td id=\"T_4db7c_row1_col4\" class=\"data row1 col4\" >6.20</td>\n",
       "      <td id=\"T_4db7c_row1_col5\" class=\"data row1 col5\" >11.00</td>\n",
       "      <td id=\"T_4db7c_row1_col6\" class=\"data row1 col6\" >33.24</td>\n",
       "      <td id=\"T_4db7c_row1_col7\" class=\"data row1 col7\" >27.87</td>\n",
       "      <td id=\"T_4db7c_row1_col8\" class=\"data row1 col8\" >7.89</td>\n",
       "      <td id=\"T_4db7c_row1_col9\" class=\"data row1 col9\" >35.26</td>\n",
       "      <td id=\"T_4db7c_row1_col10\" class=\"data row1 col10\" >11.59</td>\n",
       "      <td id=\"T_4db7c_row1_col11\" class=\"data row1 col11\" >56.34</td>\n",
       "      <td id=\"T_4db7c_row1_col12\" class=\"data row1 col12\" >26.36</td>\n",
       "      <td id=\"T_4db7c_row1_col13\" class=\"data row1 col13\" >-15.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4db7c_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.3:k=vmf:gamma=0.04:kmd=mpnet:q=log+pmi:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row2_col1\" class=\"data row2 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row2_col2\" class=\"data row2 col2\" >38.21</td>\n",
       "      <td id=\"T_4db7c_row2_col3\" class=\"data row2 col3\" >34.44</td>\n",
       "      <td id=\"T_4db7c_row2_col4\" class=\"data row2 col4\" >5.40</td>\n",
       "      <td id=\"T_4db7c_row2_col5\" class=\"data row2 col5\" >12.80</td>\n",
       "      <td id=\"T_4db7c_row2_col6\" class=\"data row2 col6\" >33.80</td>\n",
       "      <td id=\"T_4db7c_row2_col7\" class=\"data row2 col7\" >29.63</td>\n",
       "      <td id=\"T_4db7c_row2_col8\" class=\"data row2 col8\" >8.07</td>\n",
       "      <td id=\"T_4db7c_row2_col9\" class=\"data row2 col9\" >29.96</td>\n",
       "      <td id=\"T_4db7c_row2_col10\" class=\"data row2 col10\" >14.63</td>\n",
       "      <td id=\"T_4db7c_row2_col11\" class=\"data row2 col11\" >52.73</td>\n",
       "      <td id=\"T_4db7c_row2_col12\" class=\"data row2 col12\" >25.97</td>\n",
       "      <td id=\"T_4db7c_row2_col13\" class=\"data row2 col13\" >-13.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4db7c_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=0.13:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_4db7c_row3_col1\" class=\"data row3 col1\" >100000</td>\n",
       "      <td id=\"T_4db7c_row3_col2\" class=\"data row3 col2\" >38.62</td>\n",
       "      <td id=\"T_4db7c_row3_col3\" class=\"data row3 col3\" >32.83</td>\n",
       "      <td id=\"T_4db7c_row3_col4\" class=\"data row3 col4\" >4.40</td>\n",
       "      <td id=\"T_4db7c_row3_col5\" class=\"data row3 col5\" >14.20</td>\n",
       "      <td id=\"T_4db7c_row3_col6\" class=\"data row3 col6\" >30.09</td>\n",
       "      <td id=\"T_4db7c_row3_col7\" class=\"data row3 col7\" >28.15</td>\n",
       "      <td id=\"T_4db7c_row3_col8\" class=\"data row3 col8\" >10.03</td>\n",
       "      <td id=\"T_4db7c_row3_col9\" class=\"data row3 col9\" >34.72</td>\n",
       "      <td id=\"T_4db7c_row3_col10\" class=\"data row3 col10\" >13.41</td>\n",
       "      <td id=\"T_4db7c_row3_col11\" class=\"data row3 col11\" >52.67</td>\n",
       "      <td id=\"T_4db7c_row3_col12\" class=\"data row3 col12\" >25.91</td>\n",
       "      <td id=\"T_4db7c_row3_col13\" class=\"data row3 col13\" >-17.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_4db7c_row4_col0\" class=\"data row4 col0\" >llama-7b_wizardlm_score=random:s=0_pace=prune:size=200000:ep=2</td>\n",
       "      <td id=\"T_4db7c_row4_col1\" class=\"data row4 col1\" >200000</td>\n",
       "      <td id=\"T_4db7c_row4_col2\" class=\"data row4 col2\" >37.79</td>\n",
       "      <td id=\"T_4db7c_row4_col3\" class=\"data row4 col3\" >35.03</td>\n",
       "      <td id=\"T_4db7c_row4_col4\" class=\"data row4 col4\" >4.00</td>\n",
       "      <td id=\"T_4db7c_row4_col5\" class=\"data row4 col5\" >13.80</td>\n",
       "      <td id=\"T_4db7c_row4_col6\" class=\"data row4 col6\" >31.94</td>\n",
       "      <td id=\"T_4db7c_row4_col7\" class=\"data row4 col7\" >29.07</td>\n",
       "      <td id=\"T_4db7c_row4_col8\" class=\"data row4 col8\" >8.99</td>\n",
       "      <td id=\"T_4db7c_row4_col9\" class=\"data row4 col9\" >28.98</td>\n",
       "      <td id=\"T_4db7c_row4_col10\" class=\"data row4 col10\" >15.85</td>\n",
       "      <td id=\"T_4db7c_row4_col11\" class=\"data row4 col11\" >53.43</td>\n",
       "      <td id=\"T_4db7c_row4_col12\" class=\"data row4 col12\" >25.89</td>\n",
       "      <td id=\"T_4db7c_row4_col13\" class=\"data row4 col13\" >-15.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_4db7c_row5_col0\" class=\"data row5 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.7:k=vmf:gamma=0.043:kmd=mpnet:q=log+pmi:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row5_col1\" class=\"data row5 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row5_col2\" class=\"data row5 col2\" >36.27</td>\n",
       "      <td id=\"T_4db7c_row5_col3\" class=\"data row5 col3\" >34.73</td>\n",
       "      <td id=\"T_4db7c_row5_col4\" class=\"data row5 col4\" >6.40</td>\n",
       "      <td id=\"T_4db7c_row5_col5\" class=\"data row5 col5\" >11.60</td>\n",
       "      <td id=\"T_4db7c_row5_col6\" class=\"data row5 col6\" >33.43</td>\n",
       "      <td id=\"T_4db7c_row5_col7\" class=\"data row5 col7\" >28.98</td>\n",
       "      <td id=\"T_4db7c_row5_col8\" class=\"data row5 col8\" >8.95</td>\n",
       "      <td id=\"T_4db7c_row5_col9\" class=\"data row5 col9\" >35.22</td>\n",
       "      <td id=\"T_4db7c_row5_col10\" class=\"data row5 col10\" >11.59</td>\n",
       "      <td id=\"T_4db7c_row5_col11\" class=\"data row5 col11\" >51.68</td>\n",
       "      <td id=\"T_4db7c_row5_col12\" class=\"data row5 col12\" >25.88</td>\n",
       "      <td id=\"T_4db7c_row5_col13\" class=\"data row5 col13\" >-16.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_4db7c_row6_col0\" class=\"data row6 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=0.035:kmd=mpnet_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row6_col1\" class=\"data row6 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row6_col2\" class=\"data row6 col2\" >37.95</td>\n",
       "      <td id=\"T_4db7c_row6_col3\" class=\"data row6 col3\" >34.38</td>\n",
       "      <td id=\"T_4db7c_row6_col4\" class=\"data row6 col4\" >5.40</td>\n",
       "      <td id=\"T_4db7c_row6_col5\" class=\"data row6 col5\" >12.00</td>\n",
       "      <td id=\"T_4db7c_row6_col6\" class=\"data row6 col6\" >33.15</td>\n",
       "      <td id=\"T_4db7c_row6_col7\" class=\"data row6 col7\" >30.19</td>\n",
       "      <td id=\"T_4db7c_row6_col8\" class=\"data row6 col8\" >9.56</td>\n",
       "      <td id=\"T_4db7c_row6_col9\" class=\"data row6 col9\" >31.11</td>\n",
       "      <td id=\"T_4db7c_row6_col10\" class=\"data row6 col10\" >10.37</td>\n",
       "      <td id=\"T_4db7c_row6_col11\" class=\"data row6 col11\" >53.18</td>\n",
       "      <td id=\"T_4db7c_row6_col12\" class=\"data row6 col12\" >25.73</td>\n",
       "      <td id=\"T_4db7c_row6_col13\" class=\"data row6 col13\" >-14.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_4db7c_row7_col0\" class=\"data row7 col0\" >llama-7b_wizardlm_score=dedup:md=mpnet:emb=text+embedding_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_4db7c_row7_col1\" class=\"data row7 col1\" >100000</td>\n",
       "      <td id=\"T_4db7c_row7_col2\" class=\"data row7 col2\" >36.66</td>\n",
       "      <td id=\"T_4db7c_row7_col3\" class=\"data row7 col3\" >35.71</td>\n",
       "      <td id=\"T_4db7c_row7_col4\" class=\"data row7 col4\" >4.20</td>\n",
       "      <td id=\"T_4db7c_row7_col5\" class=\"data row7 col5\" >13.40</td>\n",
       "      <td id=\"T_4db7c_row7_col6\" class=\"data row7 col6\" >31.48</td>\n",
       "      <td id=\"T_4db7c_row7_col7\" class=\"data row7 col7\" >29.26</td>\n",
       "      <td id=\"T_4db7c_row7_col8\" class=\"data row7 col8\" >8.13</td>\n",
       "      <td id=\"T_4db7c_row7_col9\" class=\"data row7 col9\" >30.90</td>\n",
       "      <td id=\"T_4db7c_row7_col10\" class=\"data row7 col10\" >12.80</td>\n",
       "      <td id=\"T_4db7c_row7_col11\" class=\"data row7 col11\" >53.92</td>\n",
       "      <td id=\"T_4db7c_row7_col12\" class=\"data row7 col12\" >25.65</td>\n",
       "      <td id=\"T_4db7c_row7_col13\" class=\"data row7 col13\" >-17.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_4db7c_row8_col0\" class=\"data row8 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.3:k=rbf:gamma=auto10000:kmd=llama7b:kemb=text+embedding:q=log+pmi:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row8_col1\" class=\"data row8 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row8_col2\" class=\"data row8 col2\" >39.34</td>\n",
       "      <td id=\"T_4db7c_row8_col3\" class=\"data row8 col3\" >35.63</td>\n",
       "      <td id=\"T_4db7c_row8_col4\" class=\"data row8 col4\" >5.20</td>\n",
       "      <td id=\"T_4db7c_row8_col5\" class=\"data row8 col5\" >11.40</td>\n",
       "      <td id=\"T_4db7c_row8_col6\" class=\"data row8 col6\" >31.94</td>\n",
       "      <td id=\"T_4db7c_row8_col7\" class=\"data row8 col7\" >28.61</td>\n",
       "      <td id=\"T_4db7c_row8_col8\" class=\"data row8 col8\" >8.58</td>\n",
       "      <td id=\"T_4db7c_row8_col9\" class=\"data row8 col9\" >31.11</td>\n",
       "      <td id=\"T_4db7c_row8_col10\" class=\"data row8 col10\" >10.98</td>\n",
       "      <td id=\"T_4db7c_row8_col11\" class=\"data row8 col11\" >53.11</td>\n",
       "      <td id=\"T_4db7c_row8_col12\" class=\"data row8 col12\" >25.59</td>\n",
       "      <td id=\"T_4db7c_row8_col13\" class=\"data row8 col13\" >-18.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_4db7c_row9_col0\" class=\"data row9 col0\" >llama-7b_wizardlm_score=random:s=1_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row9_col1\" class=\"data row9 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row9_col2\" class=\"data row9 col2\" >37.47</td>\n",
       "      <td id=\"T_4db7c_row9_col3\" class=\"data row9 col3\" >34.24</td>\n",
       "      <td id=\"T_4db7c_row9_col4\" class=\"data row9 col4\" >5.00</td>\n",
       "      <td id=\"T_4db7c_row9_col5\" class=\"data row9 col5\" >13.60</td>\n",
       "      <td id=\"T_4db7c_row9_col6\" class=\"data row9 col6\" >30.74</td>\n",
       "      <td id=\"T_4db7c_row9_col7\" class=\"data row9 col7\" >30.37</td>\n",
       "      <td id=\"T_4db7c_row9_col8\" class=\"data row9 col8\" >7.61</td>\n",
       "      <td id=\"T_4db7c_row9_col9\" class=\"data row9 col9\" >28.74</td>\n",
       "      <td id=\"T_4db7c_row9_col10\" class=\"data row9 col10\" >13.41</td>\n",
       "      <td id=\"T_4db7c_row9_col11\" class=\"data row9 col11\" >54.52</td>\n",
       "      <td id=\"T_4db7c_row9_col12\" class=\"data row9 col12\" >25.57</td>\n",
       "      <td id=\"T_4db7c_row9_col13\" class=\"data row9 col13\" >-17.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_4db7c_row10_col0\" class=\"data row10 col0\" >llama-7b_wizardlm_score=random:s=0_pace=prune:size=150000:ep=3</td>\n",
       "      <td id=\"T_4db7c_row10_col1\" class=\"data row10 col1\" >150000</td>\n",
       "      <td id=\"T_4db7c_row10_col2\" class=\"data row10 col2\" >39.80</td>\n",
       "      <td id=\"T_4db7c_row10_col3\" class=\"data row10 col3\" >35.39</td>\n",
       "      <td id=\"T_4db7c_row10_col4\" class=\"data row10 col4\" >4.00</td>\n",
       "      <td id=\"T_4db7c_row10_col5\" class=\"data row10 col5\" >11.80</td>\n",
       "      <td id=\"T_4db7c_row10_col6\" class=\"data row10 col6\" >29.63</td>\n",
       "      <td id=\"T_4db7c_row10_col7\" class=\"data row10 col7\" >28.98</td>\n",
       "      <td id=\"T_4db7c_row10_col8\" class=\"data row10 col8\" >9.11</td>\n",
       "      <td id=\"T_4db7c_row10_col9\" class=\"data row10 col9\" >27.46</td>\n",
       "      <td id=\"T_4db7c_row10_col10\" class=\"data row10 col10\" >12.80</td>\n",
       "      <td id=\"T_4db7c_row10_col11\" class=\"data row10 col11\" >55.47</td>\n",
       "      <td id=\"T_4db7c_row10_col12\" class=\"data row10 col12\" >25.45</td>\n",
       "      <td id=\"T_4db7c_row10_col13\" class=\"data row10 col13\" >-18.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_4db7c_row11_col0\" class=\"data row11 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.5:k=rbf:gamma=auto10000:kmd=llama7b:kemb=text+embedding:q=log+pmi:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row11_col1\" class=\"data row11 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row11_col2\" class=\"data row11 col2\" >38.29</td>\n",
       "      <td id=\"T_4db7c_row11_col3\" class=\"data row11 col3\" >35.63</td>\n",
       "      <td id=\"T_4db7c_row11_col4\" class=\"data row11 col4\" >5.80</td>\n",
       "      <td id=\"T_4db7c_row11_col5\" class=\"data row11 col5\" >10.00</td>\n",
       "      <td id=\"T_4db7c_row11_col6\" class=\"data row11 col6\" >32.59</td>\n",
       "      <td id=\"T_4db7c_row11_col7\" class=\"data row11 col7\" >29.44</td>\n",
       "      <td id=\"T_4db7c_row11_col8\" class=\"data row11 col8\" >8.97</td>\n",
       "      <td id=\"T_4db7c_row11_col9\" class=\"data row11 col9\" >29.82</td>\n",
       "      <td id=\"T_4db7c_row11_col10\" class=\"data row11 col10\" >10.37</td>\n",
       "      <td id=\"T_4db7c_row11_col11\" class=\"data row11 col11\" >53.06</td>\n",
       "      <td id=\"T_4db7c_row11_col12\" class=\"data row11 col12\" >25.40</td>\n",
       "      <td id=\"T_4db7c_row11_col13\" class=\"data row11 col13\" >-17.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_4db7c_row12_col0\" class=\"data row12 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=auto10000:kmd=llama7b:kemb=text+embedding_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row12_col1\" class=\"data row12 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row12_col2\" class=\"data row12 col2\" >39.20</td>\n",
       "      <td id=\"T_4db7c_row12_col3\" class=\"data row12 col3\" >35.44</td>\n",
       "      <td id=\"T_4db7c_row12_col4\" class=\"data row12 col4\" >5.00</td>\n",
       "      <td id=\"T_4db7c_row12_col5\" class=\"data row12 col5\" >12.20</td>\n",
       "      <td id=\"T_4db7c_row12_col6\" class=\"data row12 col6\" >34.44</td>\n",
       "      <td id=\"T_4db7c_row12_col7\" class=\"data row12 col7\" >28.70</td>\n",
       "      <td id=\"T_4db7c_row12_col8\" class=\"data row12 col8\" >8.49</td>\n",
       "      <td id=\"T_4db7c_row12_col9\" class=\"data row12 col9\" >25.84</td>\n",
       "      <td id=\"T_4db7c_row12_col10\" class=\"data row12 col10\" >10.98</td>\n",
       "      <td id=\"T_4db7c_row12_col11\" class=\"data row12 col11\" >53.61</td>\n",
       "      <td id=\"T_4db7c_row12_col12\" class=\"data row12 col12\" >25.39</td>\n",
       "      <td id=\"T_4db7c_row12_col13\" class=\"data row12 col13\" >-19.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_4db7c_row13_col0\" class=\"data row13 col0\" >llama-7b_wizardlm_score=random:s=0_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row13_col1\" class=\"data row13 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row13_col2\" class=\"data row13 col2\" >36.73</td>\n",
       "      <td id=\"T_4db7c_row13_col3\" class=\"data row13 col3\" >35.49</td>\n",
       "      <td id=\"T_4db7c_row13_col4\" class=\"data row13 col4\" >5.40</td>\n",
       "      <td id=\"T_4db7c_row13_col5\" class=\"data row13 col5\" >14.20</td>\n",
       "      <td id=\"T_4db7c_row13_col6\" class=\"data row13 col6\" >30.19</td>\n",
       "      <td id=\"T_4db7c_row13_col7\" class=\"data row13 col7\" >29.44</td>\n",
       "      <td id=\"T_4db7c_row13_col8\" class=\"data row13 col8\" >8.45</td>\n",
       "      <td id=\"T_4db7c_row13_col9\" class=\"data row13 col9\" >26.08</td>\n",
       "      <td id=\"T_4db7c_row13_col10\" class=\"data row13 col10\" >13.41</td>\n",
       "      <td id=\"T_4db7c_row13_col11\" class=\"data row13 col11\" >52.98</td>\n",
       "      <td id=\"T_4db7c_row13_col12\" class=\"data row13 col12\" >25.24</td>\n",
       "      <td id=\"T_4db7c_row13_col13\" class=\"data row13 col13\" >-17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_4db7c_row14_col0\" class=\"data row14 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=0.13:kmd=mpnet_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row14_col1\" class=\"data row14 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row14_col2\" class=\"data row14 col2\" >37.22</td>\n",
       "      <td id=\"T_4db7c_row14_col3\" class=\"data row14 col3\" >34.10</td>\n",
       "      <td id=\"T_4db7c_row14_col4\" class=\"data row14 col4\" >5.80</td>\n",
       "      <td id=\"T_4db7c_row14_col5\" class=\"data row14 col5\" >11.80</td>\n",
       "      <td id=\"T_4db7c_row14_col6\" class=\"data row14 col6\" >33.70</td>\n",
       "      <td id=\"T_4db7c_row14_col7\" class=\"data row14 col7\" >29.54</td>\n",
       "      <td id=\"T_4db7c_row14_col8\" class=\"data row14 col8\" >8.25</td>\n",
       "      <td id=\"T_4db7c_row14_col9\" class=\"data row14 col9\" >29.84</td>\n",
       "      <td id=\"T_4db7c_row14_col10\" class=\"data row14 col10\" >8.54</td>\n",
       "      <td id=\"T_4db7c_row14_col11\" class=\"data row14 col11\" >52.99</td>\n",
       "      <td id=\"T_4db7c_row14_col12\" class=\"data row14 col12\" >25.18</td>\n",
       "      <td id=\"T_4db7c_row14_col13\" class=\"data row14 col13\" >-19.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_4db7c_row15_col0\" class=\"data row15 col0\" >llama-7b_wizardlm_score=random:s=0_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_4db7c_row15_col1\" class=\"data row15 col1\" >100000</td>\n",
       "      <td id=\"T_4db7c_row15_col2\" class=\"data row15 col2\" >39.33</td>\n",
       "      <td id=\"T_4db7c_row15_col3\" class=\"data row15 col3\" >35.36</td>\n",
       "      <td id=\"T_4db7c_row15_col4\" class=\"data row15 col4\" >4.60</td>\n",
       "      <td id=\"T_4db7c_row15_col5\" class=\"data row15 col5\" >9.60</td>\n",
       "      <td id=\"T_4db7c_row15_col6\" class=\"data row15 col6\" >29.35</td>\n",
       "      <td id=\"T_4db7c_row15_col7\" class=\"data row15 col7\" >29.54</td>\n",
       "      <td id=\"T_4db7c_row15_col8\" class=\"data row15 col8\" >7.97</td>\n",
       "      <td id=\"T_4db7c_row15_col9\" class=\"data row15 col9\" >28.67</td>\n",
       "      <td id=\"T_4db7c_row15_col10\" class=\"data row15 col10\" >13.41</td>\n",
       "      <td id=\"T_4db7c_row15_col11\" class=\"data row15 col11\" >53.42</td>\n",
       "      <td id=\"T_4db7c_row15_col12\" class=\"data row15 col12\" >25.13</td>\n",
       "      <td id=\"T_4db7c_row15_col13\" class=\"data row15 col13\" >-21.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_4db7c_row16_col0\" class=\"data row16 col0\" >llama-7b_wizardlm_score=dppmap:k=lin:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_4db7c_row16_col1\" class=\"data row16 col1\" >100000</td>\n",
       "      <td id=\"T_4db7c_row16_col2\" class=\"data row16 col2\" >34.73</td>\n",
       "      <td id=\"T_4db7c_row16_col3\" class=\"data row16 col3\" >33.99</td>\n",
       "      <td id=\"T_4db7c_row16_col4\" class=\"data row16 col4\" >4.40</td>\n",
       "      <td id=\"T_4db7c_row16_col5\" class=\"data row16 col5\" >13.40</td>\n",
       "      <td id=\"T_4db7c_row16_col6\" class=\"data row16 col6\" >32.78</td>\n",
       "      <td id=\"T_4db7c_row16_col7\" class=\"data row16 col7\" >28.70</td>\n",
       "      <td id=\"T_4db7c_row16_col8\" class=\"data row16 col8\" >9.22</td>\n",
       "      <td id=\"T_4db7c_row16_col9\" class=\"data row16 col9\" >29.88</td>\n",
       "      <td id=\"T_4db7c_row16_col10\" class=\"data row16 col10\" >10.98</td>\n",
       "      <td id=\"T_4db7c_row16_col11\" class=\"data row16 col11\" >51.55</td>\n",
       "      <td id=\"T_4db7c_row16_col12\" class=\"data row16 col12\" >24.96</td>\n",
       "      <td id=\"T_4db7c_row16_col13\" class=\"data row16 col13\" >-22.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_4db7c_row17_col0\" class=\"data row17 col0\" >llama-7b_wizardlm_score=random:s=1_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_4db7c_row17_col1\" class=\"data row17 col1\" >100000</td>\n",
       "      <td id=\"T_4db7c_row17_col2\" class=\"data row17 col2\" >36.08</td>\n",
       "      <td id=\"T_4db7c_row17_col3\" class=\"data row17 col3\" >33.93</td>\n",
       "      <td id=\"T_4db7c_row17_col4\" class=\"data row17 col4\" >5.20</td>\n",
       "      <td id=\"T_4db7c_row17_col5\" class=\"data row17 col5\" >12.20</td>\n",
       "      <td id=\"T_4db7c_row17_col6\" class=\"data row17 col6\" >31.20</td>\n",
       "      <td id=\"T_4db7c_row17_col7\" class=\"data row17 col7\" >27.69</td>\n",
       "      <td id=\"T_4db7c_row17_col8\" class=\"data row17 col8\" >7.61</td>\n",
       "      <td id=\"T_4db7c_row17_col9\" class=\"data row17 col9\" >25.99</td>\n",
       "      <td id=\"T_4db7c_row17_col10\" class=\"data row17 col10\" >14.02</td>\n",
       "      <td id=\"T_4db7c_row17_col11\" class=\"data row17 col11\" >54.47</td>\n",
       "      <td id=\"T_4db7c_row17_col12\" class=\"data row17 col12\" >24.84</td>\n",
       "      <td id=\"T_4db7c_row17_col13\" class=\"data row17 col13\" >-24.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_4db7c_row18_col0\" class=\"data row18 col0\" >llama-7b_wizardlm_score=log:pmi:neg_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row18_col1\" class=\"data row18 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row18_col2\" class=\"data row18 col2\" >37.01</td>\n",
       "      <td id=\"T_4db7c_row18_col3\" class=\"data row18 col3\" >36.61</td>\n",
       "      <td id=\"T_4db7c_row18_col4\" class=\"data row18 col4\" >5.20</td>\n",
       "      <td id=\"T_4db7c_row18_col5\" class=\"data row18 col5\" >9.40</td>\n",
       "      <td id=\"T_4db7c_row18_col6\" class=\"data row18 col6\" >32.69</td>\n",
       "      <td id=\"T_4db7c_row18_col7\" class=\"data row18 col7\" >29.07</td>\n",
       "      <td id=\"T_4db7c_row18_col8\" class=\"data row18 col8\" >8.23</td>\n",
       "      <td id=\"T_4db7c_row18_col9\" class=\"data row18 col9\" >27.94</td>\n",
       "      <td id=\"T_4db7c_row18_col10\" class=\"data row18 col10\" >9.15</td>\n",
       "      <td id=\"T_4db7c_row18_col11\" class=\"data row18 col11\" >52.43</td>\n",
       "      <td id=\"T_4db7c_row18_col12\" class=\"data row18 col12\" >24.77</td>\n",
       "      <td id=\"T_4db7c_row18_col13\" class=\"data row18 col13\" >-23.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_4db7c_row19_col0\" class=\"data row19 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=auto10000:kmd=llama7b:kemb=grad+rp+loraB_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row19_col1\" class=\"data row19 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row19_col2\" class=\"data row19 col2\" >37.15</td>\n",
       "      <td id=\"T_4db7c_row19_col3\" class=\"data row19 col3\" >33.85</td>\n",
       "      <td id=\"T_4db7c_row19_col4\" class=\"data row19 col4\" >6.00</td>\n",
       "      <td id=\"T_4db7c_row19_col5\" class=\"data row19 col5\" >16.80</td>\n",
       "      <td id=\"T_4db7c_row19_col6\" class=\"data row19 col6\" >25.46</td>\n",
       "      <td id=\"T_4db7c_row19_col7\" class=\"data row19 col7\" >29.44</td>\n",
       "      <td id=\"T_4db7c_row19_col8\" class=\"data row19 col8\" >6.69</td>\n",
       "      <td id=\"T_4db7c_row19_col9\" class=\"data row19 col9\" >25.35</td>\n",
       "      <td id=\"T_4db7c_row19_col10\" class=\"data row19 col10\" >8.54</td>\n",
       "      <td id=\"T_4db7c_row19_col11\" class=\"data row19 col11\" >56.64</td>\n",
       "      <td id=\"T_4db7c_row19_col12\" class=\"data row19 col12\" >24.59</td>\n",
       "      <td id=\"T_4db7c_row19_col13\" class=\"data row19 col13\" >-23.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_4db7c_row20_col0\" class=\"data row20 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.3:k=vmf:gamma=0.04:kmd=mpnet:q=ifd:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row20_col1\" class=\"data row20 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row20_col2\" class=\"data row20 col2\" >35.23</td>\n",
       "      <td id=\"T_4db7c_row20_col3\" class=\"data row20 col3\" >34.81</td>\n",
       "      <td id=\"T_4db7c_row20_col4\" class=\"data row20 col4\" >6.20</td>\n",
       "      <td id=\"T_4db7c_row20_col5\" class=\"data row20 col5\" >9.80</td>\n",
       "      <td id=\"T_4db7c_row20_col6\" class=\"data row20 col6\" >30.65</td>\n",
       "      <td id=\"T_4db7c_row20_col7\" class=\"data row20 col7\" >29.17</td>\n",
       "      <td id=\"T_4db7c_row20_col8\" class=\"data row20 col8\" >7.97</td>\n",
       "      <td id=\"T_4db7c_row20_col9\" class=\"data row20 col9\" >26.75</td>\n",
       "      <td id=\"T_4db7c_row20_col10\" class=\"data row20 col10\" >10.37</td>\n",
       "      <td id=\"T_4db7c_row20_col11\" class=\"data row20 col11\" >54.67</td>\n",
       "      <td id=\"T_4db7c_row20_col12\" class=\"data row20 col12\" >24.56</td>\n",
       "      <td id=\"T_4db7c_row20_col13\" class=\"data row20 col13\" >-24.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_4db7c_row21_col0\" class=\"data row21 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.3:k=vmf:gamma=0.043:kmd=mpnet:q=ifd+neg:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row21_col1\" class=\"data row21 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row21_col2\" class=\"data row21 col2\" >34.64</td>\n",
       "      <td id=\"T_4db7c_row21_col3\" class=\"data row21 col3\" >31.95</td>\n",
       "      <td id=\"T_4db7c_row21_col4\" class=\"data row21 col4\" >5.40</td>\n",
       "      <td id=\"T_4db7c_row21_col5\" class=\"data row21 col5\" >10.00</td>\n",
       "      <td id=\"T_4db7c_row21_col6\" class=\"data row21 col6\" >29.17</td>\n",
       "      <td id=\"T_4db7c_row21_col7\" class=\"data row21 col7\" >31.48</td>\n",
       "      <td id=\"T_4db7c_row21_col8\" class=\"data row21 col8\" >8.60</td>\n",
       "      <td id=\"T_4db7c_row21_col9\" class=\"data row21 col9\" >26.13</td>\n",
       "      <td id=\"T_4db7c_row21_col10\" class=\"data row21 col10\" >14.02</td>\n",
       "      <td id=\"T_4db7c_row21_col11\" class=\"data row21 col11\" >52.79</td>\n",
       "      <td id=\"T_4db7c_row21_col12\" class=\"data row21 col12\" >24.42</td>\n",
       "      <td id=\"T_4db7c_row21_col13\" class=\"data row21 col13\" >-25.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_4db7c_row22_col0\" class=\"data row22 col0\" >llama-7b_wizardlm_score=ifd_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_4db7c_row22_col1\" class=\"data row22 col1\" >100000</td>\n",
       "      <td id=\"T_4db7c_row22_col2\" class=\"data row22 col2\" >38.01</td>\n",
       "      <td id=\"T_4db7c_row22_col3\" class=\"data row22 col3\" >34.90</td>\n",
       "      <td id=\"T_4db7c_row22_col4\" class=\"data row22 col4\" >5.80</td>\n",
       "      <td id=\"T_4db7c_row22_col5\" class=\"data row22 col5\" >9.20</td>\n",
       "      <td id=\"T_4db7c_row22_col6\" class=\"data row22 col6\" >31.76</td>\n",
       "      <td id=\"T_4db7c_row22_col7\" class=\"data row22 col7\" >30.83</td>\n",
       "      <td id=\"T_4db7c_row22_col8\" class=\"data row22 col8\" >8.35</td>\n",
       "      <td id=\"T_4db7c_row22_col9\" class=\"data row22 col9\" >25.32</td>\n",
       "      <td id=\"T_4db7c_row22_col10\" class=\"data row22 col10\" >9.15</td>\n",
       "      <td id=\"T_4db7c_row22_col11\" class=\"data row22 col11\" >49.75</td>\n",
       "      <td id=\"T_4db7c_row22_col12\" class=\"data row22 col12\" >24.31</td>\n",
       "      <td id=\"T_4db7c_row22_col13\" class=\"data row22 col13\" >-23.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_4db7c_row23_col0\" class=\"data row23 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=auto1000:kmd=llama7b:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_4db7c_row23_col1\" class=\"data row23 col1\" >10000</td>\n",
       "      <td id=\"T_4db7c_row23_col2\" class=\"data row23 col2\" >34.76</td>\n",
       "      <td id=\"T_4db7c_row23_col3\" class=\"data row23 col3\" >33.86</td>\n",
       "      <td id=\"T_4db7c_row23_col4\" class=\"data row23 col4\" >6.00</td>\n",
       "      <td id=\"T_4db7c_row23_col5\" class=\"data row23 col5\" >11.60</td>\n",
       "      <td id=\"T_4db7c_row23_col6\" class=\"data row23 col6\" >26.85</td>\n",
       "      <td id=\"T_4db7c_row23_col7\" class=\"data row23 col7\" >28.98</td>\n",
       "      <td id=\"T_4db7c_row23_col8\" class=\"data row23 col8\" >8.97</td>\n",
       "      <td id=\"T_4db7c_row23_col9\" class=\"data row23 col9\" >31.01</td>\n",
       "      <td id=\"T_4db7c_row23_col10\" class=\"data row23 col10\" >11.59</td>\n",
       "      <td id=\"T_4db7c_row23_col11\" class=\"data row23 col11\" >48.39</td>\n",
       "      <td id=\"T_4db7c_row23_col12\" class=\"data row23 col12\" >24.20</td>\n",
       "      <td id=\"T_4db7c_row23_col13\" class=\"data row23 col13\" >-24.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_4db7c_row24_col0\" class=\"data row24 col0\" >llama-7b_wizardlm_score=dppmap:k=lin:kmd=mpnet_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_4db7c_row24_col1\" class=\"data row24 col1\" >10000</td>\n",
       "      <td id=\"T_4db7c_row24_col2\" class=\"data row24 col2\" >33.11</td>\n",
       "      <td id=\"T_4db7c_row24_col3\" class=\"data row24 col3\" >34.45</td>\n",
       "      <td id=\"T_4db7c_row24_col4\" class=\"data row24 col4\" >5.20</td>\n",
       "      <td id=\"T_4db7c_row24_col5\" class=\"data row24 col5\" >12.40</td>\n",
       "      <td id=\"T_4db7c_row24_col6\" class=\"data row24 col6\" >30.37</td>\n",
       "      <td id=\"T_4db7c_row24_col7\" class=\"data row24 col7\" >28.24</td>\n",
       "      <td id=\"T_4db7c_row24_col8\" class=\"data row24 col8\" >9.05</td>\n",
       "      <td id=\"T_4db7c_row24_col9\" class=\"data row24 col9\" >30.12</td>\n",
       "      <td id=\"T_4db7c_row24_col10\" class=\"data row24 col10\" >12.80</td>\n",
       "      <td id=\"T_4db7c_row24_col11\" class=\"data row24 col11\" >45.78</td>\n",
       "      <td id=\"T_4db7c_row24_col12\" class=\"data row24 col12\" >24.15</td>\n",
       "      <td id=\"T_4db7c_row24_col13\" class=\"data row24 col13\" >-23.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_4db7c_row25_col0\" class=\"data row25 col0\" >llama-7b_wizardlm_score=log:prob:neg_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_4db7c_row25_col1\" class=\"data row25 col1\" >100000</td>\n",
       "      <td id=\"T_4db7c_row25_col2\" class=\"data row25 col2\" >36.44</td>\n",
       "      <td id=\"T_4db7c_row25_col3\" class=\"data row25 col3\" >32.77</td>\n",
       "      <td id=\"T_4db7c_row25_col4\" class=\"data row25 col4\" >5.00</td>\n",
       "      <td id=\"T_4db7c_row25_col5\" class=\"data row25 col5\" >14.20</td>\n",
       "      <td id=\"T_4db7c_row25_col6\" class=\"data row25 col6\" >27.41</td>\n",
       "      <td id=\"T_4db7c_row25_col7\" class=\"data row25 col7\" >30.28</td>\n",
       "      <td id=\"T_4db7c_row25_col8\" class=\"data row25 col8\" >9.11</td>\n",
       "      <td id=\"T_4db7c_row25_col9\" class=\"data row25 col9\" >21.56</td>\n",
       "      <td id=\"T_4db7c_row25_col10\" class=\"data row25 col10\" >11.59</td>\n",
       "      <td id=\"T_4db7c_row25_col11\" class=\"data row25 col11\" >50.43</td>\n",
       "      <td id=\"T_4db7c_row25_col12\" class=\"data row25 col12\" >23.88</td>\n",
       "      <td id=\"T_4db7c_row25_col13\" class=\"data row25 col13\" >-24.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_4db7c_row26_col0\" class=\"data row26 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=0.008:kmd=mpnet_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_4db7c_row26_col1\" class=\"data row26 col1\" >10000</td>\n",
       "      <td id=\"T_4db7c_row26_col2\" class=\"data row26 col2\" >33.61</td>\n",
       "      <td id=\"T_4db7c_row26_col3\" class=\"data row26 col3\" >33.28</td>\n",
       "      <td id=\"T_4db7c_row26_col4\" class=\"data row26 col4\" >6.20</td>\n",
       "      <td id=\"T_4db7c_row26_col5\" class=\"data row26 col5\" >12.20</td>\n",
       "      <td id=\"T_4db7c_row26_col6\" class=\"data row26 col6\" >27.87</td>\n",
       "      <td id=\"T_4db7c_row26_col7\" class=\"data row26 col7\" >28.89</td>\n",
       "      <td id=\"T_4db7c_row26_col8\" class=\"data row26 col8\" >8.40</td>\n",
       "      <td id=\"T_4db7c_row26_col9\" class=\"data row26 col9\" >29.33</td>\n",
       "      <td id=\"T_4db7c_row26_col10\" class=\"data row26 col10\" >12.80</td>\n",
       "      <td id=\"T_4db7c_row26_col11\" class=\"data row26 col11\" >45.78</td>\n",
       "      <td id=\"T_4db7c_row26_col12\" class=\"data row26 col12\" >23.84</td>\n",
       "      <td id=\"T_4db7c_row26_col13\" class=\"data row26 col13\" >-25.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_4db7c_row27_col0\" class=\"data row27 col0\" >llama-7b_wizardlm_score=dedup:md=mpnet:emb=text+embedding_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row27_col1\" class=\"data row27 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row27_col2\" class=\"data row27 col2\" >36.02</td>\n",
       "      <td id=\"T_4db7c_row27_col3\" class=\"data row27 col3\" >33.74</td>\n",
       "      <td id=\"T_4db7c_row27_col4\" class=\"data row27 col4\" >4.00</td>\n",
       "      <td id=\"T_4db7c_row27_col5\" class=\"data row27 col5\" >12.20</td>\n",
       "      <td id=\"T_4db7c_row27_col6\" class=\"data row27 col6\" >26.85</td>\n",
       "      <td id=\"T_4db7c_row27_col7\" class=\"data row27 col7\" >29.44</td>\n",
       "      <td id=\"T_4db7c_row27_col8\" class=\"data row27 col8\" >9.00</td>\n",
       "      <td id=\"T_4db7c_row27_col9\" class=\"data row27 col9\" >28.50</td>\n",
       "      <td id=\"T_4db7c_row27_col10\" class=\"data row27 col10\" >4.27</td>\n",
       "      <td id=\"T_4db7c_row27_col11\" class=\"data row27 col11\" >54.03</td>\n",
       "      <td id=\"T_4db7c_row27_col12\" class=\"data row27 col12\" >23.81</td>\n",
       "      <td id=\"T_4db7c_row27_col13\" class=\"data row27 col13\" >-27.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_4db7c_row28_col0\" class=\"data row28 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.3:k=vmf:gamma=0.01:kmd=mpnet:q=log+pmi:qmd=llama7b_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_4db7c_row28_col1\" class=\"data row28 col1\" >10000</td>\n",
       "      <td id=\"T_4db7c_row28_col2\" class=\"data row28 col2\" >33.82</td>\n",
       "      <td id=\"T_4db7c_row28_col3\" class=\"data row28 col3\" >34.39</td>\n",
       "      <td id=\"T_4db7c_row28_col4\" class=\"data row28 col4\" >5.80</td>\n",
       "      <td id=\"T_4db7c_row28_col5\" class=\"data row28 col5\" >11.40</td>\n",
       "      <td id=\"T_4db7c_row28_col6\" class=\"data row28 col6\" >30.00</td>\n",
       "      <td id=\"T_4db7c_row28_col7\" class=\"data row28 col7\" >27.59</td>\n",
       "      <td id=\"T_4db7c_row28_col8\" class=\"data row28 col8\" >9.95</td>\n",
       "      <td id=\"T_4db7c_row28_col9\" class=\"data row28 col9\" >29.89</td>\n",
       "      <td id=\"T_4db7c_row28_col10\" class=\"data row28 col10\" >12.20</td>\n",
       "      <td id=\"T_4db7c_row28_col11\" class=\"data row28 col11\" >42.96</td>\n",
       "      <td id=\"T_4db7c_row28_col12\" class=\"data row28 col12\" >23.80</td>\n",
       "      <td id=\"T_4db7c_row28_col13\" class=\"data row28 col13\" >-25.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_4db7c_row29_col0\" class=\"data row29 col0\" >llama-7b_wizardlm_score=random:s=1_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_4db7c_row29_col1\" class=\"data row29 col1\" >10000</td>\n",
       "      <td id=\"T_4db7c_row29_col2\" class=\"data row29 col2\" >33.42</td>\n",
       "      <td id=\"T_4db7c_row29_col3\" class=\"data row29 col3\" >33.52</td>\n",
       "      <td id=\"T_4db7c_row29_col4\" class=\"data row29 col4\" >4.60</td>\n",
       "      <td id=\"T_4db7c_row29_col5\" class=\"data row29 col5\" >11.40</td>\n",
       "      <td id=\"T_4db7c_row29_col6\" class=\"data row29 col6\" >31.20</td>\n",
       "      <td id=\"T_4db7c_row29_col7\" class=\"data row29 col7\" >29.91</td>\n",
       "      <td id=\"T_4db7c_row29_col8\" class=\"data row29 col8\" >10.47</td>\n",
       "      <td id=\"T_4db7c_row29_col9\" class=\"data row29 col9\" >27.51</td>\n",
       "      <td id=\"T_4db7c_row29_col10\" class=\"data row29 col10\" >13.41</td>\n",
       "      <td id=\"T_4db7c_row29_col11\" class=\"data row29 col11\" >42.30</td>\n",
       "      <td id=\"T_4db7c_row29_col12\" class=\"data row29 col12\" >23.78</td>\n",
       "      <td id=\"T_4db7c_row29_col13\" class=\"data row29 col13\" >-25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_4db7c_row30_col0\" class=\"data row30 col0\" >llama-7b_wizardlm_score=dppmap:k=rbf:gamma=0.001:kmd=llama7b:kemb=grad+rp+loraB_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row30_col1\" class=\"data row30 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row30_col2\" class=\"data row30 col2\" >37.96</td>\n",
       "      <td id=\"T_4db7c_row30_col3\" class=\"data row30 col3\" >36.88</td>\n",
       "      <td id=\"T_4db7c_row30_col4\" class=\"data row30 col4\" >5.60</td>\n",
       "      <td id=\"T_4db7c_row30_col5\" class=\"data row30 col5\" >9.00</td>\n",
       "      <td id=\"T_4db7c_row30_col6\" class=\"data row30 col6\" >29.44</td>\n",
       "      <td id=\"T_4db7c_row30_col7\" class=\"data row30 col7\" >28.80</td>\n",
       "      <td id=\"T_4db7c_row30_col8\" class=\"data row30 col8\" >7.52</td>\n",
       "      <td id=\"T_4db7c_row30_col9\" class=\"data row30 col9\" >26.96</td>\n",
       "      <td id=\"T_4db7c_row30_col10\" class=\"data row30 col10\" >9.76</td>\n",
       "      <td id=\"T_4db7c_row30_col11\" class=\"data row30 col11\" >45.47</td>\n",
       "      <td id=\"T_4db7c_row30_col12\" class=\"data row30 col12\" >23.74</td>\n",
       "      <td id=\"T_4db7c_row30_col13\" class=\"data row30 col13\" >-28.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_4db7c_row31_col0\" class=\"data row31 col0\" >llama-7b_wizardlm_score=ifd:neg_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_4db7c_row31_col1\" class=\"data row31 col1\" >100000</td>\n",
       "      <td id=\"T_4db7c_row31_col2\" class=\"data row31 col2\" >35.42</td>\n",
       "      <td id=\"T_4db7c_row31_col3\" class=\"data row31 col3\" >33.51</td>\n",
       "      <td id=\"T_4db7c_row31_col4\" class=\"data row31 col4\" >3.40</td>\n",
       "      <td id=\"T_4db7c_row31_col5\" class=\"data row31 col5\" >10.80</td>\n",
       "      <td id=\"T_4db7c_row31_col6\" class=\"data row31 col6\" >27.78</td>\n",
       "      <td id=\"T_4db7c_row31_col7\" class=\"data row31 col7\" >28.89</td>\n",
       "      <td id=\"T_4db7c_row31_col8\" class=\"data row31 col8\" >8.10</td>\n",
       "      <td id=\"T_4db7c_row31_col9\" class=\"data row31 col9\" >25.53</td>\n",
       "      <td id=\"T_4db7c_row31_col10\" class=\"data row31 col10\" >11.59</td>\n",
       "      <td id=\"T_4db7c_row31_col11\" class=\"data row31 col11\" >51.36</td>\n",
       "      <td id=\"T_4db7c_row31_col12\" class=\"data row31 col12\" >23.64</td>\n",
       "      <td id=\"T_4db7c_row31_col13\" class=\"data row31 col13\" >-33.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_4db7c_row32_col0\" class=\"data row32 col0\" >llama-7b_wizardlm_score=ifd_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row32_col1\" class=\"data row32 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row32_col2\" class=\"data row32 col2\" >38.89</td>\n",
       "      <td id=\"T_4db7c_row32_col3\" class=\"data row32 col3\" >34.05</td>\n",
       "      <td id=\"T_4db7c_row32_col4\" class=\"data row32 col4\" >4.20</td>\n",
       "      <td id=\"T_4db7c_row32_col5\" class=\"data row32 col5\" >11.80</td>\n",
       "      <td id=\"T_4db7c_row32_col6\" class=\"data row32 col6\" >28.98</td>\n",
       "      <td id=\"T_4db7c_row32_col7\" class=\"data row32 col7\" >30.00</td>\n",
       "      <td id=\"T_4db7c_row32_col8\" class=\"data row32 col8\" >8.22</td>\n",
       "      <td id=\"T_4db7c_row32_col9\" class=\"data row32 col9\" >25.79</td>\n",
       "      <td id=\"T_4db7c_row32_col10\" class=\"data row32 col10\" >10.98</td>\n",
       "      <td id=\"T_4db7c_row32_col11\" class=\"data row32 col11\" >41.30</td>\n",
       "      <td id=\"T_4db7c_row32_col12\" class=\"data row32 col12\" >23.42</td>\n",
       "      <td id=\"T_4db7c_row32_col13\" class=\"data row32 col13\" >-28.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_4db7c_row33_col0\" class=\"data row33 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.5:k=vmf:gamma=0.01:kmd=mpnet:q=log+pmi:qmd=llama7b_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_4db7c_row33_col1\" class=\"data row33 col1\" >10000</td>\n",
       "      <td id=\"T_4db7c_row33_col2\" class=\"data row33 col2\" >31.80</td>\n",
       "      <td id=\"T_4db7c_row33_col3\" class=\"data row33 col3\" >33.19</td>\n",
       "      <td id=\"T_4db7c_row33_col4\" class=\"data row33 col4\" >5.00</td>\n",
       "      <td id=\"T_4db7c_row33_col5\" class=\"data row33 col5\" >11.20</td>\n",
       "      <td id=\"T_4db7c_row33_col6\" class=\"data row33 col6\" >27.78</td>\n",
       "      <td id=\"T_4db7c_row33_col7\" class=\"data row33 col7\" >27.59</td>\n",
       "      <td id=\"T_4db7c_row33_col8\" class=\"data row33 col8\" >8.07</td>\n",
       "      <td id=\"T_4db7c_row33_col9\" class=\"data row33 col9\" >30.37</td>\n",
       "      <td id=\"T_4db7c_row33_col10\" class=\"data row33 col10\" >12.80</td>\n",
       "      <td id=\"T_4db7c_row33_col11\" class=\"data row33 col11\" >44.13</td>\n",
       "      <td id=\"T_4db7c_row33_col12\" class=\"data row33 col12\" >23.19</td>\n",
       "      <td id=\"T_4db7c_row33_col13\" class=\"data row33 col13\" >-32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_4db7c_row34_col0\" class=\"data row34 col0\" >llama-7b_wizardlm_score=el2n:agg=mean_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row34_col1\" class=\"data row34 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row34_col2\" class=\"data row34 col2\" >34.50</td>\n",
       "      <td id=\"T_4db7c_row34_col3\" class=\"data row34 col3\" >33.00</td>\n",
       "      <td id=\"T_4db7c_row34_col4\" class=\"data row34 col4\" >5.20</td>\n",
       "      <td id=\"T_4db7c_row34_col5\" class=\"data row34 col5\" >12.40</td>\n",
       "      <td id=\"T_4db7c_row34_col6\" class=\"data row34 col6\" >30.46</td>\n",
       "      <td id=\"T_4db7c_row34_col7\" class=\"data row34 col7\" >29.35</td>\n",
       "      <td id=\"T_4db7c_row34_col8\" class=\"data row34 col8\" >8.91</td>\n",
       "      <td id=\"T_4db7c_row34_col9\" class=\"data row34 col9\" >21.59</td>\n",
       "      <td id=\"T_4db7c_row34_col10\" class=\"data row34 col10\" >10.98</td>\n",
       "      <td id=\"T_4db7c_row34_col11\" class=\"data row34 col11\" >45.40</td>\n",
       "      <td id=\"T_4db7c_row34_col12\" class=\"data row34 col12\" >23.18</td>\n",
       "      <td id=\"T_4db7c_row34_col13\" class=\"data row34 col13\" >-29.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_4db7c_row35_col0\" class=\"data row35 col0\" >llama-7b_wizardlm_score=log:prob:neg_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row35_col1\" class=\"data row35 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row35_col2\" class=\"data row35 col2\" >36.06</td>\n",
       "      <td id=\"T_4db7c_row35_col3\" class=\"data row35 col3\" >32.08</td>\n",
       "      <td id=\"T_4db7c_row35_col4\" class=\"data row35 col4\" >6.00</td>\n",
       "      <td id=\"T_4db7c_row35_col5\" class=\"data row35 col5\" >13.80</td>\n",
       "      <td id=\"T_4db7c_row35_col6\" class=\"data row35 col6\" >26.67</td>\n",
       "      <td id=\"T_4db7c_row35_col7\" class=\"data row35 col7\" >29.91</td>\n",
       "      <td id=\"T_4db7c_row35_col8\" class=\"data row35 col8\" >7.46</td>\n",
       "      <td id=\"T_4db7c_row35_col9\" class=\"data row35 col9\" >26.58</td>\n",
       "      <td id=\"T_4db7c_row35_col10\" class=\"data row35 col10\" >7.32</td>\n",
       "      <td id=\"T_4db7c_row35_col11\" class=\"data row35 col11\" >45.65</td>\n",
       "      <td id=\"T_4db7c_row35_col12\" class=\"data row35 col12\" >23.15</td>\n",
       "      <td id=\"T_4db7c_row35_col13\" class=\"data row35 col13\" >-29.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_4db7c_row36_col0\" class=\"data row36 col0\" >llama-7b_wizardlm_score=random:s=0_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_4db7c_row36_col1\" class=\"data row36 col1\" >10000</td>\n",
       "      <td id=\"T_4db7c_row36_col2\" class=\"data row36 col2\" >30.42</td>\n",
       "      <td id=\"T_4db7c_row36_col3\" class=\"data row36 col3\" >32.39</td>\n",
       "      <td id=\"T_4db7c_row36_col4\" class=\"data row36 col4\" >5.40</td>\n",
       "      <td id=\"T_4db7c_row36_col5\" class=\"data row36 col5\" >12.40</td>\n",
       "      <td id=\"T_4db7c_row36_col6\" class=\"data row36 col6\" >32.13</td>\n",
       "      <td id=\"T_4db7c_row36_col7\" class=\"data row36 col7\" >28.80</td>\n",
       "      <td id=\"T_4db7c_row36_col8\" class=\"data row36 col8\" >9.29</td>\n",
       "      <td id=\"T_4db7c_row36_col9\" class=\"data row36 col9\" >25.16</td>\n",
       "      <td id=\"T_4db7c_row36_col10\" class=\"data row36 col10\" >10.98</td>\n",
       "      <td id=\"T_4db7c_row36_col11\" class=\"data row36 col11\" >43.47</td>\n",
       "      <td id=\"T_4db7c_row36_col12\" class=\"data row36 col12\" >23.04</td>\n",
       "      <td id=\"T_4db7c_row36_col13\" class=\"data row36 col13\" >-28.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_4db7c_row37_col0\" class=\"data row37 col0\" >llama-7b_wizardlm_score=dppmap:k=rbf:gamma=3.5e-8:kmd=llama7b:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_4db7c_row37_col1\" class=\"data row37 col1\" >10000</td>\n",
       "      <td id=\"T_4db7c_row37_col2\" class=\"data row37 col2\" >31.97</td>\n",
       "      <td id=\"T_4db7c_row37_col3\" class=\"data row37 col3\" >32.97</td>\n",
       "      <td id=\"T_4db7c_row37_col4\" class=\"data row37 col4\" >5.00</td>\n",
       "      <td id=\"T_4db7c_row37_col5\" class=\"data row37 col5\" >12.00</td>\n",
       "      <td id=\"T_4db7c_row37_col6\" class=\"data row37 col6\" >20.09</td>\n",
       "      <td id=\"T_4db7c_row37_col7\" class=\"data row37 col7\" >25.00</td>\n",
       "      <td id=\"T_4db7c_row37_col8\" class=\"data row37 col8\" >9.44</td>\n",
       "      <td id=\"T_4db7c_row37_col9\" class=\"data row37 col9\" >27.96</td>\n",
       "      <td id=\"T_4db7c_row37_col10\" class=\"data row37 col10\" >12.80</td>\n",
       "      <td id=\"T_4db7c_row37_col11\" class=\"data row37 col11\" >50.62</td>\n",
       "      <td id=\"T_4db7c_row37_col12\" class=\"data row37 col12\" >22.78</td>\n",
       "      <td id=\"T_4db7c_row37_col13\" class=\"data row37 col13\" >-30.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_4db7c_row38_col0\" class=\"data row38 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=auto1000:kmd=llama7b:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_4db7c_row38_col1\" class=\"data row38 col1\" >10000</td>\n",
       "      <td id=\"T_4db7c_row38_col2\" class=\"data row38 col2\" >32.45</td>\n",
       "      <td id=\"T_4db7c_row38_col3\" class=\"data row38 col3\" >31.36</td>\n",
       "      <td id=\"T_4db7c_row38_col4\" class=\"data row38 col4\" >5.80</td>\n",
       "      <td id=\"T_4db7c_row38_col5\" class=\"data row38 col5\" >12.40</td>\n",
       "      <td id=\"T_4db7c_row38_col6\" class=\"data row38 col6\" >28.98</td>\n",
       "      <td id=\"T_4db7c_row38_col7\" class=\"data row38 col7\" >27.87</td>\n",
       "      <td id=\"T_4db7c_row38_col8\" class=\"data row38 col8\" >9.58</td>\n",
       "      <td id=\"T_4db7c_row38_col9\" class=\"data row38 col9\" >27.46</td>\n",
       "      <td id=\"T_4db7c_row38_col10\" class=\"data row38 col10\" >11.59</td>\n",
       "      <td id=\"T_4db7c_row38_col11\" class=\"data row38 col11\" >39.45</td>\n",
       "      <td id=\"T_4db7c_row38_col12\" class=\"data row38 col12\" >22.69</td>\n",
       "      <td id=\"T_4db7c_row38_col13\" class=\"data row38 col13\" >-29.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_4db7c_row39_col0\" class=\"data row39 col0\" >llama-7b_wizardlm_ep=2</td>\n",
       "      <td id=\"T_4db7c_row39_col1\" class=\"data row39 col1\" >None</td>\n",
       "      <td id=\"T_4db7c_row39_col2\" class=\"data row39 col2\" >38.06</td>\n",
       "      <td id=\"T_4db7c_row39_col3\" class=\"data row39 col3\" >34.44</td>\n",
       "      <td id=\"T_4db7c_row39_col4\" class=\"data row39 col4\" >4.60</td>\n",
       "      <td id=\"T_4db7c_row39_col5\" class=\"data row39 col5\" >12.20</td>\n",
       "      <td id=\"T_4db7c_row39_col6\" class=\"data row39 col6\" >31.94</td>\n",
       "      <td id=\"T_4db7c_row39_col7\" class=\"data row39 col7\" >28.43</td>\n",
       "      <td id=\"T_4db7c_row39_col8\" class=\"data row39 col8\" >10.57</td>\n",
       "      <td id=\"T_4db7c_row39_col9\" class=\"data row39 col9\" >27.16</td>\n",
       "      <td id=\"T_4db7c_row39_col10\" class=\"data row39 col10\" >14.63</td>\n",
       "      <td id=\"T_4db7c_row39_col11\" class=\"data row39 col11\" >nan</td>\n",
       "      <td id=\"T_4db7c_row39_col12\" class=\"data row39 col12\" >22.45</td>\n",
       "      <td id=\"T_4db7c_row39_col13\" class=\"data row39 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_4db7c_row40_col0\" class=\"data row40 col0\" >llama-7b_wizardlm_score=ifd:neg_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row40_col1\" class=\"data row40 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row40_col2\" class=\"data row40 col2\" >36.40</td>\n",
       "      <td id=\"T_4db7c_row40_col3\" class=\"data row40 col3\" >33.49</td>\n",
       "      <td id=\"T_4db7c_row40_col4\" class=\"data row40 col4\" >4.60</td>\n",
       "      <td id=\"T_4db7c_row40_col5\" class=\"data row40 col5\" >10.80</td>\n",
       "      <td id=\"T_4db7c_row40_col6\" class=\"data row40 col6\" >17.31</td>\n",
       "      <td id=\"T_4db7c_row40_col7\" class=\"data row40 col7\" >27.78</td>\n",
       "      <td id=\"T_4db7c_row40_col8\" class=\"data row40 col8\" >7.34</td>\n",
       "      <td id=\"T_4db7c_row40_col9\" class=\"data row40 col9\" >24.24</td>\n",
       "      <td id=\"T_4db7c_row40_col10\" class=\"data row40 col10\" >6.10</td>\n",
       "      <td id=\"T_4db7c_row40_col11\" class=\"data row40 col11\" >56.26</td>\n",
       "      <td id=\"T_4db7c_row40_col12\" class=\"data row40 col12\" >22.43</td>\n",
       "      <td id=\"T_4db7c_row40_col13\" class=\"data row40 col13\" >-36.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_4db7c_row41_col0\" class=\"data row41 col0\" >llama-7b_wizardlm_score=dppmap:k=rbf:gamma=0.0000007:kmd=llama7b:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_4db7c_row41_col1\" class=\"data row41 col1\" >10000</td>\n",
       "      <td id=\"T_4db7c_row41_col2\" class=\"data row41 col2\" >36.31</td>\n",
       "      <td id=\"T_4db7c_row41_col3\" class=\"data row41 col3\" >34.27</td>\n",
       "      <td id=\"T_4db7c_row41_col4\" class=\"data row41 col4\" >5.80</td>\n",
       "      <td id=\"T_4db7c_row41_col5\" class=\"data row41 col5\" >13.40</td>\n",
       "      <td id=\"T_4db7c_row41_col6\" class=\"data row41 col6\" >33.52</td>\n",
       "      <td id=\"T_4db7c_row41_col7\" class=\"data row41 col7\" >22.87</td>\n",
       "      <td id=\"T_4db7c_row41_col8\" class=\"data row41 col8\" >8.69</td>\n",
       "      <td id=\"T_4db7c_row41_col9\" class=\"data row41 col9\" >39.28</td>\n",
       "      <td id=\"T_4db7c_row41_col10\" class=\"data row41 col10\" >10.98</td>\n",
       "      <td id=\"T_4db7c_row41_col11\" class=\"data row41 col11\" >17.29</td>\n",
       "      <td id=\"T_4db7c_row41_col12\" class=\"data row41 col12\" >22.24</td>\n",
       "      <td id=\"T_4db7c_row41_col13\" class=\"data row41 col13\" >-23.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_4db7c_row42_col0\" class=\"data row42 col0\" >llama-7b_wizardlm_score=dppmap:k=lin:kmd=mpnet_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row42_col1\" class=\"data row42 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row42_col2\" class=\"data row42 col2\" >37.91</td>\n",
       "      <td id=\"T_4db7c_row42_col3\" class=\"data row42 col3\" >32.76</td>\n",
       "      <td id=\"T_4db7c_row42_col4\" class=\"data row42 col4\" >5.20</td>\n",
       "      <td id=\"T_4db7c_row42_col5\" class=\"data row42 col5\" >14.00</td>\n",
       "      <td id=\"T_4db7c_row42_col6\" class=\"data row42 col6\" >28.52</td>\n",
       "      <td id=\"T_4db7c_row42_col7\" class=\"data row42 col7\" >29.63</td>\n",
       "      <td id=\"T_4db7c_row42_col8\" class=\"data row42 col8\" >9.54</td>\n",
       "      <td id=\"T_4db7c_row42_col9\" class=\"data row42 col9\" >27.58</td>\n",
       "      <td id=\"T_4db7c_row42_col10\" class=\"data row42 col10\" >9.15</td>\n",
       "      <td id=\"T_4db7c_row42_col11\" class=\"data row42 col11\" >nan</td>\n",
       "      <td id=\"T_4db7c_row42_col12\" class=\"data row42 col12\" >21.59</td>\n",
       "      <td id=\"T_4db7c_row42_col13\" class=\"data row42 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_4db7c_row43_col0\" class=\"data row43 col0\" >llama-7b_wizardlm_score=log:pmi_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row43_col1\" class=\"data row43 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row43_col2\" class=\"data row43 col2\" >35.23</td>\n",
       "      <td id=\"T_4db7c_row43_col3\" class=\"data row43 col3\" >28.48</td>\n",
       "      <td id=\"T_4db7c_row43_col4\" class=\"data row43 col4\" >6.40</td>\n",
       "      <td id=\"T_4db7c_row43_col5\" class=\"data row43 col5\" >12.40</td>\n",
       "      <td id=\"T_4db7c_row43_col6\" class=\"data row43 col6\" >16.11</td>\n",
       "      <td id=\"T_4db7c_row43_col7\" class=\"data row43 col7\" >29.72</td>\n",
       "      <td id=\"T_4db7c_row43_col8\" class=\"data row43 col8\" >8.18</td>\n",
       "      <td id=\"T_4db7c_row43_col9\" class=\"data row43 col9\" >19.79</td>\n",
       "      <td id=\"T_4db7c_row43_col10\" class=\"data row43 col10\" >3.05</td>\n",
       "      <td id=\"T_4db7c_row43_col11\" class=\"data row43 col11\" >51.55</td>\n",
       "      <td id=\"T_4db7c_row43_col12\" class=\"data row43 col12\" >21.09</td>\n",
       "      <td id=\"T_4db7c_row43_col13\" class=\"data row43 col13\" >-31.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_4db7c_row44_col0\" class=\"data row44 col0\" >llama-7b_wizardlm_score=el2n:agg=mean_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_4db7c_row44_col1\" class=\"data row44 col1\" >100000</td>\n",
       "      <td id=\"T_4db7c_row44_col2\" class=\"data row44 col2\" >37.65</td>\n",
       "      <td id=\"T_4db7c_row44_col3\" class=\"data row44 col3\" >32.42</td>\n",
       "      <td id=\"T_4db7c_row44_col4\" class=\"data row44 col4\" >6.00</td>\n",
       "      <td id=\"T_4db7c_row44_col5\" class=\"data row44 col5\" >11.40</td>\n",
       "      <td id=\"T_4db7c_row44_col6\" class=\"data row44 col6\" >29.35</td>\n",
       "      <td id=\"T_4db7c_row44_col7\" class=\"data row44 col7\" >29.72</td>\n",
       "      <td id=\"T_4db7c_row44_col8\" class=\"data row44 col8\" >8.66</td>\n",
       "      <td id=\"T_4db7c_row44_col9\" class=\"data row44 col9\" >24.88</td>\n",
       "      <td id=\"T_4db7c_row44_col10\" class=\"data row44 col10\" >9.15</td>\n",
       "      <td id=\"T_4db7c_row44_col11\" class=\"data row44 col11\" >nan</td>\n",
       "      <td id=\"T_4db7c_row44_col12\" class=\"data row44 col12\" >21.03</td>\n",
       "      <td id=\"T_4db7c_row44_col13\" class=\"data row44 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_4db7c_row45_col0\" class=\"data row45 col0\" >llama-7b_wizardlm_score=grad:loraB:l2n_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_4db7c_row45_col1\" class=\"data row45 col1\" >100000</td>\n",
       "      <td id=\"T_4db7c_row45_col2\" class=\"data row45 col2\" >36.78</td>\n",
       "      <td id=\"T_4db7c_row45_col3\" class=\"data row45 col3\" >31.50</td>\n",
       "      <td id=\"T_4db7c_row45_col4\" class=\"data row45 col4\" >4.80</td>\n",
       "      <td id=\"T_4db7c_row45_col5\" class=\"data row45 col5\" >13.20</td>\n",
       "      <td id=\"T_4db7c_row45_col6\" class=\"data row45 col6\" >23.61</td>\n",
       "      <td id=\"T_4db7c_row45_col7\" class=\"data row45 col7\" >28.80</td>\n",
       "      <td id=\"T_4db7c_row45_col8\" class=\"data row45 col8\" >6.02</td>\n",
       "      <td id=\"T_4db7c_row45_col9\" class=\"data row45 col9\" >23.70</td>\n",
       "      <td id=\"T_4db7c_row45_col10\" class=\"data row45 col10\" >10.37</td>\n",
       "      <td id=\"T_4db7c_row45_col11\" class=\"data row45 col11\" >nan</td>\n",
       "      <td id=\"T_4db7c_row45_col12\" class=\"data row45 col12\" >19.86</td>\n",
       "      <td id=\"T_4db7c_row45_col13\" class=\"data row45 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4db7c_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_4db7c_row46_col0\" class=\"data row46 col0\" >llama-7b_wizardlm_score=grad:loraB:l2n_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_4db7c_row46_col1\" class=\"data row46 col1\" >50000</td>\n",
       "      <td id=\"T_4db7c_row46_col2\" class=\"data row46 col2\" >36.97</td>\n",
       "      <td id=\"T_4db7c_row46_col3\" class=\"data row46 col3\" >30.69</td>\n",
       "      <td id=\"T_4db7c_row46_col4\" class=\"data row46 col4\" >5.40</td>\n",
       "      <td id=\"T_4db7c_row46_col5\" class=\"data row46 col5\" >11.80</td>\n",
       "      <td id=\"T_4db7c_row46_col6\" class=\"data row46 col6\" >21.20</td>\n",
       "      <td id=\"T_4db7c_row46_col7\" class=\"data row46 col7\" >29.17</td>\n",
       "      <td id=\"T_4db7c_row46_col8\" class=\"data row46 col8\" >8.78</td>\n",
       "      <td id=\"T_4db7c_row46_col9\" class=\"data row46 col9\" >22.17</td>\n",
       "      <td id=\"T_4db7c_row46_col10\" class=\"data row46 col10\" >10.98</td>\n",
       "      <td id=\"T_4db7c_row46_col11\" class=\"data row46 col11\" >nan</td>\n",
       "      <td id=\"T_4db7c_row46_col12\" class=\"data row46 col12\" >19.68</td>\n",
       "      <td id=\"T_4db7c_row46_col13\" class=\"data row46 col13\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc7a5529e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_sort_rows_by_avg_ranking\n",
    "from llm.evaluate import EvalResults, get_eval_results\n",
    "\n",
    "\n",
    "\n",
    "exp_dir = ''\n",
    "chat_fmt = None\n",
    "sort_rows = True\n",
    "use_normalized_preferred_metric = False\n",
    "\n",
    "\n",
    "# ## investigate code change / package update effect on eval baselines.\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# use_normalized_preferred_metric = False\n",
    "# save_dirs = [\n",
    "#     # llama\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b_10.30update', '../results/baselines/huggyllama/llama-7b_10.30update/'),\n",
    "#     ('llama-7b_09.23update', '../results/baselines/huggyllama/llama-7b_09.23update/'),\n",
    "#     ('llama-7b_09.23update_before', '../results/baselines/huggyllama/llama-7b_09.23update_before/'),\n",
    "#     # llama2\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('llama2-7b_10.30update', '../results/baselines/NousResearch/Llama-2-7b-hf_10.30update/'),\n",
    "#     ('llama2-7b_original', '../results/baselines/NousResearch/Llama-2-7b-hf_original/'),\n",
    "#     # mistral\n",
    "#     ('mistral-7b_10.16update', '../results/baselines/mistralai/Mistral-7B-v0.1_10.16update/'),\n",
    "#     ('mistral-7b-Instruct_10.16update', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "# ]\n",
    "\n",
    "# # baselines\n",
    "# save_dirs = []\n",
    "# save_dirs += [\n",
    "# #     ('gpt2', '../results/baselines/gpt2'),\n",
    "# #     ('gpt2m', '../results/baselines/gpt2-medium'),\n",
    "# #     ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "# #     ('llama2-7b+humanmix', '../results/llama2-7b_humanmix'),\n",
    "# #     ('pythia-1.4b', '../results/baselines/EleutherAI/pythia-1.4b'),\n",
    "# #     ('pythia-2.8b', '../results/baselines/EleutherAI/pythia-2.8b'),\n",
    "# #     ('pythia-6.9b', '../results/baselines/EleutherAI/pythia-6.9b'),\n",
    "# #     ('dolly-v2-7b', '../results/baselines/databricks/dolly-v2-7b'),\n",
    "#     ('mistral-7b-v0.1', '../results/baselines/mistralai/Mistral-7B-v0.1'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b+lima_ep=2', '../results/ft1_ep=2/llama-7b_lima/'),\n",
    "# #     ('mistral-7b+lima_ep=2', '../results/ft1_ep=2/mistral-7b_lima/'), \n",
    "# ]\n",
    "# exp_dir = '../results/oi2/'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "\n",
    "# exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# # exp_dir = '../results/ft2'\n",
    "# # exp_dir = '../results/ft1'\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "#     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1/'),\n",
    "# ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "# # exp_dir = '../results/oi4'\n",
    "# # exp_dir = '../results/oi4_perf_cross_time'\n",
    "# # exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'\n",
    "# exp_dir = '../results/oi4_flan_v2_vary_subsetsize'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi4_flan2022_1m'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #              ('llama-7b_flan_v2_ep=2', '../results/ft1/llama-7b_flan_v2'),\n",
    "# #              ('llama-7b_humanmix_ep=2', '../results/ft1/llama-7b_humanmix'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "# #              ('llama-7b_cot:flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_cot:flanv2'),\n",
    "#             ]\n",
    "# use_normalized_preferred_metric = True\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# # exp_dir = '../results/oi4_tulu_v1_mix'\n",
    "# exp_dir = '../results/oi4_tulu_v1_mix_ep=3'\n",
    "# use_normalized_preferred_metric = False\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# save_dirs = [\n",
    "#     # baselines \n",
    "#     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "# #     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     ('mistral-7b_ultrachat200k_aftersplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k'),\n",
    "#     ('mistral-7b_ultrachat200k_beforesplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k_beforesplitlongconv'),\n",
    "# #     ('mistral-7b_sft-alpha', '../results/baselines/HuggingFaceH4/mistral-7b-sft-alpha'),\n",
    "# #     ('mistral-7b-sft-beta', '../results/baselines/HuggingFaceH4/mistral-7b-sft-beta'),\n",
    "# #     ('mistral-7b-sft-alpha+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-alpha'),\n",
    "# #     ('mistral-7b-sft-beta+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "# # exp_dir = '../results/oi5_ultrachat:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_ultrachat200k:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# exp_dir = '../results/oi5_ultrachat15:mistral-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# # ####\n",
    "# save_dirs = [\n",
    "#     # baselines \n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "#     # oi4_tulu_v1_mix_ep=3 models before transformers update.\n",
    "# #     ('llama-7b_tuluv1m:50k_log_prob_decr_<10.16update', '../results/oi4_tulu_v1_mix_ep=3/llama-7b_tuluv1m:50k_log_prob_decr'),\n",
    "# ]\n",
    "# exp_dir = '../results/oi5_tulu_v1_mix:llama-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # ####\n",
    "\n",
    "#####\n",
    "exp_dir = '../results/oi5_wizardlm:llama-7b'\n",
    "save_dirs = [('llama-7b_wizardlm_ep=2', '../results/oi2/llama-7b_wizardlm_ep=2')]\n",
    "save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] \n",
    "             if 'dppmapbd' not in x and 'semdedup' not in x]\n",
    "#####\n",
    "\n",
    "# #####\n",
    "# save_dirs = [\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('codellama-7b', '../results/baselines/codellama/CodeLlama-7b-hf/'),\n",
    "#     ('codellama-7b-instruct', '../results/baselines/codellama/CodeLlama-7b-Python-hf/'),\n",
    "#     ('codellama-7b-python', '../results/baselines/codellama/CodeLlama-7b-Instruct-hf/'),\n",
    "# ]\n",
    "\n",
    "# exp_dir = '../results/oi2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'starcoder' in x]\n",
    "# exp_dir = '../results/oi6_starcoder_ep=5'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstr:codellama-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# exp_dir = '../results/oi5_starcoder_commentinstrv2:codellama-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "###### \n",
    "\n",
    "from llm.evaluate import detect_oom_evals\n",
    "oom_eval_paths = detect_oom_evals([x for l in [glob.glob(os.path.join(x[1], 'eval/*/*.out')) for x in save_dirs] for x in l])\n",
    "if oom_eval_paths: print(oom_eval_paths)\n",
    "\n",
    "if any(exp_dir.endswith(x) for x in ['', 'ft2', 'oi4']):\n",
    "    chat_fmt = False\n",
    "    chat_fmt = True\n",
    "#     chat_fmt = 'both'\n",
    "    ft_args_fields = [\n",
    "        'run_name',\n",
    "        'model_args.model_name_or_path',\n",
    "        'data_args.subsample_mixture',\n",
    "        'data_args.max_train_samples',\n",
    "    ]\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "#     cols = ['MMLU/0-shot', 'GSM/Direct', 'BBH/Direct', 'TydiQA/CB', 'Codex-Eval/Pass@1']\n",
    "\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'Codex-Eval/Pass@1', 'AlpacaFarm(v.Davinci-003)/WR']\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT']\n",
    "\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm(v.Davinci-003)/WR']\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'Codex-Eval/Pass@1', 'AlpacaFarm(v.Davinci-003)/WR']\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1'] #  'ToxiGen/Acc'\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm(v.Davinci-003)/WR'] #  'ToxiGen/Acc'\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', 'AlpacaFarm(v.Davinci-003)/WR'] #  entire, without tydiqa, which has high variance\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', ] #  entire, without tydiqa, which has high variance\n",
    "    if 'starcoder' in exp_dir:\n",
    "#         cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "        cols = ['Codex-Eval/Pass@1']\n",
    "        chat_fmt = 'both'\n",
    "    print(f'chat_fmt={chat_fmt}')\n",
    "    df = get_eval_results(save_dirs, chat_fmt=chat_fmt, ft_args_fields=ft_args_fields, use_normalized_preferred_metric=use_normalized_preferred_metric)\n",
    "\n",
    "    df = df[ft_args_fields + cols]\n",
    "    df['Average'] = df[cols].mean(axis=1)\n",
    "    if sort_rows:\n",
    "        df = pd_sort_rows_by_avg_ranking(df); df['ranking'] = -df['ranking']\n",
    "        sort_value_col, sort_value_col_ascending = 'Average', False\n",
    "    #     sort_value_col, sort_value_col_ascending = 'ranking', False\n",
    "        df = df.sort_values(sort_value_col, ascending=sort_value_col_ascending)\n",
    "    df = df.reset_index(drop=True)\n",
    "else:\n",
    "    ft_args_fields = [\n",
    "        'run_name',\n",
    "        'data_args.subsample_mixture',\n",
    "        'data_args.max_train_samples',\n",
    "    ]\n",
    "    df = get_eval_results(save_dirs, chat_fmt='both', ft_args_fields=ft_args_fields, use_normalized_preferred_metric=use_normalized_preferred_metric)\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "    df = df[ft_args_fields+cols]\n",
    "    \n",
    "\n",
    "def compute_total_train_samples(x):\n",
    "    match = re.search(r'size=(\\d+)', x['run_name' if chat_fmt!='both' else ('run_name', '')])\n",
    "    total_train_samples = match.group(1) if match else None\n",
    "    return total_train_samples\n",
    "df.insert(1, 'total_train_samples' if chat_fmt!='both' else ('total_train_samples', ''), df.apply(compute_total_train_samples, axis=1))\n",
    "\n",
    "if any(exp_dir.endswith(x) for x in ['ft2']):\n",
    "#     for model_name_contain in ['gpt2', 'llama', 'pythia-1.4b']:\n",
    "#         for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "    for model_name_contain in ['llama']:\n",
    "        for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "#         for total_train_samples in [200000, 400000, 600000]:\n",
    "            dfc = df.copy()\n",
    "            dfc.insert(0, 'total_train_samples',  dfc['data_args.subsample_mixture'].apply(\n",
    "                lambda d: sum(list(d.values())) if d else 200000))\n",
    "            dfc = dfc[dfc['total_train_samples'].apply(\n",
    "                lambda x: total_train_samples-20000<x<total_train_samples+20000)]\n",
    "            dfc = dfc[dfc['model_args.model_name_or_path'].apply(\n",
    "                lambda x: model_name_contain in x)]\n",
    "            dfc['total_train_samples'] = dfc['total_train_samples'].astype(str)\n",
    "            dfc = dfc.drop(columns=['model_args.model_name_or_path', 'data_args.subsample_mixture'])\n",
    "            dfc = dfc.reset_index(drop=True)\n",
    "            if len(dfc):\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .format(precision=2))\n",
    "elif any(exp_dir.endswith(x) for x in ['oi4']):\n",
    "    dfc = df.copy()\n",
    "    dfc = dfc.drop(columns=['model_args.model_name_or_path', 'data_args.subsample_mixture', 'data_args.max_train_samples'])\n",
    "    dfc = dfc.reset_index(drop=True)\n",
    "    if len(dfc):\n",
    "        display(dfc\n",
    "                .style\n",
    "                .set_properties(**{'text-align': 'left'})\n",
    "                .background_gradient(cmap ='coolwarm')\n",
    "                .format(precision=1))\n",
    "elif 'starcoder' in exp_dir:\n",
    "    Ns = sorted(np.unique([int(x) for x in df['total_train_samples'].to_numpy() if x]).tolist())\n",
    "    for N in Ns+[None]:\n",
    "        dfc = df.copy()\n",
    "        display(dfc[dfc['total_train_samples'].apply(lambda x: int(x) == N if x else True)]\n",
    "                .sort_values([('Codex-Eval/Pass@1', 'chatfmt')], ascending=False)\n",
    "                .drop(columns=['model_args.model_name_or_path', 'data_args.subsample_mixture', 'data_args.max_train_samples'])\n",
    "                .reset_index(drop=True)\n",
    "                .style\n",
    "                .set_properties(**{'text-align': 'left'})\n",
    "                .background_gradient(cmap ='coolwarm')\n",
    "                .format(precision=1))\n",
    "else:\n",
    "    for model_name_contain in ['llama', 'pythia-1.4b', 'mistral']:\n",
    "        dfc = df.copy()\n",
    "        dfc = dfc[dfc['model_args.model_name_or_path'].apply(\n",
    "            lambda x: model_name_contain in x)]\n",
    "        dfc = dfc.drop(columns=['model_args.model_name_or_path', 'data_args.subsample_mixture', 'data_args.max_train_samples'])\n",
    "        dfc = dfc.reset_index(drop=True)\n",
    "        if len(dfc):\n",
    "            display(dfc\n",
    "                    .style\n",
    "                    .set_properties(**{'text-align': 'left'})\n",
    "                    .background_gradient(cmap ='coolwarm')\n",
    "                    .format(precision=2))\n",
    "\n",
    "# llama-7b_tulu_v1_mix(paper)\n",
    "# MMLU/0-shot, MMLU/5-shot, GSM/Direct, GSM/CoT, BBH/Direct, BBH/CoT, TydiQA/GP, TydiQA/CB, CodexEval/Pass@1, AlpacaEval(vs.Davinci-003)\n",
    "# 44.8       , 47.1       , 7.0       , 25.0   , 38.5      , 38.5   , 43.5,    , 8.0      , 18.6,           , 48.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7c162e18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_601af_row0_col0, #T_601af_row0_col1, #T_601af_row1_col0, #T_601af_row1_col1, #T_601af_row2_col0, #T_601af_row2_col1, #T_601af_row3_col0, #T_601af_row3_col1, #T_601af_row4_col0, #T_601af_row4_col1, #T_601af_row5_col0, #T_601af_row5_col1, #T_601af_row6_col0, #T_601af_row6_col1, #T_601af_row7_col0, #T_601af_row7_col1, #T_601af_row8_col0, #T_601af_row8_col1, #T_601af_row9_col0, #T_601af_row9_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_601af_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row0_col6, #T_601af_row1_col10, #T_601af_row2_col10, #T_601af_row5_col10, #T_601af_row6_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row0_col7, #T_601af_row9_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c83836;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row0_col8, #T_601af_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b3cdfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row0_col10, #T_601af_row7_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row0_col12, #T_601af_row1_col3, #T_601af_row1_col13, #T_601af_row2_col4, #T_601af_row4_col7, #T_601af_row6_col11, #T_601af_row8_col2, #T_601af_row8_col3, #T_601af_row8_col8, #T_601af_row8_col10, #T_601af_row9_col5, #T_601af_row9_col6, #T_601af_row9_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row1_col5, #T_601af_row7_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row1_col11, #T_601af_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row1_col12, #T_601af_row9_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row2_col5, #T_601af_row8_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row2_col9, #T_601af_row7_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #ba162b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row3_col4, #T_601af_row7_col4, #T_601af_row9_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row3_col7, #T_601af_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row3_col10, #T_601af_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row3_col11, #T_601af_row7_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row4_col4, #T_601af_row5_col4, #T_601af_row6_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e16751;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row4_col9, #T_601af_row5_col2, #T_601af_row5_col5, #T_601af_row5_col8, #T_601af_row5_col13, #T_601af_row6_col6, #T_601af_row7_col3, #T_601af_row8_col4, #T_601af_row9_col7, #T_601af_row9_col10, #T_601af_row9_col11, #T_601af_row9_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row4_col12, #T_601af_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f1ccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row4_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row5_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row5_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row6_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row6_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row6_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row6_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row6_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row6_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row6_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row6_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row7_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row7_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row7_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row7_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row7_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row7_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row8_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dc5d4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row8_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row8_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row8_col11, #T_601af_row8_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row8_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_601af_row9_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_601af_row9_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_601af\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_601af_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_601af_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_601af_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_601af_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_601af_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_601af_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_601af_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_601af_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_601af_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_601af_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_601af_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_601af_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(v.Davinci-003)/WR</th>\n",
       "      <th id=\"T_601af_level0_col12\" class=\"col_heading level0 col12\" >Average</th>\n",
       "      <th id=\"T_601af_level0_col13\" class=\"col_heading level0 col13\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_601af_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_601af_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=auto1000:kmd=llama7b:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_601af_row0_col1\" class=\"data row0 col1\" >10000</td>\n",
       "      <td id=\"T_601af_row0_col2\" class=\"data row0 col2\" >34.8</td>\n",
       "      <td id=\"T_601af_row0_col3\" class=\"data row0 col3\" >33.9</td>\n",
       "      <td id=\"T_601af_row0_col4\" class=\"data row0 col4\" >6.0</td>\n",
       "      <td id=\"T_601af_row0_col5\" class=\"data row0 col5\" >11.6</td>\n",
       "      <td id=\"T_601af_row0_col6\" class=\"data row0 col6\" >26.9</td>\n",
       "      <td id=\"T_601af_row0_col7\" class=\"data row0 col7\" >29.0</td>\n",
       "      <td id=\"T_601af_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_601af_row0_col9\" class=\"data row0 col9\" >31.0</td>\n",
       "      <td id=\"T_601af_row0_col10\" class=\"data row0 col10\" >11.6</td>\n",
       "      <td id=\"T_601af_row0_col11\" class=\"data row0 col11\" >48.4</td>\n",
       "      <td id=\"T_601af_row0_col12\" class=\"data row0 col12\" >24.2</td>\n",
       "      <td id=\"T_601af_row0_col13\" class=\"data row0 col13\" >-24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_601af_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_601af_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm_score=dppmap:k=lin:kmd=mpnet_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_601af_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_601af_row1_col2\" class=\"data row1 col2\" >33.1</td>\n",
       "      <td id=\"T_601af_row1_col3\" class=\"data row1 col3\" >34.4</td>\n",
       "      <td id=\"T_601af_row1_col4\" class=\"data row1 col4\" >5.2</td>\n",
       "      <td id=\"T_601af_row1_col5\" class=\"data row1 col5\" >12.4</td>\n",
       "      <td id=\"T_601af_row1_col6\" class=\"data row1 col6\" >30.4</td>\n",
       "      <td id=\"T_601af_row1_col7\" class=\"data row1 col7\" >28.2</td>\n",
       "      <td id=\"T_601af_row1_col8\" class=\"data row1 col8\" >9.0</td>\n",
       "      <td id=\"T_601af_row1_col9\" class=\"data row1 col9\" >30.1</td>\n",
       "      <td id=\"T_601af_row1_col10\" class=\"data row1 col10\" >12.8</td>\n",
       "      <td id=\"T_601af_row1_col11\" class=\"data row1 col11\" >45.8</td>\n",
       "      <td id=\"T_601af_row1_col12\" class=\"data row1 col12\" >24.2</td>\n",
       "      <td id=\"T_601af_row1_col13\" class=\"data row1 col13\" >-23.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_601af_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_601af_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=0.008:kmd=mpnet_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_601af_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_601af_row2_col2\" class=\"data row2 col2\" >33.6</td>\n",
       "      <td id=\"T_601af_row2_col3\" class=\"data row2 col3\" >33.3</td>\n",
       "      <td id=\"T_601af_row2_col4\" class=\"data row2 col4\" >6.2</td>\n",
       "      <td id=\"T_601af_row2_col5\" class=\"data row2 col5\" >12.2</td>\n",
       "      <td id=\"T_601af_row2_col6\" class=\"data row2 col6\" >27.9</td>\n",
       "      <td id=\"T_601af_row2_col7\" class=\"data row2 col7\" >28.9</td>\n",
       "      <td id=\"T_601af_row2_col8\" class=\"data row2 col8\" >8.4</td>\n",
       "      <td id=\"T_601af_row2_col9\" class=\"data row2 col9\" >29.3</td>\n",
       "      <td id=\"T_601af_row2_col10\" class=\"data row2 col10\" >12.8</td>\n",
       "      <td id=\"T_601af_row2_col11\" class=\"data row2 col11\" >45.8</td>\n",
       "      <td id=\"T_601af_row2_col12\" class=\"data row2 col12\" >23.8</td>\n",
       "      <td id=\"T_601af_row2_col13\" class=\"data row2 col13\" >-25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_601af_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_601af_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.3:k=vmf:gamma=0.01:kmd=mpnet:q=log+pmi:qmd=llama7b_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_601af_row3_col1\" class=\"data row3 col1\" >10000</td>\n",
       "      <td id=\"T_601af_row3_col2\" class=\"data row3 col2\" >33.8</td>\n",
       "      <td id=\"T_601af_row3_col3\" class=\"data row3 col3\" >34.4</td>\n",
       "      <td id=\"T_601af_row3_col4\" class=\"data row3 col4\" >5.8</td>\n",
       "      <td id=\"T_601af_row3_col5\" class=\"data row3 col5\" >11.4</td>\n",
       "      <td id=\"T_601af_row3_col6\" class=\"data row3 col6\" >30.0</td>\n",
       "      <td id=\"T_601af_row3_col7\" class=\"data row3 col7\" >27.6</td>\n",
       "      <td id=\"T_601af_row3_col8\" class=\"data row3 col8\" >10.0</td>\n",
       "      <td id=\"T_601af_row3_col9\" class=\"data row3 col9\" >29.9</td>\n",
       "      <td id=\"T_601af_row3_col10\" class=\"data row3 col10\" >12.2</td>\n",
       "      <td id=\"T_601af_row3_col11\" class=\"data row3 col11\" >43.0</td>\n",
       "      <td id=\"T_601af_row3_col12\" class=\"data row3 col12\" >23.8</td>\n",
       "      <td id=\"T_601af_row3_col13\" class=\"data row3 col13\" >-25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_601af_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_601af_row4_col0\" class=\"data row4 col0\" >score=random:s=(\\d)_pace=prune:size=10000:ep=10_avg (N=2)</td>\n",
       "      <td id=\"T_601af_row4_col1\" class=\"data row4 col1\" >10000</td>\n",
       "      <td id=\"T_601af_row4_col2\" class=\"data row4 col2\" >31.9</td>\n",
       "      <td id=\"T_601af_row4_col3\" class=\"data row4 col3\" >33.0</td>\n",
       "      <td id=\"T_601af_row4_col4\" class=\"data row4 col4\" >5.0</td>\n",
       "      <td id=\"T_601af_row4_col5\" class=\"data row4 col5\" >11.9</td>\n",
       "      <td id=\"T_601af_row4_col6\" class=\"data row4 col6\" >31.7</td>\n",
       "      <td id=\"T_601af_row4_col7\" class=\"data row4 col7\" >29.4</td>\n",
       "      <td id=\"T_601af_row4_col8\" class=\"data row4 col8\" >9.9</td>\n",
       "      <td id=\"T_601af_row4_col9\" class=\"data row4 col9\" >26.3</td>\n",
       "      <td id=\"T_601af_row4_col10\" class=\"data row4 col10\" >12.2</td>\n",
       "      <td id=\"T_601af_row4_col11\" class=\"data row4 col11\" >42.9</td>\n",
       "      <td id=\"T_601af_row4_col12\" class=\"data row4 col12\" >23.4</td>\n",
       "      <td id=\"T_601af_row4_col13\" class=\"data row4 col13\" >-27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_601af_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_601af_row5_col0\" class=\"data row5 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.5:k=vmf:gamma=0.01:kmd=mpnet:q=log+pmi:qmd=llama7b_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_601af_row5_col1\" class=\"data row5 col1\" >10000</td>\n",
       "      <td id=\"T_601af_row5_col2\" class=\"data row5 col2\" >31.8</td>\n",
       "      <td id=\"T_601af_row5_col3\" class=\"data row5 col3\" >33.2</td>\n",
       "      <td id=\"T_601af_row5_col4\" class=\"data row5 col4\" >5.0</td>\n",
       "      <td id=\"T_601af_row5_col5\" class=\"data row5 col5\" >11.2</td>\n",
       "      <td id=\"T_601af_row5_col6\" class=\"data row5 col6\" >27.8</td>\n",
       "      <td id=\"T_601af_row5_col7\" class=\"data row5 col7\" >27.6</td>\n",
       "      <td id=\"T_601af_row5_col8\" class=\"data row5 col8\" >8.1</td>\n",
       "      <td id=\"T_601af_row5_col9\" class=\"data row5 col9\" >30.4</td>\n",
       "      <td id=\"T_601af_row5_col10\" class=\"data row5 col10\" >12.8</td>\n",
       "      <td id=\"T_601af_row5_col11\" class=\"data row5 col11\" >44.1</td>\n",
       "      <td id=\"T_601af_row5_col12\" class=\"data row5 col12\" >23.2</td>\n",
       "      <td id=\"T_601af_row5_col13\" class=\"data row5 col13\" >-32.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_601af_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_601af_row6_col0\" class=\"data row6 col0\" >llama-7b_wizardlm_score=dppmap:k=rbf:gamma=3.5e-8:kmd=llama7b:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_601af_row6_col1\" class=\"data row6 col1\" >10000</td>\n",
       "      <td id=\"T_601af_row6_col2\" class=\"data row6 col2\" >32.0</td>\n",
       "      <td id=\"T_601af_row6_col3\" class=\"data row6 col3\" >33.0</td>\n",
       "      <td id=\"T_601af_row6_col4\" class=\"data row6 col4\" >5.0</td>\n",
       "      <td id=\"T_601af_row6_col5\" class=\"data row6 col5\" >12.0</td>\n",
       "      <td id=\"T_601af_row6_col6\" class=\"data row6 col6\" >20.1</td>\n",
       "      <td id=\"T_601af_row6_col7\" class=\"data row6 col7\" >25.0</td>\n",
       "      <td id=\"T_601af_row6_col8\" class=\"data row6 col8\" >9.4</td>\n",
       "      <td id=\"T_601af_row6_col9\" class=\"data row6 col9\" >28.0</td>\n",
       "      <td id=\"T_601af_row6_col10\" class=\"data row6 col10\" >12.8</td>\n",
       "      <td id=\"T_601af_row6_col11\" class=\"data row6 col11\" >50.6</td>\n",
       "      <td id=\"T_601af_row6_col12\" class=\"data row6 col12\" >22.8</td>\n",
       "      <td id=\"T_601af_row6_col13\" class=\"data row6 col13\" >-30.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_601af_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_601af_row7_col0\" class=\"data row7 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=auto1000:kmd=llama7b:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_601af_row7_col1\" class=\"data row7 col1\" >10000</td>\n",
       "      <td id=\"T_601af_row7_col2\" class=\"data row7 col2\" >32.4</td>\n",
       "      <td id=\"T_601af_row7_col3\" class=\"data row7 col3\" >31.4</td>\n",
       "      <td id=\"T_601af_row7_col4\" class=\"data row7 col4\" >5.8</td>\n",
       "      <td id=\"T_601af_row7_col5\" class=\"data row7 col5\" >12.4</td>\n",
       "      <td id=\"T_601af_row7_col6\" class=\"data row7 col6\" >29.0</td>\n",
       "      <td id=\"T_601af_row7_col7\" class=\"data row7 col7\" >27.9</td>\n",
       "      <td id=\"T_601af_row7_col8\" class=\"data row7 col8\" >9.6</td>\n",
       "      <td id=\"T_601af_row7_col9\" class=\"data row7 col9\" >27.5</td>\n",
       "      <td id=\"T_601af_row7_col10\" class=\"data row7 col10\" >11.6</td>\n",
       "      <td id=\"T_601af_row7_col11\" class=\"data row7 col11\" >39.5</td>\n",
       "      <td id=\"T_601af_row7_col12\" class=\"data row7 col12\" >22.7</td>\n",
       "      <td id=\"T_601af_row7_col13\" class=\"data row7 col13\" >-29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_601af_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_601af_row8_col0\" class=\"data row8 col0\" >llama-7b_wizardlm_ep=2</td>\n",
       "      <td id=\"T_601af_row8_col1\" class=\"data row8 col1\" >None</td>\n",
       "      <td id=\"T_601af_row8_col2\" class=\"data row8 col2\" >38.1</td>\n",
       "      <td id=\"T_601af_row8_col3\" class=\"data row8 col3\" >34.4</td>\n",
       "      <td id=\"T_601af_row8_col4\" class=\"data row8 col4\" >4.6</td>\n",
       "      <td id=\"T_601af_row8_col5\" class=\"data row8 col5\" >12.2</td>\n",
       "      <td id=\"T_601af_row8_col6\" class=\"data row8 col6\" >31.9</td>\n",
       "      <td id=\"T_601af_row8_col7\" class=\"data row8 col7\" >28.4</td>\n",
       "      <td id=\"T_601af_row8_col8\" class=\"data row8 col8\" >10.6</td>\n",
       "      <td id=\"T_601af_row8_col9\" class=\"data row8 col9\" >27.2</td>\n",
       "      <td id=\"T_601af_row8_col10\" class=\"data row8 col10\" >14.6</td>\n",
       "      <td id=\"T_601af_row8_col11\" class=\"data row8 col11\" >nan</td>\n",
       "      <td id=\"T_601af_row8_col12\" class=\"data row8 col12\" >22.4</td>\n",
       "      <td id=\"T_601af_row8_col13\" class=\"data row8 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_601af_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_601af_row9_col0\" class=\"data row9 col0\" >llama-7b_wizardlm_score=dppmap:k=rbf:gamma=0.0000007:kmd=llama7b:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_601af_row9_col1\" class=\"data row9 col1\" >10000</td>\n",
       "      <td id=\"T_601af_row9_col2\" class=\"data row9 col2\" >36.3</td>\n",
       "      <td id=\"T_601af_row9_col3\" class=\"data row9 col3\" >34.3</td>\n",
       "      <td id=\"T_601af_row9_col4\" class=\"data row9 col4\" >5.8</td>\n",
       "      <td id=\"T_601af_row9_col5\" class=\"data row9 col5\" >13.4</td>\n",
       "      <td id=\"T_601af_row9_col6\" class=\"data row9 col6\" >33.5</td>\n",
       "      <td id=\"T_601af_row9_col7\" class=\"data row9 col7\" >22.9</td>\n",
       "      <td id=\"T_601af_row9_col8\" class=\"data row9 col8\" >8.7</td>\n",
       "      <td id=\"T_601af_row9_col9\" class=\"data row9 col9\" >39.3</td>\n",
       "      <td id=\"T_601af_row9_col10\" class=\"data row9 col10\" >11.0</td>\n",
       "      <td id=\"T_601af_row9_col11\" class=\"data row9 col11\" >17.3</td>\n",
       "      <td id=\"T_601af_row9_col12\" class=\"data row9 col12\" >22.2</td>\n",
       "      <td id=\"T_601af_row9_col13\" class=\"data row9 col13\" >-23.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc80ba8cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d4cf1_row0_col0, #T_d4cf1_row0_col1, #T_d4cf1_row1_col0, #T_d4cf1_row1_col1, #T_d4cf1_row2_col0, #T_d4cf1_row2_col1, #T_d4cf1_row3_col0, #T_d4cf1_row3_col1, #T_d4cf1_row4_col0, #T_d4cf1_row4_col1, #T_d4cf1_row5_col0, #T_d4cf1_row5_col1, #T_d4cf1_row6_col0, #T_d4cf1_row6_col1, #T_d4cf1_row7_col0, #T_d4cf1_row7_col1, #T_d4cf1_row8_col0, #T_d4cf1_row8_col1, #T_d4cf1_row9_col0, #T_d4cf1_row9_col1, #T_d4cf1_row10_col0, #T_d4cf1_row10_col1, #T_d4cf1_row11_col0, #T_d4cf1_row11_col1, #T_d4cf1_row12_col0, #T_d4cf1_row12_col1, #T_d4cf1_row13_col0, #T_d4cf1_row13_col1, #T_d4cf1_row14_col0, #T_d4cf1_row14_col1, #T_d4cf1_row15_col0, #T_d4cf1_row15_col1, #T_d4cf1_row16_col0, #T_d4cf1_row16_col1, #T_d4cf1_row17_col0, #T_d4cf1_row17_col1, #T_d4cf1_row18_col0, #T_d4cf1_row18_col1, #T_d4cf1_row19_col0, #T_d4cf1_row19_col1, #T_d4cf1_row20_col0, #T_d4cf1_row20_col1, #T_d4cf1_row21_col0, #T_d4cf1_row21_col1, #T_d4cf1_row22_col0, #T_d4cf1_row22_col1, #T_d4cf1_row23_col0, #T_d4cf1_row23_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d4cf1_row0_col2, #T_d4cf1_row7_col13, #T_d4cf1_row8_col3, #T_d4cf1_row8_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row0_col3, #T_d4cf1_row2_col3, #T_d4cf1_row12_col12, #T_d4cf1_row19_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row0_col4, #T_d4cf1_row8_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row0_col5, #T_d4cf1_row2_col8, #T_d4cf1_row9_col5, #T_d4cf1_row16_col5, #T_d4cf1_row23_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row0_col6, #T_d4cf1_row0_col9, #T_d4cf1_row0_col12, #T_d4cf1_row1_col2, #T_d4cf1_row2_col10, #T_d4cf1_row2_col13, #T_d4cf1_row3_col4, #T_d4cf1_row11_col5, #T_d4cf1_row11_col11, #T_d4cf1_row13_col7, #T_d4cf1_row15_col3, #T_d4cf1_row19_col8, #T_d4cf1_row19_col10, #T_d4cf1_row22_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row0_col7, #T_d4cf1_row19_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row0_col8, #T_d4cf1_row14_col12, #T_d4cf1_row16_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row0_col10, #T_d4cf1_row13_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row0_col13, #T_d4cf1_row3_col9, #T_d4cf1_row20_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row1_col4, #T_d4cf1_row12_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row1_col8, #T_d4cf1_row5_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row1_col10, #T_d4cf1_row3_col10, #T_d4cf1_row21_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ba162b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row1_col13, #T_d4cf1_row6_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row2_col4, #T_d4cf1_row3_col8, #T_d4cf1_row4_col4, #T_d4cf1_row13_col4, #T_d4cf1_row23_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row2_col5, #T_d4cf1_row5_col8, #T_d4cf1_row10_col2, #T_d4cf1_row11_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row2_col7, #T_d4cf1_row21_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row2_col9, #T_d4cf1_row21_col5, #T_d4cf1_row21_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row2_col11, #T_d4cf1_row3_col3, #T_d4cf1_row6_col6, #T_d4cf1_row8_col13, #T_d4cf1_row17_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row2_col12, #T_d4cf1_row8_col2, #T_d4cf1_row9_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row3_col6, #T_d4cf1_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row3_col11, #T_d4cf1_row13_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row4_col2, #T_d4cf1_row9_col3, #T_d4cf1_row15_col2, #T_d4cf1_row16_col6, #T_d4cf1_row22_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row4_col5, #T_d4cf1_row22_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row4_col8, #T_d4cf1_row10_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row4_col9, #T_d4cf1_row5_col9, #T_d4cf1_row9_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row4_col10, #T_d4cf1_row7_col10, #T_d4cf1_row12_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row4_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row5_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row5_col3, #T_d4cf1_row7_col3, #T_d4cf1_row16_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row5_col4, #T_d4cf1_row6_col4, #T_d4cf1_row10_col4, #T_d4cf1_row17_col4, #T_d4cf1_row18_col12, #T_d4cf1_row21_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row5_col6, #T_d4cf1_row19_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row5_col10, #T_d4cf1_row8_col10, #T_d4cf1_row13_col12, #T_d4cf1_row16_col10, #T_d4cf1_row17_col10, #T_d4cf1_row23_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row5_col12, #T_d4cf1_row7_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row5_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row6_col2, #T_d4cf1_row17_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row6_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row6_col5, #T_d4cf1_row14_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row6_col7, #T_d4cf1_row18_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row6_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row6_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row6_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row6_col12, #T_d4cf1_row6_col13, #T_d4cf1_row7_col12, #T_d4cf1_row14_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row7_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row7_col4, #T_d4cf1_row9_col4, #T_d4cf1_row12_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row7_col5, #T_d4cf1_row13_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row7_col7, #T_d4cf1_row11_col7, #T_d4cf1_row14_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row7_col8, #T_d4cf1_row15_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row7_col9, #T_d4cf1_row9_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row7_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row8_col5, #T_d4cf1_row13_col3, #T_d4cf1_row14_col5, #T_d4cf1_row19_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row8_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row8_col7, #T_d4cf1_row19_col4, #T_d4cf1_row20_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row8_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row8_col9, #T_d4cf1_row16_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row8_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row9_col2, #T_d4cf1_row10_col10, #T_d4cf1_row21_col10, #T_d4cf1_row22_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row9_col7, #T_d4cf1_row9_col10, #T_d4cf1_row11_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row9_col8, #T_d4cf1_row13_col9, #T_d4cf1_row19_col12, #T_d4cf1_row20_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row9_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row9_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row10_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row10_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row10_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e16751;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row10_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row10_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row10_col9, #T_d4cf1_row11_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row10_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row10_col13, #T_d4cf1_row11_col13, #T_d4cf1_row18_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row11_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row11_col4, #T_d4cf1_row18_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row11_col8, #T_d4cf1_row14_col4, #T_d4cf1_row15_col5, #T_d4cf1_row16_col11, #T_d4cf1_row17_col2, #T_d4cf1_row20_col7, #T_d4cf1_row20_col13, #T_d4cf1_row22_col3, #T_d4cf1_row22_col6, #T_d4cf1_row22_col9, #T_d4cf1_row22_col10, #T_d4cf1_row23_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row11_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row11_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row12_col2, #T_d4cf1_row22_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row12_col5, #T_d4cf1_row14_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row12_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row12_col7, #T_d4cf1_row23_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row12_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row12_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row12_col13, #T_d4cf1_row17_col3, #T_d4cf1_row23_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row13_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row13_col8, #T_d4cf1_row13_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row13_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row14_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row14_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row14_col8, #T_d4cf1_row20_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f1ccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row14_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #ead5c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row14_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row15_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row15_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row15_col7, #T_d4cf1_row21_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row15_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row15_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row15_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row15_col13, #T_d4cf1_row16_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #b3cdfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row16_col3, #T_d4cf1_row21_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row16_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row16_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row16_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row17_col5, #T_d4cf1_row22_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row17_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row17_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row17_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row17_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row17_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row18_col2, #T_d4cf1_row18_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row18_col3, #T_d4cf1_row18_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row18_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row18_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row18_col10, #T_d4cf1_row20_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row18_col11, #T_d4cf1_row20_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row19_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row19_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row19_col11, #T_d4cf1_row19_col13, #T_d4cf1_row21_col11, #T_d4cf1_row21_col13, #T_d4cf1_row23_col11, #T_d4cf1_row23_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row20_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row20_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row20_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row20_col10, #T_d4cf1_row23_col3, #T_d4cf1_row23_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row21_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row21_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row22_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row22_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4cf1_row23_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4cf1_row23_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d4cf1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d4cf1_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d4cf1_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_d4cf1_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d4cf1_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d4cf1_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_d4cf1_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_d4cf1_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_d4cf1_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_d4cf1_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d4cf1_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d4cf1_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d4cf1_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(v.Davinci-003)/WR</th>\n",
       "      <th id=\"T_d4cf1_level0_col12\" class=\"col_heading level0 col12\" >Average</th>\n",
       "      <th id=\"T_d4cf1_level0_col13\" class=\"col_heading level0 col13\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d4cf1_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.5:k=vmf:gamma=0.043:kmd=mpnet:q=log+pmi:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row0_col1\" class=\"data row0 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row0_col2\" class=\"data row0 col2\" >38.8</td>\n",
       "      <td id=\"T_d4cf1_row0_col3\" class=\"data row0 col3\" >34.4</td>\n",
       "      <td id=\"T_d4cf1_row0_col4\" class=\"data row0 col4\" >5.0</td>\n",
       "      <td id=\"T_d4cf1_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_d4cf1_row0_col6\" class=\"data row0 col6\" >35.4</td>\n",
       "      <td id=\"T_d4cf1_row0_col7\" class=\"data row0 col7\" >28.4</td>\n",
       "      <td id=\"T_d4cf1_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_d4cf1_row0_col9\" class=\"data row0 col9\" >35.6</td>\n",
       "      <td id=\"T_d4cf1_row0_col10\" class=\"data row0 col10\" >14.0</td>\n",
       "      <td id=\"T_d4cf1_row0_col11\" class=\"data row0 col11\" >53.3</td>\n",
       "      <td id=\"T_d4cf1_row0_col12\" class=\"data row0 col12\" >26.6</td>\n",
       "      <td id=\"T_d4cf1_row0_col13\" class=\"data row0 col13\" >-14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d4cf1_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm_score=dppmap:k=rbf:gamma=7.5e-06:kmd=llama7b:kemb=text+embedding_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row1_col1\" class=\"data row1 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row1_col2\" class=\"data row1 col2\" >39.7</td>\n",
       "      <td id=\"T_d4cf1_row1_col3\" class=\"data row1 col3\" >34.6</td>\n",
       "      <td id=\"T_d4cf1_row1_col4\" class=\"data row1 col4\" >6.2</td>\n",
       "      <td id=\"T_d4cf1_row1_col5\" class=\"data row1 col5\" >11.0</td>\n",
       "      <td id=\"T_d4cf1_row1_col6\" class=\"data row1 col6\" >33.2</td>\n",
       "      <td id=\"T_d4cf1_row1_col7\" class=\"data row1 col7\" >27.9</td>\n",
       "      <td id=\"T_d4cf1_row1_col8\" class=\"data row1 col8\" >7.9</td>\n",
       "      <td id=\"T_d4cf1_row1_col9\" class=\"data row1 col9\" >35.3</td>\n",
       "      <td id=\"T_d4cf1_row1_col10\" class=\"data row1 col10\" >11.6</td>\n",
       "      <td id=\"T_d4cf1_row1_col11\" class=\"data row1 col11\" >56.3</td>\n",
       "      <td id=\"T_d4cf1_row1_col12\" class=\"data row1 col12\" >26.4</td>\n",
       "      <td id=\"T_d4cf1_row1_col13\" class=\"data row1 col13\" >-15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d4cf1_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.3:k=vmf:gamma=0.04:kmd=mpnet:q=log+pmi:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row2_col1\" class=\"data row2 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row2_col2\" class=\"data row2 col2\" >38.2</td>\n",
       "      <td id=\"T_d4cf1_row2_col3\" class=\"data row2 col3\" >34.4</td>\n",
       "      <td id=\"T_d4cf1_row2_col4\" class=\"data row2 col4\" >5.4</td>\n",
       "      <td id=\"T_d4cf1_row2_col5\" class=\"data row2 col5\" >12.8</td>\n",
       "      <td id=\"T_d4cf1_row2_col6\" class=\"data row2 col6\" >33.8</td>\n",
       "      <td id=\"T_d4cf1_row2_col7\" class=\"data row2 col7\" >29.6</td>\n",
       "      <td id=\"T_d4cf1_row2_col8\" class=\"data row2 col8\" >8.1</td>\n",
       "      <td id=\"T_d4cf1_row2_col9\" class=\"data row2 col9\" >30.0</td>\n",
       "      <td id=\"T_d4cf1_row2_col10\" class=\"data row2 col10\" >14.6</td>\n",
       "      <td id=\"T_d4cf1_row2_col11\" class=\"data row2 col11\" >52.7</td>\n",
       "      <td id=\"T_d4cf1_row2_col12\" class=\"data row2 col12\" >26.0</td>\n",
       "      <td id=\"T_d4cf1_row2_col13\" class=\"data row2 col13\" >-13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d4cf1_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.7:k=vmf:gamma=0.043:kmd=mpnet:q=log+pmi:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row3_col1\" class=\"data row3 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row3_col2\" class=\"data row3 col2\" >36.3</td>\n",
       "      <td id=\"T_d4cf1_row3_col3\" class=\"data row3 col3\" >34.7</td>\n",
       "      <td id=\"T_d4cf1_row3_col4\" class=\"data row3 col4\" >6.4</td>\n",
       "      <td id=\"T_d4cf1_row3_col5\" class=\"data row3 col5\" >11.6</td>\n",
       "      <td id=\"T_d4cf1_row3_col6\" class=\"data row3 col6\" >33.4</td>\n",
       "      <td id=\"T_d4cf1_row3_col7\" class=\"data row3 col7\" >29.0</td>\n",
       "      <td id=\"T_d4cf1_row3_col8\" class=\"data row3 col8\" >9.0</td>\n",
       "      <td id=\"T_d4cf1_row3_col9\" class=\"data row3 col9\" >35.2</td>\n",
       "      <td id=\"T_d4cf1_row3_col10\" class=\"data row3 col10\" >11.6</td>\n",
       "      <td id=\"T_d4cf1_row3_col11\" class=\"data row3 col11\" >51.7</td>\n",
       "      <td id=\"T_d4cf1_row3_col12\" class=\"data row3 col12\" >25.9</td>\n",
       "      <td id=\"T_d4cf1_row3_col13\" class=\"data row3 col13\" >-16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d4cf1_row4_col0\" class=\"data row4 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=0.035:kmd=mpnet_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row4_col1\" class=\"data row4 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row4_col2\" class=\"data row4 col2\" >38.0</td>\n",
       "      <td id=\"T_d4cf1_row4_col3\" class=\"data row4 col3\" >34.4</td>\n",
       "      <td id=\"T_d4cf1_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_d4cf1_row4_col5\" class=\"data row4 col5\" >12.0</td>\n",
       "      <td id=\"T_d4cf1_row4_col6\" class=\"data row4 col6\" >33.1</td>\n",
       "      <td id=\"T_d4cf1_row4_col7\" class=\"data row4 col7\" >30.2</td>\n",
       "      <td id=\"T_d4cf1_row4_col8\" class=\"data row4 col8\" >9.6</td>\n",
       "      <td id=\"T_d4cf1_row4_col9\" class=\"data row4 col9\" >31.1</td>\n",
       "      <td id=\"T_d4cf1_row4_col10\" class=\"data row4 col10\" >10.4</td>\n",
       "      <td id=\"T_d4cf1_row4_col11\" class=\"data row4 col11\" >53.2</td>\n",
       "      <td id=\"T_d4cf1_row4_col12\" class=\"data row4 col12\" >25.7</td>\n",
       "      <td id=\"T_d4cf1_row4_col13\" class=\"data row4 col13\" >-14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d4cf1_row5_col0\" class=\"data row5 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.3:k=rbf:gamma=auto10000:kmd=llama7b:kemb=text+embedding:q=log+pmi:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row5_col1\" class=\"data row5 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row5_col2\" class=\"data row5 col2\" >39.3</td>\n",
       "      <td id=\"T_d4cf1_row5_col3\" class=\"data row5 col3\" >35.6</td>\n",
       "      <td id=\"T_d4cf1_row5_col4\" class=\"data row5 col4\" >5.2</td>\n",
       "      <td id=\"T_d4cf1_row5_col5\" class=\"data row5 col5\" >11.4</td>\n",
       "      <td id=\"T_d4cf1_row5_col6\" class=\"data row5 col6\" >31.9</td>\n",
       "      <td id=\"T_d4cf1_row5_col7\" class=\"data row5 col7\" >28.6</td>\n",
       "      <td id=\"T_d4cf1_row5_col8\" class=\"data row5 col8\" >8.6</td>\n",
       "      <td id=\"T_d4cf1_row5_col9\" class=\"data row5 col9\" >31.1</td>\n",
       "      <td id=\"T_d4cf1_row5_col10\" class=\"data row5 col10\" >11.0</td>\n",
       "      <td id=\"T_d4cf1_row5_col11\" class=\"data row5 col11\" >53.1</td>\n",
       "      <td id=\"T_d4cf1_row5_col12\" class=\"data row5 col12\" >25.6</td>\n",
       "      <td id=\"T_d4cf1_row5_col13\" class=\"data row5 col13\" >-18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d4cf1_row6_col0\" class=\"data row6 col0\" >score=random:s=(\\d)_pace=prune:size=50000:ep=5_avg (N=2)</td>\n",
       "      <td id=\"T_d4cf1_row6_col1\" class=\"data row6 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row6_col2\" class=\"data row6 col2\" >37.1</td>\n",
       "      <td id=\"T_d4cf1_row6_col3\" class=\"data row6 col3\" >34.9</td>\n",
       "      <td id=\"T_d4cf1_row6_col4\" class=\"data row6 col4\" >5.2</td>\n",
       "      <td id=\"T_d4cf1_row6_col5\" class=\"data row6 col5\" >13.9</td>\n",
       "      <td id=\"T_d4cf1_row6_col6\" class=\"data row6 col6\" >30.5</td>\n",
       "      <td id=\"T_d4cf1_row6_col7\" class=\"data row6 col7\" >29.9</td>\n",
       "      <td id=\"T_d4cf1_row6_col8\" class=\"data row6 col8\" >8.0</td>\n",
       "      <td id=\"T_d4cf1_row6_col9\" class=\"data row6 col9\" >27.4</td>\n",
       "      <td id=\"T_d4cf1_row6_col10\" class=\"data row6 col10\" >13.4</td>\n",
       "      <td id=\"T_d4cf1_row6_col11\" class=\"data row6 col11\" >53.8</td>\n",
       "      <td id=\"T_d4cf1_row6_col12\" class=\"data row6 col12\" >25.4</td>\n",
       "      <td id=\"T_d4cf1_row6_col13\" class=\"data row6 col13\" >-17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d4cf1_row7_col0\" class=\"data row7 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.5:k=rbf:gamma=auto10000:kmd=llama7b:kemb=text+embedding:q=log+pmi:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row7_col1\" class=\"data row7 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row7_col2\" class=\"data row7 col2\" >38.3</td>\n",
       "      <td id=\"T_d4cf1_row7_col3\" class=\"data row7 col3\" >35.6</td>\n",
       "      <td id=\"T_d4cf1_row7_col4\" class=\"data row7 col4\" >5.8</td>\n",
       "      <td id=\"T_d4cf1_row7_col5\" class=\"data row7 col5\" >10.0</td>\n",
       "      <td id=\"T_d4cf1_row7_col6\" class=\"data row7 col6\" >32.6</td>\n",
       "      <td id=\"T_d4cf1_row7_col7\" class=\"data row7 col7\" >29.4</td>\n",
       "      <td id=\"T_d4cf1_row7_col8\" class=\"data row7 col8\" >9.0</td>\n",
       "      <td id=\"T_d4cf1_row7_col9\" class=\"data row7 col9\" >29.8</td>\n",
       "      <td id=\"T_d4cf1_row7_col10\" class=\"data row7 col10\" >10.4</td>\n",
       "      <td id=\"T_d4cf1_row7_col11\" class=\"data row7 col11\" >53.1</td>\n",
       "      <td id=\"T_d4cf1_row7_col12\" class=\"data row7 col12\" >25.4</td>\n",
       "      <td id=\"T_d4cf1_row7_col13\" class=\"data row7 col13\" >-17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d4cf1_row8_col0\" class=\"data row8 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=auto10000:kmd=llama7b:kemb=text+embedding_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row8_col1\" class=\"data row8 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row8_col2\" class=\"data row8 col2\" >39.2</td>\n",
       "      <td id=\"T_d4cf1_row8_col3\" class=\"data row8 col3\" >35.4</td>\n",
       "      <td id=\"T_d4cf1_row8_col4\" class=\"data row8 col4\" >5.0</td>\n",
       "      <td id=\"T_d4cf1_row8_col5\" class=\"data row8 col5\" >12.2</td>\n",
       "      <td id=\"T_d4cf1_row8_col6\" class=\"data row8 col6\" >34.4</td>\n",
       "      <td id=\"T_d4cf1_row8_col7\" class=\"data row8 col7\" >28.7</td>\n",
       "      <td id=\"T_d4cf1_row8_col8\" class=\"data row8 col8\" >8.5</td>\n",
       "      <td id=\"T_d4cf1_row8_col9\" class=\"data row8 col9\" >25.8</td>\n",
       "      <td id=\"T_d4cf1_row8_col10\" class=\"data row8 col10\" >11.0</td>\n",
       "      <td id=\"T_d4cf1_row8_col11\" class=\"data row8 col11\" >53.6</td>\n",
       "      <td id=\"T_d4cf1_row8_col12\" class=\"data row8 col12\" >25.4</td>\n",
       "      <td id=\"T_d4cf1_row8_col13\" class=\"data row8 col13\" >-19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d4cf1_row9_col0\" class=\"data row9 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=0.13:kmd=mpnet_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row9_col1\" class=\"data row9 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row9_col2\" class=\"data row9 col2\" >37.2</td>\n",
       "      <td id=\"T_d4cf1_row9_col3\" class=\"data row9 col3\" >34.1</td>\n",
       "      <td id=\"T_d4cf1_row9_col4\" class=\"data row9 col4\" >5.8</td>\n",
       "      <td id=\"T_d4cf1_row9_col5\" class=\"data row9 col5\" >11.8</td>\n",
       "      <td id=\"T_d4cf1_row9_col6\" class=\"data row9 col6\" >33.7</td>\n",
       "      <td id=\"T_d4cf1_row9_col7\" class=\"data row9 col7\" >29.5</td>\n",
       "      <td id=\"T_d4cf1_row9_col8\" class=\"data row9 col8\" >8.3</td>\n",
       "      <td id=\"T_d4cf1_row9_col9\" class=\"data row9 col9\" >29.8</td>\n",
       "      <td id=\"T_d4cf1_row9_col10\" class=\"data row9 col10\" >8.5</td>\n",
       "      <td id=\"T_d4cf1_row9_col11\" class=\"data row9 col11\" >53.0</td>\n",
       "      <td id=\"T_d4cf1_row9_col12\" class=\"data row9 col12\" >25.2</td>\n",
       "      <td id=\"T_d4cf1_row9_col13\" class=\"data row9 col13\" >-19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_d4cf1_row10_col0\" class=\"data row10 col0\" >llama-7b_wizardlm_score=log:pmi:neg_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row10_col1\" class=\"data row10 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row10_col2\" class=\"data row10 col2\" >37.0</td>\n",
       "      <td id=\"T_d4cf1_row10_col3\" class=\"data row10 col3\" >36.6</td>\n",
       "      <td id=\"T_d4cf1_row10_col4\" class=\"data row10 col4\" >5.2</td>\n",
       "      <td id=\"T_d4cf1_row10_col5\" class=\"data row10 col5\" >9.4</td>\n",
       "      <td id=\"T_d4cf1_row10_col6\" class=\"data row10 col6\" >32.7</td>\n",
       "      <td id=\"T_d4cf1_row10_col7\" class=\"data row10 col7\" >29.1</td>\n",
       "      <td id=\"T_d4cf1_row10_col8\" class=\"data row10 col8\" >8.2</td>\n",
       "      <td id=\"T_d4cf1_row10_col9\" class=\"data row10 col9\" >27.9</td>\n",
       "      <td id=\"T_d4cf1_row10_col10\" class=\"data row10 col10\" >9.1</td>\n",
       "      <td id=\"T_d4cf1_row10_col11\" class=\"data row10 col11\" >52.4</td>\n",
       "      <td id=\"T_d4cf1_row10_col12\" class=\"data row10 col12\" >24.8</td>\n",
       "      <td id=\"T_d4cf1_row10_col13\" class=\"data row10 col13\" >-23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_d4cf1_row11_col0\" class=\"data row11 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=auto10000:kmd=llama7b:kemb=grad+rp+loraB_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row11_col1\" class=\"data row11 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row11_col2\" class=\"data row11 col2\" >37.2</td>\n",
       "      <td id=\"T_d4cf1_row11_col3\" class=\"data row11 col3\" >33.8</td>\n",
       "      <td id=\"T_d4cf1_row11_col4\" class=\"data row11 col4\" >6.0</td>\n",
       "      <td id=\"T_d4cf1_row11_col5\" class=\"data row11 col5\" >16.8</td>\n",
       "      <td id=\"T_d4cf1_row11_col6\" class=\"data row11 col6\" >25.5</td>\n",
       "      <td id=\"T_d4cf1_row11_col7\" class=\"data row11 col7\" >29.4</td>\n",
       "      <td id=\"T_d4cf1_row11_col8\" class=\"data row11 col8\" >6.7</td>\n",
       "      <td id=\"T_d4cf1_row11_col9\" class=\"data row11 col9\" >25.3</td>\n",
       "      <td id=\"T_d4cf1_row11_col10\" class=\"data row11 col10\" >8.5</td>\n",
       "      <td id=\"T_d4cf1_row11_col11\" class=\"data row11 col11\" >56.6</td>\n",
       "      <td id=\"T_d4cf1_row11_col12\" class=\"data row11 col12\" >24.6</td>\n",
       "      <td id=\"T_d4cf1_row11_col13\" class=\"data row11 col13\" >-23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_d4cf1_row12_col0\" class=\"data row12 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.3:k=vmf:gamma=0.04:kmd=mpnet:q=ifd:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row12_col1\" class=\"data row12 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row12_col2\" class=\"data row12 col2\" >35.2</td>\n",
       "      <td id=\"T_d4cf1_row12_col3\" class=\"data row12 col3\" >34.8</td>\n",
       "      <td id=\"T_d4cf1_row12_col4\" class=\"data row12 col4\" >6.2</td>\n",
       "      <td id=\"T_d4cf1_row12_col5\" class=\"data row12 col5\" >9.8</td>\n",
       "      <td id=\"T_d4cf1_row12_col6\" class=\"data row12 col6\" >30.6</td>\n",
       "      <td id=\"T_d4cf1_row12_col7\" class=\"data row12 col7\" >29.2</td>\n",
       "      <td id=\"T_d4cf1_row12_col8\" class=\"data row12 col8\" >8.0</td>\n",
       "      <td id=\"T_d4cf1_row12_col9\" class=\"data row12 col9\" >26.7</td>\n",
       "      <td id=\"T_d4cf1_row12_col10\" class=\"data row12 col10\" >10.4</td>\n",
       "      <td id=\"T_d4cf1_row12_col11\" class=\"data row12 col11\" >54.7</td>\n",
       "      <td id=\"T_d4cf1_row12_col12\" class=\"data row12 col12\" >24.6</td>\n",
       "      <td id=\"T_d4cf1_row12_col13\" class=\"data row12 col13\" >-24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_d4cf1_row13_col0\" class=\"data row13 col0\" >llama-7b_wizardlm_score=dppmap:theta=0.3:k=vmf:gamma=0.043:kmd=mpnet:q=ifd+neg:qmd=llama7b_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row13_col1\" class=\"data row13 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row13_col2\" class=\"data row13 col2\" >34.6</td>\n",
       "      <td id=\"T_d4cf1_row13_col3\" class=\"data row13 col3\" >31.9</td>\n",
       "      <td id=\"T_d4cf1_row13_col4\" class=\"data row13 col4\" >5.4</td>\n",
       "      <td id=\"T_d4cf1_row13_col5\" class=\"data row13 col5\" >10.0</td>\n",
       "      <td id=\"T_d4cf1_row13_col6\" class=\"data row13 col6\" >29.2</td>\n",
       "      <td id=\"T_d4cf1_row13_col7\" class=\"data row13 col7\" >31.5</td>\n",
       "      <td id=\"T_d4cf1_row13_col8\" class=\"data row13 col8\" >8.6</td>\n",
       "      <td id=\"T_d4cf1_row13_col9\" class=\"data row13 col9\" >26.1</td>\n",
       "      <td id=\"T_d4cf1_row13_col10\" class=\"data row13 col10\" >14.0</td>\n",
       "      <td id=\"T_d4cf1_row13_col11\" class=\"data row13 col11\" >52.8</td>\n",
       "      <td id=\"T_d4cf1_row13_col12\" class=\"data row13 col12\" >24.4</td>\n",
       "      <td id=\"T_d4cf1_row13_col13\" class=\"data row13 col13\" >-25.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_d4cf1_row14_col0\" class=\"data row14 col0\" >llama-7b_wizardlm_score=dedup:md=mpnet:emb=text+embedding_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row14_col1\" class=\"data row14 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row14_col2\" class=\"data row14 col2\" >36.0</td>\n",
       "      <td id=\"T_d4cf1_row14_col3\" class=\"data row14 col3\" >33.7</td>\n",
       "      <td id=\"T_d4cf1_row14_col4\" class=\"data row14 col4\" >4.0</td>\n",
       "      <td id=\"T_d4cf1_row14_col5\" class=\"data row14 col5\" >12.2</td>\n",
       "      <td id=\"T_d4cf1_row14_col6\" class=\"data row14 col6\" >26.9</td>\n",
       "      <td id=\"T_d4cf1_row14_col7\" class=\"data row14 col7\" >29.4</td>\n",
       "      <td id=\"T_d4cf1_row14_col8\" class=\"data row14 col8\" >9.0</td>\n",
       "      <td id=\"T_d4cf1_row14_col9\" class=\"data row14 col9\" >28.5</td>\n",
       "      <td id=\"T_d4cf1_row14_col10\" class=\"data row14 col10\" >4.3</td>\n",
       "      <td id=\"T_d4cf1_row14_col11\" class=\"data row14 col11\" >54.0</td>\n",
       "      <td id=\"T_d4cf1_row14_col12\" class=\"data row14 col12\" >23.8</td>\n",
       "      <td id=\"T_d4cf1_row14_col13\" class=\"data row14 col13\" >-27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_d4cf1_row15_col0\" class=\"data row15 col0\" >llama-7b_wizardlm_score=dppmap:k=rbf:gamma=0.001:kmd=llama7b:kemb=grad+rp+loraB_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row15_col1\" class=\"data row15 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row15_col2\" class=\"data row15 col2\" >38.0</td>\n",
       "      <td id=\"T_d4cf1_row15_col3\" class=\"data row15 col3\" >36.9</td>\n",
       "      <td id=\"T_d4cf1_row15_col4\" class=\"data row15 col4\" >5.6</td>\n",
       "      <td id=\"T_d4cf1_row15_col5\" class=\"data row15 col5\" >9.0</td>\n",
       "      <td id=\"T_d4cf1_row15_col6\" class=\"data row15 col6\" >29.4</td>\n",
       "      <td id=\"T_d4cf1_row15_col7\" class=\"data row15 col7\" >28.8</td>\n",
       "      <td id=\"T_d4cf1_row15_col8\" class=\"data row15 col8\" >7.5</td>\n",
       "      <td id=\"T_d4cf1_row15_col9\" class=\"data row15 col9\" >27.0</td>\n",
       "      <td id=\"T_d4cf1_row15_col10\" class=\"data row15 col10\" >9.8</td>\n",
       "      <td id=\"T_d4cf1_row15_col11\" class=\"data row15 col11\" >45.5</td>\n",
       "      <td id=\"T_d4cf1_row15_col12\" class=\"data row15 col12\" >23.7</td>\n",
       "      <td id=\"T_d4cf1_row15_col13\" class=\"data row15 col13\" >-28.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_d4cf1_row16_col0\" class=\"data row16 col0\" >llama-7b_wizardlm_score=ifd_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row16_col1\" class=\"data row16 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row16_col2\" class=\"data row16 col2\" >38.9</td>\n",
       "      <td id=\"T_d4cf1_row16_col3\" class=\"data row16 col3\" >34.0</td>\n",
       "      <td id=\"T_d4cf1_row16_col4\" class=\"data row16 col4\" >4.2</td>\n",
       "      <td id=\"T_d4cf1_row16_col5\" class=\"data row16 col5\" >11.8</td>\n",
       "      <td id=\"T_d4cf1_row16_col6\" class=\"data row16 col6\" >29.0</td>\n",
       "      <td id=\"T_d4cf1_row16_col7\" class=\"data row16 col7\" >30.0</td>\n",
       "      <td id=\"T_d4cf1_row16_col8\" class=\"data row16 col8\" >8.2</td>\n",
       "      <td id=\"T_d4cf1_row16_col9\" class=\"data row16 col9\" >25.8</td>\n",
       "      <td id=\"T_d4cf1_row16_col10\" class=\"data row16 col10\" >11.0</td>\n",
       "      <td id=\"T_d4cf1_row16_col11\" class=\"data row16 col11\" >41.3</td>\n",
       "      <td id=\"T_d4cf1_row16_col12\" class=\"data row16 col12\" >23.4</td>\n",
       "      <td id=\"T_d4cf1_row16_col13\" class=\"data row16 col13\" >-28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_d4cf1_row17_col0\" class=\"data row17 col0\" >llama-7b_wizardlm_score=el2n:agg=mean_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row17_col1\" class=\"data row17 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row17_col2\" class=\"data row17 col2\" >34.5</td>\n",
       "      <td id=\"T_d4cf1_row17_col3\" class=\"data row17 col3\" >33.0</td>\n",
       "      <td id=\"T_d4cf1_row17_col4\" class=\"data row17 col4\" >5.2</td>\n",
       "      <td id=\"T_d4cf1_row17_col5\" class=\"data row17 col5\" >12.4</td>\n",
       "      <td id=\"T_d4cf1_row17_col6\" class=\"data row17 col6\" >30.5</td>\n",
       "      <td id=\"T_d4cf1_row17_col7\" class=\"data row17 col7\" >29.4</td>\n",
       "      <td id=\"T_d4cf1_row17_col8\" class=\"data row17 col8\" >8.9</td>\n",
       "      <td id=\"T_d4cf1_row17_col9\" class=\"data row17 col9\" >21.6</td>\n",
       "      <td id=\"T_d4cf1_row17_col10\" class=\"data row17 col10\" >11.0</td>\n",
       "      <td id=\"T_d4cf1_row17_col11\" class=\"data row17 col11\" >45.4</td>\n",
       "      <td id=\"T_d4cf1_row17_col12\" class=\"data row17 col12\" >23.2</td>\n",
       "      <td id=\"T_d4cf1_row17_col13\" class=\"data row17 col13\" >-29.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_d4cf1_row18_col0\" class=\"data row18 col0\" >llama-7b_wizardlm_score=log:prob:neg_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row18_col1\" class=\"data row18 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row18_col2\" class=\"data row18 col2\" >36.1</td>\n",
       "      <td id=\"T_d4cf1_row18_col3\" class=\"data row18 col3\" >32.1</td>\n",
       "      <td id=\"T_d4cf1_row18_col4\" class=\"data row18 col4\" >6.0</td>\n",
       "      <td id=\"T_d4cf1_row18_col5\" class=\"data row18 col5\" >13.8</td>\n",
       "      <td id=\"T_d4cf1_row18_col6\" class=\"data row18 col6\" >26.7</td>\n",
       "      <td id=\"T_d4cf1_row18_col7\" class=\"data row18 col7\" >29.9</td>\n",
       "      <td id=\"T_d4cf1_row18_col8\" class=\"data row18 col8\" >7.5</td>\n",
       "      <td id=\"T_d4cf1_row18_col9\" class=\"data row18 col9\" >26.6</td>\n",
       "      <td id=\"T_d4cf1_row18_col10\" class=\"data row18 col10\" >7.3</td>\n",
       "      <td id=\"T_d4cf1_row18_col11\" class=\"data row18 col11\" >45.7</td>\n",
       "      <td id=\"T_d4cf1_row18_col12\" class=\"data row18 col12\" >23.2</td>\n",
       "      <td id=\"T_d4cf1_row18_col13\" class=\"data row18 col13\" >-29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_d4cf1_row19_col0\" class=\"data row19 col0\" >llama-7b_wizardlm_ep=2</td>\n",
       "      <td id=\"T_d4cf1_row19_col1\" class=\"data row19 col1\" >None</td>\n",
       "      <td id=\"T_d4cf1_row19_col2\" class=\"data row19 col2\" >38.1</td>\n",
       "      <td id=\"T_d4cf1_row19_col3\" class=\"data row19 col3\" >34.4</td>\n",
       "      <td id=\"T_d4cf1_row19_col4\" class=\"data row19 col4\" >4.6</td>\n",
       "      <td id=\"T_d4cf1_row19_col5\" class=\"data row19 col5\" >12.2</td>\n",
       "      <td id=\"T_d4cf1_row19_col6\" class=\"data row19 col6\" >31.9</td>\n",
       "      <td id=\"T_d4cf1_row19_col7\" class=\"data row19 col7\" >28.4</td>\n",
       "      <td id=\"T_d4cf1_row19_col8\" class=\"data row19 col8\" >10.6</td>\n",
       "      <td id=\"T_d4cf1_row19_col9\" class=\"data row19 col9\" >27.2</td>\n",
       "      <td id=\"T_d4cf1_row19_col10\" class=\"data row19 col10\" >14.6</td>\n",
       "      <td id=\"T_d4cf1_row19_col11\" class=\"data row19 col11\" >nan</td>\n",
       "      <td id=\"T_d4cf1_row19_col12\" class=\"data row19 col12\" >22.4</td>\n",
       "      <td id=\"T_d4cf1_row19_col13\" class=\"data row19 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_d4cf1_row20_col0\" class=\"data row20 col0\" >llama-7b_wizardlm_score=ifd:neg_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row20_col1\" class=\"data row20 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row20_col2\" class=\"data row20 col2\" >36.4</td>\n",
       "      <td id=\"T_d4cf1_row20_col3\" class=\"data row20 col3\" >33.5</td>\n",
       "      <td id=\"T_d4cf1_row20_col4\" class=\"data row20 col4\" >4.6</td>\n",
       "      <td id=\"T_d4cf1_row20_col5\" class=\"data row20 col5\" >10.8</td>\n",
       "      <td id=\"T_d4cf1_row20_col6\" class=\"data row20 col6\" >17.3</td>\n",
       "      <td id=\"T_d4cf1_row20_col7\" class=\"data row20 col7\" >27.8</td>\n",
       "      <td id=\"T_d4cf1_row20_col8\" class=\"data row20 col8\" >7.3</td>\n",
       "      <td id=\"T_d4cf1_row20_col9\" class=\"data row20 col9\" >24.2</td>\n",
       "      <td id=\"T_d4cf1_row20_col10\" class=\"data row20 col10\" >6.1</td>\n",
       "      <td id=\"T_d4cf1_row20_col11\" class=\"data row20 col11\" >56.3</td>\n",
       "      <td id=\"T_d4cf1_row20_col12\" class=\"data row20 col12\" >22.4</td>\n",
       "      <td id=\"T_d4cf1_row20_col13\" class=\"data row20 col13\" >-36.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_d4cf1_row21_col0\" class=\"data row21 col0\" >llama-7b_wizardlm_score=dppmap:k=lin:kmd=mpnet_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row21_col1\" class=\"data row21 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row21_col2\" class=\"data row21 col2\" >37.9</td>\n",
       "      <td id=\"T_d4cf1_row21_col3\" class=\"data row21 col3\" >32.8</td>\n",
       "      <td id=\"T_d4cf1_row21_col4\" class=\"data row21 col4\" >5.2</td>\n",
       "      <td id=\"T_d4cf1_row21_col5\" class=\"data row21 col5\" >14.0</td>\n",
       "      <td id=\"T_d4cf1_row21_col6\" class=\"data row21 col6\" >28.5</td>\n",
       "      <td id=\"T_d4cf1_row21_col7\" class=\"data row21 col7\" >29.6</td>\n",
       "      <td id=\"T_d4cf1_row21_col8\" class=\"data row21 col8\" >9.5</td>\n",
       "      <td id=\"T_d4cf1_row21_col9\" class=\"data row21 col9\" >27.6</td>\n",
       "      <td id=\"T_d4cf1_row21_col10\" class=\"data row21 col10\" >9.1</td>\n",
       "      <td id=\"T_d4cf1_row21_col11\" class=\"data row21 col11\" >nan</td>\n",
       "      <td id=\"T_d4cf1_row21_col12\" class=\"data row21 col12\" >21.6</td>\n",
       "      <td id=\"T_d4cf1_row21_col13\" class=\"data row21 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_d4cf1_row22_col0\" class=\"data row22 col0\" >llama-7b_wizardlm_score=log:pmi_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row22_col1\" class=\"data row22 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row22_col2\" class=\"data row22 col2\" >35.2</td>\n",
       "      <td id=\"T_d4cf1_row22_col3\" class=\"data row22 col3\" >28.5</td>\n",
       "      <td id=\"T_d4cf1_row22_col4\" class=\"data row22 col4\" >6.4</td>\n",
       "      <td id=\"T_d4cf1_row22_col5\" class=\"data row22 col5\" >12.4</td>\n",
       "      <td id=\"T_d4cf1_row22_col6\" class=\"data row22 col6\" >16.1</td>\n",
       "      <td id=\"T_d4cf1_row22_col7\" class=\"data row22 col7\" >29.7</td>\n",
       "      <td id=\"T_d4cf1_row22_col8\" class=\"data row22 col8\" >8.2</td>\n",
       "      <td id=\"T_d4cf1_row22_col9\" class=\"data row22 col9\" >19.8</td>\n",
       "      <td id=\"T_d4cf1_row22_col10\" class=\"data row22 col10\" >3.0</td>\n",
       "      <td id=\"T_d4cf1_row22_col11\" class=\"data row22 col11\" >51.6</td>\n",
       "      <td id=\"T_d4cf1_row22_col12\" class=\"data row22 col12\" >21.1</td>\n",
       "      <td id=\"T_d4cf1_row22_col13\" class=\"data row22 col13\" >-32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4cf1_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_d4cf1_row23_col0\" class=\"data row23 col0\" >llama-7b_wizardlm_score=grad:loraB:l2n_pace=prune:size=50000:ep=5</td>\n",
       "      <td id=\"T_d4cf1_row23_col1\" class=\"data row23 col1\" >50000</td>\n",
       "      <td id=\"T_d4cf1_row23_col2\" class=\"data row23 col2\" >37.0</td>\n",
       "      <td id=\"T_d4cf1_row23_col3\" class=\"data row23 col3\" >30.7</td>\n",
       "      <td id=\"T_d4cf1_row23_col4\" class=\"data row23 col4\" >5.4</td>\n",
       "      <td id=\"T_d4cf1_row23_col5\" class=\"data row23 col5\" >11.8</td>\n",
       "      <td id=\"T_d4cf1_row23_col6\" class=\"data row23 col6\" >21.2</td>\n",
       "      <td id=\"T_d4cf1_row23_col7\" class=\"data row23 col7\" >29.2</td>\n",
       "      <td id=\"T_d4cf1_row23_col8\" class=\"data row23 col8\" >8.8</td>\n",
       "      <td id=\"T_d4cf1_row23_col9\" class=\"data row23 col9\" >22.2</td>\n",
       "      <td id=\"T_d4cf1_row23_col10\" class=\"data row23 col10\" >11.0</td>\n",
       "      <td id=\"T_d4cf1_row23_col11\" class=\"data row23 col11\" >nan</td>\n",
       "      <td id=\"T_d4cf1_row23_col12\" class=\"data row23 col12\" >19.7</td>\n",
       "      <td id=\"T_d4cf1_row23_col13\" class=\"data row23 col13\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc80ba9b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5267f_row0_col0, #T_5267f_row0_col1, #T_5267f_row1_col0, #T_5267f_row1_col1, #T_5267f_row2_col0, #T_5267f_row2_col1, #T_5267f_row3_col0, #T_5267f_row3_col1, #T_5267f_row4_col0, #T_5267f_row4_col1, #T_5267f_row5_col0, #T_5267f_row5_col1, #T_5267f_row6_col0, #T_5267f_row6_col1, #T_5267f_row7_col0, #T_5267f_row7_col1, #T_5267f_row8_col0, #T_5267f_row8_col1, #T_5267f_row9_col0, #T_5267f_row9_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5267f_row0_col2, #T_5267f_row0_col5, #T_5267f_row0_col9, #T_5267f_row0_col12, #T_5267f_row1_col3, #T_5267f_row1_col13, #T_5267f_row2_col11, #T_5267f_row3_col6, #T_5267f_row4_col7, #T_5267f_row5_col5, #T_5267f_row7_col8, #T_5267f_row7_col10, #T_5267f_row8_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row0_col4, #T_5267f_row3_col4, #T_5267f_row6_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row0_col6, #T_5267f_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row0_col7, #T_5267f_row3_col2, #T_5267f_row4_col5, #T_5267f_row4_col10, #T_5267f_row4_col11, #T_5267f_row5_col9, #T_5267f_row6_col4, #T_5267f_row6_col13, #T_5267f_row8_col10, #T_5267f_row9_col3, #T_5267f_row9_col6, #T_5267f_row9_col8, #T_5267f_row9_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #dc5d4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row0_col11, #T_5267f_row7_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row1_col5, #T_5267f_row3_col5, #T_5267f_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row1_col8, #T_5267f_row7_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row1_col10, #T_5267f_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row2_col9, #T_5267f_row5_col2, #T_5267f_row8_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row2_col12, #T_5267f_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row4_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row5_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row5_col10, #T_5267f_row6_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row5_col11, #T_5267f_row9_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row5_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row5_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row6_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row6_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row6_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row6_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row6_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row6_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row6_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row6_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row7_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row7_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row7_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row7_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row7_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row7_col11, #T_5267f_row7_col13, #T_5267f_row8_col11, #T_5267f_row8_col13, #T_5267f_row9_col11, #T_5267f_row9_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row7_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row8_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row8_col3, #T_5267f_row9_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row8_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row8_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row8_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row8_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row8_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row9_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row9_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5267f_row9_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5267f_row9_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5267f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5267f_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_5267f_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_5267f_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_5267f_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_5267f_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_5267f_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_5267f_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_5267f_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_5267f_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_5267f_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_5267f_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_5267f_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(v.Davinci-003)/WR</th>\n",
       "      <th id=\"T_5267f_level0_col12\" class=\"col_heading level0 col12\" >Average</th>\n",
       "      <th id=\"T_5267f_level0_col13\" class=\"col_heading level0 col13\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5267f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5267f_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm_score=dppmap:k=vmf:gamma=0.13:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_5267f_row0_col1\" class=\"data row0 col1\" >100000</td>\n",
       "      <td id=\"T_5267f_row0_col2\" class=\"data row0 col2\" >38.6</td>\n",
       "      <td id=\"T_5267f_row0_col3\" class=\"data row0 col3\" >32.8</td>\n",
       "      <td id=\"T_5267f_row0_col4\" class=\"data row0 col4\" >4.4</td>\n",
       "      <td id=\"T_5267f_row0_col5\" class=\"data row0 col5\" >14.2</td>\n",
       "      <td id=\"T_5267f_row0_col6\" class=\"data row0 col6\" >30.1</td>\n",
       "      <td id=\"T_5267f_row0_col7\" class=\"data row0 col7\" >28.1</td>\n",
       "      <td id=\"T_5267f_row0_col8\" class=\"data row0 col8\" >10.0</td>\n",
       "      <td id=\"T_5267f_row0_col9\" class=\"data row0 col9\" >34.7</td>\n",
       "      <td id=\"T_5267f_row0_col10\" class=\"data row0 col10\" >13.4</td>\n",
       "      <td id=\"T_5267f_row0_col11\" class=\"data row0 col11\" >52.7</td>\n",
       "      <td id=\"T_5267f_row0_col12\" class=\"data row0 col12\" >25.9</td>\n",
       "      <td id=\"T_5267f_row0_col13\" class=\"data row0 col13\" >-17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5267f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5267f_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm_score=dedup:md=mpnet:emb=text+embedding_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_5267f_row1_col1\" class=\"data row1 col1\" >100000</td>\n",
       "      <td id=\"T_5267f_row1_col2\" class=\"data row1 col2\" >36.7</td>\n",
       "      <td id=\"T_5267f_row1_col3\" class=\"data row1 col3\" >35.7</td>\n",
       "      <td id=\"T_5267f_row1_col4\" class=\"data row1 col4\" >4.2</td>\n",
       "      <td id=\"T_5267f_row1_col5\" class=\"data row1 col5\" >13.4</td>\n",
       "      <td id=\"T_5267f_row1_col6\" class=\"data row1 col6\" >31.5</td>\n",
       "      <td id=\"T_5267f_row1_col7\" class=\"data row1 col7\" >29.3</td>\n",
       "      <td id=\"T_5267f_row1_col8\" class=\"data row1 col8\" >8.1</td>\n",
       "      <td id=\"T_5267f_row1_col9\" class=\"data row1 col9\" >30.9</td>\n",
       "      <td id=\"T_5267f_row1_col10\" class=\"data row1 col10\" >12.8</td>\n",
       "      <td id=\"T_5267f_row1_col11\" class=\"data row1 col11\" >53.9</td>\n",
       "      <td id=\"T_5267f_row1_col12\" class=\"data row1 col12\" >25.6</td>\n",
       "      <td id=\"T_5267f_row1_col13\" class=\"data row1 col13\" >-17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5267f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5267f_row2_col0\" class=\"data row2 col0\" >score=random:s=(\\d)_pace=prune:size=100000_avg (N=2)</td>\n",
       "      <td id=\"T_5267f_row2_col1\" class=\"data row2 col1\" >100000</td>\n",
       "      <td id=\"T_5267f_row2_col2\" class=\"data row2 col2\" >37.7</td>\n",
       "      <td id=\"T_5267f_row2_col3\" class=\"data row2 col3\" >34.6</td>\n",
       "      <td id=\"T_5267f_row2_col4\" class=\"data row2 col4\" >4.9</td>\n",
       "      <td id=\"T_5267f_row2_col5\" class=\"data row2 col5\" >10.9</td>\n",
       "      <td id=\"T_5267f_row2_col6\" class=\"data row2 col6\" >30.3</td>\n",
       "      <td id=\"T_5267f_row2_col7\" class=\"data row2 col7\" >28.6</td>\n",
       "      <td id=\"T_5267f_row2_col8\" class=\"data row2 col8\" >7.8</td>\n",
       "      <td id=\"T_5267f_row2_col9\" class=\"data row2 col9\" >27.3</td>\n",
       "      <td id=\"T_5267f_row2_col10\" class=\"data row2 col10\" >13.7</td>\n",
       "      <td id=\"T_5267f_row2_col11\" class=\"data row2 col11\" >53.9</td>\n",
       "      <td id=\"T_5267f_row2_col12\" class=\"data row2 col12\" >25.0</td>\n",
       "      <td id=\"T_5267f_row2_col13\" class=\"data row2 col13\" >-22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5267f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5267f_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm_score=dppmap:k=lin:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_5267f_row3_col1\" class=\"data row3 col1\" >100000</td>\n",
       "      <td id=\"T_5267f_row3_col2\" class=\"data row3 col2\" >34.7</td>\n",
       "      <td id=\"T_5267f_row3_col3\" class=\"data row3 col3\" >34.0</td>\n",
       "      <td id=\"T_5267f_row3_col4\" class=\"data row3 col4\" >4.4</td>\n",
       "      <td id=\"T_5267f_row3_col5\" class=\"data row3 col5\" >13.4</td>\n",
       "      <td id=\"T_5267f_row3_col6\" class=\"data row3 col6\" >32.8</td>\n",
       "      <td id=\"T_5267f_row3_col7\" class=\"data row3 col7\" >28.7</td>\n",
       "      <td id=\"T_5267f_row3_col8\" class=\"data row3 col8\" >9.2</td>\n",
       "      <td id=\"T_5267f_row3_col9\" class=\"data row3 col9\" >29.9</td>\n",
       "      <td id=\"T_5267f_row3_col10\" class=\"data row3 col10\" >11.0</td>\n",
       "      <td id=\"T_5267f_row3_col11\" class=\"data row3 col11\" >51.6</td>\n",
       "      <td id=\"T_5267f_row3_col12\" class=\"data row3 col12\" >25.0</td>\n",
       "      <td id=\"T_5267f_row3_col13\" class=\"data row3 col13\" >-22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5267f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5267f_row4_col0\" class=\"data row4 col0\" >llama-7b_wizardlm_score=ifd_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_5267f_row4_col1\" class=\"data row4 col1\" >100000</td>\n",
       "      <td id=\"T_5267f_row4_col2\" class=\"data row4 col2\" >38.0</td>\n",
       "      <td id=\"T_5267f_row4_col3\" class=\"data row4 col3\" >34.9</td>\n",
       "      <td id=\"T_5267f_row4_col4\" class=\"data row4 col4\" >5.8</td>\n",
       "      <td id=\"T_5267f_row4_col5\" class=\"data row4 col5\" >9.2</td>\n",
       "      <td id=\"T_5267f_row4_col6\" class=\"data row4 col6\" >31.8</td>\n",
       "      <td id=\"T_5267f_row4_col7\" class=\"data row4 col7\" >30.8</td>\n",
       "      <td id=\"T_5267f_row4_col8\" class=\"data row4 col8\" >8.4</td>\n",
       "      <td id=\"T_5267f_row4_col9\" class=\"data row4 col9\" >25.3</td>\n",
       "      <td id=\"T_5267f_row4_col10\" class=\"data row4 col10\" >9.1</td>\n",
       "      <td id=\"T_5267f_row4_col11\" class=\"data row4 col11\" >49.8</td>\n",
       "      <td id=\"T_5267f_row4_col12\" class=\"data row4 col12\" >24.3</td>\n",
       "      <td id=\"T_5267f_row4_col13\" class=\"data row4 col13\" >-23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5267f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5267f_row5_col0\" class=\"data row5 col0\" >llama-7b_wizardlm_score=log:prob:neg_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_5267f_row5_col1\" class=\"data row5 col1\" >100000</td>\n",
       "      <td id=\"T_5267f_row5_col2\" class=\"data row5 col2\" >36.4</td>\n",
       "      <td id=\"T_5267f_row5_col3\" class=\"data row5 col3\" >32.8</td>\n",
       "      <td id=\"T_5267f_row5_col4\" class=\"data row5 col4\" >5.0</td>\n",
       "      <td id=\"T_5267f_row5_col5\" class=\"data row5 col5\" >14.2</td>\n",
       "      <td id=\"T_5267f_row5_col6\" class=\"data row5 col6\" >27.4</td>\n",
       "      <td id=\"T_5267f_row5_col7\" class=\"data row5 col7\" >30.3</td>\n",
       "      <td id=\"T_5267f_row5_col8\" class=\"data row5 col8\" >9.1</td>\n",
       "      <td id=\"T_5267f_row5_col9\" class=\"data row5 col9\" >21.6</td>\n",
       "      <td id=\"T_5267f_row5_col10\" class=\"data row5 col10\" >11.6</td>\n",
       "      <td id=\"T_5267f_row5_col11\" class=\"data row5 col11\" >50.4</td>\n",
       "      <td id=\"T_5267f_row5_col12\" class=\"data row5 col12\" >23.9</td>\n",
       "      <td id=\"T_5267f_row5_col13\" class=\"data row5 col13\" >-24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5267f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5267f_row6_col0\" class=\"data row6 col0\" >llama-7b_wizardlm_score=ifd:neg_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_5267f_row6_col1\" class=\"data row6 col1\" >100000</td>\n",
       "      <td id=\"T_5267f_row6_col2\" class=\"data row6 col2\" >35.4</td>\n",
       "      <td id=\"T_5267f_row6_col3\" class=\"data row6 col3\" >33.5</td>\n",
       "      <td id=\"T_5267f_row6_col4\" class=\"data row6 col4\" >3.4</td>\n",
       "      <td id=\"T_5267f_row6_col5\" class=\"data row6 col5\" >10.8</td>\n",
       "      <td id=\"T_5267f_row6_col6\" class=\"data row6 col6\" >27.8</td>\n",
       "      <td id=\"T_5267f_row6_col7\" class=\"data row6 col7\" >28.9</td>\n",
       "      <td id=\"T_5267f_row6_col8\" class=\"data row6 col8\" >8.1</td>\n",
       "      <td id=\"T_5267f_row6_col9\" class=\"data row6 col9\" >25.5</td>\n",
       "      <td id=\"T_5267f_row6_col10\" class=\"data row6 col10\" >11.6</td>\n",
       "      <td id=\"T_5267f_row6_col11\" class=\"data row6 col11\" >51.4</td>\n",
       "      <td id=\"T_5267f_row6_col12\" class=\"data row6 col12\" >23.6</td>\n",
       "      <td id=\"T_5267f_row6_col13\" class=\"data row6 col13\" >-33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5267f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_5267f_row7_col0\" class=\"data row7 col0\" >llama-7b_wizardlm_ep=2</td>\n",
       "      <td id=\"T_5267f_row7_col1\" class=\"data row7 col1\" >None</td>\n",
       "      <td id=\"T_5267f_row7_col2\" class=\"data row7 col2\" >38.1</td>\n",
       "      <td id=\"T_5267f_row7_col3\" class=\"data row7 col3\" >34.4</td>\n",
       "      <td id=\"T_5267f_row7_col4\" class=\"data row7 col4\" >4.6</td>\n",
       "      <td id=\"T_5267f_row7_col5\" class=\"data row7 col5\" >12.2</td>\n",
       "      <td id=\"T_5267f_row7_col6\" class=\"data row7 col6\" >31.9</td>\n",
       "      <td id=\"T_5267f_row7_col7\" class=\"data row7 col7\" >28.4</td>\n",
       "      <td id=\"T_5267f_row7_col8\" class=\"data row7 col8\" >10.6</td>\n",
       "      <td id=\"T_5267f_row7_col9\" class=\"data row7 col9\" >27.2</td>\n",
       "      <td id=\"T_5267f_row7_col10\" class=\"data row7 col10\" >14.6</td>\n",
       "      <td id=\"T_5267f_row7_col11\" class=\"data row7 col11\" >nan</td>\n",
       "      <td id=\"T_5267f_row7_col12\" class=\"data row7 col12\" >22.4</td>\n",
       "      <td id=\"T_5267f_row7_col13\" class=\"data row7 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5267f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_5267f_row8_col0\" class=\"data row8 col0\" >llama-7b_wizardlm_score=el2n:agg=mean_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_5267f_row8_col1\" class=\"data row8 col1\" >100000</td>\n",
       "      <td id=\"T_5267f_row8_col2\" class=\"data row8 col2\" >37.7</td>\n",
       "      <td id=\"T_5267f_row8_col3\" class=\"data row8 col3\" >32.4</td>\n",
       "      <td id=\"T_5267f_row8_col4\" class=\"data row8 col4\" >6.0</td>\n",
       "      <td id=\"T_5267f_row8_col5\" class=\"data row8 col5\" >11.4</td>\n",
       "      <td id=\"T_5267f_row8_col6\" class=\"data row8 col6\" >29.4</td>\n",
       "      <td id=\"T_5267f_row8_col7\" class=\"data row8 col7\" >29.7</td>\n",
       "      <td id=\"T_5267f_row8_col8\" class=\"data row8 col8\" >8.7</td>\n",
       "      <td id=\"T_5267f_row8_col9\" class=\"data row8 col9\" >24.9</td>\n",
       "      <td id=\"T_5267f_row8_col10\" class=\"data row8 col10\" >9.1</td>\n",
       "      <td id=\"T_5267f_row8_col11\" class=\"data row8 col11\" >nan</td>\n",
       "      <td id=\"T_5267f_row8_col12\" class=\"data row8 col12\" >21.0</td>\n",
       "      <td id=\"T_5267f_row8_col13\" class=\"data row8 col13\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5267f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_5267f_row9_col0\" class=\"data row9 col0\" >llama-7b_wizardlm_score=grad:loraB:l2n_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_5267f_row9_col1\" class=\"data row9 col1\" >100000</td>\n",
       "      <td id=\"T_5267f_row9_col2\" class=\"data row9 col2\" >36.8</td>\n",
       "      <td id=\"T_5267f_row9_col3\" class=\"data row9 col3\" >31.5</td>\n",
       "      <td id=\"T_5267f_row9_col4\" class=\"data row9 col4\" >4.8</td>\n",
       "      <td id=\"T_5267f_row9_col5\" class=\"data row9 col5\" >13.2</td>\n",
       "      <td id=\"T_5267f_row9_col6\" class=\"data row9 col6\" >23.6</td>\n",
       "      <td id=\"T_5267f_row9_col7\" class=\"data row9 col7\" >28.8</td>\n",
       "      <td id=\"T_5267f_row9_col8\" class=\"data row9 col8\" >6.0</td>\n",
       "      <td id=\"T_5267f_row9_col9\" class=\"data row9 col9\" >23.7</td>\n",
       "      <td id=\"T_5267f_row9_col10\" class=\"data row9 col10\" >10.4</td>\n",
       "      <td id=\"T_5267f_row9_col11\" class=\"data row9 col11\" >nan</td>\n",
       "      <td id=\"T_5267f_row9_col12\" class=\"data row9 col12\" >19.9</td>\n",
       "      <td id=\"T_5267f_row9_col13\" class=\"data row9 col13\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc80baa7a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1177e_row0_col0, #T_1177e_row0_col1, #T_1177e_row1_col0, #T_1177e_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_1177e_row0_col2, #T_1177e_row0_col3, #T_1177e_row0_col7, #T_1177e_row0_col9, #T_1177e_row0_col12, #T_1177e_row1_col4, #T_1177e_row1_col5, #T_1177e_row1_col6, #T_1177e_row1_col8, #T_1177e_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1177e_row0_col4, #T_1177e_row0_col5, #T_1177e_row0_col6, #T_1177e_row0_col8, #T_1177e_row0_col10, #T_1177e_row0_col11, #T_1177e_row0_col13, #T_1177e_row1_col2, #T_1177e_row1_col3, #T_1177e_row1_col7, #T_1177e_row1_col9, #T_1177e_row1_col11, #T_1177e_row1_col12, #T_1177e_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1177e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1177e_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_1177e_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_1177e_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_1177e_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_1177e_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_1177e_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_1177e_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_1177e_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_1177e_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_1177e_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_1177e_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_1177e_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(v.Davinci-003)/WR</th>\n",
       "      <th id=\"T_1177e_level0_col12\" class=\"col_heading level0 col12\" >Average</th>\n",
       "      <th id=\"T_1177e_level0_col13\" class=\"col_heading level0 col13\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1177e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1177e_row0_col0\" class=\"data row0 col0\" >score=random:s=(\\d)_pace=prune:size=150000:ep=3_avg (N=1)</td>\n",
       "      <td id=\"T_1177e_row0_col1\" class=\"data row0 col1\" >150000</td>\n",
       "      <td id=\"T_1177e_row0_col2\" class=\"data row0 col2\" >39.8</td>\n",
       "      <td id=\"T_1177e_row0_col3\" class=\"data row0 col3\" >35.4</td>\n",
       "      <td id=\"T_1177e_row0_col4\" class=\"data row0 col4\" >4.0</td>\n",
       "      <td id=\"T_1177e_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_1177e_row0_col6\" class=\"data row0 col6\" >29.6</td>\n",
       "      <td id=\"T_1177e_row0_col7\" class=\"data row0 col7\" >29.0</td>\n",
       "      <td id=\"T_1177e_row0_col8\" class=\"data row0 col8\" >9.1</td>\n",
       "      <td id=\"T_1177e_row0_col9\" class=\"data row0 col9\" >27.5</td>\n",
       "      <td id=\"T_1177e_row0_col10\" class=\"data row0 col10\" >12.8</td>\n",
       "      <td id=\"T_1177e_row0_col11\" class=\"data row0 col11\" >55.5</td>\n",
       "      <td id=\"T_1177e_row0_col12\" class=\"data row0 col12\" >25.4</td>\n",
       "      <td id=\"T_1177e_row0_col13\" class=\"data row0 col13\" >-18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1177e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1177e_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm_ep=2</td>\n",
       "      <td id=\"T_1177e_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_1177e_row1_col2\" class=\"data row1 col2\" >38.1</td>\n",
       "      <td id=\"T_1177e_row1_col3\" class=\"data row1 col3\" >34.4</td>\n",
       "      <td id=\"T_1177e_row1_col4\" class=\"data row1 col4\" >4.6</td>\n",
       "      <td id=\"T_1177e_row1_col5\" class=\"data row1 col5\" >12.2</td>\n",
       "      <td id=\"T_1177e_row1_col6\" class=\"data row1 col6\" >31.9</td>\n",
       "      <td id=\"T_1177e_row1_col7\" class=\"data row1 col7\" >28.4</td>\n",
       "      <td id=\"T_1177e_row1_col8\" class=\"data row1 col8\" >10.6</td>\n",
       "      <td id=\"T_1177e_row1_col9\" class=\"data row1 col9\" >27.2</td>\n",
       "      <td id=\"T_1177e_row1_col10\" class=\"data row1 col10\" >14.6</td>\n",
       "      <td id=\"T_1177e_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_1177e_row1_col12\" class=\"data row1 col12\" >22.4</td>\n",
       "      <td id=\"T_1177e_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc7a5503a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_39431_row0_col0, #T_39431_row0_col1, #T_39431_row1_col0, #T_39431_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_39431_row0_col2, #T_39431_row0_col4, #T_39431_row0_col6, #T_39431_row0_col8, #T_39431_row0_col11, #T_39431_row0_col13, #T_39431_row1_col3, #T_39431_row1_col5, #T_39431_row1_col6, #T_39431_row1_col7, #T_39431_row1_col9, #T_39431_row1_col10, #T_39431_row1_col11, #T_39431_row1_col12, #T_39431_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_39431_row0_col3, #T_39431_row0_col5, #T_39431_row0_col7, #T_39431_row0_col9, #T_39431_row0_col10, #T_39431_row0_col12, #T_39431_row1_col2, #T_39431_row1_col4, #T_39431_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_39431\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_39431_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_39431_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_39431_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_39431_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_39431_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_39431_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_39431_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_39431_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_39431_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_39431_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_39431_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_39431_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(v.Davinci-003)/WR</th>\n",
       "      <th id=\"T_39431_level0_col12\" class=\"col_heading level0 col12\" >Average</th>\n",
       "      <th id=\"T_39431_level0_col13\" class=\"col_heading level0 col13\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_39431_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_39431_row0_col0\" class=\"data row0 col0\" >score=random:s=(\\d)_pace=prune:size=200000_avg (N=1)</td>\n",
       "      <td id=\"T_39431_row0_col1\" class=\"data row0 col1\" >200000</td>\n",
       "      <td id=\"T_39431_row0_col2\" class=\"data row0 col2\" >37.8</td>\n",
       "      <td id=\"T_39431_row0_col3\" class=\"data row0 col3\" >35.0</td>\n",
       "      <td id=\"T_39431_row0_col4\" class=\"data row0 col4\" >4.0</td>\n",
       "      <td id=\"T_39431_row0_col5\" class=\"data row0 col5\" >13.8</td>\n",
       "      <td id=\"T_39431_row0_col6\" class=\"data row0 col6\" >31.9</td>\n",
       "      <td id=\"T_39431_row0_col7\" class=\"data row0 col7\" >29.1</td>\n",
       "      <td id=\"T_39431_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_39431_row0_col9\" class=\"data row0 col9\" >29.0</td>\n",
       "      <td id=\"T_39431_row0_col10\" class=\"data row0 col10\" >15.9</td>\n",
       "      <td id=\"T_39431_row0_col11\" class=\"data row0 col11\" >53.4</td>\n",
       "      <td id=\"T_39431_row0_col12\" class=\"data row0 col12\" >25.9</td>\n",
       "      <td id=\"T_39431_row0_col13\" class=\"data row0 col13\" >-15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39431_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_39431_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm_ep=2</td>\n",
       "      <td id=\"T_39431_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_39431_row1_col2\" class=\"data row1 col2\" >38.1</td>\n",
       "      <td id=\"T_39431_row1_col3\" class=\"data row1 col3\" >34.4</td>\n",
       "      <td id=\"T_39431_row1_col4\" class=\"data row1 col4\" >4.6</td>\n",
       "      <td id=\"T_39431_row1_col5\" class=\"data row1 col5\" >12.2</td>\n",
       "      <td id=\"T_39431_row1_col6\" class=\"data row1 col6\" >31.9</td>\n",
       "      <td id=\"T_39431_row1_col7\" class=\"data row1 col7\" >28.4</td>\n",
       "      <td id=\"T_39431_row1_col8\" class=\"data row1 col8\" >10.6</td>\n",
       "      <td id=\"T_39431_row1_col9\" class=\"data row1 col9\" >27.2</td>\n",
       "      <td id=\"T_39431_row1_col10\" class=\"data row1 col10\" >14.6</td>\n",
       "      <td id=\"T_39431_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_39431_row1_col12\" class=\"data row1 col12\" >22.4</td>\n",
       "      <td id=\"T_39431_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc7a552110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3618: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3619: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_641a2_row0_col0, #T_641a2_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_641a2_row0_col2, #T_641a2_row0_col3, #T_641a2_row0_col4, #T_641a2_row0_col5, #T_641a2_row0_col6, #T_641a2_row0_col7, #T_641a2_row0_col8, #T_641a2_row0_col9, #T_641a2_row0_col10, #T_641a2_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_641a2_row0_col11, #T_641a2_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_641a2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_641a2_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_641a2_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_641a2_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_641a2_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_641a2_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_641a2_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_641a2_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_641a2_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_641a2_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_641a2_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_641a2_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_641a2_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(v.Davinci-003)/WR</th>\n",
       "      <th id=\"T_641a2_level0_col12\" class=\"col_heading level0 col12\" >Average</th>\n",
       "      <th id=\"T_641a2_level0_col13\" class=\"col_heading level0 col13\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_641a2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_641a2_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm_ep=2</td>\n",
       "      <td id=\"T_641a2_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_641a2_row0_col2\" class=\"data row0 col2\" >38.1</td>\n",
       "      <td id=\"T_641a2_row0_col3\" class=\"data row0 col3\" >34.4</td>\n",
       "      <td id=\"T_641a2_row0_col4\" class=\"data row0 col4\" >4.6</td>\n",
       "      <td id=\"T_641a2_row0_col5\" class=\"data row0 col5\" >12.2</td>\n",
       "      <td id=\"T_641a2_row0_col6\" class=\"data row0 col6\" >31.9</td>\n",
       "      <td id=\"T_641a2_row0_col7\" class=\"data row0 col7\" >28.4</td>\n",
       "      <td id=\"T_641a2_row0_col8\" class=\"data row0 col8\" >10.6</td>\n",
       "      <td id=\"T_641a2_row0_col9\" class=\"data row0 col9\" >27.2</td>\n",
       "      <td id=\"T_641a2_row0_col10\" class=\"data row0 col10\" >14.6</td>\n",
       "      <td id=\"T_641a2_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_641a2_row0_col12\" class=\"data row0 col12\" >22.4</td>\n",
       "      <td id=\"T_641a2_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc80ba8cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_average_col_contains_substr\n",
    "\n",
    "Ns = sorted(np.unique([int(x) for x in df['total_train_samples'].to_numpy() if x]).tolist())\n",
    "for N in Ns+[None]:\n",
    "    dfc = df.copy()\n",
    "    dfc = dfc[dfc['total_train_samples'].apply(lambda x: int(x) == N if x else True)]\n",
    "#     dfc = pd_average_col_contains_substr(dfc, 'run_name', 'random_', substitute=True)\n",
    "    dfc = pd_average_col_contains_substr(dfc, 'run_name', 'score=random:s=(\\d)_pace=prune:size=10000:ep=10', substitute=True)\n",
    "    dfc = pd_average_col_contains_substr(dfc, 'run_name', 'score=random:s=(\\d)_pace=prune:size=50000:ep=5', substitute=True)\n",
    "    dfc = pd_average_col_contains_substr(dfc, 'run_name', 'score=random:s=(\\d)_pace=prune:size=150000:ep=3', substitute=True)\n",
    "    dfc = pd_average_col_contains_substr(dfc, 'run_name', 'score=random:s=(\\d)_pace=prune:size=150000:ep=1', substitute=True)\n",
    "    dfc = pd_average_col_contains_substr(dfc, 'run_name', 'score=random:s=(\\d)_pace=prune:size=100000', substitute=True)\n",
    "    dfc = pd_average_col_contains_substr(dfc, 'run_name', 'score=random:s=(\\d)_pace=prune:size=200000', substitute=True)\n",
    "    dfc = pd_average_col_contains_substr(dfc, 'run_name', 'score=random:s=(\\d)_pace=prune:size=400000', substitute=True)\n",
    "    #     dfc = dfc.sort_values(['ranking'], ascending=False)\n",
    "    dfc = dfc.sort_values(['Average'], ascending=False)\n",
    "    dfc = dfc.drop(columns=['model_args.model_name_or_path', 'data_args.subsample_mixture', 'data_args.max_train_samples'])\n",
    "    dfc = dfc.reset_index(drop=True)\n",
    "    if len(dfc):\n",
    "        display(dfc\n",
    "                .style\n",
    "                .set_properties(**{'text-align': 'left'})\n",
    "                .background_gradient(cmap ='coolwarm')\n",
    "                .format(precision=1))\n",
    "\n",
    "# random\n",
    "# log_prob_decr\n",
    "# el2n agg_mean incr\n",
    "# logit_margin_decr\n",
    "# grad l2n incr\n",
    "# kmeansl2_emb=text+embedding_nc=3000_incr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb043d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ylabel = 'llama-7b:600k'\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "ylabel = 'llama-7b_flan_v2:30k'\n",
    "exp_dir = '../results/oi4_perf_cross_time'\n",
    "# exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'\n",
    "save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in glob.glob(os.path.join(exp_dir, 'llama-7b_flan_v2:30k_kmeansl2_nc=3000_decr', 'checkpoint-*'))]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in glob.glob(os.path.join(exp_dir, 'llama-7b_flan_v2:30k_kmeansl2_nc=3000_incr', 'checkpoint-*'))]\n",
    "save_dirs += [(os.path.basename(x), x) for x in glob.glob(os.path.join(exp_dir, 'llama-7b_flan_v2:30k_kmeansl2_nc=3000_incr', 'checkpoint-*'))]\n",
    "df = get_eval_results(save_dirs, chat_fmt=None, ft_args_fields=ft_args_fields)\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "# add base model performance\n",
    "dfc.loc[dfc['model_args.model_name_or_path']=='huggyllama/llama-7b', 'model_args.model_name_or_path'] = 'checkpoint-0'\n",
    "# get steps \n",
    "dfc.insert(0, 'steps', dfc['model_args.model_name_or_path'].apply(lambda x: int(x.split('-')[-1])))\n",
    "dfc = dfc.sort_values('steps')\n",
    "\n",
    "\n",
    "y_labels_list = [\n",
    "    ['MMLU/0-shot',\n",
    "     'MMLU/0-shot_chatfmt',\n",
    "     'MMLU/5-shot',\n",
    "     'MMLU/5-shot_chatfmt',\n",
    "    ],\n",
    "    ['GSM/Direct',\n",
    "     'GSM/Direct_chatfmt',\n",
    "     'GSM/CoT', \n",
    "     'GSM/CoT_chatfmt', \n",
    "    ],\n",
    "    ['BBH/Direct',\n",
    "     'BBH/Direct_chatfmt',\n",
    "     'BBH/CoT',\n",
    "     'BBH/CoT_chatfmt',\n",
    "    ],\n",
    "    ['TydiQA/CB',\n",
    "     'TydiQA/CB_chatfmt',\n",
    "     'TydiQA/GP',\n",
    "     'TydiQA/GP_chatfmt',\n",
    "    ],\n",
    "    ['Codex-Eval/Pass@1',\n",
    "     'Codex-Eval/Pass@1_chatfmt'],\n",
    "    ['MMLU/0-shot',\n",
    "     'GSM/CoT',\n",
    "     'BBH/CoT',],\n",
    "]\n",
    "\n",
    "N = len(y_labels_list)\n",
    "\n",
    "fig, axs = plt.subplots(1,N,figsize=(5*N,5))\n",
    "\n",
    "axs[0].set_ylabel(ylabel, fontsize=20)\n",
    "\n",
    "for axi, y_labels in enumerate(y_labels_list):\n",
    "    ax = axs[axi]\n",
    "\n",
    "    x = dfc['steps']\n",
    "    y_list = []\n",
    "    for y_label in y_labels:\n",
    "        if y_label not in dfc.columns: continue\n",
    "        y = dfc[y_label].to_numpy()\n",
    "        y_list.append(y)\n",
    "        ax.plot(x, y, label=y_label)\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    ax.set_ylim(0, 55)\n",
    "    \n",
    "    \n",
    "# for y_label in ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1']:\n",
    "    \n",
    "#     for chat_fmt in ['', 'chatfmt']:\n",
    "#         col = '_'.join([y_label, chat_fmt]) if chat_fmt else y_label\n",
    "#         y = dfc[col].to_numpy()\n",
    "#         print(f'{col}\\t{y.mean():.2f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_labels = [\n",
    "    'Answer:\\n<|assistant|>\\nThe answer is:',\n",
    "    'Answer:\\n<|assistant|>\\n',\n",
    "    '<|assistant|>\\nAnswer:',\n",
    "    '<|assistant|>\\nThe answer is:',\n",
    "]\n",
    "x_labels = [f'v{i+1}:\\n{x}' for i,x in enumerate(x_labels)]\n",
    "\n",
    "dfc = df.copy()\n",
    "dfc = df.filter(regex='_v|run')\n",
    "\n",
    "runs = dfc['run_name'].to_list()[::-1]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for axi, task in enumerate(['MMLU/0-shot', 'MMLU/5-shot']):\n",
    "\n",
    "    ax = axs[axi]\n",
    "    cols = [f'{task}_v{x}' for x in [1, 2, 3, 4]]\n",
    "    x = np.arange(len(x_labels))\n",
    "\n",
    "    width = .25\n",
    "    multiplier = 0\n",
    "\n",
    "    for run in runs:\n",
    "        offset = width*multiplier\n",
    "        y = dfc[dfc['run_name']==run][cols].to_numpy().squeeze()\n",
    "        rects = ax.bar(x+offset, y, width, label=run)\n",
    "        ax.bar_label(rects, padding=3, fmt='{:.2f}')\n",
    "        multiplier += 1\n",
    "\n",
    "    ax.set_title(task)\n",
    "    ax.set_xticks(x+width)\n",
    "    ax.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_ylim(0, 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa6ba4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "total_data_points = 200000 # 10000, 50000, 100000, 200000\n",
    "subsample_mixture_list = []\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': 0.48785105, 'flan_v2': 0.48785105, 'dolly': 0.00732313, 'oasst1': 0.01697478}.items())\n",
    "] # humanmix mixture.\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.360595703125, \"dolly\": 0.0021991729736328125, \"flan_v2\": 0.63037109375, \"oasst1\": 0.0016956329345703125}.items())\n",
    "] # pythia-1.4b humanmix_uniform:200k_doremiv1.json\n",
    "\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.2254638671875, \"dolly\": 0.01409149169921875, \"flan_v2\": 0.1739501953125, \"oasst1\": 0.59423828125}.items())\n",
    "] # pythia-1.4b humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.08563232421875, \"dolly\": 0.54296875, \"flan_v2\": 0.347900390625, \"oasst1\": 0.0103302001953125}.items())\n",
    "] # llama-7b_humanmix_uniform:200k_doremiv2.json\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.0316162109375, \"dolly\": 0.204833984375, \"flan_v2\": 0.40966796875, \"oasst1\": 0.40966796875}.items()\n",
    "        )] # llama-7b_humanmix_uniform:600k_doremiv2.json\n",
    "subsample_mixture_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "6323+40966+81933+81933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_dir = 'results/ft1'\n",
    "\n",
    "# d = {\n",
    "#     'bbh_s=0': 'bbh_s=3',\n",
    "#     'gsm': 'gsm_s=8_cot',\n",
    "#     'mmlu': 'mmlu_s=0',\n",
    "#     'tydiqa_cb': 'tydiqa_s=1_cb',\n",
    "#     'tydiqa_gp': 'tydiqa_s=1_gp',\n",
    "# }\n",
    "\n",
    "# d.update({k+'_chatfmt': v+'_chatfmt' for k,v in d.items()})\n",
    "\n",
    "# for subdir in os.listdir(exp_dir):    \n",
    "#     for task_name_src, task_name_tgt in d.items():\n",
    "#         path_src = os.path.join(exp_dir, subdir, 'eval', task_name_src)\n",
    "#         path_tgt = os.path.join(exp_dir, subdir, 'eval', task_name_tgt)\n",
    "#         if os.path.isdir(path_src):\n",
    "# #             os.rename(path_src, path_tgt)\n",
    "#             print(path_src)\n",
    "#             print(path_tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27138820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfc = df.copy()\n",
    "dfc.insert(0, 'total_train_samples',  dfc['data_args.subsample_mixture'].apply(\n",
    "    lambda d: sum(list(d.values())) if d else 200000))\n",
    "# dfc[dfc['total_train_samples'].apply(\n",
    "#     lambda x: total_train_samples-500<x<total_train_samples+500)]\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad6edc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dfc = df.copy()\n",
    "dfc.columns = [x.split('_')[0] for x in dfc.columns]\n",
    "def get_dataset(x):\n",
    "    x = x.split('+')\n",
    "    if len(x) == 1:\n",
    "        return ''\n",
    "    else:\n",
    "        d = x[1]\n",
    "        d = d.replace('_', '')\n",
    "        return d\n",
    "dfc['Dataset'] = dfc['Model'].apply(get_dataset)\n",
    "order_list = ['',\n",
    " 'superni', 'cot', 'flanv2', 'dolly', 'oasst1',\n",
    " 'selfinstruct', 'unnaturalinstructions', 'stanfordalpaca', 'codealpaca', 'gpt4alpaca',\n",
    " 'baize', 'sharegpt', 'humanmix', 'h+gptmix']\n",
    "dfc['order'] = dfc['Dataset'].map({v: i for i, v in enumerate(order_list)})\n",
    "dfc = dfc.sort_values('order')\n",
    "dfc = dfc.drop(columns=['order', 'Dataset'])\n",
    "dfc = dfc.reset_index(drop=True)\n",
    "\n",
    "display(dfc[dfc['Model'].apply(lambda x: 'llama-7b' in x and ':' not in x)]\n",
    "        .style\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=1))\n",
    "\n",
    "\n",
    "display(dfc[dfc['Model'].apply(\n",
    "            lambda x: 'llama-7b' in x and (\n",
    "                ':' in x or any(c in x for c in ['dolly', 'oasst1', 'cot', 'flan'])\n",
    "                or 'humanmix' in x\n",
    "            )\n",
    "        )]\n",
    "        .style\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=1))\n",
    "\n",
    "display(dfc[dfc['Model'].apply(lambda x: 'llama2-7b' in x or 'llama-7b'==x)]\n",
    "        .style\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba1a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0588857",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"dataset\": \"flan_v2\", \"id\": \"flan_v2_2\", \"messages\": [{\"role\": \"user\", \"content\": \"Tratatul de la Lisabona nu face inutil referire, pentru prima dat n istoria Uniunii Europene, la drepturile persoanelor care aparin acestor minoriti i la valorile proprii acestora.\\n\\nWhich language is this?\\n\"}, {\"role\": \"assistant\", \"content\": \"Romanian\"}]}\n",
    "{\"dataset\": \"flan_v2\", \"id\": \"flan_v2_2\", \"messages\": [{\"role\": \"user\", \"content\": \"Tratatul de la Lisabona nu face inutil referire, pentru prima dat\\u0103 \\u00een istoria Uniunii Europene, la drepturile persoanelor care apar\\u0163in acestor minorit\\u0103\\u0163i \\u015fi la valorile proprii acestora.\\n\\nWhich language is this?\\n\"}, {\"role\": \"assistant\", \"content\": \"Romanian\"}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7702c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.1f}'.format):\n",
    "    display(df[['Model']+[x for x in df.columns if 'chatfmt' in x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82eac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.3f}'.format):\n",
    "    display(df[[x for x in df.columns if 'chatfmt' not in x]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "models = []\n",
    "models += ['t5-small', 't5-base', 't5-large', 't5-3b', 't5-11b']\n",
    "models += ['huggyllama/llama-7b']\n",
    "save_dirs = [f'../results/baselines/{x}/eval/gsm/' for x in models]\n",
    "\n",
    "data = []\n",
    "for model, save_dir in zip(models, save_dirs):\n",
    "    logfile_path = glob.glob(os.path.join(save_dir, '*.out'))[0]\n",
    "    out = get_run_statistics(logfile_path)\n",
    "    with open(os.path.join(save_dir, 'metrics.json'), 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    data.append((model, out['cpu_time']/60/60, out['avg_mem'], out['max_mem'], metrics['exact_match']))\n",
    "    \n",
    "\n",
    "import pandas as pd\n",
    "columns = ['name', 'cpu_time (hr)', 'avg_mem', 'max_mem', 'exact_match']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
