{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da1794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('ppc64le', 'dcs')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "import re\n",
    "from llm.submit import (\n",
    "    multiline_to_singleline,\n",
    "    submit_job_ccc,\n",
    "    submit_job_aimos,\n",
    "    submit_job,\n",
    "    get_run_statistics)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import json\n",
    "import platform\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import datetime\n",
    "import itertools\n",
    "import socket\n",
    "import glob\n",
    "\n",
    "import base64\n",
    "string_to_alphanumeric = lambda s: base64.urlsafe_b64encode(s.encode('utf-8')).decode('utf-8')\n",
    "alphanumeric_to_string = lambda a: base64.urlsafe_b64decode(a).decode('utf-8')\n",
    "\n",
    "arch = platform.uname().processor\n",
    "hostname = socket.gethostname()\n",
    "cluster = 'ccc' if hostname.startswith('ccc') else ('dcs' if hostname.startswith('dcs') else 'npl')\n",
    "arch, cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8323654",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850a84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_name = 'ft'\n",
    "# test_run = 1\n",
    "# test_run = bool(test_run)\n",
    "\n",
    "# queue = 'x86_12h' # 'x86_12h'\n",
    "# num_cpus = 20\n",
    "# num_gpus = 1\n",
    "# cpu_mem = 32\n",
    "# require = 'a100_80gb'\n",
    "\n",
    "# # model_name_or_path = 'mosaicml/mpt-7b'; max_seq_length = 2048\n",
    "# # model_name_or_path = 'gpt2'; max_seq_length = 1024\n",
    "# # model_name_or_path = 'gpt2-Large'; max_seq_length = 1024\n",
    "# # model_name_or_path = 'gpt2-xl'; max_seq_length = 1024\n",
    "# model_name_or_path = 'huggyllama/llama-7b'; max_seq_length = 2048\n",
    "\n",
    "\n",
    "# train_file = 'data/processed/oasst1/oasst1_data.jsonl'; train_file_short = 'oasst1'\n",
    "# train_file = 'data/processed/flanv2_cot_oasst1_dolly.jsonl'; train_file_short = 'human_mix'\n",
    "# # train_file = 'data/processed/flanv2_cot_oasst1_dolly_shuffled.jsonl'; train_file_short = 'human_mix_shuffled'\n",
    "\n",
    "# output_dir = f\"results/{model_name_or_path.replace('/', ':')}_{train_file_short}\"\n",
    "# if test_run:\n",
    "#     output_dir = 'jpt_' + output_dir\n",
    "\n",
    "# use_deepspeed = False\n",
    "# # deepspeed_config_file = 'ds_configs/stage3_no_offloading_accelerate_setauto.conf'\n",
    "# # deepspeed_config_file = 'ds_configs/stage3_offloading_accelerate.conf'\n",
    "# deepspeed_config_file = 'ds_configs/stage3_offloading_accelerate_setauto.conf'\n",
    "\n",
    "# use_lora = True\n",
    "# lora_rank = 4\n",
    "# lora_alpha = lora_rank\n",
    "# lora_dropout = 0.05\n",
    "\n",
    "# batch_size_per_gpu = 1\n",
    "# total_batch_size = 128\n",
    "# mixed_precision = 'bf16' # 'bf16', 'fp16'\n",
    "# checkpointing_steps = None # every n steps, where n='1' or every 'epoch'\n",
    "\n",
    "# gradient_acc_steps = int(total_batch_size/num_gpus/batch_size_per_gpu)\n",
    "\n",
    "# print(f\"Training {model_name_or_path} \"\n",
    "#       f\"using {num_gpus} GPUs, \"\n",
    "#       f\"{batch_size_per_gpu} batch size per GPU, \"\n",
    "#       f\"{gradient_acc_steps} gradient accumulation steps.\")\n",
    "\n",
    "# # do use fast tokenizer since mpt-7b does not have a fast tokenizer counter-part\n",
    "# #     --use_slow_tokenizer \\\n",
    "# # do not use flash attention, since having problem installing flash-attn with cuda 12.1\n",
    "# #     --use_flash_attn \\\n",
    "\n",
    "# cmd = f\"\"\"\n",
    "# {'!cd .. && ' if test_run else ''}accelerate launch \\\n",
    "#     --mixed_precision {mixed_precision} \\\n",
    "#     --num_machines 1 \\\n",
    "#     --num_processes {num_gpus} \\\n",
    "#     {'--use_deepspeed' if use_deepspeed else ''}\n",
    "#     {'--deepspeed_config_file '+deepspeed_config_file if use_deepspeed else ''}\n",
    "#     open_instruct/finetune.py \\\n",
    "#     --model_name_or_path {model_name_or_path} \\\n",
    "#     --tokenizer_name {model_name_or_path} \\\n",
    "#     --train_file {train_file} \\\n",
    "#     --max_seq_length {max_seq_length} \\\n",
    "#     {'--use_lora' if use_lora else ''}\n",
    "#     --lora_rank {lora_rank} \\\n",
    "#     --lora_alpha {lora_alpha} \\\n",
    "#     --lora_dropout {lora_dropout} \\\n",
    "#     --preprocessing_num_workers 16 \\\n",
    "#     --per_device_train_batch_size {batch_size_per_gpu} \\\n",
    "#     --gradient_accumulation_steps {gradient_acc_steps} \\\n",
    "#     --learning_rate 2e-5 \\\n",
    "#     --lr_scheduler_type linear \\\n",
    "#     --warmup_ratio 0.03 \\\n",
    "#     --weight_decay 0. \\\n",
    "#     --num_train_epochs 2 \\\n",
    "#     --output_dir {output_dir} \\\n",
    "#     --with_tracking \\\n",
    "#     --report_to tensorboard \\\n",
    "#     {'--checkpointing_steps '+str(checkpointing_steps) if checkpointing_steps else ''}\n",
    "#     --logging_steps 1\n",
    "# \"\"\"\n",
    "\n",
    "# # things to test to see its effects on (1) eval perf (2) runtime.\n",
    "# #\n",
    "# # - int8\n",
    "# # - mixed_precision bf16 or no\n",
    "# # - with/without LoRA\n",
    "# # - LoRA's rank/alpha (alpha typically set to 2*rank)\n",
    "# # - batch size\n",
    "# # - micro-batch size (largest without running out of memory)\n",
    "\n",
    "\n",
    "# cmd = multiline_to_singleline(cmd)\n",
    "# if test_run:\n",
    "#     print()\n",
    "#     print(cmd)\n",
    "\n",
    "# shell_scripts = shell_scripts_template.format(\n",
    "#     cmd=cmd,\n",
    "#     log_dir=os.getcwd(),\n",
    "#     save_dir=output_dir)\n",
    "# out = submit_job_ccc(\n",
    "#     shell_scripts, \n",
    "#     job_name=job_name, \n",
    "#     queue=queue,\n",
    "#     num_cpus=num_cpus,\n",
    "#     cpu_mem=cpu_mem,\n",
    "#     require=require,\n",
    "#     num_gpus=num_gpus,\n",
    "#     test_run=test_run,\n",
    "# )\n",
    "# if not test_run:\n",
    "#     print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c8b",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune_trainer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c2170c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "echo \"Running on $SLURM_JOB_NODELIST\"\n",
      "echo \"======\"\n",
      "\n",
      "master_addr=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\" | head -n 1)\n",
      "master_port=10002\n",
      "RDZV_ENDPOINT=$master_addr:$master_port\n",
      "\n",
      "source ~/.profile\n",
      "conda activate open-instruct\n",
      "cd /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/\n",
      "\n",
      "set -e\n",
      "set -x\n",
      "echo \"======\"\n",
      "srun {cmd}\n",
      "\n",
      "[ ! -f \"{log_dir}/$SLURM_JOB_ID*.out\" ] && mv {log_dir}/$SLURM_JOB_ID*.out {save_dir}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shell_scripts_template_slurm = \"\"\"\n",
    "echo \"Running on $SLURM_JOB_NODELIST\"\n",
    "echo \"======\"\n",
    "\n",
    "master_addr=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\" | head -n 1)\n",
    "master_port=10002\n",
    "RDZV_ENDPOINT=$master_addr:$master_port\n",
    "\n",
    "source ~/.profile\n",
    "conda activate open-instruct\n",
    "cd /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/\n",
    "\n",
    "set -e\n",
    "set -x\n",
    "echo \"======\"\n",
    "srun {cmd}\n",
    "\n",
    "[ ! -f \"{log_dir}/$SLURM_JOB_ID*.out\" ] && mv {log_dir}/$SLURM_JOB_ID*.out {save_dir}\n",
    "\"\"\"\n",
    "\n",
    "shell_scripts_template_lsf = \"\"\"\n",
    "echo \"Running on $LSB_DJOB_HOSTFILE\"\n",
    "echo \"======\"\n",
    "\n",
    "master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\")\n",
    "master_port=10002\n",
    "RDZV_ENDPOINT=$master_addr:$master_port\n",
    "\n",
    "source ~/.profile\n",
    "conda activate open-instruct\n",
    "cd /dccstor/mit_fm/wpq/github/mitibm2023/external/open-instruct/\n",
    "\n",
    "set -e\n",
    "set -x\n",
    "echo \"======\"\n",
    "srun {cmd}\n",
    "\n",
    "[ ! -f \"{log_dir}/$LSB_JOBID*.out\" ] && mv {log_dir}/$LSB_JOBID*.out {save_dir}\n",
    "\"\"\"\n",
    "\n",
    "shell_scripts_template = shell_scripts_template_slurm \\\n",
    "    if arch == 'ppc64le' else shell_scripts_template_lsf\n",
    "\n",
    "print(shell_scripts_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d611cbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133s/it, 58.5hrs\n"
     ]
    }
   ],
   "source": [
    "t = '00:33:12'\n",
    "n = 15\n",
    "# total = 1515; nnodes = 1\n",
    "# total = 2083; nnodes = 1\n",
    "total = 1587; nnodes = 1\n",
    "# total = 1041; nnodes = 1\n",
    "# total = 4228; nnodes = 1\n",
    "# total = 4512; nnodes = 4\n",
    "# total = 4296; nnodes = 1\n",
    "# total = 2254; nnodes = 2\n",
    "# total = 1128; nnodes = 4\n",
    "# total = 1074; nnodes = 4\n",
    "# total = 1252; nnodes = 4\n",
    "\n",
    "l = [int(x) for x in t.split(':')]\n",
    "t = l[0]*60*60+l[1]*60+l[2]\n",
    "# t = t/60/60 # in hr\n",
    "\n",
    "print(f'{t/n/nnodes:.0f}s/it, {t/n*total/60/60:.1f}hrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a669464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cot\n",
      "sharegpt\n",
      "dolly\n",
      "gpt4_alpaca\n",
      "flan_v2\n",
      "super_ni\n",
      "stanford_alpaca\n",
      "baize\n",
      "code_alpaca\n",
      "self_instruct\n",
      "unnatural_instructions\n",
      "oasst1\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "p = '../data/processed/'\n",
    "for x in os.listdir(p):\n",
    "    y = os.path.join(p, x)\n",
    "    if os.path.isdir(y):\n",
    "        d = os.path.join(y, os.listdir(y)[0])\n",
    "    else:\n",
    "        continue\n",
    "    d = d[3:]\n",
    "    if 'shuffled' in d:\n",
    "        continue\n",
    "#     print(f\"train_file = '{d}'; abbr_train_file = '{x}'\")\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f51bf7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'baize': 100000},\n",
       " {'code_alpaca': 100000},\n",
       " {'cot': 100000},\n",
       " {'dolly': 100000},\n",
       " {'gpt4_alpaca': 100000},\n",
       " {'oasst1': 100000},\n",
       " {'self_instruct': 100000},\n",
       " {'sharegpt': 100000},\n",
       " {'stanford_alpaca': 100000},\n",
       " {'super_ni': 100000},\n",
       " {'unnatural_instructions': 100000},\n",
       " {'cot': 50000, 'flan_v2': 50000, 'dolly': 50000, 'oasst1': 50000},\n",
       " {'cot': 97570, 'flan_v2': 97570, 'dolly': 1464, 'oasst1': 3394},\n",
       " {'baize': 16666,\n",
       "  'code_alpaca': 16666,\n",
       "  'cot': 16666,\n",
       "  'dolly': 16666,\n",
       "  'flan_v2': 16666,\n",
       "  'gpt4_alpaca': 16666,\n",
       "  'oasst1': 16666,\n",
       "  'self_instruct': 16666,\n",
       "  'sharegpt': 16666,\n",
       "  'stanford_alpaca': 16666,\n",
       "  'super_ni': 16666,\n",
       "  'unnatural_instructions': 16666},\n",
       " {'cot': 15356, 'flan_v2': 182740, 'dolly': 894, 'oasst1': 1814},\n",
       " {'cot': 22540, 'flan_v2': 174520, 'dolly': 2790, 'oasst1': 278}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# how to sample mixture sample size?\n",
    "# \n",
    "# approaches: \n",
    "# (1) want sufficient coverage for #datapoints/dataset, #datasets used, total sample size.\n",
    "#  Use 5k as a unit of data, sample different #unit/dataset, and vary total units of data.\n",
    "# (2) specify a total sample size and a mixture weight. this answers the question, given a \n",
    "#  fixed compute budget, what is the optimal mixture. this seems to be a simpler approach.\n",
    "#\n",
    "# experiments\n",
    "# (1) first use samples from a single dataset for tuning. \n",
    "# (2)\n",
    "# \n",
    "\n",
    "\n",
    "datasets = ['baize', 'code_alpaca', 'cot', 'dolly', 'flan_v2', 'gpt4_alpaca', 'oasst1', 'self_instruct', 'sharegpt', 'stanford_alpaca', 'super_ni', 'unnatural_instructions']\n",
    "total_data_points = 200000\n",
    "\n",
    "subsample_mixture_list = []\n",
    "subsample_mixture_list += [\n",
    "    {k: 100000} for k in datasets if k != 'flan_v2'\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    {k: int(total_data_points/4) for k in ['cot', 'flan_v2', 'dolly', 'oasst1']}\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': 0.48785105, 'flan_v2': 0.48785105, 'dolly': 0.00732313, 'oasst1': 0.01697478}.items())\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    {k: int(total_data_points/len(datasets)) for k in datasets} \n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': .07678, 'flan_v2': .9137, 'dolly': .004471, 'oasst1': .009072}.items())\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': 0.1127, 'flan_v2': 0.8726, 'dolly': 0.01395, 'oasst1': 0.001391}.items())\n",
    "]\n",
    "subsample_mixture_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d47226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove extra files (e.g., optimizer.bin) for non-latest checkpoints:\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-50/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-850/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-900/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-950/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-50/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-850/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-900/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-950/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1000/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1050/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1850/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1900/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1950/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2000/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2050/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2850/optimizer.bin\n"
     ]
    }
   ],
   "source": [
    "## Clean up checkpoints `optimizer.bin` to save disk space. \n",
    "# (e.g., 7b model, ~8*7=56GB for storing gradient/momentum in `optimizer.bin`)\n",
    "\n",
    "import glob, os\n",
    "\n",
    "def cleanup_checkpoints(save_dir, test_run=False):\n",
    "\n",
    "    checkpoints = glob.glob(os.path.join(save_dir, 'checkpoint-*'))\n",
    "    checkpoints = sorted(checkpoints, key=lambda x: int(x.split('-')[-1]))\n",
    "    checkpoints = checkpoints[:-1]\n",
    "    \n",
    "    if not checkpoints: return\n",
    "\n",
    "    for ckpt_path in checkpoints:\n",
    "        optimizer_bin_path = os.path.join(ckpt_path, 'optimizer.bin')\n",
    "        if os.path.isfile(optimizer_bin_path):\n",
    "            print(optimizer_bin_path)\n",
    "            if not test_run:\n",
    "                os.remove(optimizer_bin_path)\n",
    "        \n",
    "        \n",
    "test_run = True\n",
    "exp_dirs = ['../results/ft2',\n",
    "            '../results/oi3']\n",
    "\n",
    "print('Remove extra files (e.g., optimizer.bin) for non-latest checkpoints:')\n",
    "\n",
    "for exp_dir in exp_dirs:\n",
    "    for run_name in os.listdir(exp_dir):\n",
    "        save_dir = os.path.join(exp_dir, run_name)\n",
    "        if os.path.islink(save_dir): continue\n",
    "        cleanup_checkpoints(save_dir, test_run=test_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51c8d72e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results/baselines/huggyllama/llama-7b using 6 GPUs, 2 batch size per GPU, 2 gradient accumulation steps, Effective batch size 120\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi3\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 512,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 2\n",
      "}\n",
      "[{'args': 'sbatch --job-name=oi3 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J_1:2.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmpdm51zy5_', 'job_id': 928436}, {'args': 'sbatch --job-name=oi3 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J_2:2.out --time=6:00:00 --dependency=afterany:928436 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp5dvy1ufp', 'job_id': 928437}]\n"
     ]
    }
   ],
   "source": [
    "def compute_mixture_num_samples(mixture, total_data_points):\n",
    "    s = sum(mixture.values())\n",
    "    mixture = {k: int(total_data_points*v/s) for k, v in mixture.items()}\n",
    "    return mixture\n",
    "\n",
    "# ft1: reproduce open-instruct table with llama7b\n",
    "job_name = 'ft1'\n",
    "\n",
    "# ft2: test mixture weights\n",
    "# vary mixture weights\n",
    "job_name = 'ft2'\n",
    "\n",
    "# oi3: instruction tuning performance w.r.t. steps.\n",
    "job_name = 'oi3'\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "# specify `job_duration` to chain jobs for >12hr jobs.\n",
    "# job_duration = 6 if arch == 'ppc64le' else 12\n",
    "# job_duration = 6\n",
    "# shell_scripts_modification_fn = lambda x: x.replace('--overwrite_output_dir ', '')\n",
    "\n",
    "num_cpus = 144 if arch == 'ppc64le' else 32\n",
    "cpu_mem =  512 if arch == 'ppc64le' else 64\n",
    "nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12 # llama-7b\n",
    "nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12 # llama-7b on 400k data\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 30 # llama-7b on 600k data\n",
    "\n",
    "# nodes = 1; num_gpus = 1; gpu_type = 'v100'; job_duration = 6  # gpt2\n",
    "# nodes = 2; num_gpus = 6; gpu_type = 'v100'; job_duration = 6  # pythia-1.4b\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6  # pythia-2.8b|6.9b\n",
    "\n",
    "\n",
    "debug_mode = test_run\n",
    "\n",
    "overwrite_output_dir = True if test_run else False # always continue from ckpt if run from cluster.\n",
    "save_strategy = 'steps'\n",
    "save_steps = 50; save_total_limit = 200 # keep track of ckpts during training.\n",
    "# save_steps = 100; save_total_limit = 1 # \n",
    "\n",
    "\n",
    "hf_models_dir = 'results/baselines/'\n",
    "# model_name_or_path = 'results/baselines/gpt2-medium'; abbr_model_name = 'gpt2m'; max_seq_length = 1024\n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = 'results/baselines/NousResearch/Llama-2-7b-hf'; abbr_model_name = 'llama2-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = 'mosaicml/mpt-7b'; abbr_model_name = 'mpt-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-1.4b'; abbr_model_name = 'pythia-1.4b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-2.8b'; abbr_model_name = 'pythia-2.8b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-6.9b'; abbr_model_name = 'pythia-6.9b'; max_seq_length = 2048\n",
    "\n",
    "\n",
    "train_file = 'data/processed/all.jsonl'; abbr_train_file = 'all'\n",
    "# subsample_mixture = {'flan_v2': 100000}\n",
    "# subsample_mixture = dict(sorted(subsample_mixture.items()))\n",
    "\n",
    "total_data_points = 200000 # 10000, 50000, 100000, 200000\n",
    "total_data_points = 600000\n",
    "subsample_mixture_list = []\n",
    "# subsample_mixture_list += [\n",
    "#     {k: total_data_points} for k in datasets\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     {k: int(total_data_points/4) for k in ['cot', 'flan_v2', 'dolly', 'oasst1']}\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     ('humanmix', dict((k, int(v*total_data_points)) for k, v in\n",
    "#     {'cot': 0.48785105, 'flan_v2': 0.48785105, 'dolly': 0.00732313, 'oasst1': 0.01697478}.items()))\n",
    "# ] # humanmix mixture.\n",
    "# subsample_mixture_list += [\n",
    "#     {k: int(total_data_points/len(datasets)) for k in datasets} \n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*total_data_points)) for k, v in\n",
    "#     {'cot': .07678, 'flan_v2': .9137, 'dolly': .004471, 'oasst1': .009072}.items())\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*total_data_points)) for k, v in\n",
    "#     {'cot': 0.1127, 'flan_v2': 0.8726, 'dolly': 0.01395, 'oasst1': 0.001391}.items())\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*total_data_points)) for k, v in\n",
    "#     {'cot':  0.13568177819252014, 'flan_v2': 0.3957784175872803, \n",
    "#      'dolly': 0.05964866653084755, 'oasst1': 0.4088916480541229}.items())\n",
    "# ] # gpt2-medium_humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*total_data_points)) for k, v in\n",
    "#     {\"cot\": 0.360595703125, \"dolly\": 0.0021991729736328125, \"flan_v2\": 0.63037109375, \"oasst1\": 0.0016956329345703125}.items())\n",
    "# ] # pythia-1.4b humanmix_uniform:200k_doremiv1.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*total_data_points)) for k, v in\n",
    "#     {\"cot\": 0.2254638671875, \"dolly\": 0.01409149169921875, \"flan_v2\": 0.1739501953125, \"oasst1\": 0.59423828125}.items())\n",
    "# ] # pythia-1.4b humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*total_data_points)) for k, v in\n",
    "#     {\"cot\": 0.08563232421875, \"dolly\": 0.54296875, \"flan_v2\": 0.347900390625, \"oasst1\": 0.0103302001953125}.items())\n",
    "# ] # llama-7b_humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*total_data_points)) for k, v in\n",
    "#     {\"cot\": 0.0316162109375, \"dolly\": 0.204833984375, \"flan_v2\": 0.40966796875, \"oasst1\": 0.40966796875}.items()\n",
    "#         )] # llama-7b_humanmix_uniform:600k_doremiv2.json\n",
    "\n",
    "subsample_mixture_normalized_list = []\n",
    "# subsample_mixture_normalized_list += [('uniform:1200k_doremiv2', # llama-7b_humanmix_uniform:1200k_doremiv2.json\n",
    "#                                        {\"cot\": 0.11419677734375, \"dolly\": 0.1024169921875, \"flan_v2\": 0.204833984375, \"oasst1\": 0.204833984375})]\n",
    "## 10 for trying out datamodels\n",
    "# mixes = [{'cot': 0.37664033529374275,\n",
    "#   'dolly': 0.0874640765523398,\n",
    "#   'flan_v2': 0.39740799933549775,\n",
    "#   'oasst1': 0.1384875888184196},\n",
    "#  {'cot': 0.23064419241874784,\n",
    "#   'dolly': 0.04693354147889885,\n",
    "#   'flan_v2': 0.72121745986295,\n",
    "#   'oasst1': 0.0012048062394032465},\n",
    "#  {'cot': 0.11244721555034376,\n",
    "#   'dolly': 0.21997027355988638,\n",
    "#   'flan_v2': 0.5826671754210359,\n",
    "#   'oasst1': 0.08491533546873392},\n",
    "#  {'cot': 0.27704626812045546,\n",
    "#   'dolly': 0.5712282144637615,\n",
    "#   'flan_v2': 0.024940119654536592,\n",
    "#   'oasst1': 0.12678539776124645},\n",
    "#  {'cot': 0.0024519793352964607,\n",
    "#   'dolly': 0.13274603201304974,\n",
    "#   'flan_v2': 0.012268378167304219,\n",
    "#   'oasst1': 0.8525336104843496},\n",
    "#  {'cot': 0.08065633865016615,\n",
    "#   'dolly': 0.41886215168938545,\n",
    "#   'flan_v2': 0.21723932820070485,\n",
    "#   'oasst1': 0.2832421814597436},\n",
    "#  {'cot': 0.13878643021160036,\n",
    "#   'dolly': 0.05686171157146557,\n",
    "#   'flan_v2': 0.6701353469446995,\n",
    "#   'oasst1': 0.13421651127223455},\n",
    "#  {'cot': 0.2461125374866837,\n",
    "#   'dolly': 0.09774240280444893,\n",
    "#   'flan_v2': 0.13974091986040005,\n",
    "#   'oasst1': 0.5164041398484672},\n",
    "#  {'cot': 0.4069781049152398,\n",
    "#   'dolly': 0.06318759506033228,\n",
    "#   'flan_v2': 0.09504719644992135,\n",
    "#   'oasst1': 0.4347871035745066},\n",
    "#  {'cot': 0.22379693013848484,\n",
    "#   'dolly': 0.30565901275011814,\n",
    "#   'flan_v2': 0.15457716965000887,\n",
    "#   'oasst1': 0.31596688746138824}]\n",
    "\n",
    "# mixes = [\n",
    "#     {'cot': 0.46638974, 'dolly': 0.01456044, 'flan_v2': 0.50886009, 'oasst1': 0.01018973},\n",
    "#     {'cot': 0.39744481, 'dolly': 0.00472114, 'flan_v2': 0.59104177, 'oasst1': 0.00679229},\n",
    "# ]\n",
    "\n",
    "# subsample_mixture_normalized_list += [('', d) for d in mixes]\n",
    "subsample_mixture_normalized_list += [('humanmix', # humanmix\n",
    "                                       {'cot': 0.48785105, 'dolly': 0.00732313, 'flan_v2': 0.48785105, 'oasst1': 0.01697478})]\n",
    "subsample_mixture_normalized_list = [(x[0],  compute_mixture_num_samples(x[1], total_data_points)) \n",
    "                                     for x in subsample_mixture_normalized_list]\n",
    "subsample_mixture_list += subsample_mixture_normalized_list\n",
    "\n",
    "         \n",
    "# subsample_mixture_list = [dict(sorted(d.items())) for d in subsample_mixture_list]\n",
    "\n",
    "\n",
    "# subsample_mixture_list = [None]\n",
    "# train_file = 'data/processed/flanv2_cot_oasst1_dolly.jsonl'; abbr_train_file = 'humanmix'\n",
    "# train_file = 'data/processed/dolly_oasst1.jsonl'; abbr_train_file = 'dolly:oasst1'\n",
    "# train_file = 'data/processed/cot_flanv2.jsonl'; abbr_train_file = 'cot:flanv2'\n",
    "\n",
    "# train_file = 'data/processed/super_ni/super_ni_data.jsonl'; abbr_train_file = 'super_ni'\n",
    "# train_file = 'data/processed/cot/cot_data.jsonl'; abbr_train_file = 'cot'\n",
    "# train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2'\n",
    "# train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly'\n",
    "# train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1'\n",
    "\n",
    "# train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca'\n",
    "# train_file = 'data/processed/baize/baize_data.jsonl'; abbr_train_file = 'baize'\n",
    "# train_file = 'data/processed/self_instruct/self_instruct_data.jsonl'; abbr_train_file = 'self_instruct'\n",
    "\n",
    "# train_file = 'data/processed/code_alpaca/code_alpaca_data.jsonl'; abbr_train_file = 'code_alpaca'\n",
    "# train_file = 'data/processed/unnatural_instructions/unnatural_instructions_data.jsonl'; abbr_train_file = 'unnatural_instructions'\n",
    "# train_file = 'data/processed/sharegpt/sharegpt_data.jsonl'; abbr_train_file = 'sharegpt'\n",
    "# train_file = 'data/processed/gpt4_alpaca/gpt4_alpaca_data.jsonl'; abbr_train_file = 'gpt4_alpaca'\n",
    "\n",
    "\n",
    "num_train_epochs = 1\n",
    "per_device_train_batch_size = 2\n",
    "total_batch_size = 128 # 128\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "\n",
    "\n",
    "optimizer = 'adamw_hf' # 'adafactor'\n",
    "\n",
    "deepspeed = ''; fsdp = False if num_gpus == 1 else \"full_shard auto_wrap\"  # full_shard, shard_grad_op\n",
    "if 'gpt2' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPT2Block'\n",
    "elif 'llama' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'LlamaDecoderLayer'\n",
    "elif 'mpt' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MPTBlock'\n",
    "elif 'pythia' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPTNeoXLayer'        \n",
    "else: raise ValueError('Not sure how to set `fsdp_transformer_layer_cls_to_wrap`')\n",
    "    \n",
    "# deepspeed = './ds_configs/ds_zero3_cpu_offload.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/ds_zero3.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/stage3_no_offloading.conf'; fsdp = False # error with loading... something wrong with the config.\n",
    "\n",
    "# fsdp = False; deepspeed = False\n",
    "\n",
    "if fsdp and deepspeed:\n",
    "    raise ValueError('either fsdp or deepspeed, not both')\n",
    "\n",
    "use_lora = False\n",
    "lora_rank = 256 # test {8, 16, 32, 128} # just [128, 8] for now.\n",
    "lora_alpha = lora_rank \n",
    "lora_dropout = 0.05\n",
    "if use_lora:\n",
    "    abbr_model_name += f'+lora(r={lora_rank},a={lora_alpha})'\n",
    "\n",
    "mixed_precision = 'bf16' if arch == 'x86_64' else 'fp16' # mixed_precision = ''\n",
    "torch_dtype = 'bfloat16' if arch=='x86_64' else 'float16'; torch_dtype = 'float32'\n",
    "\n",
    "gradient_checkpointing = True\n",
    "load_in_8bit = False\n",
    "\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"Effective batch size {effective_batch_size}\")\n",
    "\n",
    "\n",
    "if nodes == 1:\n",
    "    exe = 'python' if num_gpus==1 else \\\n",
    "        f\"torchrun --nproc_per_node={num_gpus} --master_port=10002\"\n",
    "else:\n",
    "    exe = f\"torchrun --nnodes={nodes} --nproc_per_node={num_gpus} --rdzv-id=$SLURM_JOB_ID --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT\"\n",
    "\n",
    "if test_run:\n",
    "    exe = f\"CUDA_VISIBLE_DEVICES={','.join(map(str, range(num_gpus)))} {exe}\"\n",
    "if test_run and debug_mode:\n",
    "    exe = 'TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO ' + exe\n",
    "    error_file='/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/error_file'\n",
    "    exe = f'TORCHELASTIC_ERROR_FILE={error_file} {exe}'\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    subsample_mixture_list,\n",
    ")\n",
    "\n",
    "output_dirname_list = []\n",
    "for (mix_name_and_subsample_mixture,) in options_list:\n",
    "    mix_name, subsample_mixture = mix_name_and_subsample_mixture\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{abbr_train_file}:{int(total_data_points/1000)}k\"\n",
    "        \n",
    "    if job_name == 'ft2':\n",
    "        if subsample_mixture is not None:\n",
    "            assert(abbr_train_file=='all')\n",
    "            output_dirname += \\\n",
    "                '_mix='+','.join(f'{k}:{v}' for k,v in subsample_mixture.items())\n",
    "            \n",
    "    if job_name == 'oi3':\n",
    "        output_dirname += '_'+mix_name\n",
    "            \n",
    "            \n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "            \n",
    "    # if not test_run:\n",
    "    #     output_dirname += \\\n",
    "    #         '_ep='+str(num_train_epochs)\n",
    "    # if not test_run:\n",
    "    #     output_dirname += \\\n",
    "    #         ('_fsdp='+fsdp.split(' ')[0] if fsdp else '')+\\\n",
    "    #         ('_deepspeed='+os.path.basename(deepspeed).split('.')[0] if deepspeed else '')+\\\n",
    "    #         ('_gradckpt='+str(gradient_checkpointing) if gradient_checkpointing else '')+\\\n",
    "    #         '_mbsz='+str(batch_size_per_gpu)+\\\n",
    "    #         '_dtype='+torch_dtype+\\\n",
    "    #         ('_mp='+str(mixed_precision) if mixed_precision else '_mp=none')+\\\n",
    "    #         '_seqlen='+str(max_seq_length)+\\\n",
    "    #         '_nodes='+str(nodes)\n",
    "    output_dir = os.path.join('results', job_name, output_dirname)\n",
    "    \n",
    "    cmd = f\"\"\"\n",
    "    {'!cd .. && ' if test_run else ''}{exe}\n",
    "        open_instruct/finetune_trainer.py \\\n",
    "        --model_name_or_path={model_name_or_path} \\\n",
    "        --tokenizer_name={model_name_or_path} \\\n",
    "        {'--load_in_8bit' if load_in_8bit else ''} \\\n",
    "        --use_fast_tokenizer=True \\\n",
    "        --train_file={train_file} \\\n",
    "        --max_seq_length={max_seq_length} \\\n",
    "        {'--use_lora' if use_lora else ''}\n",
    "        {'--lora_rank='+str(lora_rank) if use_lora else ''}\n",
    "        {'--lora_alpha='+str(lora_alpha) if use_lora else ''}\n",
    "        {'--lora_dropout='+str(lora_dropout) if use_lora else ''}\n",
    "        --do_train \\\n",
    "        --preprocessing_num_workers=16 \\\n",
    "        --per_device_train_batch_size={per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
    "        --learning_rate=2e-5 \\\n",
    "        --lr_scheduler_type=linear \\\n",
    "        --warmup_ratio=0.03 \\\n",
    "        --optim={optimizer} \\\n",
    "        --weight_decay=0. \\\n",
    "        --evaluation_strategy=\"no\" \\\n",
    "        --logging_steps=1 \\\n",
    "        --save_strategy={save_strategy} \\\n",
    "        --save_steps={save_steps} \\\n",
    "        --save_total_limit={save_total_limit} \\\n",
    "        --num_train_epochs={num_train_epochs} \\\n",
    "        {'--fsdp=\"'+fsdp+'\"' if fsdp else ''}\n",
    "        {'--fsdp_transformer_layer_cls_to_wrap=\"'+fsdp_transformer_layer_cls_to_wrap+'\"' \n",
    "            if fsdp else ''}\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''}\n",
    "        --report_to=tensorboard \\\n",
    "        --torch_dtype={torch_dtype} \\\n",
    "        --dataloader_num_workers=8 \\\n",
    "        {f'--{mixed_precision}=True' if mixed_precision else ''} \\\n",
    "        {'--overwrite_output_dir' if overwrite_output_dir else ''} \\\n",
    "        {'--deepspeed='+deepspeed if deepspeed else ''} \\\n",
    "        {'--subsample_mixture=\"'+str(subsample_mixture).replace(': ', ':').replace(', ', ',')+'\"'\n",
    "            if subsample_mixture else ''} \\\n",
    "        --output_dir=\"{output_dir}\" \\\n",
    "    \"\"\" \n",
    "    #    --overwrite_cache\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    if test_run:\n",
    "        print()\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ba1bdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', {'cot': 93277, 'dolly': 2912, 'flan_v2': 101772, 'oasst1': 2037}),\n",
       " ('', {'cot': 79488, 'dolly': 944, 'flan_v2': 118208, 'oasst1': 1358}),\n",
       " ('humanmix', {'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_data_points = 200000\n",
    "subsample_mixture_normalized_list = []\n",
    "\n",
    "mixes = [\n",
    "    {'cot': 0.46638974, 'dolly': 0.01456044, 'flan_v2': 0.50886009, 'oasst1': 0.01018973},\n",
    "    {'cot': 0.39744481, 'dolly': 0.00472114, 'flan_v2': 0.59104177, 'oasst1': 0.00679229},\n",
    "]\n",
    "\n",
    "subsample_mixture_normalized_list += [('', d) for d in mixes]\n",
    "subsample_mixture_normalized_list += [('humanmix', # humanmix\n",
    "                                       {'cot': 0.48785105, 'dolly': 0.00732313, 'flan_v2': 0.48785105, 'oasst1': 0.01697478})]\n",
    "\n",
    "subsample_mixture_normalized_list = [(x[0],  compute_mixture_num_samples(x[1], total_data_points)) \n",
    "                                     for x in subsample_mixture_normalized_list]\n",
    "\n",
    "subsample_mixture_normalized_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831fe55",
   "metadata": {},
   "source": [
    "# eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e3fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_all_symlinks(directory, verbose=False):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files + dirs:\n",
    "            path = os.path.join(root, name)\n",
    "            if os.path.islink(path):\n",
    "                os.unlink(path)\n",
    "                if verbose:\n",
    "                    print(f\"Removed symlink: {path}\")\n",
    "                \n",
    "import uuid\n",
    "\n",
    "def create_unique_symlinks(file_paths, verbose=False):\n",
    "    \"\"\"Create symlinks for each `file` in `files` in the same directory, with a unique name. \"\"\"\n",
    "    dirs = [os.path.dirname(x) for x in file_paths]\n",
    "\n",
    "    symlink_path_dict = {}\n",
    "    for directory, path in zip(dirs, file_paths):\n",
    "        if os.path.isdir(path):\n",
    "            symlink_name = f\"symlink_{str(uuid.uuid4())[:8]}\"  # Generate a unique symlink name\n",
    "            symlink_path = os.path.join(directory, symlink_name)\n",
    "            try:\n",
    "                os.symlink(os.path.abspath(path), symlink_path)\n",
    "                if verbose:\n",
    "                    print(f\"Created symlink: {symlink_path} -> {path}\")\n",
    "            except OSError as e:\n",
    "                print(f\"Failed to create symlink: {path}. Error: {e}\")\n",
    "            symlink_path_dict.update({path: symlink_path})\n",
    "    return symlink_path_dict\n",
    "\n",
    "\n",
    "def get_resource_for_task(task_name, model_name_or_path):\n",
    "    model_name_or_path = model_name_or_path.lower()\n",
    "    if any(x in model_name_or_path for x in ['gpt2-medium', 'pythia-160m']):\n",
    "        return 50, 1\n",
    "    if any(x in model_name_or_path for x in ['gpt-xl']):\n",
    "        if any(x in task_name for x in ['bbh_s=3', 'tydiqa_s=1_gp', 'mmlu_s=5']):\n",
    "            return 16, 1\n",
    "        else:\n",
    "            return 32, 1\n",
    "    if any(x in model_name_or_path for x in ['llama', 'pythia-1.4b', 'pythia-2.8b']):\n",
    "        if any(x in task_name for x in ['bbh_s=3', 'mmlu_s=5']):\n",
    "            return 5, 1\n",
    "        else:\n",
    "            return 10, 1\n",
    "    if any(x in model_name_or_path for x in ['pythia-6.9b', 'dolly-v2-7b']):\n",
    "        if any(x in task_name for x in ['bbh_s=3', 'mmlu_s=5', 'mmlu_s=0']):\n",
    "            return 4, 1\n",
    "        else:\n",
    "            return 10, 1\n",
    "    return batch_size, job_duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b68375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-500')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-450')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-350')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-600')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-800')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-950')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-150')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-850')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-50')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-100')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-700')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-650')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-300')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-250')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-900')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-400')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-750')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-550')\n",
      "('mmlu_s=0', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('mmlu_s=5', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('gsm_s=8', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('gsm_s=8_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('bbh_s=3', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('bbh_s=3_cot', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('humaneval', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('tydiqa_s=1_cb', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('tydiqa_s=1_gp', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('mmlu_s=0_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('mmlu_s=5_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('gsm_s=8_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('bbh_s=3_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('humaneval_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi3/llama-7b_all:400k_humanmix/checkpoint-200')\n",
      "#cmds:  1134 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4659b031/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a8476a1b/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_77878387/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_322c8edb/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_20b38889/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a2838a7b/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cfb59a2f/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6a363d03/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be8f25ba/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_37f4c631/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_50c2653b/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_35608ca7/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5bc4447f/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bf04b6b8/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_189a3386/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_4ea7541a/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5450e87d/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_2c5b818e/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_62fbb69c/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_73b149b4/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a91046c0/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_1b915249/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_8ff264cd/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_fb920325/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc49254c/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e64becac/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_24c41624/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_ca096868/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0fe6fab9/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_be52e3e1/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_207d812e/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_afcd9e0d/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_6f7824b5/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0cee8f7b/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_89f9e5d6/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_05c786ed/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a66caa15/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5a388b49/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_e501f23e/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_96d9a157/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_129fc0e2/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_84cc9472/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_5c3cb96c/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bdef09e7/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_12efb3cc/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_352c564f/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d00d978b/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_eb49bff3/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d757e465/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_59be82fa/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d9833328/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_a63b1494/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_9e4bbed7/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_93c5594b/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_7d95685c/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_141dbb66/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d4b41052/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d1bf6e48/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_bc2ac0cd/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_d734b470/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_0ce2ebf0/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_217d44ac/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5 --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format --chat_format_version 1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc\" --save_dir \"results/oi3/llama-7b_all:400k_humanmix/symlink_cac442fc/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "num_cpus = 10; cpu_mem = 32 # mem usage quite small for llama7b+lora on bbh\n",
    "num_cpus = 24; cpu_mem = 64\n",
    "\n",
    "exp_dir = ''\n",
    "create_symlinks = False\n",
    "include_checkpoints = False\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "\n",
    "task_names = [\n",
    "    'mmlu_s=0',\n",
    "    'mmlu_s=5', # ~1hr\n",
    "    'gsm_s=8',\n",
    "    'gsm_s=8_cot',\n",
    "    'bbh_s=3',\n",
    "    'bbh_s=3_cot', # max_datapoints_per_task=40 -> 40min.\n",
    "    'humaneval',\n",
    "    'tydiqa_s=1_cb',\n",
    "    'tydiqa_s=1_gp',\n",
    "]\n",
    "task_names_chatfmt = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "# create_symlinks = False; exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "\n",
    "\n",
    "# # ## baselines eval \n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "# #     'gpt2',\n",
    "# #     'gpt2-medium',\n",
    "#     'huggyllama/llama-7b', \n",
    "#     'NousResearch/Llama-2-7b-hf',\n",
    "#     'EleutherAI/pythia-1.4b',\n",
    "#     'EleutherAI/pythia-2.8b',\n",
    "#     'EleutherAI/pythia-6.9b',\n",
    "#     'databricks/dolly-v2-7b',\n",
    "# ]]\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# ## ft2\n",
    "# exp_dir = 'results/ft2/'\n",
    "# create_symlinks = True\n",
    "# subdir_filter_fn = lambda x: any(y in x for y in ['llama-7b'])\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "## llama-7b time-series 400k, 600k\n",
    "exp_dir = 'results/oi3/'\n",
    "create_symlinks = True\n",
    "include_checkpoints = True\n",
    "subdir_filter_fn = lambda x: any(y in x for y in ['400k']) # , '600k'\n",
    "task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# eval_rest = True; create_symlinks = False; exp_dir = 'results/ft1'\n",
    "# include_checkpoints = True; eval_rest = True; create_symlinks = True; exp_dir = 'results/ft2/'; \n",
    "# include_checkpoints = True; eval_rest = True; create_symlinks = False; exp_dir = 'results/oi3/'; \n",
    "\n",
    "\n",
    "if len(subdir_path_list)==0:\n",
    "    if create_symlinks:\n",
    "        remove_all_symlinks(exp_dir)\n",
    "    subdir_path_list = []\n",
    "    subdirs = list(os.listdir(exp_dir))\n",
    "    subdirs = filter(subdir_filter_fn, subdirs)\n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(exp_dir, subdir)\n",
    "        if include_checkpoints:\n",
    "            subdir_path_list += glob.glob(os.path.join(subdir_path, 'checkpoint-*'))\n",
    "        if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "            continue\n",
    "        subdir_path_list.append(subdir_path)\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not os.path.islink(subdir_path) and \\\n",
    "                not os.path.isfile(os.path.join(subdir_path, 'eval', task_name, 'metrics.json')):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "                print((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = zip(task_names, subdir_path_list)\n",
    "    \n",
    "\n",
    "print('#cmds: ', len(list(task_name_and_model)), '\\n')\n",
    "\n",
    "if create_symlinks:\n",
    "    # create symlink for each directory.\n",
    "    symlink_path_dict = create_unique_symlinks(\n",
    "        list([x[1] for x in task_name_and_model]))\n",
    "    options_list = list(map(lambda x: (x[0], symlink_path_dict[x[1]]), task_name_and_model))\n",
    "else:\n",
    "    options_list = task_name_and_model\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "info = {}  \n",
    "cmds = []\n",
    "for task_name, model_name_or_path in options_list:\n",
    "    \n",
    "    use_chat_format = 'chatfmt' in task_name\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(model_name_or_path, 'ft_args.json'), 'r') as f:\n",
    "            ft_args = json.load(f)\n",
    "        # note `model_name_or_path` could be anything, e.g., soft links with arbitrary names.\n",
    "        # but `ft_args_model_name_or_path` indicates the finetuned model name.\n",
    "        ft_args_model_name_or_path = ft_args['model_args']['model_name_or_path']\n",
    "    except:\n",
    "        ft_args_model_name_or_path = model_name_or_path\n",
    "\n",
    "    if 'gpt2' in ft_args_model_name_or_path:\n",
    "        tydiqa_max_context_length = 400 # max ctx len without exceeding max_seq_len\n",
    "    else:\n",
    "        tydiqa_max_context_length = 512\n",
    "    batch_size, job_duration = get_resource_for_task(\n",
    "        task_name, ft_args_model_name_or_path)\n",
    "    \n",
    "    job_name = f'eval.{task_name}'\n",
    "    run_id = model_name_or_path\n",
    "    save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "    \n",
    "    if task_name.startswith('mmlu'):\n",
    "        chat_format_version = 1\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 5)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.mmlu.run_eval \\\n",
    "            --data_dir data/eval/mmlu \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --ntrain {n_shot} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--chat_format_version '+str(chat_format_version) if chat_format_version else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('gsm'):\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 8)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.gsm.run_eval \\\n",
    "            --data_dir data/eval/gsm/ \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_num_examples 200 \\\n",
    "            --n_shot {n_shot} \\\n",
    "            --max_new_tokens 256 \\\n",
    "            {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''}\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('bbh'):\n",
    "        max_num_examples_per_task = 40 if 'cot' in task_name else None\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 3)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.bbh.run_eval \\\n",
    "            --data_dir data/eval/bbh/ \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_new_tokens 256 \\\n",
    "            --n_shot {n_shot} \\\n",
    "            {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--max_num_examples_per_task '+str(max_num_examples_per_task) if max_num_examples_per_task else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('humaneval'):\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.codex_humaneval.run_eval \\\n",
    "            --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --eval_pass_at_ks 1 \\\n",
    "            --unbiased_sampling_size_n 1 \\\n",
    "            --temperature 0.1 \\\n",
    "            {'--use_chat_format' if use_chat_format else ''}\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('tydiqa'):\n",
    "        no_context = 'cb' in task_name\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot in [0,1])\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.tydiqa.run_eval \\\n",
    "            --data_dir data/eval/tydiqa \\\n",
    "            --n_shot {n_shot} \\\n",
    "            --max_num_examples_per_lang 100 \\\n",
    "            --max_context_length {tydiqa_max_context_length} \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            {'--no_context' if no_context else ''}\n",
    "            {'--use_chat_format' if use_chat_format else ''}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        raise ValueError(f'{task_name} not supported.')\n",
    "        \n",
    "        \n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "    print(cmd)\n",
    "    \n",
    "    # submit\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=save_dir)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=1,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aef11ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_fmt=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3618: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3619: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6b1e4_row0_col0, #T_6b1e4_row0_col1, #T_6b1e4_row0_col2, #T_6b1e4_row0_col3, #T_6b1e4_row1_col0, #T_6b1e4_row1_col1, #T_6b1e4_row1_col2, #T_6b1e4_row1_col3, #T_6b1e4_row2_col0, #T_6b1e4_row2_col1, #T_6b1e4_row2_col2, #T_6b1e4_row2_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6b1e4_row0_col4, #T_6b1e4_row0_col10, #T_6b1e4_row0_col12, #T_6b1e4_row1_col6, #T_6b1e4_row1_col7, #T_6b1e4_row1_col11, #T_6b1e4_row1_col12, #T_6b1e4_row2_col7, #T_6b1e4_row2_col8, #T_6b1e4_row2_col9, #T_6b1e4_row2_col12, #T_6b1e4_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6b1e4_row0_col5, #T_6b1e4_row0_col14, #T_6b1e4_row1_col5, #T_6b1e4_row1_col14, #T_6b1e4_row2_col5, #T_6b1e4_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6b1e4_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6b1e4_row0_col7, #T_6b1e4_row0_col8, #T_6b1e4_row0_col9, #T_6b1e4_row0_col11, #T_6b1e4_row0_col13, #T_6b1e4_row1_col4, #T_6b1e4_row1_col10, #T_6b1e4_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6b1e4_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6b1e4_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6b1e4_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6b1e4_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6b1e4_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6b1e4_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6b1e4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6b1e4_level0_col0\" class=\"col_heading level0 col0\" >total_train_samples</th>\n",
       "      <th id=\"T_6b1e4_level0_col1\" class=\"col_heading level0 col1\" >run_name</th>\n",
       "      <th id=\"T_6b1e4_level0_col2\" class=\"col_heading level0 col2\" >model_args.model_name_or_path</th>\n",
       "      <th id=\"T_6b1e4_level0_col3\" class=\"col_heading level0 col3\" >data_args.subsample_mixture</th>\n",
       "      <th id=\"T_6b1e4_level0_col4\" class=\"col_heading level0 col4\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_6b1e4_level0_col5\" class=\"col_heading level0 col5\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_6b1e4_level0_col6\" class=\"col_heading level0 col6\" >GSM/Direct</th>\n",
       "      <th id=\"T_6b1e4_level0_col7\" class=\"col_heading level0 col7\" >GSM/CoT</th>\n",
       "      <th id=\"T_6b1e4_level0_col8\" class=\"col_heading level0 col8\" >BBH/Direct</th>\n",
       "      <th id=\"T_6b1e4_level0_col9\" class=\"col_heading level0 col9\" >BBH/CoT</th>\n",
       "      <th id=\"T_6b1e4_level0_col10\" class=\"col_heading level0 col10\" >TydiQA/CB</th>\n",
       "      <th id=\"T_6b1e4_level0_col11\" class=\"col_heading level0 col11\" >TydiQA/GP</th>\n",
       "      <th id=\"T_6b1e4_level0_col12\" class=\"col_heading level0 col12\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_6b1e4_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_6b1e4_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6b1e4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6b1e4_row0_col0\" class=\"data row0 col0\" >199998</td>\n",
       "      <td id=\"T_6b1e4_row0_col1\" class=\"data row0 col1\" >pythia-1.4b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394</td>\n",
       "      <td id=\"T_6b1e4_row0_col2\" class=\"data row0 col2\" >results/baselines/EleutherAI/pythia-1.4b</td>\n",
       "      <td id=\"T_6b1e4_row0_col3\" class=\"data row0 col3\" >{'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}</td>\n",
       "      <td id=\"T_6b1e4_row0_col4\" class=\"data row0 col4\" >25.33</td>\n",
       "      <td id=\"T_6b1e4_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_6b1e4_row0_col6\" class=\"data row0 col6\" >4.50</td>\n",
       "      <td id=\"T_6b1e4_row0_col7\" class=\"data row0 col7\" >6.00</td>\n",
       "      <td id=\"T_6b1e4_row0_col8\" class=\"data row0 col8\" >29.69</td>\n",
       "      <td id=\"T_6b1e4_row0_col9\" class=\"data row0 col9\" >22.22</td>\n",
       "      <td id=\"T_6b1e4_row0_col10\" class=\"data row0 col10\" >2.39</td>\n",
       "      <td id=\"T_6b1e4_row0_col11\" class=\"data row0 col11\" >21.63</td>\n",
       "      <td id=\"T_6b1e4_row0_col12\" class=\"data row0 col12\" >0.00</td>\n",
       "      <td id=\"T_6b1e4_row0_col13\" class=\"data row0 col13\" >13.97</td>\n",
       "      <td id=\"T_6b1e4_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6b1e4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6b1e4_row1_col0\" class=\"data row1 col0\" >201547</td>\n",
       "      <td id=\"T_6b1e4_row1_col1\" class=\"data row1 col1\" >pythia-1.4b_all:200k_mix=cot:45092,dolly:2818,flan_v2:34790,oasst1:118847</td>\n",
       "      <td id=\"T_6b1e4_row1_col2\" class=\"data row1 col2\" >results/baselines/EleutherAI/pythia-1.4b</td>\n",
       "      <td id=\"T_6b1e4_row1_col3\" class=\"data row1 col3\" >{'cot': 45092, 'dolly': 2818, 'flan_v2': 34790, 'oasst1': 118847}</td>\n",
       "      <td id=\"T_6b1e4_row1_col4\" class=\"data row1 col4\" >26.92</td>\n",
       "      <td id=\"T_6b1e4_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_6b1e4_row1_col6\" class=\"data row1 col6\" >3.50</td>\n",
       "      <td id=\"T_6b1e4_row1_col7\" class=\"data row1 col7\" >2.50</td>\n",
       "      <td id=\"T_6b1e4_row1_col8\" class=\"data row1 col8\" >28.79</td>\n",
       "      <td id=\"T_6b1e4_row1_col9\" class=\"data row1 col9\" >19.72</td>\n",
       "      <td id=\"T_6b1e4_row1_col10\" class=\"data row1 col10\" >4.78</td>\n",
       "      <td id=\"T_6b1e4_row1_col11\" class=\"data row1 col11\" >17.69</td>\n",
       "      <td id=\"T_6b1e4_row1_col12\" class=\"data row1 col12\" >0.00</td>\n",
       "      <td id=\"T_6b1e4_row1_col13\" class=\"data row1 col13\" >12.99</td>\n",
       "      <td id=\"T_6b1e4_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6b1e4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6b1e4_row2_col0\" class=\"data row2 col0\" >198971</td>\n",
       "      <td id=\"T_6b1e4_row2_col1\" class=\"data row2 col1\" >pythia-1.4b_all:200k_mix=cot:72119,dolly:439,flan_v2:126074,oasst1:339</td>\n",
       "      <td id=\"T_6b1e4_row2_col2\" class=\"data row2 col2\" >results/baselines/EleutherAI/pythia-1.4b</td>\n",
       "      <td id=\"T_6b1e4_row2_col3\" class=\"data row2 col3\" >{'cot': 72119, 'dolly': 439, 'flan_v2': 126074, 'oasst1': 339}</td>\n",
       "      <td id=\"T_6b1e4_row2_col4\" class=\"data row2 col4\" >25.74</td>\n",
       "      <td id=\"T_6b1e4_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_6b1e4_row2_col6\" class=\"data row2 col6\" >6.00</td>\n",
       "      <td id=\"T_6b1e4_row2_col7\" class=\"data row2 col7\" >2.50</td>\n",
       "      <td id=\"T_6b1e4_row2_col8\" class=\"data row2 col8\" >27.52</td>\n",
       "      <td id=\"T_6b1e4_row2_col9\" class=\"data row2 col9\" >16.48</td>\n",
       "      <td id=\"T_6b1e4_row2_col10\" class=\"data row2 col10\" >3.31</td>\n",
       "      <td id=\"T_6b1e4_row2_col11\" class=\"data row2 col11\" >20.43</td>\n",
       "      <td id=\"T_6b1e4_row2_col12\" class=\"data row2 col12\" >0.00</td>\n",
       "      <td id=\"T_6b1e4_row2_col13\" class=\"data row2 col13\" >12.75</td>\n",
       "      <td id=\"T_6b1e4_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fff7807a560>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5c70c_row0_col0, #T_5c70c_row0_col1, #T_5c70c_row0_col2, #T_5c70c_row0_col3, #T_5c70c_row1_col0, #T_5c70c_row1_col1, #T_5c70c_row1_col2, #T_5c70c_row1_col3, #T_5c70c_row2_col0, #T_5c70c_row2_col1, #T_5c70c_row2_col2, #T_5c70c_row2_col3, #T_5c70c_row3_col0, #T_5c70c_row3_col1, #T_5c70c_row3_col2, #T_5c70c_row3_col3, #T_5c70c_row4_col0, #T_5c70c_row4_col1, #T_5c70c_row4_col2, #T_5c70c_row4_col3, #T_5c70c_row5_col0, #T_5c70c_row5_col1, #T_5c70c_row5_col2, #T_5c70c_row5_col3, #T_5c70c_row6_col0, #T_5c70c_row6_col1, #T_5c70c_row6_col2, #T_5c70c_row6_col3, #T_5c70c_row7_col0, #T_5c70c_row7_col1, #T_5c70c_row7_col2, #T_5c70c_row7_col3, #T_5c70c_row8_col0, #T_5c70c_row8_col1, #T_5c70c_row8_col2, #T_5c70c_row8_col3, #T_5c70c_row9_col0, #T_5c70c_row9_col1, #T_5c70c_row9_col2, #T_5c70c_row9_col3, #T_5c70c_row10_col0, #T_5c70c_row10_col1, #T_5c70c_row10_col2, #T_5c70c_row10_col3, #T_5c70c_row11_col0, #T_5c70c_row11_col1, #T_5c70c_row11_col2, #T_5c70c_row11_col3, #T_5c70c_row12_col0, #T_5c70c_row12_col1, #T_5c70c_row12_col2, #T_5c70c_row12_col3, #T_5c70c_row13_col0, #T_5c70c_row13_col1, #T_5c70c_row13_col2, #T_5c70c_row13_col3, #T_5c70c_row14_col0, #T_5c70c_row14_col1, #T_5c70c_row14_col2, #T_5c70c_row14_col3, #T_5c70c_row15_col0, #T_5c70c_row15_col1, #T_5c70c_row15_col2, #T_5c70c_row15_col3, #T_5c70c_row16_col0, #T_5c70c_row16_col1, #T_5c70c_row16_col2, #T_5c70c_row16_col3, #T_5c70c_row17_col0, #T_5c70c_row17_col1, #T_5c70c_row17_col2, #T_5c70c_row17_col3, #T_5c70c_row18_col0, #T_5c70c_row18_col1, #T_5c70c_row18_col2, #T_5c70c_row18_col3, #T_5c70c_row19_col0, #T_5c70c_row19_col1, #T_5c70c_row19_col2, #T_5c70c_row19_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5c70c_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row0_col6, #T_5c70c_row7_col11, #T_5c70c_row15_col10, #T_5c70c_row17_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row0_col7, #T_5c70c_row0_col9, #T_5c70c_row0_col12, #T_5c70c_row0_col13, #T_5c70c_row0_col14, #T_5c70c_row4_col10, #T_5c70c_row5_col8, #T_5c70c_row6_col4, #T_5c70c_row6_col5, #T_5c70c_row8_col11, #T_5c70c_row12_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row0_col8, #T_5c70c_row9_col10, #T_5c70c_row12_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row0_col11, #T_5c70c_row5_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row1_col4, #T_5c70c_row1_col6, #T_5c70c_row13_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row1_col8, #T_5c70c_row16_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row1_col9, #T_5c70c_row2_col9, #T_5c70c_row9_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d55042;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row1_col11, #T_5c70c_row10_col13, #T_5c70c_row11_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row1_col12, #T_5c70c_row9_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row1_col13, #T_5c70c_row1_col14, #T_5c70c_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row2_col5, #T_5c70c_row5_col5, #T_5c70c_row17_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row2_col6, #T_5c70c_row4_col6, #T_5c70c_row8_col6, #T_5c70c_row18_col6, #T_5c70c_row19_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row2_col8, #T_5c70c_row13_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row2_col10, #T_5c70c_row7_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row2_col11, #T_5c70c_row11_col13, #T_5c70c_row18_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row2_col12, #T_5c70c_row11_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row2_col14, #T_5c70c_row7_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row3_col6, #T_5c70c_row7_col6, #T_5c70c_row10_col6, #T_5c70c_row14_col6, #T_5c70c_row15_col6, #T_5c70c_row16_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row3_col7, #T_5c70c_row14_col7, #T_5c70c_row16_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row3_col8, #T_5c70c_row3_col13, #T_5c70c_row10_col11, #T_5c70c_row14_col9, #T_5c70c_row14_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row3_col10, #T_5c70c_row5_col9, #T_5c70c_row7_col5, #T_5c70c_row7_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row4_col4, #T_5c70c_row18_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row4_col5, #T_5c70c_row17_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row4_col7, #T_5c70c_row11_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row4_col8, #T_5c70c_row5_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row4_col11, #T_5c70c_row16_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row4_col12, #T_5c70c_row16_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row4_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row4_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row5_col4, #T_5c70c_row10_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row5_col6, #T_5c70c_row11_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row5_col7, #T_5c70c_row13_col13, #T_5c70c_row15_col7, #T_5c70c_row17_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row5_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row5_col11, #T_5c70c_row6_col11, #T_5c70c_row10_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row5_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row6_col6, #T_5c70c_row7_col12, #T_5c70c_row9_col12, #T_5c70c_row10_col10, #T_5c70c_row10_col12, #T_5c70c_row12_col12, #T_5c70c_row13_col12, #T_5c70c_row14_col12, #T_5c70c_row16_col12, #T_5c70c_row17_col4, #T_5c70c_row17_col5, #T_5c70c_row17_col12, #T_5c70c_row18_col9, #T_5c70c_row18_col12, #T_5c70c_row19_col7, #T_5c70c_row19_col8, #T_5c70c_row19_col11, #T_5c70c_row19_col12, #T_5c70c_row19_col13, #T_5c70c_row19_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row6_col7, #T_5c70c_row13_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row6_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row6_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row6_col10, #T_5c70c_row6_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f2c9b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row6_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row6_col13, #T_5c70c_row7_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row7_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row7_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row7_col14, #T_5c70c_row13_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row8_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row8_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row8_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row8_col8, #T_5c70c_row13_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row8_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row8_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row8_col12, #T_5c70c_row15_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row8_col13, #T_5c70c_row10_col7, #T_5c70c_row15_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row8_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row9_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row9_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row9_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row9_col7, #T_5c70c_row19_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row9_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row9_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row9_col14, #T_5c70c_row16_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row10_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row10_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row10_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row11_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row11_col7, #T_5c70c_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row11_col8, #T_5c70c_row14_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row11_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row11_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row11_col14, #T_5c70c_row12_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row12_col4, #T_5c70c_row12_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row12_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row12_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row12_col11, #T_5c70c_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row12_col14, #T_5c70c_row15_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row13_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row13_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row13_col10, #T_5c70c_row14_col4, #T_5c70c_row16_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row14_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row14_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row14_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row15_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row15_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row15_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row15_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row16_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row16_col11, #T_5c70c_row17_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row16_col14, #T_5c70c_row18_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row17_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row17_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row17_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row18_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row18_col7, #T_5c70c_row18_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row18_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row18_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row19_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c70c_row19_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c70c_row19_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5c70c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5c70c_level0_col0\" class=\"col_heading level0 col0\" >total_train_samples</th>\n",
       "      <th id=\"T_5c70c_level0_col1\" class=\"col_heading level0 col1\" >run_name</th>\n",
       "      <th id=\"T_5c70c_level0_col2\" class=\"col_heading level0 col2\" >model_args.model_name_or_path</th>\n",
       "      <th id=\"T_5c70c_level0_col3\" class=\"col_heading level0 col3\" >data_args.subsample_mixture</th>\n",
       "      <th id=\"T_5c70c_level0_col4\" class=\"col_heading level0 col4\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_5c70c_level0_col5\" class=\"col_heading level0 col5\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_5c70c_level0_col6\" class=\"col_heading level0 col6\" >GSM/Direct</th>\n",
       "      <th id=\"T_5c70c_level0_col7\" class=\"col_heading level0 col7\" >GSM/CoT</th>\n",
       "      <th id=\"T_5c70c_level0_col8\" class=\"col_heading level0 col8\" >BBH/Direct</th>\n",
       "      <th id=\"T_5c70c_level0_col9\" class=\"col_heading level0 col9\" >BBH/CoT</th>\n",
       "      <th id=\"T_5c70c_level0_col10\" class=\"col_heading level0 col10\" >TydiQA/CB</th>\n",
       "      <th id=\"T_5c70c_level0_col11\" class=\"col_heading level0 col11\" >TydiQA/GP</th>\n",
       "      <th id=\"T_5c70c_level0_col12\" class=\"col_heading level0 col12\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_5c70c_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_5c70c_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5c70c_row0_col0\" class=\"data row0 col0\" >200000</td>\n",
       "      <td id=\"T_5c70c_row0_col1\" class=\"data row0 col1\" >llama-7b_humanmix</td>\n",
       "      <td id=\"T_5c70c_row0_col2\" class=\"data row0 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row0_col3\" class=\"data row0 col3\" >{}</td>\n",
       "      <td id=\"T_5c70c_row0_col4\" class=\"data row0 col4\" >43.55</td>\n",
       "      <td id=\"T_5c70c_row0_col5\" class=\"data row0 col5\" >46.46</td>\n",
       "      <td id=\"T_5c70c_row0_col6\" class=\"data row0 col6\" >6.00</td>\n",
       "      <td id=\"T_5c70c_row0_col7\" class=\"data row0 col7\" >29.00</td>\n",
       "      <td id=\"T_5c70c_row0_col8\" class=\"data row0 col8\" >36.11</td>\n",
       "      <td id=\"T_5c70c_row0_col9\" class=\"data row0 col9\" >34.35</td>\n",
       "      <td id=\"T_5c70c_row0_col10\" class=\"data row0 col10\" >10.37</td>\n",
       "      <td id=\"T_5c70c_row0_col11\" class=\"data row0 col11\" >43.48</td>\n",
       "      <td id=\"T_5c70c_row0_col12\" class=\"data row0 col12\" >10.37</td>\n",
       "      <td id=\"T_5c70c_row0_col13\" class=\"data row0 col13\" >28.85</td>\n",
       "      <td id=\"T_5c70c_row0_col14\" class=\"data row0 col14\" >-4.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5c70c_row1_col0\" class=\"data row1 col0\" >199998</td>\n",
       "      <td id=\"T_5c70c_row1_col1\" class=\"data row1 col1\" >llama-7b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394_withreplacement</td>\n",
       "      <td id=\"T_5c70c_row1_col2\" class=\"data row1 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row1_col3\" class=\"data row1 col3\" >{'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}</td>\n",
       "      <td id=\"T_5c70c_row1_col4\" class=\"data row1 col4\" >42.57</td>\n",
       "      <td id=\"T_5c70c_row1_col5\" class=\"data row1 col5\" >44.22</td>\n",
       "      <td id=\"T_5c70c_row1_col6\" class=\"data row1 col6\" >7.00</td>\n",
       "      <td id=\"T_5c70c_row1_col7\" class=\"data row1 col7\" >23.50</td>\n",
       "      <td id=\"T_5c70c_row1_col8\" class=\"data row1 col8\" >34.21</td>\n",
       "      <td id=\"T_5c70c_row1_col9\" class=\"data row1 col9\" >33.70</td>\n",
       "      <td id=\"T_5c70c_row1_col10\" class=\"data row1 col10\" >9.63</td>\n",
       "      <td id=\"T_5c70c_row1_col11\" class=\"data row1 col11\" >42.81</td>\n",
       "      <td id=\"T_5c70c_row1_col12\" class=\"data row1 col12\" >6.71</td>\n",
       "      <td id=\"T_5c70c_row1_col13\" class=\"data row1 col13\" >27.15</td>\n",
       "      <td id=\"T_5c70c_row1_col14\" class=\"data row1 col14\" >-9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5c70c_row2_col0\" class=\"data row2 col0\" >199998</td>\n",
       "      <td id=\"T_5c70c_row2_col1\" class=\"data row2 col1\" >llama-7b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394</td>\n",
       "      <td id=\"T_5c70c_row2_col2\" class=\"data row2 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row2_col3\" class=\"data row2 col3\" >{'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}</td>\n",
       "      <td id=\"T_5c70c_row2_col4\" class=\"data row2 col4\" >42.29</td>\n",
       "      <td id=\"T_5c70c_row2_col5\" class=\"data row2 col5\" >44.31</td>\n",
       "      <td id=\"T_5c70c_row2_col6\" class=\"data row2 col6\" >5.50</td>\n",
       "      <td id=\"T_5c70c_row2_col7\" class=\"data row2 col7\" >25.00</td>\n",
       "      <td id=\"T_5c70c_row2_col8\" class=\"data row2 col8\" >36.60</td>\n",
       "      <td id=\"T_5c70c_row2_col9\" class=\"data row2 col9\" >33.70</td>\n",
       "      <td id=\"T_5c70c_row2_col10\" class=\"data row2 col10\" >10.03</td>\n",
       "      <td id=\"T_5c70c_row2_col11\" class=\"data row2 col11\" >42.69</td>\n",
       "      <td id=\"T_5c70c_row2_col12\" class=\"data row2 col12\" >3.05</td>\n",
       "      <td id=\"T_5c70c_row2_col13\" class=\"data row2 col13\" >27.02</td>\n",
       "      <td id=\"T_5c70c_row2_col14\" class=\"data row2 col14\" >-8.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5c70c_row3_col0\" class=\"data row3 col0\" >199997</td>\n",
       "      <td id=\"T_5c70c_row3_col1\" class=\"data row3 col1\" >llama-7b_all:200k_mix=cot:46128,dolly:9386,flan_v2:144243,oasst1:240</td>\n",
       "      <td id=\"T_5c70c_row3_col2\" class=\"data row3 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row3_col3\" class=\"data row3 col3\" >{'cot': 46128, 'dolly': 9386, 'flan_v2': 144243, 'oasst1': 240}</td>\n",
       "      <td id=\"T_5c70c_row3_col4\" class=\"data row3 col4\" >43.90</td>\n",
       "      <td id=\"T_5c70c_row3_col5\" class=\"data row3 col5\" >46.37</td>\n",
       "      <td id=\"T_5c70c_row3_col6\" class=\"data row3 col6\" >5.00</td>\n",
       "      <td id=\"T_5c70c_row3_col7\" class=\"data row3 col7\" >17.00</td>\n",
       "      <td id=\"T_5c70c_row3_col8\" class=\"data row3 col8\" >36.16</td>\n",
       "      <td id=\"T_5c70c_row3_col9\" class=\"data row3 col9\" >32.04</td>\n",
       "      <td id=\"T_5c70c_row3_col10\" class=\"data row3 col10\" >10.15</td>\n",
       "      <td id=\"T_5c70c_row3_col11\" class=\"data row3 col11\" >45.71</td>\n",
       "      <td id=\"T_5c70c_row3_col12\" class=\"data row3 col12\" >4.27</td>\n",
       "      <td id=\"T_5c70c_row3_col13\" class=\"data row3 col13\" >26.73</td>\n",
       "      <td id=\"T_5c70c_row3_col14\" class=\"data row3 col14\" >-9.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5c70c_row4_col0\" class=\"data row4 col0\" >199998</td>\n",
       "      <td id=\"T_5c70c_row4_col1\" class=\"data row4 col1\" >llama-7b_all:200k_mix=cot:81395,dolly:12637,flan_v2:19009,oasst1:86957</td>\n",
       "      <td id=\"T_5c70c_row4_col2\" class=\"data row4 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row4_col3\" class=\"data row4 col3\" >{'cot': 81395, 'dolly': 12637, 'flan_v2': 19009, 'oasst1': 86957}</td>\n",
       "      <td id=\"T_5c70c_row4_col4\" class=\"data row4 col4\" >41.16</td>\n",
       "      <td id=\"T_5c70c_row4_col5\" class=\"data row4 col5\" >42.08</td>\n",
       "      <td id=\"T_5c70c_row4_col6\" class=\"data row4 col6\" >5.50</td>\n",
       "      <td id=\"T_5c70c_row4_col7\" class=\"data row4 col7\" >27.50</td>\n",
       "      <td id=\"T_5c70c_row4_col8\" class=\"data row4 col8\" >33.23</td>\n",
       "      <td id=\"T_5c70c_row4_col9\" class=\"data row4 col9\" >34.07</td>\n",
       "      <td id=\"T_5c70c_row4_col10\" class=\"data row4 col10\" >11.17</td>\n",
       "      <td id=\"T_5c70c_row4_col11\" class=\"data row4 col11\" >40.23</td>\n",
       "      <td id=\"T_5c70c_row4_col12\" class=\"data row4 col12\" >2.44</td>\n",
       "      <td id=\"T_5c70c_row4_col13\" class=\"data row4 col13\" >26.38</td>\n",
       "      <td id=\"T_5c70c_row4_col14\" class=\"data row4 col14\" >-11.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5c70c_row5_col0\" class=\"data row5 col0\" >199999</td>\n",
       "      <td id=\"T_5c70c_row5_col1\" class=\"data row5 col1\" >llama-7b_all:200k_mix=cot:27757,dolly:11372,flan_v2:134027,oasst1:26843</td>\n",
       "      <td id=\"T_5c70c_row5_col2\" class=\"data row5 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row5_col3\" class=\"data row5 col3\" >{'cot': 27757, 'dolly': 11372, 'flan_v2': 134027, 'oasst1': 26843}</td>\n",
       "      <td id=\"T_5c70c_row5_col4\" class=\"data row5 col4\" >42.00</td>\n",
       "      <td id=\"T_5c70c_row5_col5\" class=\"data row5 col5\" >44.29</td>\n",
       "      <td id=\"T_5c70c_row5_col6\" class=\"data row5 col6\" >4.50</td>\n",
       "      <td id=\"T_5c70c_row5_col7\" class=\"data row5 col7\" >19.50</td>\n",
       "      <td id=\"T_5c70c_row5_col8\" class=\"data row5 col8\" >37.41</td>\n",
       "      <td id=\"T_5c70c_row5_col9\" class=\"data row5 col9\" >32.13</td>\n",
       "      <td id=\"T_5c70c_row5_col10\" class=\"data row5 col10\" >9.04</td>\n",
       "      <td id=\"T_5c70c_row5_col11\" class=\"data row5 col11\" >44.36</td>\n",
       "      <td id=\"T_5c70c_row5_col12\" class=\"data row5 col12\" >0.61</td>\n",
       "      <td id=\"T_5c70c_row5_col13\" class=\"data row5 col13\" >25.98</td>\n",
       "      <td id=\"T_5c70c_row5_col14\" class=\"data row5 col14\" >-13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5c70c_row6_col0\" class=\"data row6 col0\" >200804</td>\n",
       "      <td id=\"T_5c70c_row6_col1\" class=\"data row6 col1\" >llama-7b_all_mix=cot:15356,dolly:894,flan_v2:182740,oasst1:1814</td>\n",
       "      <td id=\"T_5c70c_row6_col2\" class=\"data row6 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row6_col3\" class=\"data row6 col3\" >{'cot': 15356, 'dolly': 894, 'flan_v2': 182740, 'oasst1': 1814}</td>\n",
       "      <td id=\"T_5c70c_row6_col4\" class=\"data row6 col4\" >44.60</td>\n",
       "      <td id=\"T_5c70c_row6_col5\" class=\"data row6 col5\" >47.04</td>\n",
       "      <td id=\"T_5c70c_row6_col6\" class=\"data row6 col6\" >3.50</td>\n",
       "      <td id=\"T_5c70c_row6_col7\" class=\"data row6 col7\" >14.00</td>\n",
       "      <td id=\"T_5c70c_row6_col8\" class=\"data row6 col8\" >37.15</td>\n",
       "      <td id=\"T_5c70c_row6_col9\" class=\"data row6 col9\" >31.20</td>\n",
       "      <td id=\"T_5c70c_row6_col10\" class=\"data row6 col10\" >9.93</td>\n",
       "      <td id=\"T_5c70c_row6_col11\" class=\"data row6 col11\" >44.36</td>\n",
       "      <td id=\"T_5c70c_row6_col12\" class=\"data row6 col12\" >1.83</td>\n",
       "      <td id=\"T_5c70c_row6_col13\" class=\"data row6 col13\" >25.96</td>\n",
       "      <td id=\"T_5c70c_row6_col14\" class=\"data row6 col14\" >-12.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_5c70c_row7_col0\" class=\"data row7 col0\" >199998</td>\n",
       "      <td id=\"T_5c70c_row7_col1\" class=\"data row7 col1\" >llama-7b_all:200k_mix=cot:75328,dolly:17492,flan_v2:79481,oasst1:27697</td>\n",
       "      <td id=\"T_5c70c_row7_col2\" class=\"data row7 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row7_col3\" class=\"data row7 col3\" >{'cot': 75328, 'dolly': 17492, 'flan_v2': 79481, 'oasst1': 27697}</td>\n",
       "      <td id=\"T_5c70c_row7_col4\" class=\"data row7 col4\" >40.40</td>\n",
       "      <td id=\"T_5c70c_row7_col5\" class=\"data row7 col5\" >41.05</td>\n",
       "      <td id=\"T_5c70c_row7_col6\" class=\"data row7 col6\" >5.00</td>\n",
       "      <td id=\"T_5c70c_row7_col7\" class=\"data row7 col7\" >22.00</td>\n",
       "      <td id=\"T_5c70c_row7_col8\" class=\"data row7 col8\" >35.95</td>\n",
       "      <td id=\"T_5c70c_row7_col9\" class=\"data row7 col9\" >31.85</td>\n",
       "      <td id=\"T_5c70c_row7_col10\" class=\"data row7 col10\" >10.58</td>\n",
       "      <td id=\"T_5c70c_row7_col11\" class=\"data row7 col11\" >43.58</td>\n",
       "      <td id=\"T_5c70c_row7_col12\" class=\"data row7 col12\" >0.00</td>\n",
       "      <td id=\"T_5c70c_row7_col13\" class=\"data row7 col13\" >25.60</td>\n",
       "      <td id=\"T_5c70c_row7_col14\" class=\"data row7 col14\" >-15.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_5c70c_row8_col0\" class=\"data row8 col0\" >199998</td>\n",
       "      <td id=\"T_5c70c_row8_col1\" class=\"data row8 col1\" >llama-7b_all:200k_mix=cot:44759,dolly:61131,flan_v2:30915,oasst1:63193</td>\n",
       "      <td id=\"T_5c70c_row8_col2\" class=\"data row8 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row8_col3\" class=\"data row8 col3\" >{'cot': 44759, 'dolly': 61131, 'flan_v2': 30915, 'oasst1': 63193}</td>\n",
       "      <td id=\"T_5c70c_row8_col4\" class=\"data row8 col4\" >38.41</td>\n",
       "      <td id=\"T_5c70c_row8_col5\" class=\"data row8 col5\" >38.54</td>\n",
       "      <td id=\"T_5c70c_row8_col6\" class=\"data row8 col6\" >5.50</td>\n",
       "      <td id=\"T_5c70c_row8_col7\" class=\"data row8 col7\" >22.50</td>\n",
       "      <td id=\"T_5c70c_row8_col8\" class=\"data row8 col8\" >34.56</td>\n",
       "      <td id=\"T_5c70c_row8_col9\" class=\"data row8 col9\" >31.76</td>\n",
       "      <td id=\"T_5c70c_row8_col10\" class=\"data row8 col10\" >10.89</td>\n",
       "      <td id=\"T_5c70c_row8_col11\" class=\"data row8 col11\" >46.57</td>\n",
       "      <td id=\"T_5c70c_row8_col12\" class=\"data row8 col12\" >1.22</td>\n",
       "      <td id=\"T_5c70c_row8_col13\" class=\"data row8 col13\" >25.55</td>\n",
       "      <td id=\"T_5c70c_row8_col14\" class=\"data row8 col14\" >-13.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_5c70c_row9_col0\" class=\"data row9 col0\" >199998</td>\n",
       "      <td id=\"T_5c70c_row9_col1\" class=\"data row9 col1\" >llama-7b_all:200k_mix=cot:27136,dolly:11929,flan_v2:79155,oasst1:81778</td>\n",
       "      <td id=\"T_5c70c_row9_col2\" class=\"data row9 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row9_col3\" class=\"data row9 col3\" >{'cot': 27136, 'dolly': 11929, 'flan_v2': 79155, 'oasst1': 81778}</td>\n",
       "      <td id=\"T_5c70c_row9_col4\" class=\"data row9 col4\" >42.47</td>\n",
       "      <td id=\"T_5c70c_row9_col5\" class=\"data row9 col5\" >42.51</td>\n",
       "      <td id=\"T_5c70c_row9_col6\" class=\"data row9 col6\" >4.00</td>\n",
       "      <td id=\"T_5c70c_row9_col7\" class=\"data row9 col7\" >15.50</td>\n",
       "      <td id=\"T_5c70c_row9_col8\" class=\"data row9 col8\" >35.85</td>\n",
       "      <td id=\"T_5c70c_row9_col9\" class=\"data row9 col9\" >33.70</td>\n",
       "      <td id=\"T_5c70c_row9_col10\" class=\"data row9 col10\" >10.26</td>\n",
       "      <td id=\"T_5c70c_row9_col11\" class=\"data row9 col11\" >44.08</td>\n",
       "      <td id=\"T_5c70c_row9_col12\" class=\"data row9 col12\" >0.00</td>\n",
       "      <td id=\"T_5c70c_row9_col13\" class=\"data row9 col13\" >25.38</td>\n",
       "      <td id=\"T_5c70c_row9_col14\" class=\"data row9 col14\" >-15.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_5c70c_row10_col0\" class=\"data row10 col0\" >199998</td>\n",
       "      <td id=\"T_5c70c_row10_col1\" class=\"data row10 col1\" >llama-7b_all:200k_mix=cot:36468,dolly:32706,flan_v2:65412,oasst1:65412</td>\n",
       "      <td id=\"T_5c70c_row10_col2\" class=\"data row10 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row10_col3\" class=\"data row10 col3\" >{'cot': 36468, 'dolly': 32706, 'flan_v2': 65412, 'oasst1': 65412}</td>\n",
       "      <td id=\"T_5c70c_row10_col4\" class=\"data row10 col4\" >40.14</td>\n",
       "      <td id=\"T_5c70c_row10_col5\" class=\"data row10 col5\" >41.60</td>\n",
       "      <td id=\"T_5c70c_row10_col6\" class=\"data row10 col6\" >5.00</td>\n",
       "      <td id=\"T_5c70c_row10_col7\" class=\"data row10 col7\" >21.00</td>\n",
       "      <td id=\"T_5c70c_row10_col8\" class=\"data row10 col8\" >34.68</td>\n",
       "      <td id=\"T_5c70c_row10_col9\" class=\"data row10 col9\" >33.24</td>\n",
       "      <td id=\"T_5c70c_row10_col10\" class=\"data row10 col10\" >8.03</td>\n",
       "      <td id=\"T_5c70c_row10_col11\" class=\"data row10 col11\" >44.31</td>\n",
       "      <td id=\"T_5c70c_row10_col12\" class=\"data row10 col12\" >0.00</td>\n",
       "      <td id=\"T_5c70c_row10_col13\" class=\"data row10 col13\" >25.33</td>\n",
       "      <td id=\"T_5c70c_row10_col14\" class=\"data row10 col14\" >-17.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_5c70c_row11_col0\" class=\"data row11 col0\" >199999</td>\n",
       "      <td id=\"T_5c70c_row11_col1\" class=\"data row11 col1\" >llama-7b_all:200k_mix=cot:22489,dolly:43994,flan_v2:116533,oasst1:16983</td>\n",
       "      <td id=\"T_5c70c_row11_col2\" class=\"data row11 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row11_col3\" class=\"data row11 col3\" >{'cot': 22489, 'dolly': 43994, 'flan_v2': 116533, 'oasst1': 16983}</td>\n",
       "      <td id=\"T_5c70c_row11_col4\" class=\"data row11 col4\" >43.26</td>\n",
       "      <td id=\"T_5c70c_row11_col5\" class=\"data row11 col5\" >45.15</td>\n",
       "      <td id=\"T_5c70c_row11_col6\" class=\"data row11 col6\" >4.50</td>\n",
       "      <td id=\"T_5c70c_row11_col7\" class=\"data row11 col7\" >15.00</td>\n",
       "      <td id=\"T_5c70c_row11_col8\" class=\"data row11 col8\" >36.49</td>\n",
       "      <td id=\"T_5c70c_row11_col9\" class=\"data row11 col9\" >31.39</td>\n",
       "      <td id=\"T_5c70c_row11_col10\" class=\"data row11 col10\" >9.69</td>\n",
       "      <td id=\"T_5c70c_row11_col11\" class=\"data row11 col11\" >38.65</td>\n",
       "      <td id=\"T_5c70c_row11_col12\" class=\"data row11 col12\" >3.05</td>\n",
       "      <td id=\"T_5c70c_row11_col13\" class=\"data row11 col13\" >25.24</td>\n",
       "      <td id=\"T_5c70c_row11_col14\" class=\"data row11 col14\" >-14.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_5c70c_row12_col0\" class=\"data row12 col0\" >211155</td>\n",
       "      <td id=\"T_5c70c_row12_col1\" class=\"data row12 col1\" >llama-7b_all:200k_mix=cot:6323,dolly:40966,flan_v2:81933,oasst1:81933</td>\n",
       "      <td id=\"T_5c70c_row12_col2\" class=\"data row12 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row12_col3\" class=\"data row12 col3\" >{'cot': 6323, 'dolly': 40966, 'flan_v2': 81933, 'oasst1': 81933}</td>\n",
       "      <td id=\"T_5c70c_row12_col4\" class=\"data row12 col4\" >40.04</td>\n",
       "      <td id=\"T_5c70c_row12_col5\" class=\"data row12 col5\" >41.90</td>\n",
       "      <td id=\"T_5c70c_row12_col6\" class=\"data row12 col6\" >7.50</td>\n",
       "      <td id=\"T_5c70c_row12_col7\" class=\"data row12 col7\" >18.50</td>\n",
       "      <td id=\"T_5c70c_row12_col8\" class=\"data row12 col8\" >35.28</td>\n",
       "      <td id=\"T_5c70c_row12_col9\" class=\"data row12 col9\" >30.28</td>\n",
       "      <td id=\"T_5c70c_row12_col10\" class=\"data row12 col10\" >10.26</td>\n",
       "      <td id=\"T_5c70c_row12_col11\" class=\"data row12 col11\" >41.28</td>\n",
       "      <td id=\"T_5c70c_row12_col12\" class=\"data row12 col12\" >0.00</td>\n",
       "      <td id=\"T_5c70c_row12_col13\" class=\"data row12 col13\" >25.00</td>\n",
       "      <td id=\"T_5c70c_row12_col14\" class=\"data row12 col14\" >-17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_5c70c_row13_col0\" class=\"data row13 col0\" >197365</td>\n",
       "      <td id=\"T_5c70c_row13_col1\" class=\"data row13 col1\" >llama-7b_all:200k_mix=cot:17126,dolly:108593,flan_v2:69580,oasst1:2066</td>\n",
       "      <td id=\"T_5c70c_row13_col2\" class=\"data row13 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row13_col3\" class=\"data row13 col3\" >{'cot': 17126, 'dolly': 108593, 'flan_v2': 69580, 'oasst1': 2066}</td>\n",
       "      <td id=\"T_5c70c_row13_col4\" class=\"data row13 col4\" >41.63</td>\n",
       "      <td id=\"T_5c70c_row13_col5\" class=\"data row13 col5\" >43.04</td>\n",
       "      <td id=\"T_5c70c_row13_col6\" class=\"data row13 col6\" >7.00</td>\n",
       "      <td id=\"T_5c70c_row13_col7\" class=\"data row13 col7\" >14.00</td>\n",
       "      <td id=\"T_5c70c_row13_col8\" class=\"data row13 col8\" >35.02</td>\n",
       "      <td id=\"T_5c70c_row13_col9\" class=\"data row13 col9\" >31.02</td>\n",
       "      <td id=\"T_5c70c_row13_col10\" class=\"data row13 col10\" >10.12</td>\n",
       "      <td id=\"T_5c70c_row13_col11\" class=\"data row13 col11\" >42.12</td>\n",
       "      <td id=\"T_5c70c_row13_col12\" class=\"data row13 col12\" >0.00</td>\n",
       "      <td id=\"T_5c70c_row13_col13\" class=\"data row13 col13\" >24.88</td>\n",
       "      <td id=\"T_5c70c_row13_col14\" class=\"data row13 col14\" >-17.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_5c70c_row14_col0\" class=\"data row14 col0\" >199998</td>\n",
       "      <td id=\"T_5c70c_row14_col1\" class=\"data row14 col1\" >llama-7b_all:200k_mix=cot:16131,dolly:83772,flan_v2:43447,oasst1:56648</td>\n",
       "      <td id=\"T_5c70c_row14_col2\" class=\"data row14 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row14_col3\" class=\"data row14 col3\" >{'cot': 16131, 'dolly': 83772, 'flan_v2': 43447, 'oasst1': 56648}</td>\n",
       "      <td id=\"T_5c70c_row14_col4\" class=\"data row14 col4\" >39.20</td>\n",
       "      <td id=\"T_5c70c_row14_col5\" class=\"data row14 col5\" >37.97</td>\n",
       "      <td id=\"T_5c70c_row14_col6\" class=\"data row14 col6\" >5.00</td>\n",
       "      <td id=\"T_5c70c_row14_col7\" class=\"data row14 col7\" >17.00</td>\n",
       "      <td id=\"T_5c70c_row14_col8\" class=\"data row14 col8\" >34.47</td>\n",
       "      <td id=\"T_5c70c_row14_col9\" class=\"data row14 col9\" >32.41</td>\n",
       "      <td id=\"T_5c70c_row14_col10\" class=\"data row14 col10\" >10.52</td>\n",
       "      <td id=\"T_5c70c_row14_col11\" class=\"data row14 col11\" >44.30</td>\n",
       "      <td id=\"T_5c70c_row14_col12\" class=\"data row14 col12\" >0.00</td>\n",
       "      <td id=\"T_5c70c_row14_col13\" class=\"data row14 col13\" >24.54</td>\n",
       "      <td id=\"T_5c70c_row14_col14\" class=\"data row14 col14\" >-18.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_5c70c_row15_col0\" class=\"data row15 col0\" >200000</td>\n",
       "      <td id=\"T_5c70c_row15_col1\" class=\"data row15 col1\" >llama-7b_all:200k_mix=cot:50000,dolly:50000,flan_v2:50000,oasst1:50000</td>\n",
       "      <td id=\"T_5c70c_row15_col2\" class=\"data row15 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row15_col3\" class=\"data row15 col3\" >{'cot': 50000, 'dolly': 50000, 'flan_v2': 50000, 'oasst1': 50000}</td>\n",
       "      <td id=\"T_5c70c_row15_col4\" class=\"data row15 col4\" >34.08</td>\n",
       "      <td id=\"T_5c70c_row15_col5\" class=\"data row15 col5\" >38.88</td>\n",
       "      <td id=\"T_5c70c_row15_col6\" class=\"data row15 col6\" >5.00</td>\n",
       "      <td id=\"T_5c70c_row15_col7\" class=\"data row15 col7\" >19.50</td>\n",
       "      <td id=\"T_5c70c_row15_col8\" class=\"data row15 col8\" >33.96</td>\n",
       "      <td id=\"T_5c70c_row15_col9\" class=\"data row15 col9\" >33.15</td>\n",
       "      <td id=\"T_5c70c_row15_col10\" class=\"data row15 col10\" >10.00</td>\n",
       "      <td id=\"T_5c70c_row15_col11\" class=\"data row15 col11\" >42.19</td>\n",
       "      <td id=\"T_5c70c_row15_col12\" class=\"data row15 col12\" >1.22</td>\n",
       "      <td id=\"T_5c70c_row15_col13\" class=\"data row15 col13\" >24.22</td>\n",
       "      <td id=\"T_5c70c_row15_col14\" class=\"data row15 col14\" >-17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_5c70c_row16_col0\" class=\"data row16 col0\" >199998</td>\n",
       "      <td id=\"T_5c70c_row16_col1\" class=\"data row16 col1\" >llama-7b_all:200k_mix=cot:49222,dolly:19548,flan_v2:27948,oasst1:103280</td>\n",
       "      <td id=\"T_5c70c_row16_col2\" class=\"data row16 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row16_col3\" class=\"data row16 col3\" >{'cot': 49222, 'dolly': 19548, 'flan_v2': 27948, 'oasst1': 103280}</td>\n",
       "      <td id=\"T_5c70c_row16_col4\" class=\"data row16 col4\" >31.76</td>\n",
       "      <td id=\"T_5c70c_row16_col5\" class=\"data row16 col5\" >33.81</td>\n",
       "      <td id=\"T_5c70c_row16_col6\" class=\"data row16 col6\" >5.00</td>\n",
       "      <td id=\"T_5c70c_row16_col7\" class=\"data row16 col7\" >23.00</td>\n",
       "      <td id=\"T_5c70c_row16_col8\" class=\"data row16 col8\" >34.89</td>\n",
       "      <td id=\"T_5c70c_row16_col9\" class=\"data row16 col9\" >30.00</td>\n",
       "      <td id=\"T_5c70c_row16_col10\" class=\"data row16 col10\" >9.08</td>\n",
       "      <td id=\"T_5c70c_row16_col11\" class=\"data row16 col11\" >40.84</td>\n",
       "      <td id=\"T_5c70c_row16_col12\" class=\"data row16 col12\" >0.00</td>\n",
       "      <td id=\"T_5c70c_row16_col13\" class=\"data row16 col13\" >23.15</td>\n",
       "      <td id=\"T_5c70c_row16_col14\" class=\"data row16 col14\" >-22.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_5c70c_row17_col0\" class=\"data row17 col0\" >199999</td>\n",
       "      <td id=\"T_5c70c_row17_col1\" class=\"data row17 col1\" >llama-7b_all:200k_mix=cot:55409,dolly:114245,flan_v2:4988,oasst1:25357</td>\n",
       "      <td id=\"T_5c70c_row17_col2\" class=\"data row17 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row17_col3\" class=\"data row17 col3\" >{'cot': 55409, 'dolly': 114245, 'flan_v2': 4988, 'oasst1': 25357}</td>\n",
       "      <td id=\"T_5c70c_row17_col4\" class=\"data row17 col4\" >28.36</td>\n",
       "      <td id=\"T_5c70c_row17_col5\" class=\"data row17 col5\" >28.65</td>\n",
       "      <td id=\"T_5c70c_row17_col6\" class=\"data row17 col6\" >6.00</td>\n",
       "      <td id=\"T_5c70c_row17_col7\" class=\"data row17 col7\" >19.50</td>\n",
       "      <td id=\"T_5c70c_row17_col8\" class=\"data row17 col8\" >35.04</td>\n",
       "      <td id=\"T_5c70c_row17_col9\" class=\"data row17 col9\" >32.50</td>\n",
       "      <td id=\"T_5c70c_row17_col10\" class=\"data row17 col10\" >10.70</td>\n",
       "      <td id=\"T_5c70c_row17_col11\" class=\"data row17 col11\" >40.50</td>\n",
       "      <td id=\"T_5c70c_row17_col12\" class=\"data row17 col12\" >0.00</td>\n",
       "      <td id=\"T_5c70c_row17_col13\" class=\"data row17 col13\" >22.36</td>\n",
       "      <td id=\"T_5c70c_row17_col14\" class=\"data row17 col14\" >-18.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_5c70c_row18_col0\" class=\"data row18 col0\" >199998</td>\n",
       "      <td id=\"T_5c70c_row18_col1\" class=\"data row18 col1\" >llama-7b_all:200k_mix=cot:490,dolly:26549,flan_v2:2453,oasst1:170506</td>\n",
       "      <td id=\"T_5c70c_row18_col2\" class=\"data row18 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row18_col3\" class=\"data row18 col3\" >{'cot': 490, 'dolly': 26549, 'flan_v2': 2453, 'oasst1': 170506}</td>\n",
       "      <td id=\"T_5c70c_row18_col4\" class=\"data row18 col4\" >36.75</td>\n",
       "      <td id=\"T_5c70c_row18_col5\" class=\"data row18 col5\" >36.38</td>\n",
       "      <td id=\"T_5c70c_row18_col6\" class=\"data row18 col6\" >5.50</td>\n",
       "      <td id=\"T_5c70c_row18_col7\" class=\"data row18 col7\" >11.50</td>\n",
       "      <td id=\"T_5c70c_row18_col8\" class=\"data row18 col8\" >33.21</td>\n",
       "      <td id=\"T_5c70c_row18_col9\" class=\"data row18 col9\" >27.50</td>\n",
       "      <td id=\"T_5c70c_row18_col10\" class=\"data row18 col10\" >10.50</td>\n",
       "      <td id=\"T_5c70c_row18_col11\" class=\"data row18 col11\" >38.80</td>\n",
       "      <td id=\"T_5c70c_row18_col12\" class=\"data row18 col12\" >0.00</td>\n",
       "      <td id=\"T_5c70c_row18_col13\" class=\"data row18 col13\" >22.24</td>\n",
       "      <td id=\"T_5c70c_row18_col14\" class=\"data row18 col14\" >-23.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c70c_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_5c70c_row19_col0\" class=\"data row19 col0\" >200000</td>\n",
       "      <td id=\"T_5c70c_row19_col1\" class=\"data row19 col1\" >llama-7b</td>\n",
       "      <td id=\"T_5c70c_row19_col2\" class=\"data row19 col2\" >huggyllama/llama-7b</td>\n",
       "      <td id=\"T_5c70c_row19_col3\" class=\"data row19 col3\" >{}</td>\n",
       "      <td id=\"T_5c70c_row19_col4\" class=\"data row19 col4\" >32.46</td>\n",
       "      <td id=\"T_5c70c_row19_col5\" class=\"data row19 col5\" >33.06</td>\n",
       "      <td id=\"T_5c70c_row19_col6\" class=\"data row19 col6\" >5.50</td>\n",
       "      <td id=\"T_5c70c_row19_col7\" class=\"data row19 col7\" >11.00</td>\n",
       "      <td id=\"T_5c70c_row19_col8\" class=\"data row19 col8\" >32.97</td>\n",
       "      <td id=\"T_5c70c_row19_col9\" class=\"data row19 col9\" >28.43</td>\n",
       "      <td id=\"T_5c70c_row19_col10\" class=\"data row19 col10\" >10.35</td>\n",
       "      <td id=\"T_5c70c_row19_col11\" class=\"data row19 col11\" >38.56</td>\n",
       "      <td id=\"T_5c70c_row19_col12\" class=\"data row19 col12\" >0.00</td>\n",
       "      <td id=\"T_5c70c_row19_col13\" class=\"data row19 col13\" >21.37</td>\n",
       "      <td id=\"T_5c70c_row19_col14\" class=\"data row19 col14\" >-24.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fff7807af20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_88ce2_row0_col0, #T_88ce2_row0_col1, #T_88ce2_row0_col2, #T_88ce2_row0_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_88ce2_row0_col4, #T_88ce2_row0_col5, #T_88ce2_row0_col6, #T_88ce2_row0_col7, #T_88ce2_row0_col8, #T_88ce2_row0_col9, #T_88ce2_row0_col10, #T_88ce2_row0_col11, #T_88ce2_row0_col12, #T_88ce2_row0_col13, #T_88ce2_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_88ce2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_88ce2_level0_col0\" class=\"col_heading level0 col0\" >total_train_samples</th>\n",
       "      <th id=\"T_88ce2_level0_col1\" class=\"col_heading level0 col1\" >run_name</th>\n",
       "      <th id=\"T_88ce2_level0_col2\" class=\"col_heading level0 col2\" >model_args.model_name_or_path</th>\n",
       "      <th id=\"T_88ce2_level0_col3\" class=\"col_heading level0 col3\" >data_args.subsample_mixture</th>\n",
       "      <th id=\"T_88ce2_level0_col4\" class=\"col_heading level0 col4\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_88ce2_level0_col5\" class=\"col_heading level0 col5\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_88ce2_level0_col6\" class=\"col_heading level0 col6\" >GSM/Direct</th>\n",
       "      <th id=\"T_88ce2_level0_col7\" class=\"col_heading level0 col7\" >GSM/CoT</th>\n",
       "      <th id=\"T_88ce2_level0_col8\" class=\"col_heading level0 col8\" >BBH/Direct</th>\n",
       "      <th id=\"T_88ce2_level0_col9\" class=\"col_heading level0 col9\" >BBH/CoT</th>\n",
       "      <th id=\"T_88ce2_level0_col10\" class=\"col_heading level0 col10\" >TydiQA/CB</th>\n",
       "      <th id=\"T_88ce2_level0_col11\" class=\"col_heading level0 col11\" >TydiQA/GP</th>\n",
       "      <th id=\"T_88ce2_level0_col12\" class=\"col_heading level0 col12\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_88ce2_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_88ce2_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_88ce2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_88ce2_row0_col0\" class=\"data row0 col0\" >399998</td>\n",
       "      <td id=\"T_88ce2_row0_col1\" class=\"data row0 col1\" >llama-7b_all:400k_mix=cot:195140,dolly:2929,flan_v2:195140,oasst1:6789</td>\n",
       "      <td id=\"T_88ce2_row0_col2\" class=\"data row0 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_88ce2_row0_col3\" class=\"data row0 col3\" >{'cot': 195140, 'dolly': 2929, 'flan_v2': 195140, 'oasst1': 6789}</td>\n",
       "      <td id=\"T_88ce2_row0_col4\" class=\"data row0 col4\" >44.00</td>\n",
       "      <td id=\"T_88ce2_row0_col5\" class=\"data row0 col5\" >45.38</td>\n",
       "      <td id=\"T_88ce2_row0_col6\" class=\"data row0 col6\" >4.50</td>\n",
       "      <td id=\"T_88ce2_row0_col7\" class=\"data row0 col7\" >25.50</td>\n",
       "      <td id=\"T_88ce2_row0_col8\" class=\"data row0 col8\" >36.53</td>\n",
       "      <td id=\"T_88ce2_row0_col9\" class=\"data row0 col9\" >31.39</td>\n",
       "      <td id=\"T_88ce2_row0_col10\" class=\"data row0 col10\" >7.92</td>\n",
       "      <td id=\"T_88ce2_row0_col11\" class=\"data row0 col11\" >39.45</td>\n",
       "      <td id=\"T_88ce2_row0_col12\" class=\"data row0 col12\" >10.98</td>\n",
       "      <td id=\"T_88ce2_row0_col13\" class=\"data row0 col13\" >27.29</td>\n",
       "      <td id=\"T_88ce2_row0_col14\" class=\"data row0 col14\" >-11.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fff7807b2e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4eaa2_row0_col0, #T_4eaa2_row0_col1, #T_4eaa2_row0_col2, #T_4eaa2_row0_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4eaa2_row0_col4, #T_4eaa2_row0_col5, #T_4eaa2_row0_col6, #T_4eaa2_row0_col7, #T_4eaa2_row0_col8, #T_4eaa2_row0_col9, #T_4eaa2_row0_col10, #T_4eaa2_row0_col11, #T_4eaa2_row0_col12, #T_4eaa2_row0_col13, #T_4eaa2_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4eaa2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4eaa2_level0_col0\" class=\"col_heading level0 col0\" >total_train_samples</th>\n",
       "      <th id=\"T_4eaa2_level0_col1\" class=\"col_heading level0 col1\" >run_name</th>\n",
       "      <th id=\"T_4eaa2_level0_col2\" class=\"col_heading level0 col2\" >model_args.model_name_or_path</th>\n",
       "      <th id=\"T_4eaa2_level0_col3\" class=\"col_heading level0 col3\" >data_args.subsample_mixture</th>\n",
       "      <th id=\"T_4eaa2_level0_col4\" class=\"col_heading level0 col4\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_4eaa2_level0_col5\" class=\"col_heading level0 col5\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_4eaa2_level0_col6\" class=\"col_heading level0 col6\" >GSM/Direct</th>\n",
       "      <th id=\"T_4eaa2_level0_col7\" class=\"col_heading level0 col7\" >GSM/CoT</th>\n",
       "      <th id=\"T_4eaa2_level0_col8\" class=\"col_heading level0 col8\" >BBH/Direct</th>\n",
       "      <th id=\"T_4eaa2_level0_col9\" class=\"col_heading level0 col9\" >BBH/CoT</th>\n",
       "      <th id=\"T_4eaa2_level0_col10\" class=\"col_heading level0 col10\" >TydiQA/CB</th>\n",
       "      <th id=\"T_4eaa2_level0_col11\" class=\"col_heading level0 col11\" >TydiQA/GP</th>\n",
       "      <th id=\"T_4eaa2_level0_col12\" class=\"col_heading level0 col12\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_4eaa2_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_4eaa2_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4eaa2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4eaa2_row0_col0\" class=\"data row0 col0\" >599997</td>\n",
       "      <td id=\"T_4eaa2_row0_col1\" class=\"data row0 col1\" >llama-7b_all:600k_mix=cot:292710,dolly:4393,flan_v2:292710,oasst1:10184</td>\n",
       "      <td id=\"T_4eaa2_row0_col2\" class=\"data row0 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_4eaa2_row0_col3\" class=\"data row0 col3\" >{'cot': 292710, 'dolly': 4393, 'flan_v2': 292710, 'oasst1': 10184}</td>\n",
       "      <td id=\"T_4eaa2_row0_col4\" class=\"data row0 col4\" >41.35</td>\n",
       "      <td id=\"T_4eaa2_row0_col5\" class=\"data row0 col5\" >44.34</td>\n",
       "      <td id=\"T_4eaa2_row0_col6\" class=\"data row0 col6\" >7.00</td>\n",
       "      <td id=\"T_4eaa2_row0_col7\" class=\"data row0 col7\" >25.00</td>\n",
       "      <td id=\"T_4eaa2_row0_col8\" class=\"data row0 col8\" >36.35</td>\n",
       "      <td id=\"T_4eaa2_row0_col9\" class=\"data row0 col9\" >35.00</td>\n",
       "      <td id=\"T_4eaa2_row0_col10\" class=\"data row0 col10\" >9.06</td>\n",
       "      <td id=\"T_4eaa2_row0_col11\" class=\"data row0 col11\" >40.96</td>\n",
       "      <td id=\"T_4eaa2_row0_col12\" class=\"data row0 col12\" >9.76</td>\n",
       "      <td id=\"T_4eaa2_row0_col13\" class=\"data row0 col13\" >27.65</td>\n",
       "      <td id=\"T_4eaa2_row0_col14\" class=\"data row0 col14\" >-7.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fff7807b1c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_sort_rows_by_avg_ranking\n",
    "from llm.evaluate import EvalResults, get_eval_results\n",
    "\n",
    "\n",
    "exp_dir = ''\n",
    "chat_fmt = None\n",
    "sort_rows = True\n",
    "\n",
    "## baselines\n",
    "# save_dirs = []\n",
    "# save_dirs += [\n",
    "# #     ('gpt2', '../results/baselines/gpt2'),\n",
    "# #     ('gpt2m', '../results/baselines/gpt2-medium'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('llama2-7b+humanmix', '../results/llama2-7b_humanmix'),\n",
    "#     ('pythia-1.4b', '../results/baselines/EleutherAI/pythia-1.4b'),\n",
    "#     ('pythia-2.8b', '../results/baselines/EleutherAI/pythia-2.8b'),\n",
    "#     ('pythia-6.9b', '../results/baselines/EleutherAI/pythia-6.9b'),\n",
    "#     ('dolly-v2-7b', '../results/baselines/databricks/dolly-v2-7b'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "exp_dir = '../results/ft2'\n",
    "save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "             ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'), # 2 epochs\n",
    "            ]\n",
    "save_dirs += [(os.path.basename(x), x) for x in \n",
    "              [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:200k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "\n",
    "# exp_dir = '../results/ft2'\n",
    "# save_dirs = []\n",
    "\n",
    "# run_dirs = [\n",
    "#     'pythia-1.4b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "#     'pythia-2.8b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "#     'pythia-6.9b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "# ]\n",
    "# for run_dir in run_dirs:\n",
    "#     save_dirs += [(os.path.basename(x), x) \n",
    "#                   for x in glob.glob(os.path.join(exp_dir, run_dir, 'checkpoint-*'))]\n",
    "\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:200k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "\n",
    "# # check mmlu chat_format_version\n",
    "# exp_dir = ''\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b-huamnmix', '../results/ft1/llama-7b_humanmix'),\n",
    "# ]\n",
    "\n",
    "# save_dirs = [x for x in save_dirs if 'replace' not in x[1]]\n",
    "\n",
    "ft_args_fields = [\n",
    "    'run_name',\n",
    "    'model_args.model_name_or_path',\n",
    "    'data_args.subsample_mixture'\n",
    "]\n",
    "\n",
    "\n",
    "if exp_dir.endswith('ft2'):\n",
    "    print('chat_fmt=True')\n",
    "    df = get_eval_results(save_dirs, chat_fmt=True, ft_args_fields=ft_args_fields)\n",
    "#     df = get_eval_results(save_dirs, chat_fmt='both', ft_args_fields=ft_args_fields)\n",
    "    cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP']\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "    df = df[ft_args_fields + cols]\n",
    "    df['Average'] = df[cols].mean(axis=1)\n",
    "    if sort_rows:\n",
    "        df = pd_sort_rows_by_avg_ranking(df); df['ranking'] = -df['ranking']\n",
    "        sort_value_col, sort_value_col_ascending = 'Average', False\n",
    "    #     sort_value_col, sort_value_col_ascending = 'ranking', False\n",
    "        df = df.sort_values(sort_value_col, ascending=sort_value_col_ascending)\n",
    "    df = df.reset_index(drop=True)\n",
    "else:\n",
    "    df = get_eval_results(save_dirs, chat_fmt='both', ft_args_fields=ft_args_fields)\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "    df = df[ft_args_fields+cols]\n",
    "    \n",
    "\n",
    "if exp_dir.endswith('ft2'):\n",
    "#     for model_name_contain in ['gpt2', 'llama', 'pythia-1.4b']:\n",
    "#         for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "    for model_name_contain in ['pythia-1.4b', 'llama']:\n",
    "        for total_train_samples in [200000, 400000, 600000]:\n",
    "            dfc = df.copy()\n",
    "            dfc.insert(0, 'total_train_samples',  dfc['data_args.subsample_mixture'].apply(\n",
    "                lambda d: sum(list(d.values())) if d else 200000))\n",
    "            dfc = dfc[dfc['total_train_samples'].apply(\n",
    "                lambda x: total_train_samples-20000<x<total_train_samples+20000)]\n",
    "            dfc = dfc[dfc['model_args.model_name_or_path'].apply(\n",
    "                lambda x: model_name_contain in x)]\n",
    "            dfc['total_train_samples'] = dfc['total_train_samples'].astype(str)\n",
    "            dfc = dfc.reset_index(drop=True)\n",
    "            if len(dfc):\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .format(precision=2))\n",
    "    \n",
    "else:\n",
    "    for model_name_contain in ['llama', 'pythia-1.4b']:\n",
    "        dfc = df.copy()\n",
    "        dfc = dfc[dfc['model_args.model_name_or_path'].apply(\n",
    "            lambda x: model_name_contain in x)]\n",
    "        dfc = dfc.reset_index(drop=True)\n",
    "        if len(dfc):\n",
    "            display(dfc\n",
    "                    .style\n",
    "                    .set_properties(**{'text-align': 'left'})\n",
    "                    .background_gradient(cmap ='coolwarm')\n",
    "                    .format(precision=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c65992",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b5121_row0_col0, #T_b5121_row3_col0, #T_b5121_row4_col0, #T_b5121_row5_col0, #T_b5121_row7_col0, #T_b5121_row8_col0, #T_b5121_row9_col0, #T_b5121_row11_col0, #T_b5121_row12_col0, #T_b5121_row14_col0, #T_b5121_row15_col0, #T_b5121_row16_col0, #T_b5121_row19_col0, #T_b5121_row20_col0, #T_b5121_row22_col0, #T_b5121_row23_col0, #T_b5121_row24_col0, #T_b5121_row25_col0 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row0_col1, #T_b5121_row0_col2, #T_b5121_row0_col3, #T_b5121_row1_col1, #T_b5121_row1_col2, #T_b5121_row1_col3, #T_b5121_row2_col1, #T_b5121_row2_col2, #T_b5121_row2_col3, #T_b5121_row3_col1, #T_b5121_row3_col2, #T_b5121_row3_col3, #T_b5121_row4_col1, #T_b5121_row4_col2, #T_b5121_row4_col3, #T_b5121_row5_col1, #T_b5121_row5_col2, #T_b5121_row5_col3, #T_b5121_row6_col1, #T_b5121_row6_col2, #T_b5121_row6_col3, #T_b5121_row7_col1, #T_b5121_row7_col2, #T_b5121_row7_col3, #T_b5121_row8_col1, #T_b5121_row8_col2, #T_b5121_row8_col3, #T_b5121_row9_col1, #T_b5121_row9_col2, #T_b5121_row9_col3, #T_b5121_row10_col1, #T_b5121_row10_col2, #T_b5121_row10_col3, #T_b5121_row11_col1, #T_b5121_row11_col2, #T_b5121_row11_col3, #T_b5121_row12_col1, #T_b5121_row12_col2, #T_b5121_row12_col3, #T_b5121_row13_col1, #T_b5121_row13_col2, #T_b5121_row13_col3, #T_b5121_row14_col1, #T_b5121_row14_col2, #T_b5121_row14_col3, #T_b5121_row15_col1, #T_b5121_row15_col2, #T_b5121_row15_col3, #T_b5121_row16_col1, #T_b5121_row16_col2, #T_b5121_row16_col3, #T_b5121_row17_col1, #T_b5121_row17_col2, #T_b5121_row17_col3, #T_b5121_row18_col1, #T_b5121_row18_col2, #T_b5121_row18_col3, #T_b5121_row19_col1, #T_b5121_row19_col2, #T_b5121_row19_col3, #T_b5121_row20_col1, #T_b5121_row20_col2, #T_b5121_row20_col3, #T_b5121_row21_col1, #T_b5121_row21_col2, #T_b5121_row21_col3, #T_b5121_row22_col1, #T_b5121_row22_col2, #T_b5121_row22_col3, #T_b5121_row23_col1, #T_b5121_row23_col2, #T_b5121_row23_col3, #T_b5121_row24_col1, #T_b5121_row24_col2, #T_b5121_row24_col3, #T_b5121_row25_col1, #T_b5121_row25_col2, #T_b5121_row25_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b5121_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row0_col6, #T_b5121_row10_col6, #T_b5121_row11_col11, #T_b5121_row13_col6, #T_b5121_row21_col6, #T_b5121_row23_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row0_col7, #T_b5121_row0_col13, #T_b5121_row0_col14, #T_b5121_row1_col0, #T_b5121_row1_col9, #T_b5121_row2_col12, #T_b5121_row8_col8, #T_b5121_row9_col4, #T_b5121_row9_col5, #T_b5121_row10_col10, #T_b5121_row12_col11, #T_b5121_row17_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row0_col8, #T_b5121_row3_col7, #T_b5121_row12_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row0_col10, #T_b5121_row8_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row0_col11, #T_b5121_row6_col10, #T_b5121_row8_col13, #T_b5121_row24_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #c83836;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row1_col6, #T_b5121_row3_col4, #T_b5121_row3_col6, #T_b5121_row7_col9, #T_b5121_row18_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row1_col7, #T_b5121_row2_col13, #T_b5121_row4_col7, #T_b5121_row16_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row1_col11, #T_b5121_row19_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row1_col13, #T_b5121_row8_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row1_col14, #T_b5121_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row2_col0 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row2_col4, #T_b5121_row5_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row2_col6, #T_b5121_row8_col6, #T_b5121_row16_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row2_col7, #T_b5121_row6_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row2_col9, #T_b5121_row4_col11, #T_b5121_row16_col9, #T_b5121_row16_col13, #T_b5121_row24_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row2_col10, #T_b5121_row6_col0, #T_b5121_row9_col6, #T_b5121_row10_col0, #T_b5121_row10_col7, #T_b5121_row11_col12, #T_b5121_row14_col12, #T_b5121_row15_col12, #T_b5121_row17_col12, #T_b5121_row18_col12, #T_b5121_row19_col12, #T_b5121_row21_col0, #T_b5121_row22_col12, #T_b5121_row23_col4, #T_b5121_row23_col5, #T_b5121_row23_col12, #T_b5121_row24_col9, #T_b5121_row24_col12, #T_b5121_row25_col8, #T_b5121_row25_col11, #T_b5121_row25_col12, #T_b5121_row25_col13, #T_b5121_row25_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row2_col11, #T_b5121_row12_col12, #T_b5121_row20_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row2_col14, #T_b5121_row22_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row3_col8, #T_b5121_row4_col12, #T_b5121_row16_col12, #T_b5121_row22_col5, #T_b5121_row22_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row3_col9, #T_b5121_row4_col9, #T_b5121_row14_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row3_col11, #T_b5121_row15_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row3_col12, #T_b5121_row9_col13, #T_b5121_row10_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row3_col13, #T_b5121_row3_col14, #T_b5121_row5_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row4_col5, #T_b5121_row8_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row4_col6, #T_b5121_row7_col6, #T_b5121_row12_col6, #T_b5121_row24_col6, #T_b5121_row25_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row4_col8, #T_b5121_row18_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row4_col10, #T_b5121_row8_col7, #T_b5121_row20_col7, #T_b5121_row23_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row4_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row4_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row5_col6, #T_b5121_row11_col6, #T_b5121_row15_col6, #T_b5121_row19_col6, #T_b5121_row20_col6, #T_b5121_row22_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row5_col7, #T_b5121_row13_col7, #T_b5121_row17_col9, #T_b5121_row19_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row5_col8, #T_b5121_row5_col13, #T_b5121_row10_col9, #T_b5121_row15_col11, #T_b5121_row19_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row5_col9, #T_b5121_row21_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row5_col10, #T_b5121_row14_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row5_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row6_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row6_col6, #T_b5121_row14_col5, #T_b5121_row20_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row6_col7, #T_b5121_row10_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row6_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row6_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row6_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row6_col12, #T_b5121_row22_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row6_col13, #T_b5121_row7_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row6_col14, #T_b5121_row11_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row7_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row7_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row7_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row7_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row7_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row7_col11, #T_b5121_row9_col7, #T_b5121_row18_col7, #T_b5121_row22_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row7_col12, #T_b5121_row17_col0, #T_b5121_row20_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row7_col13, #T_b5121_row13_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row8_col9, #T_b5121_row12_col4, #T_b5121_row19_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row8_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row8_col11, #T_b5121_row9_col11, #T_b5121_row13_col5, #T_b5121_row15_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row8_col12, #T_b5121_row13_col12, #T_b5121_row21_col12, #T_b5121_row24_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row9_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row9_col9, #T_b5121_row20_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row9_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row9_col12, #T_b5121_row13_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row9_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f2c9b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row10_col4, #T_b5121_row15_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row10_col5, #T_b5121_row18_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row10_col8, #T_b5121_row18_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row10_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row10_col12, #T_b5121_row19_col4, #T_b5121_row23_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row11_col5, #T_b5121_row11_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row11_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row11_col9, #T_b5121_row15_col7, #T_b5121_row25_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row11_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row11_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row11_col14, #T_b5121_row18_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row12_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row12_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row12_col8, #T_b5121_row18_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row12_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row12_col13, #T_b5121_row17_col10, #T_b5121_row20_col5, #T_b5121_row21_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row12_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row13_col0 {\n",
       "  text-align: left;\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row13_col4, #T_b5121_row14_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row13_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row13_col13, #T_b5121_row13_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row14_col6, #T_b5121_row25_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row14_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row14_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row14_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row14_col14, #T_b5121_row22_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row15_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row15_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row15_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row16_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row16_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row16_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row16_col10, #T_b5121_row19_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row16_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row16_col14, #T_b5121_row17_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row17_col4, #T_b5121_row17_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row17_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row17_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row17_col11, #T_b5121_row19_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row17_col14, #T_b5121_row20_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row18_col0 {\n",
       "  text-align: left;\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row18_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row18_col9, #T_b5121_row18_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row19_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row19_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row20_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row20_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row20_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row21_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row21_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row21_col7, #T_b5121_row21_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row21_col8, #T_b5121_row22_col14, #T_b5121_row24_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row21_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row21_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row22_col11, #T_b5121_row23_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row22_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row23_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row23_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row23_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row23_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row24_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row24_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row24_col8, #T_b5121_row25_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row24_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5121_row25_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5121_row25_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b5121\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b5121_level0_col0\" class=\"col_heading level0 col0\" >total_train_samples</th>\n",
       "      <th id=\"T_b5121_level0_col1\" class=\"col_heading level0 col1\" >run_name</th>\n",
       "      <th id=\"T_b5121_level0_col2\" class=\"col_heading level0 col2\" >model_args.model_name_or_path</th>\n",
       "      <th id=\"T_b5121_level0_col3\" class=\"col_heading level0 col3\" >data_args.subsample_mixture</th>\n",
       "      <th id=\"T_b5121_level0_col4\" class=\"col_heading level0 col4\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_b5121_level0_col5\" class=\"col_heading level0 col5\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_b5121_level0_col6\" class=\"col_heading level0 col6\" >GSM/Direct</th>\n",
       "      <th id=\"T_b5121_level0_col7\" class=\"col_heading level0 col7\" >GSM/CoT</th>\n",
       "      <th id=\"T_b5121_level0_col8\" class=\"col_heading level0 col8\" >BBH/Direct</th>\n",
       "      <th id=\"T_b5121_level0_col9\" class=\"col_heading level0 col9\" >BBH/CoT</th>\n",
       "      <th id=\"T_b5121_level0_col10\" class=\"col_heading level0 col10\" >TydiQA/CB</th>\n",
       "      <th id=\"T_b5121_level0_col11\" class=\"col_heading level0 col11\" >TydiQA/GP</th>\n",
       "      <th id=\"T_b5121_level0_col12\" class=\"col_heading level0 col12\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_b5121_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_b5121_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b5121_row0_col0\" class=\"data row0 col0\" >200000</td>\n",
       "      <td id=\"T_b5121_row0_col1\" class=\"data row0 col1\" >llama-7b_humanmix</td>\n",
       "      <td id=\"T_b5121_row0_col2\" class=\"data row0 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row0_col3\" class=\"data row0 col3\" >{}</td>\n",
       "      <td id=\"T_b5121_row0_col4\" class=\"data row0 col4\" >43.55</td>\n",
       "      <td id=\"T_b5121_row0_col5\" class=\"data row0 col5\" >46.46</td>\n",
       "      <td id=\"T_b5121_row0_col6\" class=\"data row0 col6\" >6.00</td>\n",
       "      <td id=\"T_b5121_row0_col7\" class=\"data row0 col7\" >29.00</td>\n",
       "      <td id=\"T_b5121_row0_col8\" class=\"data row0 col8\" >36.11</td>\n",
       "      <td id=\"T_b5121_row0_col9\" class=\"data row0 col9\" >34.35</td>\n",
       "      <td id=\"T_b5121_row0_col10\" class=\"data row0 col10\" >10.37</td>\n",
       "      <td id=\"T_b5121_row0_col11\" class=\"data row0 col11\" >43.48</td>\n",
       "      <td id=\"T_b5121_row0_col12\" class=\"data row0 col12\" >10.37</td>\n",
       "      <td id=\"T_b5121_row0_col13\" class=\"data row0 col13\" >28.85</td>\n",
       "      <td id=\"T_b5121_row0_col14\" class=\"data row0 col14\" >-4.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b5121_row1_col0\" class=\"data row1 col0\" >599997</td>\n",
       "      <td id=\"T_b5121_row1_col1\" class=\"data row1 col1\" >llama-7b_all:600k_mix=cot:292710,dolly:4393,flan_v2:292710,oasst1:10184</td>\n",
       "      <td id=\"T_b5121_row1_col2\" class=\"data row1 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row1_col3\" class=\"data row1 col3\" >{'cot': 292710, 'dolly': 4393, 'flan_v2': 292710, 'oasst1': 10184}</td>\n",
       "      <td id=\"T_b5121_row1_col4\" class=\"data row1 col4\" >41.35</td>\n",
       "      <td id=\"T_b5121_row1_col5\" class=\"data row1 col5\" >44.34</td>\n",
       "      <td id=\"T_b5121_row1_col6\" class=\"data row1 col6\" >7.00</td>\n",
       "      <td id=\"T_b5121_row1_col7\" class=\"data row1 col7\" >25.00</td>\n",
       "      <td id=\"T_b5121_row1_col8\" class=\"data row1 col8\" >36.35</td>\n",
       "      <td id=\"T_b5121_row1_col9\" class=\"data row1 col9\" >35.00</td>\n",
       "      <td id=\"T_b5121_row1_col10\" class=\"data row1 col10\" >9.06</td>\n",
       "      <td id=\"T_b5121_row1_col11\" class=\"data row1 col11\" >40.96</td>\n",
       "      <td id=\"T_b5121_row1_col12\" class=\"data row1 col12\" >9.76</td>\n",
       "      <td id=\"T_b5121_row1_col13\" class=\"data row1 col13\" >27.65</td>\n",
       "      <td id=\"T_b5121_row1_col14\" class=\"data row1 col14\" >-7.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b5121_row2_col0\" class=\"data row2 col0\" >399998</td>\n",
       "      <td id=\"T_b5121_row2_col1\" class=\"data row2 col1\" >llama-7b_all:400k_mix=cot:195140,dolly:2929,flan_v2:195140,oasst1:6789</td>\n",
       "      <td id=\"T_b5121_row2_col2\" class=\"data row2 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row2_col3\" class=\"data row2 col3\" >{'cot': 195140, 'dolly': 2929, 'flan_v2': 195140, 'oasst1': 6789}</td>\n",
       "      <td id=\"T_b5121_row2_col4\" class=\"data row2 col4\" >44.00</td>\n",
       "      <td id=\"T_b5121_row2_col5\" class=\"data row2 col5\" >45.38</td>\n",
       "      <td id=\"T_b5121_row2_col6\" class=\"data row2 col6\" >4.50</td>\n",
       "      <td id=\"T_b5121_row2_col7\" class=\"data row2 col7\" >25.50</td>\n",
       "      <td id=\"T_b5121_row2_col8\" class=\"data row2 col8\" >36.53</td>\n",
       "      <td id=\"T_b5121_row2_col9\" class=\"data row2 col9\" >31.39</td>\n",
       "      <td id=\"T_b5121_row2_col10\" class=\"data row2 col10\" >7.92</td>\n",
       "      <td id=\"T_b5121_row2_col11\" class=\"data row2 col11\" >39.45</td>\n",
       "      <td id=\"T_b5121_row2_col12\" class=\"data row2 col12\" >10.98</td>\n",
       "      <td id=\"T_b5121_row2_col13\" class=\"data row2 col13\" >27.29</td>\n",
       "      <td id=\"T_b5121_row2_col14\" class=\"data row2 col14\" >-11.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b5121_row3_col0\" class=\"data row3 col0\" >199998</td>\n",
       "      <td id=\"T_b5121_row3_col1\" class=\"data row3 col1\" >llama-7b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394_withreplacement</td>\n",
       "      <td id=\"T_b5121_row3_col2\" class=\"data row3 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row3_col3\" class=\"data row3 col3\" >{'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}</td>\n",
       "      <td id=\"T_b5121_row3_col4\" class=\"data row3 col4\" >42.57</td>\n",
       "      <td id=\"T_b5121_row3_col5\" class=\"data row3 col5\" >44.22</td>\n",
       "      <td id=\"T_b5121_row3_col6\" class=\"data row3 col6\" >7.00</td>\n",
       "      <td id=\"T_b5121_row3_col7\" class=\"data row3 col7\" >23.50</td>\n",
       "      <td id=\"T_b5121_row3_col8\" class=\"data row3 col8\" >34.21</td>\n",
       "      <td id=\"T_b5121_row3_col9\" class=\"data row3 col9\" >33.70</td>\n",
       "      <td id=\"T_b5121_row3_col10\" class=\"data row3 col10\" >9.63</td>\n",
       "      <td id=\"T_b5121_row3_col11\" class=\"data row3 col11\" >42.81</td>\n",
       "      <td id=\"T_b5121_row3_col12\" class=\"data row3 col12\" >6.71</td>\n",
       "      <td id=\"T_b5121_row3_col13\" class=\"data row3 col13\" >27.15</td>\n",
       "      <td id=\"T_b5121_row3_col14\" class=\"data row3 col14\" >-9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b5121_row4_col0\" class=\"data row4 col0\" >199998</td>\n",
       "      <td id=\"T_b5121_row4_col1\" class=\"data row4 col1\" >llama-7b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394</td>\n",
       "      <td id=\"T_b5121_row4_col2\" class=\"data row4 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row4_col3\" class=\"data row4 col3\" >{'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}</td>\n",
       "      <td id=\"T_b5121_row4_col4\" class=\"data row4 col4\" >42.29</td>\n",
       "      <td id=\"T_b5121_row4_col5\" class=\"data row4 col5\" >44.31</td>\n",
       "      <td id=\"T_b5121_row4_col6\" class=\"data row4 col6\" >5.50</td>\n",
       "      <td id=\"T_b5121_row4_col7\" class=\"data row4 col7\" >25.00</td>\n",
       "      <td id=\"T_b5121_row4_col8\" class=\"data row4 col8\" >36.60</td>\n",
       "      <td id=\"T_b5121_row4_col9\" class=\"data row4 col9\" >33.70</td>\n",
       "      <td id=\"T_b5121_row4_col10\" class=\"data row4 col10\" >10.03</td>\n",
       "      <td id=\"T_b5121_row4_col11\" class=\"data row4 col11\" >42.69</td>\n",
       "      <td id=\"T_b5121_row4_col12\" class=\"data row4 col12\" >3.05</td>\n",
       "      <td id=\"T_b5121_row4_col13\" class=\"data row4 col13\" >27.02</td>\n",
       "      <td id=\"T_b5121_row4_col14\" class=\"data row4 col14\" >-8.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b5121_row5_col0\" class=\"data row5 col0\" >199997</td>\n",
       "      <td id=\"T_b5121_row5_col1\" class=\"data row5 col1\" >llama-7b_all:200k_mix=cot:46128,dolly:9386,flan_v2:144243,oasst1:240</td>\n",
       "      <td id=\"T_b5121_row5_col2\" class=\"data row5 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row5_col3\" class=\"data row5 col3\" >{'cot': 46128, 'dolly': 9386, 'flan_v2': 144243, 'oasst1': 240}</td>\n",
       "      <td id=\"T_b5121_row5_col4\" class=\"data row5 col4\" >43.90</td>\n",
       "      <td id=\"T_b5121_row5_col5\" class=\"data row5 col5\" >46.37</td>\n",
       "      <td id=\"T_b5121_row5_col6\" class=\"data row5 col6\" >5.00</td>\n",
       "      <td id=\"T_b5121_row5_col7\" class=\"data row5 col7\" >17.00</td>\n",
       "      <td id=\"T_b5121_row5_col8\" class=\"data row5 col8\" >36.16</td>\n",
       "      <td id=\"T_b5121_row5_col9\" class=\"data row5 col9\" >32.04</td>\n",
       "      <td id=\"T_b5121_row5_col10\" class=\"data row5 col10\" >10.15</td>\n",
       "      <td id=\"T_b5121_row5_col11\" class=\"data row5 col11\" >45.71</td>\n",
       "      <td id=\"T_b5121_row5_col12\" class=\"data row5 col12\" >4.27</td>\n",
       "      <td id=\"T_b5121_row5_col13\" class=\"data row5 col13\" >26.73</td>\n",
       "      <td id=\"T_b5121_row5_col14\" class=\"data row5 col14\" >-9.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b5121_row6_col0\" class=\"data row6 col0\" >99999</td>\n",
       "      <td id=\"T_b5121_row6_col1\" class=\"data row6 col1\" >llama-7b_all:100k_mix=cot:48785,dolly:732,flan_v2:48785,oasst1:1697</td>\n",
       "      <td id=\"T_b5121_row6_col2\" class=\"data row6 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row6_col3\" class=\"data row6 col3\" >{'cot': 48785, 'dolly': 732, 'flan_v2': 48785, 'oasst1': 1697}</td>\n",
       "      <td id=\"T_b5121_row6_col4\" class=\"data row6 col4\" >41.62</td>\n",
       "      <td id=\"T_b5121_row6_col5\" class=\"data row6 col5\" >41.51</td>\n",
       "      <td id=\"T_b5121_row6_col6\" class=\"data row6 col6\" >6.50</td>\n",
       "      <td id=\"T_b5121_row6_col7\" class=\"data row6 col7\" >24.00</td>\n",
       "      <td id=\"T_b5121_row6_col8\" class=\"data row6 col8\" >35.73</td>\n",
       "      <td id=\"T_b5121_row6_col9\" class=\"data row6 col9\" >32.31</td>\n",
       "      <td id=\"T_b5121_row6_col10\" class=\"data row6 col10\" >10.50</td>\n",
       "      <td id=\"T_b5121_row6_col11\" class=\"data row6 col11\" >42.27</td>\n",
       "      <td id=\"T_b5121_row6_col12\" class=\"data row6 col12\" >3.66</td>\n",
       "      <td id=\"T_b5121_row6_col13\" class=\"data row6 col13\" >26.46</td>\n",
       "      <td id=\"T_b5121_row6_col14\" class=\"data row6 col14\" >-10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b5121_row7_col0\" class=\"data row7 col0\" >199998</td>\n",
       "      <td id=\"T_b5121_row7_col1\" class=\"data row7 col1\" >llama-7b_all:200k_mix=cot:81395,dolly:12637,flan_v2:19009,oasst1:86957</td>\n",
       "      <td id=\"T_b5121_row7_col2\" class=\"data row7 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row7_col3\" class=\"data row7 col3\" >{'cot': 81395, 'dolly': 12637, 'flan_v2': 19009, 'oasst1': 86957}</td>\n",
       "      <td id=\"T_b5121_row7_col4\" class=\"data row7 col4\" >41.16</td>\n",
       "      <td id=\"T_b5121_row7_col5\" class=\"data row7 col5\" >42.08</td>\n",
       "      <td id=\"T_b5121_row7_col6\" class=\"data row7 col6\" >5.50</td>\n",
       "      <td id=\"T_b5121_row7_col7\" class=\"data row7 col7\" >27.50</td>\n",
       "      <td id=\"T_b5121_row7_col8\" class=\"data row7 col8\" >33.23</td>\n",
       "      <td id=\"T_b5121_row7_col9\" class=\"data row7 col9\" >34.07</td>\n",
       "      <td id=\"T_b5121_row7_col10\" class=\"data row7 col10\" >11.17</td>\n",
       "      <td id=\"T_b5121_row7_col11\" class=\"data row7 col11\" >40.23</td>\n",
       "      <td id=\"T_b5121_row7_col12\" class=\"data row7 col12\" >2.44</td>\n",
       "      <td id=\"T_b5121_row7_col13\" class=\"data row7 col13\" >26.38</td>\n",
       "      <td id=\"T_b5121_row7_col14\" class=\"data row7 col14\" >-11.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b5121_row8_col0\" class=\"data row8 col0\" >199999</td>\n",
       "      <td id=\"T_b5121_row8_col1\" class=\"data row8 col1\" >llama-7b_all:200k_mix=cot:27757,dolly:11372,flan_v2:134027,oasst1:26843</td>\n",
       "      <td id=\"T_b5121_row8_col2\" class=\"data row8 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row8_col3\" class=\"data row8 col3\" >{'cot': 27757, 'dolly': 11372, 'flan_v2': 134027, 'oasst1': 26843}</td>\n",
       "      <td id=\"T_b5121_row8_col4\" class=\"data row8 col4\" >42.00</td>\n",
       "      <td id=\"T_b5121_row8_col5\" class=\"data row8 col5\" >44.29</td>\n",
       "      <td id=\"T_b5121_row8_col6\" class=\"data row8 col6\" >4.50</td>\n",
       "      <td id=\"T_b5121_row8_col7\" class=\"data row8 col7\" >19.50</td>\n",
       "      <td id=\"T_b5121_row8_col8\" class=\"data row8 col8\" >37.41</td>\n",
       "      <td id=\"T_b5121_row8_col9\" class=\"data row8 col9\" >32.13</td>\n",
       "      <td id=\"T_b5121_row8_col10\" class=\"data row8 col10\" >9.04</td>\n",
       "      <td id=\"T_b5121_row8_col11\" class=\"data row8 col11\" >44.36</td>\n",
       "      <td id=\"T_b5121_row8_col12\" class=\"data row8 col12\" >0.61</td>\n",
       "      <td id=\"T_b5121_row8_col13\" class=\"data row8 col13\" >25.98</td>\n",
       "      <td id=\"T_b5121_row8_col14\" class=\"data row8 col14\" >-13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b5121_row9_col0\" class=\"data row9 col0\" >200804</td>\n",
       "      <td id=\"T_b5121_row9_col1\" class=\"data row9 col1\" >llama-7b_all_mix=cot:15356,dolly:894,flan_v2:182740,oasst1:1814</td>\n",
       "      <td id=\"T_b5121_row9_col2\" class=\"data row9 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row9_col3\" class=\"data row9 col3\" >{'cot': 15356, 'dolly': 894, 'flan_v2': 182740, 'oasst1': 1814}</td>\n",
       "      <td id=\"T_b5121_row9_col4\" class=\"data row9 col4\" >44.60</td>\n",
       "      <td id=\"T_b5121_row9_col5\" class=\"data row9 col5\" >47.04</td>\n",
       "      <td id=\"T_b5121_row9_col6\" class=\"data row9 col6\" >3.50</td>\n",
       "      <td id=\"T_b5121_row9_col7\" class=\"data row9 col7\" >14.00</td>\n",
       "      <td id=\"T_b5121_row9_col8\" class=\"data row9 col8\" >37.15</td>\n",
       "      <td id=\"T_b5121_row9_col9\" class=\"data row9 col9\" >31.20</td>\n",
       "      <td id=\"T_b5121_row9_col10\" class=\"data row9 col10\" >9.93</td>\n",
       "      <td id=\"T_b5121_row9_col11\" class=\"data row9 col11\" >44.36</td>\n",
       "      <td id=\"T_b5121_row9_col12\" class=\"data row9 col12\" >1.83</td>\n",
       "      <td id=\"T_b5121_row9_col13\" class=\"data row9 col13\" >25.96</td>\n",
       "      <td id=\"T_b5121_row9_col14\" class=\"data row9 col14\" >-12.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_b5121_row10_col0\" class=\"data row10 col0\" >100064</td>\n",
       "      <td id=\"T_b5121_row10_col1\" class=\"data row10 col1\" >llama-7b_all:100k_mix=cot:11270,dolly:1395,flan_v2:87260,oasst1:139</td>\n",
       "      <td id=\"T_b5121_row10_col2\" class=\"data row10 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row10_col3\" class=\"data row10 col3\" >{'cot': 11270, 'dolly': 1395, 'flan_v2': 87260, 'oasst1': 139}</td>\n",
       "      <td id=\"T_b5121_row10_col4\" class=\"data row10 col4\" >40.73</td>\n",
       "      <td id=\"T_b5121_row10_col5\" class=\"data row10 col5\" >43.04</td>\n",
       "      <td id=\"T_b5121_row10_col6\" class=\"data row10 col6\" >6.00</td>\n",
       "      <td id=\"T_b5121_row10_col7\" class=\"data row10 col7\" >10.00</td>\n",
       "      <td id=\"T_b5121_row10_col8\" class=\"data row10 col8\" >35.30</td>\n",
       "      <td id=\"T_b5121_row10_col9\" class=\"data row10 col9\" >32.87</td>\n",
       "      <td id=\"T_b5121_row10_col10\" class=\"data row10 col10\" >12.12</td>\n",
       "      <td id=\"T_b5121_row10_col11\" class=\"data row10 col11\" >46.17</td>\n",
       "      <td id=\"T_b5121_row10_col12\" class=\"data row10 col12\" >7.32</td>\n",
       "      <td id=\"T_b5121_row10_col13\" class=\"data row10 col13\" >25.95</td>\n",
       "      <td id=\"T_b5121_row10_col14\" class=\"data row10 col14\" >-10.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_b5121_row11_col0\" class=\"data row11 col0\" >199998</td>\n",
       "      <td id=\"T_b5121_row11_col1\" class=\"data row11 col1\" >llama-7b_all:200k_mix=cot:75328,dolly:17492,flan_v2:79481,oasst1:27697</td>\n",
       "      <td id=\"T_b5121_row11_col2\" class=\"data row11 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row11_col3\" class=\"data row11 col3\" >{'cot': 75328, 'dolly': 17492, 'flan_v2': 79481, 'oasst1': 27697}</td>\n",
       "      <td id=\"T_b5121_row11_col4\" class=\"data row11 col4\" >40.40</td>\n",
       "      <td id=\"T_b5121_row11_col5\" class=\"data row11 col5\" >41.05</td>\n",
       "      <td id=\"T_b5121_row11_col6\" class=\"data row11 col6\" >5.00</td>\n",
       "      <td id=\"T_b5121_row11_col7\" class=\"data row11 col7\" >22.00</td>\n",
       "      <td id=\"T_b5121_row11_col8\" class=\"data row11 col8\" >35.95</td>\n",
       "      <td id=\"T_b5121_row11_col9\" class=\"data row11 col9\" >31.85</td>\n",
       "      <td id=\"T_b5121_row11_col10\" class=\"data row11 col10\" >10.58</td>\n",
       "      <td id=\"T_b5121_row11_col11\" class=\"data row11 col11\" >43.58</td>\n",
       "      <td id=\"T_b5121_row11_col12\" class=\"data row11 col12\" >0.00</td>\n",
       "      <td id=\"T_b5121_row11_col13\" class=\"data row11 col13\" >25.60</td>\n",
       "      <td id=\"T_b5121_row11_col14\" class=\"data row11 col14\" >-15.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_b5121_row12_col0\" class=\"data row12 col0\" >199998</td>\n",
       "      <td id=\"T_b5121_row12_col1\" class=\"data row12 col1\" >llama-7b_all:200k_mix=cot:44759,dolly:61131,flan_v2:30915,oasst1:63193</td>\n",
       "      <td id=\"T_b5121_row12_col2\" class=\"data row12 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row12_col3\" class=\"data row12 col3\" >{'cot': 44759, 'dolly': 61131, 'flan_v2': 30915, 'oasst1': 63193}</td>\n",
       "      <td id=\"T_b5121_row12_col4\" class=\"data row12 col4\" >38.41</td>\n",
       "      <td id=\"T_b5121_row12_col5\" class=\"data row12 col5\" >38.54</td>\n",
       "      <td id=\"T_b5121_row12_col6\" class=\"data row12 col6\" >5.50</td>\n",
       "      <td id=\"T_b5121_row12_col7\" class=\"data row12 col7\" >22.50</td>\n",
       "      <td id=\"T_b5121_row12_col8\" class=\"data row12 col8\" >34.56</td>\n",
       "      <td id=\"T_b5121_row12_col9\" class=\"data row12 col9\" >31.76</td>\n",
       "      <td id=\"T_b5121_row12_col10\" class=\"data row12 col10\" >10.89</td>\n",
       "      <td id=\"T_b5121_row12_col11\" class=\"data row12 col11\" >46.57</td>\n",
       "      <td id=\"T_b5121_row12_col12\" class=\"data row12 col12\" >1.22</td>\n",
       "      <td id=\"T_b5121_row12_col13\" class=\"data row12 col13\" >25.55</td>\n",
       "      <td id=\"T_b5121_row12_col14\" class=\"data row12 col14\" >-13.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_b5121_row13_col0\" class=\"data row13 col0\" >125254</td>\n",
       "      <td id=\"T_b5121_row13_col1\" class=\"data row13 col1\" >llama-7b_all:200k_mix=cot:22839,dolly:20483,flan_v2:40966,oasst1:40966</td>\n",
       "      <td id=\"T_b5121_row13_col2\" class=\"data row13 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row13_col3\" class=\"data row13 col3\" >{'cot': 22839, 'dolly': 20483, 'flan_v2': 40966, 'oasst1': 40966}</td>\n",
       "      <td id=\"T_b5121_row13_col4\" class=\"data row13 col4\" >42.49</td>\n",
       "      <td id=\"T_b5121_row13_col5\" class=\"data row13 col5\" >41.95</td>\n",
       "      <td id=\"T_b5121_row13_col6\" class=\"data row13 col6\" >6.00</td>\n",
       "      <td id=\"T_b5121_row13_col7\" class=\"data row13 col7\" >17.00</td>\n",
       "      <td id=\"T_b5121_row13_col8\" class=\"data row13 col8\" >34.76</td>\n",
       "      <td id=\"T_b5121_row13_col9\" class=\"data row13 col9\" >33.33</td>\n",
       "      <td id=\"T_b5121_row13_col10\" class=\"data row13 col10\" >8.61</td>\n",
       "      <td id=\"T_b5121_row13_col11\" class=\"data row13 col11\" >43.93</td>\n",
       "      <td id=\"T_b5121_row13_col12\" class=\"data row13 col12\" >0.61</td>\n",
       "      <td id=\"T_b5121_row13_col13\" class=\"data row13 col13\" >25.41</td>\n",
       "      <td id=\"T_b5121_row13_col14\" class=\"data row13 col14\" >-13.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_b5121_row14_col0\" class=\"data row14 col0\" >199998</td>\n",
       "      <td id=\"T_b5121_row14_col1\" class=\"data row14 col1\" >llama-7b_all:200k_mix=cot:27136,dolly:11929,flan_v2:79155,oasst1:81778</td>\n",
       "      <td id=\"T_b5121_row14_col2\" class=\"data row14 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row14_col3\" class=\"data row14 col3\" >{'cot': 27136, 'dolly': 11929, 'flan_v2': 79155, 'oasst1': 81778}</td>\n",
       "      <td id=\"T_b5121_row14_col4\" class=\"data row14 col4\" >42.47</td>\n",
       "      <td id=\"T_b5121_row14_col5\" class=\"data row14 col5\" >42.51</td>\n",
       "      <td id=\"T_b5121_row14_col6\" class=\"data row14 col6\" >4.00</td>\n",
       "      <td id=\"T_b5121_row14_col7\" class=\"data row14 col7\" >15.50</td>\n",
       "      <td id=\"T_b5121_row14_col8\" class=\"data row14 col8\" >35.85</td>\n",
       "      <td id=\"T_b5121_row14_col9\" class=\"data row14 col9\" >33.70</td>\n",
       "      <td id=\"T_b5121_row14_col10\" class=\"data row14 col10\" >10.26</td>\n",
       "      <td id=\"T_b5121_row14_col11\" class=\"data row14 col11\" >44.08</td>\n",
       "      <td id=\"T_b5121_row14_col12\" class=\"data row14 col12\" >0.00</td>\n",
       "      <td id=\"T_b5121_row14_col13\" class=\"data row14 col13\" >25.38</td>\n",
       "      <td id=\"T_b5121_row14_col14\" class=\"data row14 col14\" >-15.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_b5121_row15_col0\" class=\"data row15 col0\" >199998</td>\n",
       "      <td id=\"T_b5121_row15_col1\" class=\"data row15 col1\" >llama-7b_all:200k_mix=cot:36468,dolly:32706,flan_v2:65412,oasst1:65412</td>\n",
       "      <td id=\"T_b5121_row15_col2\" class=\"data row15 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row15_col3\" class=\"data row15 col3\" >{'cot': 36468, 'dolly': 32706, 'flan_v2': 65412, 'oasst1': 65412}</td>\n",
       "      <td id=\"T_b5121_row15_col4\" class=\"data row15 col4\" >40.14</td>\n",
       "      <td id=\"T_b5121_row15_col5\" class=\"data row15 col5\" >41.60</td>\n",
       "      <td id=\"T_b5121_row15_col6\" class=\"data row15 col6\" >5.00</td>\n",
       "      <td id=\"T_b5121_row15_col7\" class=\"data row15 col7\" >21.00</td>\n",
       "      <td id=\"T_b5121_row15_col8\" class=\"data row15 col8\" >34.68</td>\n",
       "      <td id=\"T_b5121_row15_col9\" class=\"data row15 col9\" >33.24</td>\n",
       "      <td id=\"T_b5121_row15_col10\" class=\"data row15 col10\" >8.03</td>\n",
       "      <td id=\"T_b5121_row15_col11\" class=\"data row15 col11\" >44.31</td>\n",
       "      <td id=\"T_b5121_row15_col12\" class=\"data row15 col12\" >0.00</td>\n",
       "      <td id=\"T_b5121_row15_col13\" class=\"data row15 col13\" >25.33</td>\n",
       "      <td id=\"T_b5121_row15_col14\" class=\"data row15 col14\" >-17.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_b5121_row16_col0\" class=\"data row16 col0\" >199999</td>\n",
       "      <td id=\"T_b5121_row16_col1\" class=\"data row16 col1\" >llama-7b_all:200k_mix=cot:22489,dolly:43994,flan_v2:116533,oasst1:16983</td>\n",
       "      <td id=\"T_b5121_row16_col2\" class=\"data row16 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row16_col3\" class=\"data row16 col3\" >{'cot': 22489, 'dolly': 43994, 'flan_v2': 116533, 'oasst1': 16983}</td>\n",
       "      <td id=\"T_b5121_row16_col4\" class=\"data row16 col4\" >43.26</td>\n",
       "      <td id=\"T_b5121_row16_col5\" class=\"data row16 col5\" >45.15</td>\n",
       "      <td id=\"T_b5121_row16_col6\" class=\"data row16 col6\" >4.50</td>\n",
       "      <td id=\"T_b5121_row16_col7\" class=\"data row16 col7\" >15.00</td>\n",
       "      <td id=\"T_b5121_row16_col8\" class=\"data row16 col8\" >36.49</td>\n",
       "      <td id=\"T_b5121_row16_col9\" class=\"data row16 col9\" >31.39</td>\n",
       "      <td id=\"T_b5121_row16_col10\" class=\"data row16 col10\" >9.69</td>\n",
       "      <td id=\"T_b5121_row16_col11\" class=\"data row16 col11\" >38.65</td>\n",
       "      <td id=\"T_b5121_row16_col12\" class=\"data row16 col12\" >3.05</td>\n",
       "      <td id=\"T_b5121_row16_col13\" class=\"data row16 col13\" >25.24</td>\n",
       "      <td id=\"T_b5121_row16_col14\" class=\"data row16 col14\" >-14.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_b5121_row17_col0\" class=\"data row17 col0\" >211155</td>\n",
       "      <td id=\"T_b5121_row17_col1\" class=\"data row17 col1\" >llama-7b_all:200k_mix=cot:6323,dolly:40966,flan_v2:81933,oasst1:81933</td>\n",
       "      <td id=\"T_b5121_row17_col2\" class=\"data row17 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row17_col3\" class=\"data row17 col3\" >{'cot': 6323, 'dolly': 40966, 'flan_v2': 81933, 'oasst1': 81933}</td>\n",
       "      <td id=\"T_b5121_row17_col4\" class=\"data row17 col4\" >40.04</td>\n",
       "      <td id=\"T_b5121_row17_col5\" class=\"data row17 col5\" >41.90</td>\n",
       "      <td id=\"T_b5121_row17_col6\" class=\"data row17 col6\" >7.50</td>\n",
       "      <td id=\"T_b5121_row17_col7\" class=\"data row17 col7\" >18.50</td>\n",
       "      <td id=\"T_b5121_row17_col8\" class=\"data row17 col8\" >35.28</td>\n",
       "      <td id=\"T_b5121_row17_col9\" class=\"data row17 col9\" >30.28</td>\n",
       "      <td id=\"T_b5121_row17_col10\" class=\"data row17 col10\" >10.26</td>\n",
       "      <td id=\"T_b5121_row17_col11\" class=\"data row17 col11\" >41.28</td>\n",
       "      <td id=\"T_b5121_row17_col12\" class=\"data row17 col12\" >0.00</td>\n",
       "      <td id=\"T_b5121_row17_col13\" class=\"data row17 col13\" >25.00</td>\n",
       "      <td id=\"T_b5121_row17_col14\" class=\"data row17 col14\" >-17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_b5121_row18_col0\" class=\"data row18 col0\" >197365</td>\n",
       "      <td id=\"T_b5121_row18_col1\" class=\"data row18 col1\" >llama-7b_all:200k_mix=cot:17126,dolly:108593,flan_v2:69580,oasst1:2066</td>\n",
       "      <td id=\"T_b5121_row18_col2\" class=\"data row18 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row18_col3\" class=\"data row18 col3\" >{'cot': 17126, 'dolly': 108593, 'flan_v2': 69580, 'oasst1': 2066}</td>\n",
       "      <td id=\"T_b5121_row18_col4\" class=\"data row18 col4\" >41.63</td>\n",
       "      <td id=\"T_b5121_row18_col5\" class=\"data row18 col5\" >43.04</td>\n",
       "      <td id=\"T_b5121_row18_col6\" class=\"data row18 col6\" >7.00</td>\n",
       "      <td id=\"T_b5121_row18_col7\" class=\"data row18 col7\" >14.00</td>\n",
       "      <td id=\"T_b5121_row18_col8\" class=\"data row18 col8\" >35.02</td>\n",
       "      <td id=\"T_b5121_row18_col9\" class=\"data row18 col9\" >31.02</td>\n",
       "      <td id=\"T_b5121_row18_col10\" class=\"data row18 col10\" >10.12</td>\n",
       "      <td id=\"T_b5121_row18_col11\" class=\"data row18 col11\" >42.12</td>\n",
       "      <td id=\"T_b5121_row18_col12\" class=\"data row18 col12\" >0.00</td>\n",
       "      <td id=\"T_b5121_row18_col13\" class=\"data row18 col13\" >24.88</td>\n",
       "      <td id=\"T_b5121_row18_col14\" class=\"data row18 col14\" >-17.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_b5121_row19_col0\" class=\"data row19 col0\" >199998</td>\n",
       "      <td id=\"T_b5121_row19_col1\" class=\"data row19 col1\" >llama-7b_all:200k_mix=cot:16131,dolly:83772,flan_v2:43447,oasst1:56648</td>\n",
       "      <td id=\"T_b5121_row19_col2\" class=\"data row19 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row19_col3\" class=\"data row19 col3\" >{'cot': 16131, 'dolly': 83772, 'flan_v2': 43447, 'oasst1': 56648}</td>\n",
       "      <td id=\"T_b5121_row19_col4\" class=\"data row19 col4\" >39.20</td>\n",
       "      <td id=\"T_b5121_row19_col5\" class=\"data row19 col5\" >37.97</td>\n",
       "      <td id=\"T_b5121_row19_col6\" class=\"data row19 col6\" >5.00</td>\n",
       "      <td id=\"T_b5121_row19_col7\" class=\"data row19 col7\" >17.00</td>\n",
       "      <td id=\"T_b5121_row19_col8\" class=\"data row19 col8\" >34.47</td>\n",
       "      <td id=\"T_b5121_row19_col9\" class=\"data row19 col9\" >32.41</td>\n",
       "      <td id=\"T_b5121_row19_col10\" class=\"data row19 col10\" >10.52</td>\n",
       "      <td id=\"T_b5121_row19_col11\" class=\"data row19 col11\" >44.30</td>\n",
       "      <td id=\"T_b5121_row19_col12\" class=\"data row19 col12\" >0.00</td>\n",
       "      <td id=\"T_b5121_row19_col13\" class=\"data row19 col13\" >24.54</td>\n",
       "      <td id=\"T_b5121_row19_col14\" class=\"data row19 col14\" >-18.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_b5121_row20_col0\" class=\"data row20 col0\" >200000</td>\n",
       "      <td id=\"T_b5121_row20_col1\" class=\"data row20 col1\" >llama-7b_all:200k_mix=cot:50000,dolly:50000,flan_v2:50000,oasst1:50000</td>\n",
       "      <td id=\"T_b5121_row20_col2\" class=\"data row20 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row20_col3\" class=\"data row20 col3\" >{'cot': 50000, 'dolly': 50000, 'flan_v2': 50000, 'oasst1': 50000}</td>\n",
       "      <td id=\"T_b5121_row20_col4\" class=\"data row20 col4\" >34.08</td>\n",
       "      <td id=\"T_b5121_row20_col5\" class=\"data row20 col5\" >38.88</td>\n",
       "      <td id=\"T_b5121_row20_col6\" class=\"data row20 col6\" >5.00</td>\n",
       "      <td id=\"T_b5121_row20_col7\" class=\"data row20 col7\" >19.50</td>\n",
       "      <td id=\"T_b5121_row20_col8\" class=\"data row20 col8\" >33.96</td>\n",
       "      <td id=\"T_b5121_row20_col9\" class=\"data row20 col9\" >33.15</td>\n",
       "      <td id=\"T_b5121_row20_col10\" class=\"data row20 col10\" >10.00</td>\n",
       "      <td id=\"T_b5121_row20_col11\" class=\"data row20 col11\" >42.19</td>\n",
       "      <td id=\"T_b5121_row20_col12\" class=\"data row20 col12\" >1.22</td>\n",
       "      <td id=\"T_b5121_row20_col13\" class=\"data row20 col13\" >24.22</td>\n",
       "      <td id=\"T_b5121_row20_col14\" class=\"data row20 col14\" >-17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_b5121_row21_col0\" class=\"data row21 col0\" >100000</td>\n",
       "      <td id=\"T_b5121_row21_col1\" class=\"data row21 col1\" >llama-7b_all:100k_mix=cot:25000,dolly:25000,flan_v2:25000,oasst1:25000</td>\n",
       "      <td id=\"T_b5121_row21_col2\" class=\"data row21 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row21_col3\" class=\"data row21 col3\" >{'cot': 25000, 'dolly': 25000, 'flan_v2': 25000, 'oasst1': 25000}</td>\n",
       "      <td id=\"T_b5121_row21_col4\" class=\"data row21 col4\" >40.28</td>\n",
       "      <td id=\"T_b5121_row21_col5\" class=\"data row21 col5\" >38.13</td>\n",
       "      <td id=\"T_b5121_row21_col6\" class=\"data row21 col6\" >6.00</td>\n",
       "      <td id=\"T_b5121_row21_col7\" class=\"data row21 col7\" >13.50</td>\n",
       "      <td id=\"T_b5121_row21_col8\" class=\"data row21 col8\" >33.49</td>\n",
       "      <td id=\"T_b5121_row21_col9\" class=\"data row21 col9\" >28.89</td>\n",
       "      <td id=\"T_b5121_row21_col10\" class=\"data row21 col10\" >10.46</td>\n",
       "      <td id=\"T_b5121_row21_col11\" class=\"data row21 col11\" >43.02</td>\n",
       "      <td id=\"T_b5121_row21_col12\" class=\"data row21 col12\" >0.61</td>\n",
       "      <td id=\"T_b5121_row21_col13\" class=\"data row21 col13\" >23.82</td>\n",
       "      <td id=\"T_b5121_row21_col14\" class=\"data row21 col14\" >-18.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_b5121_row22_col0\" class=\"data row22 col0\" >199998</td>\n",
       "      <td id=\"T_b5121_row22_col1\" class=\"data row22 col1\" >llama-7b_all:200k_mix=cot:49222,dolly:19548,flan_v2:27948,oasst1:103280</td>\n",
       "      <td id=\"T_b5121_row22_col2\" class=\"data row22 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row22_col3\" class=\"data row22 col3\" >{'cot': 49222, 'dolly': 19548, 'flan_v2': 27948, 'oasst1': 103280}</td>\n",
       "      <td id=\"T_b5121_row22_col4\" class=\"data row22 col4\" >31.76</td>\n",
       "      <td id=\"T_b5121_row22_col5\" class=\"data row22 col5\" >33.81</td>\n",
       "      <td id=\"T_b5121_row22_col6\" class=\"data row22 col6\" >5.00</td>\n",
       "      <td id=\"T_b5121_row22_col7\" class=\"data row22 col7\" >23.00</td>\n",
       "      <td id=\"T_b5121_row22_col8\" class=\"data row22 col8\" >34.89</td>\n",
       "      <td id=\"T_b5121_row22_col9\" class=\"data row22 col9\" >30.00</td>\n",
       "      <td id=\"T_b5121_row22_col10\" class=\"data row22 col10\" >9.08</td>\n",
       "      <td id=\"T_b5121_row22_col11\" class=\"data row22 col11\" >40.84</td>\n",
       "      <td id=\"T_b5121_row22_col12\" class=\"data row22 col12\" >0.00</td>\n",
       "      <td id=\"T_b5121_row22_col13\" class=\"data row22 col13\" >23.15</td>\n",
       "      <td id=\"T_b5121_row22_col14\" class=\"data row22 col14\" >-22.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_b5121_row23_col0\" class=\"data row23 col0\" >199999</td>\n",
       "      <td id=\"T_b5121_row23_col1\" class=\"data row23 col1\" >llama-7b_all:200k_mix=cot:55409,dolly:114245,flan_v2:4988,oasst1:25357</td>\n",
       "      <td id=\"T_b5121_row23_col2\" class=\"data row23 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row23_col3\" class=\"data row23 col3\" >{'cot': 55409, 'dolly': 114245, 'flan_v2': 4988, 'oasst1': 25357}</td>\n",
       "      <td id=\"T_b5121_row23_col4\" class=\"data row23 col4\" >28.36</td>\n",
       "      <td id=\"T_b5121_row23_col5\" class=\"data row23 col5\" >28.65</td>\n",
       "      <td id=\"T_b5121_row23_col6\" class=\"data row23 col6\" >6.00</td>\n",
       "      <td id=\"T_b5121_row23_col7\" class=\"data row23 col7\" >19.50</td>\n",
       "      <td id=\"T_b5121_row23_col8\" class=\"data row23 col8\" >35.04</td>\n",
       "      <td id=\"T_b5121_row23_col9\" class=\"data row23 col9\" >32.50</td>\n",
       "      <td id=\"T_b5121_row23_col10\" class=\"data row23 col10\" >10.70</td>\n",
       "      <td id=\"T_b5121_row23_col11\" class=\"data row23 col11\" >40.50</td>\n",
       "      <td id=\"T_b5121_row23_col12\" class=\"data row23 col12\" >0.00</td>\n",
       "      <td id=\"T_b5121_row23_col13\" class=\"data row23 col13\" >22.36</td>\n",
       "      <td id=\"T_b5121_row23_col14\" class=\"data row23 col14\" >-18.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_b5121_row24_col0\" class=\"data row24 col0\" >199998</td>\n",
       "      <td id=\"T_b5121_row24_col1\" class=\"data row24 col1\" >llama-7b_all:200k_mix=cot:490,dolly:26549,flan_v2:2453,oasst1:170506</td>\n",
       "      <td id=\"T_b5121_row24_col2\" class=\"data row24 col2\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row24_col3\" class=\"data row24 col3\" >{'cot': 490, 'dolly': 26549, 'flan_v2': 2453, 'oasst1': 170506}</td>\n",
       "      <td id=\"T_b5121_row24_col4\" class=\"data row24 col4\" >36.75</td>\n",
       "      <td id=\"T_b5121_row24_col5\" class=\"data row24 col5\" >36.38</td>\n",
       "      <td id=\"T_b5121_row24_col6\" class=\"data row24 col6\" >5.50</td>\n",
       "      <td id=\"T_b5121_row24_col7\" class=\"data row24 col7\" >11.50</td>\n",
       "      <td id=\"T_b5121_row24_col8\" class=\"data row24 col8\" >33.21</td>\n",
       "      <td id=\"T_b5121_row24_col9\" class=\"data row24 col9\" >27.50</td>\n",
       "      <td id=\"T_b5121_row24_col10\" class=\"data row24 col10\" >10.50</td>\n",
       "      <td id=\"T_b5121_row24_col11\" class=\"data row24 col11\" >38.80</td>\n",
       "      <td id=\"T_b5121_row24_col12\" class=\"data row24 col12\" >0.00</td>\n",
       "      <td id=\"T_b5121_row24_col13\" class=\"data row24 col13\" >22.24</td>\n",
       "      <td id=\"T_b5121_row24_col14\" class=\"data row24 col14\" >-23.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5121_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_b5121_row25_col0\" class=\"data row25 col0\" >200000</td>\n",
       "      <td id=\"T_b5121_row25_col1\" class=\"data row25 col1\" >llama-7b</td>\n",
       "      <td id=\"T_b5121_row25_col2\" class=\"data row25 col2\" >huggyllama/llama-7b</td>\n",
       "      <td id=\"T_b5121_row25_col3\" class=\"data row25 col3\" >{}</td>\n",
       "      <td id=\"T_b5121_row25_col4\" class=\"data row25 col4\" >32.46</td>\n",
       "      <td id=\"T_b5121_row25_col5\" class=\"data row25 col5\" >33.06</td>\n",
       "      <td id=\"T_b5121_row25_col6\" class=\"data row25 col6\" >5.50</td>\n",
       "      <td id=\"T_b5121_row25_col7\" class=\"data row25 col7\" >11.00</td>\n",
       "      <td id=\"T_b5121_row25_col8\" class=\"data row25 col8\" >32.97</td>\n",
       "      <td id=\"T_b5121_row25_col9\" class=\"data row25 col9\" >28.43</td>\n",
       "      <td id=\"T_b5121_row25_col10\" class=\"data row25 col10\" >10.35</td>\n",
       "      <td id=\"T_b5121_row25_col11\" class=\"data row25 col11\" >38.56</td>\n",
       "      <td id=\"T_b5121_row25_col12\" class=\"data row25 col12\" >0.00</td>\n",
       "      <td id=\"T_b5121_row25_col13\" class=\"data row25 col13\" >21.37</td>\n",
       "      <td id=\"T_b5121_row25_col14\" class=\"data row25 col14\" >-24.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fff7807bf70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfc = df.copy()\n",
    "dfc.insert(0, 'total_train_samples',  dfc['data_args.subsample_mixture'].apply(\n",
    "    lambda d: sum(list(d.values())) if d else 200000))\n",
    "dfc = dfc[dfc['model_args.model_name_or_path'].apply(\n",
    "    lambda x: 'llama-7b' in x)]\n",
    "display(dfc\n",
    "        .style\n",
    "        .set_properties(**{'text-align': 'left'})\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58c1866b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>model_args.model_name_or_path</th>\n",
       "      <th>data_args.subsample_mixture</th>\n",
       "      <th>MMLU/0-shot</th>\n",
       "      <th>MMLU/5-shot</th>\n",
       "      <th>GSM/CoT</th>\n",
       "      <th>BBH/Direct</th>\n",
       "      <th>TydiQA/GP</th>\n",
       "      <th>Codex-Eval/Pass@1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama-7b</td>\n",
       "      <td>huggyllama/llama-7b</td>\n",
       "      <td>{}</td>\n",
       "      <td>32.459764</td>\n",
       "      <td>33.057969</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.970313</td>\n",
       "      <td>38.564264</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama-7b_humanmix</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{}</td>\n",
       "      <td>43.547928</td>\n",
       "      <td>46.460618</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.114618</td>\n",
       "      <td>43.481729</td>\n",
       "      <td>10.365854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2m_all_mix=oasst1:100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'oasst1': 100000}</td>\n",
       "      <td>22.973935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.000967</td>\n",
       "      <td>6.326418</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2m_all_mix=cot:15356,dolly:894,flan_v2:182740,oasst1:1814</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 15356, 'dolly': 894, 'flan_v2': 182740, 'oasst1': 1814}</td>\n",
       "      <td>23.045150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>30.422551</td>\n",
       "      <td>7.712177</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama-7b_all:400k_mix=cot:195140,dolly:2929,flan_v2:195140,oasst1:6789</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 195140, 'dolly': 2929, 'flan_v2': 195140, 'oasst1': 6789}</td>\n",
       "      <td>44.003703</td>\n",
       "      <td>45.378151</td>\n",
       "      <td>25.5</td>\n",
       "      <td>36.525510</td>\n",
       "      <td>39.450704</td>\n",
       "      <td>10.975610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt2m_all_mix=cot:22540,dolly:2790,flan_v2:174520,oasst1:278</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 22540, 'dolly': 2790, 'flan_v2': 174520, 'oasst1': 278}</td>\n",
       "      <td>23.123487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>29.677548</td>\n",
       "      <td>8.898066</td>\n",
       "      <td>0.609756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:46128,dolly:9386,flan_v2:144243,oasst1:240</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 46128, 'dolly': 9386, 'flan_v2': 144243, 'oasst1': 240}</td>\n",
       "      <td>43.904002</td>\n",
       "      <td>46.368039</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.159018</td>\n",
       "      <td>45.712140</td>\n",
       "      <td>4.268293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama-7b_all:600k_mix=cot:292710,dolly:4393,flan_v2:292710,oasst1:10184</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 292710, 'dolly': 4393, 'flan_v2': 292710, 'oasst1': 10184}</td>\n",
       "      <td>41.354508</td>\n",
       "      <td>44.338413</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.350256</td>\n",
       "      <td>40.963928</td>\n",
       "      <td>9.756098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt2m_all_mix=sharegpt:100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'sharegpt': 100000}</td>\n",
       "      <td>23.052272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.323305</td>\n",
       "      <td>3.702220</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:22489,dolly:43994,flan_v2:116533,oasst1:16983</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 22489, 'dolly': 43994, 'flan_v2': 116533, 'oasst1': 16983}</td>\n",
       "      <td>43.255946</td>\n",
       "      <td>45.150263</td>\n",
       "      <td>15.0</td>\n",
       "      <td>36.486059</td>\n",
       "      <td>38.651060</td>\n",
       "      <td>3.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:27757,dolly:11372,flan_v2:134027,oasst1:26843</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 27757, 'dolly': 11372, 'flan_v2': 134027, 'oasst1': 26843}</td>\n",
       "      <td>41.995442</td>\n",
       "      <td>44.288563</td>\n",
       "      <td>19.5</td>\n",
       "      <td>37.408689</td>\n",
       "      <td>44.361642</td>\n",
       "      <td>0.609756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:55409,dolly:114245,flan_v2:4988,oasst1:25357</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 55409, 'dolly': 114245, 'flan_v2': 4988, 'oasst1': 25357}</td>\n",
       "      <td>28.364905</td>\n",
       "      <td>28.649765</td>\n",
       "      <td>19.5</td>\n",
       "      <td>35.042380</td>\n",
       "      <td>40.504711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>llama-7b_all:100k_mix=cot:11270,dolly:1395,flan_v2:87260,oasst1:139</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 11270, 'dolly': 1395, 'flan_v2': 87260, 'oasst1': 139}</td>\n",
       "      <td>40.734938</td>\n",
       "      <td>43.035180</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.295402</td>\n",
       "      <td>46.169230</td>\n",
       "      <td>7.317073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt2m_all:200k_mix=cot:27136,dolly:11929,flan_v2:79155,oasst1:81778</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 27136, 'dolly': 11929, 'flan_v2': 79155, 'oasst1': 81778}</td>\n",
       "      <td>23.080758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.355884</td>\n",
       "      <td>9.470316</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pythia-6.9b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394</td>\n",
       "      <td>results/baselines/EleutherAI/pythia-6.9b</td>\n",
       "      <td>{'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.836775</td>\n",
       "      <td>6.5</td>\n",
       "      <td>30.429888</td>\n",
       "      <td>26.516632</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt2m_all_mix=stanford_alpaca:100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'stanford_alpaca': 100000}</td>\n",
       "      <td>22.988178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>27.052148</td>\n",
       "      <td>5.113901</td>\n",
       "      <td>0.609756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt2m_all_mix=baize:16666,code_alpaca:16666,cot:16666,dolly:16666,flan_v2:16666,gpt4_alpaca:16666,oasst1:16666,self_instruct:16666,sharegpt:16666,stanford_alpaca:16666,super_ni:16666,unnatural_instructions:16666</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'baize': 16666, 'code_alpaca': 16666, 'cot': 16666, 'dolly': 16666, 'flan_v2': 16666, 'gpt4_alpaca': 16666, 'oasst1': 16666, 'self_instruct': 16666, 'sharegpt': 16666, 'stanford_alpaca': 16666, 'super_ni': 16666, 'unnatural_instructions': 16666}</td>\n",
       "      <td>23.016664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.758117</td>\n",
       "      <td>7.950251</td>\n",
       "      <td>1.219512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt2m_all_mix=baize:8333,code_alpaca:8333,cot:8333,dolly:8333,flan_v2:8333,gpt4_alpaca:8333,oasst1:8333,self_instruct:8333,sharegpt:8333,stanford_alpaca:8333,super_ni:8333,unnatural_instructions:8333</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'baize': 8333, 'code_alpaca': 8333, 'cot': 8333, 'dolly': 8333, 'flan_v2': 8333, 'gpt4_alpaca': 8333, 'oasst1': 8333, 'self_instruct': 8333, 'sharegpt': 8333, 'stanford_alpaca': 8333, 'super_ni': 8333, 'unnatural_instructions': 8333}</td>\n",
       "      <td>22.938328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30.391050</td>\n",
       "      <td>5.948287</td>\n",
       "      <td>0.609756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394_withreplacement</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}</td>\n",
       "      <td>42.572283</td>\n",
       "      <td>44.224469</td>\n",
       "      <td>23.5</td>\n",
       "      <td>34.212314</td>\n",
       "      <td>42.805747</td>\n",
       "      <td>6.707317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pythia-1.4b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394</td>\n",
       "      <td>results/baselines/EleutherAI/pythia-1.4b</td>\n",
       "      <td>{'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}</td>\n",
       "      <td>25.331149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.693163</td>\n",
       "      <td>21.630193</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt2m_all_mix=dolly:100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'dolly': 100000}</td>\n",
       "      <td>22.810141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>15.476953</td>\n",
       "      <td>5.569227</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:22839,dolly:20483,flan_v2:40966,oasst1:40966</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 22839, 'dolly': 20483, 'flan_v2': 40966, 'oasst1': 40966}</td>\n",
       "      <td>42.486825</td>\n",
       "      <td>41.952713</td>\n",
       "      <td>17.0</td>\n",
       "      <td>34.763686</td>\n",
       "      <td>43.925070</td>\n",
       "      <td>0.609756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt2m_all:50k_mix=cot:12500,dolly:12500,flan_v2:12500,oasst1:12500</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 12500, 'dolly': 12500, 'flan_v2': 12500, 'oasst1': 12500}</td>\n",
       "      <td>22.952571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.284956</td>\n",
       "      <td>7.082380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:44759,dolly:61131,flan_v2:30915,oasst1:63193</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 44759, 'dolly': 61131, 'flan_v2': 30915, 'oasst1': 63193}</td>\n",
       "      <td>38.406210</td>\n",
       "      <td>38.541518</td>\n",
       "      <td>22.5</td>\n",
       "      <td>34.556323</td>\n",
       "      <td>46.566055</td>\n",
       "      <td>1.219512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>llama-7b_all:100k_mix=cot:25000,dolly:25000,flan_v2:25000,oasst1:25000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 25000, 'dolly': 25000, 'flan_v2': 25000, 'oasst1': 25000}</td>\n",
       "      <td>40.279163</td>\n",
       "      <td>38.128472</td>\n",
       "      <td>13.5</td>\n",
       "      <td>33.489712</td>\n",
       "      <td>43.019298</td>\n",
       "      <td>0.609756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gpt2m_all_mix=flan_v2:100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'flan_v2': 100000}</td>\n",
       "      <td>23.002421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.757914</td>\n",
       "      <td>8.841241</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:50000,dolly:50000,flan_v2:50000,oasst1:50000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 50000, 'dolly': 50000, 'flan_v2': 50000, 'oasst1': 50000}</td>\n",
       "      <td>34.076342</td>\n",
       "      <td>38.883350</td>\n",
       "      <td>19.5</td>\n",
       "      <td>33.958081</td>\n",
       "      <td>42.187476</td>\n",
       "      <td>1.219512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gpt2m_all_mix=unnatural_instructions:100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'unnatural_instructions': 100000}</td>\n",
       "      <td>23.201823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.127942</td>\n",
       "      <td>4.095138</td>\n",
       "      <td>1.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:27136,dolly:11929,flan_v2:79155,oasst1:81778</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 27136, 'dolly': 11929, 'flan_v2': 79155, 'oasst1': 81778}</td>\n",
       "      <td>42.472582</td>\n",
       "      <td>42.508190</td>\n",
       "      <td>15.5</td>\n",
       "      <td>35.848182</td>\n",
       "      <td>44.080953</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:6323,dolly:40966,flan_v2:81933,oasst1:81933</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 6323, 'dolly': 40966, 'flan_v2': 81933, 'oasst1': 81933}</td>\n",
       "      <td>40.044153</td>\n",
       "      <td>41.895741</td>\n",
       "      <td>18.5</td>\n",
       "      <td>35.279586</td>\n",
       "      <td>41.282352</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>gpt2m_all:10k_mix=cot:4878,dolly:73,flan_v2:4878,oasst1:169</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 4878, 'dolly': 73, 'flan_v2': 4878, 'oasst1': 169}</td>\n",
       "      <td>22.945449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>28.108541</td>\n",
       "      <td>6.646854</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:16131,dolly:83772,flan_v2:43447,oasst1:56648</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 16131, 'dolly': 83772, 'flan_v2': 43447, 'oasst1': 56648}</td>\n",
       "      <td>39.196696</td>\n",
       "      <td>37.971799</td>\n",
       "      <td>17.0</td>\n",
       "      <td>34.468655</td>\n",
       "      <td>44.297010</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>gpt2m_all_mix=cot:25000,dolly:25000,flan_v2:25000,oasst1:25000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'cot': 25000, 'dolly': 25000, 'flan_v2': 25000, 'oasst1': 25000}</td>\n",
       "      <td>22.938328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.980136</td>\n",
       "      <td>7.088936</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>pythia-1.4b_all:200k_mix=cot:72119,dolly:439,flan_v2:126074,oasst1:339</td>\n",
       "      <td>results/baselines/EleutherAI/pythia-1.4b</td>\n",
       "      <td>{'cot': 72119, 'dolly': 439, 'flan_v2': 126074, 'oasst1': 339}</td>\n",
       "      <td>25.737074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>27.521610</td>\n",
       "      <td>20.432359</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pythia-1.4b_all:200k_mix=cot:45092,dolly:2818,flan_v2:34790,oasst1:118847</td>\n",
       "      <td>results/baselines/EleutherAI/pythia-1.4b</td>\n",
       "      <td>{'cot': 45092, 'dolly': 2818, 'flan_v2': 34790, 'oasst1': 118847}</td>\n",
       "      <td>26.919242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>28.792578</td>\n",
       "      <td>17.688223</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>gpt2m_all_mix=cot:40031,dolly:6009,flan_v2:40031,oasst1:13928</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'cot': 40031, 'dolly': 6009, 'flan_v2': 40031, 'oasst1': 13928}</td>\n",
       "      <td>23.023786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.827929</td>\n",
       "      <td>7.918454</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:49222,dolly:19548,flan_v2:27948,oasst1:103280</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 49222, 'dolly': 19548, 'flan_v2': 27948, 'oasst1': 103280}</td>\n",
       "      <td>31.761857</td>\n",
       "      <td>33.805726</td>\n",
       "      <td>23.0</td>\n",
       "      <td>34.887414</td>\n",
       "      <td>40.839934</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gpt2m_all_mix=cot:50000,dolly:50000,flan_v2:50000,oasst1:50000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'cot': 50000, 'dolly': 50000, 'flan_v2': 50000, 'oasst1': 50000}</td>\n",
       "      <td>22.938328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>29.973845</td>\n",
       "      <td>7.962404</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>llama-7b_all_mix=cot:15356,dolly:894,flan_v2:182740,oasst1:1814</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 15356, 'dolly': 894, 'flan_v2': 182740, 'oasst1': 1814}</td>\n",
       "      <td>44.601909</td>\n",
       "      <td>47.044581</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37.147236</td>\n",
       "      <td>44.361673</td>\n",
       "      <td>1.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>gpt2m_all:50k_mix=cot:5635,dolly:697,flan_v2:43630,oasst1:69</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 5635, 'dolly': 697, 'flan_v2': 43630, 'oasst1': 69}</td>\n",
       "      <td>22.852870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.429958</td>\n",
       "      <td>8.441289</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:490,dolly:26549,flan_v2:2453,oasst1:170506</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 490, 'dolly': 26549, 'flan_v2': 2453, 'oasst1': 170506}</td>\n",
       "      <td>36.754024</td>\n",
       "      <td>36.376585</td>\n",
       "      <td>11.5</td>\n",
       "      <td>33.211391</td>\n",
       "      <td>38.800389</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>gpt2m_all_mix=code_alpaca:100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'code_alpaca': 100000}</td>\n",
       "      <td>22.966814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>26.876242</td>\n",
       "      <td>5.525014</td>\n",
       "      <td>1.219512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>gpt2m_all_mix=baize:100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'baize': 100000}</td>\n",
       "      <td>22.924085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>25.485221</td>\n",
       "      <td>4.139038</td>\n",
       "      <td>0.609756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>gpt2m_all:10k_mix=cot:2500,dolly:2500,flan_v2:2500,oasst1:2500</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 2500, 'dolly': 2500, 'flan_v2': 2500, 'oasst1': 2500}</td>\n",
       "      <td>22.852870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.637130</td>\n",
       "      <td>5.612540</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>gpt2m_all:50k_mix=cot:24392,dolly:366,flan_v2:24392,oasst1:848</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 24392, 'dolly': 366, 'flan_v2': 24392, 'oasst1': 848}</td>\n",
       "      <td>22.895599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.028842</td>\n",
       "      <td>6.055629</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:75328,dolly:17492,flan_v2:79481,oasst1:27697</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 75328, 'dolly': 17492, 'flan_v2': 79481, 'oasst1': 27697}</td>\n",
       "      <td>40.400228</td>\n",
       "      <td>41.048284</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.952418</td>\n",
       "      <td>43.575529</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>gpt2m_all:10k_mix=cot:1127,dolly:139,flan_v2:8726,oasst1:13</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 1127, 'dolly': 139, 'flan_v2': 8726, 'oasst1': 13}</td>\n",
       "      <td>23.159094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>29.467971</td>\n",
       "      <td>4.975758</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>llama-7b_all:100k_mix=cot:48785,dolly:732,flan_v2:48785,oasst1:1697</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 48785, 'dolly': 732, 'flan_v2': 48785, 'oasst1': 1697}</td>\n",
       "      <td>41.618003</td>\n",
       "      <td>41.511181</td>\n",
       "      <td>24.0</td>\n",
       "      <td>35.729399</td>\n",
       "      <td>42.271038</td>\n",
       "      <td>3.658537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:17126,dolly:108593,flan_v2:69580,oasst1:2066</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 17126, 'dolly': 108593, 'flan_v2': 69580, 'oasst1': 2066}</td>\n",
       "      <td>41.632246</td>\n",
       "      <td>43.042302</td>\n",
       "      <td>14.0</td>\n",
       "      <td>35.015191</td>\n",
       "      <td>42.118982</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:81395,dolly:12637,flan_v2:19009,oasst1:86957</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 81395, 'dolly': 12637, 'flan_v2': 19009, 'oasst1': 86957}</td>\n",
       "      <td>41.155106</td>\n",
       "      <td>42.080900</td>\n",
       "      <td>27.5</td>\n",
       "      <td>33.232636</td>\n",
       "      <td>40.231666</td>\n",
       "      <td>2.439024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:36468,dolly:32706,flan_v2:65412,oasst1:65412</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 36468, 'dolly': 32706, 'flan_v2': 65412, 'oasst1': 65412}</td>\n",
       "      <td>40.143854</td>\n",
       "      <td>41.603760</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.675510</td>\n",
       "      <td>44.314453</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>gpt2m_all_mix=self_instruct:100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'self_instruct': 100000}</td>\n",
       "      <td>23.557898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.590479</td>\n",
       "      <td>6.140904</td>\n",
       "      <td>1.219512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>gpt2m_all_mix=cot:100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'cot': 100000}</td>\n",
       "      <td>23.016664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.558459</td>\n",
       "      <td>7.495874</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>pythia-2.8b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394</td>\n",
       "      <td>results/baselines/EleutherAI/pythia-2.8b</td>\n",
       "      <td>{'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}</td>\n",
       "      <td>24.690215</td>\n",
       "      <td>26.107392</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.050268</td>\n",
       "      <td>5.821908</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>gpt2m_all_mix=gpt4_alpaca:100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'gpt4_alpaca': 100000}</td>\n",
       "      <td>23.052272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25.812740</td>\n",
       "      <td>4.294121</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}</td>\n",
       "      <td>42.294545</td>\n",
       "      <td>44.309927</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.604393</td>\n",
       "      <td>42.691039</td>\n",
       "      <td>3.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>gpt2m_all_mix=super_ni:100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'super_ni': 100000}</td>\n",
       "      <td>23.151973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.258770</td>\n",
       "      <td>7.116692</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                               run_name  \\\n",
       "0                                                                                                                                                                                                              llama-7b   \n",
       "1                                                                                                                                                                                                     llama-7b_humanmix   \n",
       "2                                                                                                                                                                                           gpt2m_all_mix=oasst1:100000   \n",
       "3                                                                                                                                                          gpt2m_all_mix=cot:15356,dolly:894,flan_v2:182740,oasst1:1814   \n",
       "4                                                                                                                                                llama-7b_all:400k_mix=cot:195140,dolly:2929,flan_v2:195140,oasst1:6789   \n",
       "5                                                                                                                                                          gpt2m_all_mix=cot:22540,dolly:2790,flan_v2:174520,oasst1:278   \n",
       "6                                                                                                                                                  llama-7b_all:200k_mix=cot:46128,dolly:9386,flan_v2:144243,oasst1:240   \n",
       "7                                                                                                                                               llama-7b_all:600k_mix=cot:292710,dolly:4393,flan_v2:292710,oasst1:10184   \n",
       "8                                                                                                                                                                                         gpt2m_all_mix=sharegpt:100000   \n",
       "9                                                                                                                                               llama-7b_all:200k_mix=cot:22489,dolly:43994,flan_v2:116533,oasst1:16983   \n",
       "10                                                                                                                                              llama-7b_all:200k_mix=cot:27757,dolly:11372,flan_v2:134027,oasst1:26843   \n",
       "11                                                                                                                                               llama-7b_all:200k_mix=cot:55409,dolly:114245,flan_v2:4988,oasst1:25357   \n",
       "12                                                                                                                                                  llama-7b_all:100k_mix=cot:11270,dolly:1395,flan_v2:87260,oasst1:139   \n",
       "13                                                                                                                                                  gpt2m_all:200k_mix=cot:27136,dolly:11929,flan_v2:79155,oasst1:81778   \n",
       "14                                                                                                                                              pythia-6.9b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394   \n",
       "15                                                                                                                                                                                 gpt2m_all_mix=stanford_alpaca:100000   \n",
       "16  gpt2m_all_mix=baize:16666,code_alpaca:16666,cot:16666,dolly:16666,flan_v2:16666,gpt4_alpaca:16666,oasst1:16666,self_instruct:16666,sharegpt:16666,stanford_alpaca:16666,super_ni:16666,unnatural_instructions:16666   \n",
       "17              gpt2m_all_mix=baize:8333,code_alpaca:8333,cot:8333,dolly:8333,flan_v2:8333,gpt4_alpaca:8333,oasst1:8333,self_instruct:8333,sharegpt:8333,stanford_alpaca:8333,super_ni:8333,unnatural_instructions:8333   \n",
       "18                                                                                                                                 llama-7b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394_withreplacement   \n",
       "19                                                                                                                                              pythia-1.4b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394   \n",
       "20                                                                                                                                                                                           gpt2m_all_mix=dolly:100000   \n",
       "21                                                                                                                                               llama-7b_all:200k_mix=cot:22839,dolly:20483,flan_v2:40966,oasst1:40966   \n",
       "22                                                                                                                                                   gpt2m_all:50k_mix=cot:12500,dolly:12500,flan_v2:12500,oasst1:12500   \n",
       "23                                                                                                                                               llama-7b_all:200k_mix=cot:44759,dolly:61131,flan_v2:30915,oasst1:63193   \n",
       "24                                                                                                                                               llama-7b_all:100k_mix=cot:25000,dolly:25000,flan_v2:25000,oasst1:25000   \n",
       "25                                                                                                                                                                                         gpt2m_all_mix=flan_v2:100000   \n",
       "26                                                                                                                                               llama-7b_all:200k_mix=cot:50000,dolly:50000,flan_v2:50000,oasst1:50000   \n",
       "27                                                                                                                                                                          gpt2m_all_mix=unnatural_instructions:100000   \n",
       "28                                                                                                                                               llama-7b_all:200k_mix=cot:27136,dolly:11929,flan_v2:79155,oasst1:81778   \n",
       "29                                                                                                                                                llama-7b_all:200k_mix=cot:6323,dolly:40966,flan_v2:81933,oasst1:81933   \n",
       "30                                                                                                                                                          gpt2m_all:10k_mix=cot:4878,dolly:73,flan_v2:4878,oasst1:169   \n",
       "31                                                                                                                                               llama-7b_all:200k_mix=cot:16131,dolly:83772,flan_v2:43447,oasst1:56648   \n",
       "32                                                                                                                                                       gpt2m_all_mix=cot:25000,dolly:25000,flan_v2:25000,oasst1:25000   \n",
       "33                                                                                                                                               pythia-1.4b_all:200k_mix=cot:72119,dolly:439,flan_v2:126074,oasst1:339   \n",
       "34                                                                                                                                            pythia-1.4b_all:200k_mix=cot:45092,dolly:2818,flan_v2:34790,oasst1:118847   \n",
       "35                                                                                                                                                        gpt2m_all_mix=cot:40031,dolly:6009,flan_v2:40031,oasst1:13928   \n",
       "36                                                                                                                                              llama-7b_all:200k_mix=cot:49222,dolly:19548,flan_v2:27948,oasst1:103280   \n",
       "37                                                                                                                                                       gpt2m_all_mix=cot:50000,dolly:50000,flan_v2:50000,oasst1:50000   \n",
       "38                                                                                                                                                      llama-7b_all_mix=cot:15356,dolly:894,flan_v2:182740,oasst1:1814   \n",
       "39                                                                                                                                                         gpt2m_all:50k_mix=cot:5635,dolly:697,flan_v2:43630,oasst1:69   \n",
       "40                                                                                                                                                 llama-7b_all:200k_mix=cot:490,dolly:26549,flan_v2:2453,oasst1:170506   \n",
       "41                                                                                                                                                                                     gpt2m_all_mix=code_alpaca:100000   \n",
       "42                                                                                                                                                                                           gpt2m_all_mix=baize:100000   \n",
       "43                                                                                                                                                       gpt2m_all:10k_mix=cot:2500,dolly:2500,flan_v2:2500,oasst1:2500   \n",
       "44                                                                                                                                                       gpt2m_all:50k_mix=cot:24392,dolly:366,flan_v2:24392,oasst1:848   \n",
       "45                                                                                                                                               llama-7b_all:200k_mix=cot:75328,dolly:17492,flan_v2:79481,oasst1:27697   \n",
       "46                                                                                                                                                          gpt2m_all:10k_mix=cot:1127,dolly:139,flan_v2:8726,oasst1:13   \n",
       "47                                                                                                                                                  llama-7b_all:100k_mix=cot:48785,dolly:732,flan_v2:48785,oasst1:1697   \n",
       "48                                                                                                                                               llama-7b_all:200k_mix=cot:17126,dolly:108593,flan_v2:69580,oasst1:2066   \n",
       "49                                                                                                                                               llama-7b_all:200k_mix=cot:81395,dolly:12637,flan_v2:19009,oasst1:86957   \n",
       "50                                                                                                                                               llama-7b_all:200k_mix=cot:36468,dolly:32706,flan_v2:65412,oasst1:65412   \n",
       "51                                                                                                                                                                                   gpt2m_all_mix=self_instruct:100000   \n",
       "52                                                                                                                                                                                             gpt2m_all_mix=cot:100000   \n",
       "53                                                                                                                                              pythia-2.8b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394   \n",
       "54                                                                                                                                                                                     gpt2m_all_mix=gpt4_alpaca:100000   \n",
       "55                                                                                                                                                 llama-7b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394   \n",
       "56                                                                                                                                                                                        gpt2m_all_mix=super_ni:100000   \n",
       "\n",
       "               model_args.model_name_or_path  \\\n",
       "0                        huggyllama/llama-7b   \n",
       "1      results/baselines/huggyllama/llama-7b   \n",
       "2                                gpt2-medium   \n",
       "3              results/baselines/gpt2-medium   \n",
       "4      results/baselines/huggyllama/llama-7b   \n",
       "5              results/baselines/gpt2-medium   \n",
       "6      results/baselines/huggyllama/llama-7b   \n",
       "7      results/baselines/huggyllama/llama-7b   \n",
       "8                                gpt2-medium   \n",
       "9      results/baselines/huggyllama/llama-7b   \n",
       "10     results/baselines/huggyllama/llama-7b   \n",
       "11     results/baselines/huggyllama/llama-7b   \n",
       "12     results/baselines/huggyllama/llama-7b   \n",
       "13             results/baselines/gpt2-medium   \n",
       "14  results/baselines/EleutherAI/pythia-6.9b   \n",
       "15                               gpt2-medium   \n",
       "16                               gpt2-medium   \n",
       "17                               gpt2-medium   \n",
       "18     results/baselines/huggyllama/llama-7b   \n",
       "19  results/baselines/EleutherAI/pythia-1.4b   \n",
       "20                               gpt2-medium   \n",
       "21     results/baselines/huggyllama/llama-7b   \n",
       "22             results/baselines/gpt2-medium   \n",
       "23     results/baselines/huggyllama/llama-7b   \n",
       "24     results/baselines/huggyllama/llama-7b   \n",
       "25                               gpt2-medium   \n",
       "26     results/baselines/huggyllama/llama-7b   \n",
       "27                               gpt2-medium   \n",
       "28     results/baselines/huggyllama/llama-7b   \n",
       "29     results/baselines/huggyllama/llama-7b   \n",
       "30             results/baselines/gpt2-medium   \n",
       "31     results/baselines/huggyllama/llama-7b   \n",
       "32                               gpt2-medium   \n",
       "33  results/baselines/EleutherAI/pythia-1.4b   \n",
       "34  results/baselines/EleutherAI/pythia-1.4b   \n",
       "35                               gpt2-medium   \n",
       "36     results/baselines/huggyllama/llama-7b   \n",
       "37                               gpt2-medium   \n",
       "38     results/baselines/huggyllama/llama-7b   \n",
       "39             results/baselines/gpt2-medium   \n",
       "40     results/baselines/huggyllama/llama-7b   \n",
       "41                               gpt2-medium   \n",
       "42                               gpt2-medium   \n",
       "43             results/baselines/gpt2-medium   \n",
       "44             results/baselines/gpt2-medium   \n",
       "45     results/baselines/huggyllama/llama-7b   \n",
       "46             results/baselines/gpt2-medium   \n",
       "47     results/baselines/huggyllama/llama-7b   \n",
       "48     results/baselines/huggyllama/llama-7b   \n",
       "49     results/baselines/huggyllama/llama-7b   \n",
       "50     results/baselines/huggyllama/llama-7b   \n",
       "51                               gpt2-medium   \n",
       "52                               gpt2-medium   \n",
       "53  results/baselines/EleutherAI/pythia-2.8b   \n",
       "54                               gpt2-medium   \n",
       "55     results/baselines/huggyllama/llama-7b   \n",
       "56                               gpt2-medium   \n",
       "\n",
       "                                                                                                                                                                                                                               data_args.subsample_mixture  \\\n",
       "0                                                                                                                                                                                                                                                       {}   \n",
       "1                                                                                                                                                                                                                                                       {}   \n",
       "2                                                                                                                                                                                                                                       {'oasst1': 100000}   \n",
       "3                                                                                                                                                                                          {'cot': 15356, 'dolly': 894, 'flan_v2': 182740, 'oasst1': 1814}   \n",
       "4                                                                                                                                                                                        {'cot': 195140, 'dolly': 2929, 'flan_v2': 195140, 'oasst1': 6789}   \n",
       "5                                                                                                                                                                                          {'cot': 22540, 'dolly': 2790, 'flan_v2': 174520, 'oasst1': 278}   \n",
       "6                                                                                                                                                                                          {'cot': 46128, 'dolly': 9386, 'flan_v2': 144243, 'oasst1': 240}   \n",
       "7                                                                                                                                                                                       {'cot': 292710, 'dolly': 4393, 'flan_v2': 292710, 'oasst1': 10184}   \n",
       "8                                                                                                                                                                                                                                     {'sharegpt': 100000}   \n",
       "9                                                                                                                                                                                       {'cot': 22489, 'dolly': 43994, 'flan_v2': 116533, 'oasst1': 16983}   \n",
       "10                                                                                                                                                                                      {'cot': 27757, 'dolly': 11372, 'flan_v2': 134027, 'oasst1': 26843}   \n",
       "11                                                                                                                                                                                       {'cot': 55409, 'dolly': 114245, 'flan_v2': 4988, 'oasst1': 25357}   \n",
       "12                                                                                                                                                                                          {'cot': 11270, 'dolly': 1395, 'flan_v2': 87260, 'oasst1': 139}   \n",
       "13                                                                                                                                                                                       {'cot': 27136, 'dolly': 11929, 'flan_v2': 79155, 'oasst1': 81778}   \n",
       "14                                                                                                                                                                                         {'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}   \n",
       "15                                                                                                                                                                                                                             {'stanford_alpaca': 100000}   \n",
       "16  {'baize': 16666, 'code_alpaca': 16666, 'cot': 16666, 'dolly': 16666, 'flan_v2': 16666, 'gpt4_alpaca': 16666, 'oasst1': 16666, 'self_instruct': 16666, 'sharegpt': 16666, 'stanford_alpaca': 16666, 'super_ni': 16666, 'unnatural_instructions': 16666}   \n",
       "17              {'baize': 8333, 'code_alpaca': 8333, 'cot': 8333, 'dolly': 8333, 'flan_v2': 8333, 'gpt4_alpaca': 8333, 'oasst1': 8333, 'self_instruct': 8333, 'sharegpt': 8333, 'stanford_alpaca': 8333, 'super_ni': 8333, 'unnatural_instructions': 8333}   \n",
       "18                                                                                                                                                                                         {'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}   \n",
       "19                                                                                                                                                                                         {'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}   \n",
       "20                                                                                                                                                                                                                                       {'dolly': 100000}   \n",
       "21                                                                                                                                                                                       {'cot': 22839, 'dolly': 20483, 'flan_v2': 40966, 'oasst1': 40966}   \n",
       "22                                                                                                                                                                                       {'cot': 12500, 'dolly': 12500, 'flan_v2': 12500, 'oasst1': 12500}   \n",
       "23                                                                                                                                                                                       {'cot': 44759, 'dolly': 61131, 'flan_v2': 30915, 'oasst1': 63193}   \n",
       "24                                                                                                                                                                                       {'cot': 25000, 'dolly': 25000, 'flan_v2': 25000, 'oasst1': 25000}   \n",
       "25                                                                                                                                                                                                                                     {'flan_v2': 100000}   \n",
       "26                                                                                                                                                                                       {'cot': 50000, 'dolly': 50000, 'flan_v2': 50000, 'oasst1': 50000}   \n",
       "27                                                                                                                                                                                                                      {'unnatural_instructions': 100000}   \n",
       "28                                                                                                                                                                                       {'cot': 27136, 'dolly': 11929, 'flan_v2': 79155, 'oasst1': 81778}   \n",
       "29                                                                                                                                                                                        {'cot': 6323, 'dolly': 40966, 'flan_v2': 81933, 'oasst1': 81933}   \n",
       "30                                                                                                                                                                                              {'cot': 4878, 'dolly': 73, 'flan_v2': 4878, 'oasst1': 169}   \n",
       "31                                                                                                                                                                                       {'cot': 16131, 'dolly': 83772, 'flan_v2': 43447, 'oasst1': 56648}   \n",
       "32                                                                                                                                                                                       {'cot': 25000, 'dolly': 25000, 'flan_v2': 25000, 'oasst1': 25000}   \n",
       "33                                                                                                                                                                                          {'cot': 72119, 'dolly': 439, 'flan_v2': 126074, 'oasst1': 339}   \n",
       "34                                                                                                                                                                                       {'cot': 45092, 'dolly': 2818, 'flan_v2': 34790, 'oasst1': 118847}   \n",
       "35                                                                                                                                                                                        {'cot': 40031, 'dolly': 6009, 'flan_v2': 40031, 'oasst1': 13928}   \n",
       "36                                                                                                                                                                                      {'cot': 49222, 'dolly': 19548, 'flan_v2': 27948, 'oasst1': 103280}   \n",
       "37                                                                                                                                                                                       {'cot': 50000, 'dolly': 50000, 'flan_v2': 50000, 'oasst1': 50000}   \n",
       "38                                                                                                                                                                                         {'cot': 15356, 'dolly': 894, 'flan_v2': 182740, 'oasst1': 1814}   \n",
       "39                                                                                                                                                                                             {'cot': 5635, 'dolly': 697, 'flan_v2': 43630, 'oasst1': 69}   \n",
       "40                                                                                                                                                                                         {'cot': 490, 'dolly': 26549, 'flan_v2': 2453, 'oasst1': 170506}   \n",
       "41                                                                                                                                                                                                                                 {'code_alpaca': 100000}   \n",
       "42                                                                                                                                                                                                                                       {'baize': 100000}   \n",
       "43                                                                                                                                                                                           {'cot': 2500, 'dolly': 2500, 'flan_v2': 2500, 'oasst1': 2500}   \n",
       "44                                                                                                                                                                                           {'cot': 24392, 'dolly': 366, 'flan_v2': 24392, 'oasst1': 848}   \n",
       "45                                                                                                                                                                                       {'cot': 75328, 'dolly': 17492, 'flan_v2': 79481, 'oasst1': 27697}   \n",
       "46                                                                                                                                                                                              {'cot': 1127, 'dolly': 139, 'flan_v2': 8726, 'oasst1': 13}   \n",
       "47                                                                                                                                                                                          {'cot': 48785, 'dolly': 732, 'flan_v2': 48785, 'oasst1': 1697}   \n",
       "48                                                                                                                                                                                       {'cot': 17126, 'dolly': 108593, 'flan_v2': 69580, 'oasst1': 2066}   \n",
       "49                                                                                                                                                                                       {'cot': 81395, 'dolly': 12637, 'flan_v2': 19009, 'oasst1': 86957}   \n",
       "50                                                                                                                                                                                       {'cot': 36468, 'dolly': 32706, 'flan_v2': 65412, 'oasst1': 65412}   \n",
       "51                                                                                                                                                                                                                               {'self_instruct': 100000}   \n",
       "52                                                                                                                                                                                                                                         {'cot': 100000}   \n",
       "53                                                                                                                                                                                         {'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}   \n",
       "54                                                                                                                                                                                                                                 {'gpt4_alpaca': 100000}   \n",
       "55                                                                                                                                                                                         {'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}   \n",
       "56                                                                                                                                                                                                                                    {'super_ni': 100000}   \n",
       "\n",
       "    MMLU/0-shot  MMLU/5-shot  GSM/CoT  BBH/Direct  TydiQA/GP  \\\n",
       "0     32.459764    33.057969     11.0   32.970313  38.564264   \n",
       "1     43.547928    46.460618     29.0   36.114618  43.481729   \n",
       "2     22.973935          NaN      0.0   24.000967   6.326418   \n",
       "3     23.045150          NaN      3.5   30.422551   7.712177   \n",
       "4     44.003703    45.378151     25.5   36.525510  39.450704   \n",
       "5     23.123487          NaN      1.5   29.677548   8.898066   \n",
       "6     43.904002    46.368039     17.0   36.159018  45.712140   \n",
       "7     41.354508    44.338413     25.0   36.350256  40.963928   \n",
       "8     23.052272          NaN      2.0   26.323305   3.702220   \n",
       "9     43.255946    45.150263     15.0   36.486059  38.651060   \n",
       "10    41.995442    44.288563     19.5   37.408689  44.361642   \n",
       "11    28.364905    28.649765     19.5   35.042380  40.504711   \n",
       "12    40.734938    43.035180     10.0   35.295402  46.169230   \n",
       "13    23.080758          NaN      1.0   29.355884   9.470316   \n",
       "14          NaN    25.836775      6.5   30.429888  26.516632   \n",
       "15    22.988178          NaN      2.5   27.052148   5.113901   \n",
       "16    23.016664          NaN      3.0   29.758117   7.950251   \n",
       "17    22.938328          NaN      0.5   30.391050   5.948287   \n",
       "18    42.572283    44.224469     23.5   34.212314  42.805747   \n",
       "19    25.331149          NaN      6.0   29.693163  21.630193   \n",
       "20    22.810141          NaN      1.5   15.476953   5.569227   \n",
       "21    42.486825    41.952713     17.0   34.763686  43.925070   \n",
       "22    22.952571          NaN      3.0   30.284956   7.082380   \n",
       "23    38.406210    38.541518     22.5   34.556323  46.566055   \n",
       "24    40.279163    38.128472     13.5   33.489712  43.019298   \n",
       "25    23.002421          NaN      3.0   29.757914   8.841241   \n",
       "26    34.076342    38.883350     19.5   33.958081  42.187476   \n",
       "27    23.201823          NaN      1.0   29.127942   4.095138   \n",
       "28    42.472582    42.508190     15.5   35.848182  44.080953   \n",
       "29    40.044153    41.895741     18.5   35.279586  41.282352   \n",
       "30    22.945449          NaN      3.5   28.108541   6.646854   \n",
       "31    39.196696    37.971799     17.0   34.468655  44.297010   \n",
       "32    22.938328          NaN      2.5   29.980136   7.088936   \n",
       "33    25.737074          NaN      2.5   27.521610  20.432359   \n",
       "34    26.919242          NaN      2.5   28.792578  17.688223   \n",
       "35    23.023786          NaN      2.5   29.827929   7.918454   \n",
       "36    31.761857    33.805726     23.0   34.887414  40.839934   \n",
       "37    22.938328          NaN      1.5   29.973845   7.962404   \n",
       "38    44.601909    47.044581     14.0   37.147236  44.361673   \n",
       "39    22.852870          NaN      3.0   29.429958   8.441289   \n",
       "40    36.754024    36.376585     11.5   33.211391  38.800389   \n",
       "41    22.966814          NaN      0.5   26.876242   5.525014   \n",
       "42    22.924085          NaN      1.5   25.485221   4.139038   \n",
       "43    22.852870          NaN      1.0   24.637130   5.612540   \n",
       "44    22.895599          NaN      3.0   30.028842   6.055629   \n",
       "45    40.400228    41.048284     22.0   35.952418  43.575529   \n",
       "46    23.159094          NaN      3.5   29.467971   4.975758   \n",
       "47    41.618003    41.511181     24.0   35.729399  42.271038   \n",
       "48    41.632246    43.042302     14.0   35.015191  42.118982   \n",
       "49    41.155106    42.080900     27.5   33.232636  40.231666   \n",
       "50    40.143854    41.603760     21.0   34.675510  44.314453   \n",
       "51    23.557898          NaN      2.5   29.590479   6.140904   \n",
       "52    23.016664          NaN      0.0   27.558459   7.495874   \n",
       "53    24.690215    26.107392      0.5   22.050268   5.821908   \n",
       "54    23.052272          NaN      0.5   25.812740   4.294121   \n",
       "55    42.294545    44.309927     25.0   36.604393  42.691039   \n",
       "56    23.151973          NaN      2.5   29.258770   7.116692   \n",
       "\n",
       "    Codex-Eval/Pass@1  \n",
       "0            0.000000  \n",
       "1           10.365854  \n",
       "2            0.000000  \n",
       "3            0.000000  \n",
       "4           10.975610  \n",
       "5            0.609756  \n",
       "6            4.268293  \n",
       "7            9.756098  \n",
       "8            0.000000  \n",
       "9            3.048780  \n",
       "10           0.609756  \n",
       "11           0.000000  \n",
       "12           7.317073  \n",
       "13           0.000000  \n",
       "14           0.000000  \n",
       "15           0.609756  \n",
       "16           1.219512  \n",
       "17           0.609756  \n",
       "18           6.707317  \n",
       "19           0.000000  \n",
       "20           0.000000  \n",
       "21           0.609756  \n",
       "22           0.000000  \n",
       "23           1.219512  \n",
       "24           0.609756  \n",
       "25           0.000000  \n",
       "26           1.219512  \n",
       "27           1.829268  \n",
       "28           0.000000  \n",
       "29           0.000000  \n",
       "30           0.000000  \n",
       "31           0.000000  \n",
       "32           0.000000  \n",
       "33           0.000000  \n",
       "34           0.000000  \n",
       "35           0.000000  \n",
       "36           0.000000  \n",
       "37           0.000000  \n",
       "38           1.829268  \n",
       "39           0.000000  \n",
       "40           0.000000  \n",
       "41           1.219512  \n",
       "42           0.609756  \n",
       "43           0.000000  \n",
       "44           0.000000  \n",
       "45           0.000000  \n",
       "46           0.000000  \n",
       "47           3.658537  \n",
       "48           0.000000  \n",
       "49           2.439024  \n",
       "50           0.000000  \n",
       "51           1.219512  \n",
       "52           0.000000  \n",
       "53           0.000000  \n",
       "54           0.000000  \n",
       "55           3.048780  \n",
       "56           0.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_eval_results(save_dirs, chat_fmt=True, ft_args_fields=ft_args_fields)\n",
    "cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "df = df[ft_args_fields+cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1276df08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>model_args.model_name_or_path</th>\n",
       "      <th>data_args.subsample_mixture</th>\n",
       "      <th>MMLU/0-shot</th>\n",
       "      <th>MMLU/5-shot</th>\n",
       "      <th>GSM/Direct</th>\n",
       "      <th>GSM/CoT</th>\n",
       "      <th>BBH/Direct</th>\n",
       "      <th>BBH/CoT</th>\n",
       "      <th>Codex-Eval/Pass@1</th>\n",
       "      <th>TydiQA/CB</th>\n",
       "      <th>TydiQA/GP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama-7b_all:100k_mix=cot:11270,dolly:1395,flan_v2:87260,oasst1:139</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 11270, 'dolly': 1395, 'flan_v2': 87260, 'oasst1': 139}</td>\n",
       "      <td>40.734938</td>\n",
       "      <td>43.035180</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.295402</td>\n",
       "      <td>32.870370</td>\n",
       "      <td>7.317073</td>\n",
       "      <td>12.115113</td>\n",
       "      <td>46.169230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:22839,dolly:20483,flan_v2:40966,oasst1:40966</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 22839, 'dolly': 20483, 'flan_v2': 40966, 'oasst1': 40966}</td>\n",
       "      <td>42.486825</td>\n",
       "      <td>41.952713</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>34.763686</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>8.614819</td>\n",
       "      <td>43.925070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama-7b_all:100k_mix=cot:25000,dolly:25000,flan_v2:25000,oasst1:25000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 25000, 'dolly': 25000, 'flan_v2': 25000, 'oasst1': 25000}</td>\n",
       "      <td>40.279163</td>\n",
       "      <td>38.128472</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>33.489712</td>\n",
       "      <td>28.888889</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>10.456454</td>\n",
       "      <td>43.019298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:50000,dolly:50000,flan_v2:50000,oasst1:50000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 50000, 'dolly': 50000, 'flan_v2': 50000, 'oasst1': 50000}</td>\n",
       "      <td>34.076342</td>\n",
       "      <td>38.883350</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>33.958081</td>\n",
       "      <td>33.148148</td>\n",
       "      <td>1.219512</td>\n",
       "      <td>9.999042</td>\n",
       "      <td>42.187476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:27136,dolly:11929,flan_v2:79155,oasst1:81778</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 27136, 'dolly': 11929, 'flan_v2': 79155, 'oasst1': 81778}</td>\n",
       "      <td>42.472582</td>\n",
       "      <td>42.508190</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>35.848182</td>\n",
       "      <td>33.703704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.264019</td>\n",
       "      <td>44.080953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:6323,dolly:40966,flan_v2:81933,oasst1:81933</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 6323, 'dolly': 40966, 'flan_v2': 81933, 'oasst1': 81933}</td>\n",
       "      <td>40.044153</td>\n",
       "      <td>41.895741</td>\n",
       "      <td>7.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>35.279586</td>\n",
       "      <td>30.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.255578</td>\n",
       "      <td>41.282352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama-7b_all_mix=cot:15356,dolly:894,flan_v2:182740,oasst1:1814</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 15356, 'dolly': 894, 'flan_v2': 182740, 'oasst1': 1814}</td>\n",
       "      <td>44.601909</td>\n",
       "      <td>47.044581</td>\n",
       "      <td>3.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37.147236</td>\n",
       "      <td>31.203704</td>\n",
       "      <td>1.829268</td>\n",
       "      <td>9.934316</td>\n",
       "      <td>44.361673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama-7b_all:100k_mix=cot:48785,dolly:732,flan_v2:48785,oasst1:1697</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 48785, 'dolly': 732, 'flan_v2': 48785, 'oasst1': 1697}</td>\n",
       "      <td>41.618003</td>\n",
       "      <td>41.511181</td>\n",
       "      <td>6.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>35.729399</td>\n",
       "      <td>32.314815</td>\n",
       "      <td>3.658537</td>\n",
       "      <td>10.502093</td>\n",
       "      <td>42.271038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:17126,dolly:108593,flan_v2:69580,oasst1:2066</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 17126, 'dolly': 108593, 'flan_v2': 69580, 'oasst1': 2066}</td>\n",
       "      <td>41.632246</td>\n",
       "      <td>43.042302</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>35.015191</td>\n",
       "      <td>31.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.121318</td>\n",
       "      <td>42.118982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:36468,dolly:32706,flan_v2:65412,oasst1:65412</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 36468, 'dolly': 32706, 'flan_v2': 65412, 'oasst1': 65412}</td>\n",
       "      <td>40.143854</td>\n",
       "      <td>41.603760</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.675510</td>\n",
       "      <td>33.240741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.031233</td>\n",
       "      <td>44.314453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>llama-7b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}</td>\n",
       "      <td>42.294545</td>\n",
       "      <td>44.309927</td>\n",
       "      <td>5.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.604393</td>\n",
       "      <td>33.703704</td>\n",
       "      <td>3.048780</td>\n",
       "      <td>10.026821</td>\n",
       "      <td>42.691039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  run_name  \\\n",
       "0      llama-7b_all:100k_mix=cot:11270,dolly:1395,flan_v2:87260,oasst1:139   \n",
       "1   llama-7b_all:200k_mix=cot:22839,dolly:20483,flan_v2:40966,oasst1:40966   \n",
       "2   llama-7b_all:100k_mix=cot:25000,dolly:25000,flan_v2:25000,oasst1:25000   \n",
       "3   llama-7b_all:200k_mix=cot:50000,dolly:50000,flan_v2:50000,oasst1:50000   \n",
       "4   llama-7b_all:200k_mix=cot:27136,dolly:11929,flan_v2:79155,oasst1:81778   \n",
       "5    llama-7b_all:200k_mix=cot:6323,dolly:40966,flan_v2:81933,oasst1:81933   \n",
       "6          llama-7b_all_mix=cot:15356,dolly:894,flan_v2:182740,oasst1:1814   \n",
       "7      llama-7b_all:100k_mix=cot:48785,dolly:732,flan_v2:48785,oasst1:1697   \n",
       "8   llama-7b_all:200k_mix=cot:17126,dolly:108593,flan_v2:69580,oasst1:2066   \n",
       "9   llama-7b_all:200k_mix=cot:36468,dolly:32706,flan_v2:65412,oasst1:65412   \n",
       "10    llama-7b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394   \n",
       "\n",
       "            model_args.model_name_or_path  \\\n",
       "0   results/baselines/huggyllama/llama-7b   \n",
       "1   results/baselines/huggyllama/llama-7b   \n",
       "2   results/baselines/huggyllama/llama-7b   \n",
       "3   results/baselines/huggyllama/llama-7b   \n",
       "4   results/baselines/huggyllama/llama-7b   \n",
       "5   results/baselines/huggyllama/llama-7b   \n",
       "6   results/baselines/huggyllama/llama-7b   \n",
       "7   results/baselines/huggyllama/llama-7b   \n",
       "8   results/baselines/huggyllama/llama-7b   \n",
       "9   results/baselines/huggyllama/llama-7b   \n",
       "10  results/baselines/huggyllama/llama-7b   \n",
       "\n",
       "                                          data_args.subsample_mixture  \\\n",
       "0      {'cot': 11270, 'dolly': 1395, 'flan_v2': 87260, 'oasst1': 139}   \n",
       "1   {'cot': 22839, 'dolly': 20483, 'flan_v2': 40966, 'oasst1': 40966}   \n",
       "2   {'cot': 25000, 'dolly': 25000, 'flan_v2': 25000, 'oasst1': 25000}   \n",
       "3   {'cot': 50000, 'dolly': 50000, 'flan_v2': 50000, 'oasst1': 50000}   \n",
       "4   {'cot': 27136, 'dolly': 11929, 'flan_v2': 79155, 'oasst1': 81778}   \n",
       "5    {'cot': 6323, 'dolly': 40966, 'flan_v2': 81933, 'oasst1': 81933}   \n",
       "6     {'cot': 15356, 'dolly': 894, 'flan_v2': 182740, 'oasst1': 1814}   \n",
       "7      {'cot': 48785, 'dolly': 732, 'flan_v2': 48785, 'oasst1': 1697}   \n",
       "8   {'cot': 17126, 'dolly': 108593, 'flan_v2': 69580, 'oasst1': 2066}   \n",
       "9   {'cot': 36468, 'dolly': 32706, 'flan_v2': 65412, 'oasst1': 65412}   \n",
       "10    {'cot': 97570, 'dolly': 1464, 'flan_v2': 97570, 'oasst1': 3394}   \n",
       "\n",
       "    MMLU/0-shot  MMLU/5-shot  GSM/Direct  GSM/CoT  BBH/Direct    BBH/CoT  \\\n",
       "0     40.734938    43.035180         6.0     10.0   35.295402  32.870370   \n",
       "1     42.486825    41.952713         6.0     17.0   34.763686  33.333333   \n",
       "2     40.279163    38.128472         6.0     13.5   33.489712  28.888889   \n",
       "3     34.076342    38.883350         5.0     19.5   33.958081  33.148148   \n",
       "4     42.472582    42.508190         4.0     15.5   35.848182  33.703704   \n",
       "5     40.044153    41.895741         7.5     18.5   35.279586  30.277778   \n",
       "6     44.601909    47.044581         3.5     14.0   37.147236  31.203704   \n",
       "7     41.618003    41.511181         6.5     24.0   35.729399  32.314815   \n",
       "8     41.632246    43.042302         7.0     14.0   35.015191  31.018519   \n",
       "9     40.143854    41.603760         5.0     21.0   34.675510  33.240741   \n",
       "10    42.294545    44.309927         5.5     25.0   36.604393  33.703704   \n",
       "\n",
       "    Codex-Eval/Pass@1  TydiQA/CB  TydiQA/GP  \n",
       "0            7.317073  12.115113  46.169230  \n",
       "1            0.609756   8.614819  43.925070  \n",
       "2            0.609756  10.456454  43.019298  \n",
       "3            1.219512   9.999042  42.187476  \n",
       "4            0.000000  10.264019  44.080953  \n",
       "5            0.000000  10.255578  41.282352  \n",
       "6            1.829268   9.934316  44.361673  \n",
       "7            3.658537  10.502093  42.271038  \n",
       "8            0.000000  10.121318  42.118982  \n",
       "9            0.000000   8.031233  44.314453  \n",
       "10           3.048780  10.026821  42.691039  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dir = '../results/ft2'\n",
    "save_dirs = []\n",
    "save_dirs += [(os.path.basename(x), x) for x in \n",
    "              [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if ('llama-7b' in x and 'withreplacement' not in x)]\n",
    "\n",
    "chat_fmt = True\n",
    "\n",
    "dfs = []\n",
    "for model_name, save_dir in save_dirs:\n",
    "    if os.path.islink(save_dir): continue\n",
    "    if not os.path.isfile(os.path.join(save_dir, 'config.json')): continue\n",
    "    if not os.path.isdir(os.path.join(save_dir, 'eval')): continue\n",
    "    r = EvalResults(save_dir, model_name)\n",
    "    df = r.get_result_df(chat_fmt=chat_fmt, ft_args_fields=ft_args_fields)\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs, axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73ce47f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cot': 0.25, 'dolly': 0.25, 'flan_v2': 0.25, 'oasst1': 0.25},\n",
       " {'cot': 0.13568135681356813,\n",
       "  'dolly': 0.05964559645596456,\n",
       "  'flan_v2': 0.3957789577895779,\n",
       "  'oasst1': 0.4088940889408894},\n",
       " {'cot': 0.029944827259596032,\n",
       "  'dolly': 0.19400914020506263,\n",
       "  'flan_v2': 0.38802301626767066,\n",
       "  'oasst1': 0.38802301626767066},\n",
       " {'cot': 0.07647258022748551,\n",
       "  'dolly': 0.004452102547758013,\n",
       "  'flan_v2': 0.9100416326368,\n",
       "  'oasst1': 0.009033684587956415},\n",
       " {'cot': 0.08677323740278164,\n",
       "  'dolly': 0.5502140703772199,\n",
       "  'flan_v2': 0.352544777442809,\n",
       "  'oasst1': 0.01046791477718947},\n",
       " {'cot': 0.18234182341823418,\n",
       "  'dolly': 0.16353163531635317,\n",
       "  'flan_v2': 0.32706327063270635,\n",
       "  'oasst1': 0.32706327063270635},\n",
       " {'cot': 0.4878548785487855,\n",
       "  'dolly': 0.007320073200732007,\n",
       "  'flan_v2': 0.4878548785487855,\n",
       "  'oasst1': 0.016970169701697017}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc = df.copy()\n",
    "\n",
    "total_train_samples = 200000\n",
    "dfc.insert(0, 'total_train_samples',  dfc['data_args.subsample_mixture'].apply(\n",
    "    lambda d: sum(list(d.values())) if d else 200000))\n",
    "dfc = dfc[dfc['total_train_samples'].apply(\n",
    "    lambda x: total_train_samples-20000<x<total_train_samples+20000)]\n",
    "\n",
    "mixtures = [dict(x) for x in dfc['data_args.subsample_mixture']]\n",
    "mixtures = [{k: v/sum(list(d.values())) for k, v in d.items()} for d in mixtures]\n",
    "mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0741ca82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cot': 0.37664033529374275,\n",
       "  'dolly': 0.0874640765523398,\n",
       "  'flan_v2': 0.39740799933549775,\n",
       "  'oasst1': 0.1384875888184196},\n",
       " {'cot': 0.23064419241874784,\n",
       "  'dolly': 0.04693354147889885,\n",
       "  'flan_v2': 0.72121745986295,\n",
       "  'oasst1': 0.0012048062394032465},\n",
       " {'cot': 0.11244721555034376,\n",
       "  'dolly': 0.21997027355988638,\n",
       "  'flan_v2': 0.5826671754210359,\n",
       "  'oasst1': 0.08491533546873392},\n",
       " {'cot': 0.27704626812045546,\n",
       "  'dolly': 0.5712282144637615,\n",
       "  'flan_v2': 0.024940119654536592,\n",
       "  'oasst1': 0.12678539776124645},\n",
       " {'cot': 0.0024519793352964607,\n",
       "  'dolly': 0.13274603201304974,\n",
       "  'flan_v2': 0.012268378167304219,\n",
       "  'oasst1': 0.8525336104843496},\n",
       " {'cot': 0.08065633865016615,\n",
       "  'dolly': 0.41886215168938545,\n",
       "  'flan_v2': 0.21723932820070485,\n",
       "  'oasst1': 0.2832421814597436},\n",
       " {'cot': 0.13878643021160036,\n",
       "  'dolly': 0.05686171157146557,\n",
       "  'flan_v2': 0.6701353469446995,\n",
       "  'oasst1': 0.13421651127223455},\n",
       " {'cot': 0.2461125374866837,\n",
       "  'dolly': 0.09774240280444893,\n",
       "  'flan_v2': 0.13974091986040005,\n",
       "  'oasst1': 0.5164041398484672},\n",
       " {'cot': 0.4069781049152398,\n",
       "  'dolly': 0.06318759506033228,\n",
       "  'flan_v2': 0.09504719644992135,\n",
       "  'oasst1': 0.4347871035745066},\n",
       " {'cot': 0.22379693013848484,\n",
       "  'dolly': 0.30565901275011814,\n",
       "  'flan_v2': 0.15457716965000887,\n",
       "  'oasst1': 0.31596688746138824}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def runif_in_simplex(n):\n",
    "    ''' Return uniformly random vector in the n-simplex '''\n",
    "\n",
    "    k = np.random.exponential(scale=1.0, size=n)\n",
    "    return k / sum(k)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "np.random.seed(4)\n",
    "\n",
    "L = []\n",
    "dataset_name = ['cot', 'dolly', 'flan_v2', 'oasst1']\n",
    "xs = np.arange(4)\n",
    "for _ in range(10):\n",
    "    ys = runif_in_simplex(4)\n",
    "    d = {k: v for k, v in zip(dataset_name, ys)}\n",
    "    L.append(d)\n",
    "    ax.plot(xs, ys)\n",
    "L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39ea7782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dirs = []\n",
    "run_dirs = [\n",
    "#     'pythia-1.4b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "#     'pythia-2.8b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "    'pythia-6.9b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "]\n",
    "for run_dir in run_dirs:\n",
    "    save_dirs += [(os.path.basename(x), x) \n",
    "                  for x in glob.glob(os.path.join('../results/ft2', run_dir, 'checkpoint-*'))]\n",
    "    break\n",
    "\n",
    "    \n",
    "df = get_eval_results(save_dirs, chat_fmt=None, ft_args_fields=ft_args_fields)\n",
    "# df['model'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dcb043d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACUQAAAGsCAYAAAAfPj9sAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3yN1x/A8c/Nzd4kZBCCIEKM2ns0ipbaM/auUjVqVGvUHrWL1lbUqJY0NkXt2JSQGImVCInsnXt/f+SXW1d2kMH3/XrlRZ7nPOece27uc57n3O9zjkKtVqsRQgghhBBCCCGEEEIIIYQQQgghhBBCiPeATl5XQAghhBBCCCGEEEIIIYQQQgghhBBCCCHeFgmIEkIIIYQQQgghhBBCCCGEEEIIIYQQQrw3JCBKCCGEEEIIIYQQQgghhBBCCCGEEEII8d6QgCghhBBCCCGEEEIIIYQQQgghhBBCCCHEe0MCooQQQgghhBBCCCGEEEIIIYQQQgghhBDvDQmIEkIIIYQQQgghhBBCCCGEEEIIIYQQQrw3JCBKCCGEEEIIIYQQQgghhBBCCCGEEEII8d7QzesKvE6lUvH06VPMzMxQKBR5XR0hhMjX1Go1ERER2Nvbo6Pz4ca4St8hhBBZI/3Gf6TvEEKIrJG+I5n0G0IIkTXSb/xH+g4hhMga6TuSSb8hhBBZk51+I98FRD19+hQHB4e8roYQQhQojx49onjx4nldjTwjfYcQQmTPh95vgPQdQgiRXR963yH9hhBCZM+H3m+A9B1CCJFdH3rfIf2GEEJkT1b6jXwXEGVmZgYkV97c3DzbxyckJHDo0CE++eQT9PT03nb1xCukrXOXtHfuKUhtHR4ejoODg+bc+aF6k76jIL3f7wNp79wjbZ27Ckp7S7/xH+k7CgZp69wl7Z17ClJbS9+RTPqNgkPaO/dIW+eugtLe0m/8R/qOgkHaOndJe+eegtTW0nckk36j4JD2zj3S1rmroLR3dvqNfBcQlTIFoLm5eY4DooyNjTE3N8/Xb9L7QNo6d0l7556C2NYf+vSpb9J3FMT3uyCT9s490ta5q6C194feb4D0HQWFtHXukvbOPQWxrT/0vkP6jYJD2jv3SFvnroLW3h96vwHSdxQU0ta5S9o79xTEtv7Q+w7pNwoOae/cI22duwpae2el3/hwF2IVQgghhBBCCCGEEEIIIYQQQgghhBBCvHckIEoIIYQQQgghhBBCCCGEEEIIIYQQQgjx3pCAKCGEEEIIIYQQQgghhBBCCCGEEEIIIcR7QzevKyCEEEIIkVuSkpJISEjI62rkioSEBHR1dYmNjSUpKSmvq/Peyy/traenh1KpzLPyhXhffSj9R345l30I8lNbS98hhBBCiPwot67B89N12YdA2jv35Ke2lnuOtyut82N+er8/BPm5veXzJoQ2CYgSQgghxHtPrVYTGBhIaGhoXlcl16jVamxtbXn06BEKhSKvq/Pey0/tbWlpia2tbZ7XQ4j3wYfWf+Snc9n7Lr+1tfQdQgghhMgvcvsaPL9dl73vpL1zT35ra7nneHMZnR/z2/v9vsvv7S2fNyH+IwFRQgghhHjvpdwoFi1aFGNj4w/iRkClUhEZGYmpqSk6OrJK8ruWH9pbrVYTHR1NUFAQAHZ2dnlSDyHeJx9a/5EfzmUfivzS1tJ3CCGEECK/ye1r8PxyXfahkPbOPfmlreWe4+3J6PyYX97vD0V+bW/5vAmRmgRECSGEEOK9lpSUpLlRtLKyyuvq5BqVSkV8fDyGhob56qbsfZVf2tvIyAiAoKAgihYtKtMjC/EGPsT+I7+cyz4E+amtpe8QQgghRH6RF9fg+em67EMg7Z178lNbyz3Hm8vs/Jif3u8PQX5ub/m8CaEtf31ChRBCCCHespT11I2NjfO4JkLkjpS/9ZS/fSFEzkj/IT4k0ncIIYQQIj+Qa3Ah3l9yz/Fm5PwoskM+b0L8RwKihBBCCPFBeN+XORIihfytC/F2yWdKfAjk71wIIYQQ+Ylcmwjx/pHP9dsh7SiyQv5OhPiPBEQJIYQQQgghhBBCCCGEEEIIIYQQQggh3hsSECWEEEIIIYQQQgghhBBCCCGEEEIIIYR4b0hAlBBCCCGEeKscHR1ZvHhxXldDCCFEAdGkSRO+/vrrvK6GEEIIIYQQ+dLUqVOpWrVqXlfjrejXrx/u7u55XQ0hhMh1CoWC3bt353U1hPjgSECUEEIIIUQ+FhgYyMiRI3FycsLQ0BAbGxsaNGjAqlWriI6OBuDKlSu0bt2aokWLYmhoiKOjI926dSM4OBgAPz8/FAoFurq6PHnyRCv/gIAAdHV1USgU+Pn5ae3z9/fHwMCA8PBwpk6dikKh0ORjbW1No0aNWLx4MXFxcVrHXbhwgcGDB7+7RgE2bNiApaXlOy1DCCEKqr59+2rO2QqFAisrK1q2bMn169c1aV7dr6urS4kSJRgzZozWOT2jc21aA3kxMTEYGxtz+/ZtNmzYoMlfqVRSqFAhateuzQ8//EBYWJjWcX/88QfTp09/a68/LcePH0ehUBAaGvpOyxFCCCGEEB+2wMBARowYQenSpTEwMMDBwYE2bdpw9OjRvK5ahlLGjtL6OXfu3Dsvv2/fvkyYMAHQvlcxMzOjRo0a/PHHH++8Dq+6ePEi/fv3p1y5clhZWeHi4sLw4cO5fft2qrQBAQH06NGD8uXLo6OjIw97CPGalDGKoUOHpto3bNgwFAoFffv2zXbalPTt2rVLs9z0Hr7avXs3CoUi1fYNGzZQp04drXq8+pOyLy/JA2VCZJ8ERAkhhBBC5FP379+nWrVqHDp0iFmzZnHlyhWOHDnCqFGj+Ouvvzhy5AhBQUG4ublhbW3NwYMH8fb2Zt26ddjZ2WkCplLY29uzadMmrW0bN26kWLFiaZa/Z88emjRpgrm5OQAVK1YkICCAhw8fcuzYMTp37szs2bOpV68eERERmuOKFCmCsbFxuq8rISEhp00ihBAii1q2bElAQAABAQEcPXoUXV1dWrdurZVm/fr1BAQE8ODBA1asWMHmzZtZsGBBjss8fPgwDg4OODs7A2Bubk5AQACPHz/mzJkzDB48mE2bNlG1alWePn2qOa5w4cKYmZmlm298fHyO6ySEEEIIIURu8fPzo3r16vz999/MmzePGzducODAAZo2bcqXX36Z19XLkiNHjmjuI1J+qlev/k7LVKlU7N27l7Zt22q2pdyrXLhwgSpVqtC5c2fOnj37TuuRUpdRo0bRvHlzrK2tWbZsGf/88w8//fQTRkZG1KtXj59//lnrmLi4OIoUKcKkSZOoUqXKO6+jEAWRg4MD27ZtIyYmRrMtNjaW3377jRIlSuQ47dvk4eGhdR56dVwlICCAffv2vbOyhRDvjgRECSGEEOKDolariY5PzJMftVqdrboOGzYMXV1dLl68SJcuXahQoQKurq507NiRvXv30qZNG86cOUN4eDhr1qyhWrVqlCpVimbNmrFo0SIcHBy08uvTpw/r16/X2rZhwwb69OmTZvl79uzh888/1/yuq6uLra0t9vb2uLq6MmLECE6cOMG///7L3LlzNeleXzJPoVCwatUq2rZti4mJCTNmzADgr7/+onr16hgaGlK6dGmmTZtGYmKi5rjQ0FAGDx6MjY0NhoaGVKpUCU9PT44fP06/fv0ICwvTPKEzderUbLWtEELkREHqQwwMDLC1tcXW1paqVasyfvx4Hj16xPPnzzVpLC0tsbW1xcHBgdatW9OmTRuuXbuW4/Z5vd9QKBTY2tpiZ2dHhQoVGDBgAGfOnCEyMpJx48Zp0r3+hKOjoyMzZsygb9++WFhYMGjQIADOnDlDo0aNMDIywsHBga+++oqoqCjNcXFxcYwbNw4HBwcMDAwoW7Ysa9euxc/Pj6ZNmwJQqFChVE+UCiGEEEKI/Cs3rsFj4pPe2jiOQqHAy8uLTp06Ua5cOSpWrMjo0aM1syw9fPiQtm3bYmpqirm5OV26dOHZs2da+cyZMwcbGxvMzMwYMGAAsbGxqcpav349FSpUwNDQEGdnZ1asWKHZ179/fypXrqyZ/TUhIYHq1atnaak6KysrzX1Eyo+enh537txBoVCkmiFp4cKFODo6olarSUpKYsCAAZQqVQojIyPKly/PkiVLMi3z9OnT6OjoULt2bc22lHsVZ2dnVq1ahaGhIR4eHlkq4/jx49SqVQsTExMsLS2pX78+/v7+AFy7do2mTZtiZmaGubk51atX5+LFi5pjv/32W06fPo23tzfz5s2jRYsWVKxYkaZNmzJ//nwuXLjA3LlztQIjHB0dWbJkCb1798bCwiLT1yvE2/L6+TG9c1l+GKP46KOPKFGihNZsb3/88QcODg5Uq1Ytx2nfltjYWA4dOqQ1pvHquIqtrS2FCxfOMI/4+HiGDx+OnZ2dZhWH2bNna6V58eIF7du3x9jYmLJly+Lh4aG1/8SJE9SqVQsDAwPs7OyYMGGCZry8b9++nDhxgiVLlmjGxF9f8UEIkZpuXldACCGEECI3xSQk4TL5YJ6UfeuHFhjrZ+3yKzg4WDMzlImJSZppUr5oTkxM5M8//6RTp05pTveb4vPPP2fVqlWcOnWKBg0acOrUKUJCQmjTpk2qpYpCQ0M5efIkGzZsyLCezs7OtGrVij/++EMT6JSWKVOmMHv2bBYtWoRSqeTgwYP07NmTpUuX0rBhQ+7du6dZZm/KlCmoVCpatWpFREQEmzdvpkyZMty6dQulUkm9evVYvHgxkydP5s6dOwCYmppmWE8hhHgbCkof8rrIyEi2bNmCk5MTVlZWaabx8fHh+PHjdOvWLUdlqFQqPD092bVrV4bpihYtiru7O+vWrSMpKQmlUplmuvnz5/P999/z3XffAXDjxg1atGjB9OnTWbt2Lc+fP2f48OEMHz5cE+zbu3dvzp49y9KlS6lSpQoPHjzgxYsXODg4sGvXLjp27MidO3cwNzfHyMgoR69TCCGEEELkroJyDR4SEsKBAweYOXNmmuM4lpaWqNVq2rVrh4mJCSdOnCAxMZFhw4bRtWtXjh8/DsCOHTuYMmUKP/30Ew0bNuTXX39l6dKllC5dWpPX6tWrmTJlCsuXL6datWpcuXKFQYMGYWJiQp8+fTTXwxMmTGDRokV8//33vHjxQitoKrvKly9P9erV2bJli9YY0tatW+nRowcKhQKVSkXx4sXZsWMH1tbWmlli7ezs6NKlS7p5e3h40KZNG3R00p7DQU9PD11dXRISEjItIzExkXbt2jFo0CB+++034uPj8fLy0oyXubu7U61aNVauXIlSqeTq1avo6ekBcPv2bdauXcu1a9ewtbVlzZo1LFiwgMjISAYOHMjp06eZPHkya9asYfjw4bRq1SrDcTgh3rWCcn5M0a9fP9avX68Jzly3bh39+/fXnP9ymvZtOHr0KLa2tlSsWFGz7fjx4xQtWhRLS0saN27MzJkzKVq0aLp5LF26FA8PD3bs2EGJEiV49OgRjx490kozbdo05s2bx/z581m2bBnu7u74+/tTuHBhnjx5wqeffkrfvn3ZtGkTt2/fZtCgQRgaGjJ16lSWLFmCj48PlSpV4ocffgCSV2oQQmRMAqKEEEIIIfKhu3fvolarKV++vNZ2a2trzZOBX375JXPnzuXbb7+lR48eDB06lFq1atGsWTN69uyZ6stePT09evbsybp162jQoAHr1q2jZ8+emoGfV+3btw9XV9dUs0ylxdnZmUOHDmWYpkePHvTv31/ze69evZgwYYJmdqrSpUszffp0xo0bx5QpUzhy5AheXl54e3tTrlw5TZoUFhYWmoAwIYQQqXl6emqCRaOiorCzs8PT01PrS4bu3bujVCpJTEwkLi6Ozz77jFGjRmnlExYWlqWg03PnzqFSqahXr16maZ2dnYmIiCA4ODjdwcRmzZoxduxYze+9e/emR48empmkypYty9KlS2ncuDErV67k4cOH7Nixg8OHD+Pm5gZo9xspT3KmDGYKIYQQQgjxNqWM46QsH52WI0eOcP36dR48eKAZb/n111+pWLEiFy5coGbNmixevJj+/fszcOBAAGbMmMGRI0e0ZomaPn06P/74Ix06dACgVKlS3Lp1i59//pk+ffpgamrK5s2bady4MWZmZvz4448cPXo0S7MX1atXL1VgUlhYGEqlEnd3d5YvX64JiPLx8eHSpUts2rQJSB53mjZtmua4UqVKcebMGXbs2JFpQFR6S3fHxcUxf/58wsPD+fjjjzMtIzw8nLCwMFq3bk2ZMmUAqFChgib9w4cP+eabbzTvU9myZTX7Nm/eTJ8+fbC3t+f06dOMHDmSlStX4urqypIlSzh27BiTJk2iWbNmREREcOfOnQzfbyGEtl69ejFx4kT8/PxQKBScPn2abdu2pRnklJ20b8OePXu0lstr1aoVnTt3pmTJkjx48IDvv/+eZs2acenSJQwMDNLM4+HDh5QtW5YGDRqgUCgoWbJkqjR9+/ale/fuAMyaNYtly5bh5eVFy5YtWbFiBQ4ODixfvhyFQoGzszNPnz5l/PjxTJ48GQsLC/T19TE2NpYxcSGyQQKihBBCCPFBMdJTcuuHFnlWdna9/qSZl5cXKpUKd3d3zdTnM2fOZPTo0fz999+cO3eOVatWMWvWLDw9Palbt67W8QMGDKBu3brMmjWLnTt3cvbsWa1l6lK8vuxRRtRqdaZPxNWoUUPr90uXLnHhwgVmzpyp2ZaUlERsbCzR0dFcvXqV4sWLa4KhhBAiPyhIfUjTpk1ZuXIlkPy0+ooVK2jVqhVeXl6aQblFixbh5uZGUlISd+/eZfTo0QwZMoTff/9dk4+ZmRmXL19Olf+rXxxAcr/RunXrdJ/qflXK1PoZ9R1p9Rt3795ly5YtWvmoVCoePHjAjRs3UCqVNG7cONPyhRBCCCFEwfGur8FVKhUR4RGYmZulupbNzjV4Vq5xvb29cXBw0Hr4zMXFBUtLS7y9valZsybe3t4MHTpU67i6dety7NgxAJ4/f86jR48YMGCAZmlpgMTERK2Ap7p16zJ27FimT5/O+PHjadSokWZfq1atOHnyJAAlS5bk5s2bmn3bt2/XCiACNLO6duvWjW+++YZz585Rp04dtmzZQtWqVXFxcdGkXbVqFWvWrMHf35+YmBji4+OpWrVqhm3y+PFjzUMNKVIe3oiJicHCwoIFCxbQqlWrTMsoXLgwffv2pUWLFjRv3hw3Nze6dOmCnZ0dAKNHj2bgwIH8+uuvuLm50blzZ03g1PXr1zVLa+/Zs4cePXrQu3dvAH755Rd27NihqZ+dnR0vX75M93UJkRtePT9mdC57V2Vnl7W1NZ999hkbN25ErVbz2WefYW1t/cZp35Rareavv/5i27Ztmm1du3bV/L9SpUrUqFGDkiVLsnfvXjp06MAXX3yhNT4RGRlJ3759ad68OeXLl6dly5a0bt2aTz75RKusypUra/5vYmKCmZkZQUFBQPL5sG7dulr9SP369YmMjOTx48eUKFHirb92IT4EEhAlhBBCiA+KQqHI8ZJDucnJyQmFQsHt27e1tqfMdvH67E9WVlZ07tyZzp07M3v2bKpVq8by5ctTBURVqlQJZ2dnunfvToUKFahUqRJXr17VSpOQkMCBAweYOHFilurq7e1NqVKlMkzz+nTxKpWKadOmaZ5mfJWhoaEsZSSEyJcKSh8CyeddJycnze/Vq1fHwsKC1atXa5Y4tbW11aQpX748YWFhuLu7c/fuXU1Aqo6OjlY+6fHw8GD27NlZqpu3tzfm5ubpLt+XUv9XqVQqhgwZwldffZUqbYkSJbh7926WyhZCCCGEEAXLu74GV6lUJOorMdbXfaMggrJly6JQKPD29qZdu3ZppknvgbKsPGj2an0hedm82rVra+17dTlqlUrF6dOnUSqV+Pr6aqVbs2YNMTExAKlmDXdwcEj3+t/Ozo6mTZuydetW6tSpw2+//caQIUM0+3fs2MGoUaP48ccfqVu3LmZmZsyfP5/z58+n+3o8PDxo3rx5qnGglIc3zM3NtWaVzUoZ69ev56uvvuLAgQNs376d7777jsOHD1OnTh2mTp1Kjx492Lt3L/v372fKlCls27aN9u3bk5iYiKGhIQDx8fFa9yT6+vqaWWFiYmK4e/eu1oy0QuSFV8+Pb+tc9q7179+f4cOHA/DTTz+9tbRpMTc3JywsLNX20NBQzM3NNb97eXkRHx9PgwYN0s3Lzs6OkiVLas6n06ZNY8iQIZiammra+6OPPuLBgwfs37+fI0eO0KVLF9zc3LQeOnv9nJuy3Cik3RdkJdhWCJGx/HtGFEIIIYT4gFlZWdG8eXOWL19OVFRUto7V19endOnSREdHp7k/Zb31V5ewe9WxY8ewtLTM8Am+FLdv3+bAgQN07NgxW3X86KOPuHPnDk5OTql+dHR0qFy5Mo8fP8bHxyfN4/X19UlKSspWmUII8SFTKBTo6OhovvhIS8oXKBmlSYuvry9+fn6pnnxMS1BQEFu3bqVdu3bZGqT96KOPuHnzZpr9hr6+Pq6urqhUKk6cOJHm8fr6+gDSdwghhBBCiHeicOHCtGjRgp9++inNcZzQ0FBcXFx4+PAhjx490my/desWYWFhmlmZKlSowLlz57SOffV3GxsbihUrxv3791NdF7/6sNr8+fPx9vbmxIkTHDx4kPXr12v2FStWTHNMWks6ZcTd3Z3t27dz9uxZ7t27R7du3TT7Tp48Sb169Rg2bBjVqlXDycmJe/fuZZhfejOUpzy88foS21kto1q1akycOJEzZ85QqVIltm7dqtlXrlw5Ro0axaFDh+jQoYOmbZycnLh+/ToAjRo1Ytu2bdy8eZOkpCQWL15MaGgooaGhDBs2jE8//RQbG5usN5wQAoCWLVsSHx9PfHw8LVpkPPtfdtKmxdnZmYsXL6bafuHCBcqXL6/5fc+ePXz22WdaQaWvCw4O5tGjR5rZ5ooWLUrp0qU159IU5ubmdO3aldWrV7N9+3Z27dpFSEhIlurr4uLCmTNnNEFQAGfOnMHMzIxixYoBMiYuRE5IQJQQQgghRD61YsUKEhMTqVGjBtu3b8fb25s7d+6wefNmbt++jVKpxNPTk549e+Lp6YmPjw937txhwYIF7N+/XzOV+OsGDRrE8+fPGThwYJr7PTw80hyMSkxMJDAwkKdPn3Ljxg2WLVtG48aNqVq1Kt988022XtvkyZPZtGkTU6dO5ebNm3h7e2ue2gNo3LgxjRo1omPHjhw+fFjzdM2BAwcAcHR0JDIykqNHj/LixYt0g7+EEOJDFRcXR2BgIIGBgXh7ezNixAgiIyNp06aNJk1oaKjmvH7ixAlmzJiBk5NTqiUyMrNnzx7c3NwwNjbW2q5WqwkMDCQgIABvb2/WrVtHvXr1sLCwYM6cOdkqY/z48Zw9e5Yvv/ySq1ev4uvri4eHByNGjACS+4U+ffrQv39/du/ezYMHDzh+/LhmWYuSJUuiUCjw9PTk+fPnREZGZqt8IYQQQgghMrNixQqSkpKoVasWu3btwtfXF29vb5YuXUrdunVxc3OjcuXKuLu7c/nyZby8vOjduzeNGzfWLBk9cuRI1q1bx7p16/Dx8WHKlClaS9oBTJ06ldmzZ7NkyRJ8fHy4ceMG69evZ+HChQBcvXqVyZMns3btWurXr8+SJUsYOXIk9+/fz/Q1BAcHa+4jUn5iY2M1+zt06EB4eDhffPEFTZs21XxJD8kBRRcvXuTgwYP4+Pjw/fffc+HChXTLCgoK4sKFC7Ru3TrLbZxZGQ8ePGDixImcPXsWf39/Dh06hI+PDxUqVCAmJobhw4dz/Phx/P39OX36NBcuXNDc/7Rv357Vq1cTFxdHhw4d6NSpE5UrV8bAwIATJ05Qo0YN3N3dMTIy4pdfftGq19WrV7l69SqRkZE8f/6cq1evcuvWrSy/LiE+FEqlEm9vb7y9vTMMQMpO2rCwMM1nMOXn4cOHDBs2jHv37vHll19y7do1fHx8+Omnn1i7dq3WWLaHhwdt27bV/B4ZGcnYsWM5e/Ysfn5+HD9+nDZt2mBtbU379u3TrceiRYvYtm0bt2/fxsfHh507d2Jra4ulpWWW2mbYsGE8evSIESNGcPv2bfbs2cOUKVMYPXq05oEyR0dHzp8/j5+fHy9evNDMLiWESF/BmOtfCCGEEOIDVKZMGa5cucKsWbOYOHEijx8/xsDAABcXF8aOHcuwYcMIDAzE2NiYMWPG8OjRIwwMDChbtiy//PJLmsvRAejq6ma45rqHhwfr1q1Ltf3mzZvY2dmhVCqxsLDAxcWFiRMn8sUXX2imDc+qFi1a4OnpyQ8//MC8efPQ09PD2dlZK0hr165djB07lu7duxMVFYWTk5PmC/R69eoxdOhQunbtSnBwMFOmTGHq1KnZqoMQQrzPDhw4oHly0czMDGdnZ3bu3EmTJk00afr16wckzx5la2tLw4YNmThxIrq62Rsq2LNnD3369Em1PTw8HDs7OxQKBebm5pQvX54+ffowcuRIrenps6Jy5cqcOHGCSZMm0bBhQ9RqNWXKlKFr166aNCtXruTbb79l2LBhBAcHU6JECb799lsg+Sn4adOmMWHCBPr160fv3r3ZsGFDtuoghBBCCCFERkqVKsXly5eZOXMmY8aMISAggCJFilC9enVWrlyJQqFg9+7djBgxgkaNGqGjo0PLli1ZtmyZJo+uXbty7949xo8fT2xsLB07duSLL77g4MGDmjQDBw7E2NiY+fPnM27cOExMTHB1deXrr78mNjYWd3d3+vbtq3kYYsCAAezdu5devXrxzz//ZBhY4Obmlmrbb7/9ppkJytzcnDZt2rBz585UY0dDhw7l6tWrdO3aFYVCQffu3Rk2bBj79+9Ps6y//vqL2rVrp5oFKiOZlWFsbMzt27fZuHEjwcHB2NnZMXz4cIYMGUJiYiLBwcH07t2bZ8+eYW1tTYcOHZg2bRoATZs21YxNrV+/nuXLlzN37lyio6MpUqQIQUFBFCpUKNWSV5A8I1WKS5cusXXrVkqWLImfn1+WX5sQH4rsjAdkJe3x48e1PoMAffr0YcOGDZw8eZJJkybxySefEBsbS7ly5diwYQOdO3cG4N69e9y9e1drBiqlUsmNGzfYtGkToaGhmuVCt2/fjpmZWbr1MDU1Ze7cufj6+qJUKqlZsyb79u3L8uzYxYoVY9++fXzzzTdUqVKFwoULM2DAAM0DxABjx46lT58+uLi4EBMTw4MHD3B0dMxS/kJ8qBTqV+ddywfCw8OxsLAgLCws2wOkAAkJCezbt49PP/00zYsS8fZIW+cuae/cU5Da+k3Pme+LN2mHgvR+vw/yor1jY2N58OABpUqVwtDQMFfKzA9UKhXh4eGYm5tna0miy5cv06xZM54/fy6fiWzIaXu/Cxn9zUu/8R/pOwqGvGzrD7H/yMm57MWLF9jZ2fHo0SNsbW3fcQ3fH/mp3wDpO7JC+o2CQ9o790hb566C0t7Sb/xH+o7sy4tr8Px2Xfa+e7W927VrR4MGDRg3blxeV0sjNDSU1q1bEx8fz6RJk/j4448xNTUlODiY33//neXLl3P8+HGsrKzyuqqZym9/23LPkbmM2iGz82N+e78LioULF3LkyBH27duXrePye3u/T2NaH+o1UV4pKO2dnX4j/31ChRBCCCFEnklMTGTZsmX5+mJXCCFE/hESEsLChQslGEoIIYQQQgiRLQ0aNKB79+55XQ0tlpaWHDt2DHd3dyZMmICZmRkGBgbY29uzZ88efvnllwIRDCWEyJrixYszceLEvK6GEOIdkiXzhBBCCCGERq1atahVq1ZeV0MIIUQBUa5cOcqVK5fX1RBCCCGEEEIUMPlpZqhX6enpMXLkSEaOHElYWBhhYWEULVq0wM+yIoRIrUuXLnldBSHEOyYBUUIIIYQQQgghhBBCCCGEEEII8QoLCwssLCzyuhpCCCGEyCFZMk8IIYQQQgghhBBCCCGEEEIIIYQQQgjx3pCAKCGEEEIIIYQQQgghhBBCCCGEEEIIIcR7QwKihBBCCCGEEEIIIYQQQgghhBBCCCGEEO+NbAVETZ06FYVCofVja2ur2a9Wq5k6dSr29vYYGRnRpEkTbt68+dYrLYQQouCQvkMIIUR2SL8hhBAiu6TvEEIIkR3SbwghhMgu6TuEEKJgyvYMURUrViQgIEDzc+PGDc2+efPmsXDhQpYvX86FCxewtbWlefPmREREvNVKCyGEKFik7xBCCJEd0m8IIYTILuk7hBBCZIf0G0IIIbJL+g4hhCh4dLN9gK6uVsRrCrVazeLFi5k0aRIdOnQAYOPGjdjY2LB161aGDBmSZn5xcXHExcVpfg8PDwcgISGBhISE7FZPc0xOjhXZI22du6S9c09BauuCUEfI331HQXq/3wd50d4JCQmo1WpUKhUqlSrXys1rarVa8++H9LrzSn5qb5VKhVqtJiEhAaVSqbWvoJzr3na/AdJ3FFR52dYfYv+Rn85l77v81tbSd6Qm/UbBJe2de6Stc1dBae/8Xr8Ucs+RP+XFNXh+uy5730l755781tZyz5FadvqNzM6P+e39ft/l9/bO6PNW0Hyo10R5paC0d3bql+2AKF9fX+zt7TEwMKB27drMmjWL0qVL8+DBAwIDA/nkk080aQ0MDGjcuDFnzpxJ92Q/e/Zspk2blmr7oUOHMDY2zm71NA4fPpzjY0X2SFvnLmnv3FMQ2jo6Ojqvq5AlBaHvKAjv9/skN9s75UY1MjKS+Pj4XCs3v8iLp5AqV67MF198wRdffJHrZefUqVOnaNOmDX5+flhYWOQ4n/Tae+/evXz//ff4+/szePBgZs+eneMyMhMfH09MTAz//PMPiYmJWvs+1H4DpO8o6PKirT/k/iO3+47WrVvj6ur6Ts+Nb9vDhw+pUqUK//zzD66urjnOJ722PnfuHKNHj8bX15dPPvmELVu25LiMrJC+IzXpNwo+ae/cI22du/J7e3+o/QZI3/E25OU1eH6exWXOnDns3buXkydP5nVV3tiwYcMICwt759e375NChQqxefNmPvvssxwdn9Hfto+PD19++SU3btygbNmy7/RvTO45UstOv5HV82N+Ppe9j/Jre2f0eSuoPrRroryW39s7O/1GtgKiateuzaZNmyhXrhzPnj1jxowZ1KtXj5s3bxIYGAiAjY2N1jE2Njb4+/unm+fEiRMZPXq05vfw8HAcHBz45JNPMDc3z071gORosMOHD9O8eXP09PSyfbzIOmnr3CXtnXsKUlunPDGQn+X3vqMgvd/vg7xo79jYWB49eoSpqSmGhoa5UubbFBgYyJw5c9i3bx+PHz/GwsKCsmXL0qNHD3r37o2xsTFXrlxh8uTJXLhwgfDwcGxtbalVqxazZ8/G0dERf39/ypQpg1Kp5MGDBxQrVkyTf0BAACVLliQpKYl79+7h6Oio2efv74+zszPPnj1j0aJF/PDDDwAolUosLS1xcXGhffv2DB06FAMDA81xFy5cwMTE5I2C2zOzYcMGRo8eTUhIyFvJL6WuZmZmOboGVavVREREULVqVUaOHMnIkSO19o8ePZq+ffsyYsQIzMzMMDMzy1E9S5cunWb+r4qNjcXIyIhGjRql+pv/UPsNkL6joMrLti7I/Ue/fv3YtGmT5vfChQtTo0YN5s6dS+XKlQG0nhBUKpXY29vToUMHJk6ciLW1NQqFIsNzrVKpZNeuXbRr106zLSYmhiJFinDx4kXOnTvHgAEDANDR0cHc3Jxy5crx6aef8tVXX2kFn+7evRs9Pb0cnxuz4vjx43z88ccEBwdjaWn5xvmZmpoCYGJi8kb9Rtu2balatSqLFi3S2j9lyhQ++ugjDhw4gKmpaY7KAGjWrBlVqlRJlf/rpO9ITfqNgkvaO/dIW+eugtLeH2q/AdJ3vA15cQ2ecl1mZmaGQqF44/wCAwOZNWsW+/bt48mTJxQtWpQqVaowcuRIPv744xzlaWBggFKpzPE1YVb4+flRpkyZNPedPn2aOnXqvJVyUv6eX2/vfv36YWtry+zZs7XuVUxNTSlfvjwTJkzQzLyTGy5evMjKlSs5ffo0wcHB2NjY0LRpU7788kucnZ210gYEBDB27FguX76Mr68vI0aMyPT6O7uMjIyy/f6/+rfdv39/QkND+fPPP7XSLFiwAHNzc7y9vd/ovqNfv35p5v8quedILTv9Rmbnx7d9Lnvb3mSMe/ny5VhbW2vOU28yxm1ubk54eDjz5s3jjz/+wM/PD0tLSypVqsTQoUNp3759pu33+phLWpKSkt6ovd5URp+3guZDvSbKKwWlvbPTb2QrIKpVq1aa/7u6ulK3bl3KlCnDxo0bNRdDr58k1Gp1hicOAwMDrS/QUujp6b1RI7/p8SLrpK1zl7R37ikIbZ3f6wcFp+8oCO/3+yQ32zspKQmFQoGOjg46Ojq5Uubbcv/+ferXr4+lpSWzZs3C1dWVxMREfHx8WLduHcWLF6dOnTp88skntGnThoMHD2JpacmDBw/Ys2cP0dHRmtcOYG9vz+bNm5k4caKmjF9//ZVixYrx8OHDVG30119/0aRJEywtLVEoFFSsWJEjR46gUqkIDg7m+PHjzJgxg82bN3P8+HHNF9mv3/y/LiEh4Y3f/5R6vq339NX8cpLnq1Mjv9rmAJGRkQQFBdGyZUuKFy/+xnV9Pf/X6ejooFAo0vycFYTz3LvoN0D6joIuL9q6IPcfCoWCli1bsn79eiB54PG7777j888/5+HDh5p069evp2XLliQkJHDt2jX69euHnp4ec+fO1Xrd6b3+19vm6NGjODg44OLigpeXF+bm5ty5cwe1Wk1oaChnzpxh9uzZbNiwgdOnT2Nvbw+AtbV1hq8nPj4efX39N2qTNz3Pv+38UvoNhUKR5nn93r17DB06lBIlSrxxXTPrN0D6jrRIv1HwSXvnHmnr3JXf2zs/1y2F3HPkX3lxDf7qddmblunn56cZx5k3bx6VK1cmISGBgwcPMmLECG7fvp2jfFP+9t5lm6TkfeTIESpWrKi1z8rK6q2X/Wp7q1Qq9u3bh4eHh2Zbyr1KaGgo8+fPp2vXrpw6dYq6deu+1Xq8TqVSMWbMGDZs2MCgQYNYtmwZxYsXJygoiH379tGgQQNmz56tNeNPQkICRYsWZdKkSSxatOit/C29LiefidfvOdKq1/379/nss88oVarUG9UvvfxfJfccqWWn38js/Pg2z2Vv25uMcXt4eBAbG6v1ut9kjDs0NJQGDRoQFhbGjBkzqFmzJrq6upw4cYIJEybg5uaW6UNUS5cuZfbs2ZoAtGLFimnOWSny+j3I6PNWUL1Pr6UgyO/tnZ26vdGn0cTEBFdXV3x9fTVrpqZEwaYICgrK9EsxIYQQHw7pO0SeU6shPipvfv6/tnhWDRs2DF1dXS5evEiXLl2oUKECrq6udOzYkb1799KmTRvOnDlDeHg4a9asoVq1apQqVYpmzZqxaNEiHBwctPLr06eP5svxFBs2bKBPnz5plr9nzx4+//xzze8pUzPb29vj6urKiBEjOHHiBP/++y9z587VpHN0dGTx4sWa3xUKBatWraJt27aYmJgwY8YMIPlmtHr16hgaGlK6dGmmTZumNYVvaGgogwcPxsbGBkNDQypVqoSnpyfHjx+nX79+hIWFaQZcpk6dmml7xsXFMW7cOBwcHDAwMKBs2bKsXbtWK82lS5eoUaMGxsbG1KtXjzt37mj23bt3j7Zt22JjY4OpqSk1a9bkyJEjmv2tW7fG39+fUaNGaer1aqBYs2bNNNs2bNiApaUlnp6elC9fHmNjYzp16kRUVBQbN27E0dGRQoUKMWLECM0TRU2aNEmV/4dA+g2RrxSgPsTAwABbW1tsbW2pWrUq48eP59GjRzx//lyTxtLSEltbWxwcHGjdujVt2rTh2rVrOW6e1/sNhUKBra0tdnZ2VKhQgQEDBnDmzBkiIyMZN26cJl2TJk34+uuvNb87OjoyY8YM+vbti4WFBYMGDQLgzJkzNGrUCCMjIxwcHPjqq6+IiorSHJfeed7Pz4+mTZsCyctNKBQK+vbtm+nrUalUzJ07FycnJwwMDChRogQzZ87USnP//n2aNm2KsbExVapU4ezZs5p9wcHBdO/eneLFi2NsbIyrqyu//fabZv+wYcM4ceIES5Ys0ZzX/fz8UCgUBAcH079/f81MXcePH0ehUHDw4EGqVauGkZERzZo1IygoiP3791OhQgXMzc3p3r27Ztrwvn37ppn/h0D6DiGEENkh/UY+lxvX4AnRb20cR6FQ4OXlRadOnShXrhwVK1Zk9OjRnDt3Dkheerlt27aa2Xi6dOnCs2fPtPKZM2cONjY2mJmZMWDAAGJjY1OVtX79eipUqIChoSHOzs6sWLFCs69///5UrlyZuLg4IDlgp3r16ri7u2f6GqysrDT3ESk/enp63LlzB4VCkSqoa+HChTg6OqJWq0lKSmLAgAGUKlUKIyMjypcvz5IlSzIt8/Tp0+jo6FC7dm3NtpR7FWdnZ1atWoWhoSEeHh5ZKuP48ePUqlULExMTLC0tqV+/vmaWnmvXrtG0aVPNDOHVq1fn4sWLmmO//fZbTp8+jbe3N/PmzaNFixZUrFiRpk2bMn/+fC5cuMDcuXPZt2+f5hhHR0eWLFlC7969tWbCzY5169ZRsWJFDAwMsLOzY/jw4Vr7X7x4Qfv27TE2NqZs2bJ4eHho9mXWJtOmTWPjxo3s2bNHa7xKoVBw6dIlfvjhB83YWsr9yI4dO2jYsCFGRkbUrFkTHx8fLly4QI0aNTA1NaVly5aae8upU6emmf/7Ll/0Ha+fH9M7l+XxGMWbjHEvXrw41YNCbzLG/e233+Ln58f58+fp06cPLi4ulCtXjkGDBnH16lXNbNAvX76kd+/eFCpUCGNjY1q1aoWvry8AFhYW2NraYmNjo3nvU85ZKT9CiPwjWzNEvS4uLg5vb28aNmxIqVKlsLW15fDhw1SrVg1IforzxIkTWl+QCSGE+LBJ3yHyXEI0zLLPm7K/fQr6JllKGhwczKFDh5g1axYmJmkfk/JFc2JiIn/++SedOnXKMEjm888/Z9WqVZw6dYoGDRpw6tQpQkJCaNOmDdOnT9dKGxoaysmTJ9mwYUOG9XR2dqZVq1b88ccfmkCntEyZMoXZs2ezaNEilEolBw8epGfPnixdupSGDRty7949Bg8erEmrUqlo1aoVERERbN68mTJlynDr1i2USiX16tVj8eLFTJ48WROwlHKzmpHevXtz9uxZli5dSpUqVXjw4AEvXrzQSjNp0iR+/PFHihQpwtChQ+nfvz+nT58Gkmd6+vTTT5kxYwaGhoZs3LiRNm3acOfOHYoXL86vv/5Ko0aNGDx4sObL+8KFC3Pnzh3Kly/Prl27qFevHoULF8bPz4/o6GiWLl3Ktm3biIiIoEOHDnTo0AFLS0v27dvH/fv36dixIw0aNKBr16788ccfVKlSRSv/D4H0GyJfKSB9yOsiIyPZsmULTk5OWFlZpZnGx8eH48eP061btxyVoVKp8PT0ZNeuXRmmK1q0KO7u7qxbt46kpCSt5TBeNX/+fL7//nu+++47AG7cuEGLFi2YPn06a9eu5fnz5wwfPpzhw4drBkLTO887ODiwa9cuOnbsyJ07dzA3N8fIyCjT1zRx4kRWr17NokWLaNCgAQEBAam+AJo0aRILFiygbNmyTJo0ie7du3P37l10dXWJjY2levXqjB8/HnNzc/bu3UuvXr0oXbo0NWvWZPbs2fj5+VGpUiXNsrRFihQhICCA8uXL88MPP9C1a1csLCw4f/48kPxlw/LlyzE2NqZLly506dIFAwMDtm7dSmRkJO3bt2fZsmWMHz+eJUuW4OPjkyr/D4H0HUIIIbJD+o187h1fg+sAluntzMY1eEhICAcOHGDmzJlpjuNYWlqiVqtp164dJiYmnDhxgsTERIYNG0bXrl01ASQ7duxgypQp/PTTTzRs2JBff/2VpUuXUrp0aU1eq1evZsqUKSxfvpxq1apx5coVBg0ahImJCX369NFcD0+YMIFFixbx/fff8+LFC62gqewqX7481atXZ8uWLVpjSFu3bqVHjx4oFApUKhXFixdnx44dWFtbc+bMGQYPHoydnR1dunRJN28PDw/atGmT7owqenp66OrqkpCQkGkZiYmJtGvXjkGDBvHbb78RHx+Pl5eXZrzM3d2datWqsXLlSpRKJVevXtXMMnH79m3Wrl3LtWvXsLW1Zc2aNSxYsIDIyEgGDhzI6dOnmTx5MmvWrGH48OG0atXqrTystnLlSkaPHs2cOXNo1aoVYWFhmrGoFNOmTWPevHnMnz+fZcuW4e7ujr+/P4ULF063TWxsbGjZsiVjxozh9u3bhIeHa+6dChcuTEBAAG5ubrRs2ZKxY8diamqqGSebMmWKJhClf//+dO/eHXNzc5YsWaK5F5k8eTIrV65k7NixeHt7p8r/fZcv+o5Xzo8ZnsvehSyeH/PTGLdKpWLbtm24u7trZqx+1avjy3379sXX1xcPDw/Mzc0ZP348n376Kbdu3crXs+YIIVLLVkDU2LFjadOmDSVKlCAoKIgZM2YQHh5Onz59UCgUfP3118yaNYuyZctStmxZZs2ahbGxMT169HhX9RdCCJHPSd8hRM7cvXsXtVpN+fLltbZbW1trngz88ssvmTt3Lt9++y09evRg6NCh1KpVi2bNmtGzZ89UX/bq6enRs2dP1q1bR4MGDVi3bh09e/ZM8yZu3759uLq6ppplKi3Ozs4cOnQowzQ9evSgf//+mt979erFhAkTNE/ulC5dmunTpzNu3DimTJnCkSNH8PLywtvbm3LlymnSpLCwsNDcLGeFj48PO3bs4PDhw7i5uaXKL8XMmTNp3LgxABMmTOCzzz4jNjYWQ0NDqlSpQpUqVTRpZ8yYwZ9//omHhwfDhg2jUKFCKJVKzMzMtOpVtGhRIHkw6NXtCQkJrFy5kjJlygDQqVMnfv31V549e4apqSkuLi40bdqUY8eO0bVrVwoXLpxm/u8b6TeEeDs8PT01g3lRUVHY2dnh6emp9SVD9+7dUSqVJCYmEhcXx2effcaoUaO08gkLC8tS0Om5c+dQqVTUq1cv07TOzs5EREQQHBysOUe+rlmzZowdO1bze+/evenRo4dmJqmyZcuydOlSGjduzMqVK3n48GGG5/mUAfmiRYtmOv09QEREBEuWLGH58uWavqpMmTI0aNBAK93YsWP57LPPgOQvKSpWrMjdu3dxdnamWLFiWq9hxIgRHDhwgJ07d1KzZk0sLCzQ19fH2NhY67xua2uLQqHQPHX6qhkzZlC/fn0ABgwYwMSJE7l3757mtXbq1Iljx44xfvz4dPN/H0nfIYQQIjuk3xDvQso4jrOzc7ppjhw5wvXr13nw4IFmvOXXX3+lYsWKXLhwgZo1a7J48WL69+/PwIEDgeTrvyNHjmjNEjV9+nR+/PFHOnToAECpUqW4desWP//8M3369MHU1JTNmzfTuHFjzMzM+PHHHzl69GiWZi+qV69eqsCksLAwlEol7u7uLF++XBNw4OPjw6VLl9i0aROQPO40bdo0zXGlSpXizJkz7NixI9OAqAULFqS5Ly4ujvnz5xMeHs7HH3+caRnh4eGEhYXRunVrzXhLhQoVNOkfPnzIN998o3mfypYtq9m3efNm+vTpg729PadPn2bkyJGsXLkSV1dXlixZwrFjx5g0aRLNmjUjIiKCO3fuZPh+Z9WMGTMYM2YMI0eO1GyrWbOmVpq+ffvSvXt3AGbNmsWyZcvw8vKiZcuW6bbJzp07admyJaamphgZGREXF5fqvkNXVxdTU1PN9pSAqLFjx9KiRQsARo4cSffu3Tl69KjWvUjKQ5Tp5f++kb4jZ950jLt3796pZtnK6Rh3UFAQL1++zPRzmxIIdfr0ac0Yx5YtW3BwcGD37t107tz5TZpECJHLshUQ9fjxY7p3786LFy8oUqQIderU4dy5c5QsWRKAcePGERMTw7Bhw3j58iW1a9fm0KFDmmVChBBCfHik7xD5jp5x8hMseVV2Nr3+NIyXlxcqlQp3d3fN1OczZ85k9OjR/P3335w7d45Vq1Yxa9YsPD09qVu3rtbxAwYMoG7dusyaNYudO3dy9uxZrWXqUry+7FFG1Gp1pk/E1ahRQ+v3S5cuceHCBa2lh5KSkoiNjSU6OpqrV69SvHhxTTDUm7p69SpKpVIT7JSeypUra/5vZ2cHJE9vXaJECaKiopg2bRqenp48ffqUxMREYmJiePjwYY7qZGxsrBmcA7CxscHR0VEr8MDGxoagoKAc5V9QSb8h8rUC1Ic0bdqUlStXAslPq69YsYJWrVrh5eWl+TwtWrQINzc3kpKSuHv3LqNHj2bIkCH8/vvvmnzMzMy4fPlyqvxf/eIAkvuN1q1bp/tU96vU/59aP6O+I61+4+7du2zZskUrH5VKxYMHD7hx40aWzvNZ5e3tTVxcHB9//HGG6dLrN5ydnUlKSmLOnDls376dJ0+eEBcXR1xcXLpPxWbFq+XZ2NhgbGysFfhlY2ODl5dXjvMvqKTvEEIIkR3SbxQw7/gaXKVSER4RgbmZWepr2Wxcg2flGtfb2xsHBweth89cXFywtLTE29ubmjVr4u3tzdChQ7WOq1u3LseOHQPg+fPnPHr0iAEDBmjNHp2YmKgV8FS3bl3Gjh3L9OnTGT9+PI0aNdLsa9WqFSdPngSgZMmS3Lx5U7Nv+/btWgFEgGZW127duvHNN99w7tw56tSpw5YtW6hatSouLi6atKtWrWLNmjX4+/sTExNDfHw8VatWzbBNHj9+rHmoIUXKwxsxMTFYWFiwYMECWrVqlWkZhQsXpm/fvrRo0YLmzZvj5uZGly5dNNfqo0ePZuDAgfz666+4ubnRuXNnzdjM9evXNUtr79mzhx49etC7d28AfvnlF3bs2KGpn52dHS9fvkz3dWVVUFAQT58+zdZ9h4mJCWZmZlrjRdlt98y8ft8B4OrqqrVNxqvyQd/xyvkxw3PZuyo7G95kjPuff/7R+vuDnI1xZ+U8DcnnJV1dXa1lPK2srChfvjze3t7Zet1CiLyXrYCobdu2Zbg/ZY3ZqVOnvkmdhBBCvEek7xD5jkKR4yWHcpOTkxMKhSLV0jwpX3q+PvuTlZUVnTt3pnPnzsyePZtq1aqxfPnyVAFRlSpVwtnZme7du1OhQgUqVarE1atXtdIkJCRw4MABJk6cmKW6ent7U6pUqQzTvP7lr0qlYtq0aZqnGV9laGiYpaWMsiOr+b36JFHKzbFKpQLgm2++4eDBgyxYsAAnJyeMjIzo1KkT8fHxOarT608tKRSKNLellP+hkH5D5GsFpA+B5POuk5OT5vfq1atjYWHB6tWrNUuc2traatKUL1+esLAw3N3duXv3riYgVUdHRyuf9Hh4eDB79uws1c3b2xtzc/N0l+9Lqf+rVCoVQ4YM4auvvkqVtkSJEty9ezdLZWfV2+g3fvzxRxYtWsTixYtxdXXFxMSEr7/+Osf9RlrlSb+RTPoOIYQQ2SH9RgHzrq/BVSrQS0ou4w2CCMqWLYtCocDb25t27dqlmSa9B8qy8qDZf9VNvtZbvXq11pf1gNZy1CqVitOnT6NUKvH19dVKt2bNGmJiYoDUYxMODg7pXv/b2dnRtGlTtm7dSp06dfjtt98YMmSIZv+OHTsYNWoUP/74I3Xr1sXMzIz58+drln9Oi4eHB82bN091/Z3y8Ia5ubnWrLJZKWP9+vV89dVXHDhwgO3bt/Pdd99x+PBh6tSpw9SpU+nRowd79+5l//79TJkyhW3bttG+fXsSExMxNDQEkpc7e/WeRF9fHwMDAwBiYmK4e/dumjOPZ1dO7jtA+7o/J+2enfJS/jZf3/ah3Xfky77j1fPjWzqXvW1vY4x7wYIFbNy4UStdTsa4ixQpQqFChTINakoJnEpr+9tYJlMIkbvyzxlRCCGEEEJoWFlZ0bx5c5YvX05UVFS2jtXX16d06dJER0enub9///4cP35cawm7Vx07dgxLS8ssPUl2+/ZtDhw4QMeOHbNVx48++og7d+7g5OSU6kdHR4fKlSvz+PFjfHx80jxeX1+fpKSkLJfn6uqKSqXixIkT2arnq06ePEnfvn1p3749rq6u2Nra4ufn90b1yq53nb8Q4v2lUCjQ0dHRfPGRlpQvUDJKkxZfX1/8/Pz45JNPMk0bFBTE1q1badeuXbaeWv3oo4+4efNmmv2Gvr5+pud5fX19gCyfQ8uWLYuRkRFHjx7Nch1fd/LkSdq2bUvPnj2pUqUKpUuXTvVllJ6envQbQgghhBDvgcKFC9OiRQt++umnNMdxQkNDcXFx4eHDhzx69Eiz/datW4SFhWlmZapQoQLnzp3TOvbV321sbChWrBj3799PdV386sNq8+fPx9vbmxMnTnDw4EHWr1+v2VesWDHNMSmz22SVu7s727dv5+zZs9y7d49u3bpp9p08eZJ69eoxbNgwqlWrhpOTE/fu3cswv/RmKE95eOP1JbazWka1atWYOHEiZ86coVKlSmzdulWzr1y5cowaNYpDhw7RoUMHTds4OTlx/fp1ABo1asS2bdu4efMmSUlJLF68mNDQUEJDQxk2bBiffvppqmW8csLMzAxHR8c3vu/IrE1kvErklTcd4y5Tpky6x2V3jFtHR4euXbuyZcsWnj5NPfNgVFQUiYmJuLi4kJiYqBVUGBwcjI+PT6oZ9IQQ+Z8ERAkhhBBC5FMrVqwgMTGRGjVqsH37dry9vblz5w6bN2/m9u3bKJVKPD096dmzJ56envj4+HDnzh0WLFjA/v37NVOJv27QoEE8f/6cgQMHprnfw8MjzcGoxMREAgMDefr0KTdu3GDZsmU0btyYqlWr8s0332TrtU2ePJlNmzYxdepUbt68ibe3t+apPYDGjRvTqFEjOnbsyOHDh3nw4AH79+/nwIEDADg6OhIZGcnRo0d58eJFusFfKRwdHenTpw/9+/dn9+7dPHjwgOPHj2tNd54ZJycn/vjjD65evcq1a9fo0aNHqqfhSpYsyT///MOTJ0948eJFttokKxwdHd9p/kKI90dcXByBgYEEBgbi7e3NiBEjiIyMpE2bNpo0oaGhmvP6iRMnmDFjBk5OTtke4NuzZw9ubm4YG2tPma9WqwkMDCQgIABvb2/WrVtHvXr1sLCwYM6cOdkqY/z48Zw9e5Yvv/ySq1ev4uvri4eHByNGjAAyP8+XLFkShUKBp6cnz58/JzIyMsPyDA0NGT9+POPGjWPTpk3cu3ePc+fOsXbt2izX2cnJicOHD3PmzBm8vb0ZMmQIgYGBWmkcHR05f/48fn5+vHjx4q0/Zf2u8xdCCCGEEP9ZsWIFSUlJ1KpVi127duHr64u3tzdLly6lbt26uLm5UblyZdzd3bl8+TJeXl707t2bxo0ba5aMHjlyJOvWrWPdunX4+PgwZcoUrSXtAKZOncrs2bNZsmQJPj4+3Lhxg/Xr17Nw4UIArl69yuTJk1m7di3169dnyZIljBw5kvv372f6GoKDgzX3ESk/sbGxmv0dOnQgPDycL774gqZNm1KsWDHNPicnJy5evMjBgwfx8fHh+++/58KFC+mWFRQUxIULF2jdunWW2zizMh48eMDEiRM5e/Ys/v7+HDp0SBPEEBMTw/Dhwzl+/Dj+/v6cPn2aCxcuaO5/2rdvz+rVq4mLi6NDhw506tSJypUrY2BgwIkTJ6hRowbu7u4YGRnxyy+/aNXr6tWrXL16lcjISJ4/f87Vq1e5detWll7T1KlT+fHHH1m6dCm+vr5cvnyZZcuWvbU2geT7guvXr3Pnzh1evHhBQkJClvPPinedvyjY3mSMe9++fbRt2zbNfHMyxj1r1iwcHByoXbs2mzZt4tatW/j6+rJu3TqqVq1KZGQkZcuWpW3btgwaNIhTp05x7do1evbsSbFixdKtixAi/5KAKCGEEEKIfKpMmTJcuXIFNzc3Jk6cSJUqVahRowbLli1j7NixTJ8+HRcXF4yNjRkzZgxVq1alTp067Nixg19++UXrKb1X6erqYm1tja5u2qsne3h4pHlzd/PmTezs7ChRogRNmjRhx44dTJw4kZMnT2Jqapqt19aiRQs8PT05fPgwNWvWpE6dOixcuFDrycRdu3ZRs2ZNunfvjouLC+PGjdM8bVavXj2GDh1K165dKVKkCPPmzcu0zJUrV9KpUyeGDRuGs7MzgwYNytaTSYsWLaJQoULUq1ePNm3a0KJFCz766COtNNOmTcPPz48yZcpQpEiRLOedVT/88MM7zV8I8f44cOAAdnZ22NnZUbt2bS5cuMDOnTtp0qSJJk2/fv2ws7OjePHimnPtzp070+0f0rNnz540+43w8HDs7OwoVqwYdevW5eeff6ZPnz5cuXIFOzu7bJVRuXJlTpw4ga+vLw0bNqRatWp8//33WvlkdJ4vVqwY06ZNY8KECdjY2DB8+PBMy/z+++8ZM2YMkydPpkKFCnTt2pWgoKAs1/n777/no48+okWLFjRp0gRbW9tUy6eMGTMGpVKJi4sLRYoU4eHDh1nOPyvGjh37TvMXQgghhBD/KVWqFJcvX6Zp06aMGTOGSpUq0bx5c44ePcrKlStRKBTs3r2bQoUK0ahRI9zc3ChdujTbt2/X5NG1a1cmT57M+PHjqV69Ov7+/nzxxRda5QwcOJA1a9awYcMGXF1dady4MRs2bKBUqVLExsbi7u5O3759NQ9DDBgwADc3N3r16pXpLD5ubm6a+4iUn927d2v2m5ub06ZNG65du4a7u7vWsUOHDqVDhw507dqV2rVrExwczLBhw9It66+//qJ27dqpZoHKSGZlGBsbc/v2bTp27Ei5cuUYPHgww4cPZ8iQISiVSoKDg+nduzflypWjS5cutGrVimnTpgHQtGlTnJ2dGThwIImJiSxfvpzw8HACAgL4888/2bt3L6GhoaxYsSLVwyDVqlWjWrVqXLp0ia1bt1KtWjU+/fTTLL2mPn36sHjxYlasWEHFihVp3bp1qpll36RNIDlwpHz58tSoUYMiRYpw+vTpLOefFe86f1GwvckY95o1a+jVq1ea+eZkjLtQoUKcO3eOnj17MmPGDKpVq0bDhg357bffmD9/PhYWFkDy0pvVq1endevW1K1bF7Vazb59+1ItXymEyP8U6vQWwswj4eHhWFhYEBYWhrm5ebaPT0hIYN++fXz66adyUnrHpK1zl7R37ilIbf2m58z3xZu0Q0F6v98HedHesbGxPHjwgFKlSmFoaJgrZeYHKpWK8PBwzM3Ns7Uk0eXLl2nWrBnPnz+Xz0Q25LS934WM/ual3/iP9B0FQ1629YfYf+TkXPbixQvs7Ox49OgRtra277iG74/81G+A9B1ZIf1GwSHtnXukrXNXQWlv6Tf+I31H9uXFNXh+uy57373a3u3ataNBgwaMGzcur6ulERoaSuvWrYmPj2fSpEl8/PHHmJqaEhwczO+//87y5cs5fvw4VlZWeV3VTOW3v22558hcRu2Q2fkxv73fee1dj3Hn9/Z+n8a0PtRrorxSUNo7O/1G/vuECiGEEEKIPJOYmMiyZcvy9cWuEEKI/CMkJISFCxdKMJQQQgghhBAiWxo0aED37t3zuhpaLC0tOXbsGO7u7kyYMAEzMzMMDAywt7dnz549/PLLLwUiGEqID52McQshUmRvHnwhhBBCCPFeq1WrFrVq1crramTbyZMnadWqVbr7IyMjc7E2Qgjx4ShXrhzlypXL62pk28OHD3FxcUl3/61btyhRokQu1kgIIYQQQogPS36aGepVenp6jBw5kpEjRxIWFkZYWBhFixbN8Swrpqam6e7bv38/DRs2zGlVhRDpKKhj3EKIt08CooQQQgghRIFXo0YNrl69mtfVEEIIUUDY29tn2G/Y29vnXmWEEEK8NSq1CrVajVJHmddVEUII8R6wsLDAwsLijfLI6L6jWLFib5S3EEIIITImAVFCCCGEEKLAMzIywsnJKa+rIYQQooDQ1dWVfkMIIfKJ6IRoNntv5vMyn2NrkvMlWF/GvqSTRyccLRxZ88kaFArFW6ylEEIIkTNy3yGEEELkHZ28roAQQgghhBBCCCGEEEKID9P6m+tZdmUZM8/NfKN8DvodJCgmCK9AL84Hnn9LtRNC5AWVSpXXVRBCvGXyuRZCCJEXZIYoIYQQQgghhBBCCCGEEHni1ONTyf8+PUVYXBgWBjlbmuig30HN/7fc2kIduzpvpX5CiNyjr6+Pjo4OT58+pUiRIujr67/z2d5UKhXx8fHExsaioyNzCLxr0t65J7+0tVqtJj4+nufPn6Ojo4O+vn6e1UUIIcSHRwKihBBCCCGEEEIIIYQQQuS6l7EvuRl8E4BEVSJH/I/QsVzHbOcTFB3EpWeXNL+feHyCh+EPKWFe4q3VtSB4FP4IfaU+NiY2eV0VIXJER0eHUqVKERAQwNOnT3OlTLVaTUxMDEZGRrLUZi6Q9s49+a2tjY2NKVGihATCCSGEyFUSECWEEEIIIYQQQgghhBAi150LOIcateb3/X77cxQQddj/MGrUVC5SGQt9C04+OcnW21uZUGvC26xuvhYSG0KnvzphomeCZ3tPjPWM87pKQuSIvr4+JUqUIDExkaSkpHdeXkJCAv/88w+NGjVCT0/vnZf3oZP2zj35qa2VSiW6urr5IjBLCCHEh0UCooQQQgghhBBCCCGEEB+MxxGPMdQ1xNrIOq+r8sE7/eQ0AM1LNuew/2EuBF7gRcyLbL83Bx4cAKClY0vKWJTh5JOT7L67m+FVh2Oqb/rW650fnQ84T3RiNNGJ0fx17y+6OnfN6yoJkWMKhQI9Pb1cCeJQKpUkJiZiaGiY50EjHwJp79wjbS2EEEKAzEsohBBCCCGEEEIIIYT4IOy4s4PWf7bGfa87arU68wPEO6NWqzn79CwAnct1prJ1ZVRqFQf9DmYrn8CoQK4+v4oCBZ+U/IS69nUpbVGaqIQo/rz757uo+lsVEBnAHK853Aq+9Ub5eAV6af6/2XszKrUqx3mdeHSCP33/JFGV+EZ1EkIIIYQQQoi8JAFRQgghhBD5WGBgICNHjsTJyQlDQ0NsbGxo0KABq1atIjo6GoArV67QunVrihYtiqGhIY6OjnTr1o3g4GAA/Pz8UCgU6Orq8uTJE638AwICNFNW+/n5ae3z9/fHwMCA8PBwAMLDw5k0aRLOzs4YGhpia2uLm5sbf/zxR5a+TOrbty8KhSLDHyGEEG/u9fOtlZUVLVu25Pr165o0r+7X1dWlRIkSjBkzhri4OE2aDRs2YGlpmWYZCoWC3bt3a22LiYnB2NiY27dvAxAfH8+8efOoUqUKxsbGWFtbU79+fdavX09CQkKmr2Pq1KmZ9huv911CCJGeRFUic73mMv3cdJLUSTyNekpwbHBeV+uD5hvqS1BMEIZKQz6y+YhWpVoBsP/B/mzlkxJAVa1oNWxMbFAoFLhXcAdgq/dWklTvfsmtnPIO9sZ9nztbvLfw48Uf3yivC4EXNP/3C/fj1JNTOconUZXI/IvzmXxmMtvvbH+jOgkhhBBC5HSMYvTo0fl2jEKpVFKoUCGUSqWMUQiRz0lAlBBCCCFEPnX//n2qVavGoUOHmDVrFleuXOHIkSOMGjWKv/76iyNHjhAUFISbmxvW1tYcPHgQb29v1q1bh52dnSZgKoW9vT2bNm3S2rZx40aKFSuWZvl79uyhSZMmmJubExoaSr169di0aRMTJ07k8uXL/PPPP3Tt2pVx48YRFhaW6etZsmQJAQEBmh+A9evXp9omhBDizbVs2VJzbj169Ci6urq0bt1aK03KOfjBgwesWLGCzZs3s2DBghyXefjwYRwcHHB2diY+Pp4WLVowZ84cBg8ezJkzZ/Dy8uLLL79k2bJl3Lx5M9P8xo4dq9VHFC9enB9++EFrm4ODQ47rK4T4cETERzDi7xFs9t4MgL6OPgB+YX55WKv8LXjtOp6MHoMqKuqdlZEyO1R12+oYKA34xPETFCi49vwaTyKfZHL0f1IColqWaqnZ1qZMG8z1zXkc+ZgTj0+83Yq/JScfn6Tvgb48j3kOwOWgy0QnRGdyVNqeRT3DP9wfHYUOHct2BGDTrU2ZHJU2z/ue+If7Y2lgSTundjnKQwghhBDiVTkZo/j111+ZMWNGjst8l2MUT548wd7enmnTpskYhRD5nG5eV0AIIYQQIjep1WpiEmPypGwjXaNszYI0bNgwdHV1uXjxIiYmJprtrq6udOzYEbVazZ49ewgPD2fNmjXo6iZf2pUqVYomTZpoZnZK0adPH9avX8/EiRM12zZs2ECfPn2YPn16qvL37NlDhw4dAPj222/x8/PDx8cHe3t7TZpy5crRvXt3DA0NAXj58iUjR47kr7/+Ii4ujsaNG7N06VLKli2LhYUFFhYWWmVYWlpia2ub5TYRQoi8VJD6EAMDA8351dbWlvHjx9OoUSOeP39OkSJFAO1zsIODA23atOHatWs5ruOePXv4/PPPAVi8eDH//PMPFy9epFq1apo0pUuXpnPnzsTHxwMQFxfHN998w7Zt2wgPD6dGjRosWrSImjVrYmpqiqmpqeZYpVKJmZmZ9BtCiGx5HPGYEX+P4G7oXQyVhsxsMJM/7v7B6Sen8Q/3p4ZtjbyuYr6jjo/n+eLFqBMSUBgbYf8GX0Rl5PST0wDUt68PQFHjotS0rYlXoBcHHhxggOuATPN4HPGYGy9uoKPQoXnJ5prtRrpGdCrXiXX/rmOL9xaalWj2Tl5DTv3u8zszzs0gSZ1Ebbva+If7ExgVyMVnF2lUvFG280tZLs+lsAuDKg/iz7t/cj7gPHdC7lC+cPks55OQlMCqa6sA6F+pPyZ6JpkcIYQQQoi88uoYhUqlIiYxBt0EXXR03v18KLkxRvH5559z+fLlHNfxXY5RqFQqGaMQooCQgCghhBBCfFBiEmOovbV2npR9vsd5jPWMs5Q2ODhYMzPUq8FQr1IoFNja2pKYmMiff/5Jp06dMrwR/fzzz1m1ahWnTp2iQYMGnDp1ipCQENq0aZMqICo0NJSTJ0+yYcMGVCoV27Ztw93dXSsYKsWrX1b37dsXX19fPDw8MDc3Z/z48Xz66afcunULPT29LL12IYTIrwpKH/K6yMhItmzZgpOTE1ZWVmmm8fHx4fjx43Tr1i1HZahUKjw9Pdm1axcAW7Zswc3NTWugMYWenp6mTxg3bhy7du1i48aNlCxZknnz5tGiRQvu3r1L4cKFc1QXIUTuiX/4kITHjzGpVy+vq5KmK0FXGPn3SF7GvaSoUVGWNltKReuKXA66rAmIEqnF3vFB/f9lQ8J+34Vp48aYN2+eyVHZE5MYw6Vnl4D/AqIgeZYnr0AvDvhlLSAqZXaoGjY1sDay1trX3bk7G29uxCvQK9uBQe+KWq1m2ZVlrL6xGoDPy3zO1LpTmeU1i999fufM0zNvFBBV064mxUyL8XGJjznsf5gt3lv4of4PWc7nz7t/8iTyCVaGVnRzztk1gRBCCCFyx/s+RnHs2DH69u2bozJkjEIIkUKWzBNCCCGEyIfu3r2LWq2mfHntQXtra2vN0yjjx4+nTp06fPvtt/To0QNra2tatWrF/PnzefbsWao89fT06NmzJ+vWrQNg3bp19OzZM81ApX379uHq6oqDgwMvXrzg5cuXODs7Z1jnlECoNWvW0LBhQ6pUqcKWLVt48uRJqjXchRBCvFuenp6a/sLMzAwPDw+2b9+u9aRo9+7dMTU1xdDQkPLly+Pi4sKoUaO08gkLC9Pk8+rP686dO4dKpaLe/4MifH19M+03oqKiWLlyJfPnz6dVq1a4uLiwevVqjIyMWLt27VtoBSFEepIio1DFxr5RHqroaPx79uJh/wFEnTnzlmr29ng+8GTAwQG8jHtJhcIV2PrZVipaVwSgpHlJAPzC/fKwhvlXzI3ryf/5/31C4Hffk/As6K2WcenZJeJV8dia2FLKopRme/MSzdFV6HI75Db3w+5nmk9KQFQLxxap9tma2OJW0g2ALd5b3lLNcy4+KZ6JpyZqgqG+qPIFM+rPQE+ppwkKS5k1K7suBF4AoJZtLQB6u/QGYO/9vQTHBGcpj7ikOH65/gsAgyoPwkjXKEd1EUIIIYR4XU7GKCpWrKi10gHIGIUQIvtkhighhBBCfFCMdI043+N8npWdXa/P+OTl5YVKpcLd3Z24uDgAZs6cyejRo/n77785d+4cq1atYtasWXh6elK3bl2t4wcMGEDdunWZNWsWO3fu5OzZsyQmJqYq99UphdVqdZp1eZ23tze6urrUrv3fk0lWVlaUL18eb2/vbL92IYTIbwpSH9K0aVNWrlwJQEhICCtWrKBVq1Z4eXlRsmRyIMCiRYtwc3MjKSmJu3fvMnr0aIYMGcLvv/+uycfMzCzNKerLli2r9fuePXto3bq1ZjBTrVZn2m/cu3ePhIQE6tf/b2YQPT09atWqJf2GEO9QYkgI91p9ip69PY7bt6Gjr5+jfEI2bSIxKDlIJnj9hnwzS5RKreJQzCH+OfsPAG4l3JjZYKbWE+wpAVEyQ1TaYq/fAMCqb18iT58i7pY3ARMn4rBmNYq3tATLq8vlvdpfWBpaUte+LiefnOTAgwMMqzos3Twehj/EO8QbpUKptVzeq3pW6MlBv4Psvb+Xr6t/TWHDvHmyPywujFHHR3Eh8AK6Cl0m151M+7LtNftr2dVCqVDiF+7H08in2Jumnpk3PU8in/Ak8gm6Cl0+KvoRAFWKVMHV2pUbL26w484Ovqj6Rab5/O7zO8+in2FjbEOncp2y/yKFEEIIkateHaNQqVRERERgZmaWa0vmZUdOxyh69erFtm3bNPnIGIUQIrskIEoIIYQQHxSFQpHj6Xxzk5OTEwqFgtu3b2ttL126NABGRto3nVZWVnTu3JnOnTsze/ZsqlWrxvLly1MFRFWqVAlnZ2e6d+9OhQoVqFSpElevXtVKk5CQwIEDBzRP4BQpUoRChQpleuOXEjiV1vbsrCkvhBD5VUHpQwBMTExwcnLS/F69enUsLCxYvXo1M2bMAMDW1laTpnz58oSFheHu7s7du3cpV64cADo6Olr5pMfDw4PZs2drfi9XrlyW+43X+wjpN4R4t6LOnkUVFkZcWBgvN23CauDAbOeRGBJC8Oo1/+V58iRxvr4YvPZFRG6ISojiccRjHkc+5knEE049OcXZuLMADHIdxPBqw9FRaH8p5GjuCMDDiIckqZJQ6ihzu9r5WsyN5IAoo4+qYdGuLQ86dCTqzBle/vorhfv0eStlnH2a/B7Vta+LWq0m9tYtDMuXR6GrS6tSrTj55CT7H+zniypfpNsnHPA7AEBtu9oUMiyUZpoqRapQyaoS/wb/y847OxlSZUiW65igSkBP582X/X4a+ZRhR4ZxL+weJnomLGy8kHrFtAMIzfXNcbV25erzq5x9epaO5TpmOX+vgOTl8ipaV9RcpygUCnq59GLcP+PYdmcb/V37Y6A0SDePmMQYVl9PnrlqcOXBGaYVQgghRP7w6hiFSqUiUTcRYz3jXAmIyq6cjFFERETQvXt3ZsyYodkuYxRCiOzKf2dEIYQQQgiBlZUVzZs3Z/ny5URFRWXrWH19fUqXLk10dHSa+/v378/x48fp379/mvuPHTuGpaUlVatWBZJvNLt27cqWLVt4+vRpqvRRUVEkJibi4uJCYmIi58//N3tKcHAwPj4+VKhQIVuvQQghxNulUCjQ0dEhJiYm3TRKZXJAQEZp0uLr64ufnx+ffPKJZluPHj04cuQIV65cSZU+MTGRqKgonJyc0NfX59SpU5p9CQkJXLx4UfoNId6h6AsXNP9/sWJljpZCe7FyFaqoKAwrVsT044+B5Bmj3qVEVSKe9z1ZcnkJ35z4hh57e9BoWyPqbK1Dp7868fWxr5l/cT5nA86iRMn0utP56qOvUgVDQfJSavo6+iSqEnkalfr69kOWFBlJ/P3kpeqMXF0xKFOGouPHARD040Ji7/i8cRmBUYHcC7uHjkKHOnZ1CFm3Dr+OnXj67bcANCvRDAOlAX7hftwOuZ1uPikBUWktl5dCoVDg7uIOwPY720lISsi0fn5hfnT5qwtuO914EvkkOy8tlfuh93Hf5869sHsUNS7KxpYbUwVDpahnn7z99NPsLZv3+nJ5KdxKumFjbENIbAj77u/LMI/tt7cTHBtMMdNitHdqn2FaIYQQQog3JWMUQojcIgFRQgiRTfFJ8ey7v4+NNzcSlxSX19URQrzHVqxYQWJiIjVq1GD79u14e3tz584dNm/ezO3bt1EqlXh6etKzZ088PT3x8fHhzp07LFiwgP3799OqVas08x00aBDPnz9nYDqzAXh4eGiWy0sxa9YsHBwcqF27Nps2beLWrVv4+vqybt06qlatSmRkJGXLlqVt27YMGjSIU6dOce3aNXr27EmxYsVo27btW28fIYQQ6YuLiyMwMJDAwEC8vb0ZMWIEkZGRtGnTRpMmNDSUwMBAnj59yokTJzRPXWZ3oG/Pnj24ublhbPzf7Flff/019evX5+OPP+ann37i2rVr3L9/nx07dlC7dm18fX0xMTHhiy++4JtvvuHAgQPcunWLQYMGER0dzYABA95aWwghtEVfvAiAjqkpquhoni/8MVvHxz96xMv/L1tRdOwYrPr3AyBsjweJwcFvt7Kv2OWzi4knJ7LmxhoO+B3gxosbvIx7CYClgSUVrSrSwrEFfV36MtR0KJ+V+izdvHQUOpQwLwHIsnmvi/33JqjV6Nnbo2ttDUCh7t0xbdwYdXw8T8eORRX3ZmMhZ56eAaCSdSWMQ+N4/tMKAMI9/iLyxAlM9ExoVLwRAPsf7E8zj/uh9/F96YuuQpePS3ycYXktSragiFERnsc856D/wQzTHvI7RLe93fAO8SYkNoRtt7elmzbq3DlerFxJUmT6D7AsvLSQFzEvKFuoLFs+3UL5wuXTTVvXPnl233MB50hSJWVYzxRqtRqvwOQZomra1tTap6ejR48KPQDY7L053Rl9oxKiWPvvWgCGVhmKnvLNZ8USQgghhHhVTsYofvjhB8qVKydjFELkIxGxCfzm9ZCt5x+iUqV9f5HfyJJ5QgiRRX5hfvzu8zt77u0hNC4UgEP+h1jSdAnWRtZ5WzkhxHupTJkyXLlyhVmzZjFx4kQeP36MgYEBLi4ujB07lmHDhhEYGIixsTFjxozh0aNHGBgYULZsWX755Rc6dOiQZr66urpYW6d/3vLw8GDdunVa2woVKsS5c+eYM2cOM2bMwN/fn0KFCuHq6sr8+fOxsLAAYP369YwcOZLWrVsTHx9Po0aN2LdvH3p6MqguhBC56cCBA9jZ2QFgZmaGs7MzO3fupEmTJpo0/folBzEoFApsbW1p2LAhEydORFc3e0MFe/bsoc9rSygZGBhw+PBhFi1axM8//8zYsWMxNjamQoUKfPXVV1SqVAmAOXPmoFKp6NWrFxEREdSoUYODBw9SqFDaSx8JId5MYkgI8XfvAVBs0UIeDRpM2B4PLLt1w7hatSzl8XzxEkhIwKR+fUzqJi93ZujqSuyNG7z8bRtFhn/5Tuq+594eABoXb0xN25oUNytOcdPiFDMthqm+qSZdQkIC+55mPBsOQEnzktwNvYt/uD8NijV4J3UuiGJuXAfAsHJlzTaFQoHdzBnc/7wtcb6+PF+4CJuJE3JcxuknyTMg1bevz/OFC1FHR6PQ10cdH0/AtGmU+esvWpVqxWH/wxzwO8DX1b9ONdPXQb/kwKa69nWxMLDIsDw9pR5dy3dl+dXlbL61mc9KfZZq2ZMEVQKLLi3i11u/AlDCrAQPIx7y590/+bLqlxjqGmrSJr54wbM5cwn39AQg1seHYgsXpsrzUcQj/nn8DwALGy/E1sQ2w3pWsq6Emb4ZEfER3Ay+SeUilTNMD8nLPj6Lfoaejh5Vi1ZNtb9j2Y6surYKn5c+eAV6Uduudqo0W7y3EBoXiqO5I61LtwYgeO064u7fo8iwYegVK5ZpPYQQQgghMpKTMYpGjRoxa9YsGaMQIh+48TiMLef98bj2lOj45Ic3TvgEsbBLVUwM8nfIUf6unRBC5LGEpASOPjrK73d+53zgf0tA2RjbEJ0YzfXn1+nm2Y2lzZbiYuWShzUVQryv7OzsWLZsGcuWLUtzf+nSpfnll19SbVepVISHhwPg6OiY7tPAAFWrVtXsv3z5MuHh4TRu3DhVOgsLC2bPnq21/vrrChUqxKYsLpeSUZ2EEELk3IYNG9iwYUOGadI6B7/adwD07duXvn37Znj8ixcvOHfuHDt37kyVxsDAgAkTJjBhQvpfmhsaGrJ06VKWLl2aYX0B/Pz8Mk0jhMhY9KVLABiULYtpw4ZYdOxA2K4/eDZjJo47d6DQyXgy+Zh/bxK+dy8oFBQdOwZI/sKicN8+PB0zlpdbt2I1aCA6BgZvtd5+YX7ceHEDpULJ1HpT38pDSSXNS2ryFv+JvX4DSF4u71W61tbYzZzB4y+GEbJxIyaNGmJQq1ZaWWQoSZXEuYBzANQPLUrYnuT7HIfVqwn49lsSnjwhaMkSGo4bjYmeCQFRAVx7fo1qRf8L2FOr1Zrl8lqWapmlcjuX78wv13/hZvBNrj2/phU89CzqGWNPjOXq86sA9KvYj+HVhtP6z9YERAVw0O8gbZ3aolapCP39d4IW/IgqPBx0dEChIGL/AcIaNsKyg/ZSczvu7ECNmvrF6uNo4ZhpHXV1dKljV4fD/oc5/fR0lgKiUmaHqlykMka6Rqn2WxhY8HmZz9l+Zzu/3vo1VUBUeHw4G25uAOCLKl+gq6NLUkQEL375BVVYGCa1a2MhAVFCCCGEeAM5HaN4XX4bo7h+/Trm5uaZphOioIqKS8Tj2lO2nn/IjSdhmu2lrU14/DKGgzef0XHlGdb0qUHxQsYZ5JS3ZMk8IYRIQ0hSCEuvLsXtdze+OfEN5wPPo0BBo+KNWNZsGQc6HuC3z37D0dyRZ9HP6LO/D4f8DuV1tYUQ4o0lJiaybNkymdFJCCFEloSEhLBw4UJsbTOe9UII8eaSwsMJ2bSJhGfPcpxH9IULABjXrAFA0VGj0DE1JfbmTcL++EMr7a+3fmXDvxs0v6vVaoJ+XACAeZvWGL6ydIV5ixbo2tuRFBJC+F9/5bh+6dn7YC+QPBvQ25qh2dHcEXi3S+ZFxEcw12subXe3xeelzzsr522KuZEcEGXoWinVPrOmTbHs3g2AgInfkhQamu38/w3+l/D4cMz1TDFfkfxFlUX79pjUroXttGkAvPx1M+qbd2jm0AxIvWyeb6gv98Puo6ejR1OHplkqt7BhYT4r/RkKtZqQAV/iU68+AZOncGHferp6dObq86uY6ZmxuOliRtcYjb5Sny7luwCw/c524nx98e/Zi8DJU1CFh2Po4oLj9u0UGTECgMAZM4h/JXA3JjGGP3yTP1M9nHtkuX1Sls07+/RsltJfCEj+TNeyTT84rWeFngCceHwiVQDgppubiIiPwMnSSRNcFrJxE6qwMPTLlMH8s/SXnhRCCCGEyG9kjEKIN/ckCqb8dYvas44y8Y8b3HgShr5Sh7ZV7dk+uA5HxzTmt8F1sDY14HZgBG2Xn+aiX0heVztdEhAlhBCvuBp0la+Of8XCiIVsuLWBkNgQihgVYUjlIRzseJCfPv6JJg5N0NXRpaR5SbZ8toX69vWJTYplzIkxrLy2UmY8EUIUaLVq1aJXr155XQ0hhBAFRLly5Rjx/y+DhRDvjio2lkdDhvJs1myC5s7LcT7RFy8CYFwjOSBK19oa6/8vcRe0cBFJ/58l7pDfIeZdmMePl37kUcQjAKJOnSb67DkUenoU+WqkVr4KXV0K90y+hgzesOGt3her1Wo87yUvTZaynNfbkDJD1LsIiFKr1ey9v5fPd3/OZu/N3A+7z777mS/jl9cSgoJIDAwEHR0Ci5sQFB2UKo3NuHHoly5NYlAQQdOmQTbf6zNPzwDQ82EJYq9fR8fYmCKjvgbAtEF9zD9vA2o1Ad9PppVDcyB5ebxEVaImjwMPkmeHalCsAWb6Zlku272CO+Ufg51vCEkhIYTu2IHp6HnM/PE5X580Z2vJqZogLID2Tu0xTlJS6fer3GvXnpjLl9ExNsbm24k47tiOkWslrAYNxLhWLdTR0TwZ+w3q+HggOYgrPD6c4qbFqW9fP8N6Rfx9jLuftCDk183Us68HwPXn14mIj8jwOLVarZkhqqZtzXTTOVo40rh48gzAm703a7a/jH2p+X1Y1WHoKHRICg0l5P8zOBQZ/iUKpTLDOgghhBBC5CcyRiFEzqjVao7dDqLrai/mXddlq9djIuMSKWVtwrefOnPu249Z0q0atUtboVAoqF6yEHuG18fFzpzgqHi6rz7HzouP8vplpEmWzBNCCOBi4EV+vv6zZtp2BQrq2NWha/muNHJohJ7OfzOlqNVqQrdtI+badQr378fyj5ez8NJCfr31KyuuruBe6D2m15+e5lTlQgghhBBCCCFEdqiTkngydiwxV64AEPnPP6gTElBkc0bPpIgI4rxvA2D0/4AogMLu7oTu/J34e/d48dNP6H49mBnnZmj233h+g+ImxQj68UcACrm7o1889RJalp078WL5cuLv3iPq1GlMGzbI9mtNy7Xn13gc+RgjXaMszwaUFSkBUQFRAcQmxmKoa/hW8r0fep+Z52dqAlWMdI2ISYzh3+B/30r+b8PZp2e5HHSZl7EvCYkN4WXsS17GvsThWiDDgIdWKsYe7oaB0oCNrTZS0aqi5lgdIyPs58/Dr1t3oo4cxdzSErIxi9CZJ2cwjFNT3+MBAFZfDEWvaFHNfpuJE4k6eYo4Hx/K7ffGspAlIbEhXAi8QF37uqjVag75J8/Q3cKxRbZed/nC5Wnnbw0841YZPQJME6l9R03hSKh3KoSYUyO5V6wY5p9+ivlnn2Lw/AVL1ykxf6EGkjB1+xjbSZPQs7PT5KlQKrGfN5f7bdsR+++/PF+2jCKjR/Pb7d8A6ObcDaVO+kFFEUeO8HjUaEhI4NmcOThWdsXR3BG/cD+8Arz4uOTH6R77IOwBwbHBGCgNqFKkSoavvZdLL048PoHHPQ9GVBuBhYEF62+uJyohigqFK/BxieRygtetRxUZiUH58pi1yF77CiGEEEIIIQoWlUrNYe9nLP/7rmZZPKVCTYuKtvSs40jdMskBUGkpZmnE71/UZcyOa+z/N5Bvfr+Oz7MIJrSqgFIn7WPygswQJYT4YKnVas4HnKffgX70O9iPcwHn0FXo0q5MO742+5qfmv7ExyU/1gqGSoqM5MnXowic9gNhu3fzoF17nk+dzuhS/ZlWbxq6Oroc9DtIn/19CIwKzMNXJ4QQQgghhBCioFOr1QTOmEHkkaMo9PXRMTVFFRlJ9KXL2c4r+tIlUKvRL1lSKwBFoaeHzbcTAQjZvIWf/pzAy7iXmv03Xtwg/K+/iLt9Gx0zM6yGDE4zf6WZGZadOyXn8/8ZZt4Gz/vJs0O5lXDDWM/4reVb2LAwZnpmqFFrZsF6E9EJ0Sy6tIiOHh3xCvTCQGnAV9W+Yu0nawG4+eImKrXqjct5Eyq1isWXFjP48GBWXVvF9jvbOex/mIvPLnIv7B42/skzhN21U2CgNCAuKY5xJ8YRlRCllY9RxYoU+Sr5yfuiHn8R5+2dpfLD48O58eIG7c+q0AuJQK9ECQr36aOVRrdQIWwmTgDg5cqfaW9QG/hv2bzbIbfxD/fHQGlAE4cm2Xr96qQkqvwbDcDu6klsaGPM460/UHzlCszbtEFhbEzCkycEr17Ng3bteTRoEOYvonlhBos7G2L+40ytYKgUera22E3/AYDgNWu5fmAzt0NuY6A0oJ1Tu/Tb4/BhHn89ChISUBYqBElJPB0/gQZWybM9pcymlZ6UoLuqRaqir9TPMG0t21qUK1SOmMQYdvnu4kXMC7bd3gbAl1W/REehQ2JwMCGbk2eMKvLVCBQ68tWBEEIIkd/ICiUiK+TvRGRGpVKz93oAny49yZBfL3HjSRjG+koGNnBk6kdJLOlahXpO1ukGQ6Uw1tflpx4f8dXHZQFYffIBAzdeIDw2ITdeRpbIXY0Q4r2gVqmIOHKE2Dt3Mk+rVnP6yWl67+/NwEMDufjsIno6enQp14W9HfYyufZkrJRWqY6L8/XFr3MXIg4eBD09jOvUAZWK0B07uPdJCxr9/YI1jVdQyKAQ3iHedN/bnevPr7+LlyuEEEIIIYQQ4gMQ/PPPhP62DRQK7OfPx8zNDYDI48eznVfM/5fLM6pZI9U+0/r1MXX7GJKSKL/pNLoo6e3SG4CbAVcJWrIEAKvBg9AtVCjdMgr16gU6OkSdPk2sj0+26/i6hKQEDvodBN7ucnkACoVCM0vUw/CHOc5HrVZz1P8obfe0Zd2/60hUJ9KkeBN2t93NoMqDcLZyxlBpSGRCJH7hfm9U5/jHj1EnJmaeMA0xiTGMOT6Gtf8mB2i1dGzJ4MqDmVBrAvMazWP1J6vpmFAZgK7tv+No56PYmtjyMOIhs87PSpWfVf/+GNWqiU58PE/6DyDKyyvTOpwPOI9VSCJt/p/UZvw4dPRTB/KYt2mDSYMGqOPj+WTbPRRqNUceHiE+KZ4DfsnL5TUq3ggTPZNstUH0hYsoX0YQa6xLYvWKbP50M+1dOmPWtCnF5s+j3OlTFFu8CLPmzVHo64OODoV69+anb8pxxikRj3se6eZt/sknWHbpAmo1CdMWYhat5rPSn2FhYJFm+vBDh3gyajQkJmLeujWl93qiW7Qo8X5+uO1LfsAuqwFRGS2Xl0KhUNDLJXlZy63eW/n52s/EJMZQ2boyjYo3AiB49RrU0dEYVqqEabNmGWUnhBBCiFym9//ZYaOjo/O4JqIgSPk70cvmrMLi/ZekUrPn6hNaLP6HL7de5nZgBKYGunzZtAynxjdjfItymGf8rEUqOjoKRjcvx7Lu1TDQ1eHYned0WHEGvxdRmR+cC2TJPCFEgadOTCTg+8mE/fknAGaffILV8C9JcLQlMj6SiPgIIuIjiEyIJCQ2hJ13dmqmqjdQGtCxbEf6VeqHrYktAAkJqaNWw/7yJGDyZNQxMeja2lJ8yWKMqlQh+uJFns2Zmzwt+qJFmG+3Y9OwgYw2+APf8Hv0O9CPOY3m0Lxk89xrECGEEEIIIYQQBV7oH3/yfHFyIJLNpEmYt/gE1GrCdu8m8sQJbCaMz1Z+0ReSA6KMa6QOiAIwGDmYl8eOUtlPzYS4ZtQt35VNtzZR4tBNEp8moGtjQ+FevTIsQ794ccyaNyfi4EFCNm7EfubMbNXxdaefniY0LhRrI2tq2dV6o7zSUtKiJP8G/5vjQKXAqEB+OPsDJ5+cBMDexJ4JtSbQtMR/S/vp6ehRwaoCV4KucPPFTUpblM5RWVFnzvCw/wAMK1bE4Zef0bVK/SBXeoKigxjx9whuBd9CV0eXafWm8XmZz7XSqFUqfO48QAWYVK6CkYEFcxrOof/B/njc86CufV2toDSFUont4sXc7NkT4/sPeDRwEMUWLcTs4/SXeDv95DS9/lahm6TGpF7ddINuFAoFtlOncL/N5yiv3eZzRwv2uERw6skpTYBcdpfLAwjfnzzLlM2nbfmt7YxU+3WMjDBv2RLzli1JiowCVRJKc3M63NnBzXPT2XFnBz0r9Ez3KWmbCeOJ8DqHid9Dhu5TULNz17TrcfAQT0aPhqQkzNu0wX72LBS6utjNnMmjQYMw3n2MqsZ6XC35mIfhDylhXiJVHiq1iguBFwCy/Nn4tNSnLLq0iGfRz9h25/+zQ1X7EoVCQcKzIF7+lrzMX5GRX2X6JLgQQgghcpdSqcTS0pKgoCAAjI2NtfprlUpFfHw8sbGx6Mgsj+9cfm1vtVpNdHQ0QUFBWFpaolSmv3SzeH8lJqmIjEskPCaR8NgEImITiYhNICAslo1n/Lj//0AlM0Nd+tcvRb/6jlgaJ0dBpfUdeVa1qWKPo5UJgzZd5G5QJO1WnGZtn5pUL5n+Q1W5QQKihBAFmio+nqdjvyHi0CFU/7/2izh0iLBDhzjjomBnAx0CrFIP4hgqDelSvgt9K/aliHGRdPNXx8fzbO48Xm7ZAoBJvXrYL5iPbuHCQPJAsuOO7YR7ehK0cBGJTwNI/G42810rsu2TqmzTv8rYE2P5vs73dCrX6e03gBBCCCGEEEKI907kP/8Q8P33AFgNGkjhnu4AmNSvB7q6xD94QLyfH/qOjlnKTxUdTczNmwAY10g9m4xarWbOkw0Urq2g4xk1H22/RrFeRbBXmdP2dAiQvISWjqFhpmUV7tuHiIMHCff4i6KjRqFrbZ1herVaTej27bzcsQPb777D+KOPNPtSlstrVaoVujpvfxgzZYYo/3D/HB0/6dQkvAK90NXRpV/FfgyqPAgjXaNU6SpZV+JK0BVuvLhBmzJtclTWy+07AIi9eRP/Hu44rF2DfvHimR7nHezN8L+HExQdhKWBJYubLqa6TfVU6eL9/VGFh6PQ18ewXDkAqttUZ0jlIay8tpIZ52ZQpUgVHMwcNMcozcx40r8/Vf8+RtTff/N4xFfYTZ+OZccOqfJXq9W8OPk3XX3UqHV0sJk4McOgG/3ixSny1VcEzZ1Ll8MxnCihZtmVZTyJfIKRrpFmVqOsUicmEnHoEADmrVplml5p+t/sU5+V/oyFlxbiF+7H+cDz1LGrk+YxOsbGnB9SjyrfPaSmrxrbw9egu4tWmvADB3gyZmxyMNTnbbCfPRvF/7+oMm3YAMvu3Qj9bRvD9yn4qp+KM0/PpBkQ5fvSl9C4UIx0jahkVSlLbaCv1Kdb+W6suLYCgI+KfkRdu7pA8mx06rg4jKpVw6RBgyzlJ4QQQojcZWub/FB/SlDUq9RqNTExMRgZGUlgcy7I7+1taWmp+XsR779/n4Qx1eMmj1/GEB6bQHR8UobpLY31GNigFL3rOWJu+HZnEXMtboHH8PoM+vUS1x6F0nPNeVb2/Igm5Yu+1XKyQwKihCgAVGoVF55dIFQVmtdVyVdUMTE8HvEVUadOkaiERW11CCisoPMpFXVvq2lwS0097yTOVzHkRHMb4m0KYapviqu1K+4V3LEyyvhpyoTAQB6PHUvsteRl76y+GEqR4cM1A1UpFDo6WHz+OWbNmxOycSPBv6wm/sZNOtyAmjUcmF73KdPOTiM0LpQBlQbky4sjIYQQQgghhBD5Q8yNGzwe+TUkJWHR9nOKjB6t2ac0M8O4Rg2iz50j8sQJCmcxICrm6lVITETX3g794sVS7T/od5DD/ocxqadPx7umJD55Ssj69fS8ZYJpbAgxDkWwaNcuS2UZV6uGUZUqxFy7xsutv1HkqxHpplVFRREwZSrhnsmBT6Hbd2gCoiLiIzj+6Djw9pfLS+Fo7gjkLCAqLimOawGXMItR80vnX6lknX5QSkrAyr8v/s1RPZPCw4k8dgwApbU18f7++HXvTonVqzF0dk73uGMPjzH+5HhiEmMoZVGKn5r9hIO5Q5ppY/9NrpuhiwuKV5bWGFx5MOcDznM56DLj/xnPxlYb0dP5b79aTw/bHxfwYvoMwv74g4BJk0gKfYnVgAFa+T8IuUcbz+cAmHfrjEHZspm+7sK9eib/bdy8Sb/DCha1vwtA4+KN0ww8y0jUufMkvXyJsnBhTGrXztaxJnomtCndhm13trH99vZ0A6ISkhJYl3Cc2k106HNUxbM5czGuUUPzWsP37+fJ2G80n227WbNSjTHZfPMNUafPYP7wIf0OKzhT9gzdnLulKitldqiPin6EnjLrX2J0Kd+Ftf+uJS4pjuHVhifPDvXkCS937gSgyMiRMm4lhBBC5FMKhQI7OzuKFi2aahaXhIQE/vnnHxo1aiTLpOWC/Nzeenp679XMULEJSdwJU1A7Kh5by/zV1vnB/eeR9FnnRXBUfKp9RnpKzAx1MTPUxdxIDzNDPeqXscK9TklMDd5dmFBRc0N+G1SbLzZf5oTPcwZuvMiPXarQtmrqsYjcIAFRQhQAv93+jTlecwDYvXc3DR0a0rBYQ6oWrao1CPUhSYqI4NHQL4i5dIl4PR3mdoTnleyZ3WA21oOsMXwQSNyqDUQfP0Hdq7HU/fcJlu1rYf3FUPTs7TPN39jXl0dz5qJ6+RIdc3Ps583FrEmTDI/RMTLCeuhQLDt25PnSZYTu2oXDxUcs9zFkfst4lrCEl7EvGVNjDDqK/DOFphBCCCGEEEKI/CHe359HQ4aijonBpH597KZPTxWcYNqk8X8BUX36ZCnf6IvpL5f3IuYFM88nL23Xu8Zgitk78mT0GIJ/WU21pOQvWs60LcNH2RhUL9yvL0++HsXL337DavCgNGeWirt3j8dfjST+3r3/6nn1iub/R/yPEJcUR2mL0lQoXCHLZWdHygxROVky707IHb7+PZ6q99U4lHgIn6UfEOVq7QrA7ZDbJCQlZCuABZJnwlbHx2NQtiwOa9bwaNAg4nx88O/Zi+IrfsKklvaSaWq1mk23NvHjxR9Ro6aOXR1+bPIj5vrm6ZYRc/0GAIaVXbW26+roMqfhHDr+1ZEbL27w05Wf+Lr611ppkpd7m4GykCUha9cRNH8BSS9fUmTMGM3fr++GnyjxHGKMdSn3lfbx6VHo6mI3YzoPOnWm7u0kTvqouFhOh5aOLbN0/KvCDyQvl2f2SXMUutkfEu9avivb7mzj2KNjBEYFYmuS+on7ow+P8iLmBV4Ni/BFnBPRp07zZMxYHHfuIPLoUZ58M+7/wVBtsZs1M1UwFCTPMmU/Zw5+PXvS+F8VN46dJqFJQqrxP69ALwBq2qae8S0jVkZWrHRbSWhcqObYF6tWQUICxrVrY1Ine8FiQgghhMh9SqUyVcCLUqkkMTERQ0PDfBeg8z6S9s498w/5sumWkpXex6lc3JKm5YvQtHxRXItZoKPzYQfyB4bF0mttcjBUpWLmzGzniqVxcuCTmaEuesq8+y7aWF+X1b1rMHbnNTyuPeXr7VcJjU6gTz3HXK+LfCMvRAGw7/4+zf/vht1l/b/r6X+wP422NWL08dH86fsnz6Of52ENc1diSAgP+/Ql5tIlYo2U/NBNwSPnwvzc/Gdq2NbA0cIR26p1KLlqFY47tidP9Z2YSOjOndxr0RL/3n142H8ADwcO4uGQITz6YhiPvhzO4xFf8fjrUQSM/Jpia9ehevkSA5cKlPpjV6bBUK/SLVIEu+k/UOrPPzAoXx798Fgm7VDhfiyJLTc28v3p70lUJb67BhJCiA+Un58fCoWCq1evvpP8T58+jaurK3p6erTL4gwJQggh8jeFQsHu3bvfSd63b9+mTp06GBoaUrVq1XdShni/JAYH83DQYJJCQjBwqUCxJUtQ6OunSmfauDEAURcukhQZmaW8oy+kHRClVquZcW4GoXGhOBd2ZpDrIMxatcK4Rg3UsbEoE5K45QAH7FMvy5ERMzc39OztSXr5kjAPj1T7wzz38qBzF+Lv3UO3SBGKr0xewivB/yGJwcEA7L2/F0ieHepdzViTEhAVEhtCeHx4to69d+EI1e+qUarg6bhxRBw5km7a4mbFsTCwIEGVgM9Ln2zXM8zjLwDM27RBz6YoJTf/ilGN6qgiI3k0cBDhhw9r0iaoEph2dhoLLi5AjZrO5Tqzwm1FhsFQALHXk2fHNnKtnGqfnakd0+pNA2Ddv+s4+/RsqjQKhQKbb76h6DdjAQhes5aA775DnZhI4suXFN2S3D6BPZqitLTM8ms3rFABq/79ABhwSIWVypgGxbO3pJs6Pp6Iw8nlm7fMfLm8tDgVcqK6TXWS1Ens8t2VZprfbv8GQCfnLhSbMwellRVxPj48GjT4v5mh2rdPNxgqhfFH1bAamDzDVm/PaK7fOam1P0mVxMVnyZ/pWra1Uh2fmZq2NWlesjmQHIQZ+sefABQZ+VW28xJCCCGEEOJdSVKp8bwRAIBaDdcehbL4iC9tfzpNzZlHGL3jKn9de0pYdEImOb1/QqPj6b3uPE9CYyhlbcKGfrWo4mBJSSsTCpvo52kwVAp9XR0Wd61Kn7olUathisdNFh32Qa1W52o98r4lhBAZehb1jOsvrqNAwQizEcyuN5s2pdtQyKAQkQmRHPY/zOQzk2m2sxld/urCxcCLeV3ldyrh2TP8e/Um9tYtYsz0mdwNHjkas+LjFZS2KJ0qvVHlypRYs5qSWzZjXKsW6oQEor28iDpzhqhTp4g68Q+Rx44RefQoEYcPE3HgAFF//41Crca8Ywccf/sN/eLFc1RXw/Llcdy+jUI9ugPQ9pyaHzarOHtpD6OOjyI2MfaN2kII8WEIDAxk5MiRODk5YWhoiI2NDQ0aNGDVqlVER0cDcOXKFVq3bk3RokUxNDTE0dGRbt26Efz/L5NSAoV0dXV58uSJVv4BAQHo6uqiUCjw8/PT2ufv74+BgQHh4clfDoWHhzNp0iScnZ0xNDTE1tYWNzc3/vjjjyxdxPbt2xeFQpHhT37QpEkTvv7661TbR48eTdWqVXnw4AEbNmx46/kLIcTb8vr51srKipYtW3L9/192A1r7dXV1KVGiBGPGjCEuLk6TZsOGDVim86V1WoFEMTExGBsbc/v2bQDi4+OZN28eVapUwdjYGGtra+rXr8/69etTTe+flqlTp2bab7zed+WFvn37phkoO2XKFExMTLhz5w5Hjx596/mL94sqKopHQ4aS8PAhesWLU+Lnn1GamqSZ1qBUKfRLloSEBKJOn8k87/h4Yq5dA8C4pvZsMvsf7Ofow6PoKnSZUX8Gekq95MCW7yaBTvKw4eamSvwjHhIaG5rl16PQ1aVQ714AhGzchFql0tQl8IcfeDp2LOroaIzr1KHUn39g1rQpBmWdgOTl/QKjAjUz4Hxa+tMsl6tWq4nYuxfLU6cI37OHiKNHifLyIvb2bRKePCEpIkJTF0heCq2IUREAHoY/zHI5AHo7DwKQaKQPSUk8HjWayBMn0m4PhUKzbN6NFzeyVU7C06dEeyW3hUXrzwBQmptTYs0aTN0+Rh0fz5ORX/Ny+w68g70ZfGgwu3x3oaPQYXzN8fyPvfMMi+Jqw/A9W+kdBKSLAioqNuw9dk3R2BONxsSYZhLTy5diNL2ZbhJLYjRqTDTG3nvvioooghTpve7ufD8GUEIREFCSc1+XlzBzyjtnd+ewZ57zvK93ev2m7uJyQQF5YWEAmAeX73R1l/dd3N/sfmRkXtn9Cil5KeWWc5wyBbd33wWVivTfV3J1xgziP/4YsxwDUc7g9+C0al0/gNPjj6PycMcxE14/4Ydera9W/ex9+zClp6N2dsKiQ1mXtKoyJkBJXbfiwgoKTaXnsXMp5ziacBSNpGFks5FonJxwn604r+UcPAgmE7b33YfbrHcqFUMV4/LEEyR72GCTC9nvfFjq+9b5tPNkFmRiqbUkyPHW3NOSvv4ajEYsu3cvSVcpEAgEAoFAIBDcCRyOTCEluxALtcyO57rzwYhWDGzhipVeQ3J2ASuPxvDkkmOEvLORUd/u42JC5u0OuV7IKTAwecEhLlzLopGNnkWTO+JkVb3vSPWFSiXx5vAWzOinpBH/fEs4/1t9BpOp/kRRImWeQHCHszV6K6DYqzcyNGKAzwCGNh2KSTZxJukMu2J2sevqLk4nnyYsJYwXd73IhhEb0Kj+fR/vguhooh6aTOHVq+TYW/DK/fkkOGv5uvfnBDsHV1rXol07vBctJPfECQqir4JsQjYawWhCNpX+32go5HhSEr1mzEB1i1aXKjMzXN94A4tOnYh77XWaxmbw4U9Gvh20lWkF05jbZy7WOutb6kMgEPx7uXTpEl27dsXOzo7Zs2cTHByMwWDgwoUL/PTTT7i7u9OpUyf69evHsGHD2LBhA3Z2dly+fJlVq1aVCKaKcXd3Z9GiRbz88sslxxYuXEjjxo2Jiir7AGjVqlX06tULGxsb0tLS6NatG+np6cyaNYsOHTqg0WjYsWMHL7zwAn369KnwoXkxn3/+Oe+9917J725ubsyfP5+BA6uf8uJ2EBERwbRp0/CooVBWIBAI6pOBAwcyf/58QBHXvvbaawwdOrTU/b74HlxYWMiJEyd46KGH0Gg0vP/++zXqc9OmTXh6ehIYGEhBQQEDBgzgxIkTvPPOO3Tt2hUbGxv279/PRx99REhIyE1dk2bOnMm0adcfnHfo0IFHHnmEqVOnlhxzdnauUaz1QUREBEOGDMHb2/t2hyJoACR+/TV5p0+jtrPDc973aG7y3rbq1YuUhQvJ2rEDmwH9Ky2bd/IkckEBaicndD4+JceTcpOYfXA2AI+0foQAh4CSc2aBgXh+9y1yfj6FmZ9BxhVOJZ2iu0f3Kl+T3ciRJM39koKICLJ370bn14SYGTPIO30aAMfHpuH8xBMl4hDzNiHkh18k99gx1jWKQkamrUtbGls1rnKfOQcOcO2ll3EBEv5aU34hSUJlbY117964vTcHbxtvEnMTicyIpKVTxWnvbqQwIQHvg8r9NPP9GXivP0XG2nVcffIpPL/7FsvOncvUaenUkj2xeziVdIoxjKnyNaX/rThlWXTogNbdveS4yswMj88+I/6tt0lbvpz4//2P3zarONxVwkJryYc9P6SHR48q9ZF3IRy5oACVjQ3aSu5Zz3d4nqPXjhKRHsFru1/jsx6flVvObsR9qG1tiHn2ObI2XxeE/jHYnm+cqy/gUZmZ4fHOLKIemoz7plPkX76M3te3yvUz1q0HwKb/gCqJkSqir1dfHM0cScpNYmvUVgb4DCg5t/TcUgD6effDxcIFUNzcHB+eQvIPP2I7cgRub7+NpKra/mRJpyPzxUnYzPgC56ORpK/8A8vhwwBK3KHaNWp3S+t/+RERpBd9TpyfEu5QAoFAIBAIBII7iw1nrgHQwl7G3c6cUR1sGNXBkwKDicNXUth+PpFt5xIIT8jiYGQKL688xfJpXW5z1HVLodHE9MVHORqVhq25lkWTQ/F0sLjdYVWKJEnM6NcMR0sdb6w+w6J9V0jLKeSj+1uj09S9f5NwiBII6hBTXh4FV2NuXrAStkRtwT5TZsomGbPIKyXHVZKKYOdgpreZzpKhS9g2ahv2ensSchLYdXVXJS02TPLDw7kybrwihmpky8yx+cQ5qniv+3t0di+70FgR5q1bYzt0CLbDhmF3zz3YjbgP+/vvx37MaBzGjcPhgQnYTZhATrNmtRq/Tf/++K5ciXmbNljkw7N/mmi78CCPrJlEUm5SrfYlEAgqR5ZlTDk5t+Vfda1Ap0+fjkaj4fDhw4waNYqgoCCCg4MZMWIEf//9N8OGDWPv3r1kZGTwww8/EBISgq+vL3369OHTTz/F09OzVHsTJ04seThezIIFC5g4cWK5/a9atYrhw4cD8MorrxAZGcmBAweYOHEizZs3p1mzZkydOpXjx49jZWUFQGpqKg8++CD29vZYWFgwaNAgwsPDAbC1tcXV1bXkH4CdnV2ZY5VhMpl4//338ff3R6/X4+XlxbvvvluqzKVLl+jduzcWFha0bt2affuup/RITk5m7NixeHh4YGFhQXBwMEuWLCk5P2nSJHbs2MHnn39eyn1EkiSSk5OZPHkykiSxYMECtm/fjiRJbNiwgXbt2uHm5ka/fv1ISEhg3bp1BAUFYWNjw9ixY0vEaRW1LxAIGgYNaQ7R6/Ul99Y2bdrw4osvEh0dTWLi9VTbxfdgT09Phg4dyrBhwzhR5CJTE26cNz777DN27tzJli1bePzxx2nTpg1+fn6MGzeOAwcO0LSpsjMsPz+fp556qsTlsFu3bhw6dAgAKyurUnOEWq3G2tq6zLGb8dNPP9GiRQv0ej1ubm488cQTpc4nJSVx7733YmFhQdOmTVl9Q3ovo9HIlClT8PX1xdzcnICAAD7//POS82+++SYLFy5k1apVJff14vnhyJEjvP3220iSxJtvvlkynyxbtoyePXvi5uZGaGgoFy5c4NChQ7Rv3x4rKysGDhxY8jpV1L7g30exs1Cj116rktDDqlfPkno3Oh6VR87h6+nyih05ZVnmnX3vkJ6fTpBDEA8HP1y2j+7dse7Xj2AnZQNSdZ2N1FZW2N1/PwAJH37I5REjyDt9GpWtLZ7ffYvL00+XEqeYh4Qo8R47zppLikhjaJOh1eoze88eAAqcnLDo2hXz1q3R+fqidnJCKt7wJMuYMjJIX7WKrO3bS9LmXcm4UlGzZbj2y0I0RjjXGAJ73I37+++XuDVFPzadnKL72I0Uj+OZpDNV7keWZTKK7kk2RWKYG8/tSzjIK12iWNFVeV1H7zLx1n5PlgxaXGUxFEDeqeJ0ecGVuraaa8x5v8f76FQ6dsXsYsn5JRWWte7XD89581BZKk5nB5pJOHbvXWNXWMvOnbHq1QuMRhI//azK9UwFBWQWufTZDLq1jRhatZYRzUYAsOz8spLj6fnpJSkexwaOLVXHZeZMmu7aifusWVUWQxXTrusIfuuh1Imf/S6FRW6/t5Iu70YSv/wSTCas+vat0BlMIBAIBAKBQCC4HciyzIYz8QC0ciy9JqbTqOjSxIlXBgex6dmebJjRA7VK4lBkKheu/XtdokwmmZnLT7D9fCJmWhU/TWpPgGvDMd14oLMPn48JQaOSWH0ilqmLDpNTYKjzfv99FjICQT0hyzKp+alYaa3QqXVlzmfvP0Dsyy9jSEjA87vvsOrWtdp9pOenczj+MDM2mnC7cAyT5hTZzYOwu+uuMmWdzJ242/9uFpxZwPILy+nt1btG13UnIRsM5B4/TtaOnaQtW4YxPZ1cL2dm3J1CmpXEa6GvltqNV6+kXILkS+DfF6q4mKfzaIz3z4tInPslyfPmcdcxmYCrZ3nh2ljenjAfD2vhOCIQ1Adybi7n27a7LX0HHD2CZFE1tX5ycjIbN25k9uzZWFqWny5FkiRcXV0xGAz88ccfjBw5stIHDMOHD+fbb79l9+7ddOvWjd27d5OSksKwYcN45513SpVNS0tj165dLFiwAJPJxNKlSxk/fjzuN+xKL6ZYDAWK4Cc8PJzVq1djY2PDiy++yODBgzl79izaW3TdA3j55ZeZN28en376Kd26dSMuLq4kNVMxr776Kh999BFNmzbl1VdfZezYsVy8eBGNRkNeXh7t2rXjxRdfxMbGhr///psHHngAPz8/QkND+fzzz7lw4QItW7bk7bffBhT3kbi4OAICAnj77bcZPXo0tra2HDhwAFAeVn/xxRfIssyUKVMYNWoUer2eX3/9laysLO69917mzp3Liy++WGH7AoGgYdBQ5pB/kpWVxeLFi/H398fR0bHcMhcuXGD79u2MGVN115IbMZlMrFmzht9//x2AxYsX069fP0KKBA43otVqS+aEF154gd9//52FCxfi7e3NBx98wIABA7h48SIODg41iuVGvvnmG5599lnee+89Bg0aRHp6OnuKBBPFvPXWW3zwwQd8+OGHzJ07l/Hjx3PlyhUcHBwwmUx4eHiwbNkynJyc2Lt3L4888ghubm6MGjWKmTNnEhYWRkZGRono2MHBgbi4OPr168fAgQOZOXMmVlZWJCUpGyH+97//8cknn+Dg4MCMGTMYO3YsNjY2fP7551hYWDBq1CjeeOMNvvnmmwrbF/y7MCQmUnAxAiQJy65V281q0a4dKktLjMnJ5J0+jXmrVhWWzTl0XRBVzNrLa9kavRWNSsM7Xd+pNKVasFMway6t4WTSyQrLVITDAxNI+fln8sMvAmAWHIzHZ5+ibVzW9ck8pA0AuadOEtHXhFaro7935e5X/yT7gJJaLrlPb5q//nqZvz9N+fmYMjJI+n4eqT//TOJnn+Pzzt0AXEmvmiDKlJdH+m/LUQH7ezhxr5nymWz8ySdcfeIJsnfuIvrRaXj99CPmNzjhtXBqAcCl9EtkFWRhpbMqp/XS5J8/T374RSStFpsByvqHSTaxLXobP5z8gdPJitvW8V56fH2a0+7XYwRtj8T800XwzttVuh6A3FNKO2atKnffBghwCGBmh5nMPjCbz49/ziMWj1RY1jK0Iz5LlzDviyksbp7Ca+63tlvb+dlnyNq5k8yNG8k9frzU+FZE9u7dmDIz0TRqhHktpIS7v9n9/HDqBw7GH+RS2iX87Pz48+Kf5BnzCLAPIMSl7Lx3M8e3inCxcCGsf1POhZ8n8GoO1157HeN9d3Ms4RgAHVw73KSFisk7f57MIucs56eerHE7AoFAIBAIBIL/HkaTTFpOAdZm2jpz+DkTm0FMWi5mWhWBtpWLZgJcrekT6MKms9f49UAUbw5vUScx3U5kWebtNWdZdTwWjUrimwntaOfd8NaHhrd2x8ZMw2O/HGXHhUQm/HCAnyZ1wM6irNaithCCKIGgBmQVZDFt8zROJCq7p3UqHVY6K2x0NthKFgzYmEy7bTFIRYLVhE8+xrJrl2rvgtsevR2PeAOhF5SGVAYDcTOeQZozG9uindc3MrLZSBacWcDumN3EZsXiblX2ofWdjiEpiaxdu8nauYPs3XswZV5X8uY382T64FiyzSWmt5nO6MDR9R+gLMOhH2DDq2DMh9DHYOCcKouiJK0Wl2efwSK0I9HPz8QrMY2nvrrKimuPMePNv+o4eIFA0JC4ePEisiwTEBBQ6riTkxN5eXkAPP7447z//vu88sorjBs3jmnTptGxY0f69OnDhAkTMDc3L1VXq9UyYcIEfvrpJ7p168ZPP/3EhAkTyhUqrV27luDgYDw9PUlISCA1NZXAwMBKYy4WQu3Zs4cuXZSHHYsXL8bT05M///yT+4scAmpKZmYmn3/+OV9++WWJq1WTJk3o1q1bqXIzZ85kyJAhgPKQu0WLFly8eJHAwEAaN27MzJkzS8o++eSTrF+/nuXLlxMaGoqtrS06nQ4LC4tSjlWurq5IklTicnUjs2bNomvXrmRkZDB58mReeeUVIiIi8PPzA2DkyJFs27aNF198scL2BQKBoLZZs2ZNiWA1OzsbNzc31qxZg+oGd4qxY8eiVqsxGAzk5+czZMgQnnnmmVLtpKenlxK+VsT+/fsxmUwl9//w8HB69epVaZ3s7Gy++eYbFixYwKBBgwCYN28emzZt4scff+T555+vziWXy6xZs3juued4+umnS4516FD6AfKkSZMYO1Zx9Jg9ezZz587l4MGDDBw4EK1Wy1tvvVVS1tfXl71797Js2TJGjRqFlZUV5ubm5Ofnl5k3NBpNicsVUCKImjlzJgMGDCAjI4Mnn3yS8ePHs2XLFrp2VTbRTJkyhQULFgBU2L7g30X2QUXEow8KRGNvX6U6kk6HZbduZG7YQNb2HRUKouTCQnKOKeIJi6L3/uX0y8w+oKTKm9ZqWqlUeeXRyllp+3TSaWRZrtbahrZxY+xGjiTtt9+wHzcOl5deRKUrf6FT5+OD2s4OY1oavvFqvDv3wFZvW+W+jFlZ5J1R3JdymzQpt4xKr0fl7IzT9MdI/+MP8s+fJ+CY8tmMzIisUj/pq1ejSs8kwRaM3a6LzFQ6HR5ffEH0Y4+Rs28/UVMfwWv+fMxbKovxTuZOuFm6EZcdx9nks3R0u7m7T/pqZZ3Aqndv1DY2rI9cz3cnvuNiWpHATG3GyGYjmdhiIq6WrmS0X0fMM8+StmIFDpMfqnJauesOURUL625kTMAY9sbuZXv0dpbmLEV9Vo2HjQdulm64WrribO6MWqW4f2V62PNd+1QkVNVy+C4Ps2bNsL3nHtJXriTho4/x+nnRTd+PGWvXAWAzcEC1HZrKw9XSlV4evdgavZXfzv/GCx1eKEmXNzZwbI0dsCqis0dXvhp6kU/mA4cPo3bRk906GxudDQH2lX92KyPxi7kAWA8aiFlAzdsRCAQCgUAgEPy3iEnLZfy8/UQmKxkRzLQqbMy0WJtpsDbTYmOu/GxjpqW5uw0TQr1q9DdysTtUd38ndOrYm5YfF+rFprPXWHn0Ki8NCsRMW/NU2XciX269yIK9kQB8dH9rege43N6AboFeAS788nAokxcc4mhUGu+vP8+c+26+OaemCEGU4I6gugtqtxODycDzO58vEUMBFJgKSMlLwTI6mfGrjfgkKMe3tZLodE6Gs2Fkbt6MTTnOTpWxJWoLI3cr1veWd91FbEoytkeOEvvCixgzMnGYML5UeW8bb0JdQzkQf4Dfw3/nyZA7f4eXLMtcO7yb/F17KdxzgMIzYaXOq+3ssOzenZiWLjxh/IVctcTYwLFMazWt/oPNToJVj8OF9dePHfgGZBMMer/KoigAq65dabpqNZHPPwv7DzPMJKzJBYL6QjI3J+DokdvWd7Xr/OPecvDgQUwmE+PHjyc/Px+Ad999l2effZatW7eyf/9+vv32W2bPns2aNWvo3Ln0Q4cpU6bQuXNnZs+ezfLly9m3bx8GQ9kdFjemPSpO03SzuTosLAyNRkNoaGjJMUdHRwICAggLC6ukZtUICwsjPz+fvn37Vlqu1Q0PBN3c3ABISEggMDAQo9HIe++9x2+//UZMTAz5+fnk5+dX6MJVFW7sz8XFBQsLixIxFECjRo04WPSgUyAQNGwa0hzSu3dvvvnmGwBSUlL4+uuvGTRoEAcPHsTbW0kP9emnn9KvXz+MRiMXL17k2Wef5dFHH2XFihUl7VhbW3P06NEy7RenvCtm1apVDB06tERwVZXveBERERQWFpYIgUAR73bs2LFW5o2EhARiY2OrNW9YWlpibW1NQkJCybFvv/2WH374gStXrpCbm0tBQQFtquBKUpX+GjVqBEBwcHCpYzf2L/j3k7NfcZ20DO1UrXpWPXsWCaK2V+jwkhcWhpyTg8rWFn1Tf65mXuXhjQ+TUZBBsFMwk4Mn37SfAPsAdCod6fnpRGVGlaSYqyqu/3sD56eeRFOBQ10xkiRhFtKG7G3bCYiR6edXvXR5OYcPg9GI1tMTg51dpWU19vY4TplM4udfYP/zetTjZK5kXLnpvUuWZVIWLQJgXXsVLRu1LnVeZWaG51dfEfXII+QePkL0lCl4LVpYIjhp6dSSuOw4TiWduqkgSjYayVijpA60HT6MHdE7eH6HIhS10loxJnAME4Im4Gh+fVxtBg0ifdVqsrZvJ/Xnn3F9441K+wAwZmWTfzECoMpp0yRJ4p0u7zBi9QgSchP44vgXpc5rJA2NLBvhaumKhDKeQY5BOJjd+g5m5yefIOPvv8k5fJisHTuwrkR8a8rLI2vrVkAZm9pidMBotkZvZXXEakJcQriadRVrnTWD/QbXWh/FdHXvyiL7Rfw+wIoxq9Pw2nYQbXOZ9p7tS0Rn1SX31GmytmwBlQrnf6SRFQgEAoFAIBDULw3pGXlWvoEpCw6ViKEA8gpN5BXmk5CZX26dJk6WdPF3qnZfxYKoAc1dIPbmgqgeTZ1pbGdOTFoua07GMbLdnZ+VR5ZlEjPzUakkdBoVOrUKvUZV5v3wy/4rfLzpAgD/G9ace0LKOi43NNp527N8WmfeX3eOVwZXvhH/VhGCKMFtZ8HpBXxz4hs+7/M5ndyqt/h3O/j48MfsjtmNmdqMnwb8hLetN5l5GWQuXopp4SKkQiMGW0uuTB9CpE8uKQvXMGKvTNIXc7Hu27fKu9FyCnO4enQXj12QQZJwfHw6x8LC8AoMJH3xr1ybNQtjRjpOjz1W6sY4MmAkB+IP8Ef4H0xrPa1S2/vbjSzLbH16DO4bS9vuR7jCiSZqTjfTc9VThVZzmLT8NAoxMsh3EC91fKn+/ziI2AZ/TIOseFDr4K53QGsGfz0NB79TRFGDP6yWKErj7EyTnxaStmIFtnffXYfBCwSCG5EkqcYph+oTf39/JEkqkw6uWGjzT/cnR0dH7r//fu6//37mzJlDSEgIX375ZRlBVMuWLQkMDGTs2LEEBQXRsmVLjh8/XqpMYWEh69ev5+WXXwaUlG729vY3fThdLJwq73ht3Lf/ec0VcaPjVXG/JpMiMP7444/59NNP+eyzzwgODsbS0pIZM2ZQUFBQ47j+2d8/HbckSSrpXyAQNGwayhwCirDH39+/5Pd27dpha2vLvHnzmDVrFqC4GBWXCQgIID09nfHjx3Px4kWaNWsGgEqlKtVORaxevZo5c+aU/N6sWbMqzxv/nCNu57xRHE/xfXvZsmU888wzfPzxx3Tu3Blra2s+/PDDkrSpNaG8eeqfx8S88d8iu+j9ZNkp9CYlS2PVoztIEnlnz1J4LQFto7I7REvS5bVrx7XcBB7e+DAJOQk0sW3Cl32/rNKagVatJdAxkJOJJzmZeLLagihJpbqpGKqYFH9n9NugRZya7h7dq9VPsbDMvGPV0ojZP/AgKT//gvFqLL1PqdncJoek3CScLSpOb5a9ew8FFyPI00lsbSUxwqlsKgaVhQWe335L1JQp5J04SdRDk/H+eRH6Jk0Idgpm05VNnEk+c/PrOXgQQ0ICKltbLHv0YM2+VwEY6DOQ1zu/jo3Optx6DpMmkrV9O2l//InzU0+hvok4LO/MGZBlNG5u1UrtZmdmx093/cSHGz7E0s2S+Jx44rPjuZZzDYNsICYrhpismJLy3Rp3q6S1qqN1c8PhgQkk//AjiR9/glX37kjq8oVBWTt3YsrJQePuhlnr1uWWqQmd3DvhZe1FVGYUb+57E4D7/O/DXFP9DTA3o22jtuhUOv4IymTMAWfMriXS+ZyKjl1v7jBWEYlzFQGb7bCh6CtwUxMIBAKBQCAQ1D2v/nGK9afj+e3RTvi7WN/ucCrFaJKZsfQY5+IzcbLSs/KxLtiYa8jMM5CeW0hmnoHMvEIyiv7fei6BXeFJ/Lz/SrUFUZcSs7hwLQuNSqJXgDN7bq6HQq2SGNvRk482XuDXA1cahCDq+RUnWXHkapnjWrWETq1SRFIaVYnY7Mk+/jzUtWouwA2BZo2s+XFSzdOAV5W6SeooEFQRWZZZcm4JOYYc3t3/LoXGwtsdUqUsO7+MX8J+AeDdbu8S7ByMeWoexhn/Q/78R6TCQqx69iTo7/UMnfgWr3Z6lU2dLcjWQ354OJnr19+kh+vsjd3L8J3KDc560CB0TZqASoXTiy/i9KSyeyvpi7kkvPce8g2L5X09++Jg5kBibiI7o3fW4tXXPmfeew33jScxSbAvUOKrISqmPqnm5Yc0LO0hcdq1gLTCDBJzEyk0FdK9cXfe7fouKqkeb12GAtj4Ovx8jyKGcgqAqVuh0zRoNwmGfwlIcGge/P0cVPPBhaRSYT9qFCq9vi6iFwgEDRhHR0fuuusuvvzyS7Kzs6tVV6fT4efnR05OTrnnJ0+ezPbt25k8uXxHgG3btmFnZ1fifqFSqRg9ejSLFy8mtpzdGNnZ2RgMBpo3b47BYCj1kDg5OZkLFy4QFBRUrWsoj6ZNm2Jubs6WLVtq3MauXbu4++67mTBhAq1bt8bPz4/w8PBSZXQ6HUaj8VbDrZC6bl8gEAjKQ5IkVCoVubm5FZZRFz1QrqxMeYSHhxMZGUn//v1Ljo0bN47NmzdzrChV140YDAays7Px9/dHp9Oxe/fuknOFhYUcPny4VuYNa2trfHx8bnne6NKlC9OnTyckJAR/f38iIiJKlRHzhuBWKIyJoTAqCtRqzNu1v3mFG9A4OWHWSnEXy9q5o9wyOYcVQZTcOoipG6cSkxWDl7UX8/rPq5ZbTysnxdnsVNKpasVYXXbZJwLQPFaDTlV+ar2KyD5YJIjqULUFVbWVJU6PPgLAqD2gNcg3TZuXsnAhAFtaQb65mhaOZQVRSttWeM2bh1nz5hhTUoia9BAFV2No6aQ4MFVlHIvT5dkMHIhBDbtidgHwYPMHKxRDAViEhqIPDETOzSV12fKb9nM9XV71UxS4W7lzl/ldzOoyi4WDFrJh5AaOTDjCppGbWDRoEe93f58ZbWfwWOvHmNhiYrXbrwjHqVNR2dqSHx5O+qrVFZbLWFecLm9QrW6sU0kqRgWMAiC7MBsJidEBo2ut/Rsx05jRrlE7ZJVEZC9FrNz/qIkOrjV7cJB37hzZO3cpa4zTp9dmqAKBQCAQCASCapCVb2D54askZxfw1l9nK9xsfKfw3rowNocloNOomPdgO7wcLbCz0OHpYEHLxrZ0buJI/xaujGznwUNdfXl9aHMANp69Rlx69daZNpy5BkDnJo7Ymlfd+GNUe080KomjUWmci8+oVp/1zarjMeWKoQAKjTLZBUZScwq5lpGPLMMDnbx59q5m9RzlvwMhiBLcVi6mXSQ2W3mwGpkRyZJzS25zRBWzL3Yfsw/MBmCM/yNERfuz7OOFXBw2jOy9e5HMzHB98394fPsNGidF6Wqrt6VXiyGs6ah81BLnfolcTlqi8jiy+3dCL8jIEjhPf6zkuCRJOD/+OI1eeQWAlIWLiHv1tZJ2tWot9/rfC8DyCzdf+LpdXFu0APXClQAcGN+ah/44w6cfHGfDIwfYOXonm0duZu19a1l19yqWD1vOimEr+KrvV2jV9eh4lXwRfrwL9hZZv7efDI9sB9dgTCaZ9NxCaPsA3F0kijr8I6ytvihKIBAIKuLrr7/GYDDQvn17fvvtN8LCwjh//jy//PIL586dQ61Ws2bNGiZMmMCaNWu4cOEC58+f56OPPmLdunUMqiAtxNSpU0lMTOThhx8u9/zq1atL0uUVM3v2bDw9PQkNDWXRokWcPXuW8PBwfvrpJ9q0aUNWVhZNmzbl7rvvZurUqezevZsTJ04wYcIEGjduzN214IRnZmbGiy++yAsvvMCiRYuIiIhg//79/Pjjj1Vuw9/fn02bNrF3717CwsJ49NFHiY+PL1XGx8eHAwcOEBkZSVJSUq27dNR1+wKBQACQn59PfHw88fHxhIWF8eSTT5KVlcWwYcNKyqSlpREfH09sbCw7duxg1qxZ+Pv7V1uMtGrVKvr164fFDe5ZM2bMoGvXrvTt25evvvqKEydOcOnSJZYtW0ZoaCjh4eFYWlry2GOP8fzzz7N+/XrOnj3L1KlTycnJYcqUKbUyDm+++SYff/wxX3zxBeHh4Rw9epS5c+dWub6/vz+HDx9mw4YNXLhwgddff51Dhw6VKuPj48PJkyc5f/48SUlJFBbW7kafum5fcHvJPqCk1TUPDkZtVf0UvlY9ewKQtb2sIEo2Gsk5oqT5/MCwhsiMSNws3fih/w+VuiCVR7CTIpY5lVh3gqg8Qx4r1McwqMAiLRdDXFyV6xrT0sgPU5xVzTtW3TnHbswYNK6u2GUY6X9USZtXEfkXL5K9ezeyJLGuvQo/Wz8stBW7BqptbPD88Qf0TZtiSEwk9vnnCbJthoREfHY8SblJFdY15eWRuXEjoKTL2x+3n+zCbFzMXWhRjivVjUiShMNERXyU+ssvyDdxQs09dRoA81bVF0SVh1qlxtXSlRCXEAb7DWZK8BSmt5leqYir2n3Y2uL0iCJmS/ziC0x5eWXKmHJySj4XtZkur5h7/O9Br1Y2t3X36I6njWet91FM18ZKatlvPM9jUEGzWPCIq9lckLJAEfVZD+iPzrt6bm8CgUAgEAgEgtpjd3gSBUZlXXhXeBJbzyXc5ogqZunBKObtugzAx/e3JsTL/qZ1mjWyJtTXAaNJZsnB6Gr1V5wur38L12rVc7Ex467mjQD49UBUterWJ7Fpubz+p/I97Om+Tbk8ZzDnZw3k1Jv9OfJaP/a93Icdz/di0zM9WPNkN7Y815N37mnZYFIr3mkIQZTgtrLjqrIwYa1TbAC/PfEtKXkptzOkMsiyzK7IMzy55RmMshEpuz0L//Qgc9ZbBM97DzIyiHLyYvcLn5DSd2iZm9HogNGs7SCRaQ4Fly+TvmbNTfssNBbSePkeAEx9OqMvJ0WFw4MP4P7+e6BWk/7HH1ydMQNTvuIoNaLZCAD2xO4hOrN6k0x9kLFuHclz3gdgbR8bRr7wvZJiSK3FUmuJvZk9jSwb4WntiZ+dH4EOgQQ4BNz8Rp9yGXLTbj1AWcYreQeaH/tA3HEwt4fRi2Hop6CzID49j8Ff7CJ09mb2XEyCkAlwz9cooqifYM2Maomi8g1it7dAICifJk2acOzYMfr168fLL79M69atad++PXPnzmXmzJm88847NG/eHAsLC5577jnatGlDp06dWLZsGd9//z1jxowpt12NRoOTkxMaTfnZk1evXl1GwGRvb8/+/fuZMGECs2bNIiQkhO7du7NkyRI+/PBDbG1tAZg/fz7t2rVj6NChdO7cGVmWWbt2bZl0RDXl9ddf57nnnuONN94gKCiI0aNHk5BQ9S+Lr7/+Om3btmXAgAH06tULV1dX7rnnnlJlZs6ciVqtpnnz5jg7OxMVVbtfnuq6fYFAIABYv349bm5uuLm5ERoayqFDh1i+fDm9evUqKfPQQw/h5uaGh4cHY8eOpXnz5ixfvrzC+aEiVq1aVWbe0Ov1bNq0iRdeeIHvvvuOTp060aFDB7744gueeuopWrZUXFLee+89RowYwQMPPEDbtm25ePEiGzZswN7+5otrVWHixIl89tlnfP3117Ro0YKhQ4eWcQasjGnTpnHfffcxevRoQkNDSU5OZvo/HDWmTp1KQEAA7du3x9nZmT179tRK7PXVvuD2knNgPwAW1UyXV4x10Wc6e+/ekjWBYvLDwzFlZJCvV7HL4irO5s782P9H3Kzcqt1PsLMiljmXeo58Y/5NSteM7Ve3k0I2MW6KM1ROOQ5zFZFz+DDIMjpf32qlfVPp9Tg9rnym791r4uq1iu8PKQsXAZDY3ocEe6nE7akyNPb2eHzzDSorK3KPHSN3/mKa2Ckpyk4nna6wXta2bZiys9E2box5SAhbo7YC0Nurd5Vcs22GDEbt7IQhIYGMDRsqLZtb5BBlFtzqpu3eSdhPGI/GzQ1DfDypixeXOZ+1Ywdybi5aT0/MWlYuIqsJtnpbxgWOQ6vS8nBw+RtNaovO7koa9MvaNA4GKGtj6b9VfxNk4bUE0v/+GwDHSZNqLT6BQCAQCAQCQfXZek5xQbIxU9ZgZv0dRoHhzts4uzciideKxDsz+jVlWGv3Ktd9oLMiwF9yMIpCY9WuLT49j+PRaUgSDCgSN1WHcaFeAPxxNIacgqqZlNQnJpPMzOUnyMgz0NrTjif6+CNJEnqNGmszLY5WetxszfF2tKRpI2taNralibPV7Q67QVO9VU6BoJbZeVVJ6fZkyJOsDF/JuZRzfHXsK17v/PptjSstp4Dt5xPZczGJ3ZeiyHD4GJUuG0OON7bnujPn4Ff4pcVgkiSWB/Tll2b9MJzMYdbJHQS52TC0lRtDgt3wcbKkuWNzmjZuzerQ44zfbiLpq6+xHTIEqZIHw0d3/067c4WYJGgy4yXyDUY2n71Gzj/u27Z3343KyoqYZ54la/MWoh+dhseXX+Jp7UkX9y7sjd3L7xd+Z0a7GbU+RumrVpFz+DCOjz6KzqPqeViz9+3j6vPPI8mwoa2KHq/PvfVdgoYC2PIW7PsSVFrw6wnN74aAIWDpWPV2kiPg4mbUZ1cTElWUtsOnO9z3PdgoE3xEYhYP/niQmDTF3vGpJcf4+6nuuLYZB5IK/pgGRxeCbIJhX4Cq8oXKk1fTePTnI3w2ug2hftWIVSAQ/Gdwc3Nj7ty5FbpZ+Pn58f3335c5bjKZyMhQbGF9fHwqtdxt06ZNyfmjR4+SkZFBzyK3gRuxtbVlzpw5zJkzp8K27O3tWbRoUaXXVExNbIBVKhWvvvoqr776aplz5V2nnZ1dqWMODg78+eeflfbRrFkz9u3bV+Z4Wlpaqd979epV0naxy9OkSZPKpCJ88803efPNN2/avkAgENQWCxYsYMGCBZWWKe8efOPcAco9bVIFD0yL6yclJbF//36WLy/7YFav1/PSSy/x0ksvVRiHmZkZX3zxBV988UWl8QJERkbetEx5PProozz66KPlnitvHG683+v1eubPn8/8+fNLlblxLnR2dmZjkZPLjRw/frzU7zfOU8Xzxo1zSTH/HPeK2hc0fGRZJnu/kubNMrRmgih9UBAaFxcMCQnkHDyEVfduJefS9u8FIMxdxs7CiR/6/1BjFxsPKw/s9fak5qdyLuUcrZ1b16idyvg7QhFqEBwAMafIPXYc2yFDqlS32GnLIrTq7lDF2N17L5HffIZNbAr2q3ZD97JlDKmppK9WUrPt6KKsYbR0vLkgCkDn0RjXN14n9oUXSfrqa3q+1JOLXORU0il6efYqt05JurxhQzEhsy16GwB9vfpWqU+VTofD+PEkfvY5KfMXYDO07AY+AENiIobYOJAkzFrUvmioLlHp9Tg/+SRxr7xC0nffYzdyJOqiTRoAGWuL0+UNrLOd1M+0e4YnQp5Ap65eesfq0tSuKc7mziTmJrIxRKJLmEz6X3/h8vxM1FZVfziS+uuvUFiIedu2mLeu/c+wQCAQCAQCgaBqmEwyW88p6cI/GNma1/48zeWkbBbti+Th7n63ObrrXErM4rFfjmIwyQxv7c7TfZtWq37/5q44W+tJzMxnw5l4hra6uZhq41nFHSrE0w4XG7Nqu2R3beKEl4MFUSk5rDkRx6gOdefkWhN+2nOZvRHJmGvVfDqqNVq18C+qa8QIC24bqXmpnEg8QVCUTIe5O3hZp+woXhG+gvMp529bXCnZBQz8bBczfjvO8iORpFnPQ6VLRmty5IXce/hp77f4pcWgdnDAZ/5PPPPrJ8wZ1ZZeAc5oVBJhcRl8uOE8vT7aztC5u/hx92XubzaK9e0kMixVFEZHk3aTB7GZ3ympf6529MLMvykzlh7n8SUn+PSUmviM0jbg1n374vn996gsLMjZv59rs2YBcH+z+wH44+IfFBprP6XCtQ8/Im35Ci4NHUbSd9/f1IIdIPfMGaIffxzJYGRfoITh6Yl0cKv+YmUpkiOUtHb7vlR+NxXCxc2w+kn4qCksHA6HfoSsctxDCnLgwgb4eyZ83gbmtoV1L6C6shsTaoy9X4cHV5WIoY5HpzHym73EpOXi62RJoKs1ydkFTF98RFFttx4D936nCKOO/azEUIlTVHRKDpMXHCIuPY95uy7d2jgIBAJBLWEwGJg7d26tOToJBAKB4N9NSkoKn3zyCa6u1bMxFwgEUBAZieHaNSStlqwADxaHLSY9P71abUiSdEPavO0lx/MMeexf/xMAEb56vr/re/zsar6wLklSiUtUXaTNS81LZXeMsjHJr9tgAHKr4xB1oObCMkmjwTBFWUNptSkSQ2pqmTJpS5ci5+dj1qIFG+0UJ+6WzlUTRAHYDBuGzeDBYDTS66fj6AvkCh2iDKmpZO3aBYDtsGGcSDxBSl4KNjob2ru2r3KfdqNHI+n15J09S+7hw+WWKU6Xp2viV6OUjbcb27uHo2/aFFNGBsnz5pUcN2Zlk7VT2YRpM7j20+UVI0lSnYuhivspdok66yWBjwdyTk6JSK8qmHJySF26FACHSRPrJE6BQCAQCAQCQdU4FZNOUlY+VnoNfQJdeH5AMwA+3xJOclbdOPJWl7ScAh5eeJj03ELaeNrxwchW1d5ooNOoGFskSPp5X8XpyW+kOF3egGqmyytGpZIY21FxiVp88M7KzHA+PpMPNigaiFeHBOEnnJ/qBSGIEtw2dsfsRjYZeXKDmsItOzCfMZvXDzRGU2Dkw0Mf1sg1ojb4ZvtF4jPyaGSjp3XIFjSWl7FUWbAksTedvv8YKSsT89at8X39Piwz1mBLJve392TBQx059Go/3h8RTPemTqhVEqdjMnhnzVn2n/LA3NqelZ2UPpK+/gZTBQKinLNnaHz0KibA5pGH+XbHJbaejmKEaifkpTHuh0NcTc0pVceyUyjuH30EQPZBZRGwp2dPnMydSMlLYWv01lodI2NWFsakJADkvDwSP/2US/feR/bBgxXWKbhyhehHHkXOyeWUt8S6B5vxVPsZtxbIiaXwXY/rae3GLIEnDkOf18G1FchGuLwD/n4WPmoG8wfD/m9h31ew6B543wd+HQWH5kHqZcVdyqc7xj7/Y2vQHExdngaVGoCdFxIZN28/qTmFtPKwZcW0znz3QDuszTQcjUpjzrowJabWo+He7xVR1PFfYNXjUJhbJvTU7AImzj9IUlYBQW42fDq6za2NhUAgENQSHTt25IEHHrgtfUdFRWFlZVXhP5FaTiAQCO48mjVrxpNPPnnb+q9s3thVJCgQCO5UcopcjXRtWvHIzid47+B7PL7l8WqnpLPq3QtQBFGyLFNgLOCZbTNodCEZgLtHvEKAQ8AtxxvspAiiTiadvOW2QHHIikyPZHHYYp7e9jQG2UCQQxC+3QYCkHfuHKacnJu0AoaUFPIvXADAomPNNl25DxtJpAuY5ZtIukFYA2AqKCDl11+VmEcPJb0gA61KSzO7ZlVuX5IkXP/3Bho3N/RxKUzcYuJ00uly174y1q0DgwGzFi3QN2nClqgtAPT06IlWVfVNCxp7e2yLUkMnL1hYbpnidHnmDSxdXjGSWo3zc88CkLLoZwrj4gAl5aCcn4/O2xt9YODtDLHW6OLeBQArlTWOo8cBkLZkaZXXT9P+/BNTejpaT0+s+1bNaUwgEAgEAoFAUDdsCVPS5fVo5oROo2JkO09auNuQmWfg400XbnN0UGg08dgvR7mUlE1jO3O+f7AdZlp1jdoaG+qFWiVx4HIKF65lVlo2LaeA/ZdSgJoLogDub++BVi1xIjqNM7HV23RUV+QbjMz47TgFBhO9A5wZX5TaT1D3CEGU4Lax4+oOWkbKOCUVgEYDskzw1it89KOJtEP7S+zA65O49FwWFilU7+ocxqW8bdjkSny30RPTT8ouKvvR9+M9XIX2wNuwdy583VlxGQLsLXWM7uDFz1NCOfhKX14dHIQkwdKD8fiZ9WZTW4ksWx2GuDjSykkpAXDp0/cBONRCS55TVz7ccI7Z2h/5WPcta/Wv4Jx2gtHf7edKcnapehbt2gJgiI3DmJWNVqXlXv97AVh+ofy+akph0QNptb097h+8j9rRkYKICKIenEjsSy9jSEkpVd6QmEjUlIcxJidzqRF8fr+eWb3er/kuuvxMWPko/PEoFGSBd1eYtgcCB4NTU+gxE6btgqeOw11vQ+N2gAxX9sD6F2HDK3BpGxjzwdYL2k+GMb/Ci5dh0hpMnZ8k2+z6RLvqeAyTFxwip8BIN38nfp3aCUcrPd6Olnx8v2IxPn9PJGtOxioVWt0P980DSQ0nfoWPAhQXqnhlF21eoZFHfj7MpcRs3G3NWPBQB6zNhBOLQCAQuLu7c/z48Qr/ubtXPT+5QCAQCP4bVDZvtG9fdScVgeB2kH1gPwD73LK4lK64Bp9IPMHru1+v1iYxy06dkHQ6CmNiyAk/z4s7X+TSqd3Y5YCs09Ki+921Em8rJ0U0cysOUTmFOWyP3s6s/bMYtHIQw/4cxnsH3+NYguIGNTpgNFpXVzRubmA0ljgYVdrmwUMA6Jv6o3GsWSp6N2t3VvTSA5C6eDGF1667TGesXYsxMQmNiwvn2yjtBzoEolVX73u82tYW9zlzQJLod1wm4HQa0ZnRZcplFKXLsx0+DFmWSwRRfbz6VPu6HCY+CEDW1q0UXCm7IzvvpPJamrcKrnbbdwpWPXti0aEDckEBiXMV9/CMdUq6POvBg+osXV5909+7P+MDxnO3xd3YDB+OZG5Ofng4uUeP3rSubDKRslARxTk8+CCSumYPswQCgUAgEAgEtcOWc8r3jT6BjQBQqyT+N0xJYb30YBRhcRm3LTZZlnlj1Wn2XUrGUqfmh4ntcbE2q3F7brbm3BWkXOfNXKI2hyVgNMkEulrj41RzB1snKz39iwRVvx64MzZZf7LpAmFxGThY6ni/Bm5bgpojBFGC20KhqZA9MXvof1RZ4LPv7IXnZ7PRNGqEa6rMW78YufDWy+Rl1a9q84stFykwmAjyi2J11Dz84mS+WmyB7tAZJDMz3N94DleXDUjhf4NaB/Y+kBWvuAz9+TjkXY/X0UrP1B5+vDo4CICdR5pi0KhYGmoAIPnb7zDllU5/lxcWhnrXIUzApXs688xvp+kknWaEWtnZ7CSls1T/Lu0zNjH6u/1EJGaV1FXb2qJxdgagIOIiACObjURC4kDcAaIyau+GXxClLNjpvL2xHT6cJmv/xm7MaJAk0v/8k4hBg0ldtgzZZMKYmUnU1EcovHqVa/YSc0armdrp6ZrvTo09Bt/1hJNLFRemXq/AxL/AtnHZsg6+0PVpmLoVZpyGAXPApzs06QsDZsPjh2DGSRj6KQQOAb11mSbm77nM00uPYzDJDGvtzk+TOmCl15Sc79/ClWk9mwDw4oqTXEwoek2CR8KoRYrgKj9dcaH6thvy9734Y947hEXGYG2mYcHkjjSyqfkfEgKBQPBvQqPR4O/vX+E/jUZz80YEAoFA8J+isnnD3Nz8docnEFSIbDKVOET9YXsRtaRmRtsZaCQN6yLX8fWJr6vclsrCAouiVHG//fQCm6M2ExytCB4s24Sg0tVOSq/iFHFXs66Skpdyk9LXyS7MZsHpBTy84WG6Lu3Kk1uf5LfzvxGTFYNGpSHULZTn2j3HH8P/YESzEQBYhLQBqpY2L6fIKduiY/XT5RWjklSktPXhXGMgv4Ckb78BlIcBKQsXAWA/fjyn0hV36JZOVU+XdyOWnUJxmPwQAI+uNXH2wp5S5wuiosg9fhxUKmwGD+ZC6gVismLQq/UlDkHVQe/nh2XPHiDLpCz6udQ5WZbJPa0IzsxaNlxBlCRJuMx8DoD0P/8k5+hRsoscAm0G1V26vPpGq9byXLvnCNIGobaxwWaIkloydcnSm9bN2raNwitRqGxssLvv3roOVSAQCAQCgUBQCfHpeZyJzUCSoFeAc8nxjr4ODAl2wyTDO2vO3rZMSj/uvsySg9FIEnwxNoQgN5tbbvOBzt4ArDx6lax8Q4XlitPl9b8Fd6hixhelzVt1PJbsSvqsDw5cSub7ncomqDn3Bd+SwExQfYQg6j/I4fjDJOQk3LxgHXLs2jG0KZm0v1gkiLLaj9WZl/GbNwvLe4ajAnruyeDssEHkHL354ldtcDkpm2WHo0EqINliIb2PG3n3Fxl9Yjpaby983n8K2ytvQ+I5sHaDSWth+n7o/AQgKenRvu4CEaXT003p5suDnb2RCx0wZgewtbVEjqMlhsREUpeWXrRI/EpZ8NwXJLErswW5Odl8ZLYAAFPr8cTZtkVHIZ/rvmZCzkLGfLu3lL2gzl8R5uRfjADA3cqdro27ArDiwopaG6uCIocorZeS91Vta4vbm2/is3QJ+qAgTOnpxL/xP66MG0/0tMfIP3eOLGsNs0araNakIw+2eLD6ncqykuruh7sgJQJsPGDS39DrxZK0dpVi5wmdp8OkNfDASuj8ODg3gwoUuLIMn2wK562/zgIwqYsPn49ug05T9rY5s38zOvk5kF1g5LFfjlyfWIOGwtMnYMJKaH4PqLRIsccYm/ApB/WPs7nJMpoVhCmdCQSCOsdkMt3uEASCekG81wWC2kV8pgT/BcT7vP7JD7+IMSWFPC1cdINn2j3DlOApvNH5DQC+PfEtf0X8VeX29N0VsYztkXB0Kh3j89sAYNGhQ63FbKOzwcfGB4DTSTd3bipmxrYZfHzkYw7EH8BgMtDYqjGjA0Yzt89c9ozZww/9f2BSy0n42/uX1DFvo8RfFUFUdpGwzCK0ZunyivGx9WVJL2V9IW35Cgqiosg5eIj8sDAkMzPsR4/iTNIZoOaCKADnp58mzcsem1ww++DHUg860v9SXnPLLl3QODuXuEN1ce+ChdaiRv05TpqkXNMff2BMv76RrzAqClN6OpJWi1lA1dP/3YmYt26N9YABYDJxdfrjyIWF6PybYNasYV9XZdiPHgNA5oYNZZza/0nK/AVFdUahsqz5TnuBQCAQCASChowsy+y4kEh6buFtjWNrkTtUG087nKz0pc69NCgQnUbF3ohkNp69Vu+xRSZl8+5aZRPIq4OD6Fvk7HSrdGniiJ+zJdkFRv44FlNumZwCAzsvJAIwsBYEUZ2bOOLrZElWvoHVJ2Jvub2akpFXyLPLTiDLMKq9xy2lAhTUDLHN/j/Gnpg9TNs8jRCXEBYNWnTb4thxdQf9jptQm8CikRG9rQEy41Avvx+vifPY3NoB848X4BCXypXx43F46CGcn3oSlVndKSY/3XQBo0mmXUAmXdZnMPiwsiBl1ac37sPdUe97BpDBM1Rx/rEuumENeFdxF/pzOqRehp/vhfZTlFRteiskSeKNoc25mprLjuhOqLzO8VsXmYf+guTv52F///2oLC3JCwsja/NmTMDKbjouR3vymvlfuJtiwdoN412zOLh5B0MtjqHe+zlPaFbhXxDLQ989xfcP96SFuy16/6bk7NtP/sWLJdd1f7P72R2zmz8v/skTIU/UPE3dDRREKZaGOi/vUsfNW7fGd/kyUhcvJvHzL5RdjYDBXMfbI41ku1gzq+ssVFIlWkyTCXJTITsBsq5BVoLyL2LLdbFZ4FAYPhcsHG75WsrDYDSx9JKK/QmXAXh+QADTezWp0L5Qo1bxxdgQhn6xm/CELF5eeYrPx7RRyqtU4N8X/PuydNsRLm7+kTHqbfirYrGIWAERK8A5SBFrta2BUEwgENwUnU6HSqUiNjYWZ2dndDrdf8KO1GQyUVBQQF5eHiqV0MDXNXfCeMuyTEFBAYmJiahUKnS15AYhEPxX+S/OH3fCvey/wp0y1mLuuH0k79kOQJinRC/ffjzYXPk+eG/Te7mScYUfT//I//b+D3crd9o1aldpWxkFGbyjWsvjQMBV+Kbjh1j98DYGwKJD7aaObOXcisiMSE4knqCHR4+blj8Uf4j9cfvRqrQ82+5Zunt0x8va66b3U/OQEAByjx9HNpmQKvicGBITKYiIAEm6ZfGXt403m70krrV0o9HpOBK//BJTVjYAtvfcjWxjxdlkZdPUrQiiVDod6S9PxuLJj2l0MobUxb/iMGE8siyXSpcHsDVKWQfp69W3xv1ZdOqEPiCA/PPnSVu+HMeHHwYgtyhdnr55ENK/4LPvPONpMjdvxpiWBoDNwH+PO1R5mAe3xKxlS/JOnyZ95cqS1/Wf5J46Tc7hw6DRYD9+fD1HKRAIBAKBQHDn8Mv+K7y+6gwj2nrw8ajWty2OrecUoVPfQJcy5zwdLHikux9fbrvI7LVh9ApwRq+pv3THeyOSkWVo723PlG6+tdauJEk80Mmbt/46yy/7rjAhtOx3wp0XEsk3mPB0MCfIrWxGn5r0ObajJ7PXnuPXA1GMLXKMqm/eXH2GmLRcPB3MeaMoLaKgfhGCqP8YS88rjkTHE46TlpeGnZndbYlj15XtvHhcERzZ+aVjUmmRfLsjRWyF3ybQp99bTH6hBZ2WnaXnaZmUn34ia9s2PL74HH3TprUez9nYjBJ1aFeHqww6LCNL4PLkdBzt9yPtX6wUbD8ZBr4Pmn8sFHl3gcf2wKb/KanRDv+oCHju/hp8uqJRq5g7NoSR3+YQVbCajUHJjD3kgFl8CimLf8XpkakkfX3dHeqSvhkBUgKTWaW0P+gDJZ2bpMLU+3XUjZojr36SgRzC0/Aaz3z/Eh9OGYyXv7Kb8kZBVA+PHrhYuJCQk8CWqC0M8r31BaHCK4pD1KfxS8jaep5Wzq1o6dSSFo4tsNZZ4zBxItYDB3LtvffIOHKY9/qlE+kqMTv0Fdyt3Es3lhAG22ZDWpQifMpOAFMF1oVqPQycrQjO6uBhlMkkszM8kW+2X+RAggqVBLPvDWZMFSZJF2szvhzXlrHz9rP6RCztfex5sLNPyfkNZ+J5eWM8sjwE+77P4N8kCY4ugjN/QGIYJJyr9esRCAQKKpUKX19f4uLiiI29fTsB6htZlsnNzcXc3Pxf/wD/TuBOGm8LCwu8vLyEmEEguEX+i/PHnXQv+7dzp421mDvqF5Ns4vi6n/EDrjaz452u75R6HzzV9imiMqPYdGUTM7bNYPHgxXjZlP+9NCUvhWmbphFmDOMeZxWNE034bQsn8do10Ggwb127C/2tnFqxOmI1pxJPVan818eVtY77mt7HhOYTqtyPWWAgkpkZxvR0CiIj0fv5lVsu+6DiDqUPDERjb1/l9svD20bZ9LV5YCPGn44j4681JeccHpxIRFoEecY8rLRWJU5ZNSWwbT++7P0pUzaZSPjwQyw7hWLKyaHgyhUkc3Os+/blauZVzqeeRy2p6enRs8Z9SZKEw8SJxL3yCim/LMZh4kQkrZbcUycBMA9udUvXcqeg9/XFbtT9pBWlkLMZ/O8WRAHYjx1D3KuvkfrbMhwmTy5XOJiyYAGgjIfWVexGFwgEAoFA8N9ElmUW7VPMHradT8BkklGp6v+7eF6hkd0XkwAqdF96rFcTlh2O5kpyDvP3RDKtZ5N6i+9oVCoAoX4Otb5WcV9bDz5Yf57z1zI5eDmFUD/HUufXn1bS5Q1o7lprfY9s58lHGy5wKiadU1fTCfawveU2TSaZR385woVrmQQ3tqWNpx1tPO1o4W6Lua60eG3tqThWHo1BJcGno9pgpRfSnNuBGPV/EanZBSzYG8mw1u74u1iVOX8t+xo7r+4EQEbm8LXD9PPuV99hEpkeifPRSByyQGVriY1HLCcNfvyse5X32/uiPvwjqs1v8HSru3lwmJr9gTIvbrOh4PJlrkyejM+SJeg8PGo1po82ngdgWGt35IsLAcj1csRJ/gXOnwO1DgZ/BO0mVtyIzhKGfKSkSVv1BKRGwoIh0Okx6PcWlnod8yeFMnhhNwptV7OgnZppf0PKjz9iEdKGzE2bMUmwopsKY2ZzFjovRpVugIDBEDQMDDeIhFqPQXLww7RkHC1yrrBYfokZPyQzs2NLzID8iOuCKI1Kw31N7+PbE9+y/MLyWhFE5VxR8pyes0gjPHob26K3ASAh4WvrS0unlgQ7BdP8lYd4dfdFIjPSGOAzgKF+Q0s3lJcBv46GtCtlOzF3ACuXon+NFEeuNuPBJeiW4/8n6TmFLD8SzS/7rxCZnAOARpL5YkwIg1s3rnI7HX0deHlQILP+DuOdNWcJbmxLiJc9R6NSeWrJMWQZxoV6Mb23P0hNwbszDJwDp1eAb80XNwUCwc3R6XR4eXlhMBgwGo23O5x6obCwkJ07d9KjRw+0Wu3tDudfz50y3mq1Go1Gc0c8XBcI/g381+aPO+Ve9l/gThprMXfUPz+d+IGQC8oi+LD7X8FaV3r3q0pS8W63d4nLiuN08mke3/I4vwz+BVt96cXbhJwEpm6cyqX0SziYOdB4QDf4ZSXJP/wAgHnLlqjMzWs19mDnYEBJmWeSTZU6QB+MO8jha4fRqrQ8HFy+e01FSFot5i1bknP4MLnHjlUoiMopSpdn2fHW0uUB+Nj6AHDILoVp/fuTuXGj0nbPHuj9fDl94XcAWji2qNz5ugp42Xixt5MNbSPSCbmUT8zzL2AerIytdb9+qCwt2XJmBQDtGrW75Q2NNkOHkPDJJxji48nYsBHboUPIK3KIMm8VfEtt30k4T59O9s5d6Js2rfA982/CZvBgrr3/AYXR0WTv2YNV9+6lzhfGxZGxfj1wPXWiQCAQCAQCwX+RI1dSCU/IAiAlu4Dz1zIJcrOp9zj2RSSTV2jC3daMQNfyXZAs9RpeGBjIzOUn+HLrRUa09cDZWl9u2drmWJEgqq3XrW02KQ9bcy33hLiz5GA0P++/UkoQVWAwsaUoleCAlrUn4new1DGwpSurT8Ty68ErzPG49c0gG8/Gs6koneGV5BzWnIwDQK2SCGhkTRsvO9p42OHrbMkrfyjfuR7r1YT2PnWT9Uhwc4Qg6l9CodHEo78c4eDlFA5FpvDr1E5lyvxx8Q9Msqnk9wNxB26LIGrH1R30P6q4Q9l3aIykDuekwY8Vx66RFjiGb/r7o930KiEnVzHIN4h1TbP5IsSP5xdmkn/hAlFTpuDz669oHB1v0lPVOByZwtZzCahVEs/0a8rvr0UAYKa/BokJYOUKo38Bzypar/v1gsf2wsZXFQeg/V9DUjiMWoSrrQVfD3+Uh7etZVvLFO4/4IxjUiLR0x4DYF+gxFVHNS/l5OOacAJ0VjD4w/LdkDw7onpkK8Zfx+CccIaf5Ld4Z9dDjAcMsXEYs7JRW1kCMKLpCL4/+T2H4g9xOf0yvrY1tzk05eVBQjIA3s1DuadpT04lneJU0ilismK4lH6JS+mXWB2xuqSOi7kLr3d6vewC+/qXFTGUrZdyndaNwNIFLJ3LunDVAWdjM/h5fyR/Hoslt1B5wGVtpuG+EHc8cy9xV/OydpU3Y0o3X45cSWXd6XgeX3yUL8e35eGFh8k3mOgT6MLbw1uUHgdzO+hQvYVhgUBQMyRJQqvV3vaHjvWFWq3GYDBgZmb2n7nm24kYb4Hg38t/af4Q97L6Q4z1f5eDcQf5e/1cuuaD0dKMFp3K37RkrjFnbt+5jPt7HJEZkTyz/Rm+6/cdWrXyfrmaeZWpG6dyNesqjSwaMa//PBr5p3Dll5WYspSF/ltNIVceTe2bolfrySzMJDIjEj/b8kUnsizz9QnFHWpE0xG4WlZ/Uds8JIScw4fJOXYMuxEjyi2Tc+AAABahodVu/58UO0TFZcdh8/gnZG7eDCYTjhOVzXGnk08D0MLp1tMcqCQVLZxb8vWQfXyzUA9hYeSHhQFl0+X18epz6/3pdNiPG0vSF3NJWbAAmwH9ySvqz6zlv0cQpXF2psnmTf8ZgafK3Bzbe+4mddHPpC5ZWkYQlfLzL2A0YhEailnz5rcpSoFAIBAIBILbz68Ho0r9vjci+bYIojaHKUKaPkEulf7Nel9IY37eF8mJq+l8vPE8742oe1fXtJwCIhKVlOEhdSCIApjQyZslB6NZfzqehMw8XKzNANh/KZnMPANOVvpaF2ONC/Vi9YlYVh2P5ZXBQVib1XwNRpZlvtqm6Ajub+eBj5Mlx6PTOB6dRmJmPmfjMjgbl8GvB66/31o2tuHpvs1u+ToENUd4of9LePuvs2iv7GC57k2sIjeQkJFX6rzRZGRl+EoA7vK+C4CD8Qdvqc91EWvYm7UDWZarVe/U0Q20ilRS0ln6KDfWk7Ifeo2KzecSGX8yhJwRP4PWkmeiLmAmw+6sE1x+8wG0jRtTeCWK6KmPYCxa4LsVZFnmgw2KO9So9h5o9Cm4xuQC4GyVDZ6h8OiOqouhijGzgeFzYcwS0JjDxU3wywjIS6eTjxehLn2QVRI/hSiTrSk7GxOKO5RVoQ+T039R2unzGthW4oZl54V6ykaMzQajlwqZZfY9+RbK5FFwg0uUq6Ur3RsriyIrLqyo3rX8gythymJjth4e7f48D7Z4kA97fsj6EevZPmo7X/X9immtp9HVvSs2Oht0Kh3vdn+3zE5Wzq6G478AEtz3HQQMBPcQsG1cp2KoAoOJ1Sdiuf/bvQz+YhdLDkaTW2gk0NWad+9tyf6X+/La4ECca7iJVpIkPhjZCl8nS2LT8xjxzV5SsgsIbmzL3LEhaNTitisQCAQCgUAgEAgE/0UScxJ5fufztIhUNqvZduqCpFZXWN7J3Ikv+36JpdaSQ/GHeHv/28iyzKX0S0xcP5GrWVfxsPJg4aCF+Nr6Yt66NSrb69+9LTq0r/Vr0Kq0NHdUhBWVpc07GH+QI9eO1MgdqhjzkBAAco8dL/d8YXw8BVeugEpVK9dqr7fHWmeNjMw1Fx3uH35Ao1dexqJzZ0BxxQIIdqodAVGwUzDpVhL7JoaUHFM7OmLZuTNJuUkcSzgGQF+vvrXSn/2YMUh6PXmnT5O69Dfk/HxU1tbofLxrpf07hf+KGKoY+zFjAMjavp3CG1L8GrOySVu2DACHSZU43gsEAoFAIBD8y0nPKeTvIhefwcHKRo19EUm31Ob8vVc4mFi9vztlWWZrkQtS38Dy0+UVo1JJvDFM+d712+FoTsek1yzQanAsOg0AXydLHCzr5jltC3db2nnbYzDJLD0YXXJ8/RklXd5dzRuhruVUhqG+DjRxtiSnwMiq47E3r1AJu8KTOBWTjrlWzcuDg3i8tz/zHmzPwVf6su/lPnwzvi2P9vQj1NcBC50aW3Mtn45qg04jng3fTsTo/wtYeuAKukPfsEj7Hh1UF3hEvYa1p+JKldkbu5e47DgcVNbMuBKEdwJcSr9EYk5ijfpMy0hA+8irDP90HTuO/F7lehkFGbhtOgmApktH9LlnAMhybMWiyR2x1ms4GJnCiC22pIz5CzdLVyalKTf5D8O/pNH3X6N2cCDv7FmuPv4Epvz8GsVfzM7wJA5eTkGnUfFU36acSDyBzzVF4GXl2xgmrlFStdWUwMHw4J+gt4WovbBwGGQnMaPjJAAOhURzyVaZ9PY0syLGSWKaWT5Sfga4tYGOj9y8D70V6jGLSW45RfnVWhmT/IsXSxW7v9n9AKyKWEW+sebjtmmvItbKdrEm0DGw1DlHc0d6ePTg8TaP8+1d37J7zG72jdtHJ7d/OJZlxsNfTwNQ0Pkp/k73JTvfwK2QmJnPS7+fZPwP+xn5zV6Gzt3FXZ/soPsHW+n47mZav7WRgNfW0ey1dTy15BiHIlPRqCSGtnJj2aOdWfd0d8aHemNZC/lbrc20fDOhLWZaFbIMHvbm/Dipfa20LRAIBAKBQCAQCASChodRNvLSnpdIyUuhQ6yyA8cytKy79z9pZt+MD3t8iEpS8efFP3n3wLs8tP4hEnISaGLbhIWDFtLYSkn1Lmk01x1iVCrM27atk2spFgSdSipfECXLMl8fV9yhRjYbSSPLyhf7K8I8pA0ABRERGNPSypwvdocya94ctXX56SaqgyRJ+Nj4AHAl4wq2Q4bg8OCDSJJEniGP8NRwAFo6tbzlvm5sZ71nCnajRgFgd+89SBoNO6J3ICPT3LF5jdy1ykPj4IDt8OEAJHz6KQDmwS2RVGJ5uCGj9/NTHNJMJlKXLy85nr7yd0xZWeh8fbHq2fM2RigQCAQCgUBwe/nj2FXyDSaC3GyY1rMJAAcupWAwmm5Ss3xOx6Qze915fr2o4kxsRpXrhcVlEpeeh5lWRecmN8+C1M7bgeGt3ZFleHvN2WoblFSXY1FpAIR42tVpPw90UjZk/HogCoPRhMkkl6SgG9CiZt8dK0OSJMZ29AJg8YGoWxrHr7Ypz97HdvQqJRqTJAk3W3MGBbvx8qAgfnu0M6feHMDh1/rRtNGtf1cV3BriG28D52hEHLq/H+d17S+oJeUD3FqKYOOJy6XKrbiwArVR5n/rrcme8wlvLZGxzpFr7BJ15qv38EmQcciC/LfeJ78gt0r19l3aTo+TSmoyt+H90BhzyJH1OPu2JNTPkaWPdsLJSk9YXAb3rswg5v6/ecjCFxeDgZi8ZN49MgPXD99AZWFBzoEDxD7/ArLRWKNrMJlkPtxwDoAHO3njZmtO2KUDOGUq5/Xd764dpyKvTjBpDVg4QdwJmD+Illp7ZUel2sRnvQP527cdi/orrl4DIw+CpIJhn4Oq4p2ipVCpsOg+HQAbG8V1K/9iRKki3Rp3w9XSlfT8dDZd2VSjS4nPjudK2H4AHP1vbhEvSRI69T/GUJbhz+mQmwKurZiTcy+P/3qUe7/eQ2RSdo3iCovL4J6v9rD0UDR7LiZz+Eoqp2MyCE/IIjoll4TMfNJzC8k3KH/cuFjrmdGvKXte6sOX49rS0deh1ncQBrra8N0D7RnW2p1FkzuW2D4KBAKBQCAQCAQCgeC/x+a8zRxLPIaNyoJmUcqGIItOVUvz1t2jOy91fAmA387/RkpeCkEOQcwfOB8Xi9Kp3q37KunVzIODUVtZ1eIVXCfYWRFEnUw8We75A/EHOJpwFJ1Kx5SizVs1QWNvj87HB4DcEyfKnM8+oKxpWYR2rHEf/6Q4bV5kRmSp4+dSzmGUjTiZO9HIonYW6YsFURFpEdi8MhOvhQtxeuopALZEbQFqzx2qGIeJDwIg5+QAYBZc96k3BHWP/ZjRAKStWIFcWIhsMJCycBEADhMnCtGbQCAQCASC/yyyLLOkyIloXEdPWrjbYmOmITPfwOlqiJluZEuY4vIkIzFn/fkqC2y2nlNEP938nTDTVu3570uDAjHTqjh4OYWPN17AZKo7UdSxqFQAQrzrJl1eMYOCXXG01BGfkcfmsASORaeSmJmPtV5DlyZOddLnyHYe6DQqwuIyOF7khFVdjlxJ4cDlFLRqiak9fG9aXq2S0IqsQXcE4lVowCTEXEb3yzDuU+3CiArTgDkYbTzRSkbUVw9wNVVZ3EjISWBn1Hae+MuE2xElZ6VFjpFx200ciDtQ7X4L4+OxXrIRAKMETSLz2fnuU1WqG/3nUqzyIMfJCquiTHCnZR/aeDsDilXe7491xtPBnCvJOdy7KILoQct4xdwflSzzd240j555CouRrkhaDZkbNxL/9js1UnOuOx3P6ZgMLHVqpvf2ByDlxCHlGm2MqEPurXabFeLWCiavBxsPSLqANH8QYzyURa3UoPN819OXdGsINoCr0QidpoN7m2p1Ye7sSz5aLGwLgLIOUWqVmhFNRwCwJGwJJrn6yueFZxbinKwI0Fyata52fQAOzoOILaAxI3/4t/x+QvnD4cK1LIZ/uZsdF6rnWrb57DVGfrOXmLRcfJ0s+WRUa76d0I75D3Xg16mhrJzehb+f6saW53qy+8XeHHq1H/te7suMfs1oZFO3IqWezZyZOzYEP+e6WYQWCAQCgUAgEAgEAsGdz46rO9iVvwuAd+0nQV4+agcH9E2bVrmNsYFjmRA0AYAQlxB+HPAj9mZlF6qtBw7Ebc4c3N6bUyuxl0crJ0VEE54aTp4hr9S52nKHKqY4bV7OsWNlzhU7RFmGVk1YVhW8bJSdw1cyrpQ6Xpwur6Vjy1rbUOVi4YKLhQsm2URY2nksQzui0unIKshif5yyGa22BVF6f38si13EAPNWtZP+T3B7se7bF7WTE8bEJDK3bCVz8xYKY2JQ29lhe/fw2x2eQCAQCAQCwW3jaFQa569lYqZVcXdIY9QqiU5+ijvT3hqmzdtSJGwCOHA5lc1FAqmb1ytKlxdU9e9I7nbmzOwfAMCX2y7yyM+HycgrrEa0VcNkkjle5BDV1suu1tu/Eb1GzegOngD8vD+S9aeVdHl9glzqLLWcnYWOocFuACzcG1mjNr7ephiR3BfigZuteW2FJqgHbuldNWfOHCRJYsaMGSXHZFnmzTffxN3dHXNzc3r16sWZM2duNU7BP8i/vA/ND71pKYeTIVlTMHYFqs7TUfsqixqdVGdL8qH+eeEPHl1TSNcwGbRanJ54AoC+J2SuHdxVbvsFBhOFFVgFxn/4IdoCI+caw7q7/QBwX7abhH07Ko3ZaDLitkmxU9fcOxhjrLKYddLkR7sb1Kbejpb8Pq0Lga7WJGTmc/+Px7HrMp9vg6Zii4rTeh0TXC+T10VRqqb99htJn39apXErxmA08fGm8wA83N0PB0sdOYU5aCJiALBw1oBL82q1eVOcmiqiKEd/SI9i4KYPsdFYkk8Srt7K2PXJSANbT+j1cvXbV6lJ0DRGb6vsNP2nIArgvqb3YaY242TSSZacW1Kt5lPzUvk9/HcapSm/67y8qh9j4nnY9Lry811vsyXZgYw8A642ZoR42ZGRZ+Ch+Qf5bkfETUVusizz/c4Ipv58mOwCI12aOPLn9K7c19aDgS1d6R3gQpcmTrT1sqeFuy1NnK3wsLfA2Vpf6/lnBVVHzBsCgUAgqC5i7hAIBAJBdbjT5o08Qx7vHnwXgHEB42hxRVlrsewUWm1hzQsdXuCP4X/w04CfsNaVb7svSRJ2996D3vfmO1ZripulG45mjhhkA2EpYaXO7Y/bz7GEY+jVeqYE19wdqpjitHm5x46XOl5wNYbCmBhQqzFv2+6W+ynmxpR5N3I6WRFEtXC6uVt2dShOP3gm+fr7cXfMbgpNhfjY+OBn61er/QE4TJpY8rNZSyGI+jcg6XTYjVQ2QaYuXUrKggUA2I8bi8pcPKypCnfa3CEQCASCOx8xdzQMlhxUjEKGtnLHxkwLQJeidHX7IpKr3V5CRh4nr6YDEOqsfLebszaswmfqxSRl5Zc4E/UOcKm07D95uLsfn4xqjU6jYnNYAvd8tYeLCVnVjr0yLiZmkZlvwEKnJqAeUryNC/VCkmDPxWR+P6o8mx/QonZShVfExC4+APx5PJZt56smYivmbGwGW84loJJgWq8mdRCdoC6psSDq0KFDfP/997RqVdpa+YMPPuCTTz7hyy+/5NChQ7i6unLXXXeRmZl5y8EKFOSjP6NeNAwHOZVwPMl8YBPmAUU7xkoEUWGsORmH0WRE9fEP9DwtI6tUNP74I5yfeBzLe5TdQXf/GU90aulFnpTsArq9v5XhX+4hp8BQ6lzOkSNk/b0WE7BiiB1NOk3hWFtbVDJEP/ccxvT0CuM+tWcVfjEGDCoIeHA6+VcOA3BZF4CXg0Wpsi42Zvz2SGfaeduTkWdg/I+HyLMdy9L7/qaZtRcpajUPdbbjalclVV/St/NIeX08pMdUaQxXHo3hUmI29hZaHu6uLBKeST6D9zVlwrILDIJaTqGmNOwJD62DRsGYZydwT1oKAGkFirirX3YODPkY9DVzFEq39EFvqyiDDXFxGLNKT4guFi482/5ZAD498imX0i9Vue3FYYvJNeTila78waDz8qxecIYCWDkVDHnQpA90mMrvR64CcF/bxix9pBOj2ntgkmHOunM8vfQ4uQXlp0MsMJh48feTzF57DllWJs6Fkztia6GtXkyCekXMGwKBQCCoLmLuEAgEAkF1uBPnDTONGZ/1+oxgbTBPt3manP2Kq5FFaKdqtyVJEv72/mhUmtoOs9pxlJc270Z3qPub3V8mnV9NsChyiMo9eRLZcH2NqtgdyrxlS9RWlrfcTzHFKfMqcogqFjDVFsVp804lnSo5Vpwur7dX71pzo7oRyy5dcJgyGacnnkDb6NZfI8Gdgf2oUaBSkbN/P7nHjyNptdiPHXu7w2oQ3Ilzh0AgEAjubMTc0TBIzy1kzclYAMZ2vG7y0MVfSct2KDKFfEP5zyErolhI08rDhvt8TDhYarmUlM2vB6Iqrbf9fCKyDC0b2+BqW/3sNfe19eD3aV1wtzXjUmI293y1h01nr928YhU5ekV5Tt3KwxZNPaR587C3oG+g8l0kJbsAvUZFz2bOddpna087HurqA8ALK06Sml1Q5brf7FDcoQYHu+HrVHvfPwX1Q41WULKyshg/fjzz5s1j1qxZJcdlWeazzz7j1Vdf5b777gNg4cKFNGrUiF9//ZVHH320TFv5+fnk5+eX/J6RoeTrLCwspLCw+pZvxXVqUveOx1iIavMbqA/PQwOsN3bActR3dPL0un69jUPRAq2kS0RcjWfv89PpeigLE+A06y3Me/emsLAQl2ee5eyGv/G9ZuTCj1/g+vR7Jd0s3HOJhMx8EjLzmf33Wf43NAgA2Wgk7h3l9d7SRsKjbQ/U6Woav/om8VOewTUlm/AXn8Xvi2/KXbBJWLwIT+BKO3cCra3QJp9V2nVrg8FgKFPeQgvzH2zLk0tPsCM8iamLDtOliQOtXN5GZ/MTpzN28mwPa14zGWm1T+ba8iOoY9pjOW0WcsiDFQ5jfqGRTzdfAODRHr6YqZX3y7G4w/heU1yJtB371t17SG8PE/5E/dtYRscfZZGVOwBNCgrwajqEQt8+UE7fVXlvF9g1QZ2+HaOFFnVOITnnz2P2jz/IRviNYOuVreyP38/LO19mfv/5aFWVC4myCrP4NexX1EYZ+zSlf8ndvVpjpNo2G3XcCWRzewxDPic5PYftRenxhrdyRSWbmDU8iOauVsxae57VJ2IJv5bJN+Pb0Nju+m621JwCnlhygoORqagkeHlQABM7eYHJSKGpen+4VERDuo80hBihducNqN25oyG93v8GxHjXH2Ks65eGMt53enw3IuYOAYixrm/EeNcfDWmsG0KMcGfPG02tmzLacjSm7Fxyjh8HQNeubYMZ2/Jo4dCC7dHbOZFwgsJmynXsj9vP8cTj6NV6Hgh8oFauT/LyQmVtjSkzk6wzZzBrrrh5Z+3fB4BZh/Zl+rmVz5e7ubJGk5KXQkp2CtY6azIKMkoEUs1sm9Xq6xZoFwjAqcRTFBYWUmAsYNdVxc29p3vPOnuPOBQ5Gdxq+w3pXvZvoNLxdnbGokd3crYrLvRWQ4ci29ndltemIb0f7uS5Q3y+6g8x1vWLGO/6oyGNdUOIsZg79Rl5Q3q964uVR6LIKzTRzMWKYDfLkrHxsdfjaKkjObuAQ5eSCPV1qHKbm84o6d16+Ttilp/CEz19eXvtBT7bfIGhLV2wMS//eeumM0pWp15NnWr8GgU2smDltFCe+u0kByNTmbroME/29uOJXk1Q3WJmnMORioFHGw/bensPjevgUZJusJu/IzqVXG7ftfnefrZvE3ZeSCQiMZtXVp7k89GtbroJ5UpyDn8XCese6ebzr/+MNZR7SXXiq5Eg6vHHH2fIkCH069ev1M3+8uXLxMfH079//5Jjer2enj17snfv3nJv9nPmzOGtt94qc3zjxo1YWFiUOV5VNm3aVOO6dyJaQzYdLn+Bc5ZiRf5x4UiuNh5Gr0unWXvpdKmy/XROWOQnMTNsKU4XFCvGTXc3w1ethbVrS8rF9m1KrzXncPh5PRsatcFoY0OhCX48ogaUD/8vB6Kxzogk0E7Gdv9+Gp07R46ZxNKeKoYk2oAO0i7ms2WEL1PnX0azfS9733yL9NCOpWJS5ebiuUcRIUW1CmLPH/PoJReSJluSVaBi7Q1x/ZO7HSDLScWRJBU7w5PZGQ4wCK2DFXqXdczqqWJ6rpZex/OI3W9LI/O3+fOiLVqtFr0adKrSZk/b4yTi0tXY6mQcU86ydq0izNqb8Addi9wRdxVYYawkptpA7TCVjumf0zXnGnsszOmTa2CjfV/yb9Jvpe/tbC1tAaxNkAOH//iDjKtXyxTrYerBcek4Z1PO8vKfL9PHrE+lfe7K20VmYSZBmfZIpiRMWi0bDx2qsouWQ9Z5uoV/BsChRuOJ23WM7XESRpMabyuZ84d2cL6orD3wWCDMv6AmLD6TIZ/v5KFmJpraylzLhe/D1CTlS+jVMpOamnBJPcO6dXVjOdoQ7iM5OTm3O4QqUZvzBtTN3NEQXu9/E2K86w8x1vXLnT7eDWXeADF3CEojxrp+EeNdfzSEsW4oc0dDmDf2zZ+PR2Ehhba2bD59Ghpw+oycQuV9cSj6EGvXrlXS2md9D0A7TTsObTtUa301dnPDMjOTI78uIb1LZ5BlfHfuQguckiGngnWUmn6+rCVrMuVMlqxfgofGg4uFFwFwUDmwd8veml5GueTJeQDEZseyfM1yYowxZBuysZasiToQxVWp7JrOnUhDuJf9m6hovC18/fAoEkSd8vHmSB2vbVZEQ5k3oGHMHeLzVX+Isa5fxHjXHw1hrP+rc4eYN+oOWYbvTyrPu4Mt0lm3bl2p895mKpKzVfy88SDJnpWnuyum0AQ7Lyht6lPCwRLsUs7SyFzNtZxCnp+/hbt9yrZlMMH2c0o9XfIF1q69cEvXNqYRmOWp2BmvYu62S2w7fpEH/E2Y3YKR8O4wJT7DtYusXRt+S/FVFZMMTmZqkvIkXA3xlWoFoPbe2/e6widJataduYbTovW0d5YrLb80QoVJVtHczsTlY7u4fKxWwrjjudPvJdWZN6r90Vi6dClHjx7l0KGyCxvx8YoqslGjRqWON2rUiCtXrpQpD/Dyyy/z7LPPlvyekZGBp6cn/fv3x8bGprrhUVhYyKZNm7jrrrvQav896bNUW95EnRVGNmY8U/AYFsHD+WBEy3JVi2rjOpJ+/YvORWKoeQNUTJ35Hv52/qXKHW7jRPiRh2kaZ6L1seO4vv8evx2+SpbhLO62ZvRs5sSSQ1dZGWPBX31akDp7DiZgSXeJXEstU/tPZd/2fdx1110Edg3k58sjGL/ViMvfa+jw4APomlzPoXnlp68pLJSJdpK4f9r/sD/zB5yHkyY/xg7oTHtv+0qvf6gsczo2gzOxmZy/lsm5+EzOxfchN9oN88a/8s3AHHS5WrqcLyTjhJrjtsdYbeoCKJodC50aS50GC52aaxl5gImZA1twTwcPQFFu//HR/1ABspWGAWPqyVLaMJj/rZ7K2tg9jOr2P8zajKuwaFXe2/HnHWDFt1ja5JF3TUugpSVOgweXW9Yu0o5X9r7CjvwdTO45meaOzcstl2fI49PVnwIw2WUwsAgzb28GDxlStWvMz0Qz7zUkZEytxhAy7E1CgO+/2QdkMqlXEINDvcpUG5mWy/QlxzkTm8k35zQ82MmLFediyMw34GFnxvcT2tK0Uc1SC96MhnQfKd4xcCdT2/MG1O7c0ZBe738DYrzrDzHW9UtDGe+GMG+AmDsE1xFjXb+I8a4/GtJYN4S5o6HMG82NJjIAh549CKrqd+o7lKzCLBYsX0CanEZo71AupF0gels0erWeNwe/iZO5U631lRIVTcqFCzQpLMR18GAKoqKISk8HjYYejz6Cyty8VPlb/Xz9sfkPjiQcwSPYg8G+g/nxzI9wAjp4dmBw1/LXWG6FX9b8QmRGJG4hbpy7eg4iYKD/QIZ2GFrrfdU2Dele9m/gZuMtDxxIMjJqe3v8H3roNkSo0BDmDWg4c4f4fNU9YqzrFzHe9UdDGuv/6twh5o2643h0GnH7D6LXqHh5XG9s/+HclOVylaOrzpKsdmDw4I4VtFKaneFJFBw4iquNnkl392Lz5s0M7H8X1k3TmPrzMXYlqHltbA887UuL2fZEJJN/4AhOVjoeHXnXLbs5AQwDVh6L4fXVYZxOhe8uW/H1uBCaOFc/nVtGbiHx+7YB8PA9fXC00t9yfFWlWftM9l9OZXxHT9QVjEtdvLcLnCP4YmsEq67qmXpPF9wqSGMYn5HHzIO7AJk3RobS7iZ6hn8DDeVeUp15o1qCqOjoaJ5++mk2btyImVnF+S3/KdKRZblCuzG9Xo9eX/aDpdVqb2mQb7X+nYYxej8AbxRMIt69H8tGtkanVZdbNumUhqTTykS5oK+KK31aEeQcVKZcW4/2jB9sxls/5pG1di15I0fy0z7FmnFKdz/GdfTiwOVULiVls+OVObRMTyfHy5lNbVPo4NoOewvlQ6/VaglwCsBswmhOXFpC68gCrr34Ij7LlqHS65FlmYzlKzAHwnp60d/amayoo1gBp2nCZG9HtBVcS6l4fZxo63N9QU2WZWLSurP7ck++Ofc6S3pH0uU85KToeEDawl9SF2RZUQFn5xvJzr+eTq2JsyVjQr3RFuVBjc6IxuGaYq1m2cy//t47Wi1uo5cwJS8DzKr2x01l7203PyU9np1tNvHYUXjpcoVlhzUdxs7YnayPXM/r+19n2dBlmGnKfq5XRqwkOS8ZN0s32uU2JgnQ+XhXfYz+fg3So8DOC9XgD1FptZyPz+RMbCZatcTdIZ7ltuXtrGXFtK68vPIkfx6PZf5e5Q/G9t72fPdAu3qZkBvCfeROj68u5g2om7mjIbze/ybEeNcfYqzrlzt9vO/k2IoRc4egPMRY1y9ivOuPhjDWd3p8DWneyD9yBACrzl3u+HG9GfZae/xs/YhIjyAsLYwfTv8AwKiAUbjZuNVqX1bt25EC5J84gVarJatoHM1bt0ZfyYOimr5WPrY+HEk4wtWcq2i1Ws6mKM7irZxb1cnrFuwUTGRGJKdTT7MjRnH36efdr0G9RxrCvezfRKVrgy++WM/RlKUhvBca0twhPl/1hxjr+kWMd/3REMb6To8PGs4z8obwetcHy48qKc6GtHLDyaas21b3Zo2AsxyPTqdQlrDQ3VwysSNcSTPUN6gROp0OUMa7X3M3uvlHs/tiEh9vjuCrcW3Lrdcn0AW9Xncrl1WK0R19CHSzY9ovR7iUlMPI7w6waEpH2npVT7Rz+nIaAN6OFrja140RRUW08HCghUfVUhbW5nv7qb7N2BGezInoNF5ddZaFD3UsV6i2YF84hUaZjr4OdPJ3qZW+Gwp3+r2kOrGpqtPwkSNHSEhIoF27dmg0GjQaDTt27OCLL75Ao9GUqF6LVbDFJCQklFHECqqBsRBT3CkALpm34LsH2mGmVSObTMgFBZhyczFmZmJITSV5wQISl2wBYE13WNtRhbPcs9xm9Wo9dq3bsbGt8gG//PqbRF1Lx9pMw+gOnpjr1Hw8qjV+GbEEHdqstDncBZNKoqdH2TYfC5nOT/dZkW4B+ecvkPDhRwDkHDyE+dUk8rRgf/c9yiVdVRav0uxbYlYFMVR5SJKEh70FY9qGsO7+ZbRu3Z9ka5BMEkEpEUQ848/Ztwdw8NW+bJ/Zi7+f6sayRzuz4KEO/PZo5xIxFMCJ8NX4XlMs8czbdq5RPLdEFcVQN0NjYUui5Ije1gBA/sWLlZZ/rdNrOJs7czn9Mp8d/azM+UJTIfPPzAdgUotJGKMVq3adl/fNgzGZ4OA8OL4YJBXc+13Jda48prTTO8AFB8uKJ39znZpPR7fh1cFBWOjUjGrvweKpofWqThbcGmLeEAgEAkF1EXOHQCAQCKpDQ5k3VHl55BelyLMMrdoO5DudYOdgAH449QMnE09ipjZjcsvJtd6PWXArUKkojImh8FoCOQcOAnU3jj42PgBcSVc2Zp1JUl63lk4t66S/4nZXhq8kJS8Fa601HVw71ElfAoFAoaHMHQKBQCC4cxBzR8MhM6+Qv07EATCuY9kMNQCeDuY0tjPHYJI5FJl60zZlWWZLWAIAfYNKC2MkSeKVwUFIEvx9Mo4jV1IqqFf774PWnnasfqIbHXzsyco3MHdL9dPdHYtSrr+6QqqGjEat4pNRrTHTqtgVnsTP+8u6uKVkF/DrgSgAHu/tX+a8oOFQLUFU3759OXXqFMePHy/51759e8aPH8/x48fx8/PD1dW1VE7BgoICduzYQZcuXWo9+P8MCWHkRcP5P12ZteIT0ruFEhbUnHPNW3CuVWvOh7TlQoeOhHfuQsJ77wOQ10FiUTcNaqOWsHBfZLn8/Jed3DqxtKeKHGsd2pgo7r24k/Gh3ljpFSVsG0873o7agBqZ/V7B/GGjCGzKE0Q5mjsyqvMjfD1EeVul/vILmVu3kfTrLwDsaiHRrVl/KMjGOkNpx9y7dhZ4LLQWvN3tHc55K+Kq6GRzVMcWYaHT4GJtho+TJS3cbeno60CvABec/iGoORG5GZ94ZYzMWraqlZhuF4l6b/S2ituVIS4OY1ZWhWVt9ba83fVtABaHLWZ/3P5S59dfXk9MVgwOZg7c2/ReCqOiAdB5lf8HBKBYcp1fD991h7UzlWNdZ4C3cg8wmmT+PBYDwH1tPW56PZIkMbWHH6ffHMAHI1uj19RMQCe4PYh5QyAQCATVRcwdAoFAIKgODWXeML8cCUYjWm8vtO7u9dZvXRLspAiiTiadBBR3qNpMlVeM2soSfbNmAOQeO0b2wQMAWIR2qvW+ALxtlE1gkRmRXMu+RkJuAmpJTaBDYJ30VzyOSblJAPTw7IFWfefuxBUI/g00lLlDIBAIBHcOYu5oOKw6HktuoZGmLlYVpjiTJIkuTRwB2BuRdNM2z1/LJCYtFzOtii5Nyn7nae5uw6h2ngDM+jus5Ll8RGI2USk56NQquvnX/nclAGdrPXPuU55t7wpPIjW7oFr1j0alARDiZVfLkd3ZNHG24uVBSoatOevCiEgs/Tx9wd5IcguNtHC3oUfTunntBPVDtVLmWVtb07Jl6d1QlpaWODo6lhyfMWMGs2fPpmnTpjRt2pTZs2djYWHBuHHjai/q/xhZlw+SesESU54KFfmUL21SkLRaHB95hPccVoAhmeZZtuxNNnA6JoNgD9sy5Tu6duRzM4lf+mh4ZFUB485vxsX38ZLzmevX43jxDAUaLd+3a4pRDsPHxgcvGy8KCwvLtPdA8wdY1noZayKvMvSQTNwrr2DIzEACTnR15UlbX4jajwoT12Q7mjUNqIURUrDUWmJsHQSnT5OSaKY4E/V5HbQVW1cWczolgqGJys9mQWXTCzYkcm38UOcdxWipQ51dQEFEBOatW1dYvlvjboxqNoplF5bx2u7XWHn3Smx0NphkEz+e+hFQXldzjTkFUYoSVuflWX5jl3fClrfhalH+ZL0NdH0Kuj5TUmTPxSSuZeRjZ6Gld6Bzla+rNnLqCuofMW8IBAKBoLqIuUMgEAgE1aGhzBvmEcrGMMs6EvHcDlo5X99QZqY246GWD9VZX+Yhbcg/d460P1ZiTExC0ukwb1PxWset4G2rCKKuZFzhdNJpAJrYNcFCWzbVRm0Q4BCARqXBYFLcvvt69a2TfgQCwXUaytwhEAgEgjsHMXc0DGRZLnH1GdvRq9JUt138HVl+5Cr7IpJv2m6xy1PXJk6YadUUFprKlHmufzP+OhnLsag01pyMY1hrd7aEXQOgUxNHLPXVkmVUC38XKwJdrTkXn8mGM/GMqcAZ65+YTPJ/0iGqmAc6ebM57Bq7wpN4dtkJfp/WGY1aRVa+gQV7LgOKO1Rl7yPBnU+tf/JeeOEFcnNzmT59OqmpqYSGhrJx40asra1ru6v/DIln9pKfqDgaeS1YgM7HG0mtBo0GSa2+/rNGAyoVyXnJbF02D4CHC7LYC/x1MrZcQVRzx+ZYai3ZHJRF572NCU6MwfTlJ/Dll5hycrj2/gcA6B94iHSLE6gBV03bMu0Uo1frebrt07yW/iIto2V84tOQgPONoWlofyRJIj/qMHrgpKkJbb3tanWs/HsPh8WnsU5QY8xKRR22GlqNqrRObsJZstKM6IyAhTlazwrEPg0Fp6aQANioIFtJm1eZIArgufbPsT9uP1GZUcw5MIc53eewLXobEekRWGmtGB0wGtlopDBacYjS/jNl3tUjsPVtuLRd+V1jDp2mQZenwKJ07teVR5V0ecNbuwu3JwEg5g2BQCAQVB8xdwgEAoGgOtwJ84ZFRAQAlp1C663Pusbfzh9zjTm5hlzGBI6pE3eoYixCQkhbspTsHTsBMA8JQaXX36RWzfC08kQlqcgx5LAtehtw3cWpLtCpdQTYB3Am+Qw6lY6u7l3rrC+BQFB17oS5QyAQCAQNCzF33H5OxaRzNi4DnUbFfW0bV1q2s5/y/eV0TDrpOYXYWlTs0losbKos7Z2LjRmP9mjCp5sv8P76c9zVvBFbzhWlywt0qbBebTGstTvn4s+z5mRclQVRl5KyyMwzYKZVEej633ufqlQSH4xsxYBPd3IiOo2vtkXwdL+mLN5/hYw8A37Olgxo4Xq7wxTcItVKmVce27dv57PPPiv5XZIk3nzzTeLi4sjLy2PHjh1lFLOC6qE6cRTZJFFobYVFaEe0rq5onJ3R2NujtrFBZWmJSq9XxFGSxOqI1Rgw0Sovn17ZEViSy5oTsZhMZb2lNCoNLRxCQJL4rltTUKvJ2ryFzO3bSZo3D0N8PNrGjWny5CNY2il5R/eeciEqOafCeAf5DiLItRWfDpcw6BTBy8YQFT08egCQEaFYm1/WNcPN1rxWx6pz6AhSrSS0RjibYQmH59+0zplTv+CpzGOYBwUhqW75Y3FbsXBXLNx11nkA5F+MuHkdrQXvdnsXlaRizaU1bIzcyA8nfwBgTOAYrHXWGK5dQy4sBK0WrVvRzf/aWVg6Hn7oo4ihVFro+Ag8fRz6vVlGDJWVb2D9GSV/clXS5Qn+nYh5QyAQCATVRcwdAoFAIKgOd9q8YUxLwyw2DgCLjh3rrd+6RqPS8GDzBwlxCalTdyhQBFA3YhFad+OoVWtpbKU8PNkctRmAFk4t6qw/gJZOyvuxi3uXOnOiEggElXOnzR0CgUAguPMRc8edx5KDijvU4Jau2FnoKi3ramuGn7MlJhkOXK7YJSo5K59j0WkA9LmJsGlqD18a2ei5mprL51vCOXIltUr1aoOhrdwAJQVgUlZ+leocvZIGQCsPOzTqhv18vKa42Zrzzj3K53Tu1nAORaYwb5fiDjWtZxPUIoNRg+e/+c5uQMiFueiiUpSf23e8qSWbSTbx+4XfARhpMkMlG+muv0hseh7HolPLrZOX4av8H5COw8SJAMS/9TYpP/4EgMtLL3ImK5w8UwYq2YLsDE9mLj+BsRyBFYBKUvF8h+eJc5R4exT83EfF0daWtG/UHgBt/HEACl3bVH0gqoiF1oLUIOWGH5FiAVF7IeFcpXVORu3A95pyLWZBzWs9pvrG2VfZtehgkwEoDlFVoY1LG6a0nALAq7tf5XTyafRqPROCJgBcT5fXuLHiSrbnc/imC5xbA5IK2oyHJ4/A4A/Buny17LpTceQVmvBztqR1OY5lAoFAIBAIBAKBQCAQ/NvIPaSkldf5N0HjVHcuSreDJ0KeYNGgRTiYOdy88C2g9fBAfcPYWYbWrdOWt43ijJ1dmA1AS8e6fZA1qcUkBvgM4Km2T9VpPwKBQCAQCAQCwb+VrHwDq47HAkq6vKrQpYkjAHsrSZu3/Xwisgwt3G1wtTWrtD0LnYbnByjGFd9sj8BokmnWyApPh7rf9ODtaEkrD1tMMqw7HV+lOkf/w+nybmR4a3eGtHLDYJJ54McDJGXl425rxj1tKncZEzQMhCDqDifu/GFy4hUFa+MhQ25a/lD8IaIyo7DUWjLArQsAo5wiAfjrRFyZ8mk5BRy7oCwo5avDsXvsETSNGmGIi0MuKMCyS2es+/Vjx9UdAHRv3BVLnY6DkSnM33ulwjhCXEK4y/suznlK/BWqootnN3RqHeSmYpenpF2z96+b3XyOnRUnKumaHhPAkQUVF85K4ERuPD5FDlFmQUF1ElN94ujmQ46sx8K2AKi6IArgsdaPEegQSJ5RcZca0XQEjubKHwMFVxRBlNbbC2QZdn4EyBA4FKbvh3u+BnvvipoG4PeidHkj2nqIfKsCgUAgEAgEAoFAIPhPkHvgIADmHf896fLqG0mSsAhpo/xsbo55cN2lsAPwsfEp+Vmv1uNv71+n/XlYe/BRz49oat+0TvsRCAQCgUAgEAj+raw+HktOgRE/Z0s6+lZtw0aXJsoz8n2VCKK2nCtKl1dFl6f7QhrTwt2m5PfK0uzVNsUuUX+diK1S+WNRaQC09bKro4gaBpIkMevulrhY68krNAHwSA8/dBohpfk3IF7FO5yrezZSkKFFlsC+e9ebll9xYQUAQ/2GYuHbG4D28hkA1pyMK+PqtPhAFDlZzqhMluSb8gjLvUyjl19WTqrVNHrlFSRJKhFEDWrSlzeGKS5Kn2wOJ7bizHk80/YZNCoNQEm6PFPMcQCiTM608PerwghUn5Z3jQHAJ9bEcY0eTiyBwtxyy8rn1nJCp8MnocghqnnDF0RJKjWxGg/0toUAGOLiMGZlVamuVq1ldrfZ6FQ6dCodk1pMKjlXEKUI4HRe3pARA/kZoNLAyPngHHDTtq+m5rD/kuJ2dk+IUNQKBAKBQCAQCAQCgeC/QU6RQ5T5vyhd3u3AvF07ACzatUPSVZ7+4lYpdogCCHQIRKvS1ml/AoFAIBAIBAKB4NYoTpc3rqNXlU0ZOvkpphDnr2WSmFk2zVyBwcTOC0lA1YVNKpXEq0OuP2+uqpCqNhjSyh2AQ5EpXMvIq7RsRl4hFxIyAQj5jztEAdhb6vhgZCsAnK31jO5QNZcxwZ2PEETd4agO7wXA+KkW2gABAABJREFU5GaH2rbyFGMpeSlsjtoMwMhmI8FHEVBZp56msXkhSVn5HLh0XeGabzCyYG8koCLIPgSAA3EHsB7QH7dZ7+Axdy56f39is2IJTw1HJano1rgbo9p70jfQhUKjzC/hagxGU7nxeNp48r/O/2N4k+EM8BkAQGr4fgBO04TmN6hjaxNL/2bk2ujRGeBgvjPkpcHZVeWWjT33J6psNVZ5gEaDvkmTOompvkm39EGtkzFZKdaNBRERVa7b1L4pS4cu5dchv+Jm5VZyvDBKcfbSeXpCQphy0NEfNFVbhPzzWAwAnf0caWxnXuV4BAKBQCAQCAQCgUAgaMg0mj2bxMGDMG/f/naH0qCxHzMGpyefoNGrr9R5XzcKooKd6taNSiAQCAQCgUAgENwap66mcyomHZ1axX1tPapcz8FSR3M35Xn1/ktlXaIORaaQlW/AyUpPcOPKn9PfSJcmTjw/IIDJXX3rNR1dYztz2nrZIcvw98mymaNu5ER0GrIMng7mOFvr6ynCO5teAS78Mb0LK6Z1xlynvt3hCGoJIYi6gzGaZKwuK5Z2uvZtKy2bUZDBzB0zMZgMtHRsSaBDINh6gL0vkmxiqrdi5/fXyesWeauOx5KYmY+rjRnDA3oCcDD+IJIkYTdyJNZ9FIepYneoNs5tsNXbIkkSc0YEY2uuISZHYlNYQoVx3eN/D+92exdzjSKAyY1UdkUm27ZEq66bt58kSUghLQFIv6bBCHB4ftmC+ZmcuHYUn2uKO5S+adM632FYXxTYKVbuJlvFoas6afNAEUUFOJR2fSqIUpTVOm+v64Io58AqtSfLMiuPKoKoEe2q/oeIQCAQCAQCgUAgEAgEDR2zFs1J7dkTtW3dbAz7r6AyM8P58cfR+/rWeV83psxr4dSizvsTCAQCgUAgEAgENSMmLZdnlx0HYGBLVxwsq/est0sTxSVqbzlp8zaHKc/X+wQ6o1JVzXWqmMd7+/PGsObVrnerDGutuEStOVl52ryjV9IA6lWw1RAI8bLH29HydochqEWEIOoO5kxENNI1xX3J/Z4RFZaLz45n4rqJHIo/hKXWkhc6vnD9pG93AP7P3l2HV1m+ARz/ntzZdtbBuoMBoxldIiAlEtIKCIqggIEYqCiIP1FMDEIQJFSQ7u7O0TAGC9bd26n398fBKVLb2ADh+VzXuba98bz3exjbznPu577bW0UBsOFMMnqjCZNJYvbuKwC80MKPph6NATiZepJiw40l9P5KiGrj3aZ0m6uNhuebmEvF/bw3Bkm6sRXf7WgzTgOg8G5QpuMryruluSKVX5yeo5aWEH/w7ySev1zeRqRKjv/1hChN2H+/Xd5fVNXMyUxKGx0AJVHlS4j6N0mS0MWbK0SpfHwg7YJ5h2vZnrOT8dlcSS/AUqXgqVpu9xSLIAiCIAiCIAiCIAhCVapmXQ0btQ0yZNRxqfOgwxEEQRAEQRAE4RbOJebS88d9RKXm42ar4Y32IeUeo1nQXwlR6TdslySJbdeLgpS1Xd7DoHO4OzIZHI/L5lpW4W2POxGfBYiEKOHRJxKiHmLX1i7BpJcjU0tYN259y2MuZV1i4PqBXM6+jIulC/Oemkc913p/H+BnTojyyD6Ks9aC7EI9ey+ns+tSGlGp+WgtlPSL8MHP1g9XS1d0Jh2RaZGlpxfqCzmcdBiA1l43xjCwsQ8qmcSphFwOXc28+w3lpWBvSMUkyXALbVzOZ6N8bJo0BSD0msTmatd/+f27StSFtURq1Pibk3sfqYQoO2/z6kU7bQ4AJeVomXcrxvR0pMJCkMtRe3pC6jnzjjImRC07fg0wZ2ZrLZT3FIsgCIIgCIIgCIIgCEJVksvkTH9iOt+0/QZvG+8HHY4gCIIgCIIgCP+y73I6fWYeICW3hJBqWpaPaoafc/kr+zTyc0QhlxGbUXhDAlF0WgFxmYWoFXJaBDlXZuhVqpqthgg/R+D2bfNMJokTcdkA1POxv0+RCcKDIRKiHmLqI+bKTHJfW2SKm/tUHkk+wpANQ0gtTMXfzp+FnReaW+X9k29zAGRJkfSqaQPAmshEZl2vDtU/whtbjQqZTEaEewQAh5IOlZ5+IOkAepMeL60X/lZuEHsA9n4Ni/tRbVY42y3fRkthabWpOym4ak6suix5UCewatumqQMDMdnbYGGA6ORC9ACRv4Pu+i8yg47iS5u5qFaXtszT1Hh0EqLcA2pikmTY2xUA5W+Z929/tctTubsjUyoh7aJ5h8vdn7MSg5E1keZfuD3re95THIIgCIIgCIIgCIIgCPdDg2oNeMLniQcdhiAIgiAIgiAI/7LqZAJDfjlMfomBxv6OLH25GR72lhUay0ajoraXHQAH/tE2b/sFc0WNJoFOWP/Hij10LW2bd+uEqCvpBeQU6dGo5IS5i9buwqNNJEQ9pAp1BpxizEko1g1q3bR/49WNjNgygjx9HvVc67Gg0wI8tB43D2TnCY4BIJno7Wxuebb2VBIHrmSglMsY2ty/9NAIt+sJUcnXE6LyUth9egEArXMykH3mA788BVs/gksbkBVm4G26xkjlGrZdSCUqJe+O95R28QAAV9ShOGktyvV8lJdMJsM2ogkAPleKOOzsAyU5cG6l+YDYvZyjGMsicLoetkVo9VsP9h+k1dqQLHPBwk4PgCEpCWN+foXH08WavxfVvj6QEwf6QlCozd9bd7HjQio5RXqq2VrQLPC/k0EtCIIgCIIgCIIgCIIgCIIgCIIgCMLDQZIkZuyKZuzvJ9EbJbrUdufXYRHYWaruadxmgea2ef9MiNr6V7u86q73NPaD0KmWG3IZnE7IISa94Kb9J+LM7fJqe9qjUoh0EeHRJr7DH1JHIq+iySwBwOWpzjfsm392Pm/tfgu9Sc+TPk8yq/0s7Czsbj/Y9bZ5QQUn8LDToDOYAOha2/2GbNnG7uY2dmfTz5I/tyOmL0PYnXy9XV5qDJj0YO0KYd2gwxSMT04G4EXVBtzI4Oc9V+94T1LCcQAKnWuX8Vm4N9YR5vupESexwT3QvPGvtnkX1hGp+bs6lMrXB4W2/GUUH2apFj4o1BKSjRUAuntom6eLiwVA5eMDqefNG51DQHH3jOhlxxMAeKaeJwq5rMIxCIIgCIIgCIIgCIIgCIIgCIIgCILw+DGaJD5ec47PNlwAYFgLf6b3q4eF8uYuS+X1V0GH/dEZSJJEdqGOY7HmpKEn/oMJUc5aC5pfb/O37vTNVaKOi3Z5wmNEJEQ9pBLWrwdkWNjpUdc2l+c2SSamHp7KtKPTABhQfQDTWk9Do9TcebDrCVGy2L2lJfIAhre8sbqPh9YDbxtvjJKR42knOa9Wk65UYIWChh2/hjEnYdwl6LsQmr2KKeJlMqxDUEs63lD+yYoTCaTmFt86BknCOfcsAFb+jcr/hFSAVSPzdUITJHYVJqGTK+HaYUg+AxfWc8rCAn9ztUM0YTXuS0z3U76N+d/XZK8G7q1tnj7OXF1M7f2PhCiXu1fUyizQseOCOYO6V/2qbZMoCIIgCIIgCILwUCjMhJwEkKQHHYkgCIIgCIIgCIIg/OcV6428sug48/bHAPB+lzA+6FoDeSUVYmjg64BaISc5t5ir6QXsupSG0SQRWs0Gb0erSrnG/da1tjsAayITb9r3V4Woej4O9zUmQXgQHruEqGK9kSnrzvHznivkFOofdDi3ZXN0BwBqbzVYOVJiLGH87vEsPL8QgDcavME7Ee+gkJch69Wvuflj8in6hdugUcnpVMuNWp43V5WKUJp/8B2ysmJn8xcBaO77BKp6A8HRH2T/+MUik3HWsz8AvZW7CTDFMP9AzC1DMGTEYGPKRScp8K/VuCxPwT2zCA5Cbm+PRg8ucQXsD7r+PKx9HSkvkUiNBv9k8wS1JizsvsR0P0lOwQDIbAwAlERVPCFKF/ePlnl/JUS53vk5kySJhQdjMZgkwj3tCKlmU+HrC4IgCIIgCIIgPJQkCTKvwsnfYPVo+L4RfO4PX9eAzwPg1+6w+QM4/SekR4HJ9KAjFgRBEARBEARBEIT/jOxCHYN+PsTGs8moFXKm9693U9GPe6VRKajvaw+Yq0Rtu94u74mw/151qL90rOmGUi7jQnIel1PzSrfnlxi4mGL++q97FoRH2d37XT1iVp5IYPb11m7TNl/kmbqePNfUl5oed2g5d5+l5hbjGW+O0bpeCEaTkbd3v822uG0o5Uo+af4JXQK6lH1AWw9wDITMaAIKz3Ds/fZYKG+RC5d6gcZRe1nmbMthZx9kueYEmlZerW47dJZ1IKaw7sjPr+Jd5WLGHAxkVJsgrC1u/NZKOr8PbyAKX6q7O5c99nsgk8uxbtSQvC1bqREvsbGeI20Arh0mSakgTSHHL9UIgKbGo5cQZeURBhfBWptHETJK7qllnjkhSuXjA9vvnBBVYjCy6mQic/ZcLf2F2qu+Z4WvLQiCIAiCIAiC8NAwGSHlLMQdhLj95o95N5efR6aAoky4stP8+IvKGtxqIa8Wjk+GBEke4B4OqrtUfhYEQRAEQRAEQRCEx0yRzsjguYeJvJaDjUbJrOca0jTQqUqu1SzQmYNXMtkTlcaB6AwA2v0H2+X9xd5KTctgZ3ZcTGNNZBKvtzcXroiMz0aSwMvBElcbMRchPPoeu4Sog1fMP8C0FkrySwz8fiSe34/E08DXgeeb+tKpljvqWyUL3UfHdh7Br1iHTGHCrnkrvjr2NdvitqGSq/ih3Q809Wha/kH9W0JmNMTswTr0qZv364vgzxdoVJALzrZc0GVCZiYyZLT0bHnHoY1t30d2cT2tOUV4yXH+OBLMCy38bzgmN/owAMnaGtSspPKFZWHVKIK8LVupGSvxTdZ5ih180WTFcsrCAgudhEfm9QpR1e/e/u2/xtm3pvmjNoN4nCvcMs+YnY0pNxcAtacHpF0y7/hXQlRmgY5FB2OZfyCW9PwSAKzVCgY09mFQE98K3oUgCIIgCIIgCMJDwGSC00tg68eQ969y83IVeNQDnybg2wyDRyN0Cg1WWZcg+RQknYKkSHMilb4A4g+hiD9EPYC5c8zJU84h4BYObrXMH6uFg9blQdypIAiCIAiCIAiCIDxwRpPE2N9PEHktBwcrFb+/1JRQt6rrRtM8yImvtsDmcylIEjhYqf7zLeW61vZgx8U01p5K5LUng5HJZByPFe3yhMfLY5UQJUkSB69kAjDzuQaolXJ+PRDLhtNJHIvN4lhsFpO15+kf4c2Axj6421k+kDhTt+3CD7By1bFUXcT8c78D8EnzTyqWDAXg1xKOzYOYPbfev/l9SD2Ls7ULQbZ+XM6NASDcJRwny7tk2jr4I2s0HA79xLvKxYzY05Dnm/qiVPydWKZOjQTA6F63YvFXkFVEIwCqJ0BJSQF7Q5/gyYPzidRY4pMKMgkULs4oXR69iWYPL19yJSus7YsAMCQlYczPR6HVlmucv6pDKV1dkRclg7EElJZg7wdAdFo+c/deZdnxaxTrze0f3O00DGnmR78IH+wsVZV3U4IgCIIgCIIgPN6MeijOhZKc6x9zQakBr0Y3tnivTAnHYMPbcO2I+Wu1DXhHgE9T8G0KHvVBbUVMegGLDsWy9I/jZBfqcbPVEOhanUCXhgTW1BLYSkOoKhnnvIuYEk+SeXYnzsZkZEWZkHbe/Di95O/raquBd2PoNNVc+VkQBEEQBEEQBEEQHhP/W3+ezedSUCvlzH6+YZUmQwHU9rLHSq2gUGfuLtQ21BXFfSzyURXa16yGeoWc6LQCLiTnEeZuy4n4bADq+9g/0NgE4X55rBKi4jILSc4tRqWQUd/HAUu1gkZ+jqR2CeO3w/EsOhRLal4xPx7cxM8XjtPUsz5ze425rzFKkoR95AEAUrxNfHrZPBk6ut5oOgd0rvjAvs3NH5NOQVE2WNr/ve/8Gjjys/nzHjOIyDhSmhDV2qt12cZvPR7p5CJqlsQSkbeF9Wdq8HSd6xO2JhMehRcBcApuUvF7qACLkBDkdnZocnLwT4YNvhJPejcm0rIE/6h0ADRhj167PACVUkGUwosasktgp4WcfHTR0VjWqVOucXSx5oQotY+PeYIewCWEqLQCpm68wNbrfXQBanna8mLLADqHu6NSPNhKa4IgCIIgCILwX1esN2IwSWgtHquX7n87vwb2f29uPfdX8pO+8NbH1h0E3b+v3KSo/FRzRaiTC81fq6yh1Tho+gooLQAwGE1sPZ/KokOn2XP9NeZfknOLSc4tZt/ljBu2W6nt8HfuhIXUjIhaAYRaFxAsxeBRfBm73AsoUs9CRjTkp8D51VCQBoPXguIx/T4QBEEQBEEQBEEQqpzRJLH1fArrTyfRtbYH7WtUe2CxLDgQw897rwIw7dk6NPRzrPJrqhRyIvwd2XkxDYAnwv677fL+YqtR0SbEhc3nUlh7KpHqbjaciDNXiKovKkQJj4nHajbtr3Z5dbzssVQrSre72mp4qY0X7l6RzI78leRi8w/Yw3kn+P14G/rVr33fYoyOTycgNQaAKXVsMEkmngl6hhfDX7y3gW3dwSkIMi5D7H6ofj25KjseVr1i/rzZGAh6kgi1jMUXFgPlSIiyckTW8g3Y+hFvqpYyeld7utV2RyaTkRl3FkeKKJLUBIc3vLf7KCeZXI5Vw4bkb9tGjXiJzT4HyRq4mfNLn6BZyvV2eWE17mtM91OWpR8UXMLkaIk8J5+Sy5fLnxAVb06IUvn6QOoFACTXMF5acIyr6QXIZNCuejWGt/Snsb8jsqpalS0IgiAIgiAIj6C8Yj2xGYXEZhQSk1FAXHoBRamXsc08g2/JBdxkWTi4elG7Zg1sXX3BxsNcLcjGHZTq+xusyQRRm8FQDL7NQFuFk4NXdsKSwSAZb7lbUlmhU2rJxwqHojjkJxeCczC0eO3er23QwaEZsOtz0OWZt9XuB09+ZH5tDSTnFPPb4Th+PxJHSq65ZbhMBm1CXBjY2Jf6vg5cTS8gOi2fK2nmj9Fp+cRlFFKoM3I2MQ+Qc3xPzPWLWgN1gDq42FgQ6CKjmSaWlxPfRx13APZ+Ba3H3/u9CYIgCIIgCIIgCMI/5BTqWXI0nvkHYriWZe46sycqnZbBT6BRKe5yduXbfiGFiavPAvBWx9C/C3DcB80Cndh5MQ2lXEarkEeju1DXOh5sPpfCmsgketX3IqtQj4VSTpi77YMOTRDui8cqIerQ9XZ5TQL+bgGXlJ/E7xd/Z1nUMnJKcgCwVFqCSUORKYvP9v5Cx9CpOFjfn4nms+t3EGIykWkL0U7Q2K0xHzb5sHKSTPxamhOiYvaaE6KMBlg2HIpzzCX+n/gAMF+zmlU1qllXI8QhpOzjN34Z46HZeOYlEJGylANX6tIs0JmEs/twBKKVgdSyuv9tCK0amROi6idYsNpYzIzIGRhMBgLTFIDhka0QBVBiHwgFIGnNrexKoi6Xewz9XxWivH0g9SAAWdaBXE0vQKWQsWFsK4Jcy9eGTxAEQRAEQRAed99svcSCA7HIC1KoI79CbXk0dWRXGCC/goMs33zQX6/YM4DdtxjE2sWcHOUSBu0/Bhu3qgs4JwFWjoSru/7e5hwKfs3NFYn9WlTe9dOjYMnz5mSomj2g4TDysOJUmonDSUb2xBUTmVSI0WRe5PK8YhOTVPORtn6EzCkIwrpW/NpRW2DjO+bXzgAe9aDT5+AdgSRJ7L+czvz9MWy7kFp6fSdrNX0aeTMgwgdvR6vSoRyt1TTwvXHFpd5oIi6zkEtJOWzcdwxbNz8Sc0q4llVEfJY5WSotr4S0PDhINa7IB/ON+kfY+Rn4twafxhW/N0EQBEEQBEEQBEG4Liolj3n7Y1h+PIEivXkxkoOVCgnILNCx9lQSvRt43deYzibm8OriE5gk6NvQm1FtAu/r9Z+q6c63W6PoWNMNW43qvl67qrSr7opGJScus5BfD8QCEO5ph1opOv0Ij4fHJiFKkiQOXslALplodWE3kVdXsM14lk36U6TYGjEqZHhqPelfvT89gnuw99oB3t4zDr31AT5YfYLv+9+fSce8vebJ5eMBMgItnPiq7VeoFJX0A9evBRz7BWL2mL/eNRXiD4LaBnrPLV1drFVr2dBrAzJk5UvEUlmiePJDWDGCUcpVvLejN80C21MSewSAbIfwyrmPcrKOiAAgJN6A3CSx5OISFEYJr9S/KkRVfyBx3Q8K1xBIAAvrfAxASXR0ucfQxV1PiPL1gavzADitM2dj1/W2F8lQgiAIgiAIglBO+y6nU7LjS9YqN+Ouybxpv1GuotixBgqv+qQp3Thx7hJSXhJuskw85Fl4yDJRSHpzK7WCNEiKhMJ0GPhn5baM+8vpP2HdG1CcQzFq4nEjmDhIv2h+HJ0LgOQYhMy/Bfi2gMAnwNrpLgPfQmEmLO4DxTkUuTXkS9UY9q0u4EJyMpJ046HejpZE+Dmx+XJ3ggoTeV65BWn5i8he2Aju5auMS34qrB4Nlzaav7Z2MVeEqjMASSZj+/kUpm+/zMn47NJTIvwdGdTEl441q2GhLNuqWZVCTqCLFh97C3RXJTp3DkOlMr/mlySJ7EI917KKuJZVyOXUfL7eCq2NkfRQ7IPlw+HlvaCxK9+9CYIgCIIgCIIgCALmtng7LqQyb38Mey//3fa9upsNQ5v70b2uJ3P3XeXzjReZvz+GXvU971tnmKScIl6Yd4RCnZHmQU580qPWfe9K4+NkxfEP26OUPzrJQtYWStpVr8a600ksPGhOiKrvK9rlCY+PxyYh6lpWEYk5xXRNWofNKnPSUafrD5McTK5O2Pq7oz51Fb33Epp6eeJjdCZOmc7GmE1sPutLh5pVuNoWKNbrcIveC0C0r8QPDd7GVl2J5er8Wpg/Jp+G82tg9xfmr7t9A47+NxyqklcwCSu8D7o932GbfpYGMbO5mNwE26zT5jG9G1Qw8HtjERqK3MYGZV4efikKrrgb8M4ApcGE3Noalbf3A4nrfrD1rgEnwMk6jRRsKblc/gpRfyVEqbw84EgUADuynAATTQMq8AaHIAiCIAiCIDzGjCaJbSvm8qHqdwAkmRyZS3Vz1V7PeuBRH0W1mlgrLQDwBry6SOy8mMbEjRe4kJwHSARrSxgboeUpt3yUq16Gy1vh4nqo3qXygi3KgnVvwpllAESaAnhN/wpXJXfsySNCfoHG8gs0lp+nhiwWeeZlyLwMx+ahU2pR9pqFPKwc8Rh05spQmVco1nrxVNIIYmOSSncHulgT4e9EY39HIvwd8bA3VyA+fDWTgbOex0+WTCtOw2/94cXtZa9Yde0o/PEc5CWCXAmNX4bW4zGpbdl8LoXp26M4m5gLgIVSTt9G3gxq4ktINZuy31sZyGQyHKzVOFirCfcyJz3pjCY+3D6URooovLLjYN046DW7Uq8rCIIgCIIgCIIgPNokSWLtqSSmbb5IbEYhAHIZdKjhxpDmfjT2dyxNPurXyIdvt0ZxOiGH43FZNPB1rPL48ksMvDDvKCm5JQS7avlxYANUigeTlFTWBU//Jd3quLPudBKG65Wu63nbP9iABOE+emwSojZdvIjGfRHd9p4A4KqbHEe5Frv0YuQ6HfLkDAqTMyg8cLD0nI+9nRg6UELtsJ/3VjYlwt8Re6uqaZ0nSRKfLH+HgVk6jDJ4wSoLT/+2lXsRGzdwCoaMKFg6FJCg3iAI711515DLUXeaAgueYZBiK19s2sabuisgA4+azSvvOuUgUyiwatCA/J07aZnqwBX3bPxTzD/wLcKqI3uEsnz/zcO/BgZJjp1dASnYYkhKwpifj0JbtqpOxvwCjBkZAKitDWDSI6m1bIhTArob2k8KgiAIgiAIgnB3aw6cZmT+dJBBcYOX0HSYCBZ3/vtcJpPRtrorrUNcWB2ZyJdbLhKVKePV7QZ8nRyZHTiEkEuzzK3eAp8AVSW0Ko/eAStHQV4iRuR8p+/BD8buPF3Ply+b+hKbUcDVtHocTy/gz7QCMtKTCTeep7H8Am3lJwk2JMAfA9C1eBv1E+/A3V53SZK5ClXMHgxKa3pnjyXWYE1DXwdeaOFPIz9HXGwsbnlqhL8jY9uH8ermMayQTyQwN8GcFDV0/d2fi2PzYf04MOrAOQT6LMDoHMr600l8vz2Siyl5AFipFTzXxJfhLQNuG0dVGNMumN2X0hiTMIqlFpNQnF4CQU9Cnb73LQZBEARBEARBEAThvysqJY+Jq8+yP9r8fp+tRkn/CB8GNfG9oe37Xxyt1XSv68GSo9eYtz+2yhOiDEYTry4+zvmkXJy1Fswd0gg7y0ejXd3Dok2oK9ZqBQU6c2tEUSFKeJw88glReqOehecX8v2lH6ibXYRPOhgslDRZugFHFy8kkwlDWjr6+Dh0cfHo4uPQx18jb9MmrOMz8MvUEOOUQKYhiklrXPiqb90qiXPBuQUUHNgEgMHFQF3XoMqZxP43/5bmhCiT3jzZ2+nzyr9GYFtyPVtjm7CLHtHvYyHXk4s1XgE1K/9aZWQVEUH+zp00TtYyv042ASnmLGdNWI0HFtP94GpvQwzV8FcnIbO3RcrORRcdjWWdsrWP0Mebq0MpHBxQFJk/L3EIJiVWh1ohF78wBUEQBEEQBKEcCkoMWG99GxdZLpnWgTh2+gSUZU+ukctlPFPPk87h7vx2OI7p26OIzSike0YTjtitQpsdB3u/gbbvVjhGuUmHfPN7cGQWAHG4M7pkJBcUIXzaqxbPNvRCJpNR3+fG1wImk0RybjFX0wvYGpvGgZ0f8bxiI+q9UylKOIFl35/v3OrtwPdwYgESckYUvcIZoydPhlXj+wH10KjuvjpzVJsgDl3N5IXL41ijmYht4nFYORJ6zb11MpahBDaMh2PzzF9X74rh6R9YczGf7xfsIjqtAAAbCyWDm/nxQgt/HK2rZoHUnagUcr7uW5cu3+Xzjb4nb6r+NFft8o64qdKzIAiCIAiCIAiCIPwlv8TAd9uimLv3KgaThIVSzqg2QbzYyh8r9Z1TBAY382PJ0WtsOJ1ESpcwqtlqqiRGSZL4aM1Zdl5MQ6OSM2dww1smaQn3RqNS0L5GNVaeTMTT3rLK/j0F4WH06JbGAQ4mHaTXml58dewrjJTQ6ZD5P7dLrz44ungBIJPLUVVzxaphQ+x79sB17Fg8p32BVZMmAPTPCgbAwmE/y08ksO18SqXHuSNuB9OOTqPOFXPVIk/XQnOrhKrg19L8UWEBveeC2rpKLmPb7VNMyAiTxwNwTRP6QCsxWTVqBIDzpTRsFNbUyTa3ItSEhT2wmO4HmUxGqtrcElByNq86L0/bPF2sOQlK7eMDqecBSFD5AVDXx75Mb0wIgiAIgiAIwsMsv8TAyhMJDJt3hND3N/DJ2nNVdq0dy2bQXtqPATnafrPLlQz1T2qlnMHN/Nj1VlteahVAERo+KOpv3rn3a8i8WrEAkyJpc/FDFNeToRYY29OxeAp5znVY9Wpz+jTyLi2h/29yuQwPe0uaBzkzsl0YtV6cwUeKVymRVFhe3UzRj60h7eKtr3thPWz+AIBJ+oFsM9aldwMvZgyqX+bXHHK5jK/61KXA2pcXi1/DIFPC2RWw67ObD85NgnldridDyeCJDzjS+Fs6/HiS1/+IJDqtAFuNkteeDGbv208wrmMojtZq9EY9MyJnsCZ6TZliqiwBLlo+6FqDH4zPcMRUHXR5sGw4GPX3NQ5BEARBEARBEATh4SdJEqsjE2n35U5m7b6CwSTxZFg1tr7RmrFPBt81GQqgpocdjfwcMJgkFh2MrbJY5+6LYeHBOGQy+KZvPeqIVm5VZmATX5RyGZ3D3R50KEIlSy5IZurhqZzLqLo5zf+yRzIhKseUw9t73+bFzS9yNecqdmoHbC8+RcMrRQA4DBp41zG0rVsDUO+yCQCV3RlkylzeW3GanMLKm3TUGXVMOTQFudFErRjzP4fWvQQ8qighKqwbNBsDfReCW3jVXAPArRZJfj1LvyxyLVtFoqqiCauOXKuF/ALW1foe7xRD6fZHXZ42AACTOQeMkqhyJERdrxCl8v07ISqyxB2ApqJdniAIgiAIgvAfVaQzsu5UEiMXHqP15FVsWDqLdpensEr+FvUPjWXvihlQklep10xOiKP5RXNyTkzYy6i9G9zzmNYWSt55qjoNfB1YoWvEBcv6YCyBjRWoEHV+Lcp5T2FTnEi23JEhuvF8oB9Kx7oBrHm1BdXdbMs1XH0fB0aMeZ937L8gQXLCMvcq+hlt4PzaGw9MOoW0bDggsdDQjl+MT/FSqwC+6F0bpaJ8UxYuNhZ8268uhwnjXd0L5o27psKppX8fFHsAZraCa0dAY4eh/x9MK+pG31mHuJJegIOVirc6hrLvnSd47ckQ7KzMZfoL9YWM3jGaH07+wIf7PiS9KL1csd2r/hHePBHmzljdKPKxhoSj5nsTBEEQBEEQBEEQhOuiUvIZMPsQY347QUpuCT6OVswd0pCfK1B5aUgzc1XixYfjKDEYKz3WtLwSvth0AYAJncN4qpZI1KlKjfwcOf5he97p9GgXC3ncXMm+wqD1g1h4fiGTD0x+0OE8lB6phCi9Uc+8c/P4NvdbtsRtQS6T0796f14OnEWnU3nIkbBu3hyLgIC7jqVtdb2S0qkLNNWGI2HE1eM4KbklTF5Xedl1q6JXkVKYQt0UW6x1RmRqExoHPXjUr7Rr3EChgg6TIaRD1Yz/D+7PTKIYc0sB55CmVX69O5EplVg2MD+nJWs3YcrNA5UKi8DABxrX/WB0Mlc5U1oVAuWrEKWPu14hytsH0sx/lGzPNCdCNREJUYIgCIIgCMJ/SInByOazyYxdfIxBn8zk7B8fMuTSKA4phjNT/Q0DlDuoLo+ns+IwLSLfxjQ1ABb3g5OLoSjr3i4uSaT+PgoHWR4xygACe31UKfcE5spIk7vXQi6T8Up2f0wyJVzaAJc2lX2Q6B3w51BkJj07pAa0LfyU/fL6/K9nOF/3rYu1xd1Xj96Ku50l/3v1eb4P+pmDpjBUxkL4YyDGrZPBZIK8ZKTf+iHTF7DXWJOPDIN5t1MY73UOu20lqrtpHuTM6LZBLDW2Ya7Uzbxx1SsQfxgOz4b5XaEgFVxrEv/sBnptseb7HZcxSdCzvie7x7fllbZB2GhUpWPmlOTw0paX2JewDwCDZGB19OoKxVdRMpmMqb3C0Wk9eVs3zLxx9zSI2XfnEyUJMqLhyM9wcWPVByoIgiAIgiAIgiDcd/klBlbGyHn6xwMcuJKBhVLOG+1D2Px6K56oXq1CY3aoWQ03Ww3p+TrWn06q5Ijh5z1XKNabqONtz7AWoiX8/WCrUaGQV2y+RXj4nEk/w+CNg0kpNHc4O5NxhouZt6nO/hir2KzmQ2ri/omsuWIuXV/HuQ7vN32f6o7VeXfRIXrEHgbAYdAAODoXsmKhJBeKc6E456bP1bp81C4B6NKKGZQfzgFOo7Q/jCy+BX8eu0aX2u60DXW9a0zGnBz0KSlYBAffNKGrN+mZc3oOAC1ifIAsbNxKkKnU4Fqjcp+cB0Bu70XJ0zPJvbwb36Y9735CFbNu1IiCXbvJWb4cAIvgIGRq9QOOqupZuleHy2CrSScbJSXR0WU+t7RlnpcHnDKfd6SgGmqlnHo+9lURriAIgiAIgiCYFWYi3/0lrS6uR5H8FdzweupfkzdyhbkduFoLFjZ/f7TQYlJp2R1bxLbzydQ1nuZ9+Slc5Lk3LA+SnIKRBT2J5NuUTVs2EZyxnUCSricWbQC5EvxbQ42noXpXsHYu163E7ZpH7bw96CUFum4/IKtgq7zbqeFhy+BmfvyyD5You9JPvxI2vG2OWaW588nxh+H3gWDUsdEUwSu60Xg72bBoYANqeJSvKtStaFQKPh3Ulhnbf+Hsjo8ZptyAYu80dIknURZnIs9NINrkzquGsXzauz59Gnrf8zXHtAvm4NVMPrnalzCbVJrqD8G8rubqWYBUsyd/er7Nh/NiKNIbsdUo+bRnOF1re9w0VmphKiO2jOBy9mVs1DZ09u/MHxf/YHnUcobWHFrhxK2KcNJa8MWztRn6SwmtDZH0Ue6C5S/ByL1g6fD3gQXpcGXn348ccyt7gjtC6FP3LV5BEARBEARBEASh6kmSxND5xziZJAck2teoxodda5S7ItS/qRRyBjXxYdrmS8zbF0OPel6VEzCQWaBjwfVWfGPbBd3X19aC8Cg4kHiAsTvGUmQooqZTTews7NifuJ/lUct5t3EFKsc/wh6phKjnajzHgaQDtJK14r3272GhNk8yy7dtxEZfhMHNE63lZVj7VpnG0zqlk5mmJeBsJq6NXEktTOWJBslsO+rFu8tOs/mNVtj+Y9Xov0mSRNwLwyg+exaVpye2Xbti160rFkFBAKyNXktCfgKOGke8zplXHFu7FZtb2SkfjUQdu/o9of6DT4YCsIqIAMBUaK6UpAl7PEoCOvrUBMDVNo1s3DEkJWHMz0eh1d71XF28eeJcbQtIRkqUNqTgQFMfBzQqRVWGLQiCIAiCIDyu9EVwaCbs+QpFSQ4OAIUVH04OtLn+4PqfsEaVNfLANsgC20FQO2QOfoA5zapVUBd6/rAPU+p5Btufor/2OPK08xC9zfxY+zrU6A4dPwXbmxNo/k3KTcRx1/sAbHUZTKc6zSp+M3fwevsQ1p5KYnJeN7ra7kObdRX2T4fWd3j9m3waFvUGfQH7pDqM0b1CTUcZ80c2wUFrWWmxyWQyRrYLY4v7t7z9eyAfy2aiubIVgCxJywjT20wd1JqONSunPL5SIee7fvXo9O1uhuWNYJtDBu5Fl0Emp7DVh7wW14LNq80LPpoGOPFlnzp42N98v3G5cby05SUS8hNwsXRhRvsZeGm9WBO9htjcWI6mHKWRW6NKibms2oa68nxTXz46MJjGykv45l6DNWOh/mC4ssOcAJV8+saT5CrwaQIBre9rrIIgCIIgCIIgCELVk8lkDG/ux0crTvJZn/o8WfPucxVl1S/Ch++2XSbyWg4n4rKo5+Nw95PKYM7eKxTqjNTytC1TARJBEP62OWYz7+x5B71JT2O3xnz7xLecTD3J/sT9rLmyhtcbvI5GeZcFko+RRyohKswpjLVPr2Xrpq3IZeblvglZhbQ8vQMA54H9kO3/ynxw9a5QrSZo7MDC1vxRY/v35ytGoE2NJPOClsI9++jT/zm+P/UjBZqd+Dq9RGxGIVPWnmdq79q3jaf4zBmKz54FQJ+QQMbMmWTMnIlF9erYdOnMEuVSkMOAar3wTpsBgLV7CXjUq8Jn6fGlqVEDuZXV3wlR1R+PhCgfby8yJBuc1HkoHO0xZmaju3wZy7p173ieqbgYQ5K5BKbKIheAa0pfQCba5QmCIAiCIAh3FJ9ZSHxmIV4OVrjZaVAry9Ct3WSEU3/A9imQew0AybUWxyxbULdJa5SKv16+Src41wC6AnPl35J8jMV5nLmaQFR8EpZSIXbyEoKd1LhWb44spD0Kr4jbLkKxUiuZPbgRT39fwoQsb476vcRXfayQnV8N51dDUiScXQFRW6Hdh9BomLlC1a1IEmm/jcRVyueMFECd/h+X4dmrGFuNive7hDH295N8WNSPrxTTYc+XUKcv2PvcfEJGNCzoAcU5nJJXZ3jhWOr5u9LHNQ1tBVvk3U37GtXwfeUdXv3Fn4+K/ocTubzOOCYPfZqmgZX7GsPNTsNXfeoydN4Rnsl6jT9qHSHHtwMv7taQmpeKSiFjXIdQXmwZgPwW5eLPZ5zn5a0vk1mcibeNN7Paz8LLxrwatpN/J5ZFLWNZ1LL7nhAF8G6nMPZHZzA6bRQrLD5CcW4VnFt140HVws0JUAFtwbepuYKaIAiCIAiCIAiC8EjqUMOVkqtGWoe4VOq4zloLutXxYNnxa8zfH1MpCVHZhTrm7zdXhxr9xM0dlgRBuL2ll5Yy+cBkJCSe9HmSqa2molaoaeLeBHdrd5IKktgat5WuAV0fdKgPjUcqIQpArbhxUvvM2q345qVQorLANVQP2xPAxh16zblz64DqXbGKO4LcQo4xK4vuuhrMlKs4m3GGCR3UvPt7IX8cjadzbffb/nLJWbUaAJsOHbB9qiM5a9aSv2cPJRcuUHLhAu8DUb4qnP2ikCMh2StQWZrAo35lPR3CP8iUSiwbNKBgzx4ANDUej4QoW42KEzIvnDiP5GoPmdmUREffNSFKf838JpRcq0VRbP7DJLLEHaDS36wQBEEQBEEQHh0rTlzjzSWRmK7nLclkUM1Gg6eDJZ72ljd9dLO1wObabmRbJ0LKGfNJtl7wxPsYwnqQsHETdYLag+r21Xn/6WxiDuP/PMXZRHNSf7vqrkzpEU41u7KvjPJ2tOKHAfV5bu5hVpxIoKZHGMNbjYNW4yDplLlKVMJR2PAWRP4G3b4B9zo3jaM/vhDXpJ2USEqO1ZvCYKd7b0F3J0/X8eD3w/Esv9KEEda7CC0+BZveg74Lbzww5xr82h0K0riqDGBQ/pu4OjkyvV8dDuzcWqUxhlSz4YvRz/PO0pokp6UzZUArannaVcm12lZ3ZUSrAGbuho4XOlFyxgSUEOSq5Zu+dW973aPJRxm9fTT5+nyqO1bnpyd/wtnSGUmSMKan09unG8uilrElZgvvRryLnUXVxH87lmoF3/StS48fC5iiH8CHqgXm/zOBbcwJUP6tQeuCwWgip0hPVrae7MJMrNTKSmmDKAiCIAiCIAiCIDxcZDIZZVmLVhFDmvmx7Pg11p1O4r0uYbja3FvlmV/2xZBfYqC6mw3tw6pVUpSC8GiTJIk5Z+bw7fFvAegV3IsPmnyA4voiTYVcQY/gHvx48keWRy0XCVH/8MglRN1k+VIAEhu1oe6xH8zbmr9252QogNDOyLZOxLpaIXlxGuQHTtCpYSdWR68mMnctg5sOYt7+GN5ZdooNY1tib3VjIpak15O7bh0A9r17oW3VCtvOnTFkZZGzcSMH539OQEwxobF6iDVPONu7F5hPFhWiqoxVo0bmhCiZDIvQ6g86nPsm09IXis5jsjX/NVQSdfmu5+ji4gBQ+/ggS7sIQKTOAwulnDre93fCXxAEQRAEQfhv+PPYNd76MxJJAnc7DZkFOkoMJpJzi0nOLeZYbNYNx9eUxfCOcjEtFeZEqAKZNdtdBnHZbwDORfa4XMzgWgHklxhwuEtCVInByA/bL/PjzmgMJgl7KxUfdatJ97oeFVpt2CzImQmdw5i09hyfrj9PqJsNLYNdwL02DNsMR+fCtkmQeBxmtYEmo6DNu2BxvTV1TgLS+ncAmKXoxwudOpQ7hvKSyWRMfqYmnb7dw+icgWzUnEV+fg1c3gZB7cwH5afBr89ATjypam96576FpLFjzuBGOFjdn9btDtZqZg5pel+uNa5jKIdjMjkRlw3A8019ebdTGJbqW1f12hG3g7d2v0WJsYSmdnWYYjcUfl1O/OlTFEeewpCWhmVAADWGBXEu/zLrrqxjQNiA+3Iv/1TL0443O4Ty2QaJ1Yp2tPTwIytTT9Y1Pdkbz5BVoCO32HDDOR1rVmPmcw3ve6yCIAiCIAiCIAjCf1e4lx31few5HpfN4kNxvPZkSIXHyi3WM3ffVcBcHepWFZsFQbiRSTIx7eg0FpxbAMCL4S8yut7om+Y7ewT1YEbkDI4kHyE2NxZfW98HEe5D55FOiNJdu4bX+WMA+LdwhLh40FaDBoPvfrJLCDgFoXVPIC9OQ/6u3QwYNJnV0avZGLOR1U+PZcfFVGIzCnlzSSSzn294ww/t/D17MWZloXB2xrpZs9LtSgcHDjex5x2dAb9CO8YmdUe3cQuuRZn4+6aCygpcQiv9uRDMtC1bkPb112hq1EChfXxaBhTZBUIRyKyKkICSy2VPiFL5+kCque3kJcmLhv4OWChv0xJEEARBEARBqDwmI+z4FBJPQPUuUKM7WDs/6Khua8mReN5efgpJkvigRjpDw0zIdPkU5udSkJ9DUX4uusJcDMX5mEoKUOpzCTVGAVAiKfnV2IEfDN3JjrOBuAQg4frISr44tR0XGwv8nazxc7bCz9n6+ufW+DlZczElj/F/RnIpJR+ATrXcmNS9Fi42Fvd0T0Ob+3E2MZdlx6/x6uITrH61Ob5O1uYWeREvQlg32PiOuYXege/h7EroMg1CnkK/YhRqYz4nTEG4dRqHdRW1ofu3IFcbhrUIYMYuiaXyzvQ1roEN42HkAdAXwsIekBFFnoUb3XPGky2355cB9Qly1aLX6+9LjPeTSiFnxqAG/LjjMm2ru9Im1PW2x27YNottq6fzQqKROmlWOKYcJ106dtNxuitXeOlMa17zu8yyqGX0r97/gZT4f7FlADsupHLoaiYrTibe9jgbjRIHKzWO1vf2/0EQBEEQBEEQBEF4PA1u5sfxuJMsOhTHqDZBqCtYjmr+vhjyig0Eu2rpVMutkqMUhEePwWRg4v6JrI42dyYb13Acg2veOtfFzdqN5h7N2ZOwh+VRy3m9wev3M9SH1iOdEHVt7q/IkTjuGkL/HHOlKJqPBZVl2QYI7Yw24XuQQcn584QYnantUptTaadYG7OCHwYMoOdP+9l2IZVZe67wcuvA0lNzVpu/Ke26dEam/PtpNkkmZp2aBUDj2v0ZnRhK0RO1mVX7EppLH4F7I/PkulAlNGFh+P22GGW1x6sEo8IlBJLBUpNBIVB08iS62FjUvrfPDNX/VSHKwx2yYgCIMnkx2F+0yxMEQRAEQahyhhJY/hKcW2n+OnobrH8LAtpArV7mBClL+wcY4I1+OxzHB8tP0F1+kHfsNuF2JRqumPdZX3/cjqFmb1IbjKOm5MLE3GKScopJvv5IyiniSkoOBQYZaXklpOWVcDgm86YxZDKQJHDWqpnUvRadw90r5b5kMhlTetTiclo+kfHZvPTrMZaPavZ3cpONGzw7D+oOhHVvQHYc/NYP3OugSoqkWFLxg/04Zjbyq5R4ympMuyBWn0zgk5zudLXZh3XGZdgzDa7sguTTlGiceTr3LZJw4uOuNWh1mzbwj4pqtho+7l7rtvvTL5/l2MSx+B1LYFjpVnMFZ5WnJ5ra4ViG18ayTm10sXEkvfcenisO4j5cySUucTbjLLWcbz9+VVHIZfw4sD6LD8WhVspxsFJjb6XCwVqNg5UKeys19pYqlIoq6psgCIIgCIIgCIIgPBY61XJnis15UvNK2HAmie51Pcs9Rn6JgTnXq0O9+kSQqA4lCHdxMfMiE/dP5GzGWRQyBZOaT+LpwKfveE6v4F7sSdjDqsureLXeq6jkd664/zh4ZBOiTIWFFK5agQKQ1XVFnrMTrF2gwdCyDxLaGeX+79A4GSlOV5C/axcDGw7kVNopll5cyvBaw/moW03eW3GaLzZdpL6PAxH+jhhzc8nfvh0AW4fL8F09aDYG6j/PtvjtXM6+jLVKy7ZDwRTpjbQMdqa9nbkCDx71K/25EG5kWbfugw7hvtN6hcFpqGabSGJYS0rOnyfuxZfwW7wIpfOtqwzoYq8nRDmqoEAiC1vSsaVpoEiIEgRBEARBqFLFOfD7QIjZA3IVRLwEcfvNlaKit5kfa9UQ9KQ5OSrkqb/btD0Av+27wIX1P7LTYh1esnQoBtRa8G8FFjagtr7+0Jo/qqz+/tw5BKVLCN6A9y3G1uv1rF+/nhZt23MtR0dMRgFX0wuISS/gakYhMekF5BTpkSR4pq4HH3ariaN15bZ906gUzBzUgG7f7+ViSh5vLonkx4H1b5y4C24Pow7BrqnmSlFJkQB8YejD0Kfbo7jPk3xWaiUfdqvJywuP8XFRPz5X/miODTCq7ehbOJ6rJncGNfHh+aaPb/lsQ24uR6a+jfXKnfgYwSSDzJpehLbsimXt2liGh9/0esmyfn1yVqyg8MgRXj/gwfgOqSyLWvZAEqIAnLQWjG4X/ECuLQiCIAiCIAiCIDwe1Eo5Axv78vXWS8zbH1OhhKgFB2LJLtQT4GxN19oeVRClIDwaig3FzIicwbyz8zBKRmxUNnza8lPaeLe567mtvFvhpHEioziD3dd2086nXdUH/JB7ZBOi8tauQ1GQT6K1E0+57QUd5qQktVXZB/GOACsnbNwLKE63JX/Xbtr3+povjn5BWlEaW+O20j/iKQ5fzWDlyURG/3acdWNaoti0CUmnQ+3ngybpT5ABa19DOjyLma52ALiY2nE6VcLNVsM3fesi+32C+Zoe9Sr9uRAEd98QSiQlGrkO7y/eJ/blt9HHxRE/4mV85s+/ZftAXXw8AGqrEgAumjyxVCmp7WV/P0MXBEEQBEF4vOQlw8LekHIa1DbQb6G5KhRARjScXQ5nlkPqObi43vxQWprb6XX+HDR2Fb+2rgCO/mJOYnIOAedgsHIyl1+6lcJMTiz/gg5RC+ivygNAsnJG1mQkNBoGlg4Vj+VfbC1V1LG1oo63/U37sgp0lBhMuNlpKu16/+Zmp2HGoPr0m3WQjWeTeXbmAewtVSjkMpQKGQq5HIUMFPKeeAXUpVnsD8QWWREX/DzNgx5Mm8OONavRJtSFJRebM8xqF6G6s0gqK0byLid1XjQPcmJit5oPpNVbZSqJjiZr0WI0NWtg3aIlqmq3b4n3F8lgIHbhHDK+/wH7fHObwKhgK3zfm0jLpndeaSeTyaj2/gSu9uiJ37FEaobIWa9cz1sN38JKVY75BkEQBEEQBEEQBEH4D+nf2Jvvd0RxIi6bU9eyy/V+YaHOwOw95lLir7QNuu8LxwThv+JQ0iEmHZhEXJ65cEl73/a8G/EuLlZlq+6ukqvoHtSduWfmsuzSMpEQxaOaECVJ5CxeDEBsoDvtdKfBytk8KV8ecgWEPIU24Q/STttSsH8/CoOJPiF9+DHyRxafX0wn/05M6RHO6YQcotMKeO33k3yy83q7vHBb83sHTsFQkMbO/KtctHbBUpKRd74aCrmM6QPq4WQph+TT5mt6igpRQuXzdrYlRnIjVHaNgoJkvGfPInbAQIrPniVhzBi8Z/yETP33SnpJr0efkACASpkBwEWTFw39HSrcF1gQBEEQBOGxYTLCmWXmhKDAdiAv499P6ZdhYQ9z2zVrVxj0J1uz3Di28QIR/o409vfFqtVb0OotSDlnTo46/SdkXYVTv5tfvzzzY8Xj3jAeTiy8cZulg/n1jHMIOAeZP7f1gNN/oj8yl3rGIpBBloUH9u3eRFZvYNlblFcSh0quCHU7DXwdmdy9Fu8sP82x2Kw7HKnmW15HKZexqcuDqRoE5sSdj5+uSfuvMxiW9yILg3czM7cpm5M9CXC25scBDVA9oFZqpqIiEt99j5LLUXh99x0WAQEVGkefmMiFQf1QZ+X/vTHID8c2T6Jt2RKrenVveJ0DkLtnN5cnvY9lfBpWQKKTjIzh3XjmucmolWX7XtKEhuLQrx9ZixczYruC13wK2BSziR7BPSp0H/eDSTIhl4nXcoIgCIIgCIIgCELFuNpo6BLuzsqTiczbH8NXfeqW+dzFh+LILNDh42hF97qiOpTwaCsxlvDO7nc4kXqCCLcImns2p7lnc5wtb79oMqckh2lHp7Hy8koAXK1cmdB4Ak/4PFHu6/cM7sncM3PZl7iP5IJk3KzdKnorVUqSJCSkKp+veiQToiyjo9FFR1OoVNMmwNyqgGajzS0Zyiu0MxYnFqG0AkNhEYWHj/Bsw2eZdXoWJ9NOcjbjLDWdavLToAY8/f1eLkVeoujoUZDJsLM8Zh6j/SQk78bMWPk0GHIZkJPNK8qJXPDuQ7hrE0g9D4ZisLADB//KeyIE4ToLpYIklTehxmtkx5/FvmtnvGfNJPb5wRTs30/ihPfxmPoZsutv1ukTE8FoRKbRoCwx9/ONkrxoEiDa5QmCIAiCINxRyjlY/SokXH8t4OBvbnlXb+CdqzclHINFz0JhBjgGwKDl7E7XMmLhEYwmiZ92RqNWyKnva0/LYBdaBntQs80EFG0nQNQWWNwHTi6C2n0hoHX5476y8+9kqIA2kHkFsuOhKAuuHTY//kUFnDP5cjlkON36j0SmePR70veL8KG6uy2XU/MxmkwYTBImk4TBJGH8x0ejSaKejz2BLg+ulSGAr5M1I1sH8u02E20u9QbAzlLFnCGNsLN6MP9epqIi4keNovDAQQDihr6A76JFqL3KV27fmJPDqef7YJWVT5ID5GsgMAnkl2PIvPwzmT//jMlKg3WTJti1botFUCCxP3wD+49iCeRp4GAnH7qMm047p5By34fLmNHkrl+PW0o2HY/J+bPanw9tQlRqYSoTfx5A585j6BrY7T9fFUwQ/oskScJgMGA0Gh90KJVKr9ejVCopLi5+5O7tYfQwPd8qlQqFQvFAYxAEQRAE4f4b0tyflScTWRuZxHudw3DWWtz1nGK9kRm7zNWhXm0bhPIBLc4ShPuh2FDM2B1j2Z+4H4ANMRvYELMBgDDHMFp4tqC5Z3PquNRBKVciSRKbYjbxv8P/I7M4E4C+oX15rf5raNUVm1f0tfWlkVsjjiQfYcXlFYysM7Jybq6SbYndwi9nfuGDph9Qw6lGlV3nkUyIcti3D4ArPp48q9kHlo7QaHjFBgtsi0ylQetWQPYVa/J37cKtZQs6+nVk3ZV1LD6/mCktphBSzYYpz4Rz5JMvzecFe6OSHwQbDwjuwN6kA5wz5CIzqfDL9EMliyT82m/w3QbwaWI+x6Nu2VePC0I55Vn7Qe4B9CkXAbAMD8fru2+JHzmK3DVrULq4UG38WwDo4q63y/P2hrQLAFwyedFDJEQJgiAIgiDcmqEE9nwJe74Ck548yRJJJsc26ypsehe2fwJ1B5iTo1z+lXxxeSv88TzoC8C9Lgz8k6gCDa8s2o/RJFHH2570vBISsos4eCWTg1cy+WLTReytVDQPdKZFcHWerjME68hfYM1YGHWgfFWadIWw5jXz542GQ5cv/96eGQ3pUeZHRhSmtEvo0q9wvMSbGcZu1G7Vkzc7hj5WCRZ1ve2pe4vWfQ+rkW0CWXEigbjMQpRyGT8NrI+/cwUWC1UCU2Eh8SNHUXjoEHIrK5QuLuhiY4kb9gJ+CxeidClb+W+TTseRIb2wu5ZBphaiJj2H1suXny9sw3DoOLWidNS5KmFXWEzR9p0Ubd9Zeq5BDtsbWeA1+jVebfB8hVehKeztcXntNZI/+og+e0yMrRFJVFYUwQ7BFRqvKi34dTxjfkzg0o4pmJZ2QqF89JMXBeFhotPpSEpKorCw8EGHUukkScLNzY34+PjH6m+BB+Vher5lMhleXl5otQ82+VsQBEEQhPurrrc9dbztiYzPZvGhOMa0u/tr4N8Px5GeX4KnvSU96pdvMZQg/JcUGYoYs30MB5MOYqm05L3G7xGfF8/ehL2cyzjH+czznM88z+zTs7FR2dDEowlFhiL2JuwFIMAugI+afUQ913r3HEvP4J7mhKioFbwU/hIK+cO1mCFfl8/Uw1NJLUple9x2kRBVHvr4a1ifNydw1AsxZ5vS7FWwqOCLM7U1BLRBG7OzNCFKmvAeA6oPYN2VdayOXk1aYRrDwofRo14jPNNOAVDikG4+v/7zSHIFP0X+ZN6e1YQvLHvz5NNGtDsnQupZuLTRfKzHvX9zC8LtGByDIBdU2dGl27QtW+L+yWSS3nmXzLlzUbq44DR0CLq4WABUXu7IcnYBEK/ypbbXHaoaCIIgCIIgPK7ij5irQl1PJN+jiODNgsHkYclzVocYZ7cDddYlODLb/AhsB41fhqAn4fRSWDUKTAYIaAt9F5BpsGDY/H3klRiI8HNkwfAI1Ao5MRmF7IlKY09UOgejM8gu1LPudBLrTifxuaIFB2zXo8m6Crs+hycnlj3+XZ+Z2+7ZekK7f5yntsLkWosLJl/2ZtZhb04GhxMyKNabABjTLpjXnwx+4G/ICXemUSn4ondt3ll+mlfbBtEs6PbluSuLwWQgKT+JHF0OOSXmR15uGt6TFuBwLgGdRsnql6sjc69G769L0MfGEffCMHwX/IrC3v6OY0smE3tGPIvr+QQK1RAz8TlGtH8PgIFhAynuVszRlKPsit9LzJFtuJ5OpG60Cf8UOOUv48rAFox6+hNcrVzv+T7tn+1N9pIlcO4c/XeZWN5wOW9HvH3P41am/bG7CV94CICQGs1FMpQg3Gcmk4mrV6+iUCjw8PBArVY/Ur83TSYT+fn5aLVa5GKRZ5V7WJ5vSZJIS0vj2rVrBAcHi0pRgiAIgvCYGdLMl9f/yOabrZe4mJLHyNaB1PK89fuHxXojP+0yvy85qm0gKlEdSniACvWFJBcmk1uSa56v0uWQXZxdOn+VW5JLri6XWs61GBY+DEtl2RecFhmKGL19NIeSDmGptOSnJ3+iQbUGAIyuN5qMogz2J+5nb8Je9ifuJ7skmy2xWwBQypW8FP4Sw8KHoVaoK+Ven/R5kk/Vn5JUkMShpEM082xWKeNWlh9O/kBqUSreNt4MD69gYaMyeuQSonL++B2ZJJHs4UZb++Po1PaoI166t0FDO2N9dhMyBejj49FdvUrtgNoMqTmEBecWcCDpAAeSDtChIIDh6YnoFUrCvaIxIcdUZyCHkw5wOv00kkmJKbs1P7xYH623PVR/Ao7/CjumQEEa+LeqlOdAEG7Fwj0MYsC+MOaG7fbPPIMhLY20L78idepUlM7O6OPiAFBfXzmeKtkT7Ocr/lARBEEQBEH4J10+bJ0Kh2YAEli7sKzaWN4854+7nSV+VmpmJbVmjbIDq3oYcT03Hy6uh+ht5oedN+SYK3MS/ix0/5ESFLz8y2HiMgvxcbRixnMNsFCa32Tyd7bG39ma55v6oTeaiIzPZk9UOtsupHAmAd4pHsw3fA77v4NavcCt1t3vIfEk7P/e/HmXr0Bjy7WsQvZdTmfv5Qz2X04no0B3wynOWgtebh3A8JYBtx32QOIB7CzsqnR1T3kU6gvZcHUDHloPajnXwkZt86BDuq8aBzixY1yb+3KtXF0uQzcO5VLWpdJtFjqJd5cYcYiHQjVMeVYiyuIUZMKBnhZ8ukgLUVHEvTQCn7lzUWhvX8Fq8/jn8DlwCYMcrrzTm4Hd3rthv0apoYVnC1p4toAm7xCfF8++hH2szDhPS+9WPO/TrtLuVaZQUO39CcQOGEjbSIlP96ygpMFrWCju3jLgfigxlrDru/d4Jh1KtBaEjy9HoqQgCJVCp9NhMpnw9vbGysrqQYdT6UwmEzqdDo1GIxKi7oOH6fl2cXEhJiYGvV4vEqIEQRAE4THTtbYH2y+ksSYykXWnklh3KomWwc6MbBNI0wCnGxYALD12jZTcEtztNPRu4PUAowa9Sc+mmE00dW+Kk+XD0REnNjeW4ynHCXEIIcQhBJVCLGKqKsdTjvPq9lfJ0+Xd9dh9iftYe2UtHzb9kGYed08kKtQXMnr7aA4nH8ZKacVPT/5E/Wr1bzjGydKJboHd6BbYDaPJyLmMc+xN3EtGUQb9q/cn0D6wwvd2Kxqlhm4B3Vh8YTF/Rv35UCVEXci8wOILiwGY0HgCGqWmSq/3SCVEmQoKyF2+AgCPwGTztoiRYHGPk90hTyFXgZVLMQXJGvJ37MQiIIA3G75Jv+r9mH92PsujluO5LwqA09VlRDtYYZkTzMlDBRwp+QEAfXYE7z/V+O/2CnIFNBwK4b0hOw5cH443C4RHk6N3DTgA9sZMKMoGS/vSfU7Dh2NISyPr1wUkvvceKjc3ANQ2EhTCJZMnTUW7PEEQBEEQhFIuuWdQznofcsyJ5NQZQGTNt3jrl/MAfNoznHBPO/rOPEB0WgG9N1mx9OW5VOuYBEd+huML/k6GavoqtJ+MJJPx3tJTHI7JxEajZO6Qhjha33pVkEohp6GfIw39HHmlbRC9ftrPyoS69LdvTuPifbBmDAzbYn7NcTtGA6weDZIRavbktHVT3vhqF1Gp+TccZqVW0NjfkRbBLrQIciakmvaO1S32J+xnxNYRWCmt2NBrA44ax7I/sVXkk4OfsObKmtKv/e38CXcONz9cwgmxF5NOleWLI19wKesSKrkKJ0snXCQtQ5Yk4h2fi85Sxam3u9CtVgg2ahvWX13PEY7wTi+JTxYr4NQprr3yCt6zZiK3uDGpSJIkVn82gpC1xwG4+kpnnh0w+a7xeNt40696vyq5VwCr+vWx6daVvDVr6bMuh+3PbKVTYJe7nmcwGSg03b59lkmnw5STgyRJqFwrVs3q173Tab81AwC3N95AYScq/grCg/Kgk1cEobI9SpXOBEEQBEEoH5VCzvT+9RjVJpCZu6JZcyqJPVHp7IlKp463PSNbB9KhRjUMJokZO83VoV5uHVi64O9B+frY1yw4t4DGbo35uePPDzQWMFcUGr55OMkF5pwGtVxNdafqf89XOYfjbeMt/u6qBIX6QibsnUCeLg8rpRWOGkfsLOywt7DH1sIWO7Uddhbmh0Km4Jezv5CQn8CILSN4OvBp3mr4FvYa+9uO/er2VzmSfARrlTUznpxBXde6d4xHIVcQ7mKek6xKPYN7svjCYnbE7yCjKKNMiYD5+nz0kr7KYjJJJiYfnIxJMtHBtwPNPZtX2bX+8kglROWsWYMpL48SO2vqeESRJ7PGpsXIex/Yphp4NUTrcc6cELVrF07DXgDAU+vJe43f46WwYSR81wkoYmNNIyddnFDZF1Fw4WvUjqeQTApaujzL8019bx7fwgaq1bz3OAXhDnw83EiWHHCTZWFIu4TSJ6J0n0wmo9o772BISyNvw0b08eY351TqXHNClORNk4AH/0aWIAiCIAjCA1eYiWLjezSL/s38tZ0PdPuaEr+2vPndXkwS9KznSdtQcwLDouFN6DPzAHGZhQz8+RB/vNQEp45ToM27cHYFqK3M1ZyAGTujWXb8Ggq5jB8G1CfItWwLO9RKOd/1r0fX7/YwOnsAe6xPYpFwDA7PhiYv3/7EA99D8inQ2BPXeCJDfjlMRoEOhVxGHS87WgQ50yLYhbre9qiVZXsjt1BfyKSDk8yfGwqZd3YebzR4o0znVpUz6WdKk6E8tZ4k5CdwNecqV3Ousjp6NfD3pFNt59p0C+z20FS2+q/ZfW03Ky+vRIaMnzv8TB3rUOJHjKAoOhe5jQ0hc36mTu3apcf3Cu7FissrmHZ0GpP65PLhYuDQIeLGjsF3+vfIVOYkNUmS+GPW64TP3wNAfP9WPP3Klw/iFm+p2ltvkbVlEyGJejYsnkmnD+6cEHXw2n6WzH8X16h0Nm9YRJjaG0VeEcacnNKHVPh3spT7//6HfY9nyhVTbG4s+h/nYV0CJUFeVOs7sCK3JgiCIAiCIAiCIAi3FOZuyzf96vFmh1Bm77nCH0fiiYzP5uWFxwhwsaa+jwMJ2UW42ljQt5H3A431dNppFp1fBMCh5EMcST5CI7dGDzSmX8/+SnJBMjYqG+RyOTklOZxKO8WptFOlx9hZ2FHLuRZ1XerybMizD01lq/+ar499zbX8a7hZu7Hi6RVo1do7Ht89qDvTT0xn8fnFrI5ezZ5rexgfMZ4u/l1uSFAr1BcyatsojqUcK3My1P0U6hhKuHM4p9NPsyZ6DUNqDbntsUaTkUXnFzH9xHTkJjnFl4rpF9YPpbxy04mWRS3jVNoprJRWjG80vlLHvp1HanmSpNMht7HBJrAQmQyOuvUHTSWtgAzthNa9GIDC48cx5t1YTs3i2DnUuUXI7ax50jYHV5OEXlWE2vEAAJripnzdu7XI4hQeGDdbDTF4AJAVe/am/TK5HI+pU7Fq3Lh0m8GQAECs3Ifw2/T/FQRBEARBeKwcmYP81G9IyDA2eglGHYCgJ/l++2Uup+bjrLXgw25/J9O42WlYNLwx7nYaLqfm89ycw+QU6cFCC/WfK02G2ngmiakbLwDwUbcatApxKVdY/s7WTH6mFqk4MLmkr3njtkmQHX/rEzKiYef/AMhrM4nn/rhKRoGOWp62HJ3wJMtHNeeNDqFE+DuWORkKzP3fE/ITsFKa2wL9fuF3MooyynUvlUmSJL448gUATwc+zcZeG9nVdxc/tPuBl+u8THOP5tiqbdGZdJxKO8XC8wvpt7YfE/ZOILUw9YHF/aDok5LAaKzQuTklOXy0/yMAnqvxHHWsQ4h/8UWKjh1DbmODz9w5WP4jGQrMCzN6Bvdk9TOrCW76FFOfVaBTQtHO3Zwa+yKS0YgkSfz6xwTCpm9CDqR2qEf7D2fc451WLpWrK9qXhgLQdGUUcYkXbnlcZmocCz/sQ1HvYby4IJXuB00E7I6mZOtOCg8douTCBQxJSTckQwEkT5xI0ZmbX8PdjiRJ/PzHO7SONP9bBk+aiky0MxIEQRAEQRAEQRCqgLejFZO612LfO0/watsgbDVKrqQV8OexawCMaB2IRvXgXpPqTXomHpiISTKVzlf9cPIHJEl6YDGlFaYx58wcAD5o+gF7+u5hXY91fNbyMwaGDaS2S23UcjU5JTnsS9jHDyd/oOuKrsw9MxedUffA4v4vOpR0iN8v/g7ApGaT7poMBWCtsuadiHdY0HkBQfZBZJVk8e6edxm5bSQJ+eb3zgv0BYzcOpJjKcfQqrTMbD/zoUqG+kvP4J6AORHpdt/zFzMvMnD9QL44+gXFxmIKpUKmHp1Kr9W92HNtT6XFklGUwTfHvgHg1XqvUs26WqWNfSePVEKU4/PP4//D6/gHJJIrWWGKGFF5g4d2QW1jRG1rAIOBgn37btids9q8stg+WMHg/Dw2+A3g/cYTsZDcwGDHlx1fx0YjWjAID45cLiNdY65QVpB4/tbHqNV4fT8d62bN0LZujVJnLmWp9KiJUvFI/bgQBEEQBEGomGajMYV0Zk/I+5g6fAoWWs4m5vDj9RLgk7vXxN7qxjZ33o5WLBzeGGetmnNJuQz55TD5JYbS/WcScnj9j0gABjf15bmmfhUKrWd9L3rU82SR4QkiZdVBXwDrx8G/X+xKEqwZC4ZijH6tGHQkgNiMQrwdLZk7pBEOt2nTByAZjWQuWkTetm1IJtMN+86kn2Hh+YUAfNH6C2o51aLIUMQvZ36p0P1Uhi2xWzieehyNQsPoeqMBcNQ40sqrFa/UfYUZ7Wewt99e1vVYx/9a/o+Ofh2RkFgdvZquK7oyI3IGRYaiKolt97XdTD8xnRVRKziecpz0ovQHOhmXv2cvsR2fwmvOHCR9+Utjf3b4M9KK0vCz9eOVoCHEDxtO0YkTyG1t8Zk7F8vw25cBd7Z0ZlrraYwa8j1z+jthkIN6+yHWjOzKT2s+IOyzFagNkN0wiFZf/fpQLjTyG/4KWa6W2BfA2S8/umFf8cVLHHp9KHHtOtJgyWncskFnrSa2YQjbOrgwp4Ocb5+WM2uIG2nT3yJg8yZCDh+i+tkzaNu2RdLpSBgzBkNWVpli2XRlA40Wn0QOKDu1w7p+/Uq/X0EQhPKQyWSsXLkSgJiYGGQyGSdPnnygMQmCIAiCIAiVy1lrwbiOoex75wne61wddzsN1d1sGBDh80DjmndmHlFZUdhb2DO/03xUchXHUo5xOPnwA4tp+onpFBmKqO1Sm6f8nkImk+Fj60OXgC68E/EOizov4uCAg/ze5XcmNJ5AmGMY+fp8vj72NU+vfJrNMZurZA7JaDKy8NxCZp2axcaYjZzLOEe+Lr/Sr3O/FOgL+HDfhwD0CelDU4+m5Tq/jksdlnRdwuh6o1HL1exL2EePVT2Yd2YeI7eO5HjqcWxUNsxqP4s6LnWq4hbuWSf/TlgqLYnJjeFE6okb9hUbivnm2Df0XduXsxlnsVHZMCFiAt0su2FvYc+VnCuM2jaKl7e8zOWsy/ccy1fHviJXl0t1x+r0r97/nscrq0crw8FkQnboW+RKiV+MT1E/xK/yxnYJBceA0ipR+Tt3le4y5uWRv207ALaO0SCTo24whL7Ve3Nk8GaODd5N64CQyotFECqoyDbA/El61G2PUVxfve39zWdodeZV8V7Bde9DdIIgCIIgCP8BKg3GZ38lyzoYAL3RxPg/T2E0SXSq5UancPdbnhboomXBsMbYWao4EZfN8PlHyE9KITE6nmHzj1CkN9IqxIUPut5bq7bJz9TCx0nLm8UvYEAJlzbCuZU3HnRiAcTsQVJa8q5uGJEJuThYqZg/NAJXG80dx89esoSUyZ9w7ZVXudqjJ7kbNyGZTObVdvvNq+06+3emlVcrRtY1ty//4+IfpBel39N9VUSJsYSvjn0FwNBaQ3GzdrvlcX9NOnUN6Mq01tNY1HkRdVzqUGQo4oeTP9BtRTfWXlmLSTLd8vyKOJlygtPjRhHw2o9Efv4+4397nrZL2tJkcROeXfMsb+x8g2+OfcPyqOWcTS97ZaCKkoxGUj+fCpKEVfQV0r/6ulznb4vbxtora5HL5HzS4H1SR46hKDISuZ0dPr/MxTK8VpnGaePdhk/f2sjxl1tiAoJ3x9B0wjJsiqEgyIPGs/5ApqzcUt2VRaZWYxgzGADvDZEUXDxP7ubNXBrYj6vdu2O74SAWekhyU6N/azjVd+yh5NkXGP7FZpqNnsyFBi5sdU/nlcSvGXn+I6IMicgUCjymfobKxwd9YiKJ495CuksFr3xdPrt/nkRwEhg0Kvze/fB+3L4gCI8QmUx2x8eQIUPuaXxvb2+SkpKoVevG3w3z588nIiICa2trbGxsaNWqFWvXrr3tOKGhoajVahISEm57TJs2bZgx4++qgsuWLaNNmzbY2dmh1WqpXbs2kyZNIjMzE4B58+bdcK9arZYGDRqwfPnye7pnQRAEQRCEx4mNRsVLrQI58G47Nr7WCkv1g6sOdTXnKjMizX8Pvh3xNtUdq9M7pDcAP5788YEsTDufcZ6Vl1cCML7R+Nsu+lIpVNR0rkm/6v34vevvfNL8E1wtXUnIT+DNXW8yZOMQzmZU7pzR7NOzmXpkKtNPTOetXW/Rd21fmv7WlNZ/tOa59c8xYe8EZkbOZMPVDSTlJ1XqtavCtKPTSCxIxFPryRsN36jQGCqFipdqv8SfT/9Jg2oNKDIU8eWxLzmRegIbtQ2zO8wm3OX2iwAfNGuVNZ38OwHmKlF/OZR0iF6rezHnzByMkpH2vu1Z9cwqegX1orFFY1Z1W8XgGoNRypXsS9xH7zW9+eTgJ2QWZ1YojqPJR1kdvRoZMt5v8n6lt+K7k0crIeriOlQZ58mTLNnj2PuOK5vLTSaD0M5oPa4nRO3eXboiOm/TJiSdDrWbDRoHPYQ8BbYe10+TlavFhCBUKWdzYp5d9jkwlNzxUGOKuYpUouRYucmFgiAIgiAIj5BZu69wNjEXeysVH3evecdjw9xt+fWFCLQWSs5cuMbFzt1I6vkMutQ0gl21fD+g3j1X5dRaKJnevx4xMm++Nzxt3rh+PBRdryyTlwyb3zdvdh7KkisqNCo5c4Y0IsDlziWjJb2e9NmzzV8oFJRcvEjCa69xtfszrJ31LlGZF7G3sOftiLcBaOnZktrOtSk2FjP3zNx7uq+KWHx+MQn5CbhaujKk5pDbHicZDBRfuEDWkiUkT/mU4GQZCzot4PNWn+Nu7U5KYQrv7nmX59Y/x8nUk/ccV05JDku/e5UnThoJSIG+e0xMn2Hkk/lGWh3MJzH+PFtitzDnzBwm7p9Iv3X9Km0l1m1jWrmSkqjLyCzNCXE5CxeSs3Zdmc7NKs5i0oFJAAyt/jyOn86j6ORJ5HZ2+P4yF8uad/5/8W9atZbBY2ZhHP8iABo9lFRzoO78JcitrMo11v3WtMcoIkPVKEwQ26M3CWPGYjwWiVEGh6rLOTmxNy22HqH2sDeRW1oCoJAr6Bnck3U91/Fi+Iuo5WqOJB+hz5o+fLjvQzKVJXhN/w6ZRkPBvn2kTZ9+xxhm7P+KbptyAHB95RVUrq5Vft+CIDxakpKSSh/ffPMNtra2N2z79ttv72l8hUKBm5sbyn8kuI4bN44RI0bQp08fIiMjOXz4MC1btqR79+58//33N42xd+9eiouLefbZZ5k3b94tr5OZmcn+/fvp1q0bABMmTKBv3740atSIDRs2cObMGb788ksiIyNZsGBB6Xn/vN8TJ07QsWNH+vTpw8WLF+/pvgVBEARBEIT7yySZ+Gj/R+hMOpp7NqeLfxcAhocPRy1Xczz1OAeTDt7XmCRJYtrRaUhIdPLrVOaqQnKZnO5B3VnTYw0v13kZjULD8dTj9F/bnwl7J5BamHrPsR1JPsJPkT8B0MarDXVd6uKocQQgsziTk2knWR29mu9Pfs/43ePpvLwzUw9PJack556vXRX2J+znz0t/AuZWedYq63saz9/On7kd5zKx6URsVDbYW9gzu8NsajqXb97rQfirbd7mmM1cy7vGB/s+YPjm4cTlxeFq5cq3bb/lqzZf4WLlUnqOjdqGcY3Gsar7Ktr5tMMoGfnj4h90Xd6VeWfmlat1o96o55ODnwDQK6TXfa+m9Whl6sSbS9vNM3YkLKAKyu+FdsbKRYdcJWHMzKT49GkAclaZ2+XZeWYikwENhlb+tQWhElj4NCRPssRBnwzLXwTT7VcXJ182l827gg81PWzvV4iCIAiCIAj/GZdT8/l2q7ny5odda9y1uhJAHW975g5pRO+YvVgV5WFVUsgL0duYM7gRtpXUYru2lz3jnwrlR0N3oiUPKEiFLRPNOzeMh+IcUqzDGBPTFLkMpvevT30fh7uOm7N6NYbEJBQuzgTt2I7zqFHItVpKoqKo/s06pv1sZFJhBxxUdoB5cciouqMAWHJxCWmFaZVyf2WRUZTBrFOzABhTfwxWKnMijSRJ6BMSyN24kZSpnxMzaBAXG0Vw9ZkeJH84kawFC4h/8SUMiYl08u/E6mdWM6beGKyUVpxKP8VzG57jrV1vkVyQXKG4JEni041v032deTWVVddOWDdrBnI5IYkSL2wxMft7idkbfHgrPYLWjhGVthLrdkxFRaR9Z06yMQztTUqb5gAkffABxZcu3fX8/x36H5nFmQTaBtB7bTb5O3cis7DA+6ef0NSoeMWz2i+8QbVPJmPRugU15i9G6eRU4bHuF5VCRfZLPdApQGYykWsJy5vJmPFBHVrNX0P//pNRK2+9cMtaZc2Y+mNY02MNnfw6ISGx4vIKuqzowq8lu3D+2FzpKWPGTPK2bbvlGOcyziHN/QP7QjB6VcN1sJibEISHkSRJFOoM9/1R1tXvbm5upQ87OztkMhlubm5Uq1aNFi1aMPuv5Ojrzp07h1KpJDra3D44KiqKVq1aodFoqFGjBlu2bLnh+H+3zDt48CBffvklX3zxBePGjSMoKIiwsDCmTJnCa6+9xhtvvEF8fPwNY8yZM4cBAwbw3HPPMXfu3Fve27p166hTpw6enp4cPnyYTz/9tPQ6zZo1w8/Pj/bt27Ns2TIGDx5cet5f9+vm5kZwcDCffPIJcrmcU6dOlen5EwRBEARBEB4Of176k+Opx7FUWvJhkw9LKzG5WrnSJ7QPcP+rRO2I38Hh5MNYKCx4rcFr5T7fSmXFK3VfYU2PNXQJ6IKExOro1XRd0ZWfIn+ixHjnYhi3k1mcydu738YkmXg68Gmmt5vOgs4L2NV3F/v77+ePrn/wResvGFNvDN0Du1PTqSYGycDC8wvpsqILi84vQm/SV+jad6M36YkzxJVr/DxdHh/uN8+jDKg+gAj3iEqJRS6T0zukN9v6bGNjr43UdHr4k6EAajvXJsg+iGJjMd1WdiutUNY3tC+ruq/iCZ8nbnuuj60P37T9hrkd5xLmGEaePo8vj33JM6ueYVvstjL9/5l/bj7ROdE4ahx5rf5rlXRXZfdw1pqvqA6TGRnpz/4Ma6b43X1Cv9y8GyOzdsDarZi8eEvyd+1C6exM4ZEjIAM7jwyw84agdpV/bUGoBD5enrysf41fVJ+jPrcK04a3kXf+wlwB7V+yYiLxBArsgu+5UoEgCIIgCMKjxiTBeyvPojOaaBPqQo96nmU+t4GzCuvY/aVft4s+SLWcFHDyr7T4hrcIYO/lDN6JGs5Si0lwfD5o7ODcKkwyBUMzn8OIginP1KJ9jWp3HU8yGEifaU4wchr6AipXV1zGjMb++UHMm/gs9XYm4J0OfL6YK8sO4fzyy9h27kQzj2bUcalDZFokc8/MLa0eVdV+ivyJfH0+YY5hdAvsRsmVK6R9/TWFJ05iTL+5fZ9cq0UTXgtDahq66GiujRmL7+JFaCw0vFj7RXoE92D6iemsiFrBxpiNHEk+wpyOcwi0DyxXXIsvLCZo/m5sikEK8sPnf1ORqVQY0tLI3bCBnDVrKT59GruTV2h08goRGg1j2jRjXmsja3L38cfFP1h/ZT0v1X6JAWEDUCvuvSpy5oKFGFJS0LvYM8T6N1RNLPk+OxDtyWgSRo/B78+lKGxsbnnu5pjNbIjZgEKmYEpMQ/KWLAaZDI9pX2BVv949x+bYuzeOvXvf8zj3U8cWg3lz4J845klcDLNhdOM3eDekN3JZ2V5TeWg9+Lz15wwIG8AXR77gVPoppp+Yzp/W7kx6uiV2q/eQ+PY7+P+5FLWfX+l5RpORn1ZO4KWj5krWfhMnI1NXYtVsQRAqTZHeSI0PN933656b1BErdcWngmUyGS+88AK//PIL48aNK92+aNEiWrZsSWBgICaTiZ49e+Ls7MzBgwfJzc3ltddeu+O4v/32G1qtlhEjRty078033+Srr75i2bJlpePk5eWxdOlSDh06RPXq1SkoKGDnzp20bdv2hnNXr15N9+7dS2PUarWMGjXqljHY29vfcrvRaOTXX38FoH79+ne8D0EQBEEQBOHhkVKQwtfHvgZgbP2xeGg9btj/Qq0XWHppKSfTTnIg8QDNPJtVeUx6o56vjn0FwPM1nr8ppvJws3bjs5afMbD6QD4/8jkn007y48kfOZp8lOlPTC9dGFgWJsnEe3vfI60oDX87fyY0nnDDfhu1DTWcalDD6cZFb/sT9vPF0S+4nH2Zzw5/xh8X/2Bcw3G09Gx52zaAFfH+/vfZkr+FnRt3Mqn5pDJVZPriyBekFKbgbePN2PpjKy2Wv1gqLSt9zKokk8noFdyLqUemYjAZCLAL4KNmH1HPtexzd43cGvFbl99YHb2a7058R3xePK/tfI2G1RoyvtF4wpzCbnleQn4CMyNnAvBmwzexs7CrlHsqj0cqyyGzQMeGjGrkoKVRVSREKZQQ8hRa9+tt83buImeNuZe9lbcFKmsT1B8M8gfXC1UQ7qS2px02Ye15Qz8KkyRDfmQ2mZv+d8tj5enmUuAWnrXuZ4iCIAiCIAj/CbuTZZyIz0FroeTTHuHleqGftWgx8oJ8ZL5+yJu1QGYykvb11xWOZdqRabT4vQXHU46XbpPLZXz5bB2uWtdmseH6Kp/93wEwU9+Fc5IfY54IYmBj3zJdI3fDBvRxcSjs7XHo17d0+4qULXxXP4VxY7RYjBiM3NYWXXQ0iW+9xeX27Un76mtetTO37ltycUmllPC+m8tZl1l6aSkA4xuNx5iSStzQF8jbstWcDKVUoqlZE/v+/XD/3/8IWLeWkMOH8P3lF3xmzURhb0/x2bMkT5pUusrJ2dKZj5t9zJJuSwhxCCGjOIMXNr1QrjZ2Z9PPsvW3qbQ4JyHJZfj/7wtkKnNVMKWLC47PP4//0iUEbFiP8yuvoPL1QSouxrhxO0M+O8l8zcgKr8S6HUNWFhnXK33Mb65Dr5RRKCtmbOsYch0s0MXGkvj2O6Xt4v8poyijtNz1e9ktkM9cDEC1CROwbd++wjH91/nb+dO9+1v4de/Pst6r6RPap8zJUP9U17UuCzov4LOWn+Fm7UZSQRIvV99PnL81pvx8ro0eg6mwsPT4Py8upcXSiyhNoG7dHG3LlpV5W4IgCAAMHTqUixcvcviwuUq/Xq9nyZIlDBkyBICtW7dy/vx5FixYQN26dWnVqhWffvrpHce8dOkSgYGBqG+RxOnh4YGdnR2X/lGx8Pfffyc4OJiaNWuiUCjo168fc+bMueG8kpISNm3aVJoQFRUVRUBAACrV3atx5uTkoNVq0Wq1qNVqRo4cyaxZswgMLF8StCAIgiAIwuOsUF/IwHUD6bW6131vqSZJElMOTSFfn09t59r0C+130zEuVi6lVaJ+iPzhvlSJ+v3i78TmxuKkcWJY+LBKGTPcJZxfO/3K560+x1plzeHkw7y6/VUK9YV3P/m6eWfnsS9hHxYKC6a1nlbmZKpmns1Y2m0pHzT5AAcLB67mXOWVba/w8taXicqKqugt3WBb3Da2xJkrzl7KvsSA9QP4/Mjnd7y/3dd2s+LyCmTImNx8crmSwx5lPYN70jukN2Prj2Vpt6XlSob6i0KuoEdwD9b1WMdLtV/CQmHB0ZSj9F3blw/2fXDL7gCfHfqMYmMxDas1pFtAt8q4lXJ7pCpEHb6aAYC7pYSjdRWthAzthNbjDwCKz53DkGluV2DnlgwyBdQbVDXXFYRKIJfL+GlQfZYcdWHq2jzeZR6OB6eyL8eCps++gVxufiPPYDRRregKyMA7VKyAEwRBEARB+Ke4zELWxZkTHN7tXB0P+7KvCjIVFpI5bx4A7q+MRBMWxpXu+8nbsoXCEyewqle+F6Pb47Yz/9x8AN7a/RZ/dvsTB415cYiLjQVf9qnL6Ln9eVJxHFdZNjGSG98YevJsAy9ebx9SpmtIJhPpM8wreRyHDEFuZZ5I+Odqu+FNxxJQYxDG4a+QtWgRmb/Mw5CYRMbs2djNhukelmwNKWax07e81nlKue6xvKYdm4ZJMvGkz5PUsw4ldsBADCkpqAMDcZ88GU2NMOSaW7c3VHl64vnVl8QNf5GcZcuxrFMHhz59SvdXd6zOnA5zeGnLS5zPPM+wzcP4ucPPBDsE3zGmPF0eEza/wZsbzOW9nYYMwTL81gsPLPz9cRn9Ks6vvkLxqVMkT5pM8dmzWE6cztc9e3CkX0++vTCzzCux7iRjxkxMeXlkeNmwpXohYY418Cn0YadiJ592L2bSAsjfvp20GTNw/UdVjb8mF7NKsuiY7kH4L7sAcBz2Ao6DBpY7jkfN4JqD735QGchlcroEdOEJnyf49eyvzDkzh0+6FjJ1LjhERXHlnXEEfvsDGcUZ7P5tGq/GSJhUCrwnfFgp1xcEoWpYqhScm9TxgVz3Xrm7u9OlSxfmzp1LREQEa9eupaSkhGeffRaA8+fP4+Pjg5eXV+k5TZs2vadrSpJ0Q7LUnDlzGDTo7/nXQYMG0apVK7Kzs0srPW3fvh0nJyfCw8NLxyhr8rqNjQ3Hj5uTzAsLC9m6dSsjRozAycmJbt0ezAS+IAiCIAjCf82XR7/kVLq55fDE/RP5us3XlVo16E62xG5hR/wOlHIlHzX7CMVtCpm8UOsFll5cyqm0U+xL3EcLzxZVFlNOSQ4zImcAMLreaKxV1pU2tkwmo5N/J9yt3Xl568scST7CqG2j+LHdj3dNBjqZepLvjpsXUL4T8Q4hDmWbK/yLUq6kT2gfOvl3Yvap2Sw8v5D9ifvpvaY3vYN780q9V3DUOFbovnJ1uUw5aJ5DbKxujKO7IxtiN7Dg3AK2xW7jg6Yf3PRvllOSw8f7PwZgUI1BNKjWoELXfhRZqayY2HRipY01ut5oegf35pvj37D+6npWXl7JpphNDKs1jME1B6NRatget52d13ailCl5v8n79+1nwL89UhWiDl4xJycF2VZhFmdgO5TWKjSOOgAMycnIVHJsvIshtBPYulfdtQWhEshkMvo28uG51/7HKq15dX+Tc5P56vtviM80Z9ReuBKDk8ycse1X/d5bXQiCIAiCIDwqJEliwsqz6EwyGvs70L+RT7nOz/r9D4zZ2ah8fLDt3BmL4GDsejwDQOq0L8u1Ii29KJ2P9n8EgEquIrUwlff3vY9J+ruaT+sQF/q1Cmes/hUOmaozRvcKTUM9+bRn2ata5W3egi46GrmtLQ7Xk13+udou3Dmc/tX7A6CwscH55ZcJ2rUTz2++RvtkO1CpqJZYxMCdJjq+sZyoAf1Kn4fKtjdhL/sS9qGUK3mt9qtcGz2GkqgoFC7O+MyaiVX9erdNhvqLdbNmuFxvy5My+ROKTp26Yb+9xp7ZHWYT5hhGZnEmwzYN41LWpVuMZCZJEh8f+JhW6+JxzgOFlycuo0ff9V5kMhmWderg99tinF56CWQycpevoNa4X1ge+NlNK7FWXl551zH/SXctgazF5qpOM5oXIJcr+bDxh7TUtOSPzn/gUq8JczqapwzSpk/n7PpFpedujNnIltgt+KfJGbY4HQwGbDt3xvXNN8sVg1A2lkpLRtQZwdoea2lTtwdf91BgkIN+8w5WfTqcaXs/pc+mAgCcXxiG2qd8P5cEQbi/ZDIZVmrlfX9U1uTz8OHD+f333ykqKmLevHn06NEDq+vJ0rf6O+Zu1w0ODiY6OhqdTnfTvsTERHJzcwkJMb8xc+7cOQ4dOsT48eNRKpUolUqaNGlCUVERv/32W+l5/2yXBxASEkJ0dDR6vf6u9yeXywkKCiIoKIjatWvzxhtv0LZtW6ZOnXrXcwVBEARBEATYGb+TJZeWAOaEmW1x2/jtwm93PqmS5JTk8Okhc4XS4eHD77iAzdnSmb6h5vdJfzz5Y5VWifop8idydbmEOITwTNAzVXKNuq51mdV+FlqVlmMpxxi5deQdKynllOQwfvd4jJKRTn6d6BXcq8LXtlHb8EbDN1jVfRXtfdtjkkwsubSE7iu7cyX7SoXG/ObYN6QVpeFj48NTlk8xpfkUfmz3Ix7WHiQWJDJy60je3v02mcWZped8fuRzUotS8bP1Y3S9u8+9CffGXevO1FZTWdh5IbVdalNkKOL7k9/TbWU3Vl5eyWeHPwPMCwcD7R9cxd1HKiHq9SdDmDGwLk2q3VzOv9JYaCGgNVqP4tJNNl46FCoJGgytuusKQiXzcrCi2+szuOzZHYVM4tWMKbz7zSwWH4oj+uxRANKU7ig0Ng84UkEQBEEQhIfHb4fjOXg1C5VcYsozNUsrbJaFqbiYjLlzAXB+6UVkSnPBXpfRo5FZWFB07Bj5O3aUaSxJknh/3/tklWRR3bE6CzotQC1Xs/vabn49++sNx47rEEqBRzP66j5E8qjPDwPqo1KU7aWgJEmkzzCvYHN87jkUWi0AW+O2mlfbyW692k6u0WD71FN4f/89IXv34Pbxx8QG2WACDMcjSf7oIy61bEXihAlIBkOZYrkbg8nAtCPTABgYOgDlZzMpPHgQuZUVPjNnovL0LPNYTi8Ox6b9k0h6PdfGvlZaGfgvdhZ2zO4wmxpONcgqyWLYpmFczLx4y7GWXlrK1b0b6XjMPLHmOWkScsuyVxWTqdW4vvE6PvPnoXR3Rx8XR/Lzw+h3QMHqrivp4NsBCXPS1bGUY2UeN+3bb5H0ei4EqIn0lzG01lBCHUIB8LHxYXaH2Twxagq76lsgl6Bgwid8v/5D4nPjmXJoCk65EpOWq6CgEKtGjXD/7H/I5I/UFMNDx9XKlcnNJ/PxyCXs7G5udxm0cD+h32/ENQckVydcRox4wFEKgvCo69y5M9bW1vz0009s3LiRgQP/rgxYo0YN4uLiSExMLN124MCBO47Xv39/8vPzmTlz5k37pk2bhkajoW9f8xtVc+bMoVWrVkRGRnLy5MnSx/jx40vb5kmSxJo1a3j66adLxxkwYAD5+fn8+OOPt4wh+y5J2gqFgqKiojseIwiCIAiCIJgX703cb65CM7jGYMY1HAfAtKPTOJdxrsqv/9Wxr8gozsDfzp8Xw1+86/FDaw3FUmnJ6fTT7EnYUyUxXc25yh8XzN2nxjUcd9uKVZWhtkttZrWfhY3KhuOpxxm5dSQF+oKbjvtrXjGpIAkfGx8+bPphpSyg8Lb15qs2X/FLx18Isg8iuySb0dtHl7tt4pHkIyy9tBSADyI+QCUzt75u6dWSFd1XMChsEHKZnPVX1/P0yqdZdXkVO+J2sDp6NXKZnMnNJ2OpLPvcm3Bv6rjUYWGnhXze6nPcrd1JLkjmg30fkFSQhIe1ByPqPNi5qkdqttLOSkW76q54VV6VuVsL7YTWo+Tv63rngL0PBD5RxRcWhMolV8gJemEuhX5PopHp+UE2lV9WbuDksf0AFNnfufWHIAiCIAjC46aOtx01PWzo4m3C17F8Peiz/1yGMT0dpYc7dv94k07l5obj888DkPrlV2VKEPrtwm/sS9iHhcKCz1p+Rk3nmrwd8TYA3x7/lsi0yNJj1Uo584ZGMKVHLRYMi8Daouyd0/N37KDkwgXkVlY4PmduT/PP1XbDwofdtZy2ws4Oh759cJz9Pa+8omDxE0oUoUGg15OzbDlZiytnleCyS8uIzonG3sKevruM5K5ZAwoFnt9+i6ZGjXKNJZPJcP/f/1D7+WFISiLhjTdv+nf5KymqllMtskuyGbZ5GBcyL9xwzMXMi3y5/zNeXm9EDtj16IF1s2YVuj/riAgCVq3EtnNnMBpJ/246ulFvMyVwLB18O2AwGXh9x+sk5Cfcdazic+fMzw/wSysjvnZ+jKh94+SETCbjmaBn6P3TBtL87LEpAv+pS+m5tCv6nGw++lOJRWYB6qBAvL6fjlxdRW3rhZvUcKrBK1PWU9i2IQoJmlw0J9t5vfNeaUtLQRCEqqJQKBgyZAjvvvsuQUFBRERElO578sknCQ0N5fnnnycyMpI9e/YwYcKEO47XtGlTxo4dy1tvvcWXX35JdHQ0Fy5c4P333+e7775j9uzZODk5odfrWbBgAf3796dWrVo3PIYPH86xY8eIjIzk2LFjFBQU0KpVq9JrNG7cmPHjx/Pmm28yfvx4Dhw4QGxsLNu2bePZZ59l/vz5pcdKkkRycjLJyclcvXqVWbNmsWnTphsqTgmCIAiCIAg3kySJD/d9SGZxJiEOIYypP4YB1QfQ1rstepOecbvGka/Lr7LrH0o6xPKo5ciQ8XGzj1Er7j5P4WTpRL/QfkDVVYn66uhXGCQDrb1a09Tj3tpJl0W4SzizO8zGRm1Oinp5y8s3Pe+Lzi9iZ/xOVHIVX7T+Aq1aW6kxNHRryJyOc/Cw9iAuL443d76J3nT3aq0AJcYSPj5gbnvXO6T3TW3vrFRWvB3xNos6LyLEIYSckhze3/c+r+98HTAn4tV1rVup9yPc3V+tG1c/s5ox9cZgqbREhoz3Gr/3wJPTHqmEqPsmpBMaBz1azyKsfRRYu5VA/cEgVsMK/0UKJVYDFiB5RWAnK2SB+jOaYW4LYulZ8wEHJwiCIAiC8HCp6WHHny81prV7+SZITDodGT//DIDziy9iVMqZfGAy7+99n1xdLk4vDkdhZ4cuOprsFSvuOFZ0djRfHfsKgDcavFFacvjZkGfp6NcRg2Rg/K7xN6y+crRWM7CxL/ZWZU9akSSJ9J/M1aEcBg5EYW8PmFfbpRel42/nz0u1XyrzeBHuEfgHN2JlY1jybmOqffA+YK5UpE9JLfM4t5Kry+WHkz8A8EFSBPlzzG9suk+ahLZliwqNqdBq8fp+OjIrKwoPHiTt229vOsZWbcvMDjMJdw4npySHYZuGla54LNQXMm7XOLrsK8YrAxROTlR7e3wF7/B6TLa2eHw5DY/PpyLXaik6fpzYZ3ryTmYTwhyqk1WSxavbXr3l6r9/Sp32JQB7a8i46i5jYtOJaJS3biXobOdO07nLMNlpCUiBYRv0vLVcolpKCUoXF3xmzUJhZ3dP9yWUn1wup96XM1GHmBexWDZqhE2nTg84KkEQHhfDhg1Dp9MxdOiN1fLlcjkrVqygpKSEiIgIhg8fzpQpU+463jfffMOPP/7Ib7/9Rq1atQgLC+OLL75g+/btDBpkTshevXo1GRkZ9OjR46bzg4ODCQ8PZ86cOaxatYouXbqgVN6YAD516lQWL17MoUOH6NixIzVr1uSNN96gdu3aDB48uPS43Nxc3N3dcXd3JywsjC+//JJJkybdNbFLEARBEAThUZCUn8SoraOYc3pOuZOD/rj4B3sS9qCWq5nacipqhRqZTMbk5pNxt3YnPi+ejw98XCVJR0WGotIkmr6hfannWq/M5w6pNQRLpSVnM86y69quSo3rYNJBdl7biVKm5M2Gb1bq2HdS07kmszvMxlZty8m0k4zYOoI8XR4AZ9PP8uUx87zQuIbjqOFUvkWEZeWocWR6u+lYKa04lHyIqYfL1oJ6ZuRMYnNjcbF04fUGr9/2uFrOtfi96++MrT8WC4UFRsmIv50/r9R7pbJuQagAjVLDi7VfZFOvTazovoLW3q0fdEgiIapCbN2RedbHu2UWPs3iza0u6j33oKMShIpTWyEb8Ac4h+Imy6S9wtxqw8m/7oONSxAEQRAE4SGkVMgpR6c8AHJWrsSQnIzSxQW7nj2ZETmDJZeWsCp6FYPWDyJRloPTyJcBSJ/+PabbtGXRGXW8vfttSowltPBsQf/q/Uv3yWQyPmr6Ed423iQWJDJx/8R7mmQq2LuP4tOnkWk0OA4xv1F4OOkwy6OWA/DR/9m77+ioijaO498t6Z2WUAKBJPTeaygCKghIVREUUF8sqIiIBRFQsCAgoqKoIEpTFFBEBQGp0jvSW2gJHdLLJrvvHwuRGAjpBX6fc/bs3Xvnzjx3Epjs7nNnmozK0N12N3q29rMAzD88n/hOrXCuVRNrTAzn3n8vy3ECfL37a64kXKHDmeL4f7UEgGLPD8K7e7ds1esUFESpd+1f5F766msi//wzTRlPR0+mtptKzWI1iUyM5Kk/n2Lvpb2M3TSWpKPH6brB/jPwe3N4SlJZdhgMBrw6d6b8zz/jUrcu1pgYLr7xFu/+5klQog9Hrh7htTWvkWxNvun50X//Tcz69SSZYG5LIz0q9qCBX4N023QoVYqASZPBaKTlPzaqnbBidHPD/8upOJQqle1rkqwxurpS9ssvKfq//1H6w3E5Mr29iMiN+vXrd9Pl5MLDwzGbzfTtm/bz0IoVK7J27VoSEhI4ePAg9957LzabjQcffBCAgIAAbDYbtWvXTnXegAED2Lp1K3FxcRw/fhw/Pz+mTJlCcrJ9POvevTvJycn4+vreNNbdu3czefJkfvnll1TL5d2oV69erF69msjISKKjo9m1axcjRozA+9r43K9fP2w2W8ojPj6egwcP8sYbb2Ay5d7SJiIiIiIFgcVqYeiaoaw9s5ZJ2yelfP6UEceuHmP81vEADKk/hCCfoJRjXk5efNjyQ8wGM0tClzD/8Pwcj/3zXZ9zKuoUvq6+vFj3xUydW8S5SMrnazk5S1SyNZkPt3wIQK9KvSjvVT5H6s2oakX/TYrafWE3Ty97mvDocIauHkqSNYl7yt6T6nPF3FDRpyLvt3gfAwZ+OPgD3x/4Pt3yBy8f5Jt/vgFgeOPheDp6plvewejAkzWeZH7n+Txd62k+u+cznExOORa/ZJ2Ps0/KTbz5TQlRWVW5w7/blTqAx83fjIsUGq5FoO8C8Pj3Cw2jb5V8DEhERETkzmCzWLj05VcAFH3yCTZf3sGXu78E7B8KHY84zqO/PcrJtlVxKF2apPPnufztdzet65Mdn3DwykF8nHx4p9k7aRIg3B3d7R8yGc2sOLmCuQeythydfXaozwHweeghzEWLEpcUx6gNowD73XZ1fetmut4Gfg1o6NeQJGsSX++dRsmRI8FoJOqPJUSv+ztLsZ6KOsWs/bMIDLPx+A8XwWrFq0d3ij37bJbq+y/P++6jyLUZMMJff4OEY8fSlPFw9GBqu6nUKl6LyMRI+v3Rj18P/8LTf1gxJ4N769Z43HdfjsRznWOZ0pT77luKv/gCODhgWb2esZ9H02G7gdWnVjJ5x+Q059isVs5PsN8FuLSOAUqWSPduuxu5NWlC8ZcG21+YzZSe/DHOVfR+Ib85+PlRYshLOPj55XcoInIXSEhI4MiRI4wYMYJevXrdMjkpuwICAli1ahWVK1dm586dGT4vMTGR7t27c79mzBMRERHJtE92fMLuC7txNbtiNpj5I/QPBiwdwMW4i+meZ0m28Nra10hITqBZqWY3TbKpVbwWL9R9AYD3N7/PoSuHcizufZf28d1e++doIxqPyNLyb/2q9cPV7Mr+y/tZeWpljsT185GfOXTlEB6OHjxT65kcqTOzqhatytftv8bLyYvdF3fT+efOnI4+TWn30oxuOjpPbqxqXbZ1SpLa+5vfZ0PYhpuWS7ImMXL9SJJsSbQr1457yt6T4TbKeZbjudrP4e/hnyMxy51FCVFZVemGhKj6/W9dTqQw8SpjT4py8QF3XyhWKb8jEhERESn0In77Dcvp05iKFCG50z28tuY1bNjoHtydBZ0XULVoVa4kXOGJlU9zuncIAJe+/pqkK1dS1bMpfBPf7rUvBTe66WiKuRS7aXvVilZjaP2hAIzfOj5lCbfMiN28hbjt2zE4OlJkwADg37vtSriWYHDdwZmu87rrs0QtPLKQy2W9KdLXvhTO2XfexpqQsTsPwZ4INX7LeB5a/BBFLiYyYr4RQ4IFt5AWlBw5Mkc/1Cnx8hBcGzTAGhPD6edfIDk67ZJ07o7ufNH2C2oXr018cjz3brdR8YwNo5sbfiPfypUPmQxmM8WeeYYKC+bjUrs2htg4+i21MHpmMktXTePXo7+mKh/5228k7NtPrBMsaGZkeKPb3213o6JPPkmpD96n3Hff4d6sWU5fjoiIFHBz586lUqVKREREMG7cuFxtq3z58owaNYp69epl+BxHR0dGjhyJh4dHLkYmIiIicudZc3pNysw8Y5uPZWq7qSkzCz3626McuXLklud+uvNT9l/ej7eTN+80ewej4ebpB49Xe5zmpZuTkJzA0NVDibXEZjtui9XCyPUjSbYlc3/A/VlensvH2YfeVXoD9s+/sjpLlM1mY8vZLQxZNYR3Nr4DwNM1n8bb2TtL9eWEKkWrMK39NLydvIlPjsdsMDMuZBxeTl55FsOA6gPoVKETybZkXl79MiciT6QpM3v/bPZe2ouHowevN3w9z2KTO58SorKqRFWo/wTU7gPlW+V3NCI5p0QVeGEnPLcJHJzzOxoRERGRQs2WnMylL6YC4NPvcV7fOopL8ZcI8g7i1YavUsK1BN/c+w1t/NtgsVp4wTSPqIDiWKOjU2ZoAohIiGD4uuHYsNGjYg9al22dcizpyhVid+xI9WFN78q9ae3f2j7d+eqhRCdGZyru62179+iOg2+JVHfbvdnozSzdbXddPd96NCrZiCRrEp/u+BT3Z5/CXKIElhMnU2bSuhWrzcr6M+sZtGIQHRd05Nt938LVSN76yYhrtAXnqlUp89FHGBwcshzfzRjMZkp/NBGzry+JR49yrEMHTj7xJGfffofL335L1MqVJBw7jhuOfNHuCx7xbsdja+xvt0sMfTnXZ+9xCg6m3JzZ+I54E6OrK5XPwIfTktn93hvsPL0FAGtiIucnfQzAL42NNK7SnnvKZfxuO7i2XF+XLrjWrZPj1yAiIgVfv379SE5OZtu2bZQuXTq/wxERERGRHHA25izD1w0H4JHKj9C2XFsalmzIrA6z8PfwJywmjL5/9OXvM2ln9t5ydktKItWopqMo7lr8lu0YDUbGNh9LCZcSHI84zthNY7Md+8x9Mzlw+QBeTl682vDVbNX1eNXHcXNw48DlA/xy9BeSrckZPjcuKY6fDv1Ej197MGDpAJadWEayLZnW/q1zfVm6jKhUpBJft/+aZqWbMab5GGoWr5mn7RsMBkY2HUnN4jWJSoxi0IpBRCZGphw/FXWKT3d8CsDQ+kPT/T0SySwlRGWVwQAPTIQHPwOjulHuMC7e9lmiRERERCRbIpcsITE0FKOXF4tqJbIpfBMuZhfGtxyPi9kFAFcHVz5q/RH9q/fHZjAwqfElAK7MmUviqVPYbDbe2fgO52LPUc6zHK/UfwWAuH/2Evba6xxp2YoTj/Tm9LPPkXT5MmD/oOGdZu9Q0q0kp6JOMXrD6Azf3Ra7fQexGzeCgwNFn3ySJGsSo9aPItmWzL0B96ZKxsqq52o/B8Cvx36l2S9tmd3eCYDzU7/g0O7VaT50irZEM3v/bLr83IWBywey+vRqbNho51afqYv8KH7JgkPp0vhP/QKjm1u247sZc7FilPl4EkY3N5LOnyfm77+5MmcO5957n9PPPMuxDh04ULsO4fd1odfHuzAnJOFSty7eDz2UK/H8l8FopMijj1Lht8W4tW6F2Qrd1iVx+eH+nFr3J1fmzCHpzBkuu8Oapp66205ERERERETkLpdkTeLVNa9yNeEqVYpU4eX6L6ccK+9VntkdZlO3RF2iLdE8t+I5fjjwQ8rxiIQI3lj3Rsos6BlZ4qyIcxE+CPkAo8HIoqOL+OXIL1mO/WTkSabsnALAK/VfoahL0SzXBeDt7E3vyvZZokb8PYImc5vQf0l/Jm6byLITyzgbczbNZ2tnos8wfst47vnxHkZvGM2hK4dwMbvQo2IP5neez+Q2k3Ew5exNe1lVqUglvmj7BR0rdMyX9p1MTnzc+mP83PwIjQzlldWvkGRNwmaz8faGt4lPjqehX0O6BnXNl/jkzmXO7wBERERERETuRDarNWV2qPhubZl80D770RuN3iDQOzBVWaPByJB6QyjnUY4xhjHsCkigVmgSZyZ8yD/Pt2Np6FLMBjPvN34Hy5K/CJ01i7hdu/6twGAgeuVKjnXuQql3x+IeEoKXkxcftvyQfn/0Y0noEhqVbESPij1uG/fFL67NDvVgFxxKlWL6P9PZf3k/no6evNbwtRzpmzol6vB8nef5/sD3XIi7wPwyYVQqb6D28WS2D3uGvn3cqVa8OlV9qnIg9gDvLXyPmCT7MnVuDm48GPQgPd1CsL04EsvpM5iLF8f/qy8xF8/dO8hcatcm6K8VJBw6ROLJkySGnrA/nzxJ4okT2GJjsZw5A4DBwYGS77yNIY9voHEoWRL/KVO4+Nsijo96k5IXk4h+8kWiHR0BmNfCyPNNdLediIiIiIiIyN3ui11fsP38dlzNrnzY8kOcTE6pjvs4+/BV+68YvWE0i44uYsymMYRGhjK0/lDGbhrL2ZizlPUoy7AGwzLcZn2/+jxb61k+3fkpYzeNpUbxGlTwqpCpuG02G6M3jCYhOYEmJZvQObBzps6/lQHVB3Ay6iRrT68lNimWree2svXc1pTjxV2KU71Ydar4VOGv6L8YsWgENuxJUmXcy/Bw5Yd5MOjBPF2OrjAp5lKMT9p8wmN/PMb6sPWM3zqeKkWqsDF8I04mJ0Y2GYnBYMjvMOUOk6lPZj///HNq1qyJp6cnnp6eNGnShD/++CPluM1mY9SoUZQqVQoXFxdatWrF3r17czxoEREpPDR2iIhIZtxJ40bUihUkHD6Mwd2N4SX/xmqz0jmwMw8GPXjLc7pX7M4X7b7g5/b2Jenilyxj1sK38Y628d6h2jj2eoGwV16xJ0M5OODZqRMBP3xP+YULcAoOIvniRU79byBnx4zFGh9PreK1eKHuCwC8v/l99lzYk27McXv+IWbNWjCZKPrUU6nvtmvwCsVciuVM5wD/q/k/VvRcwbIey/io9SQiBvUkyWygVqiNWnti2HJ2C9/u/5ZNiZuISYqhvFd53mj0Bit6rmCw54MkD3wVy+nTOJQtS7k5s3GqkLkPz7LK5OWFa4MGeHfvTomXh1Dm40lUWLiAStu2Erx2DeVmz6Lku+9SbvYsnAIDb19hLjAYDBR/oAulF81nXd1ry2AnJnK6KMS0a0S34G75EpdIbrmTxg4REcl9GjdERCSz7sSxY2P4Rr7c/SVgX+6unGe5m5ZzNDkyptkYXqhj/3xp1v5ZPLT4If44/gcmg4n3WryHq4Nrptp+ssaTNCrZiLikOIauHkpEQkSmzl94ZCGbz27GxezCW03eyrEkGndHd8a3HM/6R9azsPNC3m76Nj0r9qRykcqYDCYuxF1g5amVTNk9hQNJB7Bho2mppnza5lMWd13M49UeVzLUbVQuUpl3m78LwOz9s3ln4zsAPFv7Wcp6ls3P0OQOlamEqDJlyvD++++zdetWtm7dSps2bejSpUvKf+jjxo1j4sSJfPrpp2zZsgU/Pz/atWtHVFRUrgQvIiIFn8YOERHJjDtl3LDZbFz6/AsAtjQrxgnbRQI8AxjeaPhtz21UshHvPvE922rbl3574ftoPv/MSrmfNpJ84SLm4sUp9vwggv9aQekPx+FSqxbOlSsT8OOP+PTtC8CVWbMI7dmT+AMHeLza4zQv3ZyE5ASe+PMJVpxcccu2L061x+z1QEcc/P1T7rZrXLIxXQK7ZLdb0jAYDPi5+dG2XFue7jgav2fsS+m9tM6LMbXeoFtQN2o71GZK6yn80uUXHqn8CIZd+znR9zGSL17EqXJlAmbPwtHfP8djyyyDwYC5eHFc69XDu1tXXGrWzO+QKF2qIg0mfcOYPo6srm7g867OjGiuu+3kznOnjB0iIpI3NG6IiEhm3Wljx8W4i7y25rWU5e7uL39/uuUNBgNP1XwqZRapg1cOAvB0raepWTzzn3+YjCbeb/E+RZ2LcvjKYfr83oeTkSczdO6F2AuM3zoegOdqP0cZjzKZbj8j8QX5BNE1uCtvNXmLHzv9yIbeG/ju/u8YWn8o95W7j6ZOTVnwwAKmtptKS/+WmIymHI/jTtW2XFsG1R4EQEJyAlWKVOGxqo/lc1Ryp8rUknmdOnVK9Xrs2LF8/vnnbNy4kapVqzJp0iSGDx9Ot272u02//fZbfH19mTNnDgMHDrxpnQkJCSQkJKS8joyMBMBisWCxWDJ1MdfPu/FZco/6Om+pv/NOYerrwhBjQR87CtPP+06g/s476uu8VVj6u6DHB7kzbkDejx0xa9YSv28fyU5mPq98GkejE+83ex8HHDLUnr+rP/eMnsbFbo9QJNoG2HCuUwevRx7GvW1bDA4O2P4bg8lE0WGv4Ny0CeffHEHC4SMc79mLoi++yNiHx/Da+tfZEL6Bl1a+xOA6g+lTuQ8ASWfOEL9nD/G7dhG9fAUYDHgNeIKfDv7E5rObcTY580aDN0hKSspUP2WFV79+RCz6FcuJEzRYdIR2Q19l2cVl1CtWj6SkJGJWr+bsy0OxJSTgXLcuJT+ZjM3Ts1D8bueXaj7VePihMYwtP5YX6rxAKZdSt+yvwvJ/2Z2gMPV1YYhR7znkRgWpvy0WCzabDavVitVqze9wcpzNZkt5vhOvr6ApSP1ttVqx2WxYLBZMptRf/hWEf3u3c6e855Ccob7OW+rvvFOY+rowxHgnvedItibz2prXuBR/iSCvIIbUGZLh9u4pfQ8l7inBiA0jqOBVgccrP57ln5+X2YvPWn/G4NWDCY0M5dHfH2V8i/HULVE33fPGbhxLVGIUVYtUpVdQrzz7/TFjprpPdar7VMdS3sKyZcso7VK6UPz+FkT9q/TnTNQZVp5eyVuN3sKWbMOSnLYvC9P/ZXeCwtLfmYnPYLv+TiqTkpOT+fHHH3n88cfZsWMHzs7OBAYGsn37durUqZNSrkuXLnh7e/Ptt9/etJ5Ro0YxevToNPvnzJmDq2vmptcTEbnbxMbG0rt3byIiIvD09MzvcG5LY4eISP66W8cNyOOxw2bDf8rnuJw8yeKGRr67x0hnl840dGqY6arcd+/BOTSUqHp1SShdOsPnmaKj8Z0/H/d9+wGICQoirGc3liavJOLENoLCoP5ZT8qFWTDHxKQ6N7JuHQ737MDHUR8Tb4vnPuf7aO7cPNOxZ5Xr4cOU+XoaNoOBk88PSrluj23b8PtpPgarlegqVQh/tDc2B4c8i0vkbnW3jh16zyE5wWw24+fnh7+/P46OjvkdjkiOSUxM5NSpU5w9ezZN0vzdOm6Axg4Rkay6W8eO/Bo3VsWvYnn8chxw4BmPZyhhKpHpOq6nF+TEDNRR1ihmxcziTPIZTJjo6tqV2o61b1p2X+I+5sTOwYiRZzyeoaSpZLbbF5HCJzPjRqZmiALYs2cPTZo0IT4+Hnd3dxYuXEjVqlVZv349AL6+vqnK+/r6cuLEiVvW9/rrrzNkyJCU15GRkfj7+9O+ffssDXoWiz0js127djjow/Fcpb7OW+rvvFOY+vr6HQMFXUEeOwrTz/tOoP7OO+rrvFVY+vtuHTcgb8eOS1OmcOXkSRLNBn5pZKBd2XaMbJbFZco6dMj8OdfYevYk8sefuPjhh7gdOULFCZMITky8ocRV+5PZjFPlyjhXr45zzZoE3ncv328cTnxkPFWKVOHt9m9jNmb6rWO2nD0TRvQffxC84i/+6fMojS5c5Mq8HwHw6NyJwFGjqF2A/60VVoXl/7I7QWHq67t17NB7jsKrIPV3fHw8p06dwt3dHWdn53yNJTfYbDaioqLw8PBI9+8ck8nE/PnzefDBBwkNDSUwMJBt27ZRu3btvAu2AFi1ahX33HMPly5dwtvbO9Pn366/f/75Z4YNG8bx48cZNGgQH330UQ5EfXPx8fG4uLgQEhKS5nf7bh03QGNHYaW+zlvq77xTmPr6bh078mPc2H5+O3+t+AuA4Y2H07lC50y1k1s6J3VmxIYR/HXqL36K/QmfCj48XePpVH/zRCVGMem3SQD0q9aPJ2o9kU/RFq5/X4Wd+jpvFZb+zsy4kelPtStVqsTOnTu5evUq8+fP5/HHH2f16tUpx//7Zsxms6X7htjJyQknJ6c0+x0cHLLVydk9XzJOfZ231N95pzD0dUGP77rCMHYUhp/3nUT9nXfU13mroPd3QY7tRjk9bkDejR1np3/Flc+/AOC7NgY8/PwZ3Wx0vs0KUezR3ng0aULYK68Qv3cvAA7lyhIZ5Md88y72+SZhCC7Hx/dOpJSnPwArTq5g+anlmAwm3mn2Di5OLnked8k3Xufo2rUk7t1LmS+/4srx4wAUefxxSrw6DIPRmOcx3U0K+v9ld5LC0NcFPb7r9J5D/qsg9HdycjIGgwGj0YixkIxdt/ub6vHHH2fGjBkAKcu2Xb/G9Fzvg3LlyhEeHk6xYsVSnfPtt9/y2WefsXfvXoxGI3Xq1GHYsGE88MADN62vUqVKHD9+nOPHj1P6FrNotmrViocffpinn34agPnz5/PJJ5+wY8cOkpOTqVChAj169GDQoEEUKVKEGTNm0L9//5Tz3dzcqFSpUqrlb7Lj+vVm9ffhen8HBgYyePBgBg8enOr4M888Q//+/XnhhRfw8PDI8u9cQEDATeu/kdFoxGAw3PTfWX7/u8uowvyeQ3KH+jpvqb/zTmHo64Ie33WF+T3HpbhL7Lqwi7GbxmK1WelUoRPdKnbLkRmecoKDgwMftf6Ij7d/zPR/pvPVP19xKvoU7zR7B2ezPfn6062fcjHuIgGeATxb51kcTPn/e1MY/n3dKdTXeaug93dmYst0QpSjoyNBQUEA1K9fny1btvDxxx/z6quvAnD27FlKlvx3errz58+nyYgVEZG7i8YOERHJjMIybthsNsKiw9h5fie7LuzCsPgvuvx4GoC5IUb+auDIrFbj8XD0yPPYbuRUoTwBP3xPwpEjOPj5Ybo2I4Hr5QMMWjGIc7EnePT3R/m4zccEeQfx7sZ3AehfvT+VilTKl5jNxYtTfPBgzo0Zg+u1ZKjiL71E0f89VWA+rBORgqWwjB0iBV14eHjK9g8//MBbb73FwYMHU/a5uGQvUdpkMuHn55dq39ChQ/n0008ZM2YMDz74IBaLhVmzZtGlSxc+/vhjBg0alKr8unXriI+Pp2fPnsyYMYPhw4enaefy5cusX7+e2bNnAzB8+HA++OADXnrpJd59911KlSrF4cOH+eKLL5g5cyYvvvgiAJ6eninXGxUVxTfffEOvXr3Yu3cvlSrlz99FGREdHc358+e59957KVWqVH6HUyho3BARkcwqLGNHsjWZI1ePsPP8TnZesH9mdSrqVMrxAM8A3mz8ZoH7fMVoMPJSvZcI8Azg7Q1vsyR0CWExYXzc+mOORxznx0P2mcNHNhmJkyltIpmIyM1k+9Ykm81GQkIC5cuXx8/Pj2XLlqUcS0xMZPXq1TRt2jS7zYiIyB1EY4eIiGRGQRo3TkaeZNb+WcyNmct9P9/HvfPv5dW1r3J84Sw6XUuGWtbMjehH2jPlnilUK1otT+K6HYPZjHPlyinJUACVi1RmTsc5VC1alSsJV3hi6RMMWjGI83HnKedZjoE1B+ZfwIDPIw/jXLcuNqOR4m+9RbGB/ytwH9aJSMFVkMYOkVRsNkiMyfuHzZah8Pz8/FIeXl5eGAwG/Pz88PX1pXnz5nz11Vepyu/btw+z2czRo0cBOHz4cMoyalWrVk31bw8gNDQUg8HAzp07Adi4cSMTJkzgww8/ZOjQoQQFBVGlShXGjh3L4MGDGTJkCKdOnUpVx7Rp0+jduzd9+/Zl+vTp2G5ybb/99hu1atWidOnSbN68mXfffTelnaZNmxIQEEC7du1SZne47vr1+vn5ERwczJgxYzAajezevTtD/ZeQkMCwYcPw9/fHycmJ4OBgpk2blqrMtm3bqF+/Pq6urjRt2jRVwtnRo0fp0qULvr6+uLu706BBA5YvX55y/IEHHuDEiRO89NJLGAwGDAYDq1atwsPDnoDfpk2blH0zZszA29ubxYsXU6lSJVxdXenRowcxMTF8++23BAQE4OPjw/PPP09ycjJgn1Xrv/XfLTRuiIhIZhWksWPbuW0sj1vO0yuepuncpvT4tQdjNo1h8bHFnIo6hQEDQd5B9KjYg6ntpuLq4JoncWVF1+CuTG03FU9HT3Zf2M2jvz3KyPUjAehZsSf1/ernc4QiUphkaoaoN954g/vvvx9/f3+ioqL4/vvvWbVqFUuWLMFgMDB48GDeffddgoODCQ4O5t1338XV1ZXevXvnVvwiIlLAaewQEZHMKOjjxvbz25m4Y6L9hQXMBjMPnCvFw78exwg4duvEoDHvF5plcUq4luCbe7/hjXVvsOLkCraf3w7Y77a7PiV5fjGYTJT++iuW/vwzwT175GssIlKwFfSxQyQVSyy8mw8z+LwRBo5uWT7dYDAwYMAAvvnmG4YOHZqyf/bs2bRo0YLAwECsVivdunWjWLFibNy4kcjIyHSXXQOYO3cu7u7uDByYNhH75ZdfZuLEicyfPz+lnqioKH788Uc2bdpE5cqViYmJYdWqVbRu3TrVuYsWLaJLly4pMbq7u/Pss8/eNAbvGxLGb5ScnMx3330HQN26ddO9jusee+wxNmzYwOTJk6lVqxbHjx/n4sWLqcoMHz6cCRMmULx4cZ5++mkGDBjA33//DdhneurQoQNjxozB2dmZb7/9lk6dOnHw4EHKlCnDzJkzCQkJ4X//+x9PPfUUAEWKFOHgwYNUqlSJ+fPn07RpU4oUKUJoaCixsbFMnjyZ77//nqioKLp160a3bt3w9vbm999/59ixY3Tv3p3mzZvz0EMPsWDBAmrVqpWq/juRxg0REcmsgj52zDs8j1UJq+Cc/bWbgxs1i9Wkdona1CpeixrFa+Dp6JknseSEhiUbMqvDLJ5b8VzK7FbFXYrzUr2X8jkyESlsMpUQde7cOfr27Ut4eDheXl7UrFmTJUuW0K5dOwCGDRtGXFwczz77LFeuXKFRo0b8+eefKXeoiIjI3Udjh4iIZEZBHzfqlqhLy9ItcbrkRM/mPal0MolzEwZhS7bh2bEjpd55D0MhSYa6ztXBlYmtJjJp+yRm/DODvlX70sCvQX6HBYDBwQGrW9a/vBWRu0NBHztE7hT9+/fnrbfeYvPmzTRs2BCLxcK8efMYN24cAMuXL2f//v2EhoZSpkwZAN59913uv//+W9Z56NAhAgMDcXR0THOsVKlSeHl5cejQoZR933//PcHBwVSrZp+F8+GHH2batGmpEqISEhJYunQpb731FmCftapChQo4ODjc9hojIiJwd3cHIC4uDgcHB7788ksCAwNve+6hQ4eYN28ey5Yto23btgBUqFAhTbmxY8fSsmVLAF577TU6duxIfHw8zs7O1KpVi1q1aqWUHTNmDAsXLmTRokU8++yz+Pj4YDKZ8PDwSLX0YIkSJQB7ctSN+y0WC59//nlK/D169GDmzJmcO3cOd3d3qlatSuvWrVm5ciUPPfQQRYoUuWn9dxqNGyIiklkFfewIKR3CxfCL3F/7fuqVrEegVyAmoylP2s4t5b3KM6fDHIasHsLO8zsZ2WQkHo4ai0UkczKVEPXf6X3/y2AwMGrUKEaNGpWdmERE5A6isUNERDKjoI8bZT3L8lHLj/j999+pdsGZsEFPYktIwL1VK0q9/x4GU+H8sMloMDKk3hAG1hyIm4MSkESkcCnoY4dIKg6u9tma8qPdbCpZsiQdO3Zk+vTpNGzYkMWLF5OQkEDPnj0B2L9/P2XLlk1JhgJo0qRJttq02WypkqWmTZtGnz59Ul736dOHkJAQrl69mjLT019//UXRokWpUaNGSh0ZXfrNw8OD7dvtM2bGxsayfPlyBg4cSNGiRenUqVO65+7cuROTyZSS7HQrNWvWTNkuWbIkAOfPn6ds2bLExMQwevRoFi9eTFhYGElJScTFxXHy5MkMxf9frq6uqZK5fH19CQgISEn6ur7v/PnzWaq/sNK4ISIimVXQx46O5Tti2G+gQ3CHDCWBFxbezt5Maz+N2KRYfV4lIlmSqYQoERERERERAcez5wh79z2sMTG4NmpE6UkfYbgDPnDSh0siIiK5zGDI1tJ1+e3JJ5+kb9++fPTRR8yYMYOuXbvi6mpPtrLZbGnK3y4RKTg4mHXr1pGYmJhmlqiwsDAiIyOpWLEiAPv27WPTpk1s2bKFV199NaVccnIyc+fO5ZlnngFSL5cHULFiRdatW4fFYrntF4RGo5GgoKCU1zVr1uTPP//kgw8+uG1ClIuLS7rHr7sxhuv9Y7VaAXjllVdYunQp48ePJygoCBcXF3r06EFiYmKG6k6vrevt3Wzf9fZFREREChqDwaDPq0QkywrXWg4iIiIiIiL5zHLqFGW+/hprRATONWtS5rPPMDo753dYIiIiIrmuQ4cOuLm58fnnn7NkyRIeffTRlGNVq1bl5MmThIX9OwPWhg0b0q3vkUceITo6mqlTp6Y5Nn78eJydnXnooYcA+8wMISEh7Nq1i507d6Y8hg0bljJrg81m49dff6Vz584p9fTu3Zvo6GimTJly0xiuXr2abowmk4m4uLh0ywDUqFEDq9XK6tWrb1v2VtauXUu/fv3o2rUrNWrUwM/Pj9DQ0FRlHB0dSU5OznIbt5Pb9YuIiIiIiOQVzRAlIiIiIiKSQZazZznz1FOYo6JwDAqi7JdTMbnrLjURERG5O5hMJvr168frr79OUFAQDRs2TDnWtm1bKlWqxGOPPcaECROIjIxk+PDh6dbXpEkTXnzxRV555RUSExN58MEHsVgszJo1i8mTJzNjxgyKFi2KxWJh5syZvP3221SvXj1VHU8++STjxo1j165dWCwWYmJiCAkJSTneqFEjhg0bxssvv8yZM2fo2rUrpUqV4siRI3zxxRc0b96cF198EbAnVJ09exaAuLg4li1bxtKlS3nrrbdu2zcBAQE8/vjjDBgwgMmTJ1OrVi1OnDjB+fPn6dWrV4b6NygoiAULFtCpUycMBgMjRoxIM3tTuXLlWLNmDQ8//DBOTk4UK1YsQ3VnVEBAQK7WLyIiIiIiklc0Q5SIiIiIiEgGRfz8M0lnwkgsWpRSX07F5O2d3yGJiIiI5KknnniCxMRE+vfvn2q/0Whk4cKFJCQk0LBhQ5588knGjh172/omTZrElClTmDt3LtWrV6dKlSp8+OGH/PXXX/Tp0wewL4N36dIlunbtmub84OBgatSowbRp0/jll1/o2LEjZnPq+4A/+OAD5syZw6ZNm7j33nupVq0aQ4YMoWbNmjz++OMp5SIjIylZsiQlS5akSpUqTJgwgbfffvu2iV3Xff755/To0YNnn32WypUr89RTTxETE5OhcwE++ugjfHx8aNq0KZ06deLee++lbt26qcqMHj2a0NBQAgMDKV68eIbrzqi33347V+sXERERERHJK5ohSkREREREJIOKDhyI1QZbnJ2oqi+IRERE5A7Wr18/+vXrl2Z/eHg4ZrOZvn37pjlWsWJF1q5dm2qfzWZL2Q4ICEj1+roBAwYwYMAAAEJDQ2nZsiVTpkyhWbNmmEwmunfvnu4ybrt37wagZs2avPnmmzct06tXr3RnarrV9WaGs7MzEydOZOLEiWmOtWrVKs21165dO03//PXXX6nKPPfccwApM0U1btyYXbt2pSrj7e2dpu6bXc+oUaMYNWpUqn0zZsxI9fpm9YuIiIiIiBRGmiFKREREREQkgwwGAz5PPkFSkSL5HYqIiIhInkpISODIkSOMGDGCXr164evrmyvtBAQEsGrVKipXrszOnTszfF5iYiLdu3fn/vvvz5W4REREREREpHBRQpSIiIiIiIiIiIiIpGvu3LlUqlSJiIgIxo0bl6ttlS9fnlGjRlGvXr0Mn+Po6MjIkSPx8PDIlZjWrl2Lu7v7LR8iIiIiIiJSsGjJPBERERERERERERFJ13+XYLu+hNvdon79+pmasUpERERERETylxKiREREREQKiMRTpzC6u2P28cnvUERERERE5AYuLi4EBQXldxgiIiIiIiKSQUqIEhERERHJR8mRkUT+/jtX5y8gfs8eHMqUIXDJHxjM+lNdREREREREREREREQkK/Qti4iIiIhIHrNZrcRu3szV+QuI+vNPbAkJKccsp08Tt2sXrvXq5WOEIiIiIiIiIiIiIiIihZcSokRERERE8ojlzBmuLvyZiIULsZw5k7LfKTgIr+7did24iehVq4hevUYJUSIiIiIiIiIiIiIiIlmkhCgRERERkVs4ePkgX+z6gidrPEm1YtWyXM/lK+Fsfa4vZXaEYbDZADC6u+P5QEe8u3fHuXp1DAYD5iJFriVErabEkJdy6jJERERERERERERERORuZImDX1+EgBZQt2/W67HZYO0EiLkI7UaD2SnnYswlSogSEREREbmFGXtnsPzkcrae28qsDrMo51ku03UkJCcw5/3HuWe7fUao2FpBBPX5Hx5t22J0cUlV1q1FCzAYSDh4EMvZszj4+eXIdYiIiIiIiIiIiIiIyF1o/2LY/YP9YXaGmj2zVs+q92D1B/bt2IvQ9UswGnMuzlxQsKMTEREREclH289tB+BqwlWeXf4sl+MvZ+p8q83KiDXDqbHqFABf3mfkyY6nOVC/RJpkKACzjw8uNWsCEL1mTTajFxERERHJfwaDgZ9//hmA0NBQDAYDO3fuzNeYRERERERE7hon1/+7/cuzELou83XsmPVvMpTBCHt+hJVjcia+XKSEKBERERGRmzgbc5awmDBMBhOl3UtzMuokz//1PPFJ8Rmu4+PtH3Nx2R+UiACrpzvOHe8jyZbESytf4siVIzc9x61lCADRq2+eEHUi8gR/HP8j8xckIiIiInIbBoMh3Ue/fv2yVb+/vz/h4eFUr1491f5vv/2Whg0b4ubmhoeHByEhISxevPiW9VSqVAlHR0fOnDlzyzKtWrXiiy++SHk9f/582rRpg4+PD66urlSqVIkBAwawY8eOlDIzZsxIdb0lS5akV69eHD9+PBtXLSIiIiIiko9ObLA/F6kAyYnwfW+4cDDj5x9daV9yD6DFy9D5U/v22gmwbUbWYkqMgQ2fgdWatfMzSAlRIiIiIiI3se3cNgAqF6nMlLZT8HT0ZPeF3byx7g2sttv/kT7v4Dym/zOdDlvtZYs/8iij2rxL3RJ1ibJE8cyKZzgfez7Nee4tWwIQs2ED1sTEVMeWnVjGQ4sf4o11b7D7wu7sXqKIiIiISCrh4eEpj0mTJuHp6Zlq38cff5yt+k0mE35+fpjN5pR9Q4cOZeDAgfTq1Ytdu3axefNmWrRoQZcuXfj000/T1LFu3Tri4+Pp2bMnM2bMuGk7ly9fZv369XTq1AmAV199lYceeojatWuzaNEi9u7dy5dffklgYCBvvPFGqnOvX3NYWBhz5sxh586ddO7cmeTk5Gxdu4iIiIiISJ6LvQwX9tu3H/8V/BtBfATM6gFR525//rm9MO8xsCZBjZ7QZgTUeRRavmo/vngIHF6euZguHIKv7oGlb8DfH2Xu3ExSQpSIiIiIyE1cXy6vTok6VPCqwMetP8bB6MCyE8uYsHVCuueuOb2GsZvGUu6cjWonAbMZn96P4GRy4uPWHxPgGcDZmLMMWjGIWEtsqnOdq1TBVLwYtthY4rZuBcCSbOGDzR8wZNUQYiwx1CxWEz83v1y5bhERERHJPTabjVhLbJ4/bDZbhuLz8/NLeXh5eWEwGPDz88PX15fmzZvz1VdfpSq/b98+zGYzR48eBeDw4cOEhITg7OxM1apVWbZsWary/10yb+PGjUyYMIEPP/yQoUOHEhQURJUqVRg7diyDBw9myJAhnDp1KlUd06ZNo3fv3vTt25fp06ff9Np+++03atWqRenSpdm4cSPjxo1j4sSJTJw4kRYtWlC+fHlatmzJ8OHD+f3331Ode/2aS5YsSevWrRk5ciT//PMPR47cfIZXERERERGRAuvkRvtz0WDwKgMPz4UigRBxEub0ss/UdCuRYTC7JyREQrnm0OUzMBjsx1q9DrUeAVsy/Pg4hGfwBu49P8FXre1JWu6+9gStXGS+fRERERERkbvP9vP2hKh6vvUAqO9XnzHNxvDq2lf5bt93lHYvTe8qvdOct/fSXoauHorVZuXpA2WAE3jeey8Ovr4AeDt7M6XtFPr83of9l/czdPVQJreZjNlo/9PcYDTi3iKEiAULiF69mqhaFRi6eii7LuwCoH+1/jxf93kcjA550AsiIiIikpPikuJoNCd3P/C9mU29N+Hq4Jrl8w0GAwMGDOCbb75h6NChKftnz55NixYtCAwMxGq10q1bN4oVK8bGjRuJjIxk8ODB6dY7d+5c3N3dGThwYJpjL7/8MhMnTmT+/Pkp9URFRfHjjz+yadMmKleuTExMDKtWraJ169apzl20aBFdunRJ1cazzz57y2tLj4uLCwAWiyXdciIiIiIiIgXOyWvL5ZVrYn92KwqP/gjT2kH4TvjpCXh4NhhNqc+Lj4TZvSDyDBSrCA/PArPTv8cNBug02X78+Bp7ctWTy+1JVzeTlAB/vgmbv7S/DmgB3aeBh2+OXu5/aYYoEREREZH/iEiI4MjVI/ift1Hhg5+IP2hfT7tDhQ68WNe+VvYHWz5g5cmVqc4Liwlj0IpBxCXF0catLoFbwgAo8ljfVOX8Pfz5pM0nOJucWXtmLe9uejfVne3Xl827sGIpvX7txa4Lu/Bw8ODj1h8zpP4QJUOJiIiISJ7r378/Bw8eZPPmzYA9QWjevHn069cPgOXLl7N//35mzpxJ7dq1CQkJ4d133023zkOHDhEYGIijo2OaY6VKlcLLy4tDhw6l7Pv+++8JDg6mWrVqmEwmHn74YaZNm5bqvISEBJYuXZqSEHXo0CEqVKiQapm+iRMn4u7unvKIiIi4aXynT5/mww8/pEyZMlSsWPH2nSQiIiIiIlKQXE+IKtv0331FA+GR78HsDIf+gD9ehRtn3k22wI/94NwecCtuT6By8Ulbt9kRes2E4lUgKtw+m1T8Td5bXT0J39z/bzJU8yHQ9+dcT4YCzRAlIiIiIpLGjvM7AOi30ZmEvas5c+wE5X9eiNHZmSeqP8HpqNPMPzyfYWuG8c1931DJqxJx1jheWPUCF+MuEuwTzLDjtYi0bMalVi1catVK00bN4jV5P+R9Xlr5Ej8e+pHS7qV5osYTADg3bojVZMR0+hyO4SaqBFVlQqsJ+Hv452k/iIiIiEjOcjG7sKn3pnxpN7tKlixJx44dmT59Og0bNmTx4sUkJCTQs2dPAPbv30/ZsmUpU+bfO4KbNGmSrTZtNluqZKlp06bRp0+flNd9+vQhJCSEq1ev4u3tDcBff/1F0aJFqVGjRkq5/84CNWDAADp37symTZvo06dPqpsTIiIicHd3ty9vGBtL3bp1WbBgwU2TtkRERERERAqsxFgIs3/XkTJD1HX+DaHblzDvcdjyFfiUgwZPg82GackrcHQFOLhC7x/AJ+DWbbh42xOmvm4L5/fBvMfg0Z/AdO2m7sPLYMFTEHcFnL2h61SodF8uXOzNaYYoEREREZH/2H5uO06JNqocigcgMTSUi599Bti/THmz8Zs0K92M+OR4nlvxHKGRocyJncOxiGOUcCnBZy0mEfPjQgB8/jM71I3uKXsPrzZ8FYBJ2yfxx/E/uBx/mUGbhrGvtP1LmQFRtZjZYaaSoURERETuAAaDAVcH1zx/3G5ZuIx68skn+f7774mLi2PGjBl07doVV1f7Unw3JhXdeL3pCQ4O5ujRoyQmJqY5FhYWRmRkZMrMTPv27WPTpk0MGzYMs9mM2WymcePGxMXFMXfu3JTzblwu78Y2blzyztvbm6CgIEqXLp2mXQ8PD3bu3MmePXuIjo5m27ZtNGjQ4DY9IyIiIiIiUsCc2QrWJPAoBd7l0h6v2gXaj7Fv//kmhv2/EHzuV4w7Z4HBaF/SrnS927fj7Q+PzgMHNzi2Cn59EZKTYMU7MLuHPRmqVB0YuCZPk6FACVEiIiIiImlsO7+NukdtmC3JGN3cALg0/Rvi9vwDgNloZkLLCVQuUpnL8Zd5+PeHOZ50HFezK5+1/QyX1dtJvngRs68vnu3bp9vWo1UepU8V+13uw9cNp+einmwI38CeYPsdFM1PuuJkckqvChERERGRPNGhQwfc3Nz4/PPPWbJkCY8++mjKsapVq3Ly5EnCwsJS9m3YsCHd+h555BGio6OZOnVqmmPjx4/H2dmZhx56CLDPDhUSEsKuXbvYuXNnymPYsGEpy+bZbDZ+/fVXOnfunKaNKVOmZOgajUYjQUFBVKhQAbdr7wVEREREREQKnRPX3o+VawK3ulmlyXPQcCAApp+fpmr4T/b994+Dyh0y3lbJWtBzBhhMsHM2fFoP1o63H2vwJAxYap+FKo8pIUpERERE5AZxSXHsu7iPRgftd7j79H4Ezw4dIDmZ8OHDsV27e93NwY3P7vkMPzc/Eq2JGDEyrvk4KvlU4vJ33107tzcGB4fbtjm0/lDuKXsPFquF83HnCfAMoM8TEwGI3bwZa2xsLl2tiIiIiEjGmUwm+vXrx+uvv05QUBANGzZMOda2bVsqVarEY489xq5du1i7di3Dhw9Pt74mTZrw4osv8sorrzBhwgSOHj3KgQMHePPNN5k8eTJfffUVRYsWxWKxMHPmTB555BGqV6+e6vHkk0+ybds2du3axbZt24iJiSEkJCRVGy+//DIvv/wyQ4YMYd26dZw4cYKNGzcybdo0DAYDRqM+JhcRERERkTvMyfX257LpLGVuMMB970Gljhis9ll1kxs9Cw2fynx7FdtDxwn27Suh9hmjun1t32fOn5u+zfnSqoiIiIhIAfXPxX8wJlqod9T+2qP9vTiULkXMhg0kHDrExa++ovhzzwFQwrUEX7T9golbJ1LqSimalmpK3LZtJOzbj8HJCe9ePTPUpslo4r0W7zFm4xhczC68VO8lXM2uHC1dGsuZM8Rs3IRHm9a5dckiIiIiIhn2xBNP8O6779K/f/9U+41GIwsXLuSJJ56gYcOGBAQEMHnyZO67L/0lESZNmkTNmjWZMmUKb775JvHx8Tg6OvLXX3+lJDYtWrSIS5cu0bVr1zTnBwcHU6NGDaZNm4aXlxcdO3bEbE79sff48eNp2LAhn3/+OdOnTyc2NhZfX19CQkLYsGEDnp6e2ewVERERERGRAiQ5CU5tsW+nlxAFYDRB96+xLn6Zo2cjCLhnFKastlu/PyTFw7HV0HYUlKic1ZpyhBKiRERERERusO3cNmods+GUaMOhVCmcq1fDYDDg++Zwwl4eysUvpuLRrh3OFSsCEOgdyKSWk/j9998BuPzdTAC8unTB7OOT4XZdzC6MbT421T73liFcmTOX6DWrlRAlIiIiInmqX79+9OvXL83+8PBwzGYzffv2TXOsYsWKrF27NtU+m82Wsh0QEJDq9XUDBgxgwIABAISGhtKyZUumTJlCs2bNMJlMdO/eneTk5FvGunv3bgBq1qzJm2++edMyvXr1olevXresA259zSIiIiIiIoXK2d1giQFnLyhR9fblHV1J7jSZfb//ToAhmzPoNn7G/igANBewiIiIiBQqU3dN5YPNH2C5Nn1rTtt+bjuNry2X59G+PYZra2t7duiAe5s2YLEQPvxNbElJac61nDlD1PLlABTp2yfbsbhduyM+es2am35xJCIiIiKSVxISEjhy5AgjRoygV69e+Pr65ko7AQEBrFq1isqVK7Nz584Mn5eYmEj37t25//77cyUuERERERGRHHPoT/ixH1w9mTv1n9xgf/ZvDHfxEuF375WLiIiISKFzKuoUn+78lFn7Z/HOhndyPEkoyZrE3vCd1Dt8LSHq3vYpxwwGA34jR2L08CB+zx4uf/tdmvMjvv8erFbcmjbFKTg42/G4NWqEwcmJpLBwEg4fznZ9IiIiIiJZNXfuXCpVqkRERATjxo3L1bbKly/PqFGjqFevXobPcXR0ZOTIkXh4eORiZCIiIiIiItlks8HS12HvQpjVA+Ku5HwbJ9bbn8vdZrm8O5wSokRERESk0Fh+YnnK9sIjC/ly95c5Wv/BywcJOhyDayKYfX1xqVUr1XEH3xL4vjoMgAuTJ5MYGppyzJCQQOT8BQD4PJZ2+ZCsMLq44NqoIQAxa9bkSJ0iIiIiIlnRr18/kpOT2bZtG6VLl87vcERERERERAqn8/vh0hH79sWD8ENfSErIufptNji50b5dtmnO1VsIKSFKRERERAqNZSeWAdDQz54k9OnOT/n16K85Vv+2c9v+XS6vXTsMN5lK1qt7d9yaNsGWkEDYm29is1oB8Ny+HWtUFI7lyuF+bam7nOAe0hKA6NVKiBIRERERERERERERKdT2/WJ/LlkLHD0gdC38MsieyJQTLh6G2ItgdoZSdXKmzkJKCVEiIiIiUiiER4ez5+IeDBj4IOQD+lfvD8Bb699iU/imHGljV9g26l9bLs/zhuXybmQwGPB7+x0Mrq7Ebd3Gle+/x2a14rPubwB8+va9aSJVVrm3tCdXxW7fTnJkZI7VKyIiIiIiIiIiIiIieWz/Ivtzo2fgoe/AaIY98+CvMTlT/8kN9ufS9cHsmDN1FlJKiBIRERGRQmH5SftyeXV961LMpRiD6w7mvoD7SLIm8dLKlzhy5Ui26rfZbMRu3oR7PNiKeOFSt+4tyzqWKU2Jl14C4ML4CUT+9BOOFy9i9PDAu+uD2YojTVv+/jhWqADJycSsX5+jdYuIiIiIiIiIiIiISB65cAjO7wOjA1S6DwLbQKeP7cfWjodt32a/jesJUWUbZ7+uQk4JUSIiIiJSKFxfLq9duXYAGA1GxjQfQ90SdYmyRPHsime5EHshy/WHRoZSbbd9Biavdu0xmEzplvd5tDcudetijY3lwjv2Ozc8u3bF6OaW5Rhu5foSfFo2T0RERERERERERESkkNp/bbm8Ci3Bxce+XacPhAyzby9+CY4sz14bJ67dWF2uSfbquQMoIUpERERECrzzsefZeX4nAPeUvSdlv5PJiY9bf0yAZwDhMeE8t+I5Yi2xWWpje9gWGhyyL5fnfd/9ty1vMBopOWYMBkf7lLM2gwGvRx7OUtu3496qJQDRa9Zgs1pzpQ0REREREREREREREclF+64tl1e1S+r9rd+Amg+DLRnmPQ5n92St/sgwuHoCDEYo0zB7sd4BlBAlIiIiIgXeipMrsGGjVvFa+Ln5pTrm7ezNlHumUMS5CPsv7+eVNa+QZE3KdBtn1i3DMw4S3Z1xbdAgQ+c4VShP8RdfACCqRg0cypTJdLsZ4Vq3LkY3N5IvXSJ+775caUNERERERERERERERHLJ5WNwdjcYTFCpY+pjBgN0/gQCWkBiNMzuBRFnMt/G9dmh/GqAs2f2Yy7klBAlIiIiIgXef5fL+y9/T38mt5mMk8mJNafX8P7m97HZbJlqw2XtTgCsLepjMJszfF6RAQMoM2sm53r2yFR7mWFwdMStaVMAoteszrV2RERERERymsFg4OeffwYgNDQUg8HAzp078zWm/DBjxgy8vb1zrf4vv/wSf39/jEYjkyZNyrV2REREREQki67PDhXQHNyKpj1udoSHZkHxKhAVBnN6QXxk5to4ucH+XLZp9mK9QyghSkRERESyxWazEX/wELbExFyp/1LcJbad2wZA23Jtb1muVvFafNDiAwwY+OHgD8zYOyPDbZyNDKPa3mgAynTqman4DAYDzrVqYbu2dF5ucW8ZAkD06jW52o6IiIiI3L0MBkO6j379+mWrfn9/f8LDw6levXqq/d9++y0NGzbEzc0NDw8PQkJCWLx48S3rqVSpEo6Ojpw5c+s7plu1asUXX3yR8nr+/Pm0adMGHx8fXF1dqVSpEgMGDGDHjh0pZWbMmJHqekuWLEmvXr04fvx4Nq46Z5lMppQEs+siIyMZNGgQr776KmfOnOF///tfluu/MYFNRERERERy0P5bLJd3IxdveHQeuPvCuX9g3mOQbMl4Gyc32p/LNclymHcSJUSJiIiISLac/2Acx7t04dy4D3Ol/r9O/YXVZqVa0WqUdi+dbtl7yt3DKw1eAWDitolsCt+UoTb2r16ITwzEuRgp1rxVdkPOFW4t7AlR8Xv2kHTpUj5HIyIiIiJ3ovDw8JTHpEmT8PT0TLXv448/zlb9JpMJPz8/zDfMyDp06FAGDhxIr1692LVrF5s3b6ZFixZ06dKFTz/9NE0d69atIz4+np49ezJjxoybtnP58mXWr19Pp06dAHj11Vd56KGHqF27NosWLWLv3r18+eWXBAYG8sYbb6Q69/o1h4WFMWfOHHbu3Ennzp1JTk7O1rXnppMnT2KxWOjYsSMlS5bE1dU1v0MSEREREZEbXT0JZ7YBBqjSKf2y3mWh9zxwcINjK2HF2xlrI+4qnNtr3y6rhChQQpSIiIiIZMPlmbO4fO1LiKs//kjSlSs53sayUPtyeenNDnWjvlX70j24OwAj148k1hJ723Oi/7S3caFueQy5PNNTVjn4lsCpahWw2YhZty6/wxERERGRLLDZbFhjY/P8kdHlpP38/FIeXl5eGAwG/Pz88PX1pXnz5nz11Vepyu/btw+z2czRo0cBOHz4MCEhITg7O1O1alWWLVuWqvx/l8zbuHEjEyZM4MMPP2To0KEEBQVRpUoVxo4dy+DBgxkyZAinTp1KVce0adPo3bs3ffv2Zfr06Te9tt9++41atWpRunRpNm7cyLhx45g4cSITJ06kRYsWlC9fnpYtWzJ8+HB+//33VOdev+aSJUvSunVrRo4cyT///MORI0du239Xr17lf//7H76+vjg7O1O9evU0M10tXbqUKlWq4O7uzn333Ud4eHjKsS1bttCuXTuKFSuGl5cXLVu2ZPv27SnHa9asCUDXrl0xGAwEBAQwY8YMatSoAUCFChUwGAyEhoYyatQoateuzfTp0ylbtizu7u4888wzJCcnM27cOPz8/ChRogRjx45NqT8gICBN/SIiIiIikgP2/2p/LtcU3Evcvnyp2tBtqn17w6fXkqlu49QmwAZFAjPWxl3AfPsiIiIiIiJpRa1Ywbl33wXA6OaGNSaGq/N+pNjArC/P8F9X46+y+exmANqVa5fh84bWH8rfYX9zJvoMn+z4hFcbvnrLsjarleKb7V/guLRrk72Ac5l7SAgJ+/YTvXo1Xl3SmVZXRERERAokW1wcB+vWy/N2K23fhiEbswYZDAYGDBjAN998w9ChQ1P2z549mxYtWhAYGIjVaqVbt24UK1aMjRs3EhkZyeDBg9Otd+7cubi7uzNw4MA0x15++WUmTpzI/PnzU+qJiorixx9/ZNOmTVSuXJmYmBhWrVpF69atU527aNEiulz7e/l6G88+++wtry09Li4uAFgs6S9TYbVauf/++4mKimLWrFkEBgayb98+TCZTSpnY2FjGjx/PzJkzMRqN9OnTh6FDhzJ79uyU63v88ceZPHkyABMmTKBDhw4cPnwYNzc3/vrrL4KDg/nmm2+47777MJlMuLu74+/vT9u2bdm8eTP+/v4UL14cgKNHj/LHH3+wZMkSjh49So8ePTh+/DgVK1Zk9erVrF+/ngEDBnDPPffQuHFjtmzZQokSJVLVLyIiIiIiOWBfBpbL+68qnaBGT9jzI/wyCP63Gszp3NB9Yr39WcvlpdAMUSIiIiKSaXG7d3Pm5aFgs+Hdqxd+b40A4MqcOdj+80VBrCWWRUcXMXjlYH479lum2ll5aiXJtmQq+VSinGe5DJ/n7ujOyCYjAZi9fzY7z++8ZdlL2zbgFZFErCNUue+hTMWX19xDWgIQve5vbElJ+RyNiIiIiNxN+vfvz8GDB9m82X7DgsViYd68efTr1w+A5cuXs3//fmbOnEnt2rUJCQnh3Ws3UNzKoUOHCAwMxPEms7SWKlUKLy8vDh06lLLv+++/Jzg4mGrVqmEymXj44YeZNm1aqvMSEhJYunRpSkLUoUOHqFChQqpl+iZOnIi7u3vKIyIi4qbxnT59mg8//JAyZcpQsWLFdK9l+fLlbN68mQULFtCuXTsqVKjAAw88wP33359SxmKx8MUXX1C/fn3q1q3LoEGDWLFiRcrxNm3a0KdPH6pUqUKVKlWYOnUqsbGxrF69GoBixYoB4O3tjZ+fH8WLF8fFxYWiRYsCULx4cfz8/FISmaxWK9OnT6dq1ap06tSJ1q1bc/DgQSZNmkSlSpXo378/lSpVYtWqVSnn/7d+EREREREBrFY4thp+fg6WDre/zqjIMDi10b59u+Xy/uu+D8C1GJzfB2snpF/25Ab7c9mmmWvjDqYZokREREQkUxJPn+bUM89ii4/HLaQFfm+NwGa1Yho/nqRz54j88088O3Rg98XdLDy8kCWhS4ixxACw5vQaKhepTKB3YIbaWnYic8vl3ah56eZ0DuzMoqOLeGv9W/zY6UecTE5pyp1Y9AOuwMEq7tTzLp3pdvKSS62amLy8SI6IIG7nTlzr18/vkEREREQkEwwuLlTanoGlDnKh3ewqWbIkHTt2ZPr06TRs2JDFixeTkJBAz549Adi/fz9ly5alTJkyKec0aZK9O5NtNluqZKlp06bRp0+flNd9+vQhJCSEq1ev4u3tDcBff/1F0aJFU5aRg7SzQA0YMIDOnTuzadMm+vTpk2rZvYiICNzd3bHZbMTGxlK3bl0WLFhw06StG+3cufO2iVOurq4EBv77XqhkyZKcP38+5fX58+d56623+Ouvvzh37hzJycnExsZy8uTJdNu+lYCAADw8PFJe+/r6YjKZMBqNqfbdGIOIiIiIiNzg6knYORd2zrJvX+cTAA2fylgd+68to12mIXiWylz7bkWhw4fwU39YOx6qdgbfamnLWeLgzLXltjVDVAolRImIiIhIhiVfvcqpp/5H8qVLOFWtQumJH2EwmzEAPg8/zMVPPuXQFxMYY/mSYxHHUs4r414Gd0d3Dlw+wFvr3+K7+77DZEx/+YWoxCg2hNvvaGhfrn2W4h3WYBh/n/mb4xHHmbprKi/UfSHVcZvNBqvsd2ZEN6txsyoKFIPJhO+IETj4lsClVq38DkdEREREMslgMGRr6br89uSTT9K3b18++ugjZsyYQdeuXXG9dj03JhVdd7vl6IKDg1m3bh2JiYlpEo7CwsKIjIxMSTDat28fmzZtYsuWLbz66r9LYicnJzN37lyeeeYZIPVyeTe2YbFYcHBwAOwzIHl7e3P69Ok0MXl4eLB9+3aMRiO+vr64ubllpGtSltZLz/X2rzMYDKn6rV+/fly4cIFJkyZRrlw5nJycaNKkCYmJiRmKISPt3WyfNTN3t4uIiIiI3Oks8XBgMeyYBcdWAdf+ZnfyhNJ17fuWj4KK94J32dvXtz8Ly+XdqFpX+Ge+PaZfnoMnloPpP6k+Z7aB1QLufuBTPmvt3IGUECUiIiIiGWJNTOT0oOdJPH4cc8mS+H/+BSZ3N6w2K2tOr+GPMnt41ATuh8Mx7TuPc1kX2ge058GgB6nnW4/zsed58JcH2X1hN3MOzKFv1b5p2kg8cQLLmTMAbArbSJWjiZR0K4XvvrPEcDZT8Zp8fPCsXJkRjUcweNVgpv8znbbl2lK1aNWUMvF79+F6IYp4B/Btc1/2OiiPeD3QMb9DEBEREZG7VIcOHXBzc+Pzzz9nyZIl/Pbbv0tiV61alZMnTxIWFkapUva7njds2JBufY888giffPIJU6dO5fnnn091bPz48Tg7O/PQQ/ZlradNm0ZISAifffZZqnIzZ85k2rRpPPPMM9hsNn799Ve+++67NG1MmTKFF1988bbXaDQaCQoKum25/6pZsyanT5/m0KFDt11e71bWrl3LlClT6NChAwCnTp3i4sWLqco4ODiQnJycpfozIrfrFxEREREpsM7+A9tmwJ55EH/DstrlQ6BOX6j8AJidYUYH+/J0v74IfRZAejeCRJ+HE3/bt6t2zlpcBgN0nAChayFsB2z4FJoPTl3m+nJ55ZqkH89dRglRIiIiInJbNquV8NffIHbrVozu7vhP/QIH3xJEJEQwfN1wVp9eDUC5qgZa77Ex7HhVqg+djruje0odfm5+DKk3hHc2vsPk7ZNpVaYV/p7+Kcfj9+0j9KGHsVksAJQGRgBwmpPTnshS3I6BgdTu1o0uxVvyy5XVjFw/kjkd5+BgtN8VfXXJ7wDsCDTQtmzjLLUhIiIiInK3MJlM9OvXj9dff52goCAaNmyYcqxt27ZUqlSJxx57jAkTJhAZGcnw4cPTra9Jkya8+OKLvPLKKyQmJvLggw9isViYNWsWkydPZsaMGRQtWhSLxcLMmTN5++23qV69eqo6nnzyScaNG8euXbuwWCzExMQQEhKSqo2XX36Zl19+mRMnTtCtWzf8/f0JDw9n2rRpGAyGVEvIZVXLli0JCQmhe/fuTJw4kaCgIA4cOIDBYOC++zJ280VQUBAzZ86kfv36REZG8sorr6SZeSogIIAVK1bQrFkznJyc8PHxyXbseVm/iIiIiEiBY7XC2gmwciwps0F5+UPt3vaHT0Dq8p0/gc+bwdG/YOccqPPores+sBhsVihVJ2OzSd2Khx/c+659hqhV79mTs4rdcCPHiWsJUWW1XN6Nsv9OT0RERETueBcmfUzkb7+B2UyZTybjXLEiey/updevvVh9ejWORkf6VetH+1c+BsBrw36cLkenqadHxR409GtIfHI8ozaMSlkewmaxEPbGcGwWC+YSJXAIDuJkCQMnigOB5XCqWDHTD4OzM4lHj3L+ww959PVVvLHAgPvGfczY+bW9TZuNy3/Y72jfV8MTfw//NPGKiIiIiEhqTzzxBImJifTv3z/VfqPRyMKFC0lISKBhw4Y8+eSTjB079rb1TZo0iSlTpjB37lyqV69OlSpV+PDDD/nrr7/o06cPYF8G79KlS3Tt2jXN+cHBwdSoUYNp06bxyy+/0LFjR8zm1PcBjx8/njlz5rBjxw4eeOABgoOD6dmzJ1arlQ0bNuDp6ZmNHvnX/PnzadCgAY888ghVq1Zl2LBhmZptafr06Vy5coU6derQt29fXnjhBUqUKJGqzIcffsiyZcvw9/enTp06ORL3jSZMmJCr9YuIiIiIFCgxl2BOT1g5BrDZE436/gwv7obWb6RNhgIoFmw/BrD0dYhKZ3WLfdlcLu9GtR+FwDaQFA+LBtkTuQCsyXBqs31bCVGpaIYoEREREUnXlR/mcenLLwEo+c47uDZuzA8HfuCDLR9gsVrw9/BnQssJVClaBYATDRoQu2ULV+bMpcSQl1LVZTQYGdVkFN0WdWPz2c38dPgnelbsyaWvvybhwAFM3t6UX7iA5ZFbeGXNK5TzLMevD/6KIQtTvCZHRxP5++9EzF9A3K5d1D6YTO2DELFkMgcfPE3JBiEYz5wj0QzmZo2y1IaIiIiIyJ2qX79+9OvXL83+8PBwzGYzffumXQK7YsWKrF27NtW+6zdBgH32oRtfXzdgwAAGDBgAQGhoKC1btmTKlCk0a9YMk8lE9+7d000s2r17N2Bftu7NN9+8aZlevXrRq1evW9YBt77mjCpSpAjTp0/PcN0PPvhgqv6oU6cOW7ZsSVWmR48eAFivfdnRqVMnunRJ/WVK7dq10/TrqFGjGDVqVKp9M2bMSBPXqlWrUr3u1KkTnTp1uuk1iIiIiIjcUU5vhXmPQ+RpMLvYl6VLb7anGzUZBHsXQvhO+O1leGhW2qXqYi/D8TX27SpZXC7vRgYDdPoYpjSxL5G35Wto9D84uwcSo8DJE3yrZb+dO4hmiBIRERGRW4peu5azb78NQLHnnsPxgfa8tvY1xmwag8VqoY1/G75/4PuUZCiAIo8/BsDVefOwxsWlqdPf05/n6zwPwIStEzizZyMXp3wOgO/wNzAXLcqfJ/4EoG3ZtllOVDK5u+PTqxcBP3xPhd8WU2TAAGI9HPCKAevsBZwZPBiAXeUN1CjXMP3KRERERETucgkJCRw5coQRI0bQq1cvfH19c6WdgIAAVq1aReXKldm5c2eGz0tMTKR79+7cf//9uRKXiIiIiIjcIWw22DQVpt9nT4YqEghPLs94MhSAyQxdPgOj2b4s3t6Facsc+A1syeBbA4oG5kzs3mWh7Sj79vJRcOWEPTkKwL8RGE05084dQglRIiIiInJT8fv3c+bFwZCcjNeDDxLZ534e+e0Rfj/+OyaDiaH1hzKp9SQ8HVMvL+HeujUOZcqQfPUqEb/+etO6H63yKDWL1yQ2IZpDr7yIzWLBvWVLPB94gLikONadWQdAu4B2OXItToGB+A57hVLLfmfyQ25sCTZgM9oTrVbXMFDPt16OtCMiIiIicqeaO3culSpVIiIignHjxuVqW+XLl2fUqFHUq5fxv9MdHR0ZOXIkHh4euRLT7NmzcXd3v+mjWjXdhS0iIiIiUigkRMFP/eGPYWC12Jey+98q8Kue+br8qkOLofbt31+xL793o/05uFzejeo/AWWbgiUGfn0RTvxt319Oy+X9l5bMExEREZE0LOHhnBr4NNbYWFwbN2ZH/8aM/v0R4pLiKOFSgg9bfkhd37o3PddgMuHT51HOv/8BV2bOxLtnzzSzPJmMJt5p+g7T3uyCX2gkya7O+I0ehcFg4O8zfxOXFEdp99JULVI1R6+rpHcZ7nn0NUZXGI1PjIEiEVbOlfMg2Ds4R9sREREREbnT/HfJt+tLuN0tOnfuTKNGjW56zMHBIY+jERERERGRTDu3D+Y9BpcO22d2aj8GGj2ddqm7zGjxsj3x6fw+WPIqdP/avj/uKhxdad/O6YQooxG6fAqfN4VjK8FwbR6ksk1ztp07gGaIEhEREZFUkqOiOPW/gSSdP49jcBBzH/PntY1vEpcUR6OSjZjXad4tk6Gu8+7eHaOrKwmHjxC7YcNNy5SJMPHIteWzZ99jIsLLnqufE8vlpad7cHca+TXiipuNo6UM1C5RG5OmkRURERERkXR4eHgQFBR000e5cuXyOzwREREREUnPru/hqzb2ZCjP0tD/D2j8TPaSoQDMjvbkJIMR9vwIB5fY9x9aYp+BqnhlKF4x+/H/V9FAaP2GfdtmBZMTlE7/e5u7kRKiRERERCSFLTGR0y+8QMLhw5iLF+e35+ow+5R97euBNQcyte1UiroUvW09Jg8PvLp1A+Dyt9+lbcdqJXzEW5gSkzgW5MbiavG8t+k9EpITWHPaniWVU8vl/ZfBYGBk05G4mF0AqFtCbxJEREREJPfYbLb8DkEkR+l3WkREREQKlSMrYOFASIqDwDYwcA34N8y5+kvXgyaD7NuLB9tnh9qXS8vl3ajxc1CqzrUY6oLZKffaKqSUECUiIiIigP1D7fC3RhK7YSNGV1d8Pp3ArEv2uxnGhYxjUJ1BmZpJqUifR8FgIHr1ahJDQ1MduzpvHrGbN2NwcaHCux9iMpr588SfjN04lhhLDL6uvtQoViMnLy8Vfw9/xjYfS7NSzega3DXX2hERERGRu9f1ZdRiY2PzORKRnJWYmAiAyaSZdkVERESkEFg/2f5cqzc8+hO4Fcv5Nlq/AUUCISocfnsZjiy378/NhCiTGbp9DUHtIGRo7rVTiJnzOwARERERKRgufjaFiJ9/BpOJ0pM+Yr55H3FJcQR5B3FfwH2Zrs8xIAD3li2JXrWKyzNn4TfiTQAs4eGc/3A8ACVeGkyRmq0ZkDSAr/Z8xcIj9tmo2pZri9GQu7n77cq1o1253JmFSkRERETEZDLh7e3N+fPnAXB1dc2VJaHzi9VqJTExkfj4eIxG3Xeb2wpKf1utVi5cuICrqytms75eEBEREZEC7vx+OLbKvqRdq9cgEzd9Z4qDC3T+BGZ0gH9+su8rEgglquZOe9cVC4I+P+VuG4WY3rGIiIiICFcX/szFTz8FwO+tt3Bu3pQ5C8YC0Ldq3yx/cVPk8ceIXrWKqwsXUvzFFzB6eBA+ciTWmBhcatfG59FHARhYayArTq7gWMQxACUqiYiIiMgdwc/PDyAlKepOYrPZiIuLw8XF5Y5K9CqoClJ/G41GypYtm+9xiIiIiIjc1sbP7c+VO4JPudxtK6AZNHgKtnxlf121C+hv5nylhCgRERGRu1zMhg2EjxgBQNGnnsLnoV4sP7GcsJgwvJ286VC+Q5brdm3cGKfgYBIOH+bq/AWYfLyJWbMWg4MDJceOwXBtiQUnkxNvN3ubx/94nJJuJaldvHZOXJqIiIiISL4yGAyULFmSEiVKYLFY8jucHGWxWFizZg0hISEpywNK7ilI/e3o6KhZwURERESk4Iu9DLt/sG83eiZv2mw7Eg7/CRGnoUaPvGlTbkkJUSIiIiJ3sfhDhzj9/AuQlIRnhw4Uf2kwADP3zQSgZ8WeOJuds1y/wWDA57G+nB3xFpe/+w5rbCwAxQYNwikwMFXZWsVrsaDLAtwd3DHl1rS1IiIiIiL5wGQyYTLdWX/jmkwmkpKScHZ2zvcEnbuB+ltEREREJJO2fQNJ8eBXE8o1zZs2nTzgqb8g+hz4VsubNuWWlBAlIiIiUoBYzp7F6OaGycMjW/WcP3eMpIPbifUpgtl88y9ebBYL4aNGY42OxrV+fUq+/x4Go5F9l/ax/fx2zAYzD1d+OFtxAHh16sSFCRNJCg8HwKlqFYoO6H/TshW8KmS7PRERERERERERERERKeQSY/CMPQk2W+bPTbbA5q/t242fzdul69yK2R+S75QQJSIiIlJAWMLCONqhI87VqhEwe1amz09MTmTlqZX8fORnOr+9mqrnbYRNn3fb8xzLl6fMp59gdHQEYPb+2QC0D2hPCdcSmY7jv4zOzng/9BCXpk4Fs5lSY8di0B3NIiIiIiIiIiIiIiJyI5sNTm+BHTMx/7OA1onRJK+Pg1bDMlfPvl8gKgzcSkD1brkTqxR4mVro+7333qNBgwZ4eHhQokQJHnzwQQ4ePJiqjM1mY9SoUZQqVQoXFxdatWrF3r17czRoEREpPDR2iGRc7PYd2OLjidu2jaRLlzJ83sHLB3l/8/u0+bENQ1cPZd/+tQSct2EFwv0ccawYjFPFijd9uLUMwf+rLzF5ewNwMe4ifxz/A4A+Vfrk2LUV6fc47q1b4zfyLZyrVMmxeuXOo3FDREQyS2OHiIhkhsYNERHJLI0dInkg6hz8/TF81hCmtYPt32FIjAbAuGYcnN+fufo2fWF/bvAEmJ1yOFgpLDKVELV69Wqee+45Nm7cyLJly0hKSqJ9+/bExMSklBk3bhwTJ07k008/ZcuWLfj5+dGuXTuioqJyPHgRESn4NHaIZFzCoUMp27Hbt6dbNiIhgrkH5tLr1170+LUHs/fPJiIhghKuJXjW0BqAU75GXuxv5Y/R7amw6JebPspOnYpjmTIp9c47OA+L1UKt4rWoUbxGjl2b2ccH/8+n4NOzZ47VKXcmjRsiIpJZGjtERCQzNG6IiEhmaewQySXJFjjwG8x9BCZWgWVvwcVD4OAKtXqT1OcXznrWxmC1wC/PgTU5Y/We3mqfZcrkCPUH5O41SIGWqSXzlixZkur1N998Q4kSJdi2bRshISHYbDYmTZrE8OHD6dbNPu3Yt99+i6+vL3PmzGHgwIFp6kxISCAhISHldWRkJAAWiwWLxZLpC7p+TlbOlcxRX+ct9XfeKUx9XRhiLOhjR2H6ed8JClp/Ry9fTuy6dRR79VWMLi75HQ5xh/69qyh68xZcWrVKdTzZmsyWc1v45dgvrDy1kkRrIgBmo5nWZVrTuUJnGvs15vK77xMBWMoHA0eZtmcarUu3pqJPxXTbT0xO5IeDPwDwcMWHC8zPqTAoaL/bt1LQ44PcGTdAY0dhpb7OW+rvvFOY+rowxKj3HHIj9XfeUV/nrcLS3wU9PtB7DklNfZ231N95pzD1dWGIUe855Ebq7xxw4SDG3XMw7pmHIeZCym5r6QZYa/XGVvVBcPLAYrGwy78fvodHYDizjeS/P8Ha+LnbVm/a8BlGwFqtG8lOPqCfVYYUlt/tzMSXqYSo/4qIiACgSJEiABw/fpyzZ8/Svn37lDJOTk60bNmS9evX3/Q/+/fee4/Ro0en2f/nn3/i6uqa5diWLVuW5XMlc9TXeUv9nXcKQ1/HxsbmdwiZVlDHjsLw876TFIj+ttmo8O57mCMjOQRENmyY3xFRftduHK5tn1u5ki3VqwFwOfkyOxJ3sD1xOxG2iJTyfkY/6jnVo6ZDTdwi3YjYGcFSllJu9WqcANfA+lR1cGKfZR9D/hzCQPeBmAymW7a/PXE7l+Mv42nwJPGfRH7f+3suXu2dqUD8bqfjbh03QGNHYae+zlvq77xTGPr6bh07NG4UfurvvKO+zlsFvb/v1nEDNHYUdurrvKX+zjuFoa/v1rFD40bhp/7OHHNyLKWvbKLspTUUiT2asj/e7MWpIs04WbQF0c6lIRwIX/vviY5F2OnbkzqnpsNfY1gd7kqMk+8t23FOvEy7vb8AsCahKhG/63uOzCrov9uZGTeynBBls9kYMmQIzZs3p3r16gCcPXsWAF/f1L+Avr6+nDhx4qb1vP766wwZMiTldWRkJP7+/rRv3x5PT89Mx2WxWFi2bBnt2rXDwcHh9idIlqmv85b6O+8Upr6+fsdAYVEQx47C9PO+ExSk/k48dpyT1/4NBV6NoGSHDvkajzUmhmOvvpby2jk8HALi+Tl8CVvPbU3Z7+Hgwf0B99M5sDNVfKpgMBhS1ZMcEcnx114HIK58AOPve5yHlz5MWGIYFwMu0r9a/5u2b7PZmLVkFsTC4zUfp1O1TrlwlXeugvS7nZ67ddwAjR2Flfo6b6m/805h6uu7dezQuFF4qb/zjvo6bxWW/r5bxw3Q2FFYqa/zlvo77xSmvr5bxw6NG4WX+jsTbFYMJ9dj3DUHw/5fMSTF2XcbTNiC22Ot+QimoHYEmBwIuMnp1/u60sNjsP54BFPoGtpELyT5wZ/BYLxpk8aVYzGSjLVsE5r1eDbXLu1OVFh+tzMzbmQ5IWrQoEHs3r2bdevWpTn23y/mbDZbmn3XOTk54eTklGa/g4NDtjo5u+dLxqmv85b6O+8Uhr4u6PH9V0EeOwrDz/tOUhD6O2rrlpTtuA0bMNtsGBwd05RLsiZxPOI4Qd5Bt/ydzAlxoaH2jWI+xNgScbsUww8L32ZPeSMGDDQp1YQHgx6kTdk2OJnS/v5fF79nN9hsOJQrR7KHB34efrza8FWGrxvO1D1TaVu+LRW8KqQ5b+vZrRy4cgBnkzO9KvfK959PYVUQfrfTU5Bju5mcGjdAY0dhp77OW+rvvFMY+rqgx/dfes8h16m/8476Om8V9P4uyLHdjN5zyHXq67yl/s47haGvC3p8/6X3HHJdoevvi4fBqww4uOR+W9HnYdu3sHMWXAn9d3+xSlCnD4aaD2Hw8OXmKU1pOTg6YuzyCUxpgvHkeoy7ZkKDJ9MWTIyFHd8CYGz8LMbC9PMpQAr673ZmYsvo71gqzz//PIsWLWLlypWUKVMmZb+fnx/wbxbsdefPn0+TESsiIncXjR1S0MRu3JiybY2NJXbbtpuWe33t63Rb1I2lJ5bmajzxhw4BsMvjKtv87NN9NjznwXO1n2Np96VMbTeV+8vfn24yFEDctetwrls3ZV+nCp1oVroZidZERv49kmRrcprzZu2fBcADgQ/g7eydE5ckki0aN0REJLM0doiISGZo3BARkczS2CGF1o7Z8Gl9+O3l3G/LZoMZHWHlGHsylKMH1OsHT66A5zZBsxfAIwv/LnwC4J6R9u1lI+HqqbRl9syDuMvgXRYqd8zGRcidIlMJUTabjUGDBrFgwQL++usvypcvn+p4+fLl8fPzS7WmYGJiIqtXr6Zp06Y5E7GIiBQqGjukILIlJxOzaTMATsHBAESvXpOm3J+hf7IkdAkAfxz7I1djSjh8BICTxeFixRIAdI2txNO1nqake8kM1xO7bTsALjckRBkMBkY2Homr2ZWdF3by/cHvU51zOuo0K0+tBKBPlT7Zug6R7NK4ISIimaWxQ0REMkPjhoiIZJbGDinUIsNgyWv27X2/QFJi7rZ3+RhcPARGB3jwCxh6EDp9DGXqQ3ZX4Wj4P/BvBInRsHiwPfnqOpsNNn7xbzmjKXttyR0hUwlRzz33HLNmzWLOnDl4eHhw9uxZzp49S1ycfa1Hg8HA4MGDeffdd1m4cCH//PMP/fr1w9XVld69e+fKBYiISMGmsUMKovh9+7FGRmJ0d6fo0wMBiF6TOiHqavxVxm4am/J6Y/hGEpNz741CwrUZok4WN1C+xf0AxO3ajS0x421a4+OJ++cfAJzr1kl1rKR7SV6ub7/74+PtH3M66nTKsbkH5mK1WWlSsgmB3oHZug6R7NK4ISIimaWxQ0REMkPjhoiIZJbGDim0bDZY/BIkRNpfJ0bDyQ252+axVfZn/4ZQ+xFwdMu5uo1G6PwpmJzgyHLYdcPN38dWwYX94OAGdfrmXJtSqJkzU/jzzz8HoFWrVqn2f/PNN/Tr1w+AYcOGERcXx7PPPsuVK1do1KgRf/75Jx4eHjkSsIiIFC4aO6Qgitlo/4PftWFD3ENCwGQi8dgxEk+dwtHfH4APtnzA5fjLBHoFEpEYwcW4i2w7t40mpZrkeDw2my0lIepUcQO1GnTE5P0zyVevEr9vHy61a2eonrjdu8FiwVS8GA7+/nAtOeq6HhV78MfxP9h6biujNoziq3ZfEZsUy8LDCwHoU1WzQ0n+07ghIiKZpbFDREQyQ+OGiIhklsYOKbT2/ASHlthnayrTAE6uh8N/QoWWudfm8dX25/K51EbxitDqNVgx2j7zVWAb+xJ8m67NDlXnUXDxzp22pdDJVEKU7cYpx27BYDAwatQoRo0aldWYRETkDqKxQwqi2A0bAXBr3BiThweudesSu2UL0avXUKTPo6w5vYbFxxZjNBh5u9nb/HToJxYeWcjaM2tzJSEq+dIlkq9cwQpElPKgctEqhNWrR/SKFcRu25bxhKht2wBwrVcfw02mnjUajIxuOprui7qzKXwTCw4vICE5gShLFAGeATQv3TwHr0okazRuiIhIZmnsEBGRzNC4ISIimaWxQwql6AvwxzD7dsthUKzivwlR945N/9ysslrh+Fr7dm4mXTV9Afb9DOG74PeXoe1oe+IXQMOBudeuFDqZWjJPREREpLCzJiYSu307AG5NGgPg3jIEgOjVq4lKjGL0htEA9KnSh5rFa9KiTAsA1p5emysxXZ8d6qwP1PZvhMlowrVePQBit27LcD3Xy14/92bKepZlUJ1BAIzfOp7v9n0HQO8qvTEa9KehiIiIiIiIiIiIiEih98crEHcZfKtD85cgsDUYTHDxEFw+njttnttjb9PRHUrf+nuKbDOZoctnYDTD/l/hx8ft+4PvhWJBudeuFDr61ktERETuKnE7dmKLj8dUvBiOQfY/jN1b2u9UiN20iY/Xj+N87Hn8PfxTEocal2yM2WAmNDKUU5GncjymhMOHAftyeY1KNgLAtf61hKjt27FZrbetw5aURNyOHanOvZU+VfpQs1hNoi3RnIk+g4eDB10Cu2TnEkREREREREREREREpCDYvxj2LrQnQHX5FEwO4OwFZa+tgHF4We60e3yN/blcU3ubucmvBjQfYt8+u8f+3Pjp3G1TCh0lRImIiMhdJWbjBgDcGjVOWVbOMSgIc6mS2BITObRiAQCjm47GxewCgIejB3V96wKw5syaHI8p9uABAE4WJyUhyrlKFQwuLlgjIkg4cuS2dcQfOIg1NhajuztOFSumW9ZkNDG66WjMRvvqyd2Cu+Hq4JrNqxARERERERERERERkXwVdwV+u5Yo1OwFKFXn32MV29ufD/+ZO20fW21/Lp+Ly+XdKGQoFK9s3y5eGSq0zpt2pdBQQpSIiIjcVWI3bAT+XS4P7Ou7O7doBkDdIzZ6VexFA78Gqc5rUfrasnlncn7ZvKv7dgEQUcaL8p7l7TE5OOBSqxYAcdeW+EtP3Hb7cnkudepgMJluWz7IJ4jRTUfTonQL+lXvl8XIRURERERERERERESkwFg6HKLPQdFgaPla6mPB1xKiQtdCYmzOtpuUCCfW27cr5FFClNkJekyHCq3g/nFw7SZ4keuUECUiIiJ3jeToaOL22KdOdWvcONWxFaWuAFD/uJHBdQenObdFGXtC1JbwLcRacu6Ngs1qheP2ZfiKVauXMmsVgGu9a8vmbd1223qul7l+TkZ0DuzMlLZTKOZSLDMhi4iIiIiIiIiIiIhIQXNkOeycDRjsS+U5OKc+XrwyePlDUrw9KSonndkGlhhwLQolquVs3enxrQaP/ZJ3SVhSqCghSkRERO4asVu2QHIyDmXL4lC6dMr+ned38plxNYkmKHo1GcdT59KcW8GrAqXdS5NoTWTL2S05FpPl9GlMCUkkmqBKrdTTubrWv5YQtS39hCibzZZS5vo5IiIiIiIiIiIiIiJyl0iIgl8H27cbDYSyjdOWMRj+nSUqp5fNO35tubyAFmBUGooUDPpNFBERkbtG7MZry+XdMDtUQnICb61/i3hHuFDFF4Do1avTnGswGGheujmQs8vmXd2/G4AzxaBxmWapjrnUqgVmM0nh4VjOnLllHYmhoSRfuoTBwQHnGjVyLDYRERERERERERERESkElo+CiFPgXRbajLh1uesJUYf+BJst59o/du17Fc3UJAWIEqJERETkrhGz4VpCVJN/E6Km7prK8YjjFHUuSpWOjwIQvXrNTc8PKRMCwJrTa7Dl0BuF0O32ti6XcsfPzS/VMaOrK85VqwLpzxIVd+2Yc82aGJ2cciQuEREREREREREREREpBEL/hi1f27c7fwJO7rcuW74FmJwg4iRcOJgz7SfGwOlrK2uUV0KUFBzm/A5AREREJDdcirvEoSuHUl4brkTidcj+el85I7awDVyJv8L0f6YD8GbjNylurETkBxOJ3b6d5KgoTB4eqeps4NcAJ5MT4THhHL16lCCfoGzHGbl/Dx6AQ/DN63KtV4/43buJ3boNr86db1omduu2lLIiIiIiIiIiIiIiInIHsMTDma2QbEmnkA1+e9m+WfcxqNAq/Tod3exJUUeWw+GlUKJy9uM8sQGsFvDyhyIVsl+fSA5RQpSIiIjccRKTE+n9W2/CYsJS9jXdZ2UwEFoChm0Zmqp8u3LtaFuuLQCO5cuTePw4MX+vx/O+e1OVczG70MCvAevOrGPNmTU5khBlDrXHWLJGo5sed61fj8vffEPs9lvPEBW7fXtKWRERERERERERERERuQP8/jLsmJWxsh4lof2YjJUNbn8tIWoZNHsx6/Fdd3yV/bl8SzAYsl+fSA5RQpSIiIjccZaGLiUsJgwXswtlPMoA0Cw8HLjK6UpFCPbxTSlbzLkYwxsNT3ntHhLC5ePHiV6zJk1CFECL0i1Yd2Yda0+vZUD1AdmK80JEGMUuJAJQrWGHm5ZxqVsXgMQjR0m6cgWzj0+q45bz57GcPAkGAy61a2crHhERERERERERERERKQAiw2HX9/btElWBdBKNzI7Q7m1w9spY3cHt4A/g5AaIj8j4ebdybLX9uYKWy5OCRQlRIiIickex2WzM3DcTgKdqPMVTNZ8C4Mgn7bFwlYcfHctTrVrd8nz3Vi25/O23RK9dg81qxWA0pjreokwL3tv8HjvO7yAqMQoPR49b1HR7O7f+RhkbxDkbKVI2+KZlzD4+OAYGknj0KHHbt+Nxzz2pjsdts88c5VSpEiZPzyzHIiIiIiIiIiIiIiIiBcTWaWBNgrJNYMCSnK27SAUoGgyXDsPRlVDtwazXFXsZzu6xb5cPyZHwRHKK8fZFRERERAqPHed3sP/yfpxMTvSo2AOAxNNnsJw6BWYzrvUbpHu+S716GF1dSb5wkfh9+9Mc9/fwp7xXeZJtyawPW5+tWE/uXAdAXNniGNKZRta1nn0pvNitaZfNu77vehkRERERERERERERESnELPGwdbp9u/EzudNGcHv78+Fl2avn+BrABsUrg4dftsMSyUlKiBIREZE7yqz99vW0H6jwAD7O9uXlYjduAMClRg1M7m7pnm90dMS1aRMAotesvmmZFqVbALD29Nosx2mz2Yg9cMAeV6XK6ZZ1rX8tIWrbTRKiru27XkZERERERERERERERAqxPT9C7CXw8odKHXOnjeB29ufDf4LVmvV6jl/7HqW8lsuTgkcJUSIiInLHCIsOY8XJFQA8WuXRlP0xGzYC4NakcYbqcW9p/8M9ZvWamx4PKWOf9nXdmXVYbVl7o3A6+jQ+YVEAlK6ZflzXZ3+K37cPa2xsyv7kyEgSDh4E7DNbiYiIiIiIiIiIiIhIIWazwcbP7dsN/wcmc+60U64pOLpDzHk4uyvr9Ry/9j1KBSVEScGTS/96RERE5G6SZE1iz8U9xCfFp1/QChabJdfi+P7A91htVhqVbESwTzBgn4kpZtMmAFwbZzAhKsSe8BS3ezdJly9jLlIk1fG6Jeri5uDGpfhL7L+0n2rFqmU61k3hmyh7wQaAR5Xq6ZZ1KF0ac8mSJIWHE7d7N27XriNu506w2XAoWxaHEiUyHYOIiIiIiIiIiIiIiFxz/gBEhadbxJCcjJMlIvdiCF0L5/eCgyvU7Zt77ZidoEIrOLDYvmxeqTqZryPiDFw6AgYjlGuW4yGKZJcSokRERCTbvvnnGybvmJyhsrUdatOFLjkeQ6wllp8O/wRA3yr/vklIOHyY5IsXMTg741K7dobqcvD1xalKFRL27ydm3Tq8OndOfdzkQJOSTVh+cjlrzqzJUkLU9mPr6Btp33YKDr5tedd69YhcvJjYrdtSEqJit25LOSYiIiIiIiIiklmfrTzCnE0nebtLNe6p4pvf4YiIiOSfsB3wZWvAlm4xM9DSoQgkdQUHh5yP4/rsULV7g4tPztd/o+D29oSoQ0uh5bDMn399ubxSdcDFO0dDE8kJWjJPREREssVms7Ho6CIA/D38CfYJvukjyDsIgN2W3ZyLPZfjcSw6uoioxCjKepSlRZkWKftjN9qXy3OtVw+jo2OG67s+S1T0LZbNu97GutPrMh2r1WYlfM9m+3ZxH0xeXrc9x7VeXQBit21N2Re7bVuqYyIiIiIiIiIiGXXsQjQTlx3izNU4Bs7cxi87z+R3SCIiIvln9zzABm7FoUS1Wz5sDm64WC5j2Lsg52O4fAwO/mHfbvR0ztf/X8Ht7M9ntkHMxcyff+xaQlR5LZcnBZNmiBIREZFsOXL1CKGRoTgYHZj3wDzcHd1vWbbfH/3Ydn4b8w7NY0iDITkWg9VmZfb+2QD0rtIbo+HfnO+YDfaEKLcmGVsu7zr3liFcmjqV6HXrsCUlYTCn/rOpeenmAOy5uIfL8Zcp4lzkZtXc1OErh/E+Y59S171S1Qyd43JtFqi4nbuwWSzYrFbid+9OdUxEREREREREJKMm/HmIZKsND2czUfFJDP5hJ5HxSfRtXC6/QxMREclbVivs+8W+3eljqNzx1kVXT8C08m1Mm7+Eeo+BwZBzcWz6ErBBUDsodvuVJbLNsxT41oBze+DICqj1UMbPtdn+nSGqghKipGDSDFEiIiKSLctOLAOgWalm6SZDAfSu1BuABUcWEJcUl2Mx/H3mb0IjQ3F3cOfBoAdT9tuSkojdsgUA18ZNMlWnS61amLy8sEZEEHct8ehGJVxLUKVIFWzY+PvM35mqe1P4Jvwv2Kfdda5YKUPnOAUFYfTywhYXR/z+/cTv2YPNYsFUtCiOAQGZal9ERERERERE7m67Tl3ltz3hGAzww/+a8HiTcthsMOLnf/hs5RFstvSXCxIREbmjhG2HyDPg6A6BbdItaq3TlySDI4bz/0Bo5leQuKX4SNgxy77d+Jmcq/d2Kra3Px9emrnzLh6GqHAwOYF/o5yPSyQHKCFKREREsuV6QlTbcm1vWzakdAg+Rh8iEiP47dhvORbD9dmhugZ3xc3BLWV//D//YI2OxujlhXOVypmq02Ay4dbcPgtU9KrVNy1zfZaotafXZqruTWc3UfZaQpRTxYzd5WEwGnGte23ZvK3biN16fbm8ehhy8g4UEREREREREbmj2Ww2PlhyAICudUpTtZQnozpX44U2QQB8uPQg7/1xQElRIiJy97g+O1Rwe3BwSb+siw+nijSzb2/6Iudi2DkbEqOgWKXbJmXlqOBrCVFHVkByUsbPuz47lH/D2/eZSD5RQpSIiIhk2bGIYxy5egSzwUwr/1a3LW8ymmjsaF+6bta+WTnywdqxq8f4O+xvjAYjvSv3TnUsZuO15fIaNsRgMmW6bveWIQBEr1lz0+MhZezH14WtI8masTcKFquFreFb8L9gf+1csWKG43Gtb18aL3b7NmK3b0u1T0REREREREQkI9Yevsj6o5dwNBkZ0s7+uYTBYGBI+0q82bEKAF+uOcZr8/eQbFVSlIiI3OFstn8Toqp2ydApx4tfSyI68BtcPp79GKzJ/yZXNX46Z5fhu53S9cHZG+KvwuktGT/v2Cr7s5bLkwJMCVEiIiKSZctPLAegUalGeDl5Zeicek71cDW7cjTiKBvCN2Sp3cTTp7GEhQH/zg7VqkwryniUSVUuZoM9Icq1SeMstePWogUYDCQcOEDksmXErF+f6lHhUDSNT7sQcDCCf5bPw2ax3LbOvRf34hgRi2ccYDTiWKFChuNxrWdPforbuo247TsAcKmnhCgRERERERERyRir9d/Zofo0LkcZH9dUx59sUYFxPWpiNMAPW0/x/NztJCQl50eoIiIieSN8F1w9AWYXCG6XoVOiXEpjrdAasMHmr7Ifw6GlcCXUnphU8+Hs15cZJjMEXVsB5PCfGTvHmgyh11bOKN8qN6ISyRHm/A5ARERECq/rCVHtymbsTQKAs8GZzhU68/2h75m9fzZNSzXN8Lk2m40rM2dybtyHkJSEY4N6XCz1D47BNvpU7ZOqrDU+nrgd9qQht8ZZS4gy+/jgUrMmcbt2ceb5F25aZsj1je/f4fzjJ/F9/bV069wYvpGy5+13VzqWK4fR2TnD8ThXrYrB2Znkq1cBMLq64lypUobPFxEREREREZG72+I94ewNi8Tdycyga0vk/Vev+v54Opt5Ye5Oft9zlqj4rUztWw9XR32lJCIid6D9i+zPwW3B0S3Dp1kbDMR4bCXsmAmtXwcnj6zHsHGK/bleP3B0TbdorghuD//8BIeXQduRty8fvgviI8DJE0rVyf34RLJIM0SJiIhIlpyKPMX+y/sxGUy0KZu59awfrvgwBgysOb2G0IjQDJ2THB3NmRcHc+7d9yDJvjxd4pZtPP1LAl9/aqPM54uJ2707ZRm+uO3bsSUmYi5RAsfy5TMV342KDXoO52rVcKpY8aaPhAA/Thazl708Zw6WM2fSrW9T+Cb8L9q3nTKxXB6AwdERl5o1U1671KmDwawPI0VERERERETk9hKTrEz48yAA/wupQBE3x1uWva96Sab3a4Cro4m1hy/S5+tNRMTefmZskcLkYnQCczefJDYxKb9DEZH8YrPB3p/t21UfzNypgW2gaBAkRMLOOVmP4ew/9tmWDCZo+FTW68mOoHsAA5zbAxHpf8cBwPHV9udyzewzTIkUUEqIEhERkSxZdnIZAPX96uPj7JOpc8t6liWkTAgAcw7c/o1C/MGDhHbvQdSff4KDA75vvkm55UtZ3MaDc97gHG/l6g/zCO31EMc7d+bSNzOIXGqf2tWtSWMM2Vhv271FC8rP/4kKi3656SPg54W88pQDe8oZwGLhwpQpt6wrLimOXRd2pcwQ5RQcnOl4XOvXu+m2iIiIiIiIiEh6vt9ykhOXYinm7sQTzW9/81jz4GLMerIRns5mtp+8ykNfbuBCVEIeRCqS+05ciqHrlL95fcEeJv55KL/DEZH8cn4fXD4KJif7LEmZYTBCo6ft25u+AKs1azFs+tz+XLUzeJXJWh3Z5VYMytS3bx9Zdvvyx64lRFVomXsxieQAJUSJiIgUIFfir/DqmldZcnxJfodyW1lZLu9G15e4+/nIz0QmRt6y3NUFCwnt9RCJJ05gLlmSgFkzKdLnUdYk7eO7RnGMerE4Jad/hWfnThicnUk4fITzH3zA1R9+AMC1cZMsxZdR3s7e1Cxek+9b2v+silj4MwnHjt+07I5zO7BYLQRest8x4VQx8wlRLvXq3XRbRERERERERORWYhKSmLziMAAv3hOEm1PGZnOoW9aHeU83obiHEwfORtHzi/Wcuhybm6GK5LoDZyPp8cUGTl2OA+CHLaeISdAsUSI5xmaDFe/AnyPs2wXZvmvL5QW2AWfPzJ9f6xFw9oLLx+Dwn5k/P+Yi7P7Rvt3omcyfn5OuJ4RtmwFhO279s0tKgJMb7dvllRAlBZsSokRERAqQdze9y+/Hf+et9W9xKe5SfodzS2HRYey5uAcDBu4pd0+W6mjk14gg7yDikuJYeHhhmuPW+HjChg8n/I03sCUk4NaiBeUXzMelVi0AZu+bDUDPKg/h3bQ5pceNI3jtGvxGj8a5ln1ZOYOLC27NmmbxKjPu/vL3c7i0gS3BBrBaWfp/9u47Korza+D4d3bpvRcRUOy99941Glts0SQSE6MxzZjqm6Zpv/RYolFTxESjxl6iUWPv2DuISBNEQHpfdvf9YxRDBANKjfdzzh6W2WeeuTOUgdk7977rz46IHej0BUvJH409imIwUi1BvVPkvipENW+O1sEBrbNzgfZ5QgghhBBCCCGEEEX56UAYCem5+DpbMaatT4nWre9hx+rJHfB2siT8ZiYjFxzmSlxaGUUqRNk6GZnE6IVHiE/Lob6HLb7OVqTl5LH2VDFaRAkhiufMCtj/FRyaA0GbKzqae7u4Qf3YcMj9rW9uAy2fUp8fKbp7RJGOLwZ9DlRrCd5t7y+G0tJgMGjN1GSoRd1hQWc48j1k/OO9qmvHIC8LrN3ArUGFhCpEcUlClBBCCFFJ7IrcxZ/hamWorLwsfjr/UwVHVLTb1aFaurfExdLlvuZQFIUnGqhVon679Bt5hjt3YeWGhxM+5nFS1qwFjQbXqa/gvXABJo5qa77zCec5HX8aE40Jo+uNzl9Pa2uL4+hR1Fy5Er8tW/Bbvw5TN7f73c1iG1t/LJ90/oSzQxthAOqcjGPOilfptaoXnwd+zuUktez20etHcU8Gk1w9ioUFZj4luwAJoLG2puaa1dRc9TsaC4vS3REhhBBCCCGEEEL859xMz2HRvqsAvNa3Hqbakr815OtszapJHanjZkNsajYjFxzm7LXkUo5UlZiRK9V6RJk4EJLAEz8eJSVLR0sfB1Y+14GnO9YAIOBgGMbKXslGiKog7Qb8+fadz3d9DAZ9xcVzL/GXIf4SaEyhXv/7n6ftc2r7vLC9cONi8dfLy4VjP6jP208BRbn/GEqDW33w/wMaj1BbCN44r34tv64Hvz8FITvUr+Xtdnk1u1Z8zEL8C0mIEkIIISqB1NxUPj7yMQB9NU0wzzWyMmglsRmxFRxZ4f6KvNUuz/f+2uXdNtBvIA7mDsRkxLAnag8Aqdu3EzZiJDlBQWidnPD56UdcJk9G0dz5s2XppaUADKgxoMiELHO/mpj5+j5QfMWlKAqDaw3mq2dWYdqvOwBPHTAhKSeJpZeW8tjGxxi9eTQXb17EO169sGJeqxaKVntf2zP18sK0WrXSCl8IIYQQQgghhBD/YfN2h5Kek0djLzsGNfG873k87C34fVIHmlW3JylTx9gfjnI4tPQqnJ+PTuGF307S+uMdDP7uANm6SvoGuqiS/jx/nQkBx8jM1dOljgtLn22HvZUpj7Wqjo25CaHxGRy4klDRYQpR9W15HbKTwb0JWDhAfBCcW13RURXu0q3qUH7dwNLx/udx8IH6g9TnR78v/noX10P6DbDxuP8KVaXNuy2M+AleD4ZHvgLP5mDQqZW0lo2AbxvDqV/VsX7SLk9UfpIQJYQQQlQCXx37iviseAZFuvDsp6f5YKstuYZcFp5dWNGh3eVGxg1OxZ0CoJfP/bXLu83CxIKRdUcCapJT5vHjRL/8Cob0dCxbtaLmurVYd+iQP95oNLL04lL+DFMraY1rOO6Btl8Wakx7G7RaGofksNDtVfr49sFEY8LFmxcxYqRZqgNwf+3yhBBCCCGEEEIIIUoiKjGTpUciAHirf300mger5OBobcayie3p4OdMek4e4xcH8tfFG/c9n9Fo5OCVBJ786SiD5h7gj7PXMRghND4jP24hHtSq41FMWXaSXL2BAY09+HF8a6zMTACwtTBlRKvqAAQcDK/AKIX4D7iwHi5tBI0JDPseOr2iLt/zqVoNqbJ50HZ5f9d+ivrx7O93t5grTMRh2P6u+rzts2Bi9uAxlCZLR2g7ESbthckHoN3zYOkEaTGQdl0dU1MSokTlJwlRQgghRAU7FH2IdVfWYZsJT27JBKOR2heTcU02si5kHZGpkRUdYgE7I3cC0My1GR7WHg883+h6ozFRTDgRe5yILz4BwO6RAfgGLMbU3T1/XHpuOq/tfY3Pj32O3qhneJ3hNHJu9MDbL21mvr44DB8OgNey3Xzd7Wt2jtzJm23epFO1TnTJUdvkmdetW5FhCiGEEEIIIYQQ4iHw7Y7L5OoNdKrtTJc6rqUyp425CYufbkOfhu7k5hmYtPQE609Fl2gOvcHI1nPXGTLvION+PMr+kAS0GoUhzavxYo/aAMzbfYXUbF2pxCweXj8dCOON1WcxGGFU6+rMfbwF5iYFq7Y/1UGtMr8rOI6ImxkVEaYQVV9molodCqDzq+DRBNpNAms3SAq/U1Woski8CrHnQNFCvYEPPp9Pe/BsBnnZcGJx0eOMRjg4BwIGqtWhXOtDm2cffPtlyaMJDPgMXguCkUugwaPQeRo4lk+HDiEehCRECSGEEBUoU5fJzMMzAfjgmA9KUmr+a09GeqM36pl3el5FhVeo0mqXd5u7tTt9avSh+VUjnA1CMTfH7a23UUxN88cEJwYz5o8x7IjYgYnGhOltpzOjw4xS2X5ZcJnyPIqZGZnHj5Nx8BBOFk482aSdTpAAALZySURBVPBJFvRZgH20+jWWhCghhBBCCCGEEEKUpUvXU1l3Wk1Ueqt//VKd28JUy/fjWjK8pRd6g5GpK0/zy+Hwf10vJ0/P8sBIen+zl+eXneTstRQsTDWM7+DLnte7M3tMC6b2rkMtV2uSMnX8sO9qqcYtHh5Go5Fvtgfz0eaLAEzsUpPPH2uKifbut0b9XG3oXs8VoxF+OSyVyYS4L39Oh4x4NcGn6xvqMjPrO8/3fgG6rIqL758ublQ/1ugM1s4PPp+i3KkSdexH0BeS0JuVDCufgB3vgVEPTUbCszsfrF1feTIxh0ZDYfRS6P1BRUcjRLGYVHQAQgghxMNs1slZxGTE0DvaCZ9DV0GjwXHsWJKWLqX9qSxoYmRr2FYmNJ5APad6FR0uCVkJnLhxAoDevr1Lbd4n6o0l6r1NAFiMGY6pu1v+a+uvrOfjIx+To8/Bw9qDr7t9TVPXpqW27bJg6umJ4+OPk7hkCfHffot1p44oioIhJ4fcCPWiirTME0IIIYQQQgghRFkwGo3sD0ng0y2XMBphYBNPmlZ3KPXtmGg1fDWiGXYWpgQcCuf9DRf4clsw92rKl6s3kK0zAGBvacr4Dr6M71gDZxvzAvO+0a8+k5ee4Mf9YTzZ3hc3O4tSj19ULnl6A1vOx7L4YBhWZlrmjGlR4PuiJAwGIx9uvkjAoXAAXu9blxd61EZRiv7u9O9Ygz3B8fx+LIppfepibS5voQpRbJe3w9kVoGhgyDw1cea2VuPh0FxIiYTAH6DTyxUX59+VZru82xoNg+3vqS3lLm6AJiPuvHb9DPz+lFotS2sG/T+D1hPURCohRJmRClFCCCFEBTlx4wTLg5ZjmWPk2a3q3QJOTz2F27RX0VhbQ8wNnsprixEj353+roKjVe2K3IXBaKCRcyO8bLxKbd4ap2LxuwGZZrC9szUA2XnZvH/wfd47+B45+hw6eXVi1aBVlT4Z6jbnSc+hsbIi+8IF0nbsACD36lXQ69Ha22PiVjpl6oUQQgghhBBCCCFATSjZeCaGQXMP8NTPgQTFpmFrbsLr/cruJjuNRuGDRxsytXcdFAXSsvNIvccjW2fA096Cdwc24NDbPZnWt16hSS/9GrnTwseBLJ2eObtCyix+UfGydXp+PRJBz6/38vLyU5yKTObglZuMXHiYmOSSV5PR6Q28tupMfjLUh0Ma8WLPOvdMhgLoWseVmi7WpOXksfbktfvZFSEeTtmpsHmq+rz9FKjeuuDrJubQ/W31+YFv1PEVLTkSYk4Citr+rbSYmN9pf3dkvvrRaIQTAfBjHzUZyt4HJmyDNs9IMpQQ5UDSm4UQQogKkJ2XzQeH1JKi7530RRN/FVMfH1xfeRmNpSW2A/qTsnoNQ4JtWdpEw56oPZyNP1vhyUB/Rajt8kqzOpQxL4/42XMA2NxWw66YjfRMGsLb+98mOCkYBYUXmr/AxKYT0ShVJ5fbxMkJJ//xJMz/nvjZc7Dt1Yucy5cBtTrUv12EEUIIIYQQQgghhCiObJ2eVSeu8cO+q0QmZgJgaarl8bY+PNulJtUcLMt0+4qiMLV3Xca18yUtu5AWQf8YW93REtNC2pb9c9xb/eszZtERVgRG8WxnP2q4WJdm2KKCpWTq+PVIOAGHwklIzwXA0cqUse18WHcymqvxGYxccJhfn2mLn6tNsebM1ul58bdT/HXpBlqNwtcjmzG0RfFu6tRoFMZ38GXGJrWy1BPtfeX6nRDFseN9SI0Gx5rQ453CxzQdDQdnQcJlNVHodoJURbmkdqvAtyPYuN17bEm1ngD7v4LoE3B1L5xZrj4A6vaHod+DlVPpblMIUaQqmxCl1+vR6e7+w1qn02FiYkJ2djZ6vb4CInt4yLEuX8U53mZmZmg0VSdZQIiH2fwz84lIjaDTdXtq77kKgOfHH6GxVC9QOQwdSsrqNRh3HmDYgEdYE7WZOafm8GPfHyss5uTsZAJjAwHo49unwGtGo5HcsHDMatYo8YWClA0byQ0LQ+PgQGA3CxKzExixaQR6ox4nCyc+6/IZHap1KLX9KE9OTz9N4rLfyA0NJWXTJnJC1DsazevWreDIhBBCCCGEEEIIUdWlZOlYeiSCxQfDCiSU+HesyVMdfHG0NivXeFxtzXG1vb8WZ4Vp7+dM93qu7AmO56vtwXw3tmWpzS0qTnIOfPZnMCuOXSMjV32vw8vBkue6+jGqtTeWZlrGtvPlyR+PcjUhg1ELD7NkQlsaVbO/57zpOXlMXHKcw1dvYm6iYd7YlvRu6F6i2B5rVZ2vtl8mND6DA1cS6FJHKrwLcU9h++DEYvX54LlgZlX4OK0J9Pg/WOUPh76DNhPB2rncwrxLWbTLu83GFZqMhNPL4NdhYNSrrQR7vgedpoK8jytEuapyCVFGo5HY2FiSk5OLfN3Dw4OoqCjJ3C5jcqzLV3GOt0ajoWbNmpiZle8/ukKIkjmfcJ4lF5ZgnmvkhW3qz7PDmNFYt22bP8ayVStMvb3RRUXhn1CfDZo/OXr9KEeuH6G9Z/sKiXt31G70Rj11Hevia+ebv9xoMBDz1tukbtqE/dCheP7v02KfFwy5ucTPU9sBujz3HMOa65l9cjZ6o56Wbi35ousXuFuX7MJFZaK1tcX52WeI//obEuZ+h6mPNyAJUUIIIYQQQgghhLh/RqOR+XtC+X5PKOk5eYCaUDKxS01GtfHGyqzKvfVTpDf71Wfv5Xg2n73OpK4pNKl+76SYkjoekUTAZQ1bU8+g0RR9PcvKzIRnu9SkvoddqW7/fiRl5LL8WCTp2XmMau1d5pWzrsans3DvVdJy7l39qzgyc/LYH6JFb4wAoL6HLZO71WJgU88CVcO8HCz5fXIHxv8cyIWYVMYsOsLP/m1oU6PwqiqJGbn4Lw7k7LUUbMxN+HF8a9r7lTzZwtbClBGtqhNwKJyAg+GVNiFq56UbHI9I4pVedbAw1VZ0OOJhlZsBG19Sn7eeADW73Ht8gyHg0RRiz8LBb6Hvx2UfY2FSYyDq6K2YSrFd3t+1m6wmRBn1YO0GI37+9+MjhCgTVe6v4tvJUG5ublhZWd31hqvBYCA9PR0bGxuplFPG5FiXr3873gaDgZiYGK5fv46Pj48kqQlRSen0Ot4/9D4Go4G3zvhicv0qJp6euL3+eoFxiqJgP3QICXO/Q9m6h1GTR/Fb0G/MPTmXdo+0q5Cf8R0RO4C7q0PFz5pN6ia1xGzK+vWYVquG68svFWvO5N9XkRdzHRM3NxzHPs4YTR4hSSHUsKvBs02fxVRjWro7UQGcxo0j8Zdf0EVHo4uOBsC8bp0KjkoIIYQQQgghhBBV1ZqT0Xy5LRiAeu62TO7ux6Cm1f61DV1V1LCaHUObe7HuVDRfbAvi12faldrcN1KzmfLbaZIyNXDzxr+O33YhlsX+bWhdRFJOWYtOzuLH/VdZERhFlk6trLRgbygDmnjyfLdaNPYq3WQxgPPRKTz1cyCJGbmlOKtCmxqOTOlem+71XIu8zuliY87y59rzbMBxAsMTefKnoyx4ohXd6xVsbxWbks2TPx0lJC4dRytTlkxoS9PqDvcd3VMdfAk4FM6u4Dgibmbg61y5WjVm5OQxdcVp0nLyyMzJY+aQxhUdknhY7foEksLBrjr0nvnv4zUa6PU+LBsBgT9A+ylgV63Mw7zLpc3qx+pty277nk2h+/+px6f3B2DrUTbbEUL8qyqVEKXX6/OToZydC8/sNhgM5ObmYmFhIUk6ZUyOdfkqzvF2dXUlJiaGvLw8TE2rfhKBEP9FP577kZCkEFrG2dB4ZxgAnh/ORGtjc9dY+yFDSZj7HZlHjjLhvddZd2UdZxPOsidqDz18epRr3Km5qRy+fhiAvr5985cnrfydm4sWAWD3yCOkbtlCwvz5mHp54fDY8HvOacjMJGHBAgBcpkxBY2GBDfB518/LZicqiMbKCpfJk7nx0Z07XszrSEKUEEIIIYQQQgghSi7iZgYfbDgPwEs9azOtT93//M2x0/rUZfPZGPaHJHAgJIHOdVweeE6Dwchrv58hKVNHNSsjE3s2QKstutLOxtMxHI9I4okiknLK0uUbaSzYG8rG0zHkGYwANKpmh4uNOXsvx/PH2ev8cfY6Xeq4MLlbLTrWci6V74mjV2/y7JLjpOXk0djLjlGtvR94Tr1eT2r4eaaMblOs9zDsLNQEpynLTrA7OJ6Jvxzn29HNGdRUTWIIT8jgiZ+Oci0pCw87C5Y+25babrYPFKOfq01+q8ZfDkfw3qCGDzRfaVt78hpptyrDLTkcQbd6rvSsX3Ur7IsqKioQjsxXnz86CyyKWT2vdm/w6QCRh2HflzDo2zILsUhl2S7v77q/VbbzCyGKpUolROl0ajlOK6si+o8K8ZC73SpPr9dLQpQQldDlpMssOrcIkzwj07abg9GI/ZAh2HQpvFSqWXUvrNq1I/PoUbTb9zOu7Th+PPcjc07NoZt3NzRK+SWj7o3aS54hDz97P/wc/ABI37eP2A8/BMDlhRdwfelFTL29ublwIdc/+ABTTw+sO3Yscs7EpcvQJyRg6u39r8lTVZ3jyJEk/rwYXXQ0Jp6eaG0f7MKMEEIIIYQQQgghHj46vYFXVpwmI1dP2xpOTO3930+GAvB2smJcO7Vqz+d/BtGxVqd7trcrjp8OhHHgSgIWphr86+byRDufe15TH9nKm+eXnWBPIUk5ZeV4eCIL9oby16W4/GUdaznzfPdadK7tgqIoXLqeysK9oWw6e539IQnsD0mgaXV7JnerRb9GHmjv8zjtCrrB80tPkpNnoF1NJ34c3xpbiwd/z0Gn07Hl5vkSrWNppmXhk615bdUZNp2J4aXlp0jLzqO5twNP/hRIQnoONZyt+PWZdng7lc77h/4da7AnOJ7fj0UxrU9drM0rx9upBoORgEPhANR0sSYsIYM3Vp1l69QuuNlaVGxw4uGhy4YNLwJGaPY41Onzr6vkUxS1StTiAXDyF+j4Ejj5lVmod0mPg8hD6vOyapcnhKhUqmRZn4fhD3wh7of8bAhReeUZ8nj/4PvkGfJ47ZwPZlE30Lq44D797XuuZz90KAAp69YzvuF4bE1tuZJ8ha1hW8sh6jv+2S4v+9Iloqe+Cno99kOH4vLiCwC4Tn0Fu0GDIC+Pay+/Qnbw5ULn06emcvPHH9V1Xn4J5T+exKmYmeE69RUArNq0ruBohBBCCCGEEEIIURXN2RnC6ahkbC1M+HZM8/tOdqmKXuxZG2szLeeiU9hy/voDzXUhJoUvtgUB8H8D6uFu+e/rWJppWfRkawY19USnN/LS8lMsD4x8oDiKcuhKAiMXHGLEgsP8dSkORYEBjT3Y8EInfpvYni517rSZa+Bpx6wxLdjzenfGd/DFwlTD2WspTFl2kt7f7GV5YCQ5efoSbX/D6Wie++UEOXkGetV3Y8mEtqWSDPUgzEw0zBrdnHHtfDAaYfraczz2/SES0nOo72HL75M7lFoyFEDXOq7UdLEmLSePtSevldq8D+rAlQRC4zOwNtOyenIH6nvYcjMjlzdWncVwq3qYEGVu3xeQEAzWbtDv05Kv79tRrRRlyIM9n5V+fPcStBmMBqjWAhx9y3fbQogKUSUTooQQQoiq5teLv3Lh5gUaJVjSaod6scTj/ffQOjjccz27vn1QrKzIjYjA7GIYTzd+GoD5p+ejM+jKOmwAMnQZHIw+CKgJUbqYGKKem4QhMxOr9u3x/HBm/kUYRVHw/PQTrNq0wZCeTtSkSehu3LhrzuSAJRhSUzGvUxu7Rx4pl/2oaPaPPkrNtWvweP/9ig5FCCGEEEIIIYQQVUxgWCLzdl8B4NNhTfByKEYWz3+Ii405z3WtBcBX24LR6Q33NU9Wrp6Xl59CpzfSp6E7Y1pXL/a6ZiYaZo9pwdi/JeUs3Bt6X3EUJTAskSd+Osqx8CTMtBrGtPFm57RufP9EK5p5OxS5nreTFTOHNObgWz15uWdt7C1NCUvIYPrac3T5fDcL9oaSlv3v1xKXHolg6srT5BmMDG1ejQVPtsLCtOhWguVJq1H4eGhjpnRXvw8yc/W08nVk5aQOpV4dSaNRGN9BTZYIOBSO0Vg5ko2W3KoONbK1N8425sx5vAXmJhr2Xo5nyeHwCo1NPCSun4EDs9TnA78CK6f7m6fnu+rHs79D3KVSCa1YyqtdnhCi0pCEKCGEEKKMhaeEM+/0PLR6I2/ttAG9Htt+/bDr2/df19VYW2PXrx8AKevWMa7BOJwsnIhMi2TDlQ33XDcvPp7cyAe/U23/tf3kGnLxsfWhloknUZMmkxcfj3md2lSfMxvlVrvO/JjNzKj+3VzM/PzIi40latJk9OkZ+a9r09NJXroUANdXXkHRVo6LKuXBomFDtDY2FR2GEEIIIYQQQgghqpCULB2vrjyNwQiPtazOo83KtlVbZfVsl5q42JgRfjOTlcei7muOj/+4SGh8Bm625nz+WNMSd13QahQ+GdqY528l5fxvaxCf/xlUKgkzf/86923ozv63evDZY03xcy3+tSRnG3Om9a3Hobd78u7ABnjaWxCXlsNnW4Po+NkuPv8ziLi07LvWMxqNzNt9hXfXn8dohKc6+PLNqOaYaivX24iKovBm//p8OaIpk7r58eszbbG3LJvqVY+1qo6NuQmh8RkcuJJQJtsoifCEDHYFq+0Tn7qVrFXX3ZZ3BjYA1O/FoNjUCotPPAT0OtjwAhj1akLRgyQVVWtxa30j7Pq41EK8p8xECNuvPm8wuHy2KYSocJXrLxnxn6coCuvXr6/oMIQQotwYjAY+OPQBOfocXrzojcXV62jt7fF4791iz3G7bV7q1q1Y6DVMbDIRUKtEpeYW/k9uTkgIoQMHEdq3H2GjR5O08nf0aWklijvweiDT90/n3YNqrH29ehL9yivkhIRg4uqK98KFaO3sCl1fa2+P96KFaJ2dyQkKIvrVVzHq1LvQnHbvxpiVhUWTJtj06lXsmIQQQgghhBBCCCEeNkajkXfWnSM6OQtfZytmDmlU0SFVGGtzE17qWQeA2TtDyMzNK9H62y/EsuyoevPgN6Oa42Rt9i9rFE5RFN7qX5+3+tcH4Ps9oby7/vwDtSz759f5m9HNcbe7/6pH1uYmPNvFj71v9OCrkc2o7WZDWnYe3+8JpfPnu/m/decIT8jI3/ZnW4P4clswAC/1rM3MwY3QVOKWjCNbezN9QAOszEzKbBu2FqaMaKVWEAs4GF5m2ymuXw5HYDRC93quBZLknmzvS6/6buTmGXh5+SmydSVrkShEsR2cDbHnwNIRHvnqwefr8Q4oGrWNXfiBB5+vKAlX4K8ZML+Dmszl3gSca5Xd9oQQlYokRJUTf39/FEVh8uTJd702ZcoUFEXB39+/xGNvjx96683yf+revTtTp069a/n69esLvfMhICCA9u3bA+ofwTNmzKBatWpYWlrSvXt3Lly48O87W8aK2ichhKiMVgav5GTcSfySzOi0LRoA9/+bjomLS7HnsGrTGlMvLwzp6aT9tZOR9Ubia+dLfFY83xz/5q7xurg4IidNwpCqJktlnzlL7AcfENKlKzFvvUXG0UCMhsLLil9Pv86CMwt4ZO0jPLP9GTZf3UyOPocGjvV5dPU1Mg8fQbGywnvhAkyr3ftuRLPq1fFe8D2KpSUZ+/cT++FH6K5fx/7wEQDcXp1a4rvwhBBCCCGEEEIIIR4ma05Gs/nsdbQahVmjm2NjXnYJIFXB42198HGyIj4th58PhBV7vRup2by15iwAz3X1o3Od4l+bK8rz3Wvxv+FNUBRYdjSSqStP33crv7L6OpuZaBjRqjrbp3Zl0ZOtaOnjQG6egd+ORtLz6z288NtJXvv9DAv3XQXg3YENeK1vPblmd8vtSky7guM4EZFIVGLmAz9y8kqesJSek8eq42pVNP+ONQq8pigKn49oiouNOZdvpPO/LeXYfuxvriVlcum6VKj6z4oLgr2fq8/7fwY2bg8+p2s9aDlefb7xJcjNfPA5b8tJh1NL4ef+8F0rOPAtpMeClTP0/aj0tiOEqPQe7r+cy5m3tzcrVqzg22+/xdJS7e+dnZ3N8uXL8fHxue+xpWnjxo0MGaKWOPziiy/45ptvCAgIoG7dunz88cf06dOH4OBgbG1tyywGIYT4r4hJj2HWiVkoBiPv7nYC3TWsu3XFbnDJyrEqGg32Q4aQMH8+KevWYT9oIDM7zsT/T3/WhKyhX41+dKjWAQBDRgbXJj9PXsx1zGrUoPp3c0nft5/kNWvIDQ0lZcNGUjZsxLR6deyHD8Nh6FAM7s7sjtzNuivrOBxzGCPq3Ww2pjYMqDmAYbWH4bFyLwmb5oFWS/VZ32LRsGGxYrds0gSvr7/i2osvkbxqFemHD6PR67Fs2warDh1KdkCFEEIIIYQQQgghHiIRNzP5YMN5AF7tXYcWPo4VHFHFMzPR8Frfuryy4jRzdl0hIT2XZ7vUpLqjVZHrGAxGXvv9DEmZOhpVs+P1vvVKLZ7H2/pga2HCqytPs/FMDGnZOuaPa4WlmbbYc4QnZJT511mjUejbyIM+Dd05Fp7E93uusDs4nj/OXldfV+Cz4U0Z1ca71Lddlfm52tC9nit7guN57PvDpTJnXXcb1r/QqUTVrdaevEZaTh41XazpWsf1rtddbMz5elQzxv8cyJLDEXSr50qXWk6lEu+/CY5NY+HeUDaciaGljwOrJncsl+2KcmTQw8YXQZ8LdfpC09GlN3efmXB5GyRehT2fQt8HaJ9nNELUUTj1K5xfBzq1Ch6KBmr3gRZPQN3+YHJ/1QGFEFVTla8QZTQayczNK/DIytXftawsHiXtCd2yZUt8fHxYu3Zt/rK1a9fi7e1NixYt7ntsacnOzmb79u0MHjwYo9HIrFmzeOeddxg+fDiNGzdmyZIlZGZm8ttvvxU5R25uLi+++CKenp5YWFhQo0YN/ve//xUYk5CQwLBhw7CysqJOnTps3LixwOt79+6lbdu2mJub4+npydtvv01enlr61t/fn7179zJ79mwURUFRFMLDw0v9WAghxIMyGo3MPDyTzLxMJgZ7YRN8DY21NZ4zZtzXHVb2Q9Vk1YxDh9DFxtLKvRVj6o0BULejy8SYl8e1adPIvngRrZMT3osWYl67Ns4TnsZv8yZqrFyBw6hRaKyt0V27RsKcuYT06sWu3q3Imvgq/T/fx8xfdXy7wpIlG6qzbFMNnpobjO2Ln5Dw3TwAPN5/H5uuXUsUu23Pnrj/3/8BkHftGgBOL70sd5oJIYQQQgghhBBCFEFvgGmrz5KRq6dtTSee7167okOqNB5tWo2et1qEBRwKp/uXe5i28jTBsWmFjv/pQBgHriRgYaph9pgWmJmU7ltjg5pW44enWmNhqmF3cDzjfw4kNVtXrHV1egNTV54ut6+zoii0renE4qfb8ufULgxtXg0vB0vmjW0pyVBFeKVXHdxszbEy0z7wQ6tRuHwjnQ83XSz29g0GI0sOhQMwvoNvka0Mu9V1ZUKnmgC8seos8Wk5D7zv93IsPJFnAo7Rb9Y+1p6KRm8wYmaiISOnZK0sRRVwdCFcOwZmtjDoWyjN6/oW9vDoLPX54Xlw7cT9zRNxGL5rAz/3UytD6TLAqRb0+gBevQjjfoeGgyUZSoiHUJWvEJWl09Pw/W0Vsu2LH/YrcX/ip59+msWLFzNu3DgAfv75ZyZMmMCePXseaGxp2LlzJx4eHjRq1IirV68SGxtL37598183NzenW7duHDp0iEmTJhU6x5w5c9i4cSO///47Pj4+REVFERUVVWDMzJkz+eKLL/jyyy+ZO3cu48aNIyIiAicnJ6Kjo3nkkUfw9/fnl19+ISgoiIkTJ2JhYcGMGTOYPXs2ly9fpnHjxnz44YcAuLrenQ0vhBAVbf2V9RyKOUT1VFN6/3kDALc33sDU0/O+5jPz8cGqdWsyjx8nZeMmXJ6byNRWU9l7bS/R6dHMOTmb8VtzyNi7D8XcHO/58zD7W0VBRVGwbNYMy2bNcJ/+NmnbtxOydCHW58Kocf2fZZrTgDT++S+z88SJOI4edV/xOz0xDl10NImLF5PeqCGWzZvd1zxCCCGEEEIIIYQQD4M/r2k4G52KnYUJ345ujraIJIiHkUaj8NP41hy4ksCCvaEcvHKTtaeiWXsqml713ZjcvRZtaqjVcc5Hp/DFtiAA3h/UiNpuNmUSU/d6bvz6TDsmBBwjMDyRxxcd4ZcJbXG2Mb/nenN2hnA6KrlCvs71PeyYNaZsbsD/L2nh40jgO71LZa5DoQmM+/EoK45F0b2eK/0b//u14gNXEgiNz8DG3ITHWlW/59g3+9fjUGgCQbFpvL3uPMOcSyXsfAaDkV1BcXy/N5QTEUmAmhszoLEHk7vVoml1h9LdoKh4iVdhp/p+LH0/BPt7fw/el7r9oMkoOPc7bHgBJu0Fk3v/7iwg7hL8NhpyUsDUGhoPg+ZPgE/70k3eEkJUSVU+IaqqefLJJ5k+fTrh4eEoisLBgwdZsWJFoUlOJRlbGjZs2JDfLi82NhYAd3f3AmPc3d2JiIgoco7IyEjq1KlD586dURQFX1/fu8b4+/vz+OOPA/Dpp58yd+5cAgMD6d+/P/Pnz8fb25vvvvsORVGoX78+MTExvPXWW7z//vvY29tjZmaGlZUVHh4epbXrQghRquIz4/ny+JdgNPLBXlfIjsSqXTscRo18oHnthw1VE6LWrcN54rNYm1ozo8MMJv01ifSApSTvNoCiUO2rL7Fs3rzIeTSWlpxv7cILKTE4d9Iy0aI3/Wv2R6MUfXeciavrPecsDrc338CyZw/2hIXxYDMJIYQQQgghhBBC/HcFhieyI1p9E/fT4U3wcrCs4IgqH0VR6FLHlS51XDl7LZkFe0PZej6WnUFx7AyKo7WvI8928ePLbUHo9Eb6NXLn8bZlWwGpTQ0nVjzXnqd+CuRCTCojFx5m6TPtqFbE1y8wLJF5u68A8nV+WHSs5cKkrrVYsDeUt9eeo7m3Ix72FvdcJ+BWdagRrapja2F6z7EWplrmPt6CQXMPsC/kJs46hUGlELdOb2DD6RgW7g0lJC4dADOthsdaeTGxix9+rmWTaCgqmNEIG1+GvCyo0QVa+pfdtgZ8Dld3Q/wl2P819Pi/4q2XFgvLRqrJUD4dYNwqMLctuziFEFVOlU+IsjTVcvHDfvmfGwwG0lLTsLWzRaMp246AlqbF7wF9m4uLCwMHDmTJkiUYjUYGDhyIi4vLA499UEajkU2bNrFixYoCy//ZzshoNOYve/7551m2bFn+a+np6fj7+9OnTx/q1atH//79GTRoUIEqUwBNmzbNf25tbY2trS1xcXEAXLp0iQ4dOhTYbqdOnUhPT+fatWv4/K3aiRBClBd9cjK6GzewqFfvX8cajUY+PvIxablpPHnFE/vzkSgWFnh+9CHKA56XbPv1J/bjT8gNCyP77FksmzWjo1dHXk5sRefdRwFwfut17Pr0uec8QYlBTNszDb1RT/vWQxjd6eNyaV+nKAqWzZtjjIkp820JIYQQQgghxIMIS8ggKTOXlj6OFR2KEOIhk5Kl443V5zGiMLxFNQY1rVbRIVV6Tas7MH9cK67Gp/PD/qusORHN8YgkjkeorZfc7cz5bHjTcrn+1aiaPasmd+CJH49yNT6DEd8fYumz7e5KGEnJ0vHqytMYjGqii3ydHx7T+tTl4JUEzkWnMO330yx9pl2RbfDCEzLYHay+f/ZUh7sLEBSmjrst7w5swHsbLrAxQkODQxGMa18Da/OSvyWcmZvHisAoftx/lZiUbABszE0Y196HZzrVxM3u3slcooo7EQDh+8HEEgbPgbJ8393KCR75Elb5qwlRDR4Fjyb3XicnHX4bBSlR4FwbxvwmyVBCiLuUbcZQOVAUBSszkwIPSzPtXcvK4nG/fzxPmDCBgIAAlixZwoQJE0ptbGHs7OxISUm5a3lycjJ2dnb5nwcGBpKbm0vnzp0B8qsv3a4UdVtcXFx+1aiZM2eyb98+Tp48yenTpwFo2bIlYWFhfPTRR2RlZTFq1ChGjBhRYA5T04IZ7IqiYDAYgIIJV7cZjcb8cUIIUV6Mej3pBw4SPW0aIV26EjZkKDHvvIMhO/ue622L2MauqF24pWt5dMtNAFynvlKgfd390tpYY9tHLc+cvG4dAJknTtD555MA/NFa4bcmqfecIzYjlhf+eoHMvEzaebRjRocZ8vtVCCGEEEIIIf7mekoWg+ceYPj8Q7y8/BRJGbkVHZIQ4iFyOPQmN9JycDE38t7A+hUdTpXi52rD/4Y35cBbPZjUzQ8bcxNMtQrfjGqOo7VZucax+vmO+LlaE5OSzcgFhzkffed9GqPRyDvrzhGdnIWvsxUzBjcqt9hExTMz0TB7THMsTbUcCr3Jov1Xixz7y+EIjEboXs+1RFWYnmjvS58GbuiNCp9uDabT57v4ZsdlEov5N01iRi7f7LhMx8928eHmi8SkZONiY86b/etx8O2eTB/QQJKh/utSrsH299Tnvd4HJ7+y32bDoVB/EBjy1NZ5+ryix+rzYPXTcP0MWLnAuNVqUpUQQvxDlU+Iqor69+9Pbm4uubm59OvXr9TGFqZ+/focP378ruXHjh2j3t8qnWzYsIGBAwei1apVr2rWrImHhwc7duzIH5Obm8vevXvp2LEjAG5ubvj5+VG7dm1q166dP87Ozo7Ro0fzww8/sHLlStasWUNiYmKx4m3YsCGHDh3KT4ICOHToELa2tnh5eQFgZmaGXq8vwVEQQojiy42KIn7OHK707kPUs8+SumUrRp0OgJQ1awkf8zi5RbQOTcpO4n9H/wdGIzMOeEJmFpbNmuH05JOlFp/DsGEApG7ZSnZwMNemvAA6HdmdmvFLLw0BFwK4cPNCoeum5aYxZecU4rLiqO1Qm296fIOp9t5lloUQQgghhBBVSPQJWPwI/DUT8nIqOpoqa+bGi6TlqG/AbDwTQ59v97Hj4o0KjkoI8bDo39iD5c+0YXxdPTb3UdFFgJudBdMHNODI//Vi/5s96VS7bDpv3Es1B0tWTepAYy87bmbk8viiIxwLV98nWXMyms1nr2OiUZg9poV8nR9Cfq42zBjcEICvtgVz7trdhQ3Sc/JYdTwKAP+ONUo0v6IozBrVlNF+enydrEjO1DFnZwgdP9vJjI0XuJaUWeh615IymbHxAh0/28mcnSEkZ+rwdbbik2GNOfBWD6Z0r429pVxP/s8zGmHzq5CbBtXbQrtJ5bNdRYGBX4OFg5rodGhO0fFtfQNCtqvVq8auBKea5ROjEKLKkYSoCqDVarl06RKXLl3KT0B60LEpKSmcPn26wCMyMpIpU6YQGhrKCy+8wJkzZ7h8+TLz5s3jp59+4o033shff+PGjQwZMiT/c0VRmDp1Kp9++inr1q3j/Pnz+Pv7Y2VlxdixY4uM49tvv2XFihUEBQVx+fJlVq1ahYeHBw4ODsU6NlOmTCEqKoqXXnqJoKAgNmzYwAcffMC0adPyWyDWqFGDo0ePEh4eTkJCQn51KSGEuF9Kbi5pmzYTMd6f0D59SZj/PXnXr6Oxt8dx3Dhqrl2Dz+Kf0To5kRMURNhjI0jdvv2ueT4L/IzE7EQeC3fD5VQ4iqkpnp9+gvIvv+tLwqpdO0w8PTGkphL++Fj0KSlYNGtKs+8W089vAHqjnvcPvo9Oryuwns6g47U9rxGSFIKLpQvzes3DzsyuiK0IIYQQQgghqhSjEeOxnzH81B8iDsKBb+DH3pAQUtGRVTk7L93gzwuxaDUKX49sRh03GxLSc5j4y3Gm/X6alEzdv08iHh4GuWlTlI0WPg74FL8YjCiCjbkJHvYVV8XG2cac3ya2p20NJ9Jy8njyp6MsPRLBBxvOA/Bqn7o093aosPhExRrV2psBjT3IMxh5ZcUpMnMLVsNZe/IaaTl5+LlY07WOa4nnNzPR0NHdyLZXOjFvbEuaeNmTrTMQcCicbl/u4dWVpwmKVbsNBMWm8urK03T7cg8Bh8LJ1hlo7GXHvLEt2fVad8a188XCtPSucYtK7uzvarKR1gyGfAeacvza23pA//+pz/d8Vvj/Mwdnw/GfAQUe+xGqty6/+IQQVY6knVeQv7erK42xe/bsoUWLFgWWjR8/noCAAPbv388777xD3759yc7Opm7dugQEBDBy5EgAQkNDuXLlyl0VqN58802ysrKYMmUKSUlJtGvXju3bt2NrW3T/VRsbGz7//HNCQkLQarW0adOGLVu25Ccz/RsvLy+2bNnCG2+8QbNmzXBycuKZZ57h3XffzR/z+uuvM378eBo2bEhWVhZhYWHUqFGjWPMLIcTf6dPTifv8C/w2buRGzq27pxUF644dcXhsODa9eqExN88fX3PdWqKnvUbWiRNEv/wKWf7+uL02jRu5N/k9+He2hG3BMUNh1JY0AFxemIJ5rVqlGrOi0WA/ZDA3FyzEmJmJqbc33vPno7G0ZHq76Ry5foTLSZf56fxPTG42GVDLcH94+EMOXz+MpYkl83rNo5pNtVKNSwghhBBCCFExUlJTiF/xIrVjNqIA+/RNaKIJxzH2LCzsCv0/g5ZPqXdci3vKzM3j/Q1qxd1nO9fksVbVGdjUk1l/hbBoXyhrT0Zz8EoCnz3WlB713Co4WlHR0jZNx/zsMoyD52LeZMi/r1BZpFyDnHRwk1ZsQpQHOwtTlkxoy5RlJ9gdHM+769VkqHY1nZjcrXSvG4qqRVEU/je8CaejkrmakMGHmy7y2WNNATAYjAQcCgfgqQ6+aDT3/3ecVqMwsKknjzTx4FDoTb7fE8qBKwmsOxXNulPR1PewJSg2LX9859ouTO5Wi061nVHk78eHS24GXNwA2/5P/bzbW+Ba797rlIVmj8P5NXDlL7V13tNb7yRlnV8Df32gPu//P2gwqPzjE0JUKZIQVU4CAgLu+fr69evva+zt8fdap1WrVvz5559Fvr5hwwZ69uyJjU3BW04URWHGjBnMmDHjnvH83cSJE5k4cWKRr/+9Fd5tycnJBT7v1q0bgYGBRc5Rt25dDh8+XOyYhBCiKBpLSzL370ebk4OJlxcOjw3HYehQTKsVnixk6u6Ob8Bi4r6dReLPP5MYEMD5fWv5aGAWN23U328zjlZHSQ3DvEEDnJ95pkzidhg2jMSffkZjZYX3woWYODsD4GThxNtt3+bt/W+z8OxCevn0oo5jHRaeXcj6K+vRKBq+6vYVDZ0blklcQgghhBBCiPJhNBo5HpHE9gOHGR4ynQZKBHqjwteGx9lkM4KcpOvMt15Ea90Z2PSy+mbCo7PByqmiQy9UZm4e566lUNfdFkdrswqLY9ZfIUQnZ+HlYMkrvesAYGGq5e0B9enT0J03Vp3hakIGTy8+xujW3rwzqAF2FtI2pqrZExxHYkYug5pWw8yk5A0UdHoDO9f+QP8L8wHIXvMs68P19O03GCuzSn65PSsZFnaDzARo+xz0+RBMLSs6KiH+8yzNtCx8sjWvrTrDpjMx2FmY8O3o5mgfIMlF/Dc4WJnx9ahmjPvxKCuORdGtrisDmnhy4EoCV+MzsDE34bFW1UtlW4qi0Km2C51qu3DuWgoL9oay9fx1gmLTUBR4pLEnk7vVokl1+1LZnqgijEaICoTTS+H8WshNV5d7NoNOr1RMTIoCg2bB/PYQdRQCf4D2kyHiMKxTbwKn3fPQ/vmKiU8IUaVU8v/QRHmoXr0606dPr+gwhBCi3ClaLS5vvcmxS5fo/sILmP2tGlRRgtNCWdctj5gMG/zXp1Ptaiqf/QR/jm9AV6c2eB79BbRaqn3yMYpp2VwYN/P1pea6tWhs7TB1L3hX8iM1H+HPsD/Zc20PHxz6gFH1RjHv9DwA3mn3Dl2rdy2TmIQQQgghhBBlLykjlzUnr7HiWBS+CXv51vR77JRMkhQHjrb6kkm9hvGMwcCguQcYmfIGX3ntZ3jSzyiXNkL0CRi+CGp0rujdyGc0Gtl24QYfbb5IdHIWJhr1jbqBTT3p19ADe6vySza6GJPKTwfCAPhoaKO7Elta+Tqy5ZUufLktmJ8PhrHyeBT7Q+L5fERTutxHGxtRMQ6H3uTpgGMYjfDNjstM7V2XYS28ip2UcCw8kW/X7GZ+6kxQIN7ogKuSTNfjL/HE6TQGdOvCE+19sTSrpG2FDs5Wk6EAAhfB1b1qqxnPphUblxAPATMTDbNGN6dPQ3caetpSzUGSEYWqYy0XJnWtxYK9oby99hzNfRzyq0ONaFUd2zJIvm5S3Z5541oSnpDBkas3aefnTE0X61LfjqjE0mLhzAo4tRRu/q0tnWNNaPEEtHkGtBWY+O/gDX1mwh+vwc6Z4FIb1jwL+lyoPwj6fVJxsQkhqhRJiBKMGjWqokMQQogKE9zUkXMZRqzijqHVFn3B8mrKVTZc2cClxEvqAj+Im+LGtLUG7CMSGL0gCI11FAbA+dlnsWhYtlWYzGvXLnS5oii82/5djm84zrmEc5xLOAfAhMYTGFVPft8LIYQQQghRqRiNkBEPyVGQlai+AeFU805LiFty8vTM2x3Kgr2h5OXl8arJal4yWw9AultLHMYtpb+9V/74759oxagFh3ktuhvGzl0YETYDbl6BgEHQ5TXo/nbFvsEBhCdkMGPTBfYExwNgbaYlI1fP3svx7L0czzvac3Sp48rAJp70aeRerEpMOr2Bm+k5FFKg/J4MBiPvrD+H3mBkQGMPetZ3L3SchamW9wY1pF8jD95YfYaIm5k89XMgC59oRd9GHiXbaBVkNBpJz8kjOVNHUmYuCalZXEktvCJ8ZZScmcurK09jNIKpVuFaUhavrzrDgr2hvNanLv0bexTZGigpI5fPtgbx+/EIlpp+jYM2gySHRjhM/IObiwbhnHKeWbqPGL7lQxbuu8rkbn480d4XC9PCrzOkZus4EZHEsbBEjoUncul6GnXcbejXyIO+Dd3xc7UpdL0HknodjnyvPu/8Kpz+DRKC4Yee0Os96PASaEpeMUsIUXxajcLgZoVXphcPt2l96nLwSgLnolOY+MtxLsSkAjC+Y40y3W4NF2tqSCLUf0N8MK6p51HCrOEe73OQlQhnV0HIdjDq1WWmVtBwqJoI5dux8rTabjVBrVoVcRCWPqYu82oNw3+46/8lIYQoiiRECSGEeKhNPzCdhOwEAnYFFGu8qcaUHt49GFZnGB08O6CM13Hjk09IXrUaQ3o6Zn5+uEyp2FKt7tbuvN76dWYcngHAgBoDeKVlBZW3FUIIIYQQ4mGXEoVz2iWUs6mQFgMpUeojOQpSroE+p+B4EwtwqQtuDcGtAcHG6sw4YuDwTSscSeMnm4W0zDuljm03GZs+H4FJwTZzzb0d+GBwQ95Zd543D2qo/tRa2l/+Ek79Cvu/gqt7YPAcdRvl/IZHtk7P/D1qcldungFTrcJzXf14sUcdYlKy2HL2On+cU9u37AqKY1dQHGZrNXSt68qAxh6YmWiIS8shPi2HuLRs4m89j0/LITEzF6MRvK21tOiUha9r8ZK+fguM5FRkMjbmJnzwaKN/Hd+2phNbX+nCu+vOs/ZUNK+tOsNmD1t8ncvuDcXEjFyWB0aSlJGL3mjEYDCiNxrRG24/QG8wYDDCgMYeDGjiefckRiNcPwNBm9XndfpA9TaFvqG04XQ0W85dJylDTX5KytSRkpWLTv/P5CcTji0+zmePNavUb6gajUbeXnOO2NRs/FysWTW5A6tOXGPB3lCuxKXz/LKTNPGy5/V+9ehaxyU/McpoNLL2ZDSfbLlEYkYuz2n/oJP2AkZTKxyf+AWsHXGeuB7jT73xSQrnV8uvGZ7+f3z8x6VbiVG1GNfOh7TsPI6FJxIYpj6CYlMx/ONQnopM5lRkMp9tDaKO263kqEbuNPGyLzJRq0T2fQF5WeDdDnp9AB1ehI0vQ/AfsON9CNkBwxaAfem0ZhJCCFF8ZiYaZo9pzsA5BzgfrSZD9ajnKlWbRLFpj86nY+gyCC3BStXbqklQjYaBhV2ZxXbfNBoYPBe+7wh52eBYAx5fAWZWFR2ZEKIKKXFC1L59+/jyyy85ceIE169fZ926dQwdOjT/daPRyMyZM1m0aBFJSUm0a9eOefPm0ajRv19MEEII8d9T2c8bNexroM3VYmtne88LjDamNvSr0Y+BNQfiYOFw5wULLZ4ffYRV69ak/PEHbtOmoSlG672yNrzOcCLTIsnQZfBGmzfQKHKXpxCi6qjs5w4hhBCVS2U/b5iseorON87BlaJGKGDrCZYOkBimJizEnlUfQD1gOZBuYYmZqRlmuhT1Lu7Bc6HJiCK3O7atD6cik1l94hovrL7Mppe+pFrt3rDpZYg+rr6x4FgT6vRVHzU6gWnZtu/ZFXSDGRsvEpmYCUDn2i7MHNKIWreq4dRyteGlXnV4qVcdQm6k8ce562w+e50rcen8dekGf126UeTc1mTxnPYvxmp3otOZcH5+LWjdHd/GncCjCZgXXnEnLi2bz/8MAuD1vnXxsLco1r5YmZnw+YimRCRmciIiieeXnmTtlI5FVgS6X3qDkeWBkXy5LZiULF2x1vnzQixNqttT3dFKTXyKPQsX1sOFdZAUdmfg/q/A0kn9+tftB7V7gYU9V+PTee33M+T9M2PnFnMTDY5WZjhYmhAan8aRsCT6z97HtD51mdCpJiba+/j/06Av0zv9VxyL4s8LsZhqFWaPaYGzjTmTu9VibDsfftwfxk/7r3IuOoXxPwfStqYTb/Srh6OVGe+uP8eRq4kADHS5wduZq8EASv/P1NYtADauKE+shR970yDrCn95B/B46stEpuTw0eaLfLUtmCyd/q6YfJysaFPDibY1HWlUzZ5TUclsvxDL4dCbhMSlExJ3he92X8HT3oK+Dd3pVd+FDJ36PVHi+m43Q+HEEvV57xlqIqS1C4xZBid/gT/fhvD96u+FQd9C48fu+1hXFZX93CGEePj4udowY3BD3lqjVvwv6+pQomQq+3nDaOtJioU3dna2KNwjkVqjBb/u0OJJcK1bLrE9EOdaakWosyuh90ywkVbVQoiSKXFCVEZGBs2aNePpp5/mscfu/sfoiy++4JtvviEgIIC6devy8ccf06dPH4KDg7G1tS2VoIUQQlQdlf28sajXIrZs2cIjjzyCqen9t4ywHzIE+yFDSjGyB6MoCq+2erWiwxBCiPtS2c8dQgghKpfKft4wOtciIzkOq2r10Th4g70POHiDvbf60bbanQpPBj0kR3Dy+CGOHjmAly6cOso16mivY2PMAl0WONeGUb+C+73bdCuKwsdDG3MxJpWL11OZsuwkKyc9inn11rDlTbVNRlIYBC5UHyaWULOrWjWoTl9w9P3XfTsZmcTh0JvYW5riZG2Gg5X60cnKDAcrM8xM1MSYa0mZzNx0kR0X1YQmdztz3hvUkIFNPIu8MaWOuy1T3W15pVcdLt9IZ/PZGPZdjsfcRIurnTmuNua42ZnjZZ5Ns+gVeIf8gjYnJX/92sYYOLYfjgGKRq26Va2F+vBsDp7NwNSCjzZfIi07j6bV7XmyQ41/3ee/M9VqmDe2JQPn7Ofi9VRmbLzAZ481LdEc93IqMon3NpzPrxRR38OWbvVc0SoKWs2th6KgufXcRKOw6ex1zkQlsWzDH7zlfUlNgkq8emdSE0uo2xc0pnBlx622KSvUh8YEfDtyPKUR1Y21cavZiKc6+KrJT1amOFqZ4WhlhqWZmrik0+n4Ze0W/kpx4/DVRD7dEsSmM9f5/LGmNKxWgioDFzfA6gngWh8aD4dGw9XWkaXkSlw6MzddAOCNfvVoUt0+/zU7C1Om9anL+A6+fL8nlF+ORBAYlsjIBYfRahT0BiMWphpe6+7Nsxc/QEnXQf1B0PKpghtxrgVjf4clg/CK38fuFjVZ6f4a8/aEEp2chaJAPXdb2tZ0upUE5YS7XcHku8Ze9jzZ3peULB27g+LYfjGWPcHxXE/JZsnhCJYcjgBMeOfEDmzNTXC49XWxtzRVn1uqz1vXcKRbXdeCP1u7Plbb4tTpq7bCuU1RoNV4qNEZ1k6E6BPq1+Lydnjky8pZLaKUVPZzhxDi4TSqtTexKTlk5ObRtY4kflQmlf28Yej2Nnsymj7w+xyVUsPB6kMIIe5DiROiBgwYwIABAwp9zWg0MmvWLN555x2GDx8OwJIlS3B3d+e3335j0qRJd62Tk5NDTs6d0uCpqeo/+DqdDp2u4F1POp0Oo9GIwWDAYDAUGcPtj0WNEaVDjnX5Ks7xNhgMGI1GdDod2nv1CBb3dPt3zz9/B1VGVSHG0j5vQMnOHf+mKn29/wvkeJcfOdblq6oc78oe321y7hC3ybEuX3K8y09VOtZVIcZKf94Y9D07d+ygT58+hb85YQRuzRmbms2Hm2+y45Ij8Cg1na34aEhDavvYoku8ipIei9GrNZhZ569zL1pg7pimDF9whNNRyczceJ6ZjzaEEUsgNx0lbB9K6F9orvyFkhYDIdvUB2B0qYeh0WMYOrwE2oJx6/QG5uwKZeH+MIyFFxECwNpci6OVGQnpOWTrDGg1Cv4dfHixRy1szE3Iy8sr1jH0c7bg5R5+vNzD787C9Btojn6P5tBilNwMNWbn2uS2fZHAS1EkpdzEMuEcTTRX8SAJ4oPUx5nl6lgLe65Vf5TLFxqjUXz48NEGGPR5GO4u5HNPzlZavh7ZhKeXnGDFsSiaV7fjsZZeJZpDubIDzbEfMdbuhaH5E9zMNeHrHSGsOhENgK2FCVN71WZsm+r3rr6UHsegm3+SeWMVfuHXIVxdbDSxwFi7D4YGQzDW7qN+/wAY8lCijqJc2Y4mZDvKzRAI28co9jHKHHSpnmgDfcDWA6NdNbCthtHWkzy7ahhtq6Ezd8LFAn4c1JQN5+L535/BnItOYfB3B5jYuQYvdPfD/N8qZmXEY7JpKoohD26cVx87P8RQrSXGhsMwNBgKdoW0/yumnDwDL/12kmydgY61nBjfphq6yGNgZqMmF95iZ67hrX51eKq9N/P3XmXViWj0BiPd6rrwwaD6+B55H+VmCEYbD/IGfAOFfe96NEcZugjtGn+0p5YwupsXQ16ZSvCNNHycrLC3/MfPURE/w1YmMLCxGwMbu5Gt03PoaiI7LsaxOziemxlqW8jU7DxSs/OITCx8v7vXdeG9gfXxcbKC62cwvbAWIwp53d4p/HeHnQ88uRnNga/QHPwW5ewKjBGH0A9dgLF622If73vtV2VT6c8dVehvhapOjnX5kuP976Z0qwGAXp+HvoR/l/xdVTrWVSFGOW+Iv5PjXX7kWJevqnK8SxKfYjTe67LFv6ysKAVKAl69epVatWpx8uRJWrRokT9uyJAhODg4sGTJkrvmmDFjBjNnzrxr+W+//YaVVcEeoCYmJnh4eODt7Y2Zmdn9hi3Ef1Zubi5RUVHExsYW+6KiqNoyMzMZO3YsKSkp2NlV/rv2SuO8ASU7dwghhLijqp03QM4dQghR0arauaOqnjd0BjgSp7ApUkOOXkGjGOldzUjf6gZMS6H79cUkhUVBGowojKulp63bPy4HGo3YZl/DPfUM7qlncEoPQYN6M9ZN6zocr/EC2WZO6ufZsCRES0S6Wn2moYMBrQIZeQoZeZCug8w8MP6jVUctWyMj/PRUe8DDZ5mbQO0bW/C9uRetUb0ImmLpw2X3R4lxaKNWg1J3ib9iFP6I1OBCMn2trzLK+Sru2WE4ZF7FIi81f84QbR3SvLoT49gWveb+WqBvu6awJUqLqWLk1SZ6vKz/fR2tIYdG0cupmbArf1maxo4FuoEs1vUhEwvauhp41MeA3T0uhVpnx1I7biveiQfyj0m20ZRjmmZY+LTlhn1z9Np/bwVomX2DoKAztMw7RXttECbc+11YIwqpFtU5XnMK6RZepOTC6jANZxPVr4GbhZExtfTUusevjtZh3+GVHEiKpQ9XXXrjlXwU17SLKBjzt3HTpi7RDu2IcWhLrmnJfg+tC9dw4XoKfU3P8KzjWaplnMdcnw7ANcf2XKw2iiwzl7vWu5kNKblQ0xY8U0/S7uosAA7VepN4u8b33GbN+L9oeu0XAE76TCTKuUuJYr6XPANk6dWfscw89ecuKw8y8iAzTyE5B44nKOiNCqaKkT7VDXyQ9Tnu6eeJcuzIyRqT/3UbjukhtIpYgHVufLH295+q2nkDqu65Qwgh/iuq2rlDzhtCCFGxSnLeKHGFqHuJjY0FwN3dvcByd3d3IiIiCl1n+vTpTJs2Lf/z1NRUvL296du3713BZ2dnExUVhY2NDRYWhf8TbzQaSUtLw9bWtsiS26J0yLEuX8U53tnZ2VhaWtK1a9cif0bEv9PpdOy41927lcjtOwaqqvs5b0DJzh3/pip9vf8L5HiXHznW5auqHO+qft4AOXc8bORYly853uWnKh3rqn7uqIznDZ3eQEhcOueiUzkXncr5mBQu30hHp1cTQJp72/PJkIbUdS+91hqPAOa7QpmzO5TVEaaM6teWhp5F74c+OwVD0Ga0f72Hc0YIfcM+Qj9kAZvS6/PNxkuk5+RhZ2HCx0MaMqCxx13rGwxGUrPzSMrMJTk1DevUK9Sp4Yti63FXtal7MughNRolKQwlMRQl+gTKpbUoBjXpx+DVGkOnV7Gq3ZfmikJz7hzvvn37MNDUlMHB8UxbdY5lGY7sNunE/LHNcfa0YeWa37C9+Bt9tSeoow+ByBBa3FiBofFIDC2eAveSJYH0NxhJX3qSfSE3WXnNjnXPt8PW4h77ev00Jhsmo9y8AkBCzcHoI47gbojjDe1yJplsJqXps3j0fhEs7AudQok5iebwXJSgzfkJRAav1iQ1eoq+W225mWPOdy2a0a+Re6Hr/9OG0zF8c8oLa/NH2TW5Gc5ZVyHtOkradUiNUauIpcWipMaoyw067LOj6HHjJ/QTdoC5LY8D2y7cYObmS8Sl5zLnggnj2nrzUg8/nG0KJpspwVswORWIUdFi9fhiGns2AyAvPQ5N0CaUi+vQRB3BJT0Yl/RgmkYvAyc/jPY+GB3U1pNGB1+4/bmlk9oCLi8H5dpRoo9voe7N7TSwiFQ3eOvXmdHMBnIzqJ50BK/UUxjaTsLQcWrh7eHSYjH5UW1Hr283hTa93yzGkXwE/S4HtIfn0OLaYpp26ovRr0exvgZFUaJPYjy9jNMp1jQa9d49zx2h8Rl8uPkSh64mkhQdhLvZeQwaUzwen8MjjjXuuR2j0cjVhG4sv9CLjAtbeWLIVNpYluw8VdXPG1A5zx2i7MixLl9yvMtPVTrWVf3cIeeNh48c7/Ijx7p8VZXjXZLzRqkmRN32z2QNo9FYZAKHubk55uZ333llamp610HW6/UoioJGo0GjKfz2uNutxG6PE2Xnfo71P7OmKwN/f3+Sk5NZv359qc9tNBqZNGkSq1evJikpiVOnTtG8efP7mqs4x1uj0aAoSqE/P6LkqsJxrOzxFVdJzhtQsnNHcVWFr/d/iRzv8iPHunxV9uNdmWMrKTl3PFzkWJcvOd7lpyoc68oeX3FV5HkjJC6dwDiFY9uucD4mjYvXU8nNM9w1zsXGnJd61uaJ9r5oNaV/49nUPvU4F5PK7uB4Xlxxhs0vdsHeqoh9MXWBNv5QqxusGo9y/Qya5aOIzBtKZt5jtPZ1ZtaY5lR3LPrOdVclD9cLS+HgbMiIu7VUAWtXsKumPmw97zy3dISUa5B49c4jKRz0uXdPXqMLdH0DTc2uaIr4Ot7+WvVtXI31bnY898txriZkMObHQF7uVYdvz7uj00/l5yE+9MzaASeXoCSFoz3xM9oTP4NXK2g4BOy81Jht3MDGHSwcoIjrMrPHtGTgnP1EJGbyzoZLzB/X8u7vM4MeDs6C3Z+CIY88aw++d3idry9Vw4QRjLE4whtWm7HPjMTuzLcQ9BO0mwTtngdrZ7X01ZW/1OMavv/OvHX7Q6dX0Ph0wFlRGJcezJxdV/hyRwh9G1fDzOTe1+6ydXq++UtNzprSvTbuHp7APVrVGQzoEkLJ+6EPlolX0GydBiMWg6IwqHl1utR159Mtl1h5PIplgVGsOhHNo82q8XSnGjT2soesJPjzDQCUTi9j6tP6ztyOXtBhsvpIuQYX1sH5NSgxp+BmiNrarzBmNmBfHZKjQJeBL4AGDChoqrWA2r2gVi+U6q0h7iJsfxclbB/aw3PQnlkG3adDK/87SXsGA/zxMmTeBI8maPvMQGtSzJ//PjMh/TrKuVWYrHkaer0PDQaXrP2fPg+CNsOR+RB1FIA2gP64K9qu04pcrX41B5ZNbM+mMzH4bfgAjPBLbg+O7UjjvUF6POwL3kSZm2cgMCyRnUE32BUUR8TNzFuvNMMvLJlHm1Urfsz8d84bIP9zPGzkWJcvOd7lpyoc68oeX3HJeePhI8e7/MixLl+V/XiXJLZSTYjy8FDvCIuNjcXT884/d3FxcXdlxT5s/P39WbJkCZMmTWLBggUFXpsyZQrff/8948ePJyAgoERjb89dVEJP9+7dad68ObNmzSqwfP369QwbNox/dkwMCAhgwYIFHDlyBKPRyMyZM1m0aBFJSUm0a9eOefPm0ahRowc+Hg+iqH2qSHv27KFHjx4kJSXh4OCQv/zPP/8kICCAPXv24Ofnh4vL3SW4SzJ/eHh4lSgXKkRxyXlDCCFEScm5QwghRElUhvPGyyvOcCVeC6FR+ctsLUxoWt2eJl4ONK1uT9Pq9ng5WJZpBW6NRuHb0c159LsDRCVmMWTeAbrVdaWlryOtfB0L375TTS4OWMWVX19msO5PXjFZx1Dna3iNXYqJfRHJULkZcPznW4lQ8eoyc3vQZYJBpyZHZcTB9dPFC1xrBo41wKkWONdSk5S825Zo32u72bDuhU68vPwUey/H88WfwQD0buBOj1aNQWkCnaZC2F44EQBBf0D0CfXxTxqTOwlS1m7g4A0+HaBGZxztqjFvXEtGLTzM1vOx/HQgjGe7+N1ZNykC1k2CyMMAnLHrjn/8WJJu2gAwtFUNpg7oj73Vx2oS0L6vIP4S7PsSDs+HZmMg8gjEXbgTS5NR0PElcG9YIMxJ3Wqx/FgUETcz+eVweME4CvHTgTBiUrLxcrDkmc41//2gajTgWINjNV6kS+j/UC6sA+/20F5tyWZvZcrnI5oyuHk1vtwWzOmoZNacvMaak9doW8OJb8wXUT39BjjXgW5vF70d++qkt3qeM26PE341mNraGzSzScEi/RokR0JyhPox7TrkpkN8EAApGkf+0jUm2KYt0yZPxsLereC8ns3gqY1w+U/Y/h7cDIEtr0PgIujzEdTtB4ELIXQXmFjAYz+BSQnaKWo0MGQepMWqiWtb34Stb6nfK42GQcPBYHt3dTUAspLh1K9wdBGk3KpupTHF4NUKTdQRtLtmQm4q9PpArYhVCEVRGGx2Aowh5Gosma8fRty56+wJjuPVPnUZ1LQa+0Li2XUpjv0h8WTk3mmPaKbV0M7PiV713WhTw6n4+/wfUhnOHUIIIaoOOW8IIUTlVaoJUTVr1sTDw4MdO3bk90jNzc1l7969fP7556W5qSrJ29ubFStW8O2332JpaQmoLc6WL1+Oj4/PfY8tTRs3bmTIkCEAfPHFF3zzzTcEBARQt25dPv74Y/r06UNwcDC2tqVXtv2/LDQ0FE9PTzp27FjRoQhRKcl5QwghREnJuUMIIURJVIbzRruaThiz0+napAbNfRxpWt0BXycrNGVQBerfOFiZseCJVoxeeITwm5mEH45gyWG1jYe7nTmtfB1p6aMmSDWsZsdvRyP535YgcvVPcdy6Ph8oi/BNOQY/dIORi8H3b9c7cjPg2E9qIlRmwq0N+kLXN9REHkWrVtpJi4HUW49brdhIjYGsRLUak5PfnYdzLXWZRvvA+25vacrP/m34YlsQC/dexcpMy8whje4kgWk0UKuH+kiPhzPLIeaUmtSVfgPS4yA7GQx5atxp1+9Mfvxn9aNTLVrU6MxPLRvw+jFbPtsaRHNvB1r7OsLZlfDH65CbRo7Gkvdyx/N7XBdAoXcDN6b1qUfDan+7Ca7JCGg0HIL/UBOirp+B4z+pr5nZqJWM2j+vVkQqhLW5Ca/1qcvba88xd9cVRrSqjoOVWaFj49NymL9brQ71Rr96WJgW/3gn2dTB0Gsm2h3vwPZ3wKtlgYS1TrVd6FTbhVORSSw+GM6Wc9cxj9xDdbO1GFDY6DOdHjot9rdu8DUajUTczORkZBInIpI4GZlMcGwqhvx7Os0x1brTrmZDetZ3o1d3N3ydrUGXrVaTSolkY0gOr+zJw9TEhI3jO2FhX8TNhYoC9QZA7d5qItye/0HCZVg+Gnw7wbVj6rh+n4BrvWIfk3wm5jD2dzixWE1wu3YMIg+pj61vqj8/DYfeSY66GQpHF8LpZWpyF4CVM7R+Bto8i97CiUuLp9Ao5nc48K2aODXw68J/PvR5sOsjAMw6v8ji+gN5b/15TkYm8/Efl/j4j0sFhrvamtOznhs96rvRuY4LNuZl0liiyqgM5w4hhBBVh5w3hBCi8irxfzbp6elcuXIl//OwsDBOnz6Nk5MTPj4+TJ06lU8//ZQ6depQp04dPv30U6ysrBg7dmypBl4VtWzZkqtXr7J27VrGjRsHwNq1a/H29sbPz+++x5aW7Oxstm/fzkcffYTRaGTWrFm88847DB8+HIAlS5bg7u7Ob7/9xqRJkwqdIzc3l2nTprFmzRqSkpLw8PBg0qRJTJ8+PX9MQkICw4YNY9u2bXh5efH1118zePDg/Nf37t3LG2+8wZkzZ3BycmL8+PF8/PHHmJiY4O/vz969e9m7dy+zZ88G1O/BGjVq3HPfLly4wJtvvsn+/fsxGo00b96cgIAAatWqlT/mq6++4uuvvyY3N5cxY8Ywa9as/HJrS5cuZdasWQQHB2NtbU3Pnj2ZNWsWbm5uhIeH06NHDwAcHR0BGD9+fP4xA/WuLF9fX8LDw+nevTtNmjRBq9WyZMkSzMzM+Oijjxg3bhwvvvgiq1evxs3Nje+++44BAwYUmP/2fv69QpgQlZ2cN4QQQpSUnDuEEEKURGU/b8x4tAFbtGE8MqBepSg536iaPXvf6M7hqzfVhJOIJC7EpHIjNYct52LZci4WAK1GQX8rC6V3A3emjngHbeZY+H28WrUoYJDaBqzNM7cqQs25kwjlWENNhGo6+k77MQAbV/Xh2ayc91ql1ShMH9CARxp7YmNhgpeDZeEDbVyh08t3L8/LuZUgFXcnUSo+GMIPQOxZSAyFxFC6AoEWEGrw5OwvjWlSywzzkD8AOGmsyytZzxNldKdjLWde71ePlj6Ohceh0UCDR6H+ILVN3rnV4FoXWk9QWwz+i5GtvQk4FE5QbBpzdl7h/UcbFjru278uk5Grp2l1ewaXsD0agKHNc2hjjqtJP6v8YdI+sC5YJb2FjyMtfBx5p7cPFj9OgxxYkteXmYctsDy+k4FNPUnJ0nEyIombGXe3SfRysKSxlx0hN9K5mpDBgSsJHLiSwIebL1LL1ZpeDdzpWd8NGwtXXj9wCCMa3nmkAfU9ilFpXWsKbSdC01Gw/2s48j1EHFRfq9tfTUi6X2ZW0OEF9ZEcBRc3wMX1anJUxEH1sfVNcGuotvHjVuaXW0M14a3JSDC99X2q03HFfRD1mrfHZMtraqJVdgoMWwgm/0h2O7NcTe6ydIKOL9HIwp7Vkzuy6kQU/9saRHKmjiZe9mpSWQM3Glezr5AkzYpU2c8dQgghKhc5bwghRNVU4oSo48eP5ydnAEybpvYrv52g8eabb5KVlcWUKVPy26xt37697CoKGY1qye3bDAb181ytetGgLJlaFVmWuChPP/00ixcvzk9y+vnnn5kwYQJ79ux5oLGlYefOnXh4eNCoUSOuXr1KbGwsffv2zX/d3Nycbt26cejQoSIToubMmcPGjRv5/fff8fHxISoqiqioqAJjZs6cyRdffMGXX37J3LlzGTduHBERETg5OREdHc0jjzyCv78/v/zyC0FBQUycOBELCwtmzJjB7NmzuXz5Mo0bN+bDDz8EwNXV9Z77FR0dTdeuXenevTu7du3Czs6OgwcPkpeXlz9m9+7deHp6snv3bq5cucLo0aNp3rw5EydOBNREr48++oh69eoRFxfHq6++ir+/P1u2bMHb25s1a9bw2GOPERwcjJ2dXX5Vr1q1arFo0SKOHTuGVnvnbq0lS5bw5ptvEhgYyMqVK3n++efz2xj+3//9H99++y1PPvkkkZGRBeY/duwY1apVw9raugRfWSEqVqU7bwghhKj05NwhhBCiJOS8UXLONuYMalqNQU3V5JesXD1nryVzIlJNkDoRkURSpg4zEzWp5KkOvmolJet6MHEnbJ4GZ1fAXx/A7k9Bn6NO7FjzViLUqIKJUJVMM2+H+1vRxFytyFRYVaasZLUVXvgBCN+P8fpZammuU8twHUJAZ9QyK+8xFugfpamPM5/3rUfH2i53z1MYRYE6fdRHCWg1Cv/3SAOe+jmQX4+E81QHX2q4FLymdPlGGisC1bZs7w5seH9JMYoCg+dC7Hm19dyaZ+CJtYVWLnI/9hnkXMdg74Nd+w+pfzSOoNg0Vp+4lj/GTKuhsZddfrWylr6OuNtZ5L9+NT6dXUFx7AqKIzAskdD4DELjr7Jo39X8MT3ru/FUB9+S7YeFPfT5UE2A2v2pmvA2+LsSX/8tkoM3dHxRffwzOep2G8Q6faH9FPDrXuR2jS2eAitHWPscXFgLOWkw6hc1+QpAl6VWuwLo8pq6X6htM0e38WFYi+pk5uYVWTHsYSHnDiGEECUh5w0hhKiaSpwQ1b17d4xGY5GvK4rCjBkzmDFjxoPEVXy6TPj0zp1LGsChfLYM/xcDZiVLTHnyySeZPn064eHhKIrCwYMHWbFiRaFJTiUZWxo2bNiQ3y4vNla9G/CfvW3d3d2JiIgoco7IyEjq1KlD586d86si/ZO/vz+PP/44AJ9++ilz584lMDCQ/v37M3/+fLy9vfnuu+9QFIX69esTExPDW2+9xfvvv4+9vT1mZmZYWVnl9+T9N/PmzcPe3p4VK1bk34lZt27dAmMcHR357rvv0Gq11K9fn4EDB7Jz5878hKgJEybkj/Xz82POnDm0bduW9PR0bGxscHJyAsDNzQ0HB4f8sba2tmi12rtibdasGe+++y4A06dP57PPPsPFxSV/e++//z7ff/89Z8+epX379vnzu7q64uHhgaask/2EKEWV7rwhhBCi0pNzhxBCiJKQ88aDszTT0s7PmXZ+zoDatiz8ZiYOlqY4Wv8jacLMGoYtUNt9bXlDTYZyrAnd3oQmo0D7kLbasnRQ26/VGwCAkpVM9NldbP9jNQ7GZBbn9SfXvTmL+tWjZ323O636yljXuq50q+vK3svxfLY1iAVPtirw+qdbLmEwQr9G7rSt6XT/GzK3hdG/wg894eoeNSGn57sFx0QchsBFAGgGz+axWvUZ3r4eh6/eZPuFG3g5WNLS14FG1ezv2bbPz9UGP1cbnu3iR2q2jv2XE9gZdIM9wfEkZuTiZmvOlyOa3v8xdvSF4Qvvb93i+mdyVOQRqNYcXOoUb/3Gw8HcDlY+AVd2wK/DYOxK9fvw2I+QGq22m2zz7F2rmploMPtnRamHkJw7hBBClIScN4QQomp6SK9QVBwXFxcGDhzIkiVLMBqNDBw4EBeXwu8GK8nYB2U0Gtm0aRMrVqwosPyfFw6MRmP+sueff55ly5blv5aeno6/vz99+vShXr169O/fn0GDBhWoMgXQtGnT/OfW1tbY2toSFxcHwKVLl+jQoUOB7Xbq1In09HSuXbuGj49Pifft9OnTdOnS5Z5l6Rs1alSggpOnpyfnzp3L//zUqVPMmDGD06dPk5iYiMFgANQEsIYNCy83fi9/PwZarRZnZ2eaNGmSv+x2Itrt4yKEEEIIIYQQQghRXhRFoabLPW4CVBRoNV5NikoIUavaPKyJUEWxdMCr3XBq2Hfml8PhTGxZnYFNPCukLdk7AxuwPySePy/EEhiWmJ/4tD8knj3B8ZhoFN4e0ODBN+TWAB6dA2ufhX1fQvW2UPfWdUFdFmx8UX3e4gmo1RNQv9c61nKhY637u+ZpZ2HKwKaeDGzqid5g5GJMKu725jjbmD/4/pQXB2/1UVJ1esNT62HZKIg6oraxHBmgtv0D6D4dTC3uNYMQQgghhBBC/KdV/SsVplZqpaZbDAYDqWlp2Nnaln0VHVOr+1ptwoQJvPiiegFg3rx5pTa2MHZ2dqSkpNy1PDk5GTs7u/zPAwMDyc3NpXPnzgD5FY1iY2Px9PTMHxcXF5efrDNz5kwmTZqEjY1N/rFu2bIlYWFhbN26lb/++otRo0bRu3dvVq9enT/HPxOTFEXJTzD6e8LVbbczru/3rq7b7evu5V4xZWRk0LdvX/r27cvSpUtxdXUlMjKSfv36kZube18xFba9vy+7va+3YxBCCCGEEEIIIYSodFzqFL+izUOqR303etR3q9AY6rrbMrqND8sDI/nkj4usm9IJI/DJH5cAeKpDjXsnwJVE05Fqcs6xH2HtRJi0T624tOczuHkFbDyg7yels61/0GoUmlS3L5O5Ky2f9vD0H/DrcLhxDr7vqFZtc6kHzR6v6OiEuH/BW8HKGbzbVnQkQgghhBCiCqv6CVGKUrBtncEApnp1WSVtK9a/f//8RJp+/fqV2tjC1K9fn61bt961/NixY9SrVy//8w0bNjBw4MD8Kkk1a9bEw8ODHTt20KJFCwByc3PZu3cvn3/+OaC2h7OwsMDOzq5A8pmdnR2jR49m9OjRjBgxgv79+5OYmJjf9u1eGjZsyJo1awokRh06dAhbW1u8vLwAMDMzQ6/XF/sYNG3alCVLlqDT6e5ZJaooQUFBJCQk8Nlnn+Htrd6tdfz48QJjzMzUMtMliaskynp+IYQQQgghhBBCCPHfNa1PXTaejubMtRQ2nY0hW6cnKDYNe0tTXu5Vu3Q31u9TiDkF0Sdg1Xjo/zkcmqu+Nugbta2bKD0eTWDCn/DLUEiJVJf1ek+qtomqKz4Ylo8Bc3t44wpIi0chhBBCCHGfKmfG0H+cVqvl0qVLXLp0qUCbtgcZm5KSwunTpws8IiMjmTJlCqGhobzwwgucOXOGy5cvM2/ePH766SfeeOON/PU3btzIkCFD8j9XFIWpU6fy6aefsm7dOs6fP4+/vz9WVlaMHTu2yDi+/fZbVqxYQVBQEJcvX2bVqlV4eHjg4OBQrGMzZcoUoqKieOmllwgKCmLDhg188MEHTJs2LT/pqkaNGhw9epTw8HASEhL+tYrSiy++SGpqKmPGjOH48eOEhITw66+/EhwcXKyYfHx8MDMzY+7cuVy9epWNGzfy0UcfFRjj6+uLoihs3ryZ+Ph40tPTizV3cd2ef9u2bWUyvxBCCCGEEEIIIYT473K1Nef57rUA+OLPYL7afhmAl3rWxsGqlJMNTMxh5BKwdFITo5YMAqMeGg2H+gNLd1tC5VwLntkGtXqpLQnrD6roiIS4f1d2qh9zUuDasYqNRQghhBBCVGmSEFVB7OzsCrSse9Cxe/bsoUWLFgUe77//PjVq1GD//v2EhobSt29f2rRpQ0BAAAEBAYwcORKA0NBQrly5clcFqjfffJOpU6cyZcoUWrduTXR0NNu3b8fW1rbIOGxsbPj8889p3bo1bdq0ITw8nC1bthS7faGXlxdbtmwhMDCQZs2aMXnyZJ555hnefffd/DGvv/46Wq2Whg0b5revuxdnZ2d27dpFeno63bp1o1WrVvzwww/Frhbl6upKQEAAq1atomHDhnz22Wd89dVXd8U9c+ZM3n77bdzd3fPbHJYWLy8vZsyYwcyZM/H09Cz1+YUQQgghhBBCCCHEf9sznf3wtLcgOjmL+LQcfJ2teKpDjbLZmIM3PPYDoIA+V02OeuTLstmWUNlVgyfXwpB5alcFIaqqq7sLfy6EEEIIIUQJSd3cchIQEHDP19evX39fY2+Pv9c6rVq14s8//yzy9Q0bNtCzZ09sbGwKLFcUhRkzZjBjxox7xvN3EydOZOLEiUW+bjQa71qWnJxc4PNu3boRGBhY5Bx169bl8OHDxY4J1LZ527ZtK/S1wo7drFmzCnz++OOP8/jjjxdY9s99ee+993jvvfcKLJs6dSpTp04tsGzPnj13bS88PPyuZf+c/9133+Xll1++q0WhEEIIUZhlRyPZcVVDrzwD99ExVgghhBBCCPEfY2mm5Y1+9Zj2+xkA3u5fHzOTMrzGVLs39J4Buz+FR2eDtUvZbUsI8d+QlwvhB+98Hrober5b9HghhBBCCCHuQRKiBNWrV2f69OkVHYYQQgghSklMchYfbQlGb9Cw4lgUz3atXdEhCSGEEEIIISqBoc29OBWZjKlWQ//GHmW/wc5TodMrUrFICFE8146BLgPMbCA3HWJOQlYyWDpUdGRCCCGEEKIKkjIzglGjRtGlS5eKDuO+TZ48GRsbm0IfkydPrujwhBBCiHL3y+EI9Aa10uD3e8PIzM2r4IiEEEIIIYQQlYFGo/DR0Ma8/2hDlPJKUpJkKCFEcd1ukVe3P7jUBaMBwvdXbExCCCGEEKLKkgpRosr78MMPef311wt9zc7OrpyjEUIIIR5Q4lWwdFQf9yEzN4/lgZHYk46LJoPQDHcWHwznhR5SJUoIIYQQQgghhBCV2NU96ke/7mDlBAmX1WUNHq3AoIQQQgghRFUlCVGiynNzc8PNza2iwxBCCCEeXMxp+LE32HrAMzvAzrPEU6w7FY1lViwbLWbgRAoDcz5m4V4Tnmjni72VaenHLIQQQgghhBBCCPGgspIh+oT63K87WDlD4CII3V2RUQkhhBBCiCpMWuYJIYQQQlQWuz4Cgw5SouC3UZCTXqLVDQYjK/efZ7HZF7hxExPymGG9ltTsPBbtDy2joIUQQgghhBBCCCEeUPh+tUWec21w8IYanUDRQmIoJEdWdHRCCCGEEKIKkoQoIYQQQojKIOIQXPkLNCbqXZCxZ2H106DPK/YUBy5f5/WU/9FAE4XBygUjCh3yAmmhhPDzgXDi03LKcAeEEEIIIYQQQggh7lN+u7we6kcLe6jeuuBrQgghhBBClIAkRAkhhBBCVDSjEXZ+qD5v+RSM/R1MLCFkO2x5XX29OHNsmkpX7TlyNZbox6wk0qkzADNs1pGl0zNv95Uy3AlxT7mZsHYSHF9c0ZEIIYQQQgghhBCVz+3WeLV63Fnm173ga0IIIYQQQpSAJEQJIYQQQlS0Kzsh8jCYWEDXN9Q7IB/7EVDgxGI4OOtfp7i59WO6ZmxDb1RIemQReDYj2HMYRo0pzXSn6ag5z29HI7mWlFnmuyMKceY3OLsCNk+F08srOhohhBBCCCGEEKLySI5UW+MpWqjR+c7y29WiwvaCwVAxsQkhhBBCiCpLEqKEEEIIISqSwQA7Z6rP204Eu2rq8waDoP//1Od/zYBzq4ue4/RynAO/AuA3l1dwbz0YgCwzFwwt/QGYab2WXL2eOTtDymAnxL/6exLUxhfh6t6Ki0UIIYQQQgghhKhMbrfE82qltsq7rXprMLOBzJtw41yFhCaEEEIIIaouSYgSQgghKpmwhAySMnIrOgxRXi5thNizYGYLnV4lOjmLzNw89bX2z0O759Xn65+HiEN3r391L8aNLwKwIO9Rag14qcDLhk5TwdSKOrogemtOsvrENULj08twhx5MbNQVUpLiy2dj2Slw/WzxWhI+iPhgiD6OUdGir90PDHmw8km4cfG+pgtLyGDjmZhSDlIIIYQQQgghhKggt1vi3W6Rd5vW9E7FKGmbJ4QQQgghSkgSokS5UhSF9evXV3QYQghRaR0OvUnPr/fQ7tOdTFl2gt3BcegNZZysISqOPg92f6I+7/AC28J1dP1iN32+2ceN1Gx1eb9PoP4g0OfC8sch4W8VnuIuwconUQx5bNK3Z4Pzs3So5VxwGzbu0G4yADOs12I0Gvhmx+Vy2LmSMRiMrNy4GYcf26OZ3ZT4Y2vLakMQtg/WPgdf1YOFXWDNs5BThklip38DYJe+OV3D/Ul1aw05KbBsJKReL9FUW89d59G5B3jt99Ocikwqi2iFEEIIIYQQQojyYzCoLfEAavW4+/XbbfNuV5ESQgghhBCimCQhqpz4+/ujKAqTJ0++67UpU6agKAr+/v4lHnt7/NChQwvdbvfu3Zk6depdy9evX4+iKHctDwgIoH379gXi+Pvj9msVqah9EkKI/4IFe0MxGiFXb2DLuVieXnyMTp/t4sttQYQnZFR0eKK0nV0JCZfB0pEz3uN4efkp9AYj0clZTAg4RkZOHmi0MPwH8GoN2cmw9DFIj4e0WDWhJieFM0oDXtdNxr+zX6Hndzq9DOb2VNeFMVh7mD/OXudCTEq5725RkjNzeS7gME2O/x8Wig5bMnH942lytrwDel0pbSQK9n4Bc5rDkkfVY5+Xpb52fjX80BPigkpnW39n0KvbAlbldSE63UiPa8+RbOkLqdfgt1HFSsbKzTPw4aaLPL/sJOk5eTT3dqCag2XpxyuEEEIIIYQQQpSnG+fUlnhmNlC9zd2v364aFXkYdNnlGpoQQgghhKjaJCGqHHl7e7NixQqysrLyl2VnZ7N8+XJ8fHzue2xp2rhxI0OGDMn/vH///ly/fj3/sWXLljLbthBCVITcPAP6SlKA6UpcOnsvx6Mo8ONTrXm6Uw0crEyJTc1m3u5Qun+1h1ELD7P6xLU7LdVE1ZWXA3s+AyCp5YtMWB5MTp6BjrWccbY240JMKi/+dpI8vQHMrODxFeBYA5IjYPloNZEmJYp0mxqMz5qKtbUNQ5p7Fb4tS0fopLbSe9dqHSbk8fX2ylEl6kxUMgPnHKB+6M801ESQberAKs0AAMwDv8MQ8GiJqyjl02XDudXwy1CY1UStxpUcAeZ20OppeHYXPP0n2HpCQjD80APOriq9nQO4uhvSrpNktGGXoQU967tx02DDo8lTSdU4qO0SVz+tVgsrQkxyFmMWHebng2EATOrqx28T2+NuZ1G6sQohhBBCCCGEEOXtdis8305qi7x/cq2n/t+el60mRQkhhBBCCFFMVT4hymg0kqnLLPDIysu6a1lZPIzGkr2D3rJlS3x8fFi79k4LmLVr1+Lt7U2LFi3ue2xpyc7OZvv27QwePDh/mbm5OR4eHvkPJyene86Rm5vLiy++iKenJxYWFtSoUYP//e9/BcYkJCQwbNgwrKysqFOnDhs3bizw+t69e2nbti3m5uZ4enry9ttvk5envkno7+/P3r17mT17dn7VqvDw8NI5AEKIh9L//gxm/kUt8Wk5hQ+ID4bt76kttTJulmksAYfUZIfeDdzp3dCdDx5txNH/68X8cS3pXs8VjQKBYYm8vuoMbT7+i8e+P8SIIh4j5x9g7RfPcWj+JAx6/QPFtTs4jheWneR6Sta/D34YZSTA4XlqtabgrcVf78QSSInEYOPB46ebcDMjl8ZedvzwVGt+8m+DhamG3cHxvL/xgvo3h40rjFujJjdFn4DrZ8DKhbcs3icZW8a29cHCVFv09to9D1YuuOpiGG2yj11BcRwPT3zw/b9PRqORXw+HM2LBISxTQnjZdB0AFo9+SeOJi5hqnEaa0RJN1GGMC7vA1b3FnRh99CnOLZpI+qe1YM0zalISRs6ZNmO23RuMtV/CiGujGLEph6d2alnbdjl5vl1Blwlrn4XN09SEtdJwejkAG/QdaV3Lg5/Gt+bTYU24ofHkqaxpZGMGIdthy+tQyN+W+y7HM2juAU5GJmNrYcKiJ1sx/ZEGmGqr/J/xQgghhBBCCCHEnVZ4hbXLA1CUO1WipG2eEEIIIYQoAZOKDuBBZeVl0e63dhWy7aNjj2JlalWidZ5++mkWL17MuHHjAPj555+ZMGECe/bseaCxpWHnzp14eHjQqFGj/GV79uzBzc0NBwcHunXrxieffIKbm1uRc8yZM4eNGzfy+++/4+PjQ1RUFFFRUQXGzJw5ky+++IIvv/ySuXPnMm7cOCIiInByciI6OppHHnkEf39/fvnlF4KCgpg4cSIWFhbMmDGD2bNnc/nyZRo3bsyHH34IgKura5kcDyHEf9/1lCzWnYohI1dhyPzDzB3bkvZ+zpCdChfWwamlcC3wzgoW9jDw6zKJJSVTx5oT0QA83alG/nJzEy2PNPHkkSaeXE/JYu3JaH4/HkXEzUxORCQVOd/bJr8x3GQzZMKJbe1p9cjT9xVXRk4eb6w6Q0J6LilZOn59pm3hLdkeNvo8uPIXnF6qJkEZblX3CdkOnV6Bnu+D9h5/ZuVmwL4vAfhRM4KguDy8HCz5eXwbrM1NaO7twJwxLZi09AS/HY3E29GK57vXApfaMGY5/DIEFA1Xev/EH79nYKJReLKD771jNreBrq/Dn2/zpuUGVqd15ottwax8rn25f00zcvJ4e+05Np2JQYOBRfaLMcvJg7r9oclIGigKw8dNYWhAdb4zmUWDjEj4dSj0eAc6TwNNIclAmYlw9nfyTvyCSfwFmtxaHG10ZrW+K6v1XYnKdoc0gKxbD9W+y/Cu6WRmudegT8KvKMd/UpPORv0Cjv9yXO8lKxlj0GYUYI2+K690qomiKIxt50MTL3um/GbOy8kvsMB0FpoTizE6+KJ0eRUAvcHInJ0hzNkVgtEIjarZ8f24Vvg4l+xvTyGEEEIIIYQQotLS/a3q0+2kp8L49YAzy2/d8DSzPCITQgghhBD/AVU+IaqqefLJJ5k+fTrh4eEoisLBgwdZsWJFoUlOJRlbGjZs2FCgXd6AAQMYOXIkvr6+hIWF8d5779GzZ09OnDiBubl5oXNERkZSp04dOnfujKIo+Pre/Saiv78/jz/+OACffvopc+fOJTAwkP79+zN//ny8vb357rvvUBSF+vXrExMTw1tvvcX777+Pvb09ZmZmWFlZ4eHhUSbHQQjx8PC0t2Tt5PaM/+EAsek5fPvjYmZ6n6Ze4k4UXaY6SNGCb0cI3w8nAqDjS2rbslK24lgkWTo99T1s6eDnXGS8L/SozZTutTgZmUx8Wnah47xDl9Po1Ob8z12Pf0len3GYmJqVOK6AQ+EkpOcCcOBKAquOX2NUG+8Sz/OfkRCiJsqdWQHpsXeWe7UC59pwdiUcnA3XjsOIn8G2iHNV4CLIiCPB1JMv49pia2HC4qfb4Pa3Fmh9G3nw/qCGzNx0kc//DMLL0ZLBzaqBbwd46QQoGub/GQ9kMLCpZ/Hap7V6Gg59h33qNfxNd7IwbAD7QxLoWrf8kosv30jj+aUnCI3PQKtRWNboJH4hl9Q2doO+Ve/8BLrWdWXSsL4MXePERyaLGWWyF3Z9BFFHYdhCsHICg14trX/qVwjeAvpcTIAcoyl/GdugbfUE+HWjnqLlnSLiCb+ZyeoT17gSl85z1/rTTePJHLP52F8/jWFBVzTDF0K9/ve3sxfWoeRlE2yoTqpjI3rWv5NU3qS6PZtf7MJrq+z46HICH5j+irJzBjk2XqTXGcLUlafZH5IAwONtffjg0Yb3rgAmhBBCCCGEEEJUNVFH1FZ4tp7gWr/ocbeTpa6fVSu4Wxd+7UwIIYQQQoi/q/IJUZYmlhwdezT/c4PBQFpaGra2tmgKqx5QytsuKRcXFwYOHMiSJUswGo0MHDgQFxeXBx77oIxGI5s2bWLFihX5y0aPHp3/vHHjxrRu3RpfX1/++OMPhg8fzvPPP8+yZcvyx6Snp+Pv70+fPn2oV68e/fv3Z9CgQfTt27fAtpo2bZr/3NraGltbW+Li4gC4dOkSHTp0KFCpolOnTqSnp3Pt2jV8fHxKfd+FEA83P/MUfnBbh0fiIVx1MXBDXa53qoO21ZPQdAzYusMvQ9W70PZ8DsO+L9UY8vQGfjkcAcCETjVRksLAxgPMCq8EoygKrXwdC58s+E84/REAOe1fJvPIYnwM0QRuXkjbYS+VKK6UTB0L94YC0MHPmcNXb/LRHxfpVs/17uQbXbZaUUefe885FSNoDPceU6502WoVMEPRbQWzdHoSY65QLWwtStSdvzmwcoFmY6D5OHBvqC6r9whseBEiDsKCLjDiJ6jZ9R8TJsOBWQB8kjEUtKYsfKIVdd1t79r2051qEpWYxc8Hw3j99zN42FnQtqYTOHgTl5rNprNn8scVi6kFdH8LNr7Ey+abWKrrzpfbgulc2wWNpuyrRK0/Fc30tefI0ulxtzPnh0FONN146+ep70dgV63A+FFtvLmWlMmbuyZxgnp8ar4Ebch2WNgVGg2Fc2sgLSZ//HlDTVbqu3HeqQ9fPNGNOoUc08JM6urHqahkVh2PYtMZEwZkf8I8szm0yLkCy0dzpe5E/Eb9D42JaYn213h6OQqwWt8V/0417zrG9lam/PBUKxbuc+TnvxKYoN2KsuF5vtOexZBlQw9TDRM61aRLnQSI3Hf3Bnzag2nJ/x4VQgghhBBCCCEqhdDd6ke/7vk3SBXK1h3cGkLcRQjbC42Hl0t4lZouS70OZ2Ff0ZEIIYQQQlRaVT4hSlGUAm3rDAYDeSZ5WJlalXlC1P2aMGECL774IgDz5s0rtbGFsbOzIyUl5a7lycnJ2NnZ5X8eGBhIbm4unTt3LnIuT09PfH19CQkJAdTWd5MmTcLGxib/WLds2ZKwsDC2bt3KX3/9xahRo+jduzerV6/On8fUtOCbiYqiYDAYADUx659te4xGY/44IYQoVVnJmMxvTZNbSTw6rRXrdO1ZoetKXGZT5vu2oqmtgzq213tqQtTZFWpLNLd73LVWQtsv3iA6OQsnazOGWpyAOf5g5wWjlkD11sWfKPokrH4ajAZo8QTm/T7kVIKG9ldm4X1mNjkDnsHcovjtthbtDyU1O4967rYsmdCWkQsOceZaCu+sO88PT7VCAbh+Rq2YdO53yL77fPNPJkALh/bA0OLvV1nJSoKf+0N80D2HWQJet54b0JBVoyfW7fyhTj8w+UfVrUZDwb0xrBoPN86rre16vgudXr3T5u3wd5CdzGWDFxsMnfhyZFM61i464fmdgQ2ITs5k24UbTPzlOGundKSWqw1Lj0ai0xtp6eNAc2+H4u93s7FwYBbWiaFMMtvGN9FD6frlbka28uaxVl5UdyyblmxLj0Tw7vrzAHSq7czs0c1wWTMS8rLUpLGW4wtd79U+dbmWlMXKU90J0dRiucP3mKeEw6G5ABgsHNlt1p2v49tw0ViDwc2qsXR4E6zNi/9nrqIotPRxpKWPI+8NasjWc7F8eawmfa59x9Mm26h9+QeO/phBu8klSIZMuIJy7Sh6o8IOk25salW9yG1P7laLo15z2L3sCXoYj/KBfi7c/tY6cutRmFfOlEnFOiGEEEIIIYQQolxc/VtC1L/x66EmRF3dLQlRBj381AeSo2DyfnCQG8mFEEIIIQpTOTOG/uP69+9Pbm4uubm59OvXr9TGFqZ+/focP378ruXHjh2jXr16+Z9v2LCBgQMHotUW3Yrl5s2bREVF4enpCYCbmxt+fn7Url2b2rVr54+zs7Nj9OjR/PDDD6xcuZI1a9aQmJhYrHgbNmzIoUOH8pOgAA4dOoStrS1eXurb0WZmZuj1RVfyEEKIYrN0wOjXgwSb+uQ9Og/Tt67QcFIA8Y7NuJaczYjvD7P0SIT6O8mrFdQfpCYb7f6kVMNYfDAMgGda2mH25+uAEVKvqck6RxfC334nFikpAn4bDbpMqNUTBs0CRaH58DeIwwlP4jm9fnaxY4pPy+HnA+EAvNa3LmYmGr4Y0QxTrcLxS1c4v+4LtQLSom5w7Ac1GcrGHdwa3fNhRKF68hG4frrEx6lU5eXAiifUZChz+/z4dC4NuGldm1CNL5cM3vmP04bafKYbQ/vsuTQKmsBje5xZeSqW9Jy8u+d2qQ3P7FArRxkNsPNDWD4aMhMhPZ68Q2qC89d5o3ild30eKyJR5jatRmHW6BY093YgJUuH/+JAYpKzWHbkVlWxzsWsDpU/oQn0VBvIPf//7d13eBTl2sfx7+6mQxIIIYUaOtJLqEpVKYLSBEREQAQBwRfL8YiiFPWIHI+gICCKoIKCdEQE6SK9i0iHEKTX0AIpO+8fA8EYElI2uym/z3XNxezsMzPP3Anektx7Px6LKeIZzV+Xohm9/AANRq2i2+RNLNh5gpuxjsu1K/ed4Z0FZjHU8w+V4Jvn6hC47ztzKUp3H3j802Q/CWqxWBjZoQr1ShZge0xRWkaP4HrFLlC2JZEPj+dRyyR6ne3IIWtJ3m1biU+eqpamYqh/8vFwo0PNInzXtyFNX57CjyXfASD81Pfs27oy9Rfa9T0Aa+xVaRpeBV+vlLtL1SkdRMWBM9jg/xinvUoRX7DCff8+YU1bxyoRERERERGRLOP6BXMJPEhlQdTtMYdXp+5nZTnZgaVwejfcvAyr/uPq2YiIiIhkWdm+Q1R2ZLPZ2Lt3b8K+I8ZGRUWxc+fORMcCAgLo378/48aN48UXX6RPnz54e3uzbNkyJk+ezLfffpswduHChQwfPjzh9bVr1xg2bBgdOnQgNDSUiIgI3nzzTQIDA2nXrl2y8xg9ejShoaFUq1YNq9XKrFmzCAkJIV++fCk+5x39+/dnzJgxDBw4kAEDBrB//36GDh3KK6+8ktCFKiwsjE2bNhEREUHevHkJCAjIst3ARCTri+8whXVLl/NYlcfA3Z1KhWHRgAa8OmsXy/eeYcj8P9gacZH321UmT9MhsO8n2LvQ7MZUuEaG77/7ryi2RFzC3WbhuWtfwPVzEFjO7ED15wL4+XWI3ABPjAXPZJb/ir4E0zvC9bNmd6KOX4PNLJTw8snLrgr9CfrzPUrtm8iNa/3xyXv/VtqfrTpEdGw8VYvm49EKwWCPp9zVjfwU8iXFz6/B8/fbhUA2T3igNVR/Bko0AmvKec2Y3QvLH7Oxrf4Anp2bllA5jt0OC16EY7+Bhy+xzy5i+cWC/LD1OGsOnMN++2dqPh42WlcJpWN4UaoWycfpfWc5uPU4q/afZduxS2w7dolhC/+kVZVQOoUXpVZY/rvdDD18oO14KFYPFr8GB3+BzxsRle8B/ONusMteEt9qbXnp4dLJz/NvvD1sfNk9nPbj1xN58QatPl3LpRuxhPp70bxiSNpjUKEdBI/G/cxuVtXbxU/Bfflh63HWH77A2oPnWXvwPH5ebrSpVphO4UWpVNgv3Z0ad/8VxYDvdmA34MmaRXir1QNYrpyAZUPNAQ+/AwEpF3V5uFmZ2K0mT05Yz8Gz1+hw4mm61C7G+4v3EhMXS+F83kx4pgZViuRL1xyTU7xAHoo/+ypbRm+kVtQveC1+iVuVNt+/05o9ntjt03EH5tgb8u/6Yam6X1BAAEEvf5/heYuIiIiIiIhkeUfXAIa5FJ5vKn62Uby++cGgqEi4eAQKlMr0KWZZmz+/u79rBtQfCMEVXTcfERERkSxKBVEu8vfl6hwxdvXq1VSvXj3Rse7duzN16lTWrl3LW2+9RbNmzbh58yZly5Zl6tSpdOzYEYDDhw9z6NChRB2obDYbu3fv5ptvvuHy5cuEhobSpEkTZs6cia9vMr+QB/LmzcuHH37IwYMHsdls1KpVi8WLF6e6YKlw4cIsXryYf/3rX1StWpWAgAB69erFkCFDEsa89tprdO/enQoVKhAdHc3Ro0cJCwtL1fVFRJKweSQ55O/jzhfP1mTSr0cYtXQ/83ee5I+TV5j4TA1KV+lsLpu38j3olvGCnjvdoV4rcQzvvbMAC7T5zFwqb9NE+GUI7JkHp/+ATt9AcIXEF4i7BTO7wfn94FsInv4BvBLnjeptBnJy7xcUMs6wYc4o6nVPucPVX5du8N2mSABeb14Oy96F8PMbcPUkZTGnuNsext6QNnTqMQh8AlL9vPENXoc/5mE9sgKOrTd/mOVsq96D3bMwrG4srvAhb391hovXjye8XSssPx3Di9KqcmiiTkMtKoXQolIIZ67cZO72E8zaepwj568ze9tfzN72F0UDvAn29frHzUoR5vcRr0a9T2hUJP5RZlx/DurNBx2qpKnIKDCvJ1N71qL9hPVcuhELwLP1wnC3paMo2Go1l4H8rhPuWz6nbaHNtLXCrRLxnL8Ww/lrt4iJt8N2uLkddnp4k7/6E4Q17gl5CqT6Nn9dusFzX2/hRkw8D5UO5IP2lc2lFn8cBDFXoUhtqN0nVdfy93ZnSs9atBu/nn2nrzJ04R4AmpYP4uNOVcnnk/TvsqOU6TaWC+NqE2Y/zoZpb1Hv+dEpn3D0V9yvnyLK8MFepiXFCmTOMoQiIiIiIiIi2daR1eafqekOBeCZF4rWhmPrzHNza0HU2X3m81us5gfxjq0zu5M/PdPVMxMRERHJclQQ5SRTp05N8f358+ena+yd8SmdU7NmTZYsWZLs+wsWLKBp06bkzZs34Zi3tzdLly5NcR730rt3b3r37p3s+8Y9Wtlevnw50etGjRqxefPmZK9RtmxZNmzYkOa5iYikhcVi4YVGpaheLD8DvtvOobPXeGLcOj5p3pNHrbPh8AqIWAdhD6b7Hmev3OTH30+Slxv0vHR7Obt6L0LRWuZ+3X7mUn2zesCFg/BFU3h8DFR9ynzfMGDhQHPZMQ9f6PoD+BdOch8PTy9OVBtEoR2DqXB0ClGXXsY/f2Cy8/p0xUFi4u3UL1WAB61/wOznwB4H3gFQpTMHCj1BmxmXsEdC/ohYHq2Q7KWSCijJsQINKXFhlfnDmp4/J7tUWqbYNhXW/g+AKfkHMWJjPiCGIF9PnqxZhCdrFqFkwbwpXYFgPy/6NS5F30Yl2XbsEj9sPc5Pv5/i+MVojl+MTjJ+KwEs5V1GuX9OS9sWtrlVo3+v59NVyFSyYF6+eDacrl9uwtPNSpfaRdN8jQRlmkGx+hC5Ho5vBMATKHx7S7SwchywZRfxWz/A+kArLNW7mUszptARLCo6lp5TtnDu6i3Kh/gy/pka5jPv/B4OLTO7i7X57L5dxf6uSH4fvupei86TNnAzNp7Xmpejb8NSWK2Z+z2ULzCE7XVHUGDj/xF+/GsO7e5E6cr1kh0fs206HsDC+Po826BcsuNEREREREREciXDgCOrzP2STVJ/XskmtwuiVkGtXpkzt6zuTneo8q3g4WHwWW04sMR1Hzx0lWVD4eQO6DwtyYdDRURERO5QQZRQpEgRBg8e7OppiIhkSbVLBPDTSw146fsdbDhygd4/XmBm4cepc2EerHw3QwU90zZFEhtvMC7/XDyun4L8JaDJW4kHFa0NL6yFuc/D4ZUw7wXzBxwtR8Haj+D3mWCxQaepEFI52XvVaNWHiF3jzQ43c95PtsPN4XPXmLP9BABDamN2n7LHQaUO0HYCuHlSFuh9ci+frznCW/N2U7tEAP7e7ql+7gMhbQi7vB5L5AY4tALKPJLqczPk4HJY9AoAU2wdGXGiBh5uVoY+XoHO4UVxS2OBksViITwsgPCwAIY+XpFNRy8QE2dP/gTjQTZF7aVqjTp4eae/m1GtsACWvdwQC5aMdUWyWKDLd+b3kz0+2WHXY+JYumE7pU8toor1qLmU458LzI5kVZ8yl0v8x6cyY+Ls9P12GwfPXiPYz5OvetTCz8sdrp6BJW+Ygxr/GwqWTfO0KxfxZ9krjYiJs1MiME+az0+vGi16sH33HGpc/xXmv0hsuQ24e3gmHXjrKtZ9PwKwNV8LnimZ+g5qIiIiIiIiIrnCxSNwOdJcAi8tRTylmpidv4/+av4sIw0fssoRoi+ZS+QB1OkLgaWhRjfzA4DLhkKvX5z7wUNXOX8I1o0x97d/A/UHuHQ6IiIiknWpIEro1KmTq6cgIpKlFfT1ZNrzdRi97ADjVh1i4IlHWOv1E56RG+DQcijzaJqveTM2nukbj1HPuofm0YvNg0+MBY97LK2VpwB0nQ2//hdWj4TtX5utsS8fM99/fAyUTrmoyObmxsU6/yZswwCqHp/OhTOvUiC4SJJxo5cdIN5u0KGMlQoresGtK2YXodvFUHe8/EhZlu05w5Hz13n/pz8Z9WTV+z5zvN1gz8krXHMLwB7eC9um8bBi+O1OQ2krRjodeRCAkGJlUnfCqd8xZnXHYsQz396A4TfbUryAD+O71qBiIf803fte8ni60bR8cCpGFsrwvQCKF3BQIZB3fvMThSnIA7Sr2o7vN/dhyMLFtLWsor3bOvJdPQm/fWxuxepDtS7gXxQDmLzmMNaI8zzsYeXtRypQ6MJGuIC5DOTNyxBSBeq/lO5pF87nne5zM6JYt8+ImliX0vGH2fD9cOp1/0+SMcae+bjbb3LIXogHGzVP07KIIiIiIiIiIrnCneXyitY2l8JLrdBq4OkPN6Pg5E4oUjMTJpeF7ZgOsTcguBIUv921vtEbsGsm/LUZ9i++7895coTNkxLv1+2X+4rjREREJFXSvlaLiIhILmSzWniteTmm9KjFLe8gpsaZRVBXF78D9hS6AiXjx10nuXH9Ch95fGkeCH8OSjRI/gSrDRq/Ad3mgk+Bu8VQDf8FNZ5N1T2rP9qVg25l8LHc4uCcEUne33MyikW/n8KHm7wf/R5c+QsKlIGnpicqhgLwcrfx4ZNVsFjgh61/sfbguWTve/T8dUYt2ceDI1fSdsJGxv9pI7r2QPDIC6d/h70LUzX/O/ZuWkq+yfUI+SqcPf9pyNaFE4i+fjX5E6L+wj69I5aYa6yPr8C/YnrTrEIICwc85JBiqNzAYrHwdJ1ivN+vC1P8XqD2zXEMjB/EyYIPYVis5rJ7CwfCt22xfNuWfpGvMt3jAyZb3ydscVf4tq25HVgCVjdzqTxb6ruKZRWBIcU4UM3s4lbjyCSO7d+RZMzVzdMAWGxrwhPVki5hKSIiIiIiIpLrpWe5PACb292fnx1Z6dg5ZXX2+LuFQHVeuNsJyi/ULAgCWDEixS7gOcLNK7BzurlvdTN/RnrwF9fOSURERLIsFUSJiIikQZPyQfz00kOsDerKVcMb30t/smDGBOLiU18UZRgGX62L4FW3WRTmDPgVgUeGp+7kUk3NJfQqtoMGryZdYi8FFquVmw1vF3OcmZPQZemO//1yABvxzCowCa/zf4BPIHSdBT73XvKrVlgAz9YtDsAbc3Zz/VZcwnvXb8Uxa+txOk3cQJOPVjN+9WFOX7kJwOGrFt5Ycgqj7ovm4FXvQ3xckuvfS+SBnYT+/BxellgAKsbsInz7G8SNKsOmsc9yYPtqjL8XqN2M4tbXHbBeO81+exH6x7/C649V5vNuNdO0zJ+YKhfxZ9GABjR8oDA/xtam/vH+jCj1AzGNh0Dhmlz2LcNee1H22oty2bcMBFVMvAVXhpYfQmgVVz9KuoU/0Y9dXrXwtMQSPasf8XF3v3d9bp2hwIVtxBsWvGp0wctdn04UERERERGRLCwuxuw6tGyoWWjiDPZ4c8k7gJKN037+nXMOr3bQhFLh3AFYPhyiTjjvnv90YKlZ/OOdHyp3TPzeg/8HXvng3D7Y9b1Lpuc0u76HmGsQWO5uIdimia6dk4iIiGRZKogSERFJoyL5fZjcvwVbQ58GoNK+sXT/cgPnrt5K1fmbjl7E6/Q2nrMtMQ88Pga8/FI/Af/C0HEqPPzO3U+DpVKlh9qwx6MyHpY4IucNSzi+NeIiK/ed4T33qVS8vhHcvOHpHyCgRIrXe71FeQrn8+bE5WhGLdnHtmMX+ffs36n9/nL+Nft3NkdcxGqBxuUKMr5rDb7oVh2rxWDR7tN8cqOZ+UOc8wfg95n3nfuFM39h+74T+bjGAbeyHOuyhg3F+3LSEoSvJZo6FxZQdmEbjr1XlY3Th3PxVARnJz+F58V9nDXy8brnW3zR52F6NyypZcwywN/HnUndwnmjZXlsVgtT/oih9Y7afFdlKuEXRtAy5kMWPTibfK9uhf7rE2/9foNaz7v6ETLEYrUS3HUi1wxvysftZcsPIxPe8z+9DoB1RmXaNqrlqimKiIiIiIiIpOzWVVg/Dj6pCgv6w7ox8OP/gWFk/r1P7jSXvPP0h0LV035+qabmn8c3Qcx1h07tnv7aBl81g98+hnkvOCdG93Kn6KdGd3D3Tvyedz7zg5MAq/4DsdFOnZrT2O2w6XNzv04fqNUbLFZzCcaz+1w6NREREcmaVBAlIiKSDp5uNpr0GMYtj3yUsp6iUOR8Wn26lq9+O8rF6zEpnvvN2v2Mcp+E1WJA1S5Q5lEnzdos5rA9/A4ANS4uJvLg7xiGwail++ln+5EuthWABZ6cDEVq3vd6eTzdGNmhMgBfbzhGhwkbmLn1ONdj4gkr4MO/mpdj/RsPM7VnbR6rHErjsgV5qqTZwWnMb2fYUayneaHVIyEu+YKy6OtXOf9FewobZzhhCaZA73kUL1eNej0/JGTIPv54dBpb/R7lpuFOmD2Sugc/JuDzqgSdW891w5NPgt9j8v91oFbYvbtdSdpYrRb6NirFd8/XoaCvJwfOXOPNebuJsxu0qVaI15qVc/UUM1VI0dLsqWj+oLHK/k85cWQvGHbCLv0GQESRtgT5eblyiiIiIiIiIiJJXTsHK9+D0RXhl7fg6knIGwwWG+yZ65zuQneWuivRwFwCL60CSoJ/UbDHwrH1jp3bPx1ZA988AdGXzNcRa+Hwisy9572c3QtH15jFP8l90Kx2H/ArDFdOwOYvnDs/Zzm8Ai4eNovpqjwF+YtDucfM9zZ/7tq5iYiISJakgigREZH08vLDs/FrALzmMY/LV68xYtGf1PnPcvpP38aq/WeJtyf+1FjkhRtUOPg5ZawniPMuCM3/4/Rpl6/TjF3edXCz2Dm7cBhrD54n5Ngi/u0+wxzQYiSUb5Xq6zUoU5CnahUFwNvdxpM1i/DDC/VY9VpjXmxSmhD/xIUhdYIMBjQuCcAzu6twyzsIoiJh+zf3vH58XBz7xj9Fubj9XCYv8V1+oEBwkYT3rTYblR58nPBXZhPz8n42VXybA25lzXMNC7888AEj+j5DYF7PVD+TpE6dkgX46aWHqFvSLDSrUyKAUU9WyRUduGp1eIU9HlXwsdzi0sy+XN67iiDjPFcMH6o36+rq6YmIiIiIiIjcdSkCfnoVxlSCX/9rdmgqUBoe/xQG7YYmg81xi/8FFw5n7lyOrDH/TM9yeWB2S79z7pHVDphQMvYugulPmsuzlWgINW9/qG/5MLNTkTNtnmT+Wb415Ct67zHuXtD49tdx7f8g+rJTpuZUd7pkVX8GPPOa+3X6mn/umpEzn1lEREQyRAVRIiIiGVHrefANJdg4x7Rqe6lc2J/YeIPFu0/Tc8oWHhy5klFL9nH0vNnCe+mKpfS1LQTA7fGPwcc1HYvythwGQPjVFWybNYr/ut/+gULd/lC3b5qv917bSszoU5ctQx7ho45VqV0iIMWimJealqJ9jcJct3vw4fXHzYNrRt2z1fmWSf2pfv03Ygw3TraYTLGy1ZK9rl++AtTp+Bplh2zhWJfVRHReTrunemGz5vwCHVcJ8vViWq86zOlXn2971cHTzebqKTmF1WbDv/NEog0PKt3aiX3+AAA2ejeicliIi2cnIiIiIiIiApw/BLN7wac1YMuXEHcTCtWATt/Ai5uhZndw84SHXoHiD5rFP3N7Q3xs5swn5jpEbjT37yx9lx6lmph/Hl6V8Tndy87v4YdnIT7GLEJ6ehY0fRs8/eD0brOblrNEXzKLfQDqvJDy2KpdoGB5uHkZ1n2S6VNzqvOH4NBywAK1/9YlK+whCKoAsTdgxzSXTU9ERESyJhVEiYiIZIS7NzR6HYDax7/ix5a3WNMeRlQ+RwvvvZS6toVdv85nyMdjefeTz3hozzCzM1PRFlDhCZdNu1SV+mzzNX949HLsJDwtcdwq0wqavZeu67nZrNQtWYC8nqlrdW6xWBjZvgr1SxXg25hGnCAIrp+9+4m32zZ+9z51z84EYHftD6lQt0Wq51S8XHVKVQhP/UNIurnZrNQsnh8Pt9z1v5ZFSlVkV1mzECrYOAeAd62nXTklEREREREREdPVM/BVc/hjNhjxZgHSswuh90qo0Aasf/tAk9UG7T4HL384sQ1Wj3T8fOzxsPQtc6k7/6Lm0nfpVaIRYIGzexy/PNzGiTC/rxmzqk9Dx6/N7kt5CkD9l8wxK9+FuBjH3jc5O6aZxT7BlcyitZTY3ODhd8z9jRPgyqnMn5+z3PmZYdkWib93LJa7hWKbJ5nfZyIiIiK35a7fWonLWSwW5s+f7+ppJNKjRw/atm2bKdc2DIM+ffoQEGB2Stm5c2em3EdEXKx6N8gfZhb0TGtP8cVP8+zB/2Oi8S7TPT5I2N6+9CYPWCKIwpfAjp+6etYUfHwY8YbZOelk3kp4dpqc+IdhmczDzcqEZ2pSIjgfH8V0AMD4bUxCe+vtS6dRe/9/AdhY8iVqtno+mSuJuE6tzm+x360cAMeMEMLrN3PxjERERERERCTXs9thfj+4cd7snvPCr9BtHpRsZBaQ3Eu+otB6jLm/9n8Qsc5x84mPNTtPbZsCWMyinRQ6i99XnkCoP9DcX/wa/PoRGEbG5mgYZiHYkn+br+v0gzafmUVGd9TrD3mCzCUIt3+dsfulhj3+biFQnRdSF7Nyj0HROhAXDWs+zNz5OcvNK7Bzurl/ry5ZlTuBVz64fAwO/uLUqYmIiEjWpoIoJ+nRowcWi4W+fZMuQ9S/f38sFgs9evRI89g745Mr6GncuDGDBg1Kcnz+/Pn3XMpo6tSp1K1bN9E8/r7dec+VknsmV1q9ejUWi4XLly8nOr5kyRKmTp3KokWLOHXqFJUqVUr39W02G1FRUQ6YrYg4nM3d/IFRoeoQVPGeW2zgA5zPU5qj7qU50fhjrH7Brp41xcpWY0vZV9iZ5yH8npttdrtyMn9vd6b0rM0GnyYcsBfGcvMy8evGsn/bKh5Y/zJWi8GmAm2p88xwp89NJDVsbm74PDWZXZ7hbAh6GrdcsmSgiIiIiIiIZGGbJsLhFeDmBU9OgdCqqTuvUnuo1hUwYG4fc7m2jIq5ATOehj/mgNUNnpwMVTpl/LqPjoCGZtd2Vr4Ly95Of1GUYce6bAis/sB83fhNaPEBWP/xKzSPPND4dsHUmg/h1rX03S+1DiyBy5HgnR8qd0zdORYLPDLM3N/+DZw/mGnTc5qd35nLOQaWg5KNk77v4WMu/wjm976IiIjIbalb10YcomjRosyYMYPRo0fj7W3+0vnmzZt8//33FCtWLN1jHWnhwoW0adMm4XWLFi2YMmVKwmsPD49Mu3dOdPjwYUJDQ6lfv76rpyIima1UE3NLhjsQeHvLSup2fcfVU6BwPm++7FmXsZ8/xVj+R+y6cRQ0JuFtiWGXdx1q9v0Cyz9/ACWShRQtXZmQ15YQsXixq6ciIiIiIiIiud3p3bB8qLnf/H0IKp+281t+CMfWw6WjsOhls6Aqvd2cbkbBd09B5Hpw84bO30KZR9N3rX+yWKDpW+CdD5a+CevHml3HH/8kbR3Q7XFUj5yM7eJa83WLD6Fu0g+rJ6jRHTZ8BhePmH/eKZDKDJs+v3vPtHyQsXh9KNMcDi6F5cPgsf+mPN7NC3wC0j3NNIm7lbbCNbsdNt+OQ50+yX8v1nre/B44shrO7kv7972IiIjkSNn+t4uGYWC/cSPxFh2d9FgmbEYaP21Qo0YNihUrxty5cxOOzZ07l6JFi1K9evV0j3WUmzdv8ssvv/DEE08kHPP09CQkJCRhCwhI+X+KY2JiGDBgAKGhoXh5eREWFsYHH3yQaMz58+dp164dPj4+lClThoULFyZ6f82aNdSuXRtPT09CQ0N54403iIuLA8yuVWvWrOGTTz5J6FoVERFx32fbs2cPrVq1ws/PD19fXxo0aMDhw4cTjfnoo48IDQ2lQIECvPjii8TGxia8N23aNMLDw/H19SUkJISnn36as2fPAhAREUGTJmYRRP78+RM6ePXo0YOBAwcSGRmJxWIhLCwMMDtcDRw4kEGDBpE/f36Cg4OZNGkS169fp2fPnvj6+lKqVCl+/vnnJNcPCwvDZrMl6hAmIpITVCrsT/suL/C7vSRexk0CuMIhWylK9/8BN3cV44qIiIiIiIiI3FdsNMx5HuJjzKXTwnul/RqevtBhstnNac88sztPelw/D1Nbm8VQnn7mkn2OKob6u3ovwhPjwGKFHd/C7J5m0c39xMfB77Nwm/wwxS6uxbDYoO3ElIuhwOwU33SIub/+U/M5M8PZvXB0jflctZ5P+/mPDAUssG8RfPxAytuoEjC9k1kIl9GlB1NyZA1un1Sk0f6hcPV06s45vMIsPvP0hypPJT8uXzHzex7uFlCJiIhIrpftO0QZ0dHsr1EzyfEzTrh3ue3bsPj4pOmcnj17MmXKFLp27QrAV199xXPPPcfq1aszNNYRVqxYQUhICBUrVkw4tnr1aoKCgsiXLx+NGjXi/fffJygoKNlrfPrppyxcuJAffviBYsWKcfz4cY4fP55ozPDhwxk1ahT//e9/GTt2LF27duXYsWMEBARw4sQJHnvsMXr06ME333zDvn376N27N15eXgwbNoxPPvmEAwcOUKlSJUaMGAFAwYIFU3yuEydO0LBhQxo3bszKlSvx8/Nj3bp1CUVWAKtWrSI0NJRVq1Zx6NAhOnfuTLVq1ejduzdgFnq9++67lCtXjrNnz/Lyyy/To0cPFi9eTNGiRZkzZw4dOnRg//79+Pn5JXT1KlWqFJMmTWLLli3YbHc/lfL111/z+uuvs3nzZmbOnEm/fv2YP38+7dq1480332T06NF069aNyMjIRNffsmULhQoVIk+ePKn8qoqIZB9NHghmRZ3BsKU3pylIvl7zyOObz9XTEhERERERERHJHn4ZAuf2Qd5geGJs+js7FakJjQebS9Et/hcUqwsFSqX+/Ki/4Ju2cOEg+ARCt7mpX7YvPWp0Ay9/mNML/lwAt65C52nmEnf/FHMDdk43i5kuR2IB4qxe0H4SbpXaJB1/LxXaQeincGon/PoRtBzpyKcx3ekOVb415Cua9vODK8KDL8HGiWDYUx5rjzW7SR1cCkXrwIODoGyLpEsGZsTeRTC7J5b4GPJxGePbx+HZ+ZA/LOXz7iyBV/0Z8Myb8tg6fc0CsF0z4OGhZvcwERERydWyfUFUdtOtWzcGDx5MREQEFouFdevWMWPGjHsWOaVlrCMsWLAg0XJ5LVu2pGPHjhQvXpyjR4/y9ttv07RpU7Zt24anp+c9rxEZGUmZMmV46KGHsFgsFC9ePMmYHj160KVLFwD+85//MHbsWDZv3kyLFi0YP348RYsWZdy4cVgsFsqXL8/Jkyf597//zTvvvIO/vz8eHh74+PgQEhKSquf67LPP8Pf3Z8aMGbi7uwNQtmzZRGPy58/PuHHjsNlslC9fnlatWrFixYqEgqjnnnsuYWzJkiX59NNPqV27NteuXSNv3rwJnbPuFI/d4evri81mSzLXqlWrMmSI+SmSwYMHM3LkSAIDAxPu98477zBhwgR+//136tatm3D9ggULEhISglVLR4lIDvVwq05EFCtCYOGS5A1I3X/nRURERERERERyvf0/w5Yvzf22EyBPYMau99DLcHgVHPvN7DrV6xezO9L9nD8E37aFqOPgVwSeXQCBpTM2l9So8AR4zoQZz8DhlfBtO3h6JnjnN9+PvgSbvzQLbG7c7urkE0h8rT78crEoj97pLpQaVis8Msx8zi1fml2l7lfYkxbRl8yiHjCLfNLr0RHmdj8XDpsFYju/g+ObYEYXKFgeHvw/qPQkuGWwe/vO72HBi2DEYy/djOjIneS5dBS+agHd5ie/vN35g3BoOWCB2qnokhX2EARVhLN7YMc0qD8gY/MWERGRbC/bF0RZvL0pt31bwmu73c6Vq1fx8/XN9KIRi3ca1my+LTAwkFatWvH1119jGAatWrUiMPDe/zBJy9iMMgyDH3/8kRkzZiQc69y5c8J+pUqVCA8Pp3jx4vz000+0b9+efv36MX369IQx165do0ePHjz66KOUK1eOFi1a0Lp1a5o1a5boXlWqVEnYz5MnD76+vgnLz+3du5d69eph+dsnVx588EGuXbvGX3/9RbFixdL8bDt37qRBgwYJxVD3UrFixUQdnEJDQ9m9e3fC6x07djBs2DB27tzJxYsXsdvNT1RERkZSoUKFNM/p7zGw2WwUKFCAypUrJxwLDg4GSIiLiEhuEla5vqunICIiIiIiIiKSfVw9bRacANR9EUo/nPFrWm3Q/nOYUB9ObofVI+Hht1M+59TvMK09XD8HBcqYHYD8i2R8LqlVqqlZgDW9g1nYM7U1tBkHu2fDtqkQc80cl68Y1H8Jqj+DHTdiFy9Ox72aQMnGcGQ1rPoPtJ/kuOfY/i3ERUNwJSjuhJ+TFSgFj39idgXbOAG2fmV2GpvfD1a+B/UGQI1n79+h6V42ToQl/zb3q3UlvuX/+O3HmTQ7MxHLub0wpQU8MwcKJ10Jhs23Y1q2BQSUvP+9LBao8wL8+JJ5bt1+5vexOEf0pbsFiCIiIllE9i+IslgSL1tnt2ONi8Pq45Nlu+g899xzDBhgVqZ/9tlnDht7L35+fkRFRSU5fvnyZfz8/BJeb968mZiYGB566KFkrxUaGkrx4sU5ePAgYC5998ILL5A3b96EWNeoUYOjR4/y888/s3z5cjp16sQjjzzC7NmzE67zz8Iki8WSUGBkGEaiYqg7x+6MSw/vVBSupTSn69ev06xZM5o1a8a0adMoWLAgkZGRNG/enJiYmHTN6V73+/uxO896Zw4iIiIiIiIiIiIiIknY7Wbhyo0LEFwZHhnquGv7F4HHP4VZ3WHt/2DvjymPjzoOsTcgpAo8MxfyFnTcXFKraC3o+bPZIerMHzCp8d33giuZna8qtAXb7V+Pxcam/16PDDOv//sPZoFVSKX0X+uO6Muw+Qtzv84L6V/2MD18Q+DR4dDgFdg6BTaOhysnYOlg+HUU1Optzik13ccMA9Z8CKs/MF/XfRGavQfx8dx0z09ct4W4z+wCJ7bC109Al++hRMO759+8YnasAvOeqVW5Iyx7By4fg4O/QLmWyY+9fgE2fw4R66DFBxBaJfmxkrLrF8ziyQdam19n97Q3lBAREckMWbNiKIdr0aIFMTExxMTE0Lx5c4eNvZfy5cuzdevWJMe3bNlCuXLlEl4vWLCAVq1aJeqS9E8XLlzg+PHjhIaGAubycCVLlqR06dKULn235a2fnx+dO3fmiy++YObMmcyZM4eLFy+mar4VKlRg/fr1CUVQAOvXr8fX15fChQsD4OHhQXx8fKquB2Y3prVr1xKbzn/Y7Nu3j/PnzzNy5EgaNGhA+fLlk3Ru8vAwW8amZV5pkdnXFxEREREREREREZFsaNMEc4k4Ny/o8CW4eTr2+hXbmt2BMOD8/pS32BtQrD70WOSaYqg7givCc0sgX3HzdVgD6DoH+v4GlZ+8WwyVUYWqQ8V2gAErhmf8etfOwdetISoS8gSZxT2u4OUPDw2C//vd7BwVUNLs/vPrKBhdCRb/Cy4dS/58ux2WvHG3GKrJEGj+vrnU4B3e+c1uXiUamZ27pj0J+/7WqWvnd+bxwHJmJ67U8vCBmt3N/U0T7z3mciQsfh1GVzSLto79Bj/+n1nEJWlnGLBwAFw7DUfXKo4iIpKlZPsOUdmRzWZj7969CfuOGBsVFcXOnTsTHQsICKB///6MGzeOF198kT59+uDt7c2yZcuYPHky3377bcLYhQsXMnz43f9hv3btGsOGDaNDhw6EhoYSERHBm2++SWBgIO3atUt2HqNHjyY0NJRq1aphtVqZNWsWISEh5MuXL8XnvKN///6MGTOGgQMHMmDAAPbv38/QoUN55ZVXErpQhYWFsWnTJiIiIsibNy8BAQEpdgMbMGAAY8eO5amnnmLw4MH4+/uzceNGateunagoLDnFihXDw8ODsWPH0rdvX/744w/efffdRGOKFy+OxWJh0aJFPPbYY3h7e5M3bzraxybjzvWXLl1K+/btyZMnj0OvLyIiIiIiIiIiIiLZzKnfYfkwc7/5+xBUPnPu02o0VO8G8fdZMcHNyywSygrLlAWUhH7rzeUEA0vff3x6NX3b7Jx18BeI+A3Ckl+FI0WXj8O3beHCIchTELrNdX2XHXcvqNnD/Nrv/RF+Gw2ndprL0W2ZDJU6wIP/l7gzVnwcLBwIu253d2r5X6jT597X98wLT/8Ac3rBvkUw8xloOx4qdzI7N4F5blq7ZNV6HtaPNZczPLvv7t+LM3vgtzHwxxwwbn/4PLQqnD9kLgv55wKzAFDSZutXsH8x2DzgyclmUZqIiEgWoQ5RLuLn55doybqMjl29ejXVq1dPtL3zzjuEhYWxdu1aDh8+TLNmzahVqxZTp05l6tSpdOxofrrg8OHDHDp0KFEHKpvNxu7du2nTpg1ly5ale/fulC1blg0bNuDr65vsPPLmzcuHH35IeHg4tWrVIiIigsWLF6d6+cLChQuzePFiNm/eTNWqVenbty+9evViyJAhCWNee+01bDYbFSpUSFi+LiUFChRg5cqVXLt2jUaNGlGzZk2++OKLJMvWJadgwYJMnTqVWbNmUaFCBUaOHMlHH32UZN7Dhw/njTfeIDg4OGGZQ0cpXLgww4YNY/jw4YSGhjr8+iIiIiIiIiIiIiKSjcTcgDnPm0VK5R6D8F6Zdy+bGxStbRb7pLQVCc8axVB3eObN3GIogAKloMbtjkTLhqavO865A/BVc7MYyr8YPLcUQio7dp4ZYbWZhUJ9VptdnUo2MQuKdv8AEx+E6R3NZedib5rLK+76Diw2aPd58sVQd7h7QcevoerT5jXnvQDz+sDFI+DpD1WeSvt88xWD8q3M/c2fw7H15hwn1DfnbMSbXae6zYc+a6D+7d+3rBgB8RlYQjE3Orcflr5l7j8yLGt934qIiKAOUU4zderUFN+fP39+usbeGZ/SOTVr1mTJkiXJvr9gwQKaNm2aqOOQt7c3S5cuTXEe99K7d2969+6d7PvGPf4xcPny5USvGzVqxObNm5O9xp3CrLSoUqVKss9zr9iNGTMm0esuXbrQpUuXRMf++Sxvv/02b7/9dqJjgwYNYtCgQYmOrV69Osn9IiIikhz75/WHDBnCSy+9hJ+fX6oLzEREREREREREREQkB/pliLlMXd5geGJs2rvoiOM0+jfs+h5ObIVtU82uSqn9epzcCdPaw40LEFjWLNLxL5x5c80Ii8UsJCrZGE7ugHWfmF2VDv5ibj4FzOeweULHqVD+sdRd1+YGbT4zl+rbNAF2zzKP1+hmFrWlR52+ZlerrV+Zm/kAUKGNuRxgoep3x9YbAFu+hIuHYce3EP5c+u6Z28Tdgtm9IC4aSjWFOv1cPSMREZEkVFUhFClShMGDB7t6GiIiIiIiIiIiIiIicj/7FsPWyeZ+u4mQJ9C188ntfIOhbn9zf9EgmNgAfp9lLh+Xkoh18PXjZhFRaDXo+XPWLYb6p0LVzaKnAVuhZk+zCOrGBfDIC8/MTn0x1B1WK7T4ABrf/l2VxWoufZdexR+E4NvdimweZpHawG3Q6evExVAAXn7Q8HVzf/WHZvc1ub8VI+DMbrMQru0E82soIiKSxahDlNCpUydXTyFD+vbty7Rp0+753jPPPMPEiROdPCMRERERERERERERkUxw9TQsvL3EV70BZmcWcb1Gr5vLF26ZbBaJzH0eVo6A+i9Bta7g4ZN4/IFf4IduEHfTLN7pMsMszMluCpSCx8eYhUx75prdo4IeSN+1LBZo/Ia57JrVHQJKpH9eFgt0/gYOrYAHHgffkJTHh/eEjZ/B5UizS1WDV9N/79zg0ArYMM7cb/PZ/eMrIiLiIiqIkmxvxIgRvPbaa/d8z88vG/4DQkRERERERERERETkn+x2mN/P7MQTUhkefsfVM5I73Dyh2bvw0MtmUdSmiWZxzeLXYPUH5nJitXqBTwDsng3zXgB7HJRtYXZacvd29RNkjG8w1HXQkmnlWznmOgEloXbJ1I1184QmQ2BeH/jtE7PrlU+AY+aR01w/b/53CCC8F5Rr6dr5iIiIpEAFUZLtBQUFERQU5OppiIiIiIiIiIiIiIhknk0T4PBKcPOGDpPNIg7JWnwCoNG/oN6LsHM6rP/ULIxa9R78NhrKNoM98wEDKnc0lxqzubt61gLm12P9p3DmD1j7P2j+vqtnlPUYBiwYANfOQGA5aPaeq2ckIiKSomy5oKvdbnf1FESyJMMwXD0FEREREREREREREXG0U7/D8mHmfvP3oWA5l05H7sPDB2r3hoE7zOK14EoQex32zAMMqPU8tJukYqisxGqFR4aZ+5u/gMvHXTqdLGnrV3DgZ7B5wJOTky4FKSIiksVkqw5RHh4eWK1WTp48ScGCBfHw8MBisSQaY7fbiYmJ4ebNm1it2bLeK9tQrJ3rfvE2DINz585hsVhwd9c/okRERERERERERERyhJgbMOd5iI+Bco9B+HOunpGkls0NKj8JlTrAoRWwbQoUqQUP/h/84/dbkgWUfgSKPwTHfoPVI6HtZ66eUdZxbj8sfcvcf2SYuWyniIhIFpetCqKsVislSpTg1KlTnDx58p5jDMMgOjoab2/vJMVS4liKtXOlJt4Wi4UiRYpgs9mcPDsRERERERERERERyRS/DIHz+yFvMDwxVoU02ZHFAmUeMTfJuiwWs9hn8iOw6zuoPxCCyrt6Vq4Xdwtm94K4aCjVFOr0c/WMREREUiVbFUSB2SWqWLFixMXFER8fn+T92NhYfv31Vxo2bKguOZlMsXau1MTb3d1dxVAiIiIiIiIiIiIiOcW+xbB1srnfbiLkCXTtfERyuqK1oHxr2LcIVoyALt+5ekbpZrHHQdxNIOnvU9NkxQg4sxt8CkDbCebygiIiItlAtiuIAhKWBLtXUYjNZiMuLg4vLy8V6WQyxdq5FG8RERERERERERGRXOTqaVg4wNyvN8DszCIime/hobB/Mez/CSI3QrG6mX/PmBuwczpsmghxMVDrOXN5TC//tF3HMODwCmxrR/PEsd9glwPn2GY8+IY48IIiIiKZK1sWRImIiIiIiIiIiIiIiORYhh3bjwPgxgUIqQwPv+PqGYnkHgXLQvVnYPs3sHwY9Pw585aqvHERtkyGTRPMv+93LB8Gaz+G8J5Qt//9C5Hi4+DP+bBuDJzejcN7ONUbAOVaOPqqIiIimSrTehqOHz+eEiVK4OXlRc2aNVm7dm1m3UpERHIA5Q0REUkr5Q4REUkL5Q0REUkrV+aOUueWYj26Gty8ocNkcPN02r1FBGg8GNy8IHIDHFjq+OtH/QVL3oTRlWDVe2YxVL5i8NhH5rJ0BR+AW1dg3ScwpjIsfAkuHE56ndho2PwFjK0Bc3rB6d3gnof42n1ZVuEjYl87CoP/ytj25ilo/r7jY5BD6d8dIiJZR6YURM2cOZNBgwbx1ltvsWPHDho0aEDLli2JjIzMjNuJiEg2p7whIiJppdwhIiJpobwhIiJp5dLccXo3D5ycZe43fx8Klsv8e4pIYn6FoM4L5v6K4WCPd8x1z+2H+f3hk6qw8TOIvQ7BlczCx4E7oHZvqPY09FsPXWZA0boQHwPbv4axNeGHZ+HEdoi+BL/+1yyoWvwaXD4GPgWgyVvw8h/YH32PG55B4Omb8c3DxzHPngvo3x0iIllLpiyZ9/HHH9OrVy+ef/55AMaMGcPSpUuZMGECH3zwQaKxt27d4tatWwmvo6KiALh48SKxsbFpvndsbCw3btzgwoULuLu7Z+Ap5H4Ua+dSvJ0nO8X66tWrABiG4eKZZExa8gY4Nndkp693TqB4O49i7VzZJd45JW+AckduoVg7l+LtPNkp1jkldyhv5B6Kt/Mo1s6VXeKdU/IGuDB3xN7A9n0vrDdjiSv5MEaJNnDhwv3Pk3TJLn+3copsF+8HeuC27issx/dgjHkQwz2DhUHxt7Ce2Z3w0l6kDvY6fTHCGplL8l2OSjw+sDa0/Q7LX1uwbp6I9chK2DEfdszHsHpgsccAYPgVxh7eG3vljuDuA9EGsVcuZJtY59bcoX9zZF+Kt/Mo1s6VXeKdprxhONitW7cMm81mzJ07N9Hxl156yWjYsGGS8UOHDjUAbdq0adOWge348eOO/s+506Q1bxiGcoc2bdq0ZXTLznnDMJQ7tGnTps0VW3bOHcob2rRp0+b8LTvnDcNQ7tCmTZs2V2y5LXcob2jTpk1bxrbU5A2Hd4g6f/488fHxBAcHJzoeHBzM6dOnk4wfPHgwr7zySsJru93OxYsXKVCgABaLJc33v3LlCkWLFuX48eP4+fml/QEk1RRr51K8nSc7xdowDK5evUqhQoVcPZV0S2veAMfmjuz09c4JFG/nUaydK7vEOyfkDVDuyE0Ua+dSvJ0nO8U6J+QO5Y3cRfF2HsXaubJLvHNC3gDljtxEsXYuxdt5slOsc2vuUN7IvhRv51GsnSu7xDsteSNTlswDkvyH2jCMe/7H29PTE09Pz0TH8uXLl+H7+/n5ZekvUk6iWDuX4u082SXW/v7+rp6CQ6Q2b0Dm5I7s8vXOKRRv51GsnSs7xDun5A1Q7shNFGvnUrydJ7vEOqfkDuWN3EXxdh7F2rmyQ7xzSt4A5Y7cRLF2LsXbebJLrHNj7lDeyP4Ub+dRrJ0rO8Q7tXnD6ugbBwYGYrPZklS6nj17NklFrIiIiPKGiIiklXKHiIikhfKGiIiklXKHiIiklXKHiEjW4/CCKA8PD2rWrMmyZcsSHV+2bBn169d39O1ERCSbU94QEZG0Uu4QEZG0UN4QEZG0Uu4QEZG0Uu4QEcl6MmXJvFdeeYVu3boRHh5OvXr1mDRpEpGRkfTt2zczbpeIp6cnQ4cOTdJiUBxPsXYuxdt5FGvnU97IPRRv51GsnUvxdj7ljtxBsXYuxdt5FGvnU97IPRRv51GsnUvxdj7ljtxBsXYuxdt5FGvXcFXu0NfbuRRv51GsnSsnxttiGIaRGRceP348o0aN4tSpU1SqVInRo0fTsGHDzLiViIjkAMobIiKSVsodIiKSFsobIiKSVsodIiKSVsodIiJZR6YVRImIiIiIiIiIiIiIiIiIiIiIiDib1dUTEBERERERERERERERERERERERcRQVRImIiIiIiIiIiIiIiIiIiIiISI6hgigREREREREREREREREREREREckxVBAlIiIiIiIiIiIiIiIiIiIiIiI5Ro4qiBo/fjwlSpTAy8uLmjVrsnbtWldPKdsZNmwYFosl0RYSEpLwvmEYDBs2jEKFCuHt7U3jxo3Zs2dPomvcunWLgQMHEhgYSJ48eXjiiSf466+/nP0oWc6vv/7K448/TqFChbBYLMyfPz/R+46K7aVLl+jWrRv+/v74+/vTrVs3Ll++nMlPl/XcL949evRI8r1et27dRGMU79xBuSNjlDcyl3KH8yhvSGopb2ScckfmUu5wHuUOSS3ljoxT7sg8yhvOpdwhqaG8kXHKG5lLucN5lDcktZQ7Mk65I/MobziXckdiOaYgaubMmQwaNIi33nqLHTt20KBBA1q2bElkZKSrp5btVKxYkVOnTiVsu3fvTnhv1KhRfPzxx4wbN44tW7YQEhLCo48+ytWrVxPGDBo0iHnz5jFjxgx+++03rl27RuvWrYmPj3fF42QZ169fp2rVqowbN+6e7zsqtk8//TQ7d+5kyZIlLFmyhJ07d9KtW7dMf76s5n7xBmjRokWi7/XFixcnel/xzvmUOxxDeSPzKHc4j/KGpIbyhuMod2Qe5Q7nUe6Q1FDucBzljsyhvOFcyh1yP8objqO8kXmUO5xHeUNSQ7nDcZQ7MofyhnMpd/yDkUPUrl3b6Nu3b6Jj5cuXN9544w0XzSh7Gjp0qFG1atV7vme3242QkBBj5MiRCcdu3rxp+Pv7GxMnTjQMwzAuX75suLu7GzNmzEgYc+LECcNqtRpLlizJ1LlnJ4Axb968hNeOiu2ff/5pAMbGjRsTxmzYsMEAjH379mXyU2Vd/4y3YRhG9+7djTZt2iR7juKdOyh3ZJzyhvModziP8oYkR3nDMZQ7nEe5w3mUOyQ5yh2OodzhHMobzqXcIfeivOEYyhvOo9zhPMobkhzlDsdQ7nAO5Q3nUu4wjBzRISomJoZt27bRrFmzRMebNWvG+vXrXTSr7OvgwYMUKlSIEiVK8NRTT3HkyBEAjh49yunTpxPF2dPTk0aNGiXEedu2bcTGxiYaU6hQISpVqqSvRQocFdsNGzbg7+9PnTp1EsbUrVsXf39/xf8eVq9eTVBQEGXLlqV3796cPXs24T3FO+dT7nAc5Q3XUO5wPuWN3E15w7GUO1xDucP5lDtyN+UOx1LucD7lDddQ7si9lDccS3nDNZQ7nE95I3dT7nAs5Q7nU95wjdyUO3JEQdT58+eJj48nODg40fHg4GBOnz7tolllT3Xq1OGbb75h6dKlfPHFF5w+fZr69etz4cKFhFimFOfTp0/j4eFB/vz5kx0jSTkqtqdPnyYoKCjJ9YOCghT/f2jZsiXTp09n5cqV/O9//2PLli00bdqUW7duAYp3bqDc4RjKG66j3OFcyhuivOE4yh2uo9zhXModotzhOModrqG84XzKHbmb8objKG+4jnKHcylviHKH4yh3uIbyhvPlttzh5uoJOJLFYkn02jCMJMckZS1btkzYr1y5MvXq1aNUqVJ8/fXX1K1bF0hfnPW1SB1HxPZe4xX/pDp37pywX6lSJcLDwylevDg//fQT7du3T/Y8xTvnUe7IGOUN11PucA7lDblDeSPjlDtcT7nDOZQ75A7ljoxT7nAt5Q3nUe4QUN5wBOUN11PucA7lDblDuSPjlDtcS3nDeXJb7sgRHaICAwOx2WxJqs3Onj2bpJpQ0iZPnjxUrlyZgwcPEhISApBinENCQoiJieHSpUvJjpGkHBXbkJAQzpw5k+T6586dU/zvIzQ0lOLFi3Pw4EFA8c4NlDsyh/KG8yh3uJbyRu6jvJF5lDucR7nDtZQ7ch/ljsyj3OEcyhuup9yRuyhvZB7lDedR7nAt5Y3cR7kj8yh3OIfyhuvl9NyRIwqiPDw8qFmzJsuWLUt0fNmyZdSvX99Fs8oZbt26xd69ewkNDaVEiRKEhIQkinNMTAxr1qxJiHPNmjVxd3dPNObUqVP88ccf+lqkwFGxrVevHlFRUWzevDlhzKZNm4iKilL87+PChQscP36c0NBQQPHODZQ7MofyhvMod7iW8kbuo7yReZQ7nEe5w7WUO3If5Y7Mo9zhHMobrqfckbsob2Qe5Q3nUe5wLeWN3Ee5I/ModziH8obr5fjcYeQQM2bMMNzd3Y3Jkycbf/75pzFo0CAjT548RkREhKunlq28+uqrxurVq40jR44YGzduNFq3bm34+vomxHHkyJGGv7+/MXfuXGP37t1Gly5djNDQUOPKlSsJ1+jbt69RpEgRY/ny5cb27duNpk2bGlWrVjXi4uJc9VhZwtWrV40dO3YYO3bsMADj448/Nnbs2GEcO3bMMAzHxbZFixZGlSpVjA0bNhgbNmwwKleubLRu3drpz+tqKcX76tWrxquvvmqsX7/eOHr0qLFq1SqjXr16RuHChRXvXEa5I+OUNzKXcofzKG9IaihvOIZyR+ZS7nAe5Q5JDeUOx1DuyDzKG86l3CH3o7zhGMobmUu5w3mUNyQ1lDscQ7kj8yhvOJdyR2I5piDKMAzjs88+M4oXL254eHgYNWrUMNasWePqKWU7nTt3NkJDQw13d3ejUKFCRvv27Y09e/YkvG+3242hQ4caISEhhqenp9GwYUNj9+7dia4RHR1tDBgwwAgICDC8vb2N1q1bG5GRkc5+lCxn1apVBpBk6969u2EYjovthQsXjK5duxq+vr6Gr6+v0bVrV+PSpUtOesqsI6V437hxw2jWrJlRsGBBw93d3ShWrJjRvXv3JLFUvHMH5Y6MUd7IXModzqO8IamlvJFxyh2ZS7nDeZQ7JLWUOzJOuSPzKG84l3KHpIbyRsYpb2Qu5Q7nUd6Q1FLuyDjljsyjvOFcyh2JWQzDMNLfX0pERERERERERERERERERERERCTrsLp6AiIiIiIiIiIiIiIiIiIiIiIiIo6igigREREREREREREREREREREREckxVBAlIiIiIiIiIiIiIiIiIiIiIiI5hgqiREREREREREREREREREREREQkx1BBlIiIiIiIiIiIiIiIiIiIiIiI5BgqiBIRERERERERERERERERERERkRxDBVEiIiIiIiIiIiIiIiIiIiIiIpJjqCBKRERERERERERERERERERERERyDBVEiYiIiIiIiIiIiIiIiIiIiIhIjqGCKBERERERERERERERERERERERyTFUECUiIiIiIiIiIiIiIiIiIiIiIjnG/wOtaAx/sTXDEQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 3000x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "exp_dir = '../results/oi3'\n",
    "save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "save_dirs += [(os.path.basename(x), x) for x in \n",
    "             glob.glob(os.path.join(exp_dir, 'llama-7b_all:200k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "df = get_eval_results(save_dirs, chat_fmt=None, ft_args_fields=ft_args_fields)\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "# add base model performance\n",
    "dfc.loc[dfc['model_args.model_name_or_path']=='huggyllama/llama-7b', 'model_args.model_name_or_path'] = 'checkpoint-0'\n",
    "# get steps \n",
    "dfc.insert(0, 'steps', dfc['model_args.model_name_or_path'].apply(lambda x: int(x.split('-')[-1])))\n",
    "dfc = dfc.sort_values('steps')\n",
    "\n",
    "\n",
    "y_labels_list = [\n",
    "    ['MMLU/0-shot',\n",
    "     'MMLU/0-shot_chatfmt',\n",
    "     'MMLU/5-shot',\n",
    "     'MMLU/5-shot_chatfmt',\n",
    "    ],\n",
    "    ['GSM/Direct',\n",
    "     'GSM/Direct_chatfmt',\n",
    "     'GSM/CoT', \n",
    "     'GSM/CoT_chatfmt', \n",
    "    ],\n",
    "    ['BBH/Direct',\n",
    "     'BBH/Direct_chatfmt',\n",
    "     'BBH/CoT',\n",
    "     'BBH/CoT_chatfmt',\n",
    "    ],\n",
    "    ['TydiQA/CB',\n",
    "     'TydiQA/CB_chatfmt',\n",
    "     'TydiQA/GP',\n",
    "     'TydiQA/GP_chatfmt',\n",
    "    ],\n",
    "    ['Codex-Eval/Pass@1',\n",
    "     'Codex-Eval/Pass@1_chatfmt'],\n",
    "    ['MMLU/5-shot',\n",
    "     'GSM/CoT',\n",
    "     'BBH/CoT',],\n",
    "]\n",
    "\n",
    "N = len(y_labels_list)\n",
    "\n",
    "fig, axs = plt.subplots(1,N,figsize=(5*N,5))\n",
    "\n",
    "for axi, y_labels in enumerate(y_labels_list):\n",
    "    ax = axs[axi]\n",
    "\n",
    "    x = dfc['steps']\n",
    "    y_list = []\n",
    "    for y_label in y_labels:\n",
    "        if y_label not in dfc.columns: continue\n",
    "        y = dfc[y_label].to_numpy()\n",
    "        y_list.append(y)\n",
    "        ax.plot(x, y, label=y_label)\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    ax.set_ylim(0, 55)\n",
    "    \n",
    "    \n",
    "# for y_label in ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1']:\n",
    "    \n",
    "#     for chat_fmt in ['', 'chatfmt']:\n",
    "#         col = '_'.join([y_label, chat_fmt]) if chat_fmt else y_label\n",
    "#         y = dfc[col].to_numpy()\n",
    "#         print(f'{col}\\t{y.mean():.2f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3099f05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_args.model_name_or_path</th>\n",
       "      <th>data_args.subsample_mixture</th>\n",
       "      <th>MMLU/0-shot</th>\n",
       "      <th>MMLU/0-shot_chatfmt</th>\n",
       "      <th>MMLU/5-shot_chatfmt</th>\n",
       "      <th>MMLU/0-shot_chatfmt_v1</th>\n",
       "      <th>MMLU/0-shot_chatfmt_v2</th>\n",
       "      <th>MMLU/0-shot_chatfmt_v3</th>\n",
       "      <th>MMLU/0-shot_chatfmt_v4</th>\n",
       "      <th>MMLU/5-shot_chatfmt_v1</th>\n",
       "      <th>...</th>\n",
       "      <th>BBH/Direct_chatfmt</th>\n",
       "      <th>BBH/CoT</th>\n",
       "      <th>BBH/CoT_chatfmt</th>\n",
       "      <th>Codex-Eval/Pass@1</th>\n",
       "      <th>Codex-Eval/Pass@1_chatfmt</th>\n",
       "      <th>TydiQA/CB</th>\n",
       "      <th>TydiQA/CB_chatfmt</th>\n",
       "      <th>TydiQA/GP</th>\n",
       "      <th>TydiQA/GP_chatfmt</th>\n",
       "      <th>MMLU/5-shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huggyllama/llama-7b</td>\n",
       "      <td>{}</td>\n",
       "      <td>31.861558</td>\n",
       "      <td>32.459764</td>\n",
       "      <td>33.057969</td>\n",
       "      <td>32.459764</td>\n",
       "      <td>23.059393</td>\n",
       "      <td>30.9144</td>\n",
       "      <td>33.321464</td>\n",
       "      <td>33.057969</td>\n",
       "      <td>...</td>\n",
       "      <td>32.970313</td>\n",
       "      <td>29.243182</td>\n",
       "      <td>28.425926</td>\n",
       "      <td>11.585366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.505480</td>\n",
       "      <td>10.349886</td>\n",
       "      <td>40.403106</td>\n",
       "      <td>38.564264</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>checkpoint-1150</td>\n",
       "      <td>None</td>\n",
       "      <td>31.341689</td>\n",
       "      <td>31.014101</td>\n",
       "      <td>32.908418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.019007</td>\n",
       "      <td>33.425926</td>\n",
       "      <td>33.888889</td>\n",
       "      <td>14.024390</td>\n",
       "      <td>1.829268</td>\n",
       "      <td>9.392081</td>\n",
       "      <td>9.737485</td>\n",
       "      <td>43.907156</td>\n",
       "      <td>43.738652</td>\n",
       "      <td>38.562883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>checkpoint-1650</td>\n",
       "      <td>None</td>\n",
       "      <td>42.280302</td>\n",
       "      <td>41.425723</td>\n",
       "      <td>43.156246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.235720</td>\n",
       "      <td>33.703704</td>\n",
       "      <td>33.611111</td>\n",
       "      <td>12.195122</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>9.693916</td>\n",
       "      <td>10.016957</td>\n",
       "      <td>46.802986</td>\n",
       "      <td>45.407914</td>\n",
       "      <td>43.255946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>checkpoint-500</td>\n",
       "      <td>None</td>\n",
       "      <td>38.292266</td>\n",
       "      <td>37.751033</td>\n",
       "      <td>40.763424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.146989</td>\n",
       "      <td>30.370370</td>\n",
       "      <td>29.444444</td>\n",
       "      <td>13.414634</td>\n",
       "      <td>3.048780</td>\n",
       "      <td>10.480295</td>\n",
       "      <td>10.313920</td>\n",
       "      <td>45.833678</td>\n",
       "      <td>43.672849</td>\n",
       "      <td>40.841760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>checkpoint-450</td>\n",
       "      <td>None</td>\n",
       "      <td>40.193705</td>\n",
       "      <td>37.451930</td>\n",
       "      <td>38.534397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34.433397</td>\n",
       "      <td>30.648148</td>\n",
       "      <td>31.574074</td>\n",
       "      <td>11.585366</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>10.354777</td>\n",
       "      <td>9.684929</td>\n",
       "      <td>45.662417</td>\n",
       "      <td>38.529798</td>\n",
       "      <td>36.454921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>checkpoint-350</td>\n",
       "      <td>None</td>\n",
       "      <td>41.119499</td>\n",
       "      <td>40.870246</td>\n",
       "      <td>39.332004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33.762299</td>\n",
       "      <td>31.203704</td>\n",
       "      <td>32.685185</td>\n",
       "      <td>14.634146</td>\n",
       "      <td>8.536585</td>\n",
       "      <td>10.004577</td>\n",
       "      <td>9.638428</td>\n",
       "      <td>41.657123</td>\n",
       "      <td>43.302263</td>\n",
       "      <td>38.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>checkpoint-600</td>\n",
       "      <td>None</td>\n",
       "      <td>41.219200</td>\n",
       "      <td>41.696340</td>\n",
       "      <td>42.144994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.078549</td>\n",
       "      <td>33.240741</td>\n",
       "      <td>32.129630</td>\n",
       "      <td>12.195122</td>\n",
       "      <td>1.829268</td>\n",
       "      <td>11.518016</td>\n",
       "      <td>9.529373</td>\n",
       "      <td>38.110773</td>\n",
       "      <td>41.097125</td>\n",
       "      <td>42.899872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>checkpoint-800</td>\n",
       "      <td>None</td>\n",
       "      <td>42.201966</td>\n",
       "      <td>40.941461</td>\n",
       "      <td>41.418601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.145836</td>\n",
       "      <td>32.685185</td>\n",
       "      <td>32.592593</td>\n",
       "      <td>12.804878</td>\n",
       "      <td>3.048780</td>\n",
       "      <td>10.396121</td>\n",
       "      <td>9.367477</td>\n",
       "      <td>43.079553</td>\n",
       "      <td>44.493847</td>\n",
       "      <td>41.639368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>checkpoint-950</td>\n",
       "      <td>None</td>\n",
       "      <td>40.585387</td>\n",
       "      <td>39.880359</td>\n",
       "      <td>40.806153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34.083169</td>\n",
       "      <td>30.185185</td>\n",
       "      <td>30.370370</td>\n",
       "      <td>13.414634</td>\n",
       "      <td>1.829268</td>\n",
       "      <td>10.411882</td>\n",
       "      <td>10.020261</td>\n",
       "      <td>44.920150</td>\n",
       "      <td>46.580197</td>\n",
       "      <td>39.965817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>checkpoint-1250</td>\n",
       "      <td>None</td>\n",
       "      <td>37.110098</td>\n",
       "      <td>39.410340</td>\n",
       "      <td>41.475573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.648689</td>\n",
       "      <td>33.888889</td>\n",
       "      <td>33.981481</td>\n",
       "      <td>12.195122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.823051</td>\n",
       "      <td>9.936207</td>\n",
       "      <td>44.758646</td>\n",
       "      <td>45.182731</td>\n",
       "      <td>41.034041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>checkpoint-150</td>\n",
       "      <td>None</td>\n",
       "      <td>34.610454</td>\n",
       "      <td>30.921521</td>\n",
       "      <td>31.476998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34.434668</td>\n",
       "      <td>30.185185</td>\n",
       "      <td>30.092593</td>\n",
       "      <td>16.463415</td>\n",
       "      <td>4.268293</td>\n",
       "      <td>11.122201</td>\n",
       "      <td>11.299030</td>\n",
       "      <td>41.816537</td>\n",
       "      <td>40.685642</td>\n",
       "      <td>33.506623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>checkpoint-1350</td>\n",
       "      <td>None</td>\n",
       "      <td>39.609742</td>\n",
       "      <td>41.397237</td>\n",
       "      <td>43.291554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.132192</td>\n",
       "      <td>34.351852</td>\n",
       "      <td>34.351852</td>\n",
       "      <td>12.195122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.950366</td>\n",
       "      <td>11.043178</td>\n",
       "      <td>42.600732</td>\n",
       "      <td>45.547473</td>\n",
       "      <td>42.871386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>checkpoint-1050</td>\n",
       "      <td>None</td>\n",
       "      <td>40.969947</td>\n",
       "      <td>40.870246</td>\n",
       "      <td>42.201966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.384631</td>\n",
       "      <td>31.388889</td>\n",
       "      <td>31.111111</td>\n",
       "      <td>14.024390</td>\n",
       "      <td>1.829268</td>\n",
       "      <td>9.666055</td>\n",
       "      <td>8.182204</td>\n",
       "      <td>42.964452</td>\n",
       "      <td>43.529163</td>\n",
       "      <td>43.704600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>checkpoint-1300</td>\n",
       "      <td>None</td>\n",
       "      <td>40.663723</td>\n",
       "      <td>41.276171</td>\n",
       "      <td>42.914115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.093162</td>\n",
       "      <td>33.518519</td>\n",
       "      <td>33.611111</td>\n",
       "      <td>12.195122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.139922</td>\n",
       "      <td>9.205560</td>\n",
       "      <td>45.763966</td>\n",
       "      <td>44.731724</td>\n",
       "      <td>42.906993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>checkpoint-850</td>\n",
       "      <td>None</td>\n",
       "      <td>42.543797</td>\n",
       "      <td>41.988321</td>\n",
       "      <td>42.436975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.416765</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>32.129630</td>\n",
       "      <td>12.195122</td>\n",
       "      <td>3.048780</td>\n",
       "      <td>10.412555</td>\n",
       "      <td>9.971524</td>\n",
       "      <td>43.706823</td>\n",
       "      <td>43.307353</td>\n",
       "      <td>43.191853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>checkpoint-50</td>\n",
       "      <td>None</td>\n",
       "      <td>37.131463</td>\n",
       "      <td>35.101837</td>\n",
       "      <td>36.105968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33.815796</td>\n",
       "      <td>29.537037</td>\n",
       "      <td>29.814815</td>\n",
       "      <td>13.414634</td>\n",
       "      <td>1.829268</td>\n",
       "      <td>9.772804</td>\n",
       "      <td>10.506730</td>\n",
       "      <td>42.111272</td>\n",
       "      <td>43.644052</td>\n",
       "      <td>36.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>checkpoint-100</td>\n",
       "      <td>None</td>\n",
       "      <td>36.583108</td>\n",
       "      <td>35.180174</td>\n",
       "      <td>35.927930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33.254913</td>\n",
       "      <td>31.296296</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>14.024390</td>\n",
       "      <td>3.658537</td>\n",
       "      <td>10.604540</td>\n",
       "      <td>10.283347</td>\n",
       "      <td>40.576965</td>\n",
       "      <td>45.108756</td>\n",
       "      <td>36.568865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>checkpoint-1450</td>\n",
       "      <td>None</td>\n",
       "      <td>40.749181</td>\n",
       "      <td>41.924227</td>\n",
       "      <td>43.854152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37.201889</td>\n",
       "      <td>32.222222</td>\n",
       "      <td>32.407407</td>\n",
       "      <td>13.414634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.604490</td>\n",
       "      <td>9.126629</td>\n",
       "      <td>46.841733</td>\n",
       "      <td>45.030477</td>\n",
       "      <td>44.374021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>checkpoint-700</td>\n",
       "      <td>None</td>\n",
       "      <td>39.780658</td>\n",
       "      <td>40.022789</td>\n",
       "      <td>39.837630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.020901</td>\n",
       "      <td>32.222222</td>\n",
       "      <td>30.740741</td>\n",
       "      <td>12.804878</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>8.933082</td>\n",
       "      <td>9.082622</td>\n",
       "      <td>45.165342</td>\n",
       "      <td>42.707950</td>\n",
       "      <td>39.574135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>checkpoint-650</td>\n",
       "      <td>None</td>\n",
       "      <td>40.015667</td>\n",
       "      <td>40.585387</td>\n",
       "      <td>41.269050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.446351</td>\n",
       "      <td>32.962963</td>\n",
       "      <td>32.407407</td>\n",
       "      <td>10.975610</td>\n",
       "      <td>1.219512</td>\n",
       "      <td>10.637597</td>\n",
       "      <td>9.410252</td>\n",
       "      <td>44.371611</td>\n",
       "      <td>44.058671</td>\n",
       "      <td>40.620994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>checkpoint-1100</td>\n",
       "      <td>None</td>\n",
       "      <td>32.224754</td>\n",
       "      <td>32.459764</td>\n",
       "      <td>34.361202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.061167</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>32.592593</td>\n",
       "      <td>12.804878</td>\n",
       "      <td>4.878049</td>\n",
       "      <td>9.098630</td>\n",
       "      <td>10.186244</td>\n",
       "      <td>47.688415</td>\n",
       "      <td>45.787596</td>\n",
       "      <td>40.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>checkpoint-300</td>\n",
       "      <td>None</td>\n",
       "      <td>39.502920</td>\n",
       "      <td>39.809144</td>\n",
       "      <td>39.310640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33.964215</td>\n",
       "      <td>29.166667</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>14.024390</td>\n",
       "      <td>3.658537</td>\n",
       "      <td>10.105389</td>\n",
       "      <td>8.987745</td>\n",
       "      <td>39.054953</td>\n",
       "      <td>46.236673</td>\n",
       "      <td>37.074491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>checkpoint-1000</td>\n",
       "      <td>None</td>\n",
       "      <td>42.237573</td>\n",
       "      <td>41.959835</td>\n",
       "      <td>43.419741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.474929</td>\n",
       "      <td>32.222222</td>\n",
       "      <td>32.777778</td>\n",
       "      <td>13.414634</td>\n",
       "      <td>3.048780</td>\n",
       "      <td>10.509469</td>\n",
       "      <td>9.879061</td>\n",
       "      <td>43.118828</td>\n",
       "      <td>44.730655</td>\n",
       "      <td>44.082040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>checkpoint-1200</td>\n",
       "      <td>None</td>\n",
       "      <td>36.526136</td>\n",
       "      <td>38.726677</td>\n",
       "      <td>42.280302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.571518</td>\n",
       "      <td>32.592593</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>15.243902</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>9.003687</td>\n",
       "      <td>9.571515</td>\n",
       "      <td>47.762392</td>\n",
       "      <td>41.322312</td>\n",
       "      <td>41.311779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>checkpoint-250</td>\n",
       "      <td>None</td>\n",
       "      <td>34.610454</td>\n",
       "      <td>33.435408</td>\n",
       "      <td>34.610454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>31.926539</td>\n",
       "      <td>30.277778</td>\n",
       "      <td>29.722222</td>\n",
       "      <td>14.024390</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>9.153746</td>\n",
       "      <td>9.981706</td>\n",
       "      <td>45.134082</td>\n",
       "      <td>43.827197</td>\n",
       "      <td>35.557613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>checkpoint-1600</td>\n",
       "      <td>None</td>\n",
       "      <td>40.791910</td>\n",
       "      <td>41.938470</td>\n",
       "      <td>44.117647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34.886966</td>\n",
       "      <td>31.574074</td>\n",
       "      <td>31.388889</td>\n",
       "      <td>11.585366</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>9.306889</td>\n",
       "      <td>10.939492</td>\n",
       "      <td>44.255913</td>\n",
       "      <td>42.862591</td>\n",
       "      <td>44.459479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>checkpoint-1500</td>\n",
       "      <td>None</td>\n",
       "      <td>41.297536</td>\n",
       "      <td>42.294545</td>\n",
       "      <td>43.839909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.950293</td>\n",
       "      <td>33.055556</td>\n",
       "      <td>32.962963</td>\n",
       "      <td>11.585366</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>10.193179</td>\n",
       "      <td>9.701470</td>\n",
       "      <td>42.085146</td>\n",
       "      <td>43.128486</td>\n",
       "      <td>45.014955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>checkpoint-900</td>\n",
       "      <td>None</td>\n",
       "      <td>42.102265</td>\n",
       "      <td>41.105256</td>\n",
       "      <td>43.355647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.275674</td>\n",
       "      <td>31.759259</td>\n",
       "      <td>31.203704</td>\n",
       "      <td>13.414634</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>8.072466</td>\n",
       "      <td>10.409846</td>\n",
       "      <td>44.812705</td>\n",
       "      <td>40.361275</td>\n",
       "      <td>43.113517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>checkpoint-1550</td>\n",
       "      <td>None</td>\n",
       "      <td>42.486825</td>\n",
       "      <td>43.234582</td>\n",
       "      <td>44.851161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.708353</td>\n",
       "      <td>32.314815</td>\n",
       "      <td>33.055556</td>\n",
       "      <td>10.975610</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>10.102308</td>\n",
       "      <td>8.484646</td>\n",
       "      <td>47.221444</td>\n",
       "      <td>39.937314</td>\n",
       "      <td>45.541946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>checkpoint-400</td>\n",
       "      <td>None</td>\n",
       "      <td>37.309500</td>\n",
       "      <td>35.664435</td>\n",
       "      <td>40.685088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34.372841</td>\n",
       "      <td>33.240741</td>\n",
       "      <td>32.037037</td>\n",
       "      <td>12.195122</td>\n",
       "      <td>3.658537</td>\n",
       "      <td>10.796108</td>\n",
       "      <td>9.498969</td>\n",
       "      <td>42.026308</td>\n",
       "      <td>44.303880</td>\n",
       "      <td>41.518302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>checkpoint-1400</td>\n",
       "      <td>None</td>\n",
       "      <td>40.706452</td>\n",
       "      <td>42.351517</td>\n",
       "      <td>44.523572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.893336</td>\n",
       "      <td>35.555556</td>\n",
       "      <td>34.629630</td>\n",
       "      <td>10.365854</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>10.292829</td>\n",
       "      <td>9.562766</td>\n",
       "      <td>45.699490</td>\n",
       "      <td>43.730480</td>\n",
       "      <td>44.295684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>checkpoint-750</td>\n",
       "      <td>None</td>\n",
       "      <td>39.716565</td>\n",
       "      <td>36.768267</td>\n",
       "      <td>34.560604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34.205643</td>\n",
       "      <td>30.925926</td>\n",
       "      <td>30.555556</td>\n",
       "      <td>13.414634</td>\n",
       "      <td>5.487805</td>\n",
       "      <td>9.613197</td>\n",
       "      <td>10.002179</td>\n",
       "      <td>38.937048</td>\n",
       "      <td>40.854204</td>\n",
       "      <td>35.735650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>checkpoint-550</td>\n",
       "      <td>None</td>\n",
       "      <td>35.422305</td>\n",
       "      <td>35.372454</td>\n",
       "      <td>38.961686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.145922</td>\n",
       "      <td>30.925926</td>\n",
       "      <td>30.648148</td>\n",
       "      <td>13.414634</td>\n",
       "      <td>4.268293</td>\n",
       "      <td>9.416884</td>\n",
       "      <td>10.049925</td>\n",
       "      <td>46.931470</td>\n",
       "      <td>43.590882</td>\n",
       "      <td>38.505911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>checkpoint-200</td>\n",
       "      <td>None</td>\n",
       "      <td>32.887053</td>\n",
       "      <td>34.176043</td>\n",
       "      <td>35.073351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33.985223</td>\n",
       "      <td>32.037037</td>\n",
       "      <td>30.648148</td>\n",
       "      <td>15.243902</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>9.449677</td>\n",
       "      <td>10.360039</td>\n",
       "      <td>43.179150</td>\n",
       "      <td>46.058825</td>\n",
       "      <td>32.894175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_args.model_name_or_path data_args.subsample_mixture  MMLU/0-shot  \\\n",
       "0            huggyllama/llama-7b                          {}    31.861558   \n",
       "1                checkpoint-1150                        None    31.341689   \n",
       "2                checkpoint-1650                        None    42.280302   \n",
       "3                 checkpoint-500                        None    38.292266   \n",
       "4                 checkpoint-450                        None    40.193705   \n",
       "5                 checkpoint-350                        None    41.119499   \n",
       "6                 checkpoint-600                        None    41.219200   \n",
       "7                 checkpoint-800                        None    42.201966   \n",
       "8                 checkpoint-950                        None    40.585387   \n",
       "9                checkpoint-1250                        None    37.110098   \n",
       "10                checkpoint-150                        None    34.610454   \n",
       "11               checkpoint-1350                        None    39.609742   \n",
       "12               checkpoint-1050                        None    40.969947   \n",
       "13               checkpoint-1300                        None    40.663723   \n",
       "14                checkpoint-850                        None    42.543797   \n",
       "15                 checkpoint-50                        None    37.131463   \n",
       "16                checkpoint-100                        None    36.583108   \n",
       "17               checkpoint-1450                        None    40.749181   \n",
       "18                checkpoint-700                        None    39.780658   \n",
       "19                checkpoint-650                        None    40.015667   \n",
       "20               checkpoint-1100                        None    32.224754   \n",
       "21                checkpoint-300                        None    39.502920   \n",
       "22               checkpoint-1000                        None    42.237573   \n",
       "23               checkpoint-1200                        None    36.526136   \n",
       "24                checkpoint-250                        None    34.610454   \n",
       "25               checkpoint-1600                        None    40.791910   \n",
       "26               checkpoint-1500                        None    41.297536   \n",
       "27                checkpoint-900                        None    42.102265   \n",
       "28               checkpoint-1550                        None    42.486825   \n",
       "29                checkpoint-400                        None    37.309500   \n",
       "30               checkpoint-1400                        None    40.706452   \n",
       "31                checkpoint-750                        None    39.716565   \n",
       "32                checkpoint-550                        None    35.422305   \n",
       "33                checkpoint-200                        None    32.887053   \n",
       "\n",
       "    MMLU/0-shot_chatfmt  MMLU/5-shot_chatfmt  MMLU/0-shot_chatfmt_v1  \\\n",
       "0             32.459764            33.057969               32.459764   \n",
       "1             31.014101            32.908418                     NaN   \n",
       "2             41.425723            43.156246                     NaN   \n",
       "3             37.751033            40.763424                     NaN   \n",
       "4             37.451930            38.534397                     NaN   \n",
       "5             40.870246            39.332004                     NaN   \n",
       "6             41.696340            42.144994                     NaN   \n",
       "7             40.941461            41.418601                     NaN   \n",
       "8             39.880359            40.806153                     NaN   \n",
       "9             39.410340            41.475573                     NaN   \n",
       "10            30.921521            31.476998                     NaN   \n",
       "11            41.397237            43.291554                     NaN   \n",
       "12            40.870246            42.201966                     NaN   \n",
       "13            41.276171            42.914115                     NaN   \n",
       "14            41.988321            42.436975                     NaN   \n",
       "15            35.101837            36.105968                     NaN   \n",
       "16            35.180174            35.927930                     NaN   \n",
       "17            41.924227            43.854152                     NaN   \n",
       "18            40.022789            39.837630                     NaN   \n",
       "19            40.585387            41.269050                     NaN   \n",
       "20            32.459764            34.361202                     NaN   \n",
       "21            39.809144            39.310640                     NaN   \n",
       "22            41.959835            43.419741                     NaN   \n",
       "23            38.726677            42.280302                     NaN   \n",
       "24            33.435408            34.610454                     NaN   \n",
       "25            41.938470            44.117647                     NaN   \n",
       "26            42.294545            43.839909                     NaN   \n",
       "27            41.105256            43.355647                     NaN   \n",
       "28            43.234582            44.851161                     NaN   \n",
       "29            35.664435            40.685088                     NaN   \n",
       "30            42.351517            44.523572                     NaN   \n",
       "31            36.768267            34.560604                     NaN   \n",
       "32            35.372454            38.961686                     NaN   \n",
       "33            34.176043            35.073351                     NaN   \n",
       "\n",
       "    MMLU/0-shot_chatfmt_v2  MMLU/0-shot_chatfmt_v3  MMLU/0-shot_chatfmt_v4  \\\n",
       "0                23.059393                 30.9144               33.321464   \n",
       "1                      NaN                     NaN                     NaN   \n",
       "2                      NaN                     NaN                     NaN   \n",
       "3                      NaN                     NaN                     NaN   \n",
       "4                      NaN                     NaN                     NaN   \n",
       "5                      NaN                     NaN                     NaN   \n",
       "6                      NaN                     NaN                     NaN   \n",
       "7                      NaN                     NaN                     NaN   \n",
       "8                      NaN                     NaN                     NaN   \n",
       "9                      NaN                     NaN                     NaN   \n",
       "10                     NaN                     NaN                     NaN   \n",
       "11                     NaN                     NaN                     NaN   \n",
       "12                     NaN                     NaN                     NaN   \n",
       "13                     NaN                     NaN                     NaN   \n",
       "14                     NaN                     NaN                     NaN   \n",
       "15                     NaN                     NaN                     NaN   \n",
       "16                     NaN                     NaN                     NaN   \n",
       "17                     NaN                     NaN                     NaN   \n",
       "18                     NaN                     NaN                     NaN   \n",
       "19                     NaN                     NaN                     NaN   \n",
       "20                     NaN                     NaN                     NaN   \n",
       "21                     NaN                     NaN                     NaN   \n",
       "22                     NaN                     NaN                     NaN   \n",
       "23                     NaN                     NaN                     NaN   \n",
       "24                     NaN                     NaN                     NaN   \n",
       "25                     NaN                     NaN                     NaN   \n",
       "26                     NaN                     NaN                     NaN   \n",
       "27                     NaN                     NaN                     NaN   \n",
       "28                     NaN                     NaN                     NaN   \n",
       "29                     NaN                     NaN                     NaN   \n",
       "30                     NaN                     NaN                     NaN   \n",
       "31                     NaN                     NaN                     NaN   \n",
       "32                     NaN                     NaN                     NaN   \n",
       "33                     NaN                     NaN                     NaN   \n",
       "\n",
       "    MMLU/5-shot_chatfmt_v1  ...  BBH/Direct_chatfmt    BBH/CoT  \\\n",
       "0                33.057969  ...           32.970313  29.243182   \n",
       "1                      NaN  ...           35.019007  33.425926   \n",
       "2                      NaN  ...           35.235720  33.703704   \n",
       "3                      NaN  ...           35.146989  30.370370   \n",
       "4                      NaN  ...           34.433397  30.648148   \n",
       "5                      NaN  ...           33.762299  31.203704   \n",
       "6                      NaN  ...           35.078549  33.240741   \n",
       "7                      NaN  ...           36.145836  32.685185   \n",
       "8                      NaN  ...           34.083169  30.185185   \n",
       "9                      NaN  ...           36.648689  33.888889   \n",
       "10                     NaN  ...           34.434668  30.185185   \n",
       "11                     NaN  ...           36.132192  34.351852   \n",
       "12                     NaN  ...           36.384631  31.388889   \n",
       "13                     NaN  ...           35.093162  33.518519   \n",
       "14                     NaN  ...           36.416765  32.500000   \n",
       "15                     NaN  ...           33.815796  29.537037   \n",
       "16                     NaN  ...           33.254913  31.296296   \n",
       "17                     NaN  ...           37.201889  32.222222   \n",
       "18                     NaN  ...           35.020901  32.222222   \n",
       "19                     NaN  ...           35.446351  32.962963   \n",
       "20                     NaN  ...           36.061167  33.333333   \n",
       "21                     NaN  ...           33.964215  29.166667   \n",
       "22                     NaN  ...           35.474929  32.222222   \n",
       "23                     NaN  ...           36.571518  32.592593   \n",
       "24                     NaN  ...           31.926539  30.277778   \n",
       "25                     NaN  ...           34.886966  31.574074   \n",
       "26                     NaN  ...           36.950293  33.055556   \n",
       "27                     NaN  ...           36.275674  31.759259   \n",
       "28                     NaN  ...           36.708353  32.314815   \n",
       "29                     NaN  ...           34.372841  33.240741   \n",
       "30                     NaN  ...           36.893336  35.555556   \n",
       "31                     NaN  ...           34.205643  30.925926   \n",
       "32                     NaN  ...           35.145922  30.925926   \n",
       "33                     NaN  ...           33.985223  32.037037   \n",
       "\n",
       "    BBH/CoT_chatfmt  Codex-Eval/Pass@1  Codex-Eval/Pass@1_chatfmt  TydiQA/CB  \\\n",
       "0         28.425926          11.585366                   0.000000   9.505480   \n",
       "1         33.888889          14.024390                   1.829268   9.392081   \n",
       "2         33.611111          12.195122                   2.439024   9.693916   \n",
       "3         29.444444          13.414634                   3.048780  10.480295   \n",
       "4         31.574074          11.585366                   2.439024  10.354777   \n",
       "5         32.685185          14.634146                   8.536585  10.004577   \n",
       "6         32.129630          12.195122                   1.829268  11.518016   \n",
       "7         32.592593          12.804878                   3.048780  10.396121   \n",
       "8         30.370370          13.414634                   1.829268  10.411882   \n",
       "9         33.981481          12.195122                   0.000000  10.823051   \n",
       "10        30.092593          16.463415                   4.268293  11.122201   \n",
       "11        34.351852          12.195122                   0.000000  10.950366   \n",
       "12        31.111111          14.024390                   1.829268   9.666055   \n",
       "13        33.611111          12.195122                   0.000000  10.139922   \n",
       "14        32.129630          12.195122                   3.048780  10.412555   \n",
       "15        29.814815          13.414634                   1.829268   9.772804   \n",
       "16        32.500000          14.024390                   3.658537  10.604540   \n",
       "17        32.407407          13.414634                   0.000000  10.604490   \n",
       "18        30.740741          12.804878                   2.439024   8.933082   \n",
       "19        32.407407          10.975610                   1.219512  10.637597   \n",
       "20        32.592593          12.804878                   4.878049   9.098630   \n",
       "21        30.000000          14.024390                   3.658537  10.105389   \n",
       "22        32.777778          13.414634                   3.048780  10.509469   \n",
       "23        32.500000          15.243902                   2.439024   9.003687   \n",
       "24        29.722222          14.024390                   2.439024   9.153746   \n",
       "25        31.388889          11.585366                   0.609756   9.306889   \n",
       "26        32.962963          11.585366                   0.609756  10.193179   \n",
       "27        31.203704          13.414634                   2.439024   8.072466   \n",
       "28        33.055556          10.975610                   0.609756  10.102308   \n",
       "29        32.037037          12.195122                   3.658537  10.796108   \n",
       "30        34.629630          10.365854                   0.609756  10.292829   \n",
       "31        30.555556          13.414634                   5.487805   9.613197   \n",
       "32        30.648148          13.414634                   4.268293   9.416884   \n",
       "33        30.648148          15.243902                   2.439024   9.449677   \n",
       "\n",
       "    TydiQA/CB_chatfmt  TydiQA/GP  TydiQA/GP_chatfmt  MMLU/5-shot  \n",
       "0           10.349886  40.403106          38.564264          NaN  \n",
       "1            9.737485  43.907156          43.738652    38.562883  \n",
       "2           10.016957  46.802986          45.407914    43.255946  \n",
       "3           10.313920  45.833678          43.672849    40.841760  \n",
       "4            9.684929  45.662417          38.529798    36.454921  \n",
       "5            9.638428  41.657123          43.302263    38.235294  \n",
       "6            9.529373  38.110773          41.097125    42.899872  \n",
       "7            9.367477  43.079553          44.493847    41.639368  \n",
       "8           10.020261  44.920150          46.580197    39.965817  \n",
       "9            9.936207  44.758646          45.182731    41.034041  \n",
       "10          11.299030  41.816537          40.685642    33.506623  \n",
       "11          11.043178  42.600732          45.547473    42.871386  \n",
       "12           8.182204  42.964452          43.529163    43.704600  \n",
       "13           9.205560  45.763966          44.731724    42.906993  \n",
       "14           9.971524  43.706823          43.307353    43.191853  \n",
       "15          10.506730  42.111272          43.644052    36.006267  \n",
       "16          10.283347  40.576965          45.108756    36.568865  \n",
       "17           9.126629  46.841733          45.030477    44.374021  \n",
       "18           9.082622  45.165342          42.707950    39.574135  \n",
       "19           9.410252  44.371611          44.058671    40.620994  \n",
       "20          10.186244  47.688415          45.787596    40.457200  \n",
       "21           8.987745  39.054953          46.236673    37.074491  \n",
       "22           9.879061  43.118828          44.730655    44.082040  \n",
       "23           9.571515  47.762392          41.322312    41.311779  \n",
       "24           9.981706  45.134082          43.827197    35.557613  \n",
       "25          10.939492  44.255913          42.862591    44.459479  \n",
       "26           9.701470  42.085146          43.128486    45.014955  \n",
       "27          10.409846  44.812705          40.361275    43.113517  \n",
       "28           8.484646  47.221444          39.937314    45.541946  \n",
       "29           9.498969  42.026308          44.303880    41.518302  \n",
       "30           9.562766  45.699490          43.730480    44.295684  \n",
       "31          10.002179  38.937048          40.854204    35.735650  \n",
       "32          10.049925  46.931470          43.590882    38.505911  \n",
       "33          10.360039  43.179150          46.058825    32.894175  \n",
       "\n",
       "[34 rows x 28 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "09c5af46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_labels = [\n",
    "    'Answer:\\n<|assistant|>\\nThe answer is:',\n",
    "    'Answer:\\n<|assistant|>\\n',\n",
    "    '<|assistant|>\\nAnswer:',\n",
    "    '<|assistant|>\\nThe answer is:',\n",
    "]\n",
    "x_labels = [f'v{i+1}:\\n{x}' for i,x in enumerate(x_labels)]\n",
    "\n",
    "dfc = df.copy()\n",
    "dfc = df.filter(regex='_v|run')\n",
    "\n",
    "runs = dfc['run_name'].to_list()[::-1]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for axi, task in enumerate(['MMLU/0-shot', 'MMLU/5-shot']):\n",
    "\n",
    "    ax = axs[axi]\n",
    "    cols = [f'{task}_v{x}' for x in [1, 2, 3, 4]]\n",
    "    x = np.arange(len(x_labels))\n",
    "\n",
    "    width = .25\n",
    "    multiplier = 0\n",
    "\n",
    "    for run in runs:\n",
    "        offset = width*multiplier\n",
    "        y = dfc[dfc['run_name']==run][cols].to_numpy().squeeze()\n",
    "        rects = ax.bar(x+offset, y, width, label=run)\n",
    "        ax.bar_label(rects, padding=3, fmt='{:.2f}')\n",
    "        multiplier += 1\n",
    "\n",
    "    ax.set_title(task)\n",
    "    ax.set_xticks(x+width)\n",
    "    ax.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_ylim(0, 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaa6ba4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cot': 97570, 'flan_v2': 97570, 'dolly': 1464, 'oasst1': 3394},\n",
       " {'cot': 72119, 'dolly': 439, 'flan_v2': 126074, 'oasst1': 339},\n",
       " {'cot': 45092, 'dolly': 2818, 'flan_v2': 34790, 'oasst1': 118847},\n",
       " {'cot': 17126, 'dolly': 108593, 'flan_v2': 69580, 'oasst1': 2066},\n",
       " {'cot': 6323, 'dolly': 40966, 'flan_v2': 81933, 'oasst1': 81933}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_data_points = 200000 # 10000, 50000, 100000, 200000\n",
    "subsample_mixture_list = []\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': 0.48785105, 'flan_v2': 0.48785105, 'dolly': 0.00732313, 'oasst1': 0.01697478}.items())\n",
    "] # humanmix mixture.\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.360595703125, \"dolly\": 0.0021991729736328125, \"flan_v2\": 0.63037109375, \"oasst1\": 0.0016956329345703125}.items())\n",
    "] # pythia-1.4b humanmix_uniform:200k_doremiv1.json\n",
    "\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.2254638671875, \"dolly\": 0.01409149169921875, \"flan_v2\": 0.1739501953125, \"oasst1\": 0.59423828125}.items())\n",
    "] # pythia-1.4b humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.08563232421875, \"dolly\": 0.54296875, \"flan_v2\": 0.347900390625, \"oasst1\": 0.0103302001953125}.items())\n",
    "] # llama-7b_humanmix_uniform:200k_doremiv2.json\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.0316162109375, \"dolly\": 0.204833984375, \"flan_v2\": 0.40966796875, \"oasst1\": 0.40966796875}.items()\n",
    "        )] # llama-7b_humanmix_uniform:600k_doremiv2.json\n",
    "subsample_mixture_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20b1ec2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211155"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6323+40966+81933+81933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3dd3dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_dir = 'results/ft1'\n",
    "\n",
    "# d = {\n",
    "#     'bbh_s=0': 'bbh_s=3',\n",
    "#     'gsm': 'gsm_s=8_cot',\n",
    "#     'mmlu': 'mmlu_s=0',\n",
    "#     'tydiqa_cb': 'tydiqa_s=1_cb',\n",
    "#     'tydiqa_gp': 'tydiqa_s=1_gp',\n",
    "# }\n",
    "\n",
    "# d.update({k+'_chatfmt': v+'_chatfmt' for k,v in d.items()})\n",
    "\n",
    "# for subdir in os.listdir(exp_dir):    \n",
    "#     for task_name_src, task_name_tgt in d.items():\n",
    "#         path_src = os.path.join(exp_dir, subdir, 'eval', task_name_src)\n",
    "#         path_tgt = os.path.join(exp_dir, subdir, 'eval', task_name_tgt)\n",
    "#         if os.path.isdir(path_src):\n",
    "# #             os.rename(path_src, path_tgt)\n",
    "#             print(path_src)\n",
    "#             print(path_tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27138820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_train_samples</th>\n",
       "      <th>model_args.model_name_or_path</th>\n",
       "      <th>data_args.subsample_mixture</th>\n",
       "      <th>MMLU/0-shot</th>\n",
       "      <th>GSM/Direct</th>\n",
       "      <th>GSM/CoT</th>\n",
       "      <th>BBH/Direct</th>\n",
       "      <th>Codex-Eval/Pass@1</th>\n",
       "      <th>TydiQA/CB</th>\n",
       "      <th>TydiQA/GP</th>\n",
       "      <th>Average</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200804</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>{'cot': 15356, 'dolly': 894, 'flan_v2': 182740, 'oasst1': 1814}</td>\n",
       "      <td>44.601909</td>\n",
       "      <td>3.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37.147236</td>\n",
       "      <td>1.829268</td>\n",
       "      <td>9.934316</td>\n",
       "      <td>44.361673</td>\n",
       "      <td>22.196343</td>\n",
       "      <td>-2.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200128</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 22540, 'dolly': 2790, 'flan_v2': 174520, 'oasst1': 278}</td>\n",
       "      <td>23.123487</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>29.677548</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>1.543347</td>\n",
       "      <td>8.898066</td>\n",
       "      <td>9.907458</td>\n",
       "      <td>-9.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'flan_v2': 100000}</td>\n",
       "      <td>23.002421</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.757914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.821590</td>\n",
       "      <td>8.841241</td>\n",
       "      <td>9.989024</td>\n",
       "      <td>-9.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'self_instruct': 100000}</td>\n",
       "      <td>23.557898</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.590479</td>\n",
       "      <td>1.219512</td>\n",
       "      <td>1.410211</td>\n",
       "      <td>6.140904</td>\n",
       "      <td>9.774144</td>\n",
       "      <td>-10.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'cot': 50000, 'dolly': 50000, 'flan_v2': 50000, 'oasst1': 50000}</td>\n",
       "      <td>22.938328</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>29.973845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.875094</td>\n",
       "      <td>7.962404</td>\n",
       "      <td>9.892810</td>\n",
       "      <td>-11.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200804</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 15356, 'dolly': 894, 'flan_v2': 182740, 'oasst1': 1814}</td>\n",
       "      <td>23.045150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>30.422551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.395340</td>\n",
       "      <td>7.712177</td>\n",
       "      <td>9.867888</td>\n",
       "      <td>-11.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 12500, 'dolly': 12500, 'flan_v2': 12500, 'oasst1': 12500}</td>\n",
       "      <td>22.952571</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.284956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.896922</td>\n",
       "      <td>7.082380</td>\n",
       "      <td>9.745261</td>\n",
       "      <td>-11.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>199992</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'baize': 16666, 'code_alpaca': 16666, 'cot': 16666, 'dolly': 16666, 'flan_v2': 16666, 'gpt4_alpaca': 16666, 'oasst1': 16666, 'self_instruct': 16666, 'sharegpt': 16666, 'stanford_alpaca': 16666, 'super_ni': 16666, 'unnatural_instructions': 16666}</td>\n",
       "      <td>23.016664</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.758117</td>\n",
       "      <td>1.219512</td>\n",
       "      <td>1.367148</td>\n",
       "      <td>7.950251</td>\n",
       "      <td>9.830242</td>\n",
       "      <td>-12.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99999</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'cot': 40031, 'dolly': 6009, 'flan_v2': 40031, 'oasst1': 13928}</td>\n",
       "      <td>23.023786</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.827929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.158432</td>\n",
       "      <td>7.918454</td>\n",
       "      <td>9.704086</td>\n",
       "      <td>-12.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'super_ni': 100000}</td>\n",
       "      <td>23.151973</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.258770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.877706</td>\n",
       "      <td>7.116692</td>\n",
       "      <td>9.486449</td>\n",
       "      <td>-13.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>99996</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'baize': 8333, 'code_alpaca': 8333, 'cot': 8333, 'dolly': 8333, 'flan_v2': 8333, 'gpt4_alpaca': 8333, 'oasst1': 8333, 'self_instruct': 8333, 'sharegpt': 8333, 'stanford_alpaca': 8333, 'super_ni': 8333, 'unnatural_instructions': 8333}</td>\n",
       "      <td>22.938328</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30.391050</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>1.773780</td>\n",
       "      <td>5.948287</td>\n",
       "      <td>9.380172</td>\n",
       "      <td>-14.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'unnatural_instructions': 100000}</td>\n",
       "      <td>23.201823</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.127942</td>\n",
       "      <td>1.829268</td>\n",
       "      <td>1.730040</td>\n",
       "      <td>4.095138</td>\n",
       "      <td>9.212030</td>\n",
       "      <td>-14.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9998</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 4878, 'dolly': 73, 'flan_v2': 4878, 'oasst1': 169}</td>\n",
       "      <td>22.945449</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>28.108541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.083539</td>\n",
       "      <td>6.646854</td>\n",
       "      <td>9.469198</td>\n",
       "      <td>-15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'cot': 25000, 'dolly': 25000, 'flan_v2': 25000, 'oasst1': 25000}</td>\n",
       "      <td>22.938328</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>29.980136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.445112</td>\n",
       "      <td>7.088936</td>\n",
       "      <td>9.564645</td>\n",
       "      <td>-15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>49998</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 24392, 'dolly': 366, 'flan_v2': 24392, 'oasst1': 848}</td>\n",
       "      <td>22.895599</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.028842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.448538</td>\n",
       "      <td>6.055629</td>\n",
       "      <td>9.489801</td>\n",
       "      <td>-15.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50031</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 5635, 'dolly': 697, 'flan_v2': 43630, 'oasst1': 69}</td>\n",
       "      <td>22.852870</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.429958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.456560</td>\n",
       "      <td>8.441289</td>\n",
       "      <td>9.668668</td>\n",
       "      <td>-15.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10005</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 1127, 'dolly': 139, 'flan_v2': 8726, 'oasst1': 13}</td>\n",
       "      <td>23.159094</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>29.467971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.922864</td>\n",
       "      <td>4.975758</td>\n",
       "      <td>9.289384</td>\n",
       "      <td>-15.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'cot': 100000}</td>\n",
       "      <td>23.016664</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.558459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.931833</td>\n",
       "      <td>7.495874</td>\n",
       "      <td>9.000404</td>\n",
       "      <td>-16.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'stanford_alpaca': 100000}</td>\n",
       "      <td>22.988178</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>27.052148</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>1.615986</td>\n",
       "      <td>5.113901</td>\n",
       "      <td>8.982853</td>\n",
       "      <td>-16.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{}</td>\n",
       "      <td>23.721692</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>24.459354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.398436</td>\n",
       "      <td>5.114215</td>\n",
       "      <td>8.599100</td>\n",
       "      <td>-17.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'code_alpaca': 100000}</td>\n",
       "      <td>22.966814</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>26.876242</td>\n",
       "      <td>1.219512</td>\n",
       "      <td>1.383378</td>\n",
       "      <td>5.525014</td>\n",
       "      <td>8.852994</td>\n",
       "      <td>-17.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10000</td>\n",
       "      <td>results/baselines/gpt2-medium</td>\n",
       "      <td>{'cot': 2500, 'dolly': 2500, 'flan_v2': 2500, 'oasst1': 2500}</td>\n",
       "      <td>22.852870</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.637130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.946636</td>\n",
       "      <td>5.612540</td>\n",
       "      <td>8.435597</td>\n",
       "      <td>-19.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'baize': 100000}</td>\n",
       "      <td>22.924085</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>25.485221</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>1.329486</td>\n",
       "      <td>4.139038</td>\n",
       "      <td>8.498227</td>\n",
       "      <td>-19.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'sharegpt': 100000}</td>\n",
       "      <td>23.052272</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.323305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.732119</td>\n",
       "      <td>3.702220</td>\n",
       "      <td>8.187131</td>\n",
       "      <td>-19.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'dolly': 100000}</td>\n",
       "      <td>22.810141</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>15.476953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.347582</td>\n",
       "      <td>5.569227</td>\n",
       "      <td>7.171986</td>\n",
       "      <td>-20.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'oasst1': 100000}</td>\n",
       "      <td>22.973935</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.000967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.797507</td>\n",
       "      <td>6.326418</td>\n",
       "      <td>8.156975</td>\n",
       "      <td>-20.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100000</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>{'gpt4_alpaca': 100000}</td>\n",
       "      <td>23.052272</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25.812740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.571938</td>\n",
       "      <td>4.294121</td>\n",
       "      <td>8.104439</td>\n",
       "      <td>-21.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>200000</td>\n",
       "      <td>huggyllama/llama-7b</td>\n",
       "      <td>{}</td>\n",
       "      <td>32.459764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.268293</td>\n",
       "      <td>9.765382</td>\n",
       "      <td>37.489078</td>\n",
       "      <td>18.996503</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_train_samples          model_args.model_name_or_path  \\\n",
       "0                200804  results/baselines/huggyllama/llama-7b   \n",
       "1                200128          results/baselines/gpt2-medium   \n",
       "2                100000                            gpt2-medium   \n",
       "3                100000                            gpt2-medium   \n",
       "4                200000                            gpt2-medium   \n",
       "5                200804          results/baselines/gpt2-medium   \n",
       "6                 50000          results/baselines/gpt2-medium   \n",
       "7                199992                            gpt2-medium   \n",
       "8                 99999                            gpt2-medium   \n",
       "9                100000                            gpt2-medium   \n",
       "10                99996                            gpt2-medium   \n",
       "11               100000                            gpt2-medium   \n",
       "12                 9998          results/baselines/gpt2-medium   \n",
       "13               100000                            gpt2-medium   \n",
       "14                49998          results/baselines/gpt2-medium   \n",
       "15                50031          results/baselines/gpt2-medium   \n",
       "16                10005          results/baselines/gpt2-medium   \n",
       "17               100000                            gpt2-medium   \n",
       "18               100000                            gpt2-medium   \n",
       "19               200000                            gpt2-medium   \n",
       "20               100000                            gpt2-medium   \n",
       "21                10000          results/baselines/gpt2-medium   \n",
       "22               100000                            gpt2-medium   \n",
       "23               100000                            gpt2-medium   \n",
       "24               100000                            gpt2-medium   \n",
       "25               100000                            gpt2-medium   \n",
       "26               100000                            gpt2-medium   \n",
       "27               200000                    huggyllama/llama-7b   \n",
       "\n",
       "                                                                                                                                                                                                                               data_args.subsample_mixture  \\\n",
       "0                                                                                                                                                                                          {'cot': 15356, 'dolly': 894, 'flan_v2': 182740, 'oasst1': 1814}   \n",
       "1                                                                                                                                                                                          {'cot': 22540, 'dolly': 2790, 'flan_v2': 174520, 'oasst1': 278}   \n",
       "2                                                                                                                                                                                                                                      {'flan_v2': 100000}   \n",
       "3                                                                                                                                                                                                                                {'self_instruct': 100000}   \n",
       "4                                                                                                                                                                                        {'cot': 50000, 'dolly': 50000, 'flan_v2': 50000, 'oasst1': 50000}   \n",
       "5                                                                                                                                                                                          {'cot': 15356, 'dolly': 894, 'flan_v2': 182740, 'oasst1': 1814}   \n",
       "6                                                                                                                                                                                        {'cot': 12500, 'dolly': 12500, 'flan_v2': 12500, 'oasst1': 12500}   \n",
       "7   {'baize': 16666, 'code_alpaca': 16666, 'cot': 16666, 'dolly': 16666, 'flan_v2': 16666, 'gpt4_alpaca': 16666, 'oasst1': 16666, 'self_instruct': 16666, 'sharegpt': 16666, 'stanford_alpaca': 16666, 'super_ni': 16666, 'unnatural_instructions': 16666}   \n",
       "8                                                                                                                                                                                         {'cot': 40031, 'dolly': 6009, 'flan_v2': 40031, 'oasst1': 13928}   \n",
       "9                                                                                                                                                                                                                                     {'super_ni': 100000}   \n",
       "10              {'baize': 8333, 'code_alpaca': 8333, 'cot': 8333, 'dolly': 8333, 'flan_v2': 8333, 'gpt4_alpaca': 8333, 'oasst1': 8333, 'self_instruct': 8333, 'sharegpt': 8333, 'stanford_alpaca': 8333, 'super_ni': 8333, 'unnatural_instructions': 8333}   \n",
       "11                                                                                                                                                                                                                      {'unnatural_instructions': 100000}   \n",
       "12                                                                                                                                                                                              {'cot': 4878, 'dolly': 73, 'flan_v2': 4878, 'oasst1': 169}   \n",
       "13                                                                                                                                                                                       {'cot': 25000, 'dolly': 25000, 'flan_v2': 25000, 'oasst1': 25000}   \n",
       "14                                                                                                                                                                                           {'cot': 24392, 'dolly': 366, 'flan_v2': 24392, 'oasst1': 848}   \n",
       "15                                                                                                                                                                                             {'cot': 5635, 'dolly': 697, 'flan_v2': 43630, 'oasst1': 69}   \n",
       "16                                                                                                                                                                                              {'cot': 1127, 'dolly': 139, 'flan_v2': 8726, 'oasst1': 13}   \n",
       "17                                                                                                                                                                                                                                         {'cot': 100000}   \n",
       "18                                                                                                                                                                                                                             {'stanford_alpaca': 100000}   \n",
       "19                                                                                                                                                                                                                                                      {}   \n",
       "20                                                                                                                                                                                                                                 {'code_alpaca': 100000}   \n",
       "21                                                                                                                                                                                           {'cot': 2500, 'dolly': 2500, 'flan_v2': 2500, 'oasst1': 2500}   \n",
       "22                                                                                                                                                                                                                                       {'baize': 100000}   \n",
       "23                                                                                                                                                                                                                                    {'sharegpt': 100000}   \n",
       "24                                                                                                                                                                                                                                       {'dolly': 100000}   \n",
       "25                                                                                                                                                                                                                                      {'oasst1': 100000}   \n",
       "26                                                                                                                                                                                                                                 {'gpt4_alpaca': 100000}   \n",
       "27                                                                                                                                                                                                                                                      {}   \n",
       "\n",
       "    MMLU/0-shot  GSM/Direct  GSM/CoT  BBH/Direct  Codex-Eval/Pass@1  \\\n",
       "0     44.601909         3.5     14.0   37.147236           1.829268   \n",
       "1     23.123487         4.0      1.5   29.677548           0.609756   \n",
       "2     23.002421         3.5      3.0   29.757914           0.000000   \n",
       "3     23.557898         4.0      2.5   29.590479           1.219512   \n",
       "4     22.938328         5.0      1.5   29.973845           0.000000   \n",
       "5     23.045150         3.0      3.5   30.422551           0.000000   \n",
       "6     22.952571         3.0      3.0   30.284956           0.000000   \n",
       "7     23.016664         2.5      3.0   29.758117           1.219512   \n",
       "8     23.023786         2.5      2.5   29.827929           0.000000   \n",
       "9     23.151973         2.5      2.5   29.258770           0.000000   \n",
       "10    22.938328         3.5      0.5   30.391050           0.609756   \n",
       "11    23.201823         3.5      1.0   29.127942           1.829268   \n",
       "12    22.945449         4.0      3.5   28.108541           0.000000   \n",
       "13    22.938328         3.0      2.5   29.980136           0.000000   \n",
       "14    22.895599         3.0      3.0   30.028842           0.000000   \n",
       "15    22.852870         2.5      3.0   29.429958           0.000000   \n",
       "16    23.159094         3.0      3.5   29.467971           0.000000   \n",
       "17    23.016664         3.0      0.0   27.558459           0.000000   \n",
       "18    22.988178         3.0      2.5   27.052148           0.609756   \n",
       "19    23.721692         4.0      1.5   24.459354           0.000000   \n",
       "20    22.966814         3.5      0.5   26.876242           1.219512   \n",
       "21    22.852870         3.0      1.0   24.637130           0.000000   \n",
       "22    22.924085         3.5      1.5   25.485221           0.609756   \n",
       "23    23.052272         0.5      2.0   26.323305           0.000000   \n",
       "24    22.810141         2.5      1.5   15.476953           0.000000   \n",
       "25    22.973935         2.0      0.0   24.000967           0.000000   \n",
       "26    23.052272         1.5      0.5   25.812740           0.000000   \n",
       "27    32.459764         NaN     11.0         NaN           4.268293   \n",
       "\n",
       "    TydiQA/CB  TydiQA/GP    Average  ranking  \n",
       "0    9.934316  44.361673  22.196343  -2.1250  \n",
       "1    1.543347   8.898066   9.907458  -9.2500  \n",
       "2    1.821590   8.841241   9.989024  -9.7500  \n",
       "3    1.410211   6.140904   9.774144 -10.3125  \n",
       "4    1.875094   7.962404   9.892810 -11.0625  \n",
       "5    1.395340   7.712177   9.867888 -11.2500  \n",
       "6    1.896922   7.082380   9.745261 -11.8750  \n",
       "7    1.367148   7.950251   9.830242 -12.0625  \n",
       "8    2.158432   7.918454   9.704086 -12.0625  \n",
       "9    1.877706   7.116692   9.486449 -13.6875  \n",
       "10   1.773780   5.948287   9.380172 -14.1250  \n",
       "11   1.730040   4.095138   9.212030 -14.1875  \n",
       "12   1.083539   6.646854   9.469198 -15.0000  \n",
       "13   1.445112   7.088936   9.564645 -15.0000  \n",
       "14   1.448538   6.055629   9.489801 -15.2500  \n",
       "15   1.456560   8.441289   9.668668 -15.5000  \n",
       "16   0.922864   4.975758   9.289384 -15.8750  \n",
       "17   1.931833   7.495874   9.000404 -16.1250  \n",
       "18   1.615986   5.113901   8.982853 -16.2500  \n",
       "19   1.398436   5.114215   8.599100 -17.0000  \n",
       "20   1.383378   5.525014   8.852994 -17.8125  \n",
       "21   1.946636   5.612540   8.435597 -19.5000  \n",
       "22   1.329486   4.139038   8.498227 -19.7500  \n",
       "23   1.732119   3.702220   8.187131 -19.8750  \n",
       "24   2.347582   5.569227   7.171986 -20.8125  \n",
       "25   1.797507   6.326418   8.156975 -20.8750  \n",
       "26   1.571938   4.294121   8.104439 -21.2500  \n",
       "27   9.765382  37.489078  18.996503      NaN  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dfc = df.copy()\n",
    "dfc.insert(0, 'total_train_samples',  dfc['data_args.subsample_mixture'].apply(\n",
    "    lambda d: sum(list(d.values())) if d else 200000))\n",
    "# dfc[dfc['total_train_samples'].apply(\n",
    "#     lambda x: total_train_samples-500<x<total_train_samples+500)]\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fad6edc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'`Styler.apply` and `.applymap` are not compatible with non-unique index or columns.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/core/formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    342\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:383\u001b[0m, in \u001b[0;36mStyler._repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03mHooks into Jupyter notebook rich display system, which calls _repr_html_ by\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03mdefault if an object is returned at the end of a cell.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyler.render.repr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:1308\u001b[0m, in \u001b[0;36mStyler.to_html\u001b[0;34m(self, buf, table_uuid, table_attributes, sparse_index, sparse_columns, bold_headers, caption, max_rows, max_columns, encoding, doctype_html, exclude_styles, **kwargs)\u001b[0m\n\u001b[1;32m   1305\u001b[0m     obj\u001b[38;5;241m.\u001b[39mset_caption(caption)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;66;03m# Build HTML string..\u001b[39;00m\n\u001b[0;32m-> 1308\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_html\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_styles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_styles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstyler.render.encoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoctype_html\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoctype_html\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m save_to_buffer(\n\u001b[1;32m   1320\u001b[0m     html, buf\u001b[38;5;241m=\u001b[39mbuf, encoding\u001b[38;5;241m=\u001b[39m(encoding \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1321\u001b[0m )\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style_render.py:205\u001b[0m, in \u001b[0;36mStylerRenderer._render_html\u001b[0;34m(self, sparse_index, sparse_columns, max_rows, max_cols, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_render_html\u001b[39m(\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    195\u001b[0m     sparse_index: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    201\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    Renders the ``Styler`` including all applied styles to HTML.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Generates a dict with necessary kwargs passed to jinja2 template.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m&nbsp;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     d\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_html\u001b[38;5;241m.\u001b[39mrender(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md,\n\u001b[1;32m    209\u001b[0m         html_table_tpl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_html_table,\n\u001b[1;32m    210\u001b[0m         html_style_tpl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_html_style,\n\u001b[1;32m    211\u001b[0m     )\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style_render.py:162\u001b[0m, in \u001b[0;36mStylerRenderer._render\u001b[0;34m(self, sparse_index, sparse_columns, max_rows, max_cols, blank)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_render\u001b[39m(\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    150\u001b[0m     sparse_index: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m     blank: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m ):\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Computes and applies styles and then generates the general render dicts.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    Also extends the `ctx` and `ctx_index` attributes with those of concatenated\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    stylers for use within `_translate_latex`\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     dxs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    164\u001b[0m     ctx_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style_render.py:257\u001b[0m, in \u001b[0;36mStylerRenderer._compute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_todo:\n\u001b[0;32m--> 257\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:1693\u001b[0m, in \u001b[0;36mStyler._apply\u001b[0;34m(self, func, axis, subset, **kwargs)\u001b[0m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(result\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39misin(data\u001b[38;5;241m.\u001b[39mcolumns)):\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1691\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mshape, data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m   1692\u001b[0m     )\n\u001b[0;32m-> 1693\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_ctx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:1505\u001b[0m, in \u001b[0;36mStyler._update_ctx\u001b[0;34m(self, attrs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;124;03mUpdate the state of the ``Styler`` for data cells.\u001b[39;00m\n\u001b[1;32m   1494\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;124;03m    matter.\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   1506\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Styler.apply` and `.applymap` are not compatible \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-unique index or columns.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1508\u001b[0m     )\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cn \u001b[38;5;129;01min\u001b[39;00m attrs\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m   1511\u001b[0m     j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(cn)\n",
      "\u001b[0;31mKeyError\u001b[0m: '`Styler.apply` and `.applymap` are not compatible with non-unique index or columns.'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff6ec921210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3618: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3619: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'`Styler.apply` and `.applymap` are not compatible with non-unique index or columns.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/core/formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    342\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:383\u001b[0m, in \u001b[0;36mStyler._repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03mHooks into Jupyter notebook rich display system, which calls _repr_html_ by\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03mdefault if an object is returned at the end of a cell.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyler.render.repr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:1308\u001b[0m, in \u001b[0;36mStyler.to_html\u001b[0;34m(self, buf, table_uuid, table_attributes, sparse_index, sparse_columns, bold_headers, caption, max_rows, max_columns, encoding, doctype_html, exclude_styles, **kwargs)\u001b[0m\n\u001b[1;32m   1305\u001b[0m     obj\u001b[38;5;241m.\u001b[39mset_caption(caption)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;66;03m# Build HTML string..\u001b[39;00m\n\u001b[0;32m-> 1308\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_html\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_styles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_styles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstyler.render.encoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoctype_html\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoctype_html\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m save_to_buffer(\n\u001b[1;32m   1320\u001b[0m     html, buf\u001b[38;5;241m=\u001b[39mbuf, encoding\u001b[38;5;241m=\u001b[39m(encoding \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1321\u001b[0m )\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style_render.py:205\u001b[0m, in \u001b[0;36mStylerRenderer._render_html\u001b[0;34m(self, sparse_index, sparse_columns, max_rows, max_cols, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_render_html\u001b[39m(\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    195\u001b[0m     sparse_index: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    201\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    Renders the ``Styler`` including all applied styles to HTML.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Generates a dict with necessary kwargs passed to jinja2 template.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m&nbsp;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     d\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_html\u001b[38;5;241m.\u001b[39mrender(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md,\n\u001b[1;32m    209\u001b[0m         html_table_tpl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_html_table,\n\u001b[1;32m    210\u001b[0m         html_style_tpl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_html_style,\n\u001b[1;32m    211\u001b[0m     )\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style_render.py:162\u001b[0m, in \u001b[0;36mStylerRenderer._render\u001b[0;34m(self, sparse_index, sparse_columns, max_rows, max_cols, blank)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_render\u001b[39m(\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    150\u001b[0m     sparse_index: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m     blank: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m ):\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Computes and applies styles and then generates the general render dicts.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    Also extends the `ctx` and `ctx_index` attributes with those of concatenated\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    stylers for use within `_translate_latex`\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     dxs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    164\u001b[0m     ctx_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style_render.py:257\u001b[0m, in \u001b[0;36mStylerRenderer._compute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_todo:\n\u001b[0;32m--> 257\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:1693\u001b[0m, in \u001b[0;36mStyler._apply\u001b[0;34m(self, func, axis, subset, **kwargs)\u001b[0m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(result\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39misin(data\u001b[38;5;241m.\u001b[39mcolumns)):\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1691\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mshape, data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m   1692\u001b[0m     )\n\u001b[0;32m-> 1693\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_ctx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:1505\u001b[0m, in \u001b[0;36mStyler._update_ctx\u001b[0;34m(self, attrs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;124;03mUpdate the state of the ``Styler`` for data cells.\u001b[39;00m\n\u001b[1;32m   1494\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;124;03m    matter.\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   1506\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Styler.apply` and `.applymap` are not compatible \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-unique index or columns.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1508\u001b[0m     )\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cn \u001b[38;5;129;01min\u001b[39;00m attrs\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m   1511\u001b[0m     j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(cn)\n",
      "\u001b[0;31mKeyError\u001b[0m: '`Styler.apply` and `.applymap` are not compatible with non-unique index or columns.'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fff9c6f3250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'`Styler.apply` and `.applymap` are not compatible with non-unique index or columns.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/core/formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    342\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:383\u001b[0m, in \u001b[0;36mStyler._repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03mHooks into Jupyter notebook rich display system, which calls _repr_html_ by\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03mdefault if an object is returned at the end of a cell.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyler.render.repr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:1308\u001b[0m, in \u001b[0;36mStyler.to_html\u001b[0;34m(self, buf, table_uuid, table_attributes, sparse_index, sparse_columns, bold_headers, caption, max_rows, max_columns, encoding, doctype_html, exclude_styles, **kwargs)\u001b[0m\n\u001b[1;32m   1305\u001b[0m     obj\u001b[38;5;241m.\u001b[39mset_caption(caption)\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;66;03m# Build HTML string..\u001b[39;00m\n\u001b[0;32m-> 1308\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_html\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_styles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_styles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstyler.render.encoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoctype_html\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoctype_html\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m save_to_buffer(\n\u001b[1;32m   1320\u001b[0m     html, buf\u001b[38;5;241m=\u001b[39mbuf, encoding\u001b[38;5;241m=\u001b[39m(encoding \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1321\u001b[0m )\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style_render.py:205\u001b[0m, in \u001b[0;36mStylerRenderer._render_html\u001b[0;34m(self, sparse_index, sparse_columns, max_rows, max_cols, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_render_html\u001b[39m(\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    195\u001b[0m     sparse_index: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    201\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    Renders the ``Styler`` including all applied styles to HTML.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Generates a dict with necessary kwargs passed to jinja2 template.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m&nbsp;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     d\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_html\u001b[38;5;241m.\u001b[39mrender(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md,\n\u001b[1;32m    209\u001b[0m         html_table_tpl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_html_table,\n\u001b[1;32m    210\u001b[0m         html_style_tpl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_html_style,\n\u001b[1;32m    211\u001b[0m     )\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style_render.py:162\u001b[0m, in \u001b[0;36mStylerRenderer._render\u001b[0;34m(self, sparse_index, sparse_columns, max_rows, max_cols, blank)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_render\u001b[39m(\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    150\u001b[0m     sparse_index: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m     blank: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m ):\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Computes and applies styles and then generates the general render dicts.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    Also extends the `ctx` and `ctx_index` attributes with those of concatenated\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    stylers for use within `_translate_latex`\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     dxs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    164\u001b[0m     ctx_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style_render.py:257\u001b[0m, in \u001b[0;36mStylerRenderer._compute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_todo:\n\u001b[0;32m--> 257\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:1693\u001b[0m, in \u001b[0;36mStyler._apply\u001b[0;34m(self, func, axis, subset, **kwargs)\u001b[0m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(result\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39misin(data\u001b[38;5;241m.\u001b[39mcolumns)):\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1691\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mshape, data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m   1692\u001b[0m     )\n\u001b[0;32m-> 1693\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_ctx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:1505\u001b[0m, in \u001b[0;36mStyler._update_ctx\u001b[0;34m(self, attrs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;124;03mUpdate the state of the ``Styler`` for data cells.\u001b[39;00m\n\u001b[1;32m   1494\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;124;03m    matter.\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   1506\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Styler.apply` and `.applymap` are not compatible \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-unique index or columns.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1508\u001b[0m     )\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cn \u001b[38;5;129;01min\u001b[39;00m attrs\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m   1511\u001b[0m     j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(cn)\n",
      "\u001b[0;31mKeyError\u001b[0m: '`Styler.apply` and `.applymap` are not compatible with non-unique index or columns.'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff6ec19eef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "dfc = df.copy()\n",
    "dfc.columns = [x.split('_')[0] for x in dfc.columns]\n",
    "def get_dataset(x):\n",
    "    x = x.split('+')\n",
    "    if len(x) == 1:\n",
    "        return ''\n",
    "    else:\n",
    "        d = x[1]\n",
    "        d = d.replace('_', '')\n",
    "        return d\n",
    "dfc['Dataset'] = dfc['Model'].apply(get_dataset)\n",
    "order_list = ['',\n",
    " 'superni', 'cot', 'flanv2', 'dolly', 'oasst1',\n",
    " 'selfinstruct', 'unnaturalinstructions', 'stanfordalpaca', 'codealpaca', 'gpt4alpaca',\n",
    " 'baize', 'sharegpt', 'humanmix', 'h+gptmix']\n",
    "dfc['order'] = dfc['Dataset'].map({v: i for i, v in enumerate(order_list)})\n",
    "dfc = dfc.sort_values('order')\n",
    "dfc = dfc.drop(columns=['order', 'Dataset'])\n",
    "dfc = dfc.reset_index(drop=True)\n",
    "\n",
    "display(dfc[dfc['Model'].apply(lambda x: 'llama-7b' in x and ':' not in x)]\n",
    "        .style\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=1))\n",
    "\n",
    "\n",
    "display(dfc[dfc['Model'].apply(\n",
    "            lambda x: 'llama-7b' in x and (\n",
    "                ':' in x or any(c in x for c in ['dolly', 'oasst1', 'cot', 'flan'])\n",
    "                or 'humanmix' in x\n",
    "            )\n",
    "        )]\n",
    "        .style\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=1))\n",
    "\n",
    "display(dfc[dfc['Model'].apply(lambda x: 'llama2-7b' in x or 'llama-7b'==x)]\n",
    "        .style\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "00ba1a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MMLU/0-shot</th>\n",
       "      <th>GSM/CoT</th>\n",
       "      <th>BBH/Direct</th>\n",
       "      <th>Codex-Eval/Pass@1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama-7b</td>\n",
       "      <td>32.459764</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.970313</td>\n",
       "      <td>5.487805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama-7b+dolly</td>\n",
       "      <td>37.231164</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.603476</td>\n",
       "      <td>11.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama-7b+oasst1</td>\n",
       "      <td>34.147557</td>\n",
       "      <td>7.5</td>\n",
       "      <td>29.692361</td>\n",
       "      <td>2.439024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>llama-7b+dolly:oasst1</td>\n",
       "      <td>37.900584</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.150571</td>\n",
       "      <td>9.146341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  MMLU/0-shot  GSM/CoT  BBH/Direct  Codex-Eval/Pass@1\n",
       "0                llama-7b    32.459764     11.0   32.970313           5.487805\n",
       "4          llama-7b+dolly    37.231164     13.0   30.603476          11.585366\n",
       "5         llama-7b+oasst1    34.147557      7.5   29.692361           2.439024\n",
       "14  llama-7b+dolly:oasst1    37.900584      7.0   30.150571           9.146341"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0588857",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"dataset\": \"flan_v2\", \"id\": \"flan_v2_2\", \"messages\": [{\"role\": \"user\", \"content\": \"Tratatul de la Lisabona nu face inutil referire, pentru prima dat n istoria Uniunii Europene, la drepturile persoanelor care aparin acestor minoriti i la valorile proprii acestora.\\n\\nWhich language is this?\\n\"}, {\"role\": \"assistant\", \"content\": \"Romanian\"}]}\n",
    "{\"dataset\": \"flan_v2\", \"id\": \"flan_v2_2\", \"messages\": [{\"role\": \"user\", \"content\": \"Tratatul de la Lisabona nu face inutil referire, pentru prima dat\\u0103 \\u00een istoria Uniunii Europene, la drepturile persoanelor care apar\\u0163in acestor minorit\\u0103\\u0163i \\u015fi la valorile proprii acestora.\\n\\nWhich language is this?\\n\"}, {\"role\": \"assistant\", \"content\": \"Romanian\"}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7702c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.1f}'.format):\n",
    "    display(df[['Model']+[x for x in df.columns if 'chatfmt' in x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82eac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.3f}'.format):\n",
    "    display(df[[x for x in df.columns if 'chatfmt' not in x]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "models = []\n",
    "models += ['t5-small', 't5-base', 't5-large', 't5-3b', 't5-11b']\n",
    "models += ['huggyllama/llama-7b']\n",
    "save_dirs = [f'../results/baselines/{x}/eval/gsm/' for x in models]\n",
    "\n",
    "data = []\n",
    "for model, save_dir in zip(models, save_dirs):\n",
    "    logfile_path = glob.glob(os.path.join(save_dir, '*.out'))[0]\n",
    "    out = get_run_statistics(logfile_path)\n",
    "    with open(os.path.join(save_dir, 'metrics.json'), 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    data.append((model, out['cpu_time']/60/60, out['avg_mem'], out['max_mem'], metrics['exact_match']))\n",
    "    \n",
    "\n",
    "import pandas as pd\n",
    "columns = ['name', 'cpu_time (hr)', 'avg_mem', 'max_mem', 'exact_match']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
