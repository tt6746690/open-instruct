{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3da1794b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'x86_64', 'cluster': 'ccc', 'queue': 'alt_7d'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "import re\n",
    "from llm.submit import (\n",
    "    multiline_to_singleline,\n",
    "    submit_job_ccc,\n",
    "    submit_job_aimos,\n",
    "    submit_job,\n",
    "        get_run_statistics)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import datetime\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import base64\n",
    "string_to_alphanumeric = lambda s: base64.urlsafe_b64encode(s.encode('utf-8')).decode('utf-8')\n",
    "alphanumeric_to_string = lambda a: base64.urlsafe_b64decode(a).decode('utf-8')\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm, shell_scripts_template_lsf, get_host_info, move_lsf_job_summary_to_save_dir\n",
    "from note_pruning_analysis import open_instruct_dir\n",
    "import getpass\n",
    "\n",
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "info = get_host_info()\n",
    "info.update({'queue': queue})\n",
    "arch, cluster = info['arch'], info['cluster']\n",
    "print(info)\n",
    "\n",
    "os.environ['TORCHELASTIC_ERROR_FILE'] = os.path.join(os.getcwd(), 'torchelastic_error_file') \n",
    "\n",
    "## jobs submitted in notebook inherits env variables.\n",
    "cache_dir = os.path.normpath(os.path.join(os.getcwd(), '../../../../mitibm2023/cache')) \\\n",
    "    if arch == 'ppc64le' else '/dccstor/data-pruning/cache'\n",
    "os.environ['WANDB_DIR'] = cache_dir\n",
    "os.makedirs(os.environ['WANDB_DIR'], exist_ok=True, mode=0o777)\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_PROJECT'] = 'mitibm'\n",
    "##\n",
    "##\n",
    "\n",
    "shell_scripts_template = shell_scripts_template_slurm \\\n",
    "    if arch == 'ppc64le' else shell_scripts_template_lsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c421d1",
   "metadata": {},
   "source": [
    "# DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c09b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/oi2/llama-7b_sharegptv2_ep=2 using 6 GPUs, 1 batch size per GPU, 1 gradient accumulation steps, 30 effective batch size.\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp7pssto1b', 'job_id': 1354503}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2p8zx1bt', 'job_id': 1354504}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2_mpillk', 'job_id': 1354505}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm\n",
    "debug = False\n",
    "if debug:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'INFO'\n",
    "    os.environ['NCCL_DEBUG'] = 'INFO'\n",
    "else:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'WARNING'\n",
    "    os.environ['NCCL_DEBUG'] = ''\n",
    "num_cpus = 144 if arch == 'ppc64le' else 32\n",
    "cpu_mem =  650 if arch == 'ppc64le' else 64\n",
    "\n",
    "preprocessing_num_workers = 32\n",
    "report_to = 'wandb'\n",
    "mixed_precision = 'bf16' if arch == 'x86_64' else 'fp16'\n",
    "torch_dtype = 'bfloat16' if arch=='x86_64' else 'float32'\n",
    "gradient_checkpointing = True\n",
    "use_fast_tokenizer = True\n",
    "hf_models_dir = 'results/baselines/'\n",
    "resume_from_checkpoint = True # resume from latest checkpoint if exists, otherwise train from scratch\n",
    "num_train_epochs = 2\n",
    "checkpointing_steps = 300 # (50_000 / 32) * 2 / 6 ~= 500 (data size of 50k, bsz=32, ep=2, total save 6 times at most)\n",
    "max_train_steps = None\n",
    "subsample_inds_file_list = [None]\n",
    "dataloader_sampler = 'RandomSampler'\n",
    "overwrite_cache = True\n",
    "\n",
    "\n",
    "# #####\n",
    "# job_name = 'dpo1'\n",
    "\n",
    "# # model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-410m-deduped'; max_seq_length = 2048; abbr_model_name = 'pythia-410m'\n",
    "# # model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "\n",
    "# train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "\n",
    "\n",
    "# M = 60_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 20_000\n",
    "# M = 50_000; pacing_fn_list = [f'prune_size={M}_ep=5']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "#     (10_000, 10), # 1k\n",
    "#     (30_000, 3),  # 10k\n",
    "    (60_000, 3),  # 20k\n",
    "]]\n",
    "\n",
    "gen_output_md = 'llama7br512p4096'\n",
    "# gen_output_md = 'llama7b+sharegptv2ep2+r512p4096'\n",
    "# gen_output_model_name = 'all-mpnet-base-v2'\n",
    "\n",
    "scoring_fn_list = []\n",
    "scoring_fn_list += ['random_s=0']\n",
    "# scoring_fn_list += ['random_s=1']\n",
    "scoring_fn_list += [ \n",
    "    f'dppmap_k=vmf_gamma=1_kmd={gen_output_md}_kemb=grad+rp+loraB',\n",
    "    f'dppmap_k=rbf_gamma=1e-3_kmd={gen_output_md}_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1_kmd=mpnet_kemb=text+embedding',\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'dpo2_{dataset}:{abbr_model_name}'\n",
    "    \n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12\n",
    "# nodes = 2; num_gpus = 1; gpu_type = 'v100'; job_duration = 6; cpu_mem = 100; num_cpus = 32; max_train_steps = 5; checkpointing_steps = 2; report_to = 'tensorboard'\n",
    "    \n",
    "#####\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs = 1 # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "use_deepspeed = True\n",
    "deepspeed_config_file = 'ds_configs/stage3_no_offloading_accelerate.conf'\n",
    "\n",
    "per_device_train_batch_size = 1; total_batch_size = 32\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"{effective_batch_size} effective batch size.\")\n",
    "\n",
    "# reference: https://gist.github.com/pacman100/1cb1f17b2f1b3139a63b764263e70b25\n",
    "launcher = f\"\"\"accelerate launch \\\n",
    "    --mixed_precision {mixed_precision} \\\n",
    "    --num_machines {nodes} \\\n",
    "    --num_processes {num_gpus*nodes} \\\n",
    "    {'--use_deepspeed' if use_deepspeed else ''} \\\n",
    "    {'--deepspeed_config_file '+deepspeed_config_file if use_deepspeed else ''} \\\n",
    "    {'--main_process_ip $master_addr' if use_deepspeed else ''} \\\n",
    "    {'--main_process_port $master_port' if use_deepspeed else ''} \\\n",
    "    {'--machine_rank $SLURM_PROCID' if use_deepspeed else ''} \\\n",
    "    {'--rdzv_backend c10d' if use_deepspeed and nodes>1 else ''} \\\n",
    "    {'--deepspeed_multinode_launcher standard' if use_deepspeed and nodes>1 else ''} \\\n",
    "\"\"\"\n",
    "\n",
    "cmds = []\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    subsample_inds_file_list,\n",
    ")\n",
    "\n",
    "output_dirname_list = []\n",
    "for (subsample_inds_file,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{dataset}\"\n",
    "    if any(job_name == y for y in ['dpo1']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "\n",
    "    if subsample_inds_file:\n",
    "        assert(num_train_epochs==1)\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                s = f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "\n",
    "    if subsample_inds_file is not None:\n",
    "        assert(dataloader_sampler=='SequentialSampler')\n",
    "        assert(num_train_epochs==1)\n",
    "    else:\n",
    "        assert(dataloader_sampler=='RandomSampler')\n",
    "\n",
    "    output_dir = os.path.join('results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join('results', job_name), exist_ok=True)\n",
    "    wandb_run_name = output_dir.replace('results/', '')\n",
    "\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {f'cd .. && CUDA_VISIBLE_DEVICES={os.environ[\"CUDA_VISIBLE_DEVICES\"]} ' if test_run else ''}{launcher}\n",
    "        open_instruct/dpo_tune.py \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --tokenizer_name {model_name_or_path} \\\n",
    "        {'--use_slow_tokenizer' if not  use_fast_tokenizer else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        --train_file {train_file} \\\n",
    "        --max_seq_length {max_seq_length} \\\n",
    "        {'--subsample_inds_file '+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        --dataloader_sampler {dataloader_sampler} \\\n",
    "        --preprocessing_num_workers {preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size {per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
    "        --learning_rate 5e-7 \\\n",
    "        --lr_scheduler_type linear \\\n",
    "        --warmup_ratio 0.1 \\\n",
    "        --weight_decay 0. \\\n",
    "        --num_train_epochs {num_train_epochs} \\\n",
    "        --with_tracking \\\n",
    "        {'--report_to \"'+str(report_to)+'\"' if report_to else ''} \\\n",
    "        --checkpointing_steps {checkpointing_steps} \\\n",
    "        {'--max_train_steps '+str(max_train_steps) if max_train_steps else ''} \\\n",
    "        {'--resume_from_checkpoint' if resume_from_checkpoint else ''} \\\n",
    "        {'--low_cpu_mem_usage' if not use_deepspeed else ''} \\\n",
    "        {'--overwrite_cache' if overwrite_cache else ''} \\\n",
    "        --logging_steps 1 \\\n",
    "        --output_dir {output_dir}\n",
    "    \"\"\"\n",
    "    # if test_run:\n",
    "    #     print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    if test_run:\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64': # ccc\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "        queue=queue,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda1f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prune: {1k@10, 10k@3}, datasets={dolly, stanford_alpaca}, scoring={random, dppmapx2}\n",
    "# need to gen curriculum for 50k sft datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b79b9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_dpo.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce604bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=5\n",
      "+ cd ..\n",
      "+ CUDA_VISIBLE_DEVICES=2,5\n",
      "+ accelerate launch --mixed_precision fp16 --num_machines 1 --num_processes 2 --use_deepspeed --deepspeed_config_file ds_configs/stage3_no_offloading_accelerate.conf open_instruct/dpo_tune.py --model_name_or_path results/baselines/huggyllama/llama-7b --tokenizer_name results/baselines/huggyllama/llama-7b --gradient_checkpointing --train_file data/processed/ultrafeedback/ultrafeedback_data.jsonl --max_seq_length 2048 --preprocessing_num_workers 32 --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --learning_rate 5e-7 --lr_scheduler_type linear --warmup_ratio 0.1 --weight_decay 0. --num_train_epochs 2 --with_tracking --report_to tensorboard --checkpointing_steps 500 --logging_steps 1 --output_dir results/dpo1/jpt_llama-7b_ultrafeedback\n",
      "[2024-01-08 20:41:08,547] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "[2024-01-08 20:41:17,396] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-08 20:41:17,400] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:662:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,611] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 1\n",
      "Local process index: 1\n",
      "Device: cuda:1\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 251.17it/s]\n",
      "01/08/2024 20:41:25 - WARNING - datasets.builder - Found cached dataset json (/gpfs/u/scratch/PTFM/PTFMqngp/huggingface_cache/datasets/json/default-201ebfceee303348/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 252.78it/s]\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:26,493] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 6.74B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.74s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:16<00:00,  8.11s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:43,556] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 13.48B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.60s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "01/08/2024 20:42:20 - INFO - accelerate.accelerator - Updating DeepSpeed's gradient accumulation steps to 16 from 1.\n",
      "[2024-01-08 20:42:20,382] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.1+23a11a39, git-hash=23a11a39, git-branch=master\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 1\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "[2024-01-08 20:42:20,751] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n",
      "[2024-01-08 20:42:20,779] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\n",
      "[2024-01-08 20:42:20,891] [INFO] [utils.py:786:see_memory_usage] Stage 3 initialize beginning\n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 14.16 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.9 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:118:__init__] Reduce bucket size 16777216\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:119:__init__] Prefetch bucket size 15099494\n",
      "[2024-01-08 20:42:20,995] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 13.64 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n",
      "[2024-01-08 20:42:21,139] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.76 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:21,240] [INFO] [utils.py:786:see_memory_usage] Before creating fp16 partitions\n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.4 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:23,090] [INFO] [utils.py:786:see_memory_usage] After creating fp16 partitions: 4\n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.4 GB         CA 14.6 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.99 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,190] [INFO] [utils.py:786:see_memory_usage] Before creating fp32 partitions\n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.39 GB         CA 14.6 GB         Max_CA 15 GB \n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.81 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,742] [INFO] [utils.py:786:see_memory_usage] After creating fp32 partitions\n",
      "[2024-01-08 20:42:23,743] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 26.61 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,744] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 116.15 GB, percent = 16.7%\n",
      "[2024-01-08 20:42:23,836] [INFO] [utils.py:786:see_memory_usage] Before initializing optimizer states\n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 25.94 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 117.28 GB, percent = 16.8%\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 1; 31.75 GiB total capacity; 25.93 GiB already allocated; 3.34 GiB free; 27.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 0; 31.75 GiB total capacity; 25.94 GiB already allocated; 3.21 GiB free; 27.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 409110) of binary: /gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/python3.10\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 964, in launch_command\r\n",
      "    deepspeed_launcher(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 687, in deepspeed_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "open_instruct/dpo_tune.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 409111)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 409110)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_dpo.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c8b",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune_trainer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "19aebd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/baselines/huggyllama/llama-7b using 8 GPUs, 1 batch size per GPU, 16 gradient accumulation steps, Effective batch size 128\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_sharegpt50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 128,\n",
      "    \"cpu_mem\": 768,\n",
      "    \"num_gpus\": 8,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_sharegpt50k:llama-7b -mem 768g -cores 1x128+8 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=8 --rdzv_backend=c10d --master_port=0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/sharegpt/sharegpt50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=16 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=80000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/sharegpt50k/random_s=0/inds_prune_size=80000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=80000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=80000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1411460}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_sharegpt50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 128,\n",
      "    \"cpu_mem\": 768,\n",
      "    \"num_gpus\": 8,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_sharegpt50k:llama-7b -mem 768g -cores 1x128+8 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=8 --rdzv_backend=c10d --master_port=0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/sharegpt/sharegpt50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=16 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=80000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/sharegpt50k/dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB/inds_prune_size=80000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=80000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=80000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1411461}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "add_hardwarespec_to_dirname = False\n",
    "save_strategy = 'steps'\n",
    "save_steps = 200 if getpass.getuser() in ('PTFMqngp', 'wpq') else 1_000_000\n",
    "save_total_limit = 1\n",
    "preprocessing_num_workers = 32\n",
    "evaluation_strategy = 'no' # set do_eval=False\n",
    "eval_steps = save_steps\n",
    "report_to = 'tensorboard wandb'\n",
    "suffix = None\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0.03\n",
    "dataloader_sampler = None\n",
    "hf_models_dir = 'results/baselines/'\n",
    "subsample_inds_file_list = [None]\n",
    "max_train_samples_list = [None]\n",
    "num_train_epochs_list = [1]\n",
    "scoring_fn_and_pacing_fn = None\n",
    "\n",
    "\n",
    "# ########### sft baselines\n",
    "\n",
    "\n",
    "# job_name = 'oi2'; num_train_epochs_list = [3]\n",
    "# # model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "\n",
    "# # train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca'; \n",
    "# # train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# # train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2'; max_train_samples_list=[100_000]\n",
    "\n",
    "# ## 50k sft datasets\n",
    "# # train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# # train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# # train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "# train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "\n",
    "# # train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2'; max_train_samples_list=[100_000]\n",
    "# ###########\n",
    "\n",
    "\n",
    "############ pruning runs\n",
    "\n",
    "# model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048; gen_output_md = 'mistral7br512p4096'\n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048; gen_output_md = 'llama7br512p4096'\n",
    "\n",
    "\n",
    "# # 50k sft datasets\n",
    "# dataset = 'flan_v250k'; train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca50k'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# dataset = 'wizardlm50k'; train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "dataset = 'sharegpt50k'; train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "# dataset = 'ultrachat50k'; train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "\n",
    "# dataset = 'flan_v2'; train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca';\n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# dataset = 'wizardlmv2'; train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2';\n",
    "# dataset = 'sharegptv2'; train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2';\n",
    "# dataset = 'ultrachat200kv2'; train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2';\n",
    "\n",
    "\n",
    "# dataset = 'oasst1'; train_file = 'data/processed/oasst/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# dataset = 'open_orca_slim'; train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; \n",
    "# dataset = 'tulu_v2'; train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2';\n",
    "        \n",
    "# M = 80_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 40_000\n",
    "# M = 40_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 20_000\n",
    "# M = 30_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [\n",
    "    f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "#         (10_000, 10), # 1k\n",
    "#         (30_000, 3),  # 10k\n",
    "#         (60_000, 3),  # 20k\n",
    "        (80_000, 3),  # 40k\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "kmd = 'llama7br512p4096'\n",
    "scoring_fn_list = [\n",
    "    'random_s=0',\n",
    "#     'random_s=1',\n",
    "#     'log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n',\n",
    "#     'ifd_neg', 'log_pmi_neg',\n",
    "#     'numtoks_input_neg', 'numtoks_output_neg', 'numtoks_total_neg',\n",
    "#     f'dppmap_k=vmf_gamma=1_kmd=mpnet', #_kemb=text+embedding',\n",
    "    ##\n",
    "#     f'dppmap_k=rbf_gamma=1e-3_kmd={kmd}_kemb=text+embedding',\n",
    "    f'dppmap_k=vmf_gamma=1_kmd={kmd}_kemb=grad+rp+loraB',\n",
    "    # added baseline\n",
    "#     f'dppmap_k=vmf_gamma=10_kmd={kmd}_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1e-2_kmd={md}_kemb=grad+rp+loraB',\n",
    "]\n",
    "\n",
    "scoring_fn_list += [ # vary kernel embedding model \n",
    "#     f'dppmap_k=vmf_gamma=auto{subset_size}_kmd={kmd}_kemb=grad+rp+loraB'\n",
    "#     for kmd in ['llama7br256p4096', 'llama7br512p4096', 'pythia1br512p4096']\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'oi5_{dataset}:{abbr_model_name}'\n",
    "############ \n",
    "\n",
    "    \n",
    "# add_hardwarespec_to_dirname = True\n",
    "# job_name += '_debug' # wpq debug\n",
    "# max_train_samples_list=[128*2]\n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "debug_mode = test_run\n",
    "\n",
    "if arch == 'x86_64':\n",
    "    nodes = 1; num_gpus = 8; gpu_type = 'a100_80gb'; job_duration = 6\n",
    "    num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus); preprocessing_num_workers = 128 # tok takes quite a bit.\n",
    "    per_device_train_batch_size = 1\n",
    "    gradient_checkpointing = False\n",
    "    mixed_precision = 'bf16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = True \n",
    "    save_model_torch_dtype = 'bfloat16' # typically save fp32 weights, but for disk space sake, convert to bf16.\n",
    "else:\n",
    "    nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_checkpointing = True\n",
    "    mixed_precision = 'fp16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = False\n",
    "    save_model_torch_dtype = None\n",
    "\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs_list = [1] # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "overwrite_output_dir = True if test_run else False # always continue from ckpt if run from cluster.\n",
    "\n",
    "total_batch_size = 128\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "optimizer = 'adamw_hf'\n",
    "\n",
    "deepspeed = ''; fsdp = False if num_gpus == 1 else \"full_shard auto_wrap\" \n",
    "if 'gpt2' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPT2Block'\n",
    "elif 'llama' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'LlamaDecoderLayer'\n",
    "elif 'mpt' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MPTBlock'\n",
    "elif 'pythia' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPTNeoXLayer'        \n",
    "elif 'mistral' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MistralDecoderLayer'\n",
    "else: raise ValueError('Not sure how to set `fsdp_transformer_layer_cls_to_wrap`')\n",
    "    \n",
    "# deepspeed = './ds_configs/ds_zero3_cpu_offload.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/ds_zero3.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/stage3_no_offloading.conf'; fsdp = False # error with loading... something wrong with the config.\n",
    "# fsdp = False; deepspeed = False\n",
    "\n",
    "if fsdp and deepspeed:\n",
    "    raise ValueError('either fsdp or deepspeed, not both')\n",
    "\n",
    "use_lora = False\n",
    "lora_rank = 256 \n",
    "lora_alpha = lora_rank \n",
    "lora_dropout = 0.05\n",
    "if use_lora:\n",
    "    abbr_model_name += f'+lora(r={lora_rank},a={lora_alpha})'\n",
    "load_in_8bit = False\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"Effective batch size {effective_batch_size}\")\n",
    "\n",
    "\n",
    "if nodes == 1:\n",
    "    exe = 'python' if num_gpus==1 else \\\n",
    "        f\"torchrun --nnodes 1 --nproc_per_node={num_gpus} --rdzv_backend=c10d --master_port=0\" # assigns random port. https://github.com/pytorch/pytorch/issues/73320\n",
    "else:\n",
    "    exe = f\"torchrun --nnodes={nodes} --nproc_per_node={num_gpus} --rdzv-id=${'SLURM_JOB_ID' if arch == 'ppcle64' else 'LSB_JOBID'} --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT\"\n",
    "\n",
    "if test_run:\n",
    "    exe = f\"CUDA_VISIBLE_DEVICES={','.join(map(str, range(num_gpus)))} {exe}\"\n",
    "if test_run and debug_mode:\n",
    "    exe = 'TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO ' + exe\n",
    "    error_file = os.path.join(open_instruct_dir, 'scripts', 'error_file')\n",
    "    exe = f'TORCHELASTIC_ERROR_FILE={error_file} {exe}'\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "options_list = itertools.product(\n",
    "    num_train_epochs_list,\n",
    "    subsample_inds_file_list,\n",
    "    max_train_samples_list,\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "output_dirname_list = []\n",
    "for (num_train_epochs,\n",
    "     subsample_inds_file,\n",
    "     max_train_samples,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{abbr_train_file}\"\n",
    "    if max_train_samples:\n",
    "        output_dirname += f\":{int(max_train_samples/1000)}k\"\n",
    "            \n",
    "    if any(job_name == y for y in ['oi2']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "        \n",
    "    if subsample_inds_file:\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                return f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            else:\n",
    "                return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "            \n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "            \n",
    "    if add_hardwarespec_to_dirname:\n",
    "        output_dirname += \\\n",
    "            ('_fsdp='+fsdp.split(' ')[0] if fsdp else '')+\\\n",
    "            ('_deepspeed='+os.path.basename(deepspeed).split('.')[0] if deepspeed else '')+\\\n",
    "            ('_gradckpt='+str(gradient_checkpointing) if gradient_checkpointing else '')+\\\n",
    "            '_mbsz='+str(per_device_train_batch_size)+\\\n",
    "            ('_dtype='+torch_dtype if torch_dtype is not None else '')+\\\n",
    "            ('_mp='+str(mixed_precision) if mixed_precision else '_mp=none')+\\\n",
    "            '_seqlen='+str(max_seq_length)+\\\n",
    "            '_nodes='+str(nodes)+\\\n",
    "            '_ngpus='+str(num_gpus)+\\\n",
    "            ('_fa2' if use_flash_attn else '')\n",
    "    if suffix:\n",
    "        output_dirname += suffix\n",
    "    output_dir = os.path.join(open_instruct_dir, 'results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join(open_instruct_dir, 'results', job_name), exist_ok=True)\n",
    "    if arch == 'x86_64':\n",
    "        wandb_run_name = 'ccc'+output_dir[output_dir.find('results'):][7:] # e.g., ccc/oi2/run_name\n",
    "    else:\n",
    "        wandb_run_name = output_dir.replace('results/', '') # e.g., oi2/run_name\n",
    "    \n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {'cd .. && ' if test_run else ''}{exe}\n",
    "        open_instruct/finetune_trainer.py \\\n",
    "        --model_name_or_path={model_name_or_path} \\\n",
    "        --tokenizer_name={model_name_or_path} \\\n",
    "        {'--load_in_8bit' if load_in_8bit else ''} \\\n",
    "        --use_fast_tokenizer=True \\\n",
    "        --train_file={train_file} \\\n",
    "        --max_seq_length={max_seq_length} \\\n",
    "        {'--max_train_samples='+str(max_train_samples) if max_train_samples else ''} \\\n",
    "        {'--use_lora' if use_lora else ''} \\\n",
    "        {'--lora_rank='+str(lora_rank) if use_lora else ''} \\\n",
    "        {'--lora_alpha='+str(lora_alpha) if use_lora else ''} \\\n",
    "        {'--lora_dropout='+str(lora_dropout) if use_lora else ''} \\\n",
    "        --do_train \\\n",
    "        --preprocessing_num_workers={preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size={per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
    "        --learning_rate=2e-5 \\\n",
    "        --lr_scheduler_type={lr_scheduler_type} \\\n",
    "        --warmup_ratio={warmup_ratio} \\\n",
    "        --weight_decay=0. \\\n",
    "        --optim={optimizer} \\\n",
    "        --evaluation_strategy={evaluation_strategy} \\\n",
    "        {'--eval_steps='+str(eval_steps) if eval_steps else ''} \\\n",
    "        {'--report_to '+str(report_to) if report_to else ''} \\\n",
    "        --run_name {wandb_run_name} \\\n",
    "        --logging_strategy=steps \\\n",
    "        --logging_first_step \\\n",
    "        --logging_steps=1 \\\n",
    "        --save_strategy={save_strategy} \\\n",
    "        --save_steps={save_steps} \\\n",
    "        --save_total_limit={save_total_limit} \\\n",
    "        --num_train_epochs={num_train_epochs} \\\n",
    "        --ddp_timeout=7200 \\\n",
    "        {'--fsdp=\"'+fsdp+'\"' if fsdp else ''} \\\n",
    "        {'--fsdp_transformer_layer_cls_to_wrap=\"'+fsdp_transformer_layer_cls_to_wrap+'\"' \n",
    "            if fsdp else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        {'--torch_dtype='+str(torch_dtype) if torch_dtype else ''} \\\n",
    "        {'--save_model_torch_dtype='+str(save_model_torch_dtype) if save_model_torch_dtype else ''} \\\n",
    "        --dataloader_num_workers=8 \\\n",
    "        {f'--{mixed_precision}=True' if mixed_precision else ''} \\\n",
    "        {f'--tf32=True' if use_tf32 else ''} \\\n",
    "        {'--overwrite_output_dir' if overwrite_output_dir else ''} \\\n",
    "        {'--deepspeed='+deepspeed if deepspeed else ''} \\\n",
    "        {'--subsample_inds_file='+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        {'--dataloader_sampler '+str(dataloader_sampler) if dataloader_sampler else ''} \\\n",
    "        --use_flash_attn {'True' if use_flash_attn else 'False'} \\\n",
    "        --low_cpu_mem_usage \\\n",
    "        --overwrite_cache \\\n",
    "        --output_dir=\"{output_dir}\" \\\n",
    "    \"\"\" \n",
    "    #  --overwrite_cache   # if delete a dataset and need to refresh cache\n",
    "\n",
    "    if test_run:\n",
    "        print()\n",
    "        print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64':\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        queue=queue,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12fc2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_sft.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed0c2894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ cd ..\n",
      "+ TORCHELASTIC_ERROR_FILE=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/error_file\n",
      "+ TORCH_CPP_LOG_LEVEL=INFO\n",
      "+ NCCL_DEBUG=INFO\n",
      "+ LOGLEVEL=INFO\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/oasst1/oasst1_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=32 --per_device_train_batch_size=1 --gradient_accumulation_steps=128 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=200 --report_to tensorboard wandb --run_name /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=200 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --overwrite_output_dir --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl --dataloader_sampler SequentialSampler --use_flash_attn True --low_cpu_mem_usage --overwrite_cache --output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10\n",
      "[2024-01-19 02:04:37,834] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Saving args dict to /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10.args.json\n",
      "01/19/2024 02:04:39 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "01/19/2024 02:04:39 - INFO - __main__ - Training parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=8,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_sampler=SequentialSampler,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=7200,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=200.0,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=128,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10/runs/Jan19_02-04-39_cccxc552,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1.0,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard', 'wandb'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=True,\n",
      "save_steps=200,\n",
      "save_strategy=steps,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=True,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "Using custom data configuration default-b03eccd42e843020\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Using custom data configuration default-b03eccd42e843020\n",
      "Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "[INFO|configuration_utils.py:715] 2024-01-19 02:04:39,135 >> loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "[INFO|configuration_utils.py:777] 2024-01-19 02:04:39,136 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3118] 2024-01-19 02:04:39,229 >> loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1222] 2024-01-19 02:04:39,229 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[WARNING|modeling_utils.py:1304] 2024-01-19 02:04:39,230 >> You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:39,230 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.07it/s]\n",
      "[INFO|modeling_utils.py:3950] 2024-01-19 02:04:41,778 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:3958] 2024-01-19 02:04:41,778 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:749] 2024-01-19 02:04:41,781 >> loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:41,781 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "01/19/2024 02:04:41 - INFO - __main__ - [wpq] model.dtype=torch.bfloat16\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1648] 2024-01-19 02:04:41,845 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spawning 32 processes\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Spawning 32 processes\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 0/33717 [00:Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 22/33717 [00Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   1%| | 361/33717 [0Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):   3%| | 1001/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   5%| | 1719/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   7%| | 2251/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):  12%| | 4021/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  14%|▏| 4841/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  18%|▏| 5957/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32): 100%|█| 33717/33717 \n",
      "Concatenating 32 shards\n",
      "01/19/2024 02:04:55 - INFO - datasets.arrow_dataset - Concatenating 32 shards\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - __main__ - Subsample dataset according to indices: /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl\n",
      "01/19/2024 02:04:56 - INFO - __main__ - subsample_inds_file has 10000 indices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[wpq] Example 0 of train_dataset: \r\n",
      "{'dataset': 'oasst1', 'id': 'oasst1_20480', 'messages': [{'role': 'user', 'content': 'Cómo manejar un carro manual'}, {'role': 'assistant', 'content': 'Lo primero que tienes que hacer, si nunca has conducido un coche manual, es familiarizarte con el embrague y palanca de cambios. Si conduces habitualmente un coche automático, estarás acostumbrado a no utilizar para nada el pie izquierdo ni la palanca del cambio. Encontrarás tres pedales, siendo el embrague el que está situado a la izquierda y el que tendrás que pisar cada vez que cambies de marcha. Por otro lado, la palanca del cambio se ubica siempre en la consola central.\\n\\nPara arrancar un coche manual, es necesario seguir una serie de pasos que, al principio, pueden parecer muchos, pero que, con el tiempo, acabarás haciéndolos sin darte cuenta:\\n\\n1) Comprueba que la palanca del cambio está en punto muerto\\n2) Coloca el pie derecho en el pedal del freno\\n3) Arranca el motor\\n4) Pisa el embrague con el pie izquierdo\\n5) Coloca la palanca del cambio en la primera marcha, sin levantar el pedal del freno\\n6) Suelta el freno de mano\\n7) Suelta el pedal del freno\\nYa estás listo para iniciar la marcha, soltando suavemente el embrague, a medida que aceleras.\\n\\nUna vez que ya estás en marcha, debes hacer un uso correcto del cambio manual para cambiar las marchas de forma correcta. Un uso incorrecto de la caja de cambios manual puede repercutir negativamente en tu seguridad y también afectar gravemente al embrague y a la transmisión, lo que se traduce en serias averías de coste muy elevado. Para evitarlo, te explicamos cómo debes proceder:\\n\\nUna vez que hayas arrancado, pisa el acelerador muy lentamente. Notarás que el régimen del motor aumenta. En ese momento, comienza a soltar suavemente el pedal del embrague. Verás que el motor vuelve a bajar de vueltas. En ese momento, puedes presionar un poco más el acelerador y el coche comenzará a avanzar.\\n\\nAhora llega el momento de meter la segunda marcha. Dependiendo del tipo de coche y combustible, podrás circular a un régimen de giro más bajo o alto. El régimen de giro en coche de gasolina, por lo general, oscila entre loas 2.500 y 3.000 vueltas. Si el motor está sobrealimentado por turbo, te permitirá circular por debajo de ese rango, ya que algunos coches turbos modernos entregan la totalidad de su par motor, incluso por debajo de las 2.000 vueltas.\\n\\nUn coche con motor turbodiésel te permite circular a un régimen muy bajo, por debajo de las 2.000 vueltas, ya que la entrega de par se produce antes que en un motor de gasolina.\\n\\nCuando el coche alcance un régimen de vueltas apropiado, suelta el pedal del acelerador y vuelve a pisar el embrague. Coge la palanca del cambio y baja para meter segunda. Suelta el embrague y presiona nuevamente el acelerador. A partir de aquí, cada vez que quieras cambiar de marcha, deberás repetir el mismo proceso: soltar el acelerador, pisar embrague, meter la marcha, soltar embrague y volver a acelerar.\\n\\n¡Buen viaje!'}], 'input_ids': tensor([    1,   529, 29989,  1792, 29989, 29958,    13, 29907, 29980,  4346,\r\n",
      "          767, 29872,  4758,   443,  1559,   307, 12219,    13, 29966, 29989,\r\n",
      "          465, 22137, 29989, 29958,    13,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'labels': tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:593] 2024-01-19 02:04:57,333 >> Using auto half precision backend\n",
      "[INFO|trainer.py:738] 2024-01-19 02:04:57,494 >> The following columns in the training set don't have a corresponding argument in `LlamaForCausalLM.forward` and have been ignored: messages, id, dataset. If messages, id, dataset are not expected by `LlamaForCausalLM.forward`,  you can safely ignore this message.\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1723] 2024-01-19 02:04:57,514 >> ***** Running training *****\n",
      "[INFO|trainer.py:1724] 2024-01-19 02:04:57,514 >>   Num examples = 10,000\n",
      "[INFO|trainer.py:1725] 2024-01-19 02:04:57,514 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1726] 2024-01-19 02:04:57,514 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:1729] 2024-01-19 02:04:57,514 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1730] 2024-01-19 02:04:57,514 >>   Gradient Accumulation steps = 128\n",
      "[INFO|trainer.py:1731] 2024-01-19 02:04:57,514 >>   Total optimization steps = 78\n",
      "[INFO|trainer.py:1732] 2024-01-19 02:04:57,515 >>   Number of trainable parameters = 6,738,423,808\n",
      "[INFO|integration_utils.py:718] 2024-01-19 02:04:57,519 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "  0%|                                                    | 0/78 [00:00<?, ?it/s][WARNING|logging.py:314] 2024-01-19 02:05:01,563 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,569 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,572 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,576 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,577 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 1.6425, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}         \n",
      "{'loss': 1.7168, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.03}        \n",
      "  3%|█▏                                          | 2/78 [00:42<26:54, 21.24s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash gen_cmds_sft.sh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:177\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:646\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGCONT)\n\u001b[0;32m--> 646\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_sft.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831fe55",
   "metadata": {},
   "source": [
    "# eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "499d6f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('humaneval_chatfmt', 'results/baselines/huggyllama/llama-7b')\n",
      "#cmds:  1 \n",
      "\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from gen_cmds_utils import remove_all_symlinks, create_unique_symlinks, get_chat_formatting_function, get_resource_for_task, OPENAI_MODEL_LIST\n",
    "\n",
    "\n",
    "create_symlinks = False\n",
    "include_checkpoints = False\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "use_slow_tokenizer = True\n",
    "definitely_run_mtbench_on_non_alt7b_queue = False\n",
    "launch_one_job_per_model = True\n",
    "\n",
    "task_names = [\n",
    "    'mmlu_s=0',\n",
    "    'mmlu_s=5', \n",
    "    'gsm_s=8',\n",
    "    'gsm_s=8_cot',\n",
    "    'bbh_s=3',\n",
    "    'bbh_s=3_cot', # max_datapoints_per_task=40 -> 40min.\n",
    "    'humaneval',\n",
    "    'tydiqa_s=1_cb', # 3min\n",
    "    'tydiqa_s=1_gp',\n",
    "    # 'toxigen', # ~1.5hr\n",
    "#     'alpacafarm_ann=gpt35:turbo:1106',\n",
    "    # 'alpacafarm_ann=chatgpt', # ~$1 per eval.\n",
    "]\n",
    "task_names_chatfmt = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "\n",
    "task_names_mtbench = ['mtbench_ann=gpt:4:1106:preview_chatfmt'] # ann=gpt:4, ann=gpt:3.5:turbo:1106, gpt:4:1106:preview (gpt4-turbo)\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:3.5:turbo:1106_chatfmt'] # for debug sake, prefer gpt4\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:4_chatfmt']\n",
    "# task_names_alpacafarm = ['alpacafarm_ann=chatgpt_chatfmt']\n",
    "task_names_alpacafarm = ['alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt']\n",
    "task_names_chateval = task_names_mtbench + task_names_alpacafarm\n",
    "\n",
    "\n",
    "# # ## baselines eval \n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "# #     'huggyllama/llama-7b', \n",
    "# #     'mistralai/Mistral-7B-v0.1',\n",
    "# #     'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "# #     'NousResearch/Llama-2-7b-hf',\n",
    "# #     'NousResearch/Llama-2-7b-chat-hf',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-beta',\n",
    "# #     'HuggingFaceH4/zephyr-7b-alpha',\n",
    "#     'HuggingFaceH4/zephyr-7b-beta',\n",
    "# #     'codellama/CodeLlama-7b-hf',\n",
    "# #     'codellama/CodeLlama-7b-Python-hf',\n",
    "# #     'codellama/CodeLlama-7b-Instruct-hf',\n",
    "# ]]\n",
    "# # task_names = task_names + task_names_chatfmt\n",
    "# task_names = task_names_mtbench; definitely_run_mtbench_on_non_alt7b_queue = True\n",
    "\n",
    "# # oi5\n",
    "# exp_dir = 'results/oi2'\n",
    "# exp_dir = 'results/oi5_flan_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_dolly:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlm50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegpt50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b_debug'\n",
    "# exp_dir = 'results/oi5_stanford_alpaca:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlmv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegptv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_ultrachat200kv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_tulu_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_open_orca_slim:llama-7b'\n",
    "# exp_dir = 'results/dpo1'\n",
    "# exp_dir = 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2'\n",
    "exp_dirs = [\n",
    "    'results/baselines/huggyllama',\n",
    "#     'results/oi2',\n",
    "#     'results/oi5_dolly:llama-7b',\n",
    "#     'results/oi5_flan_v250k:llama-7b',\n",
    "#     'results/oi5_stanford_alpaca50k:llama-7b',\n",
    "#     'results/oi5_oasst2:llama-7b',\n",
    "#     'results/oi5_wizardlm50k:llama-7b',\n",
    "#     'results/oi5_sharegpt50k:llama-7b',\n",
    "#     'results/oi5_ultrachat50k:llama-7b',\n",
    "]\n",
    "\n",
    "subdir_filter_fn = lambda x: 'llama-7b' in x\n",
    "task_names = task_names + task_names_chatfmt;\n",
    "# task_names = task_names_alpacafarm; \n",
    "# task_names = task_names_mtbench; definitely_run_mtbench_on_non_alt7b_queue = False\n",
    "# task_names = task_names + task_names_chatfmt + task_names_mtbench\n",
    "# task_names = task_names\n",
    "# task_names = ['alpacafarm_ann=gpt35:turbo:1106_chatfmt']\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "num_gpus = 1\n",
    "if arch == 'x86_64': # ccc\n",
    "\n",
    "    if definitely_run_mtbench_on_non_alt7b_queue:\n",
    "        gpu_type = 'v100'; num_cpus = int(32/8*num_gpus); cpu_mem = int(240/8*num_gpus)\n",
    "    else:\n",
    "        gpu_type = 'a100_80gb'; num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus)\n",
    "    use_vllm = True; torch_dtype = 'bfloat16'\n",
    "else:\n",
    "    gpu_type = 'v100'\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    use_vllm = False; torch_dtype = 'float16'\n",
    "    \n",
    "    \n",
    "if len(subdir_path_list)==0:\n",
    "    subdir_path_list = []\n",
    "    for exp_dir in exp_dirs:\n",
    "        if create_symlinks:\n",
    "            remove_all_symlinks(exp_dir)\n",
    "        subdirs = list(os.listdir(exp_dir))\n",
    "        subdirs = filter(subdir_filter_fn, subdirs)\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(exp_dir, subdir)\n",
    "            if include_checkpoints:\n",
    "                subdir_path_list += glob.glob(os.path.join(subdir_path, 'checkpoint-*'))\n",
    "            if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "                continue\n",
    "            subdir_path_list.append(subdir_path)\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not os.path.islink(subdir_path) and \\\n",
    "                not os.path.isfile(os.path.join(subdir_path, 'eval', task_name, 'metrics.json')):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "                print((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "\n",
    "print('#cmds: ', len(list(task_name_and_model)), '\\n')\n",
    "\n",
    "if create_symlinks:\n",
    "    # create symlink for each directory.\n",
    "    symlink_path_dict = create_unique_symlinks(\n",
    "        list([x[1] for x in task_name_and_model]))\n",
    "    options_list = list(map(lambda x: (x[0], symlink_path_dict[x[1]]), task_name_and_model))\n",
    "else:\n",
    "    options_list = task_name_and_model\n",
    "    \n",
    "    \n",
    "dfo = pd.DataFrame(options_list, columns=['task_name', 'model_name_or_path'])\n",
    "model_and_task_list = dfo.groupby('model_name_or_path')['task_name'].agg(list).to_dict()\n",
    "\n",
    "\n",
    "info = {}  \n",
    "cmds = []\n",
    "for model_name_or_path, task_name_list in model_and_task_list.items():\n",
    "    num_tasks = len(task_name_list)\n",
    "    cmds_per_model = []\n",
    "    for i, task_name in enumerate(task_name_list):\n",
    "        queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else \\\n",
    "            ('alt_7d' if task_name.startswith('mtbench') else 'alt_1h')\n",
    "\n",
    "        use_chat_format = 'chatfmt' in task_name\n",
    "        chat_formatting_function = get_chat_formatting_function(model_name_or_path)\n",
    "\n",
    "        try:\n",
    "            with open(os.path.join(model_name_or_path, 'ft_args.json'), 'r') as f:\n",
    "                ft_args = json.load(f)\n",
    "            # note `model_name_or_path` could be anything, e.g., soft links with arbitrary names.\n",
    "            # but `ft_args_model_name_or_path` indicates the finetuned model name.\n",
    "            if 'model_args' in ft_args:\n",
    "                ft_args_model_name_or_path = ft_args['model_args']['model_name_or_path']\n",
    "            else:\n",
    "                ft_args_model_name_or_path = ft_args['model_name_or_path']\n",
    "        except:\n",
    "            ft_args_model_name_or_path = model_name_or_path\n",
    "\n",
    "        batch_size, job_duration = get_resource_for_task(\n",
    "            task_name, ft_args_model_name_or_path)\n",
    "\n",
    "        job_name = f'eval.{task_name}'\n",
    "        save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "\n",
    "        if task_name.startswith('mmlu'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 5)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.mmlu.run_eval \\\n",
    "                --data_dir data/eval/mmlu \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --ntrain {n_shot} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('gsm'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 8)\n",
    "            # open-instruct used 200 examples. use higher amount to get a more accurate number\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.gsm.run_eval \\\n",
    "                --data_dir data/eval/gsm/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_num_examples 500 \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('bbh'):\n",
    "            max_num_examples_per_task = 40\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 3)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.bbh.run_eval \\\n",
    "                --data_dir data/eval/bbh/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                --n_shot {n_shot} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--max_num_examples_per_task '+str(max_num_examples_per_task) if max_num_examples_per_task else ''} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('humaneval'):\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.codex_humaneval.run_eval \\\n",
    "                --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens 512 \\\n",
    "                --eval_pass_at_ks 1 \\\n",
    "                --unbiased_sampling_size_n 3 \\\n",
    "                --temperature 0.1 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('tydiqa'):\n",
    "            no_context = 'cb' in task_name\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot in [0,1])\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.tydiqa.run_eval \\\n",
    "                --data_dir data/eval/tydiqa \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_num_examples_per_lang 100 \\\n",
    "                --max_context_length 512 \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_context' if no_context else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('toxigen'):\n",
    "            # max_prompts_per_group=500 (out of 1000) is open-instruct default.\n",
    "            # eval batch size=1 much faster (llama-7b) not sure why.\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.toxigen.run_eval \\\n",
    "                --data_dir data/eval/toxigen \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size 1 \\\n",
    "                --max_prompts_per_group 200 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('alpacafarm'):\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            annotators_config = match.group(1)\n",
    "            annotators_config = annotators_config.replace(':', '_')\n",
    "            if not annotators_config in ['chatgpt', 'alpaca_eval_gpt4_0314', 'gpt35_turbo_1106', 'alpaca_eval_gpt4_turbo_fn']:\n",
    "                raise ValueError('Just support 2 annotators_config.')\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.alpaca_farm.run_eval \\\n",
    "                --reference_path alpaca_eval_data \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --max_new_tokens 2048 \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --annotators_config {annotators_config} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('mtbench'):\n",
    "            assert('chatfmt' in task_name)\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            judge_model = match.group(1).replace(':', '-')\n",
    "            if not judge_model in OPENAI_MODEL_LIST:\n",
    "                raise ValueError('fastchat does not support the judge model.')\n",
    "            os.makedirs(save_dir, exist_ok=True) # since not using python file, make the directory now.\n",
    "            fastchat_mtbench_data_dir = os.path.normpath(os.path.join(open_instruct_dir, '../FastChat/fastchat/llm_judge/data'))\n",
    "            question_file = os.path.join(fastchat_mtbench_data_dir, 'mt_bench/question.jsonl')\n",
    "            rating_file = os.path.join(save_dir, f'{judge_model}_single.jsonl')\n",
    "            question_begin, question_end = (0, 1) if False else (None, None)\n",
    "            model_id = os.path.basename(model_name_or_path) if 'results/baselines' in save_dir else 'tulu'\n",
    "            cmd = \"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_model_answer \\\n",
    "                    --model-path {model_name_or_path} \\\n",
    "                    --model-id {model_id} \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --question-file {question_file} \\\n",
    "                    {'--question-begin '+str(question_begin) if question_begin else ''} \\\n",
    "                    {'--question-end '+str(question_end) if question_end else ''} \\\n",
    "                    --max-new-token 2048 \\\n",
    "                    --answer-file {os.path.join(save_dir, 'model_answer.jsonl')} \\\n",
    "                    --dtype {torch_dtype} \\\n",
    "                && \\\n",
    "            \"\"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_judgment \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --judge-file {os.path.join(fastchat_mtbench_data_dir, 'judge_prompts.jsonl')} \\\n",
    "                    --judge-model {judge_model} \\\n",
    "                    --mode single \\\n",
    "                    --question-file {question_file} \\\n",
    "                    --answer-dir {save_dir} \\\n",
    "                    --ref-answer-dir {os.path.join(fastchat_mtbench_data_dir, 'mt_bench/reference_answer')} \\\n",
    "                    --output-file {rating_file} \\\n",
    "                && \\\n",
    "                python -m fastchat.llm_judge.show_result \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --input-file {rating_file} \\\n",
    "                    --mode single \\\n",
    "                    --save-to-json\n",
    "            \"\"\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'{task_name} not supported.')\n",
    "            \n",
    "        if task_name.startswith('alpacafarm') and (getpass.getuser() not in ('PTFMqngp', 'wpq')):\n",
    "            queue = 'alt_6h'\n",
    "\n",
    "        if test_run:\n",
    "            print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd.strip())]))\n",
    "\n",
    "        cmd = multiline_to_singleline(cmd)\n",
    "        cmds.append(cmd)\n",
    "        cmds_per_model.append(cmd)\n",
    "        \n",
    "        if launch_one_job_per_model:\n",
    "            shell_scripts = shell_scripts_template.format(\n",
    "                conda_env='open-instruct',\n",
    "                cwd=os.path.dirname(os.getcwd()),\n",
    "                cmd=cmd,\n",
    "                log_dir=os.getcwd(),\n",
    "                save_dir=save_dir,\n",
    "            )\n",
    "            if arch == 'x86_64': # ccc\n",
    "                shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "            out = submit_job(\n",
    "                shell_scripts, \n",
    "                job_name=job_name,\n",
    "                num_cpus=num_cpus,\n",
    "                cpu_mem=cpu_mem,\n",
    "                num_gpus=num_gpus,\n",
    "                gpu_type=gpu_type,\n",
    "                test_run=test_run,\n",
    "                job_duration=job_duration,\n",
    "                queue=queue,\n",
    "            )\n",
    "        else:\n",
    "            if i + 1 == num_tasks:\n",
    "                assert(len(cmds_per_model) == num_tasks)\n",
    "                cmd = ' && '.join(cmds_per_model)\n",
    "                if test_run:\n",
    "                    print(cmd)\n",
    "                shell_scripts = shell_scripts_template.format(\n",
    "                    conda_env='open-instruct',\n",
    "                    cwd=os.path.dirname(os.getcwd()),\n",
    "                    cmd=cmd,\n",
    "                    log_dir=os.getcwd(),\n",
    "                    save_dir=os.getcwd(), # just delete afterwards.\n",
    "                )\n",
    "                if arch == 'x86_64': # ccc\n",
    "                    shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "                out = submit_job(\n",
    "                    shell_scripts, \n",
    "                    job_name=f'eval.{os.path.basename(model_name_or_path)}',\n",
    "                    num_cpus=num_cpus,\n",
    "                    cpu_mem=cpu_mem,\n",
    "                    num_gpus=num_gpus,\n",
    "                    gpu_type=gpu_type,\n",
    "                    test_run=test_run,\n",
    "                    job_duration=6,\n",
    "                    queue=None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_6b',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ea7ac978",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_eval.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b3939309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10 --max_new_tokens 2048 --save_dir results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt --eval_batch_size 10 --annotators_config alpaca_eval_gpt4_turbo_fn --use_vllm --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype bfloat16\n",
      "[2024-01-21 21:11:36,716] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:loading data and model...\n",
      "INFO 01-21 21:11:39 llm_engine.py:73] Initializing an LLM engine with config: model='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10', tokenizer='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO 01-21 21:11:39 tokenizer.py:32] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "MegaBlocks not found. Please install it by `pip install megablocks`. Note that MegaBlocks depends on mosaicml-turbo, which only supports Python 3.10 for now.\n",
      "STK not found: please see https://github.com/stanford-futuredata/stk\n",
      "INFO 01-21 21:11:53 llm_engine.py:222] # GPU blocks: 7451, # CPU blocks: 512\n",
      "Processed prompts: 100%|██████████████████████| 805/805 [01:01<00:00, 13.00it/s]\n",
      "INFO:root:Evaluating the llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10-greedy-long outputs.\n",
      "INFO:root:Creating the annotator from `alpaca_eval_gpt4_turbo_fn`.\n",
      "WARNING:root:Saving_path is given but not 'auto', make sure that it's different for different seeds.\n",
      "Annotation chunk:   0%|                                   | 0/7 [00:00<?, ?it/s]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:02<06:07,  2.90s/it]\u001b[A\n",
      "prompt_batches:   2%|▋                          | 3/128 [00:03<01:52,  1.11it/s]\u001b[A\n",
      "prompt_batches:   3%|▊                          | 4/128 [00:06<03:40,  1.78s/it]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/128 [00:11<02:02,  1.04s/it]\u001b[A\n",
      "prompt_batches:   9%|██▍                       | 12/128 [00:14<02:13,  1.15s/it]\u001b[A\n",
      "prompt_batches:  14%|███▋                      | 18/128 [00:14<01:00,  1.81it/s]\u001b[A\n",
      "prompt_batches:  16%|████                      | 20/128 [00:15<01:02,  1.73it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:18<01:16,  1.38it/s]\u001b[A\n",
      "prompt_batches:  18%|████▋                     | 23/128 [00:18<01:08,  1.52it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:21<01:29,  1.16it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/128 [00:21<01:17,  1.31it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:23<01:36,  1.05it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:25<01:27,  1.12it/s]\u001b[A\n",
      "prompt_batches:  25%|██████▌                   | 32/128 [00:29<01:47,  1.12s/it]\u001b[A\n",
      "prompt_batches:  30%|███████▋                  | 38/128 [00:34<01:27,  1.03it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/128 [00:36<01:25,  1.03it/s]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:38<01:15,  1.12it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▎                | 46/128 [00:46<01:56,  1.42s/it]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:47<01:01,  1.21it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▌              | 57/128 [00:49<00:49,  1.43it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▊              | 58/128 [00:50<00:54,  1.29it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 59/128 [00:53<01:04,  1.08it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:54<00:48,  1.36it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▊             | 63/128 [00:55<00:52,  1.23it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 64/128 [00:56<00:56,  1.13it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 65/128 [00:56<00:47,  1.32it/s]\u001b[A\n",
      "prompt_batches:  53%|█████████████▊            | 68/128 [00:58<00:39,  1.53it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [01:11<02:16,  2.36s/it]\u001b[A\n",
      "prompt_batches:  66%|█████████████████▎        | 85/128 [01:11<00:25,  1.69it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:13<00:21,  1.79it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:19<00:37,  1.02it/s]\u001b[A\n",
      "prompt_batches:  78%|███████████████████▌     | 100/128 [01:21<00:16,  1.71it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:25<00:17,  1.45it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:28<00:12,  1.55it/s]\u001b[A\n",
      "prompt_batches:  86%|█████████████████████▍   | 110/128 [01:28<00:10,  1.76it/s]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▎  | 114/128 [01:29<00:06,  2.21it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:30<00:07,  1.70it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 117/128 [01:32<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 119/128 [01:33<00:05,  1.66it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▋ | 121/128 [01:35<00:04,  1.46it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▍| 125/128 [01:36<00:01,  2.04it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 126/128 [01:36<00:01,  1.92it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:37<00:00,  1.31it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 97.8 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  14%|███▊                       | 1/7 [01:37<09:47, 97.89s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:05<12:20,  5.83s/it]\u001b[A\n",
      "prompt_batches:   5%|█▍                         | 7/128 [00:15<03:59,  1.98s/it]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:19<02:12,  1.16s/it]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:19<01:50,  1.02it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:20<01:07,  1.59it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:22<01:22,  1.28it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:23<01:03,  1.63it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/128 [00:24<01:05,  1.56it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:24<00:58,  1.73it/s]\u001b[A\n",
      "prompt_batches:  22%|█████▋                    | 28/128 [00:25<01:02,  1.59it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/128 [00:26<01:06,  1.48it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:26<01:08,  1.42it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▎                   | 31/128 [00:29<01:45,  1.09s/it]\u001b[A\n",
      "prompt_batches:  27%|██████▉                   | 34/128 [00:29<00:52,  1.78it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 36/128 [00:29<00:42,  2.14it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/128 [00:30<00:38,  2.34it/s]\u001b[A\n",
      "prompt_batches:  30%|███████▋                  | 38/128 [00:38<03:11,  2.12s/it]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:40<01:28,  1.04s/it]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:41<00:43,  1.79it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:42<00:36,  2.06it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▏              | 55/128 [00:43<00:40,  1.81it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▌              | 57/128 [00:46<00:54,  1.31it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:47<00:33,  1.97it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 64/128 [00:55<01:15,  1.18s/it]\u001b[A\n",
      "prompt_batches:  56%|██████████████▋           | 72/128 [00:55<00:32,  1.71it/s]\u001b[A\n",
      "prompt_batches:  57%|██████████████▊           | 73/128 [00:56<00:32,  1.71it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 74/128 [01:05<01:23,  1.54s/it]\u001b[A\n",
      "prompt_batches:  67%|█████████████████▍        | 86/128 [01:06<00:24,  1.71it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▋        | 87/128 [01:07<00:23,  1.74it/s]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▉        | 88/128 [01:07<00:21,  1.82it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:08<00:22,  1.76it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:12<00:43,  1.13s/it]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 95/128 [01:13<00:19,  1.67it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:13<00:20,  1.57it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:15<00:25,  1.23it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:17<00:18,  1.44it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:19<00:19,  1.31it/s]\u001b[A\n",
      "prompt_batches:  84%|████████████████████▉    | 107/128 [01:20<00:10,  2.09it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:20<00:10,  1.95it/s]\u001b[A\n",
      "prompt_batches:  86%|█████████████████████▍   | 110/128 [01:22<00:10,  1.67it/s]\u001b[A\n",
      "prompt_batches:  88%|█████████████████████▉   | 112/128 [01:24<00:12,  1.33it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:25<00:07,  1.82it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▋  | 116/128 [01:27<00:08,  1.43it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 117/128 [01:27<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 119/128 [01:28<00:05,  1.71it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▍ | 120/128 [01:30<00:06,  1.17it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:32<00:05,  1.03it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:33<00:00,  1.37it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 93.5 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  29%|███████▋                   | 2/7 [03:11<07:56, 95.40s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:03<07:34,  3.58s/it]\u001b[A\n",
      "prompt_batches:   2%|▍                          | 2/128 [00:06<06:45,  3.22s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/128 [00:07<01:14,  1.60it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/128 [00:08<01:16,  1.54it/s]\u001b[A\n",
      "prompt_batches:   9%|██▏                       | 11/128 [00:09<01:20,  1.45it/s]\u001b[A\n",
      "prompt_batches:   9%|██▍                       | 12/128 [00:10<01:29,  1.30it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:10<01:00,  1.89it/s]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:12<01:07,  1.65it/s]\u001b[A\n",
      "prompt_batches:  13%|███▍                      | 17/128 [00:13<01:10,  1.57it/s]\u001b[A\n",
      "prompt_batches:  14%|███▋                      | 18/128 [00:14<01:21,  1.35it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:15<01:08,  1.57it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:16<01:17,  1.36it/s]\u001b[A\n",
      "prompt_batches:  18%|████▋                     | 23/128 [00:17<01:23,  1.26it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:18<01:07,  1.53it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:20<01:06,  1.51it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:23<01:22,  1.18it/s]\u001b[A\n",
      "prompt_batches:  26%|██████▋                   | 33/128 [00:23<00:54,  1.75it/s]\u001b[A\n",
      "prompt_batches:  27%|███████                   | 35/128 [00:24<00:48,  1.93it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 36/128 [00:25<00:53,  1.73it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/128 [00:25<00:50,  1.82it/s]\u001b[A\n",
      "prompt_batches:  30%|███████▉                  | 39/128 [00:27<00:51,  1.74it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/128 [00:29<01:28,  1.01s/it]\u001b[A\n",
      "prompt_batches:  34%|████████▉                 | 44/128 [00:30<00:42,  1.97it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████▏                | 45/128 [00:32<01:06,  1.24it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▎                | 46/128 [00:32<00:55,  1.47it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▊                | 48/128 [00:32<00:37,  2.12it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▉                | 49/128 [00:34<01:00,  1.30it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:34<00:39,  1.95it/s]\u001b[A\n",
      "prompt_batches:  42%|██████████▉               | 54/128 [00:38<01:00,  1.22it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▏              | 55/128 [00:39<00:57,  1.28it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▍              | 56/128 [00:40<01:05,  1.09it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 59/128 [00:43<01:06,  1.05it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:43<00:40,  1.65it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▊             | 63/128 [00:44<00:40,  1.59it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 65/128 [00:46<00:46,  1.37it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 66/128 [00:46<00:38,  1.61it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▌            | 67/128 [00:46<00:34,  1.78it/s]\u001b[A\n",
      "prompt_batches:  54%|██████████████            | 69/128 [00:47<00:27,  2.11it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [00:49<00:48,  1.18it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▍           | 71/128 [00:50<00:50,  1.13it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▏          | 75/128 [00:51<00:25,  2.05it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▍          | 76/128 [00:54<00:45,  1.14it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████          | 79/128 [00:54<00:28,  1.72it/s]\u001b[A\n",
      "prompt_batches:  63%|████████████████▍         | 81/128 [00:55<00:25,  1.81it/s]\u001b[A\n",
      "prompt_batches:  64%|████████████████▋         | 82/128 [00:57<00:32,  1.42it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 83/128 [01:00<00:55,  1.24s/it]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▉        | 88/128 [01:01<00:22,  1.76it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:02<00:24,  1.60it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 91/128 [01:05<00:33,  1.10it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▋       | 92/128 [01:06<00:35,  1.03it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:07<00:19,  1.63it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:07<00:16,  1.85it/s]\u001b[A\n",
      "prompt_batches:  77%|███████████████████▉      | 98/128 [01:08<00:18,  1.62it/s]\u001b[A\n",
      "prompt_batches:  77%|████████████████████      | 99/128 [01:10<00:25,  1.13it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:11<00:20,  1.29it/s]\u001b[A\n",
      "prompt_batches:  80%|███████████████████▉     | 102/128 [01:12<00:16,  1.55it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 104/128 [01:12<00:14,  1.70it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▌    | 105/128 [01:15<00:22,  1.02it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:16<00:13,  1.53it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▎   | 109/128 [01:17<00:14,  1.33it/s]\u001b[A\n",
      "prompt_batches:  87%|█████████████████████▋   | 111/128 [01:19<00:15,  1.10it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:23<00:11,  1.16it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▋  | 116/128 [01:28<00:18,  1.51s/it]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:29<00:04,  1.36it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:32<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 92.2 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation chunk:  43%|███████████▌               | 3/7 [04:43<06:15, 93.97s/it]INFO:root:Annotating 127 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 127 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/127 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/127 [00:03<07:05,  3.38s/it]\u001b[A\n",
      "prompt_batches:   2%|▍                          | 2/127 [00:04<03:43,  1.79s/it]\u001b[A\n",
      "prompt_batches:   5%|█▎                         | 6/127 [00:04<01:06,  1.81it/s]\u001b[A\n",
      "prompt_batches:   6%|█▍                         | 7/127 [00:06<01:38,  1.22it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/127 [00:06<00:56,  2.05it/s]\u001b[A\n",
      "prompt_batches:   9%|██▎                       | 11/127 [00:10<01:59,  1.03s/it]\u001b[A\n",
      "prompt_batches:  10%|██▋                       | 13/127 [00:11<01:41,  1.12it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/127 [00:12<01:31,  1.24it/s]\u001b[A\n",
      "prompt_batches:  13%|███▍                      | 17/127 [00:14<01:24,  1.30it/s]\u001b[A\n",
      "prompt_batches:  15%|███▉                      | 19/127 [00:15<01:13,  1.48it/s]\u001b[A\n",
      "prompt_batches:  17%|████▎                     | 21/127 [00:15<00:59,  1.77it/s]\u001b[A\n",
      "prompt_batches:  19%|████▉                     | 24/127 [00:18<01:04,  1.59it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/127 [00:19<01:00,  1.66it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/127 [00:23<01:36,  1.02it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/127 [00:24<00:41,  2.16it/s]\u001b[A\n",
      "prompt_batches:  31%|███████▉                  | 39/127 [00:26<00:49,  1.79it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/127 [00:26<00:44,  1.94it/s]\u001b[A\n",
      "prompt_batches:  33%|████████▌                 | 42/127 [00:27<00:39,  2.17it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████                 | 44/127 [00:27<00:32,  2.56it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████▏                | 45/127 [00:28<00:28,  2.84it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▍                | 46/127 [00:28<00:36,  2.23it/s]\u001b[A\n",
      "prompt_batches:  37%|█████████▌                | 47/127 [00:29<00:42,  1.86it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▊                | 48/127 [00:31<01:08,  1.15it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▋               | 52/127 [00:32<00:40,  1.87it/s]\u001b[A\n",
      "prompt_batches:  42%|██████████▊               | 53/127 [00:34<00:47,  1.56it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████               | 54/127 [00:35<00:52,  1.40it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▎              | 55/127 [00:35<00:53,  1.35it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▊              | 58/127 [00:37<00:41,  1.65it/s]\u001b[A\n",
      "prompt_batches:  46%|████████████              | 59/127 [00:37<00:40,  1.68it/s]\u001b[A\n",
      "prompt_batches:  47%|████████████▎             | 60/127 [00:38<00:36,  1.85it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▋             | 62/127 [00:39<00:43,  1.49it/s]\u001b[A\n",
      "prompt_batches:  50%|████████████▉             | 63/127 [00:42<01:10,  1.10s/it]\u001b[A\n",
      "prompt_batches:  54%|█████████████▉            | 68/127 [00:43<00:28,  2.08it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▎           | 70/127 [00:45<00:41,  1.36it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▌           | 71/127 [00:51<01:21,  1.45s/it]\u001b[A\n",
      "prompt_batches:  59%|███████████████▎          | 75/127 [00:52<00:45,  1.15it/s]\u001b[A\n",
      "prompt_batches:  61%|███████████████▊          | 77/127 [00:53<00:37,  1.32it/s]\u001b[A\n",
      "prompt_batches:  63%|████████████████▍         | 80/127 [00:53<00:24,  1.93it/s]\u001b[A\n",
      "prompt_batches:  64%|████████████████▌         | 81/127 [00:55<00:32,  1.43it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 82/127 [00:56<00:34,  1.32it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▉         | 83/127 [00:56<00:29,  1.50it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▌        | 86/127 [00:56<00:17,  2.41it/s]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▊        | 87/127 [00:58<00:25,  1.54it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 90/127 [01:00<00:22,  1.64it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▊       | 92/127 [01:00<00:18,  1.90it/s]\u001b[A\n",
      "prompt_batches:  73%|███████████████████       | 93/127 [01:01<00:17,  1.94it/s]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▏      | 94/127 [01:01<00:17,  1.93it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▍      | 95/127 [01:02<00:15,  2.08it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 96/127 [01:03<00:23,  1.33it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▊      | 97/127 [01:03<00:18,  1.59it/s]\u001b[A\n",
      "prompt_batches:  78%|████████████████████▎     | 99/127 [01:04<00:15,  1.78it/s]\u001b[A\n",
      "prompt_batches:  80%|███████████████████▉     | 101/127 [01:06<00:16,  1.61it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 102/127 [01:08<00:21,  1.16it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▍    | 104/127 [01:10<00:20,  1.10it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 107/127 [01:10<00:11,  1.69it/s]\u001b[A\n",
      "prompt_batches:  87%|█████████████████████▋   | 110/127 [01:16<00:19,  1.13s/it]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 116/127 [01:18<00:07,  1.39it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 121/127 [01:19<00:03,  1.93it/s]\u001b[A\n",
      "prompt_batches:  96%|████████████████████████ | 122/127 [01:21<00:03,  1.47it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 123/127 [01:24<00:03,  1.10it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 127/127 [01:27<00:00,  1.45it/s]\u001b[A\n",
      "INFO:root:Completed 127 examples in 87.5 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation chunk:  57%|███████████████▍           | 4/7 [06:11<04:34, 91.46s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:04<10:20,  4.88s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/128 [00:07<01:36,  1.25it/s]\u001b[A\n",
      "prompt_batches:   7%|█▉                         | 9/128 [00:07<01:24,  1.41it/s]\u001b[A\n",
      "prompt_batches:  10%|██▋                       | 13/128 [00:08<00:53,  2.16it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:10<01:12,  1.57it/s]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:10<01:02,  1.80it/s]\u001b[A\n",
      "prompt_batches:  15%|███▊                      | 19/128 [00:12<01:00,  1.79it/s]\u001b[A\n",
      "prompt_batches:  16%|████                      | 20/128 [00:13<01:08,  1.58it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:13<00:59,  1.79it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:14<00:59,  1.78it/s]\u001b[A\n",
      "prompt_batches:  19%|████▉                     | 24/128 [00:16<01:22,  1.25it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:17<00:54,  1.86it/s]\u001b[A\n",
      "prompt_batches:  22%|█████▋                    | 28/128 [00:18<00:55,  1.79it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/128 [00:18<00:57,  1.72it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:21<01:35,  1.02it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▎                   | 31/128 [00:26<03:17,  2.04s/it]\u001b[A\n",
      "prompt_batches:  32%|████████▎                 | 41/128 [00:29<01:00,  1.44it/s]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:30<00:55,  1.52it/s]\u001b[A\n",
      "prompt_batches:  37%|█████████▌                | 47/128 [00:32<00:51,  1.59it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:33<00:38,  1.99it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▌               | 52/128 [00:36<00:51,  1.48it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:36<00:52,  1.43it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▍              | 56/128 [00:37<00:38,  1.85it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▊              | 58/128 [00:38<00:31,  2.20it/s]\u001b[A\n",
      "prompt_batches:  47%|████████████▏             | 60/128 [00:45<01:26,  1.26s/it]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 66/128 [00:46<00:42,  1.47it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▌            | 67/128 [00:47<00:47,  1.27it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [00:49<00:39,  1.49it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▋           | 72/128 [00:49<00:32,  1.72it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 74/128 [00:52<00:40,  1.35it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▍          | 76/128 [00:52<00:33,  1.55it/s]\u001b[A\n",
      "prompt_batches:  60%|███████████████▋          | 77/128 [00:55<00:46,  1.10it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████          | 79/128 [00:57<00:45,  1.09it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████▎         | 80/128 [00:57<00:42,  1.14it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 83/128 [00:59<00:34,  1.31it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▋        | 87/128 [01:01<00:24,  1.65it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:02<00:21,  1.80it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:02<00:19,  1.98it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 91/128 [01:05<00:39,  1.07s/it]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 95/128 [01:07<00:22,  1.45it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:08<00:24,  1.31it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:09<00:24,  1.27it/s]\u001b[A\n",
      "prompt_batches:  77%|████████████████████      | 99/128 [01:10<00:19,  1.47it/s]\u001b[A\n",
      "prompt_batches:  78%|███████████████████▌     | 100/128 [01:11<00:20,  1.38it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:11<00:18,  1.43it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:12<00:16,  1.54it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 104/128 [01:13<00:17,  1.41it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▌    | 105/128 [01:15<00:22,  1.01it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:18<00:18,  1.07it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▎   | 109/128 [01:20<00:21,  1.12s/it]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▎  | 114/128 [01:22<00:10,  1.35it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:26<00:15,  1.21s/it]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:26<00:03,  1.94it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 124/128 [01:28<00:02,  1.81it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 126/128 [01:29<00:01,  1.73it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:32<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 92.2 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  71%|███████████████████▎       | 5/7 [07:43<03:03, 91.78s/it]INFO:root:Annotating 124 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 124 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/124 [00:04<08:16,  4.04s/it]\u001b[A\n",
      "prompt_batches:   5%|█▎                         | 6/124 [00:05<01:25,  1.38it/s]\u001b[A\n",
      "prompt_batches:   6%|█▌                         | 7/124 [00:07<01:57,  1.00s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/124 [00:07<01:38,  1.18it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/124 [00:08<01:05,  1.73it/s]\u001b[A\n",
      "prompt_batches:  10%|██▌                       | 12/124 [00:10<01:38,  1.14it/s]\u001b[A\n",
      "prompt_batches:  12%|███▏                      | 15/124 [00:11<00:59,  1.84it/s]\u001b[A\n",
      "prompt_batches:  14%|███▌                      | 17/124 [00:13<01:13,  1.46it/s]\u001b[A\n",
      "prompt_batches:  15%|███▉                      | 19/124 [00:15<01:21,  1.28it/s]\u001b[A\n",
      "prompt_batches:  19%|████▊                     | 23/124 [00:16<00:56,  1.80it/s]\u001b[A\n",
      "prompt_batches:  19%|█████                     | 24/124 [00:17<01:09,  1.44it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 26/124 [00:20<01:18,  1.25it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 29/124 [00:20<00:57,  1.66it/s]\u001b[A\n",
      "prompt_batches:  25%|██████▌                   | 31/124 [00:22<00:59,  1.57it/s]\u001b[A\n",
      "prompt_batches:  26%|██████▋                   | 32/124 [00:23<01:08,  1.35it/s]\u001b[A\n",
      "prompt_batches:  27%|██████▉                   | 33/124 [00:24<01:03,  1.44it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 35/124 [00:26<01:11,  1.24it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 36/124 [00:27<01:11,  1.24it/s]\u001b[A\n",
      "prompt_batches:  32%|████████▍                 | 40/124 [00:28<00:42,  1.99it/s]\u001b[A\n",
      "prompt_batches:  33%|████████▌                 | 41/124 [00:29<01:00,  1.38it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▍                | 45/124 [00:32<00:54,  1.46it/s]\u001b[A\n",
      "prompt_batches:  39%|██████████                | 48/124 [00:33<00:39,  1.92it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 49/124 [00:36<01:05,  1.14it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▎              | 54/124 [00:37<00:37,  1.89it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▋              | 56/124 [00:38<00:35,  1.89it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 57/124 [00:40<00:53,  1.25it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▎             | 59/124 [00:40<00:39,  1.63it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 62/124 [00:41<00:31,  1.97it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 63/124 [00:42<00:35,  1.71it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 64/124 [00:43<00:35,  1.71it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▋            | 65/124 [00:44<00:42,  1.38it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▎           | 68/124 [00:45<00:30,  1.85it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▍           | 69/124 [00:46<00:27,  1.97it/s]\u001b[A\n",
      "prompt_batches:  57%|██████████████▉           | 71/124 [00:47<00:31,  1.66it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 72/124 [00:47<00:27,  1.87it/s]\u001b[A\n",
      "prompt_batches:  60%|███████████████▋          | 75/124 [00:54<01:06,  1.35s/it]\u001b[A\n",
      "prompt_batches:  61%|███████████████▉          | 76/124 [00:55<00:54,  1.13s/it]\u001b[A\n",
      "prompt_batches:  65%|████████████████▉         | 81/124 [00:55<00:22,  1.89it/s]\u001b[A\n",
      "prompt_batches:  67%|█████████████████▍        | 83/124 [00:56<00:24,  1.66it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▌        | 84/124 [00:59<00:35,  1.12it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 88/124 [01:00<00:22,  1.61it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▋       | 89/124 [01:00<00:19,  1.77it/s]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 92/124 [01:02<00:18,  1.74it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 93/124 [01:04<00:22,  1.36it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 94/124 [01:05<00:26,  1.12it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████▊     | 99/124 [01:07<00:13,  1.87it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▏    | 100/124 [01:07<00:13,  1.82it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 101/124 [01:08<00:11,  1.95it/s]\u001b[A\n",
      "prompt_batches:  83%|████████████████████▊    | 103/124 [01:08<00:08,  2.44it/s]\u001b[A\n",
      "prompt_batches:  84%|████████████████████▉    | 104/124 [01:09<00:08,  2.41it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▏   | 105/124 [01:12<00:19,  1.02s/it]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▏  | 110/124 [01:16<00:12,  1.11it/s]\u001b[A\n",
      "prompt_batches:  92%|██████████████████████▉  | 114/124 [01:17<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 115/124 [01:17<00:05,  1.62it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▍ | 116/124 [01:19<00:05,  1.40it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▌ | 117/124 [01:19<00:05,  1.38it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 118/124 [01:20<00:04,  1.36it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 120/124 [01:21<00:02,  1.79it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 122/124 [01:23<00:01,  1.27it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 124/124 [01:24<00:00,  1.47it/s]\u001b[A\n",
      "INFO:root:Completed 124 examples in 84.6 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  86%|███████████████████████▏   | 6/7 [09:08<01:29, 89.38s/it]INFO:root:Annotating 37 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 37 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                    | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   3%|▊                           | 1/37 [00:03<02:03,  3.43s/it]\u001b[A\n",
      "prompt_batches:  16%|████▌                       | 6/37 [00:04<00:21,  1.45it/s]\u001b[A\n",
      "prompt_batches:  19%|█████▎                      | 7/37 [00:05<00:19,  1.55it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▊                     | 9/37 [00:07<00:22,  1.26it/s]\u001b[A\n",
      "prompt_batches:  30%|████████                   | 11/37 [00:08<00:17,  1.46it/s]\u001b[A\n",
      "prompt_batches:  32%|████████▊                  | 12/37 [00:11<00:27,  1.08s/it]\u001b[A\n",
      "prompt_batches:  41%|██████████▉                | 15/37 [00:12<00:15,  1.39it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▊             | 19/37 [00:12<00:07,  2.40it/s]\u001b[A\n",
      "prompt_batches:  54%|██████████████▌            | 20/37 [00:14<00:10,  1.61it/s]\u001b[A\n",
      "prompt_batches:  59%|████████████████           | 22/37 [00:15<00:08,  1.77it/s]\u001b[A\n",
      "prompt_batches:  65%|█████████████████▌         | 24/37 [00:17<00:10,  1.28it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▉        | 26/37 [00:20<00:10,  1.03it/s]\u001b[A\n",
      "prompt_batches:  84%|██████████████████████▌    | 31/37 [00:21<00:03,  1.68it/s]\u001b[A\n",
      "prompt_batches:  89%|████████████████████████   | 33/37 [00:24<00:02,  1.36it/s]\u001b[A\n",
      "prompt_batches: 100%|███████████████████████████| 37/37 [00:26<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 37 examples in 26.8 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk: 100%|███████████████████████████| 7/7 [09:35<00:00, 82.20s/it]\n",
      "/dccstor/data-pruning/wpq/github/mitibm2023/external/alpaca_eval/src/alpaca_eval/metrics.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  series_preferences[series_preferences == 0] = 1.5\n",
      "INFO:root:Saving all results to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Price (per-example / total) = 0.0191 / 15.29\n",
      "Time  (per-example / total) = 0.7184 / 574.70\n",
      "                                                                                                                           model  win_rate  standard_error  n_wins  n_wins_base  n_draws  n_total       mode  avg_length  avg_output_tok_length  price\n",
      "0  llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10-greedy-long     19.32            1.39     153          647        5      805  community         607                 172.59  15.29\n",
      "Map: 100%|███████████████████████████| 805/805 [00:00<00:00, 2978.74 examples/s]\n",
      "Filter (num_proc=4): 100%|███████████| 805/805 [00:00<00:00, 4447.74 examples/s]\n",
      "Creating json from Arrow format: 100%|███████████| 1/1 [00:00<00:00, 178.53ba/s]\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3 --max_new_tokens 2048 --save_dir results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt --eval_batch_size 10 --annotators_config alpaca_eval_gpt4_turbo_fn --use_vllm --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype bfloat16\n",
      "[2024-01-21 21:22:39,160] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:loading data and model...\n",
      "INFO 01-21 21:22:41 llm_engine.py:73] Initializing an LLM engine with config: model='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3', tokenizer='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO 01-21 21:22:41 tokenizer.py:32] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "MegaBlocks not found. Please install it by `pip install megablocks`. Note that MegaBlocks depends on mosaicml-turbo, which only supports Python 3.10 for now.\n",
      "STK not found: please see https://github.com/stanford-futuredata/stk\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/eval/alpaca_farm/run_eval.py\", line 160, in <module>\n",
      "    main(args)\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/eval/alpaca_farm/run_eval.py\", line 38, in main\n",
      "    model = vllm.LLM(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/entrypoints/llm.py\", line 93, in __init__\n",
      "    self.llm_engine = LLMEngine.from_engine_args(engine_args)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 246, in from_engine_args\n",
      "    engine = cls(*engine_configs,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 109, in __init__\n",
      "    self._init_workers(distributed_init_method)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 145, in _init_workers\n",
      "    self._run_workers(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 750, in _run_workers\n",
      "    self._run_workers_in_batch(workers, method, *args, **kwargs))\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 724, in _run_workers_in_batch\n",
      "    output = executor(*args, **kwargs)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/worker/worker.py\", line 72, in load_model\n",
      "    self.model_runner.load_model()\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 36, in load_model\n",
      "    self.model = get_model(self.model_config)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/model_loader.py\", line 124, in get_model\n",
      "    model.load_weights(model_config.model, model_config.download_dir,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 335, in load_weights\n",
      "    weight_loader(param, loaded_weight, shard_id)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 303, in weight_loader\n",
      "    param_data.copy_(loaded_weight)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_eval.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859d6d6",
   "metadata": {},
   "source": [
    "# Visualize Eval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1b033ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move ./1397708.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/bbh_s=3_cot_chatfmt/1397708.out.lsf\n",
      "Job ./1388986.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/mmlu_s=0_chatfmt\n",
      "Job ./1389187.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=0_chatfmt\n",
      "Move ./1397603.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3/eval/mmlu_s=5/1397603.out.lsf\n",
      "Move ./1397594.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=5_chatfmt/1397594.out.lsf\n",
      "Move ./1398282.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp/1398282.out.lsf\n",
      "Job ./1397600.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_cb_chatfmt\n",
      "Move ./1397652.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/bbh_s=3/1397652.out.lsf\n",
      "Job ./1394502.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=0\n",
      "Job ./1396996.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "./1394831.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1396995.out exited with error code. --save_dir=results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Move ./1398502.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/1398502.out.lsf\n",
      "Move ./1397699.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/bbh_s=3_cot/1397699.out.lsf\n",
      "Move ./1397702.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_gp/1397702.out.lsf\n",
      "Move ./1398283.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_cb/1398283.out.lsf\n",
      "Job ./1397663.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/humaneval_chatfmt\n",
      "Job ./1388963.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/bbh_s=3\n",
      "Job ./1389159.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp\n",
      "Job ./1397561.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/gsm_s=8_cot\n",
      "./1388921.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1388458.out exited with error code. --save_dir=results/oi2/llama-7b_sharegpt50k_ep=2/eval/mmlu_s=0\n",
      "./1388192.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1397164.out exited with error code. --save_dir=results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/mmlu_s=5\n",
      "Move ./1397678.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/humaneval_chatfmt/1397678.out.lsf\n",
      "Job ./1397644.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/bbh_s=3_cot_chatfmt\n",
      "Job ./1397642.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/gsm_s=8_cot_chatfmt\n",
      "./1394835.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1393671.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/humaneval\n",
      "Job ./1397168.out exited with error code. --save_dir=results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/bbh_s=3_cot\n",
      "Move ./1397655.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_cb/1397655.out.lsf\n",
      "Job ./1397003.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Job ./1396671.out exited with error code. --save_dir=results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/gsm_s=8_chatfmt\n",
      "./1388919.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1397615.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3/eval/bbh_s=3_chatfmt\n",
      "Job ./1388463.out exited with error code. --save_dir=results/oi2/llama-7b_sharegpt50k_ep=2/eval/mmlu_s=5_chatfmt\n",
      "Job ./1397072.out exited with error code. --save_dir=results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3/eval/humaneval\n",
      "Job ./1388948.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/tydiqa_s=1_cb\n",
      "./1396744.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1389161.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/mmlu_s=0_chatfmt\n",
      "Job ./1388971.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/gsm_s=8_cot_chatfmt\n",
      "Job ./1393673.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_gp\n",
      "Move ./1397671.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/tydiqa_s=1_gp/1397671.out.lsf\n",
      "Move ./1397689.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/bbh_s=3_chatfmt/1397689.out.lsf\n",
      "Job ./1394503.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/mmlu_s=0\n",
      "Move ./1397648.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/mmlu_s=0/1397648.out.lsf\n",
      "./1396354.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1396997.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Move ./1398299.out -> /dccstor/data-pruning/results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/1398299.out.lsf\n",
      "Job ./1396413.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp\n",
      "Job ./1393687.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/gsm_s=8_cot\n",
      "Move ./1397703.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/mmlu_s=0_chatfmt/1397703.out.lsf\n",
      "Job ./1397014.out exited with error code. --save_dir=results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "./1397179.out does not have `--save_dir` specified. Probably still running.\n",
      "Move ./1397700.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/humaneval/1397700.out.lsf\n",
      "Job ./1388947.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/humaneval\n",
      "Job ./1389097.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/gsm_s=8_cot\n",
      "Job ./1388991.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/bbh_s=3_cot_chatfmt\n",
      "Job ./1397093.out exited with error code. --save_dir=results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/gsm_s=8\n",
      "Job ./1388976.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp_chatfmt\n",
      "Job ./1396720.out exited with error code. --save_dir=results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3/eval/humaneval\n",
      "Job ./1388969.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=5_chatfmt\n",
      "Job ./1396437.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/bbh_s=3_cot_chatfmt\n",
      "Job ./1397004.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Job ./1393700.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_cb_chatfmt\n",
      "Job ./1389178.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/mmlu_s=5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/model_outputs/sft/llama-7b+lora:r=512:a=11585+proj=4096;/1389415.out.lsf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:816\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './1389415.out' -> '/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/model_outputs/sft/llama-7b+lora:r=512:a=11585+proj=4096;/1389415.out.lsf'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# if job successfully ran, lsf system will generate a summary in log_dir,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# call this function to move lsf summary to save_dir if job is successful.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmove_lsf_job_summary_to_save_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/wpq/github/mitibm2023/src/llm/submit.py:464\u001b[0m, in \u001b[0;36mmove_lsf_job_summary_to_save_dir\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m    462\u001b[0m     target_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, save_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(out_file)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.lsf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    463\u001b[0m     target_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(target_path)\n\u001b[0;32m--> 464\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMove \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExited with exit code\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m t:\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:836\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    834\u001b[0m         rmtree(src)\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 836\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    433\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 434\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m             \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[1;32m    259\u001b[0m                 \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/model_outputs/sft/llama-7b+lora:r=512:a=11585+proj=4096;/1389415.out.lsf'"
     ]
    }
   ],
   "source": [
    "# if job successfully ran, lsf system will generate a summary in log_dir,\n",
    "# call this function to move lsf summary to save_dir if job is successful.\n",
    "move_lsf_job_summary_to_save_dir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "4392e9ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_fmt=mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f2974 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_f2974_row0_col0, #T_f2974_row1_col0, #T_f2974_row2_col0, #T_f2974_row3_col0, #T_f2974_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f2974_row0_col1, #T_f2974_row1_col1, #T_f2974_row2_col1, #T_f2974_row3_col1, #T_f2974_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f2974_row0_col2, #T_f2974_row0_col3, #T_f2974_row0_col4, #T_f2974_row0_col6, #T_f2974_row0_col9, #T_f2974_row0_col10, #T_f2974_row0_col12, #T_f2974_row0_col16, #T_f2974_row0_col17, #T_f2974_row1_col10, #T_f2974_row1_col11, #T_f2974_row2_col13, #T_f2974_row2_col14, #T_f2974_row2_col15, #T_f2974_row4_col4, #T_f2974_row4_col5, #T_f2974_row4_col7, #T_f2974_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row0_col7, #T_f2974_row0_col8, #T_f2974_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row0_col11, #T_f2974_row0_col14, #T_f2974_row0_col15, #T_f2974_row1_col4, #T_f2974_row1_col8, #T_f2974_row1_col9, #T_f2974_row2_col10, #T_f2974_row3_col2, #T_f2974_row3_col5, #T_f2974_row3_col7, #T_f2974_row3_col12, #T_f2974_row3_col13, #T_f2974_row3_col17, #T_f2974_row4_col3, #T_f2974_row4_col6, #T_f2974_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row1_col2, #T_f2974_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row1_col14, #T_f2974_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row2_col3, #T_f2974_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2974_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2974_row4_col11, #T_f2974_row4_col12, #T_f2974_row4_col13, #T_f2974_row4_col14, #T_f2974_row4_col15, #T_f2974_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f2974\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f2974_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_f2974_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_f2974_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_f2974_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_f2974_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_f2974_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_f2974_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_f2974_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_f2974_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_f2974_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_f2974_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_f2974_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_f2974_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_f2974_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_f2974_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_f2974_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_f2974_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_f2974_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f2974_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f2974_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_f2974_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_f2974_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_f2974_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_f2974_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_f2974_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_f2974_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_f2974_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_f2974_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_f2974_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_f2974_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_f2974_row0_col11\" class=\"data row0 col11\" >11.1</td>\n",
       "      <td id=\"T_f2974_row0_col12\" class=\"data row0 col12\" >319.7</td>\n",
       "      <td id=\"T_f2974_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_f2974_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_f2974_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_f2974_row0_col16\" class=\"data row0 col16\" >44.9</td>\n",
       "      <td id=\"T_f2974_row0_col17\" class=\"data row0 col17\" >-25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2974_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f2974_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_f2974_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_f2974_row1_col2\" class=\"data row1 col2\" >34.7</td>\n",
       "      <td id=\"T_f2974_row1_col3\" class=\"data row1 col3\" >37.0</td>\n",
       "      <td id=\"T_f2974_row1_col4\" class=\"data row1 col4\" >3.4</td>\n",
       "      <td id=\"T_f2974_row1_col5\" class=\"data row1 col5\" >10.0</td>\n",
       "      <td id=\"T_f2974_row1_col6\" class=\"data row1 col6\" >30.9</td>\n",
       "      <td id=\"T_f2974_row1_col7\" class=\"data row1 col7\" >30.1</td>\n",
       "      <td id=\"T_f2974_row1_col8\" class=\"data row1 col8\" >6.4</td>\n",
       "      <td id=\"T_f2974_row1_col9\" class=\"data row1 col9\" >35.4</td>\n",
       "      <td id=\"T_f2974_row1_col10\" class=\"data row1 col10\" >10.4</td>\n",
       "      <td id=\"T_f2974_row1_col11\" class=\"data row1 col11\" >22.5</td>\n",
       "      <td id=\"T_f2974_row1_col12\" class=\"data row1 col12\" >298.0</td>\n",
       "      <td id=\"T_f2974_row1_col13\" class=\"data row1 col13\" >33.6</td>\n",
       "      <td id=\"T_f2974_row1_col14\" class=\"data row1 col14\" >18.1</td>\n",
       "      <td id=\"T_f2974_row1_col15\" class=\"data row1 col15\" >25.9</td>\n",
       "      <td id=\"T_f2974_row1_col16\" class=\"data row1 col16\" >42.6</td>\n",
       "      <td id=\"T_f2974_row1_col17\" class=\"data row1 col17\" >-36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2974_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f2974_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_f2974_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_f2974_row2_col2\" class=\"data row2 col2\" >33.3</td>\n",
       "      <td id=\"T_f2974_row2_col3\" class=\"data row2 col3\" >37.1</td>\n",
       "      <td id=\"T_f2974_row2_col4\" class=\"data row2 col4\" >4.6</td>\n",
       "      <td id=\"T_f2974_row2_col5\" class=\"data row2 col5\" >9.4</td>\n",
       "      <td id=\"T_f2974_row2_col6\" class=\"data row2 col6\" >31.4</td>\n",
       "      <td id=\"T_f2974_row2_col7\" class=\"data row2 col7\" >28.7</td>\n",
       "      <td id=\"T_f2974_row2_col8\" class=\"data row2 col8\" >7.3</td>\n",
       "      <td id=\"T_f2974_row2_col9\" class=\"data row2 col9\" >35.9</td>\n",
       "      <td id=\"T_f2974_row2_col10\" class=\"data row2 col10\" >7.5</td>\n",
       "      <td id=\"T_f2974_row2_col11\" class=\"data row2 col11\" >19.2</td>\n",
       "      <td id=\"T_f2974_row2_col12\" class=\"data row2 col12\" >172.6</td>\n",
       "      <td id=\"T_f2974_row2_col13\" class=\"data row2 col13\" >38.2</td>\n",
       "      <td id=\"T_f2974_row2_col14\" class=\"data row2 col14\" >20.0</td>\n",
       "      <td id=\"T_f2974_row2_col15\" class=\"data row2 col15\" >29.1</td>\n",
       "      <td id=\"T_f2974_row2_col16\" class=\"data row2 col16\" >33.9</td>\n",
       "      <td id=\"T_f2974_row2_col17\" class=\"data row2 col17\" >-38.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2974_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f2974_row3_col0\" class=\"data row3 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_f2974_row3_col1\" class=\"data row3 col1\" >10000</td>\n",
       "      <td id=\"T_f2974_row3_col2\" class=\"data row3 col2\" >30.9</td>\n",
       "      <td id=\"T_f2974_row3_col3\" class=\"data row3 col3\" >34.8</td>\n",
       "      <td id=\"T_f2974_row3_col4\" class=\"data row3 col4\" >5.0</td>\n",
       "      <td id=\"T_f2974_row3_col5\" class=\"data row3 col5\" >8.4</td>\n",
       "      <td id=\"T_f2974_row3_col6\" class=\"data row3 col6\" >32.9</td>\n",
       "      <td id=\"T_f2974_row3_col7\" class=\"data row3 col7\" >25.7</td>\n",
       "      <td id=\"T_f2974_row3_col8\" class=\"data row3 col8\" >8.0</td>\n",
       "      <td id=\"T_f2974_row3_col9\" class=\"data row3 col9\" >41.0</td>\n",
       "      <td id=\"T_f2974_row3_col10\" class=\"data row3 col10\" >7.9</td>\n",
       "      <td id=\"T_f2974_row3_col11\" class=\"data row3 col11\" >15.5</td>\n",
       "      <td id=\"T_f2974_row3_col12\" class=\"data row3 col12\" >101.5</td>\n",
       "      <td id=\"T_f2974_row3_col13\" class=\"data row3 col13\" >33.2</td>\n",
       "      <td id=\"T_f2974_row3_col14\" class=\"data row3 col14\" >17.7</td>\n",
       "      <td id=\"T_f2974_row3_col15\" class=\"data row3 col15\" >25.5</td>\n",
       "      <td id=\"T_f2974_row3_col16\" class=\"data row3 col16\" >27.7</td>\n",
       "      <td id=\"T_f2974_row3_col17\" class=\"data row3 col17\" >-39.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2974_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f2974_row4_col0\" class=\"data row4 col0\" >llama-7b</td>\n",
       "      <td id=\"T_f2974_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_f2974_row4_col2\" class=\"data row4 col2\" >31.8</td>\n",
       "      <td id=\"T_f2974_row4_col3\" class=\"data row4 col3\" >34.5</td>\n",
       "      <td id=\"T_f2974_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_f2974_row4_col5\" class=\"data row4 col5\" >11.8</td>\n",
       "      <td id=\"T_f2974_row4_col6\" class=\"data row4 col6\" >30.6</td>\n",
       "      <td id=\"T_f2974_row4_col7\" class=\"data row4 col7\" >32.7</td>\n",
       "      <td id=\"T_f2974_row4_col8\" class=\"data row4 col8\" >9.6</td>\n",
       "      <td id=\"T_f2974_row4_col9\" class=\"data row4 col9\" >38.4</td>\n",
       "      <td id=\"T_f2974_row4_col10\" class=\"data row4 col10\" >10.2</td>\n",
       "      <td id=\"T_f2974_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_f2974_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_f2974_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_f2974_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_f2974_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_f2974_row4_col16\" class=\"data row4 col16\" >22.8</td>\n",
       "      <td id=\"T_f2974_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf4d67d60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8e945 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_8e945_row0_col0, #T_8e945_row1_col0, #T_8e945_row2_col0, #T_8e945_row3_col0, #T_8e945_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8e945_row0_col1, #T_8e945_row1_col1, #T_8e945_row2_col1, #T_8e945_row3_col1, #T_8e945_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8e945_row0_col2, #T_8e945_row0_col9, #T_8e945_row0_col12, #T_8e945_row0_col16, #T_8e945_row0_col17, #T_8e945_row1_col10, #T_8e945_row1_col14, #T_8e945_row2_col3, #T_8e945_row2_col4, #T_8e945_row2_col7, #T_8e945_row2_col11, #T_8e945_row3_col6, #T_8e945_row3_col13, #T_8e945_row3_col15, #T_8e945_row4_col5, #T_8e945_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row0_col3, #T_8e945_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row0_col4, #T_8e945_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row0_col10, #T_8e945_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row0_col11, #T_8e945_row0_col13, #T_8e945_row0_col14, #T_8e945_row0_col15, #T_8e945_row1_col7, #T_8e945_row2_col8, #T_8e945_row2_col9, #T_8e945_row3_col4, #T_8e945_row3_col5, #T_8e945_row3_col7, #T_8e945_row3_col12, #T_8e945_row3_col17, #T_8e945_row4_col2, #T_8e945_row4_col3, #T_8e945_row4_col6, #T_8e945_row4_col10, #T_8e945_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row1_col8, #T_8e945_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row1_col13, #T_8e945_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e945_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e945_row4_col11, #T_8e945_row4_col12, #T_8e945_row4_col13, #T_8e945_row4_col14, #T_8e945_row4_col15, #T_8e945_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8e945\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8e945_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_8e945_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_8e945_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_8e945_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_8e945_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_8e945_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_8e945_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_8e945_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_8e945_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_8e945_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_8e945_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_8e945_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_8e945_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_8e945_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_8e945_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_8e945_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_8e945_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_8e945_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8e945_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8e945_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_8e945_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_8e945_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_8e945_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_8e945_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_8e945_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_8e945_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_8e945_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_8e945_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_8e945_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_8e945_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_8e945_row0_col11\" class=\"data row0 col11\" >11.1</td>\n",
       "      <td id=\"T_8e945_row0_col12\" class=\"data row0 col12\" >319.7</td>\n",
       "      <td id=\"T_8e945_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_8e945_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_8e945_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_8e945_row0_col16\" class=\"data row0 col16\" >44.9</td>\n",
       "      <td id=\"T_8e945_row0_col17\" class=\"data row0 col17\" >-25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e945_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8e945_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_8e945_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_8e945_row1_col2\" class=\"data row1 col2\" >36.1</td>\n",
       "      <td id=\"T_8e945_row1_col3\" class=\"data row1 col3\" >35.0</td>\n",
       "      <td id=\"T_8e945_row1_col4\" class=\"data row1 col4\" >4.4</td>\n",
       "      <td id=\"T_8e945_row1_col5\" class=\"data row1 col5\" >10.2</td>\n",
       "      <td id=\"T_8e945_row1_col6\" class=\"data row1 col6\" >31.2</td>\n",
       "      <td id=\"T_8e945_row1_col7\" class=\"data row1 col7\" >30.3</td>\n",
       "      <td id=\"T_8e945_row1_col8\" class=\"data row1 col8\" >8.6</td>\n",
       "      <td id=\"T_8e945_row1_col9\" class=\"data row1 col9\" >42.1</td>\n",
       "      <td id=\"T_8e945_row1_col10\" class=\"data row1 col10\" >11.6</td>\n",
       "      <td id=\"T_8e945_row1_col11\" class=\"data row1 col11\" >12.0</td>\n",
       "      <td id=\"T_8e945_row1_col12\" class=\"data row1 col12\" >277.6</td>\n",
       "      <td id=\"T_8e945_row1_col13\" class=\"data row1 col13\" >35.8</td>\n",
       "      <td id=\"T_8e945_row1_col14\" class=\"data row1 col14\" >19.7</td>\n",
       "      <td id=\"T_8e945_row1_col15\" class=\"data row1 col15\" >27.8</td>\n",
       "      <td id=\"T_8e945_row1_col16\" class=\"data row1 col16\" >41.6</td>\n",
       "      <td id=\"T_8e945_row1_col17\" class=\"data row1 col17\" >-31.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e945_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8e945_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_8e945_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_8e945_row2_col2\" class=\"data row2 col2\" >36.6</td>\n",
       "      <td id=\"T_8e945_row2_col3\" class=\"data row2 col3\" >39.2</td>\n",
       "      <td id=\"T_8e945_row2_col4\" class=\"data row2 col4\" >5.6</td>\n",
       "      <td id=\"T_8e945_row2_col5\" class=\"data row2 col5\" >9.6</td>\n",
       "      <td id=\"T_8e945_row2_col6\" class=\"data row2 col6\" >33.5</td>\n",
       "      <td id=\"T_8e945_row2_col7\" class=\"data row2 col7\" >33.1</td>\n",
       "      <td id=\"T_8e945_row2_col8\" class=\"data row2 col8\" >7.5</td>\n",
       "      <td id=\"T_8e945_row2_col9\" class=\"data row2 col9\" >37.7</td>\n",
       "      <td id=\"T_8e945_row2_col10\" class=\"data row2 col10\" >10.4</td>\n",
       "      <td id=\"T_8e945_row2_col11\" class=\"data row2 col11\" >17.6</td>\n",
       "      <td id=\"T_8e945_row2_col12\" class=\"data row2 col12\" >263.1</td>\n",
       "      <td id=\"T_8e945_row2_col13\" class=\"data row2 col13\" >38.5</td>\n",
       "      <td id=\"T_8e945_row2_col14\" class=\"data row2 col14\" >19.5</td>\n",
       "      <td id=\"T_8e945_row2_col15\" class=\"data row2 col15\" >29.1</td>\n",
       "      <td id=\"T_8e945_row2_col16\" class=\"data row2 col16\" >41.5</td>\n",
       "      <td id=\"T_8e945_row2_col17\" class=\"data row2 col17\" >-29.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e945_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8e945_row3_col0\" class=\"data row3 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_8e945_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_8e945_row3_col2\" class=\"data row3 col2\" >36.9</td>\n",
       "      <td id=\"T_8e945_row3_col3\" class=\"data row3 col3\" >37.1</td>\n",
       "      <td id=\"T_8e945_row3_col4\" class=\"data row3 col4\" >3.0</td>\n",
       "      <td id=\"T_8e945_row3_col5\" class=\"data row3 col5\" >9.4</td>\n",
       "      <td id=\"T_8e945_row3_col6\" class=\"data row3 col6\" >34.1</td>\n",
       "      <td id=\"T_8e945_row3_col7\" class=\"data row3 col7\" >30.3</td>\n",
       "      <td id=\"T_8e945_row3_col8\" class=\"data row3 col8\" >8.0</td>\n",
       "      <td id=\"T_8e945_row3_col9\" class=\"data row3 col9\" >40.9</td>\n",
       "      <td id=\"T_8e945_row3_col10\" class=\"data row3 col10\" >10.6</td>\n",
       "      <td id=\"T_8e945_row3_col11\" class=\"data row3 col11\" >13.9</td>\n",
       "      <td id=\"T_8e945_row3_col12\" class=\"data row3 col12\" >260.5</td>\n",
       "      <td id=\"T_8e945_row3_col13\" class=\"data row3 col13\" >40.1</td>\n",
       "      <td id=\"T_8e945_row3_col14\" class=\"data row3 col14\" >18.2</td>\n",
       "      <td id=\"T_8e945_row3_col15\" class=\"data row3 col15\" >29.4</td>\n",
       "      <td id=\"T_8e945_row3_col16\" class=\"data row3 col16\" >40.9</td>\n",
       "      <td id=\"T_8e945_row3_col17\" class=\"data row3 col17\" >-32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e945_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8e945_row4_col0\" class=\"data row4 col0\" >llama-7b</td>\n",
       "      <td id=\"T_8e945_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_8e945_row4_col2\" class=\"data row4 col2\" >31.8</td>\n",
       "      <td id=\"T_8e945_row4_col3\" class=\"data row4 col3\" >34.5</td>\n",
       "      <td id=\"T_8e945_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_8e945_row4_col5\" class=\"data row4 col5\" >11.8</td>\n",
       "      <td id=\"T_8e945_row4_col6\" class=\"data row4 col6\" >30.6</td>\n",
       "      <td id=\"T_8e945_row4_col7\" class=\"data row4 col7\" >32.7</td>\n",
       "      <td id=\"T_8e945_row4_col8\" class=\"data row4 col8\" >9.6</td>\n",
       "      <td id=\"T_8e945_row4_col9\" class=\"data row4 col9\" >38.4</td>\n",
       "      <td id=\"T_8e945_row4_col10\" class=\"data row4 col10\" >10.2</td>\n",
       "      <td id=\"T_8e945_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_8e945_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_8e945_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_8e945_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_8e945_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_8e945_row4_col16\" class=\"data row4 col16\" >22.8</td>\n",
       "      <td id=\"T_8e945_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfd21b010>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_23b73 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_23b73_row0_col0, #T_23b73_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_23b73_row0_col1, #T_23b73_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_23b73_row0_col2, #T_23b73_row0_col3, #T_23b73_row0_col6, #T_23b73_row0_col9, #T_23b73_row0_col10, #T_23b73_row0_col16, #T_23b73_row1_col5, #T_23b73_row1_col7, #T_23b73_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_23b73_row0_col4, #T_23b73_row0_col5, #T_23b73_row0_col7, #T_23b73_row0_col8, #T_23b73_row0_col11, #T_23b73_row0_col12, #T_23b73_row0_col13, #T_23b73_row0_col14, #T_23b73_row0_col15, #T_23b73_row0_col17, #T_23b73_row1_col2, #T_23b73_row1_col3, #T_23b73_row1_col4, #T_23b73_row1_col6, #T_23b73_row1_col9, #T_23b73_row1_col10, #T_23b73_row1_col11, #T_23b73_row1_col12, #T_23b73_row1_col13, #T_23b73_row1_col14, #T_23b73_row1_col15, #T_23b73_row1_col16, #T_23b73_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_23b73\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_23b73_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_23b73_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_23b73_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_23b73_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_23b73_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_23b73_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_23b73_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_23b73_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_23b73_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_23b73_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_23b73_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_23b73_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_23b73_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_23b73_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_23b73_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_23b73_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_23b73_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_23b73_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_23b73_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_23b73_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_23b73_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_23b73_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_23b73_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_23b73_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_23b73_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_23b73_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_23b73_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_23b73_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_23b73_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_23b73_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_23b73_row0_col11\" class=\"data row0 col11\" >11.1</td>\n",
       "      <td id=\"T_23b73_row0_col12\" class=\"data row0 col12\" >319.7</td>\n",
       "      <td id=\"T_23b73_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_23b73_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_23b73_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_23b73_row0_col16\" class=\"data row0 col16\" >44.9</td>\n",
       "      <td id=\"T_23b73_row0_col17\" class=\"data row0 col17\" >-25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b73_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_23b73_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_23b73_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_23b73_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_23b73_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_23b73_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_23b73_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_23b73_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_23b73_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_23b73_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_23b73_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_23b73_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_23b73_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_23b73_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_23b73_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_23b73_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_23b73_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_23b73_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_23b73_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf4d65540>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2358b td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_2358b_row0_col0, #T_2358b_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2358b_row0_col1, #T_2358b_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2358b_row0_col2, #T_2358b_row0_col3, #T_2358b_row0_col6, #T_2358b_row0_col9, #T_2358b_row0_col10, #T_2358b_row0_col16, #T_2358b_row1_col5, #T_2358b_row1_col7, #T_2358b_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2358b_row0_col4, #T_2358b_row0_col5, #T_2358b_row0_col7, #T_2358b_row0_col8, #T_2358b_row0_col11, #T_2358b_row0_col12, #T_2358b_row0_col13, #T_2358b_row0_col14, #T_2358b_row0_col15, #T_2358b_row0_col17, #T_2358b_row1_col2, #T_2358b_row1_col3, #T_2358b_row1_col4, #T_2358b_row1_col6, #T_2358b_row1_col9, #T_2358b_row1_col10, #T_2358b_row1_col11, #T_2358b_row1_col12, #T_2358b_row1_col13, #T_2358b_row1_col14, #T_2358b_row1_col15, #T_2358b_row1_col16, #T_2358b_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2358b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2358b_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_2358b_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_2358b_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_2358b_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_2358b_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_2358b_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_2358b_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_2358b_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_2358b_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_2358b_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_2358b_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_2358b_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_2358b_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_2358b_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_2358b_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_2358b_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_2358b_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_2358b_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2358b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2358b_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_2358b_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_2358b_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_2358b_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_2358b_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_2358b_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_2358b_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_2358b_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_2358b_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_2358b_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_2358b_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_2358b_row0_col11\" class=\"data row0 col11\" >11.1</td>\n",
       "      <td id=\"T_2358b_row0_col12\" class=\"data row0 col12\" >319.7</td>\n",
       "      <td id=\"T_2358b_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_2358b_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_2358b_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_2358b_row0_col16\" class=\"data row0 col16\" >44.9</td>\n",
       "      <td id=\"T_2358b_row0_col17\" class=\"data row0 col17\" >-25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2358b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2358b_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_2358b_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_2358b_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_2358b_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_2358b_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_2358b_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_2358b_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_2358b_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_2358b_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_2358b_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_2358b_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_2358b_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_2358b_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_2358b_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_2358b_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_2358b_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_2358b_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_2358b_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf6ca7940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e95be td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_e95be_row0_col0, #T_e95be_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e95be_row0_col1, #T_e95be_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e95be_row0_col2, #T_e95be_row0_col3, #T_e95be_row0_col6, #T_e95be_row0_col9, #T_e95be_row0_col10, #T_e95be_row0_col16, #T_e95be_row1_col5, #T_e95be_row1_col7, #T_e95be_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e95be_row0_col4, #T_e95be_row0_col5, #T_e95be_row0_col7, #T_e95be_row0_col8, #T_e95be_row0_col11, #T_e95be_row0_col12, #T_e95be_row0_col13, #T_e95be_row0_col14, #T_e95be_row0_col15, #T_e95be_row0_col17, #T_e95be_row1_col2, #T_e95be_row1_col3, #T_e95be_row1_col4, #T_e95be_row1_col6, #T_e95be_row1_col9, #T_e95be_row1_col10, #T_e95be_row1_col11, #T_e95be_row1_col12, #T_e95be_row1_col13, #T_e95be_row1_col14, #T_e95be_row1_col15, #T_e95be_row1_col16, #T_e95be_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e95be\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e95be_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_e95be_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_e95be_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_e95be_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_e95be_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_e95be_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_e95be_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_e95be_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_e95be_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_e95be_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_e95be_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_e95be_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_e95be_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_e95be_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_e95be_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_e95be_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_e95be_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_e95be_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e95be_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e95be_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_e95be_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_e95be_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_e95be_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_e95be_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_e95be_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_e95be_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_e95be_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_e95be_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_e95be_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_e95be_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_e95be_row0_col11\" class=\"data row0 col11\" >11.1</td>\n",
       "      <td id=\"T_e95be_row0_col12\" class=\"data row0 col12\" >319.7</td>\n",
       "      <td id=\"T_e95be_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_e95be_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_e95be_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_e95be_row0_col16\" class=\"data row0 col16\" >44.9</td>\n",
       "      <td id=\"T_e95be_row0_col17\" class=\"data row0 col17\" >-25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e95be_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e95be_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_e95be_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_e95be_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_e95be_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_e95be_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_e95be_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_e95be_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_e95be_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_e95be_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_e95be_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_e95be_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_e95be_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_e95be_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_e95be_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_e95be_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_e95be_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_e95be_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_e95be_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf36ed480>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_195d8 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_195d8_row0_col0, #T_195d8_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_195d8_row0_col1, #T_195d8_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_195d8_row0_col2, #T_195d8_row0_col3, #T_195d8_row0_col6, #T_195d8_row0_col7, #T_195d8_row0_col9, #T_195d8_row0_col16, #T_195d8_row1_col4, #T_195d8_row1_col8, #T_195d8_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_195d8_row0_col4, #T_195d8_row0_col5, #T_195d8_row0_col8, #T_195d8_row0_col10, #T_195d8_row0_col11, #T_195d8_row0_col12, #T_195d8_row1_col2, #T_195d8_row1_col3, #T_195d8_row1_col5, #T_195d8_row1_col6, #T_195d8_row1_col7, #T_195d8_row1_col9, #T_195d8_row1_col11, #T_195d8_row1_col12, #T_195d8_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_195d8_row0_col13, #T_195d8_row0_col14, #T_195d8_row0_col15, #T_195d8_row0_col17, #T_195d8_row1_col13, #T_195d8_row1_col14, #T_195d8_row1_col15, #T_195d8_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_195d8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_195d8_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_195d8_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_195d8_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_195d8_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_195d8_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_195d8_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_195d8_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_195d8_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_195d8_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_195d8_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_195d8_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_195d8_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_195d8_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_195d8_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_195d8_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_195d8_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_195d8_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_195d8_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_195d8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_195d8_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_195d8_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_195d8_row0_col2\" class=\"data row0 col2\" >44.3</td>\n",
       "      <td id=\"T_195d8_row0_col3\" class=\"data row0 col3\" >45.7</td>\n",
       "      <td id=\"T_195d8_row0_col4\" class=\"data row0 col4\" >3.0</td>\n",
       "      <td id=\"T_195d8_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_195d8_row0_col6\" class=\"data row0 col6\" >36.8</td>\n",
       "      <td id=\"T_195d8_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_195d8_row0_col8\" class=\"data row0 col8\" >8.4</td>\n",
       "      <td id=\"T_195d8_row0_col9\" class=\"data row0 col9\" >43.3</td>\n",
       "      <td id=\"T_195d8_row0_col10\" class=\"data row0 col10\" >8.5</td>\n",
       "      <td id=\"T_195d8_row0_col11\" class=\"data row0 col11\" >4.2</td>\n",
       "      <td id=\"T_195d8_row0_col12\" class=\"data row0 col12\" >101.4</td>\n",
       "      <td id=\"T_195d8_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_195d8_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_195d8_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_195d8_row0_col16\" class=\"data row0 col16\" >31.1</td>\n",
       "      <td id=\"T_195d8_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_195d8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_195d8_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_195d8_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_195d8_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_195d8_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_195d8_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_195d8_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_195d8_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_195d8_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_195d8_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_195d8_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_195d8_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_195d8_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_195d8_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_195d8_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_195d8_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_195d8_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_195d8_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_195d8_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfd21a470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a93b8 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_a93b8_row0_col0, #T_a93b8_row1_col0, #T_a93b8_row2_col0, #T_a93b8_row3_col0, #T_a93b8_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a93b8_row0_col1, #T_a93b8_row1_col1, #T_a93b8_row2_col1, #T_a93b8_row3_col1, #T_a93b8_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a93b8_row0_col2, #T_a93b8_row0_col3, #T_a93b8_row0_col6, #T_a93b8_row0_col7, #T_a93b8_row0_col9, #T_a93b8_row0_col16, #T_a93b8_row1_col5, #T_a93b8_row1_col10, #T_a93b8_row1_col11, #T_a93b8_row1_col12, #T_a93b8_row1_col15, #T_a93b8_row2_col4, #T_a93b8_row2_col14, #T_a93b8_row2_col17, #T_a93b8_row3_col13, #T_a93b8_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row0_col4, #T_a93b8_row0_col10, #T_a93b8_row0_col11, #T_a93b8_row1_col3, #T_a93b8_row2_col12, #T_a93b8_row2_col13, #T_a93b8_row2_col15, #T_a93b8_row3_col5, #T_a93b8_row3_col7, #T_a93b8_row3_col8, #T_a93b8_row3_col9, #T_a93b8_row3_col14, #T_a93b8_row3_col17, #T_a93b8_row4_col2, #T_a93b8_row4_col6, #T_a93b8_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row0_col5, #T_a93b8_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row0_col13, #T_a93b8_row0_col14, #T_a93b8_row0_col15, #T_a93b8_row0_col17, #T_a93b8_row4_col11, #T_a93b8_row4_col12, #T_a93b8_row4_col13, #T_a93b8_row4_col14, #T_a93b8_row4_col15, #T_a93b8_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row1_col9, #T_a93b8_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a93b8_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a93b8_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a93b8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a93b8_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_a93b8_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_a93b8_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_a93b8_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_a93b8_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_a93b8_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_a93b8_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_a93b8_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_a93b8_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_a93b8_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_a93b8_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_a93b8_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_a93b8_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_a93b8_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_a93b8_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_a93b8_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_a93b8_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_a93b8_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a93b8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a93b8_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_a93b8_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_a93b8_row0_col2\" class=\"data row0 col2\" >44.3</td>\n",
       "      <td id=\"T_a93b8_row0_col3\" class=\"data row0 col3\" >45.7</td>\n",
       "      <td id=\"T_a93b8_row0_col4\" class=\"data row0 col4\" >3.0</td>\n",
       "      <td id=\"T_a93b8_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_a93b8_row0_col6\" class=\"data row0 col6\" >36.8</td>\n",
       "      <td id=\"T_a93b8_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_a93b8_row0_col8\" class=\"data row0 col8\" >8.4</td>\n",
       "      <td id=\"T_a93b8_row0_col9\" class=\"data row0 col9\" >43.3</td>\n",
       "      <td id=\"T_a93b8_row0_col10\" class=\"data row0 col10\" >8.5</td>\n",
       "      <td id=\"T_a93b8_row0_col11\" class=\"data row0 col11\" >4.2</td>\n",
       "      <td id=\"T_a93b8_row0_col12\" class=\"data row0 col12\" >101.4</td>\n",
       "      <td id=\"T_a93b8_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_a93b8_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_a93b8_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_a93b8_row0_col16\" class=\"data row0 col16\" >31.1</td>\n",
       "      <td id=\"T_a93b8_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a93b8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a93b8_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_a93b8_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_a93b8_row1_col2\" class=\"data row1 col2\" >34.9</td>\n",
       "      <td id=\"T_a93b8_row1_col3\" class=\"data row1 col3\" >34.1</td>\n",
       "      <td id=\"T_a93b8_row1_col4\" class=\"data row1 col4\" >5.0</td>\n",
       "      <td id=\"T_a93b8_row1_col5\" class=\"data row1 col5\" >15.4</td>\n",
       "      <td id=\"T_a93b8_row1_col6\" class=\"data row1 col6\" >31.7</td>\n",
       "      <td id=\"T_a93b8_row1_col7\" class=\"data row1 col7\" >34.0</td>\n",
       "      <td id=\"T_a93b8_row1_col8\" class=\"data row1 col8\" >8.9</td>\n",
       "      <td id=\"T_a93b8_row1_col9\" class=\"data row1 col9\" >42.2</td>\n",
       "      <td id=\"T_a93b8_row1_col10\" class=\"data row1 col10\" >10.6</td>\n",
       "      <td id=\"T_a93b8_row1_col11\" class=\"data row1 col11\" >7.8</td>\n",
       "      <td id=\"T_a93b8_row1_col12\" class=\"data row1 col12\" >140.7</td>\n",
       "      <td id=\"T_a93b8_row1_col13\" class=\"data row1 col13\" >24.6</td>\n",
       "      <td id=\"T_a93b8_row1_col14\" class=\"data row1 col14\" >18.0</td>\n",
       "      <td id=\"T_a93b8_row1_col15\" class=\"data row1 col15\" >21.3</td>\n",
       "      <td id=\"T_a93b8_row1_col16\" class=\"data row1 col16\" >30.7</td>\n",
       "      <td id=\"T_a93b8_row1_col17\" class=\"data row1 col17\" >-31.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a93b8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a93b8_row2_col0\" class=\"data row2 col0\" >llama-7b_flan_v250k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_a93b8_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_a93b8_row2_col2\" class=\"data row2 col2\" >42.0</td>\n",
       "      <td id=\"T_a93b8_row2_col3\" class=\"data row2 col3\" >42.2</td>\n",
       "      <td id=\"T_a93b8_row2_col4\" class=\"data row2 col4\" >5.6</td>\n",
       "      <td id=\"T_a93b8_row2_col5\" class=\"data row2 col5\" >12.0</td>\n",
       "      <td id=\"T_a93b8_row2_col6\" class=\"data row2 col6\" >33.9</td>\n",
       "      <td id=\"T_a93b8_row2_col7\" class=\"data row2 col7\" >33.3</td>\n",
       "      <td id=\"T_a93b8_row2_col8\" class=\"data row2 col8\" >8.1</td>\n",
       "      <td id=\"T_a93b8_row2_col9\" class=\"data row2 col9\" >38.6</td>\n",
       "      <td id=\"T_a93b8_row2_col10\" class=\"data row2 col10\" >9.1</td>\n",
       "      <td id=\"T_a93b8_row2_col11\" class=\"data row2 col11\" >5.1</td>\n",
       "      <td id=\"T_a93b8_row2_col12\" class=\"data row2 col12\" >85.9</td>\n",
       "      <td id=\"T_a93b8_row2_col13\" class=\"data row2 col13\" >23.5</td>\n",
       "      <td id=\"T_a93b8_row2_col14\" class=\"data row2 col14\" >18.4</td>\n",
       "      <td id=\"T_a93b8_row2_col15\" class=\"data row2 col15\" >20.9</td>\n",
       "      <td id=\"T_a93b8_row2_col16\" class=\"data row2 col16\" >27.1</td>\n",
       "      <td id=\"T_a93b8_row2_col17\" class=\"data row2 col17\" >-29.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a93b8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a93b8_row3_col0\" class=\"data row3 col0\" >llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_a93b8_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_a93b8_row3_col2\" class=\"data row3 col2\" >41.6</td>\n",
       "      <td id=\"T_a93b8_row3_col3\" class=\"data row3 col3\" >40.0</td>\n",
       "      <td id=\"T_a93b8_row3_col4\" class=\"data row3 col4\" >3.4</td>\n",
       "      <td id=\"T_a93b8_row3_col5\" class=\"data row3 col5\" >10.8</td>\n",
       "      <td id=\"T_a93b8_row3_col6\" class=\"data row3 col6\" >36.2</td>\n",
       "      <td id=\"T_a93b8_row3_col7\" class=\"data row3 col7\" >32.4</td>\n",
       "      <td id=\"T_a93b8_row3_col8\" class=\"data row3 col8\" >7.4</td>\n",
       "      <td id=\"T_a93b8_row3_col9\" class=\"data row3 col9\" >37.3</td>\n",
       "      <td id=\"T_a93b8_row3_col10\" class=\"data row3 col10\" >8.9</td>\n",
       "      <td id=\"T_a93b8_row3_col11\" class=\"data row3 col11\" >4.3</td>\n",
       "      <td id=\"T_a93b8_row3_col12\" class=\"data row3 col12\" >90.2</td>\n",
       "      <td id=\"T_a93b8_row3_col13\" class=\"data row3 col13\" >25.9</td>\n",
       "      <td id=\"T_a93b8_row3_col14\" class=\"data row3 col14\" >16.2</td>\n",
       "      <td id=\"T_a93b8_row3_col15\" class=\"data row3 col15\" >21.1</td>\n",
       "      <td id=\"T_a93b8_row3_col16\" class=\"data row3 col16\" >26.8</td>\n",
       "      <td id=\"T_a93b8_row3_col17\" class=\"data row3 col17\" >-35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a93b8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a93b8_row4_col0\" class=\"data row4 col0\" >llama-7b</td>\n",
       "      <td id=\"T_a93b8_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_a93b8_row4_col2\" class=\"data row4 col2\" >31.8</td>\n",
       "      <td id=\"T_a93b8_row4_col3\" class=\"data row4 col3\" >34.5</td>\n",
       "      <td id=\"T_a93b8_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_a93b8_row4_col5\" class=\"data row4 col5\" >11.8</td>\n",
       "      <td id=\"T_a93b8_row4_col6\" class=\"data row4 col6\" >30.6</td>\n",
       "      <td id=\"T_a93b8_row4_col7\" class=\"data row4 col7\" >32.7</td>\n",
       "      <td id=\"T_a93b8_row4_col8\" class=\"data row4 col8\" >9.6</td>\n",
       "      <td id=\"T_a93b8_row4_col9\" class=\"data row4 col9\" >38.4</td>\n",
       "      <td id=\"T_a93b8_row4_col10\" class=\"data row4 col10\" >10.2</td>\n",
       "      <td id=\"T_a93b8_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_a93b8_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_a93b8_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_a93b8_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_a93b8_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_a93b8_row4_col16\" class=\"data row4 col16\" >22.8</td>\n",
       "      <td id=\"T_a93b8_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf434fb80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8df1c td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_8df1c_row0_col0, #T_8df1c_row1_col0, #T_8df1c_row2_col0, #T_8df1c_row3_col0, #T_8df1c_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8df1c_row0_col1, #T_8df1c_row1_col1, #T_8df1c_row2_col1, #T_8df1c_row3_col1, #T_8df1c_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8df1c_row0_col2, #T_8df1c_row0_col3, #T_8df1c_row0_col6, #T_8df1c_row0_col9, #T_8df1c_row0_col16, #T_8df1c_row1_col7, #T_8df1c_row1_col11, #T_8df1c_row1_col12, #T_8df1c_row1_col13, #T_8df1c_row1_col15, #T_8df1c_row2_col2, #T_8df1c_row2_col5, #T_8df1c_row2_col14, #T_8df1c_row2_col17, #T_8df1c_row4_col4, #T_8df1c_row4_col8, #T_8df1c_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row0_col4, #T_8df1c_row0_col5, #T_8df1c_row0_col10, #T_8df1c_row0_col11, #T_8df1c_row0_col12, #T_8df1c_row1_col8, #T_8df1c_row1_col17, #T_8df1c_row2_col13, #T_8df1c_row3_col7, #T_8df1c_row3_col14, #T_8df1c_row3_col15, #T_8df1c_row4_col2, #T_8df1c_row4_col3, #T_8df1c_row4_col5, #T_8df1c_row4_col6, #T_8df1c_row4_col7, #T_8df1c_row4_col9, #T_8df1c_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row0_col13, #T_8df1c_row0_col14, #T_8df1c_row0_col15, #T_8df1c_row0_col17, #T_8df1c_row3_col11, #T_8df1c_row3_col12, #T_8df1c_row3_col17, #T_8df1c_row4_col11, #T_8df1c_row4_col12, #T_8df1c_row4_col13, #T_8df1c_row4_col14, #T_8df1c_row4_col15, #T_8df1c_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row2_col10, #T_8df1c_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row3_col5, #T_8df1c_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8df1c_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8df1c_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8df1c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8df1c_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_8df1c_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_8df1c_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_8df1c_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_8df1c_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_8df1c_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_8df1c_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_8df1c_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_8df1c_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_8df1c_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_8df1c_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_8df1c_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_8df1c_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_8df1c_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_8df1c_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_8df1c_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_8df1c_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_8df1c_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8df1c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8df1c_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_8df1c_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_8df1c_row0_col2\" class=\"data row0 col2\" >44.3</td>\n",
       "      <td id=\"T_8df1c_row0_col3\" class=\"data row0 col3\" >45.7</td>\n",
       "      <td id=\"T_8df1c_row0_col4\" class=\"data row0 col4\" >3.0</td>\n",
       "      <td id=\"T_8df1c_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_8df1c_row0_col6\" class=\"data row0 col6\" >36.8</td>\n",
       "      <td id=\"T_8df1c_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_8df1c_row0_col8\" class=\"data row0 col8\" >8.4</td>\n",
       "      <td id=\"T_8df1c_row0_col9\" class=\"data row0 col9\" >43.3</td>\n",
       "      <td id=\"T_8df1c_row0_col10\" class=\"data row0 col10\" >8.5</td>\n",
       "      <td id=\"T_8df1c_row0_col11\" class=\"data row0 col11\" >4.2</td>\n",
       "      <td id=\"T_8df1c_row0_col12\" class=\"data row0 col12\" >101.4</td>\n",
       "      <td id=\"T_8df1c_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_8df1c_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_8df1c_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_8df1c_row0_col16\" class=\"data row0 col16\" >31.1</td>\n",
       "      <td id=\"T_8df1c_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8df1c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8df1c_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_8df1c_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_8df1c_row1_col2\" class=\"data row1 col2\" >40.6</td>\n",
       "      <td id=\"T_8df1c_row1_col3\" class=\"data row1 col3\" >41.1</td>\n",
       "      <td id=\"T_8df1c_row1_col4\" class=\"data row1 col4\" >4.0</td>\n",
       "      <td id=\"T_8df1c_row1_col5\" class=\"data row1 col5\" >12.4</td>\n",
       "      <td id=\"T_8df1c_row1_col6\" class=\"data row1 col6\" >33.7</td>\n",
       "      <td id=\"T_8df1c_row1_col7\" class=\"data row1 col7\" >35.6</td>\n",
       "      <td id=\"T_8df1c_row1_col8\" class=\"data row1 col8\" >7.9</td>\n",
       "      <td id=\"T_8df1c_row1_col9\" class=\"data row1 col9\" >40.4</td>\n",
       "      <td id=\"T_8df1c_row1_col10\" class=\"data row1 col10\" >8.7</td>\n",
       "      <td id=\"T_8df1c_row1_col11\" class=\"data row1 col11\" >5.3</td>\n",
       "      <td id=\"T_8df1c_row1_col12\" class=\"data row1 col12\" >122.3</td>\n",
       "      <td id=\"T_8df1c_row1_col13\" class=\"data row1 col13\" >24.0</td>\n",
       "      <td id=\"T_8df1c_row1_col14\" class=\"data row1 col14\" >18.4</td>\n",
       "      <td id=\"T_8df1c_row1_col15\" class=\"data row1 col15\" >21.2</td>\n",
       "      <td id=\"T_8df1c_row1_col16\" class=\"data row1 col16\" >29.7</td>\n",
       "      <td id=\"T_8df1c_row1_col17\" class=\"data row1 col17\" >-30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8df1c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8df1c_row2_col0\" class=\"data row2 col0\" >llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_8df1c_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_8df1c_row2_col2\" class=\"data row2 col2\" >44.3</td>\n",
       "      <td id=\"T_8df1c_row2_col3\" class=\"data row2 col3\" >45.1</td>\n",
       "      <td id=\"T_8df1c_row2_col4\" class=\"data row2 col4\" >4.4</td>\n",
       "      <td id=\"T_8df1c_row2_col5\" class=\"data row2 col5\" >14.8</td>\n",
       "      <td id=\"T_8df1c_row2_col6\" class=\"data row2 col6\" >36.3</td>\n",
       "      <td id=\"T_8df1c_row2_col7\" class=\"data row2 col7\" >34.3</td>\n",
       "      <td id=\"T_8df1c_row2_col8\" class=\"data row2 col8\" >8.0</td>\n",
       "      <td id=\"T_8df1c_row2_col9\" class=\"data row2 col9\" >40.2</td>\n",
       "      <td id=\"T_8df1c_row2_col10\" class=\"data row2 col10\" >9.3</td>\n",
       "      <td id=\"T_8df1c_row2_col11\" class=\"data row2 col11\" >4.8</td>\n",
       "      <td id=\"T_8df1c_row2_col12\" class=\"data row2 col12\" >107.2</td>\n",
       "      <td id=\"T_8df1c_row2_col13\" class=\"data row2 col13\" >22.1</td>\n",
       "      <td id=\"T_8df1c_row2_col14\" class=\"data row2 col14\" >19.0</td>\n",
       "      <td id=\"T_8df1c_row2_col15\" class=\"data row2 col15\" >20.6</td>\n",
       "      <td id=\"T_8df1c_row2_col16\" class=\"data row2 col16\" >29.3</td>\n",
       "      <td id=\"T_8df1c_row2_col17\" class=\"data row2 col17\" >-27.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8df1c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8df1c_row3_col0\" class=\"data row3 col0\" >llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_8df1c_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_8df1c_row3_col2\" class=\"data row3 col2\" >43.4</td>\n",
       "      <td id=\"T_8df1c_row3_col3\" class=\"data row3 col3\" >41.5</td>\n",
       "      <td id=\"T_8df1c_row3_col4\" class=\"data row3 col4\" >3.6</td>\n",
       "      <td id=\"T_8df1c_row3_col5\" class=\"data row3 col5\" >12.6</td>\n",
       "      <td id=\"T_8df1c_row3_col6\" class=\"data row3 col6\" >35.3</td>\n",
       "      <td id=\"T_8df1c_row3_col7\" class=\"data row3 col7\" >32.7</td>\n",
       "      <td id=\"T_8df1c_row3_col8\" class=\"data row3 col8\" >8.1</td>\n",
       "      <td id=\"T_8df1c_row3_col9\" class=\"data row3 col9\" >42.8</td>\n",
       "      <td id=\"T_8df1c_row3_col10\" class=\"data row3 col10\" >9.3</td>\n",
       "      <td id=\"T_8df1c_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_8df1c_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_8df1c_row3_col13\" class=\"data row3 col13\" >22.6</td>\n",
       "      <td id=\"T_8df1c_row3_col14\" class=\"data row3 col14\" >15.9</td>\n",
       "      <td id=\"T_8df1c_row3_col15\" class=\"data row3 col15\" >19.2</td>\n",
       "      <td id=\"T_8df1c_row3_col16\" class=\"data row3 col16\" >23.9</td>\n",
       "      <td id=\"T_8df1c_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8df1c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8df1c_row4_col0\" class=\"data row4 col0\" >llama-7b</td>\n",
       "      <td id=\"T_8df1c_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_8df1c_row4_col2\" class=\"data row4 col2\" >31.8</td>\n",
       "      <td id=\"T_8df1c_row4_col3\" class=\"data row4 col3\" >34.5</td>\n",
       "      <td id=\"T_8df1c_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_8df1c_row4_col5\" class=\"data row4 col5\" >11.8</td>\n",
       "      <td id=\"T_8df1c_row4_col6\" class=\"data row4 col6\" >30.6</td>\n",
       "      <td id=\"T_8df1c_row4_col7\" class=\"data row4 col7\" >32.7</td>\n",
       "      <td id=\"T_8df1c_row4_col8\" class=\"data row4 col8\" >9.6</td>\n",
       "      <td id=\"T_8df1c_row4_col9\" class=\"data row4 col9\" >38.4</td>\n",
       "      <td id=\"T_8df1c_row4_col10\" class=\"data row4 col10\" >10.2</td>\n",
       "      <td id=\"T_8df1c_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_8df1c_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_8df1c_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_8df1c_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_8df1c_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_8df1c_row4_col16\" class=\"data row4 col16\" >22.8</td>\n",
       "      <td id=\"T_8df1c_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf6ca44f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a7570 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_a7570_row0_col0, #T_a7570_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a7570_row0_col1, #T_a7570_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a7570_row0_col2, #T_a7570_row0_col3, #T_a7570_row0_col6, #T_a7570_row0_col7, #T_a7570_row0_col9, #T_a7570_row0_col16, #T_a7570_row1_col4, #T_a7570_row1_col8, #T_a7570_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a7570_row0_col4, #T_a7570_row0_col5, #T_a7570_row0_col8, #T_a7570_row0_col10, #T_a7570_row0_col11, #T_a7570_row0_col12, #T_a7570_row1_col2, #T_a7570_row1_col3, #T_a7570_row1_col5, #T_a7570_row1_col6, #T_a7570_row1_col7, #T_a7570_row1_col9, #T_a7570_row1_col11, #T_a7570_row1_col12, #T_a7570_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a7570_row0_col13, #T_a7570_row0_col14, #T_a7570_row0_col15, #T_a7570_row0_col17, #T_a7570_row1_col13, #T_a7570_row1_col14, #T_a7570_row1_col15, #T_a7570_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a7570\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a7570_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_a7570_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_a7570_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_a7570_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_a7570_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_a7570_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_a7570_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_a7570_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_a7570_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_a7570_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_a7570_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_a7570_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_a7570_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_a7570_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_a7570_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_a7570_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_a7570_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_a7570_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a7570_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a7570_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_a7570_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_a7570_row0_col2\" class=\"data row0 col2\" >44.3</td>\n",
       "      <td id=\"T_a7570_row0_col3\" class=\"data row0 col3\" >45.7</td>\n",
       "      <td id=\"T_a7570_row0_col4\" class=\"data row0 col4\" >3.0</td>\n",
       "      <td id=\"T_a7570_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_a7570_row0_col6\" class=\"data row0 col6\" >36.8</td>\n",
       "      <td id=\"T_a7570_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_a7570_row0_col8\" class=\"data row0 col8\" >8.4</td>\n",
       "      <td id=\"T_a7570_row0_col9\" class=\"data row0 col9\" >43.3</td>\n",
       "      <td id=\"T_a7570_row0_col10\" class=\"data row0 col10\" >8.5</td>\n",
       "      <td id=\"T_a7570_row0_col11\" class=\"data row0 col11\" >4.2</td>\n",
       "      <td id=\"T_a7570_row0_col12\" class=\"data row0 col12\" >101.4</td>\n",
       "      <td id=\"T_a7570_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_a7570_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_a7570_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_a7570_row0_col16\" class=\"data row0 col16\" >31.1</td>\n",
       "      <td id=\"T_a7570_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7570_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a7570_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_a7570_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_a7570_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_a7570_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_a7570_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_a7570_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_a7570_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_a7570_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_a7570_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_a7570_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_a7570_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_a7570_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_a7570_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_a7570_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_a7570_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_a7570_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_a7570_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_a7570_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf434e800>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bafe3 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_bafe3_row0_col0, #T_bafe3_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bafe3_row0_col1, #T_bafe3_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bafe3_row0_col2, #T_bafe3_row0_col3, #T_bafe3_row0_col6, #T_bafe3_row0_col7, #T_bafe3_row0_col9, #T_bafe3_row0_col16, #T_bafe3_row1_col4, #T_bafe3_row1_col8, #T_bafe3_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bafe3_row0_col4, #T_bafe3_row0_col5, #T_bafe3_row0_col8, #T_bafe3_row0_col10, #T_bafe3_row0_col11, #T_bafe3_row0_col12, #T_bafe3_row1_col2, #T_bafe3_row1_col3, #T_bafe3_row1_col5, #T_bafe3_row1_col6, #T_bafe3_row1_col7, #T_bafe3_row1_col9, #T_bafe3_row1_col11, #T_bafe3_row1_col12, #T_bafe3_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bafe3_row0_col13, #T_bafe3_row0_col14, #T_bafe3_row0_col15, #T_bafe3_row0_col17, #T_bafe3_row1_col13, #T_bafe3_row1_col14, #T_bafe3_row1_col15, #T_bafe3_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bafe3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bafe3_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_bafe3_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_bafe3_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_bafe3_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_bafe3_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_bafe3_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_bafe3_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_bafe3_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_bafe3_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_bafe3_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_bafe3_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_bafe3_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_bafe3_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_bafe3_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_bafe3_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_bafe3_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_bafe3_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_bafe3_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bafe3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bafe3_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_bafe3_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_bafe3_row0_col2\" class=\"data row0 col2\" >44.3</td>\n",
       "      <td id=\"T_bafe3_row0_col3\" class=\"data row0 col3\" >45.7</td>\n",
       "      <td id=\"T_bafe3_row0_col4\" class=\"data row0 col4\" >3.0</td>\n",
       "      <td id=\"T_bafe3_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_bafe3_row0_col6\" class=\"data row0 col6\" >36.8</td>\n",
       "      <td id=\"T_bafe3_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_bafe3_row0_col8\" class=\"data row0 col8\" >8.4</td>\n",
       "      <td id=\"T_bafe3_row0_col9\" class=\"data row0 col9\" >43.3</td>\n",
       "      <td id=\"T_bafe3_row0_col10\" class=\"data row0 col10\" >8.5</td>\n",
       "      <td id=\"T_bafe3_row0_col11\" class=\"data row0 col11\" >4.2</td>\n",
       "      <td id=\"T_bafe3_row0_col12\" class=\"data row0 col12\" >101.4</td>\n",
       "      <td id=\"T_bafe3_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_bafe3_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_bafe3_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_bafe3_row0_col16\" class=\"data row0 col16\" >31.1</td>\n",
       "      <td id=\"T_bafe3_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bafe3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bafe3_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_bafe3_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_bafe3_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_bafe3_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_bafe3_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_bafe3_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_bafe3_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_bafe3_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_bafe3_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_bafe3_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_bafe3_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_bafe3_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_bafe3_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_bafe3_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_bafe3_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_bafe3_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_bafe3_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_bafe3_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf6ca7940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_45808 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_45808_row0_col0, #T_45808_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_45808_row0_col1, #T_45808_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_45808_row0_col2, #T_45808_row0_col4, #T_45808_row0_col5, #T_45808_row0_col8, #T_45808_row0_col9, #T_45808_row0_col10, #T_45808_row0_col11, #T_45808_row0_col12, #T_45808_row1_col3, #T_45808_row1_col6, #T_45808_row1_col7, #T_45808_row1_col11, #T_45808_row1_col12, #T_45808_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45808_row0_col3, #T_45808_row0_col6, #T_45808_row0_col7, #T_45808_row0_col16, #T_45808_row1_col2, #T_45808_row1_col4, #T_45808_row1_col5, #T_45808_row1_col8, #T_45808_row1_col9, #T_45808_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45808_row0_col13, #T_45808_row0_col14, #T_45808_row0_col15, #T_45808_row0_col17, #T_45808_row1_col13, #T_45808_row1_col14, #T_45808_row1_col15, #T_45808_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_45808\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_45808_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_45808_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_45808_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_45808_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_45808_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_45808_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_45808_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_45808_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_45808_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_45808_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_45808_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_45808_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_45808_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_45808_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_45808_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_45808_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_45808_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_45808_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_45808_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_45808_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_45808_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_45808_row0_col2\" class=\"data row0 col2\" >31.3</td>\n",
       "      <td id=\"T_45808_row0_col3\" class=\"data row0 col3\" >34.6</td>\n",
       "      <td id=\"T_45808_row0_col4\" class=\"data row0 col4\" >5.2</td>\n",
       "      <td id=\"T_45808_row0_col5\" class=\"data row0 col5\" >10.2</td>\n",
       "      <td id=\"T_45808_row0_col6\" class=\"data row0 col6\" >32.6</td>\n",
       "      <td id=\"T_45808_row0_col7\" class=\"data row0 col7\" >32.8</td>\n",
       "      <td id=\"T_45808_row0_col8\" class=\"data row0 col8\" >8.9</td>\n",
       "      <td id=\"T_45808_row0_col9\" class=\"data row0 col9\" >31.9</td>\n",
       "      <td id=\"T_45808_row0_col10\" class=\"data row0 col10\" >9.8</td>\n",
       "      <td id=\"T_45808_row0_col11\" class=\"data row0 col11\" >38.3</td>\n",
       "      <td id=\"T_45808_row0_col12\" class=\"data row0 col12\" >278.1</td>\n",
       "      <td id=\"T_45808_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_45808_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_45808_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_45808_row0_col16\" class=\"data row0 col16\" >46.7</td>\n",
       "      <td id=\"T_45808_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45808_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_45808_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_45808_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_45808_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_45808_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_45808_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_45808_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_45808_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_45808_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_45808_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_45808_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_45808_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_45808_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_45808_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_45808_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_45808_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_45808_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_45808_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_45808_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf36ed120>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3a8f7 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_3a8f7_row0_col0, #T_3a8f7_row1_col0, #T_3a8f7_row2_col0, #T_3a8f7_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3a8f7_row0_col1, #T_3a8f7_row1_col1, #T_3a8f7_row2_col1, #T_3a8f7_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3a8f7_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a8f7_row0_col3, #T_3a8f7_row0_col4, #T_3a8f7_row0_col6, #T_3a8f7_row0_col11, #T_3a8f7_row0_col12, #T_3a8f7_row0_col14, #T_3a8f7_row0_col16, #T_3a8f7_row1_col2, #T_3a8f7_row1_col5, #T_3a8f7_row1_col7, #T_3a8f7_row1_col10, #T_3a8f7_row1_col13, #T_3a8f7_row1_col15, #T_3a8f7_row1_col17, #T_3a8f7_row3_col8, #T_3a8f7_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a8f7_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a8f7_row0_col7, #T_3a8f7_row0_col9, #T_3a8f7_row0_col10, #T_3a8f7_row0_col13, #T_3a8f7_row0_col15, #T_3a8f7_row0_col17, #T_3a8f7_row1_col8, #T_3a8f7_row1_col11, #T_3a8f7_row1_col14, #T_3a8f7_row2_col2, #T_3a8f7_row2_col4, #T_3a8f7_row2_col5, #T_3a8f7_row2_col12, #T_3a8f7_row3_col3, #T_3a8f7_row3_col6, #T_3a8f7_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a8f7_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a8f7_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a8f7_row1_col4, #T_3a8f7_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a8f7_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a8f7_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a8f7_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a8f7_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a8f7_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a8f7_row2_col6, #T_3a8f7_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a8f7_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a8f7_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a8f7_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a8f7_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a8f7_row2_col13, #T_3a8f7_row2_col14, #T_3a8f7_row2_col15, #T_3a8f7_row2_col17, #T_3a8f7_row3_col11, #T_3a8f7_row3_col12, #T_3a8f7_row3_col13, #T_3a8f7_row3_col14, #T_3a8f7_row3_col15, #T_3a8f7_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a8f7_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a8f7_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a8f7_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a8f7_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a8f7_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3a8f7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3a8f7_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_3a8f7_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_3a8f7_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_3a8f7_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_3a8f7_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_3a8f7_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_3a8f7_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_3a8f7_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_3a8f7_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_3a8f7_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_3a8f7_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_3a8f7_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_3a8f7_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_3a8f7_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_3a8f7_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_3a8f7_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_3a8f7_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_3a8f7_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3a8f7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3a8f7_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_3a8f7_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_3a8f7_row0_col2\" class=\"data row0 col2\" >33.1</td>\n",
       "      <td id=\"T_3a8f7_row0_col3\" class=\"data row0 col3\" >36.7</td>\n",
       "      <td id=\"T_3a8f7_row0_col4\" class=\"data row0 col4\" >6.2</td>\n",
       "      <td id=\"T_3a8f7_row0_col5\" class=\"data row0 col5\" >11.0</td>\n",
       "      <td id=\"T_3a8f7_row0_col6\" class=\"data row0 col6\" >33.9</td>\n",
       "      <td id=\"T_3a8f7_row0_col7\" class=\"data row0 col7\" >32.5</td>\n",
       "      <td id=\"T_3a8f7_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_3a8f7_row0_col9\" class=\"data row0 col9\" >29.1</td>\n",
       "      <td id=\"T_3a8f7_row0_col10\" class=\"data row0 col10\" >7.9</td>\n",
       "      <td id=\"T_3a8f7_row0_col11\" class=\"data row0 col11\" >40.1</td>\n",
       "      <td id=\"T_3a8f7_row0_col12\" class=\"data row0 col12\" >363.7</td>\n",
       "      <td id=\"T_3a8f7_row0_col13\" class=\"data row0 col13\" >39.5</td>\n",
       "      <td id=\"T_3a8f7_row0_col14\" class=\"data row0 col14\" >27.6</td>\n",
       "      <td id=\"T_3a8f7_row0_col15\" class=\"data row0 col15\" >33.6</td>\n",
       "      <td id=\"T_3a8f7_row0_col16\" class=\"data row0 col16\" >50.2</td>\n",
       "      <td id=\"T_3a8f7_row0_col17\" class=\"data row0 col17\" >-26.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a8f7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3a8f7_row1_col0\" class=\"data row1 col0\" >llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_3a8f7_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_3a8f7_row1_col2\" class=\"data row1 col2\" >33.7</td>\n",
       "      <td id=\"T_3a8f7_row1_col3\" class=\"data row1 col3\" >35.7</td>\n",
       "      <td id=\"T_3a8f7_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_3a8f7_row1_col5\" class=\"data row1 col5\" >12.4</td>\n",
       "      <td id=\"T_3a8f7_row1_col6\" class=\"data row1 col6\" >33.6</td>\n",
       "      <td id=\"T_3a8f7_row1_col7\" class=\"data row1 col7\" >34.1</td>\n",
       "      <td id=\"T_3a8f7_row1_col8\" class=\"data row1 col8\" >7.4</td>\n",
       "      <td id=\"T_3a8f7_row1_col9\" class=\"data row1 col9\" >31.7</td>\n",
       "      <td id=\"T_3a8f7_row1_col10\" class=\"data row1 col10\" >11.0</td>\n",
       "      <td id=\"T_3a8f7_row1_col11\" class=\"data row1 col11\" >33.1</td>\n",
       "      <td id=\"T_3a8f7_row1_col12\" class=\"data row1 col12\" >321.7</td>\n",
       "      <td id=\"T_3a8f7_row1_col13\" class=\"data row1 col13\" >39.8</td>\n",
       "      <td id=\"T_3a8f7_row1_col14\" class=\"data row1 col14\" >27.3</td>\n",
       "      <td id=\"T_3a8f7_row1_col15\" class=\"data row1 col15\" >33.6</td>\n",
       "      <td id=\"T_3a8f7_row1_col16\" class=\"data row1 col16\" >47.2</td>\n",
       "      <td id=\"T_3a8f7_row1_col17\" class=\"data row1 col17\" >-25.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a8f7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3a8f7_row2_col0\" class=\"data row2 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_3a8f7_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_3a8f7_row2_col2\" class=\"data row2 col2\" >31.3</td>\n",
       "      <td id=\"T_3a8f7_row2_col3\" class=\"data row2 col3\" >34.6</td>\n",
       "      <td id=\"T_3a8f7_row2_col4\" class=\"data row2 col4\" >5.2</td>\n",
       "      <td id=\"T_3a8f7_row2_col5\" class=\"data row2 col5\" >10.2</td>\n",
       "      <td id=\"T_3a8f7_row2_col6\" class=\"data row2 col6\" >32.6</td>\n",
       "      <td id=\"T_3a8f7_row2_col7\" class=\"data row2 col7\" >32.8</td>\n",
       "      <td id=\"T_3a8f7_row2_col8\" class=\"data row2 col8\" >8.9</td>\n",
       "      <td id=\"T_3a8f7_row2_col9\" class=\"data row2 col9\" >31.9</td>\n",
       "      <td id=\"T_3a8f7_row2_col10\" class=\"data row2 col10\" >9.8</td>\n",
       "      <td id=\"T_3a8f7_row2_col11\" class=\"data row2 col11\" >38.3</td>\n",
       "      <td id=\"T_3a8f7_row2_col12\" class=\"data row2 col12\" >278.1</td>\n",
       "      <td id=\"T_3a8f7_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_3a8f7_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_3a8f7_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_3a8f7_row2_col16\" class=\"data row2 col16\" >46.7</td>\n",
       "      <td id=\"T_3a8f7_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a8f7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3a8f7_row3_col0\" class=\"data row3 col0\" >llama-7b</td>\n",
       "      <td id=\"T_3a8f7_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_3a8f7_row3_col2\" class=\"data row3 col2\" >31.8</td>\n",
       "      <td id=\"T_3a8f7_row3_col3\" class=\"data row3 col3\" >34.5</td>\n",
       "      <td id=\"T_3a8f7_row3_col4\" class=\"data row3 col4\" >5.4</td>\n",
       "      <td id=\"T_3a8f7_row3_col5\" class=\"data row3 col5\" >11.8</td>\n",
       "      <td id=\"T_3a8f7_row3_col6\" class=\"data row3 col6\" >30.6</td>\n",
       "      <td id=\"T_3a8f7_row3_col7\" class=\"data row3 col7\" >32.7</td>\n",
       "      <td id=\"T_3a8f7_row3_col8\" class=\"data row3 col8\" >9.6</td>\n",
       "      <td id=\"T_3a8f7_row3_col9\" class=\"data row3 col9\" >38.4</td>\n",
       "      <td id=\"T_3a8f7_row3_col10\" class=\"data row3 col10\" >10.2</td>\n",
       "      <td id=\"T_3a8f7_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_3a8f7_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_3a8f7_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_3a8f7_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_3a8f7_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_3a8f7_row3_col16\" class=\"data row3 col16\" >22.8</td>\n",
       "      <td id=\"T_3a8f7_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf5bd9c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d8f57 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_d8f57_row0_col0, #T_d8f57_row1_col0, #T_d8f57_row2_col0, #T_d8f57_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d8f57_row0_col1, #T_d8f57_row1_col1, #T_d8f57_row2_col1, #T_d8f57_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d8f57_row0_col2, #T_d8f57_row0_col3, #T_d8f57_row0_col5, #T_d8f57_row0_col7, #T_d8f57_row0_col12, #T_d8f57_row0_col16, #T_d8f57_row0_col17, #T_d8f57_row2_col4, #T_d8f57_row2_col6, #T_d8f57_row2_col10, #T_d8f57_row2_col11, #T_d8f57_row2_col13, #T_d8f57_row2_col14, #T_d8f57_row2_col15, #T_d8f57_row3_col4, #T_d8f57_row3_col8, #T_d8f57_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d8f57_row0_col4, #T_d8f57_row0_col6, #T_d8f57_row0_col10, #T_d8f57_row0_col13, #T_d8f57_row0_col14, #T_d8f57_row0_col15, #T_d8f57_row1_col2, #T_d8f57_row1_col5, #T_d8f57_row1_col10, #T_d8f57_row1_col11, #T_d8f57_row2_col8, #T_d8f57_row2_col9, #T_d8f57_row2_col12, #T_d8f57_row2_col17, #T_d8f57_row3_col3, #T_d8f57_row3_col7, #T_d8f57_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d8f57_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d8f57_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d8f57_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d8f57_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d8f57_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d8f57_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d8f57_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d8f57_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d8f57_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d8f57_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d8f57_row1_col13, #T_d8f57_row1_col14, #T_d8f57_row1_col15, #T_d8f57_row1_col17, #T_d8f57_row3_col11, #T_d8f57_row3_col12, #T_d8f57_row3_col13, #T_d8f57_row3_col14, #T_d8f57_row3_col15, #T_d8f57_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d8f57_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d8f57_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d8f57_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d8f57_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d8f57_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d8f57_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d8f57_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d8f57_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d8f57_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d8f57_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d8f57\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d8f57_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d8f57_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_d8f57_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d8f57_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d8f57_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_d8f57_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_d8f57_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_d8f57_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_d8f57_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d8f57_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d8f57_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d8f57_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_d8f57_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_d8f57_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_d8f57_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_d8f57_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_d8f57_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_d8f57_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d8f57_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d8f57_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_d8f57_row0_col1\" class=\"data row0 col1\" >60000</td>\n",
       "      <td id=\"T_d8f57_row0_col2\" class=\"data row0 col2\" >35.8</td>\n",
       "      <td id=\"T_d8f57_row0_col3\" class=\"data row0 col3\" >37.5</td>\n",
       "      <td id=\"T_d8f57_row0_col4\" class=\"data row0 col4\" >4.6</td>\n",
       "      <td id=\"T_d8f57_row0_col5\" class=\"data row0 col5\" >12.2</td>\n",
       "      <td id=\"T_d8f57_row0_col6\" class=\"data row0 col6\" >30.4</td>\n",
       "      <td id=\"T_d8f57_row0_col7\" class=\"data row0 col7\" >33.9</td>\n",
       "      <td id=\"T_d8f57_row0_col8\" class=\"data row0 col8\" >8.5</td>\n",
       "      <td id=\"T_d8f57_row0_col9\" class=\"data row0 col9\" >33.1</td>\n",
       "      <td id=\"T_d8f57_row0_col10\" class=\"data row0 col10\" >9.8</td>\n",
       "      <td id=\"T_d8f57_row0_col11\" class=\"data row0 col11\" >38.4</td>\n",
       "      <td id=\"T_d8f57_row0_col12\" class=\"data row0 col12\" >356.8</td>\n",
       "      <td id=\"T_d8f57_row0_col13\" class=\"data row0 col13\" >41.6</td>\n",
       "      <td id=\"T_d8f57_row0_col14\" class=\"data row0 col14\" >27.3</td>\n",
       "      <td id=\"T_d8f57_row0_col15\" class=\"data row0 col15\" >34.5</td>\n",
       "      <td id=\"T_d8f57_row0_col16\" class=\"data row0 col16\" >50.3</td>\n",
       "      <td id=\"T_d8f57_row0_col17\" class=\"data row0 col17\" >-24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d8f57_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d8f57_row1_col0\" class=\"data row1 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_d8f57_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_d8f57_row1_col2\" class=\"data row1 col2\" >31.3</td>\n",
       "      <td id=\"T_d8f57_row1_col3\" class=\"data row1 col3\" >34.6</td>\n",
       "      <td id=\"T_d8f57_row1_col4\" class=\"data row1 col4\" >5.2</td>\n",
       "      <td id=\"T_d8f57_row1_col5\" class=\"data row1 col5\" >10.2</td>\n",
       "      <td id=\"T_d8f57_row1_col6\" class=\"data row1 col6\" >32.6</td>\n",
       "      <td id=\"T_d8f57_row1_col7\" class=\"data row1 col7\" >32.8</td>\n",
       "      <td id=\"T_d8f57_row1_col8\" class=\"data row1 col8\" >8.9</td>\n",
       "      <td id=\"T_d8f57_row1_col9\" class=\"data row1 col9\" >31.9</td>\n",
       "      <td id=\"T_d8f57_row1_col10\" class=\"data row1 col10\" >9.8</td>\n",
       "      <td id=\"T_d8f57_row1_col11\" class=\"data row1 col11\" >38.3</td>\n",
       "      <td id=\"T_d8f57_row1_col12\" class=\"data row1 col12\" >278.1</td>\n",
       "      <td id=\"T_d8f57_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_d8f57_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_d8f57_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_d8f57_row1_col16\" class=\"data row1 col16\" >46.7</td>\n",
       "      <td id=\"T_d8f57_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d8f57_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d8f57_row2_col0\" class=\"data row2 col0\" >llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_d8f57_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_d8f57_row2_col2\" class=\"data row2 col2\" >34.5</td>\n",
       "      <td id=\"T_d8f57_row2_col3\" class=\"data row2 col3\" >35.7</td>\n",
       "      <td id=\"T_d8f57_row2_col4\" class=\"data row2 col4\" >5.4</td>\n",
       "      <td id=\"T_d8f57_row2_col5\" class=\"data row2 col5\" >11.0</td>\n",
       "      <td id=\"T_d8f57_row2_col6\" class=\"data row2 col6\" >33.7</td>\n",
       "      <td id=\"T_d8f57_row2_col7\" class=\"data row2 col7\" >33.7</td>\n",
       "      <td id=\"T_d8f57_row2_col8\" class=\"data row2 col8\" >7.6</td>\n",
       "      <td id=\"T_d8f57_row2_col9\" class=\"data row2 col9\" >28.9</td>\n",
       "      <td id=\"T_d8f57_row2_col10\" class=\"data row2 col10\" >13.0</td>\n",
       "      <td id=\"T_d8f57_row2_col11\" class=\"data row2 col11\" >40.6</td>\n",
       "      <td id=\"T_d8f57_row2_col12\" class=\"data row2 col12\" >277.1</td>\n",
       "      <td id=\"T_d8f57_row2_col13\" class=\"data row2 col13\" >43.2</td>\n",
       "      <td id=\"T_d8f57_row2_col14\" class=\"data row2 col14\" >31.6</td>\n",
       "      <td id=\"T_d8f57_row2_col15\" class=\"data row2 col15\" >37.4</td>\n",
       "      <td id=\"T_d8f57_row2_col16\" class=\"data row2 col16\" >45.2</td>\n",
       "      <td id=\"T_d8f57_row2_col17\" class=\"data row2 col17\" >-26.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d8f57_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d8f57_row3_col0\" class=\"data row3 col0\" >llama-7b</td>\n",
       "      <td id=\"T_d8f57_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_d8f57_row3_col2\" class=\"data row3 col2\" >31.8</td>\n",
       "      <td id=\"T_d8f57_row3_col3\" class=\"data row3 col3\" >34.5</td>\n",
       "      <td id=\"T_d8f57_row3_col4\" class=\"data row3 col4\" >5.4</td>\n",
       "      <td id=\"T_d8f57_row3_col5\" class=\"data row3 col5\" >11.8</td>\n",
       "      <td id=\"T_d8f57_row3_col6\" class=\"data row3 col6\" >30.6</td>\n",
       "      <td id=\"T_d8f57_row3_col7\" class=\"data row3 col7\" >32.7</td>\n",
       "      <td id=\"T_d8f57_row3_col8\" class=\"data row3 col8\" >9.6</td>\n",
       "      <td id=\"T_d8f57_row3_col9\" class=\"data row3 col9\" >38.4</td>\n",
       "      <td id=\"T_d8f57_row3_col10\" class=\"data row3 col10\" >10.2</td>\n",
       "      <td id=\"T_d8f57_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_d8f57_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_d8f57_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_d8f57_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_d8f57_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_d8f57_row3_col16\" class=\"data row3 col16\" >22.8</td>\n",
       "      <td id=\"T_d8f57_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf4fd3a30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_987b7 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_987b7_row0_col0, #T_987b7_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_987b7_row0_col1, #T_987b7_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_987b7_row0_col2, #T_987b7_row0_col4, #T_987b7_row0_col5, #T_987b7_row0_col8, #T_987b7_row0_col9, #T_987b7_row0_col10, #T_987b7_row0_col11, #T_987b7_row0_col12, #T_987b7_row1_col3, #T_987b7_row1_col6, #T_987b7_row1_col7, #T_987b7_row1_col11, #T_987b7_row1_col12, #T_987b7_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_987b7_row0_col3, #T_987b7_row0_col6, #T_987b7_row0_col7, #T_987b7_row0_col16, #T_987b7_row1_col2, #T_987b7_row1_col4, #T_987b7_row1_col5, #T_987b7_row1_col8, #T_987b7_row1_col9, #T_987b7_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_987b7_row0_col13, #T_987b7_row0_col14, #T_987b7_row0_col15, #T_987b7_row0_col17, #T_987b7_row1_col13, #T_987b7_row1_col14, #T_987b7_row1_col15, #T_987b7_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_987b7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_987b7_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_987b7_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_987b7_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_987b7_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_987b7_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_987b7_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_987b7_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_987b7_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_987b7_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_987b7_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_987b7_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_987b7_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_987b7_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_987b7_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_987b7_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_987b7_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_987b7_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_987b7_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_987b7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_987b7_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_987b7_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_987b7_row0_col2\" class=\"data row0 col2\" >31.3</td>\n",
       "      <td id=\"T_987b7_row0_col3\" class=\"data row0 col3\" >34.6</td>\n",
       "      <td id=\"T_987b7_row0_col4\" class=\"data row0 col4\" >5.2</td>\n",
       "      <td id=\"T_987b7_row0_col5\" class=\"data row0 col5\" >10.2</td>\n",
       "      <td id=\"T_987b7_row0_col6\" class=\"data row0 col6\" >32.6</td>\n",
       "      <td id=\"T_987b7_row0_col7\" class=\"data row0 col7\" >32.8</td>\n",
       "      <td id=\"T_987b7_row0_col8\" class=\"data row0 col8\" >8.9</td>\n",
       "      <td id=\"T_987b7_row0_col9\" class=\"data row0 col9\" >31.9</td>\n",
       "      <td id=\"T_987b7_row0_col10\" class=\"data row0 col10\" >9.8</td>\n",
       "      <td id=\"T_987b7_row0_col11\" class=\"data row0 col11\" >38.3</td>\n",
       "      <td id=\"T_987b7_row0_col12\" class=\"data row0 col12\" >278.1</td>\n",
       "      <td id=\"T_987b7_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_987b7_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_987b7_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_987b7_row0_col16\" class=\"data row0 col16\" >46.7</td>\n",
       "      <td id=\"T_987b7_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_987b7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_987b7_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_987b7_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_987b7_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_987b7_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_987b7_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_987b7_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_987b7_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_987b7_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_987b7_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_987b7_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_987b7_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_987b7_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_987b7_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_987b7_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_987b7_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_987b7_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_987b7_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_987b7_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfd2187f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a8fbf td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_a8fbf_row0_col0, #T_a8fbf_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a8fbf_row0_col1, #T_a8fbf_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a8fbf_row0_col2, #T_a8fbf_row0_col4, #T_a8fbf_row0_col5, #T_a8fbf_row0_col8, #T_a8fbf_row0_col9, #T_a8fbf_row0_col10, #T_a8fbf_row0_col11, #T_a8fbf_row0_col12, #T_a8fbf_row1_col3, #T_a8fbf_row1_col6, #T_a8fbf_row1_col7, #T_a8fbf_row1_col11, #T_a8fbf_row1_col12, #T_a8fbf_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a8fbf_row0_col3, #T_a8fbf_row0_col6, #T_a8fbf_row0_col7, #T_a8fbf_row0_col16, #T_a8fbf_row1_col2, #T_a8fbf_row1_col4, #T_a8fbf_row1_col5, #T_a8fbf_row1_col8, #T_a8fbf_row1_col9, #T_a8fbf_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a8fbf_row0_col13, #T_a8fbf_row0_col14, #T_a8fbf_row0_col15, #T_a8fbf_row0_col17, #T_a8fbf_row1_col13, #T_a8fbf_row1_col14, #T_a8fbf_row1_col15, #T_a8fbf_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a8fbf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a8fbf_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_a8fbf_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_a8fbf_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_a8fbf_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_a8fbf_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_a8fbf_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_a8fbf_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_a8fbf_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_a8fbf_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_a8fbf_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_a8fbf_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_a8fbf_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_a8fbf_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_a8fbf_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_a8fbf_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_a8fbf_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_a8fbf_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_a8fbf_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a8fbf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a8fbf_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_a8fbf_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_a8fbf_row0_col2\" class=\"data row0 col2\" >31.3</td>\n",
       "      <td id=\"T_a8fbf_row0_col3\" class=\"data row0 col3\" >34.6</td>\n",
       "      <td id=\"T_a8fbf_row0_col4\" class=\"data row0 col4\" >5.2</td>\n",
       "      <td id=\"T_a8fbf_row0_col5\" class=\"data row0 col5\" >10.2</td>\n",
       "      <td id=\"T_a8fbf_row0_col6\" class=\"data row0 col6\" >32.6</td>\n",
       "      <td id=\"T_a8fbf_row0_col7\" class=\"data row0 col7\" >32.8</td>\n",
       "      <td id=\"T_a8fbf_row0_col8\" class=\"data row0 col8\" >8.9</td>\n",
       "      <td id=\"T_a8fbf_row0_col9\" class=\"data row0 col9\" >31.9</td>\n",
       "      <td id=\"T_a8fbf_row0_col10\" class=\"data row0 col10\" >9.8</td>\n",
       "      <td id=\"T_a8fbf_row0_col11\" class=\"data row0 col11\" >38.3</td>\n",
       "      <td id=\"T_a8fbf_row0_col12\" class=\"data row0 col12\" >278.1</td>\n",
       "      <td id=\"T_a8fbf_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_a8fbf_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_a8fbf_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_a8fbf_row0_col16\" class=\"data row0 col16\" >46.7</td>\n",
       "      <td id=\"T_a8fbf_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a8fbf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a8fbf_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_a8fbf_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_a8fbf_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_a8fbf_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_a8fbf_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_a8fbf_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_a8fbf_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_a8fbf_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_a8fbf_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_a8fbf_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_a8fbf_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_a8fbf_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_a8fbf_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_a8fbf_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_a8fbf_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_a8fbf_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_a8fbf_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_a8fbf_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfd815360>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7fbf1 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_7fbf1_row0_col0, #T_7fbf1_row1_col0, #T_7fbf1_row2_col0, #T_7fbf1_row3_col0, #T_7fbf1_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7fbf1_row0_col1, #T_7fbf1_row1_col1, #T_7fbf1_row2_col1, #T_7fbf1_row3_col1, #T_7fbf1_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7fbf1_row0_col2, #T_7fbf1_row0_col3, #T_7fbf1_row0_col5, #T_7fbf1_row0_col7, #T_7fbf1_row0_col10, #T_7fbf1_row0_col13, #T_7fbf1_row0_col14, #T_7fbf1_row0_col15, #T_7fbf1_row0_col16, #T_7fbf1_row0_col17, #T_7fbf1_row1_col11, #T_7fbf1_row1_col12, #T_7fbf1_row1_col16, #T_7fbf1_row3_col4, #T_7fbf1_row3_col6, #T_7fbf1_row4_col8, #T_7fbf1_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row0_col4, #T_7fbf1_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row0_col6, #T_7fbf1_row0_col12, #T_7fbf1_row1_col2, #T_7fbf1_row1_col3, #T_7fbf1_row1_col7, #T_7fbf1_row1_col9, #T_7fbf1_row2_col5, #T_7fbf1_row2_col8, #T_7fbf1_row2_col13, #T_7fbf1_row2_col15, #T_7fbf1_row2_col17, #T_7fbf1_row3_col10, #T_7fbf1_row3_col11, #T_7fbf1_row3_col14, #T_7fbf1_row4_col4, #T_7fbf1_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row1_col5, #T_7fbf1_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row1_col6, #T_7fbf1_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row1_col14, #T_7fbf1_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row2_col6, #T_7fbf1_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbf1_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbf1_row4_col11, #T_7fbf1_row4_col12, #T_7fbf1_row4_col13, #T_7fbf1_row4_col14, #T_7fbf1_row4_col15, #T_7fbf1_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7fbf1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7fbf1_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_7fbf1_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_7fbf1_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_7fbf1_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_7fbf1_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_7fbf1_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_7fbf1_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_7fbf1_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_7fbf1_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_7fbf1_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_7fbf1_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_7fbf1_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_7fbf1_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_7fbf1_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_7fbf1_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_7fbf1_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_7fbf1_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_7fbf1_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbf1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7fbf1_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_7fbf1_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_7fbf1_row0_col2\" class=\"data row0 col2\" >39.0</td>\n",
       "      <td id=\"T_7fbf1_row0_col3\" class=\"data row0 col3\" >38.8</td>\n",
       "      <td id=\"T_7fbf1_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_7fbf1_row0_col5\" class=\"data row0 col5\" >16.0</td>\n",
       "      <td id=\"T_7fbf1_row0_col6\" class=\"data row0 col6\" >29.9</td>\n",
       "      <td id=\"T_7fbf1_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_7fbf1_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_7fbf1_row0_col9\" class=\"data row0 col9\" >34.9</td>\n",
       "      <td id=\"T_7fbf1_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_7fbf1_row0_col11\" class=\"data row0 col11\" >46.3</td>\n",
       "      <td id=\"T_7fbf1_row0_col12\" class=\"data row0 col12\" >279.4</td>\n",
       "      <td id=\"T_7fbf1_row0_col13\" class=\"data row0 col13\" >54.4</td>\n",
       "      <td id=\"T_7fbf1_row0_col14\" class=\"data row0 col14\" >36.0</td>\n",
       "      <td id=\"T_7fbf1_row0_col15\" class=\"data row0 col15\" >45.3</td>\n",
       "      <td id=\"T_7fbf1_row0_col16\" class=\"data row0 col16\" >48.7</td>\n",
       "      <td id=\"T_7fbf1_row0_col17\" class=\"data row0 col17\" >-13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbf1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7fbf1_row1_col0\" class=\"data row1 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_7fbf1_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_7fbf1_row1_col2\" class=\"data row1 col2\" >30.9</td>\n",
       "      <td id=\"T_7fbf1_row1_col3\" class=\"data row1 col3\" >33.0</td>\n",
       "      <td id=\"T_7fbf1_row1_col4\" class=\"data row1 col4\" >6.4</td>\n",
       "      <td id=\"T_7fbf1_row1_col5\" class=\"data row1 col5\" >13.6</td>\n",
       "      <td id=\"T_7fbf1_row1_col6\" class=\"data row1 col6\" >33.5</td>\n",
       "      <td id=\"T_7fbf1_row1_col7\" class=\"data row1 col7\" >30.7</td>\n",
       "      <td id=\"T_7fbf1_row1_col8\" class=\"data row1 col8\" >7.3</td>\n",
       "      <td id=\"T_7fbf1_row1_col9\" class=\"data row1 col9\" >28.3</td>\n",
       "      <td id=\"T_7fbf1_row1_col10\" class=\"data row1 col10\" >12.2</td>\n",
       "      <td id=\"T_7fbf1_row1_col11\" class=\"data row1 col11\" >51.0</td>\n",
       "      <td id=\"T_7fbf1_row1_col12\" class=\"data row1 col12\" >314.6</td>\n",
       "      <td id=\"T_7fbf1_row1_col13\" class=\"data row1 col13\" >46.4</td>\n",
       "      <td id=\"T_7fbf1_row1_col14\" class=\"data row1 col14\" >34.0</td>\n",
       "      <td id=\"T_7fbf1_row1_col15\" class=\"data row1 col15\" >40.2</td>\n",
       "      <td id=\"T_7fbf1_row1_col16\" class=\"data row1 col16\" >48.7</td>\n",
       "      <td id=\"T_7fbf1_row1_col17\" class=\"data row1 col17\" >-23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbf1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7fbf1_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_7fbf1_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_7fbf1_row2_col2\" class=\"data row2 col2\" >31.7</td>\n",
       "      <td id=\"T_7fbf1_row2_col3\" class=\"data row2 col3\" >37.0</td>\n",
       "      <td id=\"T_7fbf1_row2_col4\" class=\"data row2 col4\" >6.0</td>\n",
       "      <td id=\"T_7fbf1_row2_col5\" class=\"data row2 col5\" >9.6</td>\n",
       "      <td id=\"T_7fbf1_row2_col6\" class=\"data row2 col6\" >31.2</td>\n",
       "      <td id=\"T_7fbf1_row2_col7\" class=\"data row2 col7\" >33.1</td>\n",
       "      <td id=\"T_7fbf1_row2_col8\" class=\"data row2 col8\" >7.0</td>\n",
       "      <td id=\"T_7fbf1_row2_col9\" class=\"data row2 col9\" >30.0</td>\n",
       "      <td id=\"T_7fbf1_row2_col10\" class=\"data row2 col10\" >11.8</td>\n",
       "      <td id=\"T_7fbf1_row2_col11\" class=\"data row2 col11\" >46.8</td>\n",
       "      <td id=\"T_7fbf1_row2_col12\" class=\"data row2 col12\" >299.0</td>\n",
       "      <td id=\"T_7fbf1_row2_col13\" class=\"data row2 col13\" >43.5</td>\n",
       "      <td id=\"T_7fbf1_row2_col14\" class=\"data row2 col14\" >31.9</td>\n",
       "      <td id=\"T_7fbf1_row2_col15\" class=\"data row2 col15\" >37.7</td>\n",
       "      <td id=\"T_7fbf1_row2_col16\" class=\"data row2 col16\" >46.9</td>\n",
       "      <td id=\"T_7fbf1_row2_col17\" class=\"data row2 col17\" >-28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbf1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7fbf1_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_7fbf1_row3_col1\" class=\"data row3 col1\" >10000</td>\n",
       "      <td id=\"T_7fbf1_row3_col2\" class=\"data row3 col2\" >32.9</td>\n",
       "      <td id=\"T_7fbf1_row3_col3\" class=\"data row3 col3\" >34.7</td>\n",
       "      <td id=\"T_7fbf1_row3_col4\" class=\"data row3 col4\" >6.8</td>\n",
       "      <td id=\"T_7fbf1_row3_col5\" class=\"data row3 col5\" >12.0</td>\n",
       "      <td id=\"T_7fbf1_row3_col6\" class=\"data row3 col6\" >35.0</td>\n",
       "      <td id=\"T_7fbf1_row3_col7\" class=\"data row3 col7\" >31.4</td>\n",
       "      <td id=\"T_7fbf1_row3_col8\" class=\"data row3 col8\" >8.9</td>\n",
       "      <td id=\"T_7fbf1_row3_col9\" class=\"data row3 col9\" >32.1</td>\n",
       "      <td id=\"T_7fbf1_row3_col10\" class=\"data row3 col10\" >8.7</td>\n",
       "      <td id=\"T_7fbf1_row3_col11\" class=\"data row3 col11\" >42.2</td>\n",
       "      <td id=\"T_7fbf1_row3_col12\" class=\"data row3 col12\" >288.6</td>\n",
       "      <td id=\"T_7fbf1_row3_col13\" class=\"data row3 col13\" >46.0</td>\n",
       "      <td id=\"T_7fbf1_row3_col14\" class=\"data row3 col14\" >31.8</td>\n",
       "      <td id=\"T_7fbf1_row3_col15\" class=\"data row3 col15\" >38.9</td>\n",
       "      <td id=\"T_7fbf1_row3_col16\" class=\"data row3 col16\" >46.4</td>\n",
       "      <td id=\"T_7fbf1_row3_col17\" class=\"data row3 col17\" >-23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbf1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7fbf1_row4_col0\" class=\"data row4 col0\" >llama-7b</td>\n",
       "      <td id=\"T_7fbf1_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_7fbf1_row4_col2\" class=\"data row4 col2\" >31.8</td>\n",
       "      <td id=\"T_7fbf1_row4_col3\" class=\"data row4 col3\" >34.5</td>\n",
       "      <td id=\"T_7fbf1_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_7fbf1_row4_col5\" class=\"data row4 col5\" >11.8</td>\n",
       "      <td id=\"T_7fbf1_row4_col6\" class=\"data row4 col6\" >30.6</td>\n",
       "      <td id=\"T_7fbf1_row4_col7\" class=\"data row4 col7\" >32.7</td>\n",
       "      <td id=\"T_7fbf1_row4_col8\" class=\"data row4 col8\" >9.6</td>\n",
       "      <td id=\"T_7fbf1_row4_col9\" class=\"data row4 col9\" >38.4</td>\n",
       "      <td id=\"T_7fbf1_row4_col10\" class=\"data row4 col10\" >10.2</td>\n",
       "      <td id=\"T_7fbf1_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_7fbf1_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_7fbf1_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_7fbf1_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_7fbf1_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_7fbf1_row4_col16\" class=\"data row4 col16\" >22.8</td>\n",
       "      <td id=\"T_7fbf1_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf4d647f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_61a87 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_61a87_row0_col0, #T_61a87_row1_col0, #T_61a87_row2_col0, #T_61a87_row3_col0, #T_61a87_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_61a87_row0_col1, #T_61a87_row1_col1, #T_61a87_row2_col1, #T_61a87_row3_col1, #T_61a87_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_61a87_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row0_col6, #T_61a87_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row0_col9, #T_61a87_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row0_col12, #T_61a87_row0_col14, #T_61a87_row0_col15, #T_61a87_row0_col16, #T_61a87_row0_col17, #T_61a87_row1_col6, #T_61a87_row1_col10, #T_61a87_row1_col11, #T_61a87_row2_col2, #T_61a87_row2_col3, #T_61a87_row2_col4, #T_61a87_row2_col5, #T_61a87_row2_col13, #T_61a87_row3_col7, #T_61a87_row4_col8, #T_61a87_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row1_col4, #T_61a87_row1_col5, #T_61a87_row1_col13, #T_61a87_row1_col14, #T_61a87_row1_col15, #T_61a87_row2_col6, #T_61a87_row2_col11, #T_61a87_row2_col12, #T_61a87_row3_col8, #T_61a87_row3_col9, #T_61a87_row3_col17, #T_61a87_row4_col2, #T_61a87_row4_col3, #T_61a87_row4_col7, #T_61a87_row4_col10, #T_61a87_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row2_col9, #T_61a87_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row2_col15, #T_61a87_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_61a87_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61a87_row4_col11, #T_61a87_row4_col12, #T_61a87_row4_col13, #T_61a87_row4_col14, #T_61a87_row4_col15, #T_61a87_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_61a87\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_61a87_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_61a87_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_61a87_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_61a87_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_61a87_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_61a87_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_61a87_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_61a87_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_61a87_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_61a87_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_61a87_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_61a87_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_61a87_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_61a87_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_61a87_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_61a87_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_61a87_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_61a87_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_61a87_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_61a87_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_61a87_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_61a87_row0_col2\" class=\"data row0 col2\" >37.9</td>\n",
       "      <td id=\"T_61a87_row0_col3\" class=\"data row0 col3\" >37.7</td>\n",
       "      <td id=\"T_61a87_row0_col4\" class=\"data row0 col4\" >6.0</td>\n",
       "      <td id=\"T_61a87_row0_col5\" class=\"data row0 col5\" >13.0</td>\n",
       "      <td id=\"T_61a87_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_61a87_row0_col7\" class=\"data row0 col7\" >33.9</td>\n",
       "      <td id=\"T_61a87_row0_col8\" class=\"data row0 col8\" >8.7</td>\n",
       "      <td id=\"T_61a87_row0_col9\" class=\"data row0 col9\" >33.6</td>\n",
       "      <td id=\"T_61a87_row0_col10\" class=\"data row0 col10\" >11.4</td>\n",
       "      <td id=\"T_61a87_row0_col11\" class=\"data row0 col11\" >48.9</td>\n",
       "      <td id=\"T_61a87_row0_col12\" class=\"data row0 col12\" >347.0</td>\n",
       "      <td id=\"T_61a87_row0_col13\" class=\"data row0 col13\" >53.1</td>\n",
       "      <td id=\"T_61a87_row0_col14\" class=\"data row0 col14\" >40.5</td>\n",
       "      <td id=\"T_61a87_row0_col15\" class=\"data row0 col15\" >46.9</td>\n",
       "      <td id=\"T_61a87_row0_col16\" class=\"data row0 col16\" >53.5</td>\n",
       "      <td id=\"T_61a87_row0_col17\" class=\"data row0 col17\" >-13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61a87_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_61a87_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_61a87_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_61a87_row1_col2\" class=\"data row1 col2\" >33.9</td>\n",
       "      <td id=\"T_61a87_row1_col3\" class=\"data row1 col3\" >35.2</td>\n",
       "      <td id=\"T_61a87_row1_col4\" class=\"data row1 col4\" >5.2</td>\n",
       "      <td id=\"T_61a87_row1_col5\" class=\"data row1 col5\" >11.0</td>\n",
       "      <td id=\"T_61a87_row1_col6\" class=\"data row1 col6\" >34.1</td>\n",
       "      <td id=\"T_61a87_row1_col7\" class=\"data row1 col7\" >34.2</td>\n",
       "      <td id=\"T_61a87_row1_col8\" class=\"data row1 col8\" >8.9</td>\n",
       "      <td id=\"T_61a87_row1_col9\" class=\"data row1 col9\" >32.8</td>\n",
       "      <td id=\"T_61a87_row1_col10\" class=\"data row1 col10\" >14.0</td>\n",
       "      <td id=\"T_61a87_row1_col11\" class=\"data row1 col11\" >52.4</td>\n",
       "      <td id=\"T_61a87_row1_col12\" class=\"data row1 col12\" >311.7</td>\n",
       "      <td id=\"T_61a87_row1_col13\" class=\"data row1 col13\" >45.9</td>\n",
       "      <td id=\"T_61a87_row1_col14\" class=\"data row1 col14\" >35.4</td>\n",
       "      <td id=\"T_61a87_row1_col15\" class=\"data row1 col15\" >40.6</td>\n",
       "      <td id=\"T_61a87_row1_col16\" class=\"data row1 col16\" >49.7</td>\n",
       "      <td id=\"T_61a87_row1_col17\" class=\"data row1 col17\" >-16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61a87_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_61a87_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_61a87_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_61a87_row2_col2\" class=\"data row2 col2\" >39.0</td>\n",
       "      <td id=\"T_61a87_row2_col3\" class=\"data row2 col3\" >38.8</td>\n",
       "      <td id=\"T_61a87_row2_col4\" class=\"data row2 col4\" >6.4</td>\n",
       "      <td id=\"T_61a87_row2_col5\" class=\"data row2 col5\" >16.0</td>\n",
       "      <td id=\"T_61a87_row2_col6\" class=\"data row2 col6\" >29.9</td>\n",
       "      <td id=\"T_61a87_row2_col7\" class=\"data row2 col7\" >34.4</td>\n",
       "      <td id=\"T_61a87_row2_col8\" class=\"data row2 col8\" >8.0</td>\n",
       "      <td id=\"T_61a87_row2_col9\" class=\"data row2 col9\" >34.9</td>\n",
       "      <td id=\"T_61a87_row2_col10\" class=\"data row2 col10\" >13.2</td>\n",
       "      <td id=\"T_61a87_row2_col11\" class=\"data row2 col11\" >46.3</td>\n",
       "      <td id=\"T_61a87_row2_col12\" class=\"data row2 col12\" >279.4</td>\n",
       "      <td id=\"T_61a87_row2_col13\" class=\"data row2 col13\" >54.4</td>\n",
       "      <td id=\"T_61a87_row2_col14\" class=\"data row2 col14\" >36.0</td>\n",
       "      <td id=\"T_61a87_row2_col15\" class=\"data row2 col15\" >45.3</td>\n",
       "      <td id=\"T_61a87_row2_col16\" class=\"data row2 col16\" >48.7</td>\n",
       "      <td id=\"T_61a87_row2_col17\" class=\"data row2 col17\" >-13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61a87_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_61a87_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_61a87_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_61a87_row3_col2\" class=\"data row3 col2\" >35.0</td>\n",
       "      <td id=\"T_61a87_row3_col3\" class=\"data row3 col3\" >35.7</td>\n",
       "      <td id=\"T_61a87_row3_col4\" class=\"data row3 col4\" >5.8</td>\n",
       "      <td id=\"T_61a87_row3_col5\" class=\"data row3 col5\" >14.4</td>\n",
       "      <td id=\"T_61a87_row3_col6\" class=\"data row3 col6\" >32.8</td>\n",
       "      <td id=\"T_61a87_row3_col7\" class=\"data row3 col7\" >34.5</td>\n",
       "      <td id=\"T_61a87_row3_col8\" class=\"data row3 col8\" >7.5</td>\n",
       "      <td id=\"T_61a87_row3_col9\" class=\"data row3 col9\" >31.3</td>\n",
       "      <td id=\"T_61a87_row3_col10\" class=\"data row3 col10\" >12.8</td>\n",
       "      <td id=\"T_61a87_row3_col11\" class=\"data row3 col11\" >47.8</td>\n",
       "      <td id=\"T_61a87_row3_col12\" class=\"data row3 col12\" >283.6</td>\n",
       "      <td id=\"T_61a87_row3_col13\" class=\"data row3 col13\" >48.6</td>\n",
       "      <td id=\"T_61a87_row3_col14\" class=\"data row3 col14\" >39.2</td>\n",
       "      <td id=\"T_61a87_row3_col15\" class=\"data row3 col15\" >44.0</td>\n",
       "      <td id=\"T_61a87_row3_col16\" class=\"data row3 col16\" >48.1</td>\n",
       "      <td id=\"T_61a87_row3_col17\" class=\"data row3 col17\" >-18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61a87_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_61a87_row4_col0\" class=\"data row4 col0\" >llama-7b</td>\n",
       "      <td id=\"T_61a87_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_61a87_row4_col2\" class=\"data row4 col2\" >31.8</td>\n",
       "      <td id=\"T_61a87_row4_col3\" class=\"data row4 col3\" >34.5</td>\n",
       "      <td id=\"T_61a87_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_61a87_row4_col5\" class=\"data row4 col5\" >11.8</td>\n",
       "      <td id=\"T_61a87_row4_col6\" class=\"data row4 col6\" >30.6</td>\n",
       "      <td id=\"T_61a87_row4_col7\" class=\"data row4 col7\" >32.7</td>\n",
       "      <td id=\"T_61a87_row4_col8\" class=\"data row4 col8\" >9.6</td>\n",
       "      <td id=\"T_61a87_row4_col9\" class=\"data row4 col9\" >38.4</td>\n",
       "      <td id=\"T_61a87_row4_col10\" class=\"data row4 col10\" >10.2</td>\n",
       "      <td id=\"T_61a87_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_61a87_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_61a87_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_61a87_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_61a87_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_61a87_row4_col16\" class=\"data row4 col16\" >22.8</td>\n",
       "      <td id=\"T_61a87_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cff4ecbb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ea3d9 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_ea3d9_row0_col0, #T_ea3d9_row1_col0, #T_ea3d9_row2_col0, #T_ea3d9_row3_col0, #T_ea3d9_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ea3d9_row0_col1, #T_ea3d9_row1_col1, #T_ea3d9_row2_col1, #T_ea3d9_row3_col1, #T_ea3d9_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ea3d9_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row0_col3, #T_ea3d9_row0_col4, #T_ea3d9_row0_col6, #T_ea3d9_row0_col11, #T_ea3d9_row0_col12, #T_ea3d9_row0_col14, #T_ea3d9_row0_col16, #T_ea3d9_row0_col17, #T_ea3d9_row1_col7, #T_ea3d9_row2_col2, #T_ea3d9_row3_col4, #T_ea3d9_row3_col5, #T_ea3d9_row3_col10, #T_ea3d9_row3_col13, #T_ea3d9_row3_col15, #T_ea3d9_row4_col8, #T_ea3d9_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row0_col9, #T_ea3d9_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row1_col5, #T_ea3d9_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row1_col8, #T_ea3d9_row1_col9, #T_ea3d9_row1_col14, #T_ea3d9_row1_col15, #T_ea3d9_row1_col17, #T_ea3d9_row2_col13, #T_ea3d9_row3_col6, #T_ea3d9_row3_col11, #T_ea3d9_row3_col12, #T_ea3d9_row4_col2, #T_ea3d9_row4_col3, #T_ea3d9_row4_col4, #T_ea3d9_row4_col5, #T_ea3d9_row4_col7, #T_ea3d9_row4_col10, #T_ea3d9_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row1_col11, #T_ea3d9_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #d55042;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dc5d4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea3d9_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea3d9_row4_col11, #T_ea3d9_row4_col12, #T_ea3d9_row4_col13, #T_ea3d9_row4_col14, #T_ea3d9_row4_col15, #T_ea3d9_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ea3d9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ea3d9_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_ea3d9_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_ea3d9_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_ea3d9_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_ea3d9_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_ea3d9_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_ea3d9_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_ea3d9_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_ea3d9_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_ea3d9_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_ea3d9_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_ea3d9_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_ea3d9_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_ea3d9_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_ea3d9_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_ea3d9_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_ea3d9_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_ea3d9_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ea3d9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ea3d9_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_ea3d9_row0_col1\" class=\"data row0 col1\" >60000</td>\n",
       "      <td id=\"T_ea3d9_row0_col2\" class=\"data row0 col2\" >40.0</td>\n",
       "      <td id=\"T_ea3d9_row0_col3\" class=\"data row0 col3\" >39.4</td>\n",
       "      <td id=\"T_ea3d9_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_ea3d9_row0_col5\" class=\"data row0 col5\" >14.4</td>\n",
       "      <td id=\"T_ea3d9_row0_col6\" class=\"data row0 col6\" >32.4</td>\n",
       "      <td id=\"T_ea3d9_row0_col7\" class=\"data row0 col7\" >34.6</td>\n",
       "      <td id=\"T_ea3d9_row0_col8\" class=\"data row0 col8\" >7.8</td>\n",
       "      <td id=\"T_ea3d9_row0_col9\" class=\"data row0 col9\" >34.4</td>\n",
       "      <td id=\"T_ea3d9_row0_col10\" class=\"data row0 col10\" >11.4</td>\n",
       "      <td id=\"T_ea3d9_row0_col11\" class=\"data row0 col11\" >54.6</td>\n",
       "      <td id=\"T_ea3d9_row0_col12\" class=\"data row0 col12\" >326.7</td>\n",
       "      <td id=\"T_ea3d9_row0_col13\" class=\"data row0 col13\" >51.8</td>\n",
       "      <td id=\"T_ea3d9_row0_col14\" class=\"data row0 col14\" >38.8</td>\n",
       "      <td id=\"T_ea3d9_row0_col15\" class=\"data row0 col15\" >45.2</td>\n",
       "      <td id=\"T_ea3d9_row0_col16\" class=\"data row0 col16\" >52.7</td>\n",
       "      <td id=\"T_ea3d9_row0_col17\" class=\"data row0 col17\" >-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea3d9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ea3d9_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_ea3d9_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_ea3d9_row1_col2\" class=\"data row1 col2\" >39.6</td>\n",
       "      <td id=\"T_ea3d9_row1_col3\" class=\"data row1 col3\" >38.6</td>\n",
       "      <td id=\"T_ea3d9_row1_col4\" class=\"data row1 col4\" >6.2</td>\n",
       "      <td id=\"T_ea3d9_row1_col5\" class=\"data row1 col5\" >14.0</td>\n",
       "      <td id=\"T_ea3d9_row1_col6\" class=\"data row1 col6\" >32.3</td>\n",
       "      <td id=\"T_ea3d9_row1_col7\" class=\"data row1 col7\" >35.9</td>\n",
       "      <td id=\"T_ea3d9_row1_col8\" class=\"data row1 col8\" >7.5</td>\n",
       "      <td id=\"T_ea3d9_row1_col9\" class=\"data row1 col9\" >30.6</td>\n",
       "      <td id=\"T_ea3d9_row1_col10\" class=\"data row1 col10\" >11.0</td>\n",
       "      <td id=\"T_ea3d9_row1_col11\" class=\"data row1 col11\" >50.8</td>\n",
       "      <td id=\"T_ea3d9_row1_col12\" class=\"data row1 col12\" >302.1</td>\n",
       "      <td id=\"T_ea3d9_row1_col13\" class=\"data row1 col13\" >50.6</td>\n",
       "      <td id=\"T_ea3d9_row1_col14\" class=\"data row1 col14\" >35.2</td>\n",
       "      <td id=\"T_ea3d9_row1_col15\" class=\"data row1 col15\" >43.0</td>\n",
       "      <td id=\"T_ea3d9_row1_col16\" class=\"data row1 col16\" >49.8</td>\n",
       "      <td id=\"T_ea3d9_row1_col17\" class=\"data row1 col17\" >-15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea3d9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ea3d9_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_ea3d9_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_ea3d9_row2_col2\" class=\"data row2 col2\" >40.2</td>\n",
       "      <td id=\"T_ea3d9_row2_col3\" class=\"data row2 col3\" >37.6</td>\n",
       "      <td id=\"T_ea3d9_row2_col4\" class=\"data row2 col4\" >5.6</td>\n",
       "      <td id=\"T_ea3d9_row2_col5\" class=\"data row2 col5\" >14.0</td>\n",
       "      <td id=\"T_ea3d9_row2_col6\" class=\"data row2 col6\" >32.2</td>\n",
       "      <td id=\"T_ea3d9_row2_col7\" class=\"data row2 col7\" >33.5</td>\n",
       "      <td id=\"T_ea3d9_row2_col8\" class=\"data row2 col8\" >8.2</td>\n",
       "      <td id=\"T_ea3d9_row2_col9\" class=\"data row2 col9\" >32.7</td>\n",
       "      <td id=\"T_ea3d9_row2_col10\" class=\"data row2 col10\" >12.4</td>\n",
       "      <td id=\"T_ea3d9_row2_col11\" class=\"data row2 col11\" >50.4</td>\n",
       "      <td id=\"T_ea3d9_row2_col12\" class=\"data row2 col12\" >288.3</td>\n",
       "      <td id=\"T_ea3d9_row2_col13\" class=\"data row2 col13\" >49.6</td>\n",
       "      <td id=\"T_ea3d9_row2_col14\" class=\"data row2 col14\" >36.6</td>\n",
       "      <td id=\"T_ea3d9_row2_col15\" class=\"data row2 col15\" >43.1</td>\n",
       "      <td id=\"T_ea3d9_row2_col16\" class=\"data row2 col16\" >48.9</td>\n",
       "      <td id=\"T_ea3d9_row2_col17\" class=\"data row2 col17\" >-15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea3d9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ea3d9_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_ea3d9_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_ea3d9_row3_col2\" class=\"data row3 col2\" >39.0</td>\n",
       "      <td id=\"T_ea3d9_row3_col3\" class=\"data row3 col3\" >38.8</td>\n",
       "      <td id=\"T_ea3d9_row3_col4\" class=\"data row3 col4\" >6.4</td>\n",
       "      <td id=\"T_ea3d9_row3_col5\" class=\"data row3 col5\" >16.0</td>\n",
       "      <td id=\"T_ea3d9_row3_col6\" class=\"data row3 col6\" >29.9</td>\n",
       "      <td id=\"T_ea3d9_row3_col7\" class=\"data row3 col7\" >34.4</td>\n",
       "      <td id=\"T_ea3d9_row3_col8\" class=\"data row3 col8\" >8.0</td>\n",
       "      <td id=\"T_ea3d9_row3_col9\" class=\"data row3 col9\" >34.9</td>\n",
       "      <td id=\"T_ea3d9_row3_col10\" class=\"data row3 col10\" >13.2</td>\n",
       "      <td id=\"T_ea3d9_row3_col11\" class=\"data row3 col11\" >46.3</td>\n",
       "      <td id=\"T_ea3d9_row3_col12\" class=\"data row3 col12\" >279.4</td>\n",
       "      <td id=\"T_ea3d9_row3_col13\" class=\"data row3 col13\" >54.4</td>\n",
       "      <td id=\"T_ea3d9_row3_col14\" class=\"data row3 col14\" >36.0</td>\n",
       "      <td id=\"T_ea3d9_row3_col15\" class=\"data row3 col15\" >45.3</td>\n",
       "      <td id=\"T_ea3d9_row3_col16\" class=\"data row3 col16\" >48.7</td>\n",
       "      <td id=\"T_ea3d9_row3_col17\" class=\"data row3 col17\" >-13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea3d9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ea3d9_row4_col0\" class=\"data row4 col0\" >llama-7b</td>\n",
       "      <td id=\"T_ea3d9_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_ea3d9_row4_col2\" class=\"data row4 col2\" >31.8</td>\n",
       "      <td id=\"T_ea3d9_row4_col3\" class=\"data row4 col3\" >34.5</td>\n",
       "      <td id=\"T_ea3d9_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_ea3d9_row4_col5\" class=\"data row4 col5\" >11.8</td>\n",
       "      <td id=\"T_ea3d9_row4_col6\" class=\"data row4 col6\" >30.6</td>\n",
       "      <td id=\"T_ea3d9_row4_col7\" class=\"data row4 col7\" >32.7</td>\n",
       "      <td id=\"T_ea3d9_row4_col8\" class=\"data row4 col8\" >9.6</td>\n",
       "      <td id=\"T_ea3d9_row4_col9\" class=\"data row4 col9\" >38.4</td>\n",
       "      <td id=\"T_ea3d9_row4_col10\" class=\"data row4 col10\" >10.2</td>\n",
       "      <td id=\"T_ea3d9_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_ea3d9_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_ea3d9_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_ea3d9_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_ea3d9_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_ea3d9_row4_col16\" class=\"data row4 col16\" >22.8</td>\n",
       "      <td id=\"T_ea3d9_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf71772b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f5525 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_f5525_row0_col0, #T_f5525_row1_col0, #T_f5525_row2_col0, #T_f5525_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f5525_row0_col1, #T_f5525_row1_col1, #T_f5525_row2_col1, #T_f5525_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f5525_row0_col2, #T_f5525_row0_col3, #T_f5525_row0_col4, #T_f5525_row0_col5, #T_f5525_row0_col6, #T_f5525_row0_col7, #T_f5525_row0_col8, #T_f5525_row0_col9, #T_f5525_row0_col10, #T_f5525_row1_col2, #T_f5525_row1_col3, #T_f5525_row1_col4, #T_f5525_row1_col5, #T_f5525_row1_col6, #T_f5525_row1_col7, #T_f5525_row1_col8, #T_f5525_row1_col9, #T_f5525_row1_col10, #T_f5525_row3_col11, #T_f5525_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f5525_row0_col11, #T_f5525_row0_col12, #T_f5525_row0_col16, #T_f5525_row1_col11, #T_f5525_row2_col2, #T_f5525_row2_col3, #T_f5525_row2_col4, #T_f5525_row2_col5, #T_f5525_row2_col7, #T_f5525_row2_col10, #T_f5525_row3_col6, #T_f5525_row3_col8, #T_f5525_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f5525_row0_col13, #T_f5525_row0_col14, #T_f5525_row0_col15, #T_f5525_row0_col17, #T_f5525_row1_col13, #T_f5525_row1_col14, #T_f5525_row1_col15, #T_f5525_row1_col17, #T_f5525_row2_col6, #T_f5525_row2_col8, #T_f5525_row2_col9, #T_f5525_row2_col11, #T_f5525_row2_col12, #T_f5525_row2_col13, #T_f5525_row2_col14, #T_f5525_row2_col15, #T_f5525_row2_col17, #T_f5525_row3_col2, #T_f5525_row3_col3, #T_f5525_row3_col4, #T_f5525_row3_col5, #T_f5525_row3_col7, #T_f5525_row3_col10, #T_f5525_row3_col13, #T_f5525_row3_col14, #T_f5525_row3_col15, #T_f5525_row3_col16, #T_f5525_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f5525_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f5525_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #ba162b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f5525_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f5525\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5525_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_f5525_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_f5525_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_f5525_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_f5525_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_f5525_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_f5525_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_f5525_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_f5525_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_f5525_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_f5525_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_f5525_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_f5525_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_f5525_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_f5525_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_f5525_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_f5525_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_f5525_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5525_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f5525_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=80000:ep=2</td>\n",
       "      <td id=\"T_f5525_row0_col1\" class=\"data row0 col1\" >80000</td>\n",
       "      <td id=\"T_f5525_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_f5525_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "      <td id=\"T_f5525_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "      <td id=\"T_f5525_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_f5525_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_f5525_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_f5525_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_f5525_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "      <td id=\"T_f5525_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_f5525_row0_col11\" class=\"data row0 col11\" >49.0</td>\n",
       "      <td id=\"T_f5525_row0_col12\" class=\"data row0 col12\" >308.2</td>\n",
       "      <td id=\"T_f5525_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_f5525_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_f5525_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_f5525_row0_col16\" class=\"data row0 col16\" >178.6</td>\n",
       "      <td id=\"T_f5525_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5525_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f5525_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=80000:ep=2</td>\n",
       "      <td id=\"T_f5525_row1_col1\" class=\"data row1 col1\" >80000</td>\n",
       "      <td id=\"T_f5525_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_f5525_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_f5525_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_f5525_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_f5525_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_f5525_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_f5525_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_f5525_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_f5525_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_f5525_row1_col11\" class=\"data row1 col11\" >49.0</td>\n",
       "      <td id=\"T_f5525_row1_col12\" class=\"data row1 col12\" >303.2</td>\n",
       "      <td id=\"T_f5525_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_f5525_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_f5525_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_f5525_row1_col16\" class=\"data row1 col16\" >176.1</td>\n",
       "      <td id=\"T_f5525_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5525_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f5525_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_f5525_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_f5525_row2_col2\" class=\"data row2 col2\" >39.0</td>\n",
       "      <td id=\"T_f5525_row2_col3\" class=\"data row2 col3\" >38.8</td>\n",
       "      <td id=\"T_f5525_row2_col4\" class=\"data row2 col4\" >6.4</td>\n",
       "      <td id=\"T_f5525_row2_col5\" class=\"data row2 col5\" >16.0</td>\n",
       "      <td id=\"T_f5525_row2_col6\" class=\"data row2 col6\" >29.9</td>\n",
       "      <td id=\"T_f5525_row2_col7\" class=\"data row2 col7\" >34.4</td>\n",
       "      <td id=\"T_f5525_row2_col8\" class=\"data row2 col8\" >8.0</td>\n",
       "      <td id=\"T_f5525_row2_col9\" class=\"data row2 col9\" >34.9</td>\n",
       "      <td id=\"T_f5525_row2_col10\" class=\"data row2 col10\" >13.2</td>\n",
       "      <td id=\"T_f5525_row2_col11\" class=\"data row2 col11\" >46.3</td>\n",
       "      <td id=\"T_f5525_row2_col12\" class=\"data row2 col12\" >279.4</td>\n",
       "      <td id=\"T_f5525_row2_col13\" class=\"data row2 col13\" >54.4</td>\n",
       "      <td id=\"T_f5525_row2_col14\" class=\"data row2 col14\" >36.0</td>\n",
       "      <td id=\"T_f5525_row2_col15\" class=\"data row2 col15\" >45.3</td>\n",
       "      <td id=\"T_f5525_row2_col16\" class=\"data row2 col16\" >48.7</td>\n",
       "      <td id=\"T_f5525_row2_col17\" class=\"data row2 col17\" >-13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5525_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f5525_row3_col0\" class=\"data row3 col0\" >llama-7b</td>\n",
       "      <td id=\"T_f5525_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_f5525_row3_col2\" class=\"data row3 col2\" >31.8</td>\n",
       "      <td id=\"T_f5525_row3_col3\" class=\"data row3 col3\" >34.5</td>\n",
       "      <td id=\"T_f5525_row3_col4\" class=\"data row3 col4\" >5.4</td>\n",
       "      <td id=\"T_f5525_row3_col5\" class=\"data row3 col5\" >11.8</td>\n",
       "      <td id=\"T_f5525_row3_col6\" class=\"data row3 col6\" >30.6</td>\n",
       "      <td id=\"T_f5525_row3_col7\" class=\"data row3 col7\" >32.7</td>\n",
       "      <td id=\"T_f5525_row3_col8\" class=\"data row3 col8\" >9.6</td>\n",
       "      <td id=\"T_f5525_row3_col9\" class=\"data row3 col9\" >38.4</td>\n",
       "      <td id=\"T_f5525_row3_col10\" class=\"data row3 col10\" >10.2</td>\n",
       "      <td id=\"T_f5525_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_f5525_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_f5525_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_f5525_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_f5525_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_f5525_row3_col16\" class=\"data row3 col16\" >22.8</td>\n",
       "      <td id=\"T_f5525_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf7175090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d1a34 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_d1a34_row0_col0, #T_d1a34_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d1a34_row0_col1, #T_d1a34_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d1a34_row0_col2, #T_d1a34_row0_col3, #T_d1a34_row0_col4, #T_d1a34_row0_col5, #T_d1a34_row0_col7, #T_d1a34_row0_col10, #T_d1a34_row0_col16, #T_d1a34_row1_col6, #T_d1a34_row1_col8, #T_d1a34_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d1a34_row0_col6, #T_d1a34_row0_col8, #T_d1a34_row0_col9, #T_d1a34_row0_col11, #T_d1a34_row0_col12, #T_d1a34_row0_col13, #T_d1a34_row0_col14, #T_d1a34_row0_col15, #T_d1a34_row0_col17, #T_d1a34_row1_col2, #T_d1a34_row1_col3, #T_d1a34_row1_col4, #T_d1a34_row1_col5, #T_d1a34_row1_col7, #T_d1a34_row1_col10, #T_d1a34_row1_col11, #T_d1a34_row1_col12, #T_d1a34_row1_col13, #T_d1a34_row1_col14, #T_d1a34_row1_col15, #T_d1a34_row1_col16, #T_d1a34_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d1a34\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d1a34_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d1a34_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_d1a34_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d1a34_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d1a34_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_d1a34_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_d1a34_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_d1a34_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_d1a34_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d1a34_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d1a34_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d1a34_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_d1a34_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_d1a34_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_d1a34_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_d1a34_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_d1a34_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_d1a34_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d1a34_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d1a34_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_d1a34_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_d1a34_row0_col2\" class=\"data row0 col2\" >39.0</td>\n",
       "      <td id=\"T_d1a34_row0_col3\" class=\"data row0 col3\" >38.8</td>\n",
       "      <td id=\"T_d1a34_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_d1a34_row0_col5\" class=\"data row0 col5\" >16.0</td>\n",
       "      <td id=\"T_d1a34_row0_col6\" class=\"data row0 col6\" >29.9</td>\n",
       "      <td id=\"T_d1a34_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_d1a34_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_d1a34_row0_col9\" class=\"data row0 col9\" >34.9</td>\n",
       "      <td id=\"T_d1a34_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_d1a34_row0_col11\" class=\"data row0 col11\" >46.3</td>\n",
       "      <td id=\"T_d1a34_row0_col12\" class=\"data row0 col12\" >279.4</td>\n",
       "      <td id=\"T_d1a34_row0_col13\" class=\"data row0 col13\" >54.4</td>\n",
       "      <td id=\"T_d1a34_row0_col14\" class=\"data row0 col14\" >36.0</td>\n",
       "      <td id=\"T_d1a34_row0_col15\" class=\"data row0 col15\" >45.3</td>\n",
       "      <td id=\"T_d1a34_row0_col16\" class=\"data row0 col16\" >48.7</td>\n",
       "      <td id=\"T_d1a34_row0_col17\" class=\"data row0 col17\" >-13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1a34_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d1a34_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_d1a34_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_d1a34_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_d1a34_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_d1a34_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_d1a34_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_d1a34_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_d1a34_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_d1a34_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_d1a34_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_d1a34_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_d1a34_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_d1a34_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_d1a34_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_d1a34_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_d1a34_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_d1a34_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_d1a34_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf5bd8af0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_36fda td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_36fda_row0_col0, #T_36fda_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_36fda_row0_col1, #T_36fda_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_36fda_row0_col2, #T_36fda_row0_col3, #T_36fda_row0_col6, #T_36fda_row0_col10, #T_36fda_row0_col16, #T_36fda_row1_col4, #T_36fda_row1_col5, #T_36fda_row1_col7, #T_36fda_row1_col8, #T_36fda_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36fda_row0_col4, #T_36fda_row0_col5, #T_36fda_row0_col7, #T_36fda_row0_col8, #T_36fda_row0_col9, #T_36fda_row0_col11, #T_36fda_row0_col12, #T_36fda_row1_col2, #T_36fda_row1_col3, #T_36fda_row1_col6, #T_36fda_row1_col10, #T_36fda_row1_col11, #T_36fda_row1_col12, #T_36fda_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36fda_row0_col13, #T_36fda_row0_col14, #T_36fda_row0_col15, #T_36fda_row0_col17, #T_36fda_row1_col13, #T_36fda_row1_col14, #T_36fda_row1_col15, #T_36fda_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_36fda\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_36fda_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_36fda_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_36fda_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_36fda_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_36fda_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_36fda_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_36fda_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_36fda_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_36fda_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_36fda_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_36fda_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_36fda_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_36fda_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_36fda_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_36fda_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_36fda_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_36fda_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_36fda_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_36fda_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_36fda_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_36fda_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_36fda_row0_col2\" class=\"data row0 col2\" >42.2</td>\n",
       "      <td id=\"T_36fda_row0_col3\" class=\"data row0 col3\" >42.6</td>\n",
       "      <td id=\"T_36fda_row0_col4\" class=\"data row0 col4\" >4.0</td>\n",
       "      <td id=\"T_36fda_row0_col5\" class=\"data row0 col5\" >5.0</td>\n",
       "      <td id=\"T_36fda_row0_col6\" class=\"data row0 col6\" >33.6</td>\n",
       "      <td id=\"T_36fda_row0_col7\" class=\"data row0 col7\" >31.7</td>\n",
       "      <td id=\"T_36fda_row0_col8\" class=\"data row0 col8\" >7.2</td>\n",
       "      <td id=\"T_36fda_row0_col9\" class=\"data row0 col9\" >33.9</td>\n",
       "      <td id=\"T_36fda_row0_col10\" class=\"data row0 col10\" >10.8</td>\n",
       "      <td id=\"T_36fda_row0_col11\" class=\"data row0 col11\" >20.6</td>\n",
       "      <td id=\"T_36fda_row0_col12\" class=\"data row0 col12\" >146.4</td>\n",
       "      <td id=\"T_36fda_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_36fda_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_36fda_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_36fda_row0_col16\" class=\"data row0 col16\" >34.4</td>\n",
       "      <td id=\"T_36fda_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36fda_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_36fda_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_36fda_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_36fda_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_36fda_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_36fda_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_36fda_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_36fda_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_36fda_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_36fda_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_36fda_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_36fda_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_36fda_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_36fda_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_36fda_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_36fda_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_36fda_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_36fda_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_36fda_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf6ca6410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9caf3 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_9caf3_row0_col0, #T_9caf3_row1_col0, #T_9caf3_row2_col0, #T_9caf3_row3_col0, #T_9caf3_row4_col0, #T_9caf3_row5_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9caf3_row0_col1, #T_9caf3_row1_col1, #T_9caf3_row2_col1, #T_9caf3_row3_col1, #T_9caf3_row4_col1, #T_9caf3_row5_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9caf3_row0_col2, #T_9caf3_row0_col3, #T_9caf3_row0_col4, #T_9caf3_row0_col5, #T_9caf3_row0_col6, #T_9caf3_row0_col7, #T_9caf3_row0_col8, #T_9caf3_row0_col9, #T_9caf3_row0_col10, #T_9caf3_row0_col13, #T_9caf3_row0_col14, #T_9caf3_row0_col15, #T_9caf3_row0_col17, #T_9caf3_row2_col13, #T_9caf3_row2_col14, #T_9caf3_row2_col15, #T_9caf3_row2_col17, #T_9caf3_row5_col11, #T_9caf3_row5_col12, #T_9caf3_row5_col13, #T_9caf3_row5_col14, #T_9caf3_row5_col15, #T_9caf3_row5_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row0_col16, #T_9caf3_row1_col6, #T_9caf3_row1_col7, #T_9caf3_row1_col11, #T_9caf3_row1_col12, #T_9caf3_row1_col13, #T_9caf3_row1_col17, #T_9caf3_row2_col2, #T_9caf3_row2_col3, #T_9caf3_row2_col10, #T_9caf3_row3_col13, #T_9caf3_row3_col14, #T_9caf3_row3_col15, #T_9caf3_row5_col4, #T_9caf3_row5_col5, #T_9caf3_row5_col8, #T_9caf3_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row1_col2, #T_9caf3_row1_col3, #T_9caf3_row2_col4, #T_9caf3_row2_col5, #T_9caf3_row2_col7, #T_9caf3_row2_col9, #T_9caf3_row2_col11, #T_9caf3_row3_col8, #T_9caf3_row4_col4, #T_9caf3_row4_col10, #T_9caf3_row4_col12, #T_9caf3_row4_col13, #T_9caf3_row4_col14, #T_9caf3_row4_col15, #T_9caf3_row4_col17, #T_9caf3_row5_col6, #T_9caf3_row5_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row1_col4, #T_9caf3_row2_col6, #T_9caf3_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row3_col9, #T_9caf3_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9caf3_row5_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9caf3_row5_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9caf3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9caf3_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_9caf3_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_9caf3_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_9caf3_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_9caf3_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_9caf3_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_9caf3_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_9caf3_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_9caf3_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_9caf3_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_9caf3_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_9caf3_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_9caf3_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_9caf3_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_9caf3_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_9caf3_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_9caf3_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_9caf3_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9caf3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9caf3_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_9caf3_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_9caf3_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_9caf3_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "      <td id=\"T_9caf3_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "      <td id=\"T_9caf3_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_9caf3_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_9caf3_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_9caf3_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_9caf3_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "      <td id=\"T_9caf3_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_9caf3_row0_col11\" class=\"data row0 col11\" >23.8</td>\n",
       "      <td id=\"T_9caf3_row0_col12\" class=\"data row0 col12\" >148.6</td>\n",
       "      <td id=\"T_9caf3_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_9caf3_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_9caf3_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_9caf3_row0_col16\" class=\"data row0 col16\" >86.2</td>\n",
       "      <td id=\"T_9caf3_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9caf3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9caf3_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_9caf3_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_9caf3_row1_col2\" class=\"data row1 col2\" >27.3</td>\n",
       "      <td id=\"T_9caf3_row1_col3\" class=\"data row1 col3\" >30.3</td>\n",
       "      <td id=\"T_9caf3_row1_col4\" class=\"data row1 col4\" >5.0</td>\n",
       "      <td id=\"T_9caf3_row1_col5\" class=\"data row1 col5\" >9.8</td>\n",
       "      <td id=\"T_9caf3_row1_col6\" class=\"data row1 col6\" >34.8</td>\n",
       "      <td id=\"T_9caf3_row1_col7\" class=\"data row1 col7\" >33.4</td>\n",
       "      <td id=\"T_9caf3_row1_col8\" class=\"data row1 col8\" >7.8</td>\n",
       "      <td id=\"T_9caf3_row1_col9\" class=\"data row1 col9\" >37.4</td>\n",
       "      <td id=\"T_9caf3_row1_col10\" class=\"data row1 col10\" >9.6</td>\n",
       "      <td id=\"T_9caf3_row1_col11\" class=\"data row1 col11\" >25.3</td>\n",
       "      <td id=\"T_9caf3_row1_col12\" class=\"data row1 col12\" >161.5</td>\n",
       "      <td id=\"T_9caf3_row1_col13\" class=\"data row1 col13\" >40.6</td>\n",
       "      <td id=\"T_9caf3_row1_col14\" class=\"data row1 col14\" >27.5</td>\n",
       "      <td id=\"T_9caf3_row1_col15\" class=\"data row1 col15\" >34.1</td>\n",
       "      <td id=\"T_9caf3_row1_col16\" class=\"data row1 col16\" >34.6</td>\n",
       "      <td id=\"T_9caf3_row1_col17\" class=\"data row1 col17\" >-33.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9caf3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9caf3_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_9caf3_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_9caf3_row2_col2\" class=\"data row2 col2\" >42.2</td>\n",
       "      <td id=\"T_9caf3_row2_col3\" class=\"data row2 col3\" >42.6</td>\n",
       "      <td id=\"T_9caf3_row2_col4\" class=\"data row2 col4\" >4.0</td>\n",
       "      <td id=\"T_9caf3_row2_col5\" class=\"data row2 col5\" >5.0</td>\n",
       "      <td id=\"T_9caf3_row2_col6\" class=\"data row2 col6\" >33.6</td>\n",
       "      <td id=\"T_9caf3_row2_col7\" class=\"data row2 col7\" >31.7</td>\n",
       "      <td id=\"T_9caf3_row2_col8\" class=\"data row2 col8\" >7.2</td>\n",
       "      <td id=\"T_9caf3_row2_col9\" class=\"data row2 col9\" >33.9</td>\n",
       "      <td id=\"T_9caf3_row2_col10\" class=\"data row2 col10\" >10.8</td>\n",
       "      <td id=\"T_9caf3_row2_col11\" class=\"data row2 col11\" >20.6</td>\n",
       "      <td id=\"T_9caf3_row2_col12\" class=\"data row2 col12\" >146.4</td>\n",
       "      <td id=\"T_9caf3_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_9caf3_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_9caf3_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_9caf3_row2_col16\" class=\"data row2 col16\" >34.4</td>\n",
       "      <td id=\"T_9caf3_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9caf3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9caf3_row3_col0\" class=\"data row3 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_9caf3_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_9caf3_row3_col2\" class=\"data row3 col2\" >35.6</td>\n",
       "      <td id=\"T_9caf3_row3_col3\" class=\"data row3 col3\" >38.3</td>\n",
       "      <td id=\"T_9caf3_row3_col4\" class=\"data row3 col4\" >5.0</td>\n",
       "      <td id=\"T_9caf3_row3_col5\" class=\"data row3 col5\" >5.2</td>\n",
       "      <td id=\"T_9caf3_row3_col6\" class=\"data row3 col6\" >31.3</td>\n",
       "      <td id=\"T_9caf3_row3_col7\" class=\"data row3 col7\" >31.9</td>\n",
       "      <td id=\"T_9caf3_row3_col8\" class=\"data row3 col8\" >7.1</td>\n",
       "      <td id=\"T_9caf3_row3_col9\" class=\"data row3 col9\" >35.8</td>\n",
       "      <td id=\"T_9caf3_row3_col10\" class=\"data row3 col10\" >8.7</td>\n",
       "      <td id=\"T_9caf3_row3_col11\" class=\"data row3 col11\" >24.7</td>\n",
       "      <td id=\"T_9caf3_row3_col12\" class=\"data row3 col12\" >137.7</td>\n",
       "      <td id=\"T_9caf3_row3_col13\" class=\"data row3 col13\" >40.6</td>\n",
       "      <td id=\"T_9caf3_row3_col14\" class=\"data row3 col14\" >27.7</td>\n",
       "      <td id=\"T_9caf3_row3_col15\" class=\"data row3 col15\" >34.3</td>\n",
       "      <td id=\"T_9caf3_row3_col16\" class=\"data row3 col16\" >33.1</td>\n",
       "      <td id=\"T_9caf3_row3_col17\" class=\"data row3 col17\" >-34.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9caf3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_9caf3_row4_col0\" class=\"data row4 col0\" >llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_9caf3_row4_col1\" class=\"data row4 col1\" >30000</td>\n",
       "      <td id=\"T_9caf3_row4_col2\" class=\"data row4 col2\" >30.9</td>\n",
       "      <td id=\"T_9caf3_row4_col3\" class=\"data row4 col3\" >33.6</td>\n",
       "      <td id=\"T_9caf3_row4_col4\" class=\"data row4 col4\" >4.0</td>\n",
       "      <td id=\"T_9caf3_row4_col5\" class=\"data row4 col5\" >5.6</td>\n",
       "      <td id=\"T_9caf3_row4_col6\" class=\"data row4 col6\" >34.5</td>\n",
       "      <td id=\"T_9caf3_row4_col7\" class=\"data row4 col7\" >32.3</td>\n",
       "      <td id=\"T_9caf3_row4_col8\" class=\"data row4 col8\" >7.9</td>\n",
       "      <td id=\"T_9caf3_row4_col9\" class=\"data row4 col9\" >36.8</td>\n",
       "      <td id=\"T_9caf3_row4_col10\" class=\"data row4 col10\" >8.5</td>\n",
       "      <td id=\"T_9caf3_row4_col11\" class=\"data row4 col11\" >22.4</td>\n",
       "      <td id=\"T_9caf3_row4_col12\" class=\"data row4 col12\" >121.3</td>\n",
       "      <td id=\"T_9caf3_row4_col13\" class=\"data row4 col13\" >39.5</td>\n",
       "      <td id=\"T_9caf3_row4_col14\" class=\"data row4 col14\" >26.6</td>\n",
       "      <td id=\"T_9caf3_row4_col15\" class=\"data row4 col15\" >33.1</td>\n",
       "      <td id=\"T_9caf3_row4_col16\" class=\"data row4 col16\" >31.2</td>\n",
       "      <td id=\"T_9caf3_row4_col17\" class=\"data row4 col17\" >-37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9caf3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_9caf3_row5_col0\" class=\"data row5 col0\" >llama-7b</td>\n",
       "      <td id=\"T_9caf3_row5_col1\" class=\"data row5 col1\" >None</td>\n",
       "      <td id=\"T_9caf3_row5_col2\" class=\"data row5 col2\" >31.8</td>\n",
       "      <td id=\"T_9caf3_row5_col3\" class=\"data row5 col3\" >34.5</td>\n",
       "      <td id=\"T_9caf3_row5_col4\" class=\"data row5 col4\" >5.4</td>\n",
       "      <td id=\"T_9caf3_row5_col5\" class=\"data row5 col5\" >11.8</td>\n",
       "      <td id=\"T_9caf3_row5_col6\" class=\"data row5 col6\" >30.6</td>\n",
       "      <td id=\"T_9caf3_row5_col7\" class=\"data row5 col7\" >32.7</td>\n",
       "      <td id=\"T_9caf3_row5_col8\" class=\"data row5 col8\" >9.6</td>\n",
       "      <td id=\"T_9caf3_row5_col9\" class=\"data row5 col9\" >38.4</td>\n",
       "      <td id=\"T_9caf3_row5_col10\" class=\"data row5 col10\" >10.2</td>\n",
       "      <td id=\"T_9caf3_row5_col11\" class=\"data row5 col11\" >nan</td>\n",
       "      <td id=\"T_9caf3_row5_col12\" class=\"data row5 col12\" >nan</td>\n",
       "      <td id=\"T_9caf3_row5_col13\" class=\"data row5 col13\" >nan</td>\n",
       "      <td id=\"T_9caf3_row5_col14\" class=\"data row5 col14\" >nan</td>\n",
       "      <td id=\"T_9caf3_row5_col15\" class=\"data row5 col15\" >nan</td>\n",
       "      <td id=\"T_9caf3_row5_col16\" class=\"data row5 col16\" >22.8</td>\n",
       "      <td id=\"T_9caf3_row5_col17\" class=\"data row5 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfd21b100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0e44b td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_0e44b_row0_col0, #T_0e44b_row1_col0, #T_0e44b_row2_col0, #T_0e44b_row3_col0, #T_0e44b_row4_col0, #T_0e44b_row5_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0e44b_row0_col1, #T_0e44b_row1_col1, #T_0e44b_row2_col1, #T_0e44b_row3_col1, #T_0e44b_row4_col1, #T_0e44b_row5_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0e44b_row0_col2, #T_0e44b_row0_col3, #T_0e44b_row0_col4, #T_0e44b_row0_col5, #T_0e44b_row0_col6, #T_0e44b_row0_col7, #T_0e44b_row0_col8, #T_0e44b_row0_col9, #T_0e44b_row0_col10, #T_0e44b_row0_col13, #T_0e44b_row0_col14, #T_0e44b_row0_col15, #T_0e44b_row0_col17, #T_0e44b_row1_col2, #T_0e44b_row1_col3, #T_0e44b_row1_col4, #T_0e44b_row1_col5, #T_0e44b_row1_col6, #T_0e44b_row1_col7, #T_0e44b_row1_col8, #T_0e44b_row1_col9, #T_0e44b_row1_col10, #T_0e44b_row1_col13, #T_0e44b_row1_col14, #T_0e44b_row1_col15, #T_0e44b_row1_col17, #T_0e44b_row2_col2, #T_0e44b_row2_col3, #T_0e44b_row2_col4, #T_0e44b_row2_col5, #T_0e44b_row2_col6, #T_0e44b_row2_col7, #T_0e44b_row2_col8, #T_0e44b_row2_col9, #T_0e44b_row2_col10, #T_0e44b_row2_col13, #T_0e44b_row2_col14, #T_0e44b_row2_col15, #T_0e44b_row2_col17, #T_0e44b_row3_col2, #T_0e44b_row3_col3, #T_0e44b_row3_col4, #T_0e44b_row3_col5, #T_0e44b_row3_col6, #T_0e44b_row3_col7, #T_0e44b_row3_col8, #T_0e44b_row3_col9, #T_0e44b_row3_col10, #T_0e44b_row3_col13, #T_0e44b_row3_col14, #T_0e44b_row3_col15, #T_0e44b_row3_col17, #T_0e44b_row4_col13, #T_0e44b_row4_col14, #T_0e44b_row4_col15, #T_0e44b_row4_col17, #T_0e44b_row5_col11, #T_0e44b_row5_col12, #T_0e44b_row5_col13, #T_0e44b_row5_col14, #T_0e44b_row5_col15, #T_0e44b_row5_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0e44b_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0e44b_row0_col12, #T_0e44b_row0_col16, #T_0e44b_row2_col11, #T_0e44b_row4_col2, #T_0e44b_row4_col3, #T_0e44b_row4_col6, #T_0e44b_row4_col10, #T_0e44b_row5_col4, #T_0e44b_row5_col5, #T_0e44b_row5_col7, #T_0e44b_row5_col8, #T_0e44b_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0e44b_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e44b_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e44b_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0e44b_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0e44b_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0e44b_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e44b_row3_col12, #T_0e44b_row4_col4, #T_0e44b_row4_col5, #T_0e44b_row4_col7, #T_0e44b_row4_col8, #T_0e44b_row4_col9, #T_0e44b_row4_col11, #T_0e44b_row5_col2, #T_0e44b_row5_col3, #T_0e44b_row5_col6, #T_0e44b_row5_col10, #T_0e44b_row5_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0e44b_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0e44b_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e44b_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0e44b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0e44b_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_0e44b_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_0e44b_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_0e44b_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_0e44b_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_0e44b_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_0e44b_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_0e44b_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_0e44b_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_0e44b_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_0e44b_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_0e44b_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_0e44b_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_0e44b_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_0e44b_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_0e44b_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_0e44b_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_0e44b_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0e44b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0e44b_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_0e44b_row0_col1\" class=\"data row0 col1\" >60000</td>\n",
       "      <td id=\"T_0e44b_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_0e44b_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "      <td id=\"T_0e44b_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "      <td id=\"T_0e44b_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_0e44b_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_0e44b_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_0e44b_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_0e44b_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "      <td id=\"T_0e44b_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_0e44b_row0_col11\" class=\"data row0 col11\" >25.6</td>\n",
       "      <td id=\"T_0e44b_row0_col12\" class=\"data row0 col12\" >164.8</td>\n",
       "      <td id=\"T_0e44b_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_0e44b_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_0e44b_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_0e44b_row0_col16\" class=\"data row0 col16\" >95.2</td>\n",
       "      <td id=\"T_0e44b_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e44b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0e44b_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_0e44b_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_0e44b_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_0e44b_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_0e44b_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_0e44b_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_0e44b_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_0e44b_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_0e44b_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_0e44b_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_0e44b_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_0e44b_row1_col11\" class=\"data row1 col11\" >22.4</td>\n",
       "      <td id=\"T_0e44b_row1_col12\" class=\"data row1 col12\" >143.2</td>\n",
       "      <td id=\"T_0e44b_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_0e44b_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_0e44b_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_0e44b_row1_col16\" class=\"data row1 col16\" >82.8</td>\n",
       "      <td id=\"T_0e44b_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e44b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0e44b_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_0e44b_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_0e44b_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_0e44b_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_0e44b_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "      <td id=\"T_0e44b_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_0e44b_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "      <td id=\"T_0e44b_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_0e44b_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_0e44b_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_0e44b_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_0e44b_row2_col11\" class=\"data row2 col11\" >25.7</td>\n",
       "      <td id=\"T_0e44b_row2_col12\" class=\"data row2 col12\" >136.5</td>\n",
       "      <td id=\"T_0e44b_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_0e44b_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_0e44b_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_0e44b_row2_col16\" class=\"data row2 col16\" >81.1</td>\n",
       "      <td id=\"T_0e44b_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e44b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0e44b_row3_col0\" class=\"data row3 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_0e44b_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_0e44b_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
       "      <td id=\"T_0e44b_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
       "      <td id=\"T_0e44b_row3_col4\" class=\"data row3 col4\" >nan</td>\n",
       "      <td id=\"T_0e44b_row3_col5\" class=\"data row3 col5\" >nan</td>\n",
       "      <td id=\"T_0e44b_row3_col6\" class=\"data row3 col6\" >nan</td>\n",
       "      <td id=\"T_0e44b_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "      <td id=\"T_0e44b_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
       "      <td id=\"T_0e44b_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
       "      <td id=\"T_0e44b_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
       "      <td id=\"T_0e44b_row3_col11\" class=\"data row3 col11\" >23.4</td>\n",
       "      <td id=\"T_0e44b_row3_col12\" class=\"data row3 col12\" >135.6</td>\n",
       "      <td id=\"T_0e44b_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_0e44b_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_0e44b_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_0e44b_row3_col16\" class=\"data row3 col16\" >79.5</td>\n",
       "      <td id=\"T_0e44b_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e44b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0e44b_row4_col0\" class=\"data row4 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_0e44b_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_0e44b_row4_col2\" class=\"data row4 col2\" >42.2</td>\n",
       "      <td id=\"T_0e44b_row4_col3\" class=\"data row4 col3\" >42.6</td>\n",
       "      <td id=\"T_0e44b_row4_col4\" class=\"data row4 col4\" >4.0</td>\n",
       "      <td id=\"T_0e44b_row4_col5\" class=\"data row4 col5\" >5.0</td>\n",
       "      <td id=\"T_0e44b_row4_col6\" class=\"data row4 col6\" >33.6</td>\n",
       "      <td id=\"T_0e44b_row4_col7\" class=\"data row4 col7\" >31.7</td>\n",
       "      <td id=\"T_0e44b_row4_col8\" class=\"data row4 col8\" >7.2</td>\n",
       "      <td id=\"T_0e44b_row4_col9\" class=\"data row4 col9\" >33.9</td>\n",
       "      <td id=\"T_0e44b_row4_col10\" class=\"data row4 col10\" >10.8</td>\n",
       "      <td id=\"T_0e44b_row4_col11\" class=\"data row4 col11\" >20.6</td>\n",
       "      <td id=\"T_0e44b_row4_col12\" class=\"data row4 col12\" >146.4</td>\n",
       "      <td id=\"T_0e44b_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_0e44b_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_0e44b_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_0e44b_row4_col16\" class=\"data row4 col16\" >34.4</td>\n",
       "      <td id=\"T_0e44b_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e44b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_0e44b_row5_col0\" class=\"data row5 col0\" >llama-7b</td>\n",
       "      <td id=\"T_0e44b_row5_col1\" class=\"data row5 col1\" >None</td>\n",
       "      <td id=\"T_0e44b_row5_col2\" class=\"data row5 col2\" >31.8</td>\n",
       "      <td id=\"T_0e44b_row5_col3\" class=\"data row5 col3\" >34.5</td>\n",
       "      <td id=\"T_0e44b_row5_col4\" class=\"data row5 col4\" >5.4</td>\n",
       "      <td id=\"T_0e44b_row5_col5\" class=\"data row5 col5\" >11.8</td>\n",
       "      <td id=\"T_0e44b_row5_col6\" class=\"data row5 col6\" >30.6</td>\n",
       "      <td id=\"T_0e44b_row5_col7\" class=\"data row5 col7\" >32.7</td>\n",
       "      <td id=\"T_0e44b_row5_col8\" class=\"data row5 col8\" >9.6</td>\n",
       "      <td id=\"T_0e44b_row5_col9\" class=\"data row5 col9\" >38.4</td>\n",
       "      <td id=\"T_0e44b_row5_col10\" class=\"data row5 col10\" >10.2</td>\n",
       "      <td id=\"T_0e44b_row5_col11\" class=\"data row5 col11\" >nan</td>\n",
       "      <td id=\"T_0e44b_row5_col12\" class=\"data row5 col12\" >nan</td>\n",
       "      <td id=\"T_0e44b_row5_col13\" class=\"data row5 col13\" >nan</td>\n",
       "      <td id=\"T_0e44b_row5_col14\" class=\"data row5 col14\" >nan</td>\n",
       "      <td id=\"T_0e44b_row5_col15\" class=\"data row5 col15\" >nan</td>\n",
       "      <td id=\"T_0e44b_row5_col16\" class=\"data row5 col16\" >22.8</td>\n",
       "      <td id=\"T_0e44b_row5_col17\" class=\"data row5 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf682b070>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_656ee td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_656ee_row0_col0, #T_656ee_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_656ee_row0_col1, #T_656ee_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_656ee_row0_col2, #T_656ee_row0_col3, #T_656ee_row0_col6, #T_656ee_row0_col10, #T_656ee_row0_col16, #T_656ee_row1_col4, #T_656ee_row1_col5, #T_656ee_row1_col7, #T_656ee_row1_col8, #T_656ee_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_656ee_row0_col4, #T_656ee_row0_col5, #T_656ee_row0_col7, #T_656ee_row0_col8, #T_656ee_row0_col9, #T_656ee_row0_col11, #T_656ee_row0_col12, #T_656ee_row1_col2, #T_656ee_row1_col3, #T_656ee_row1_col6, #T_656ee_row1_col10, #T_656ee_row1_col11, #T_656ee_row1_col12, #T_656ee_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_656ee_row0_col13, #T_656ee_row0_col14, #T_656ee_row0_col15, #T_656ee_row0_col17, #T_656ee_row1_col13, #T_656ee_row1_col14, #T_656ee_row1_col15, #T_656ee_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_656ee\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_656ee_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_656ee_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_656ee_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_656ee_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_656ee_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_656ee_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_656ee_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_656ee_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_656ee_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_656ee_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_656ee_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_656ee_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_656ee_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_656ee_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_656ee_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_656ee_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_656ee_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_656ee_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_656ee_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_656ee_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_656ee_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_656ee_row0_col2\" class=\"data row0 col2\" >42.2</td>\n",
       "      <td id=\"T_656ee_row0_col3\" class=\"data row0 col3\" >42.6</td>\n",
       "      <td id=\"T_656ee_row0_col4\" class=\"data row0 col4\" >4.0</td>\n",
       "      <td id=\"T_656ee_row0_col5\" class=\"data row0 col5\" >5.0</td>\n",
       "      <td id=\"T_656ee_row0_col6\" class=\"data row0 col6\" >33.6</td>\n",
       "      <td id=\"T_656ee_row0_col7\" class=\"data row0 col7\" >31.7</td>\n",
       "      <td id=\"T_656ee_row0_col8\" class=\"data row0 col8\" >7.2</td>\n",
       "      <td id=\"T_656ee_row0_col9\" class=\"data row0 col9\" >33.9</td>\n",
       "      <td id=\"T_656ee_row0_col10\" class=\"data row0 col10\" >10.8</td>\n",
       "      <td id=\"T_656ee_row0_col11\" class=\"data row0 col11\" >20.6</td>\n",
       "      <td id=\"T_656ee_row0_col12\" class=\"data row0 col12\" >146.4</td>\n",
       "      <td id=\"T_656ee_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_656ee_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_656ee_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_656ee_row0_col16\" class=\"data row0 col16\" >34.4</td>\n",
       "      <td id=\"T_656ee_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_656ee_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_656ee_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_656ee_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_656ee_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_656ee_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_656ee_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_656ee_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_656ee_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_656ee_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_656ee_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_656ee_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_656ee_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_656ee_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_656ee_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_656ee_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_656ee_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_656ee_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_656ee_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_656ee_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf5bdb160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6018a td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_6018a_row0_col0, #T_6018a_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6018a_row0_col1, #T_6018a_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6018a_row0_col2, #T_6018a_row0_col3, #T_6018a_row0_col6, #T_6018a_row0_col10, #T_6018a_row0_col16, #T_6018a_row1_col4, #T_6018a_row1_col5, #T_6018a_row1_col7, #T_6018a_row1_col8, #T_6018a_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6018a_row0_col4, #T_6018a_row0_col5, #T_6018a_row0_col7, #T_6018a_row0_col8, #T_6018a_row0_col9, #T_6018a_row0_col11, #T_6018a_row0_col12, #T_6018a_row1_col2, #T_6018a_row1_col3, #T_6018a_row1_col6, #T_6018a_row1_col10, #T_6018a_row1_col11, #T_6018a_row1_col12, #T_6018a_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6018a_row0_col13, #T_6018a_row0_col14, #T_6018a_row0_col15, #T_6018a_row0_col17, #T_6018a_row1_col13, #T_6018a_row1_col14, #T_6018a_row1_col15, #T_6018a_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6018a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6018a_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_6018a_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_6018a_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_6018a_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_6018a_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_6018a_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_6018a_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_6018a_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_6018a_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_6018a_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_6018a_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_6018a_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_6018a_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_6018a_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_6018a_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_6018a_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_6018a_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_6018a_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6018a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6018a_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_6018a_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_6018a_row0_col2\" class=\"data row0 col2\" >42.2</td>\n",
       "      <td id=\"T_6018a_row0_col3\" class=\"data row0 col3\" >42.6</td>\n",
       "      <td id=\"T_6018a_row0_col4\" class=\"data row0 col4\" >4.0</td>\n",
       "      <td id=\"T_6018a_row0_col5\" class=\"data row0 col5\" >5.0</td>\n",
       "      <td id=\"T_6018a_row0_col6\" class=\"data row0 col6\" >33.6</td>\n",
       "      <td id=\"T_6018a_row0_col7\" class=\"data row0 col7\" >31.7</td>\n",
       "      <td id=\"T_6018a_row0_col8\" class=\"data row0 col8\" >7.2</td>\n",
       "      <td id=\"T_6018a_row0_col9\" class=\"data row0 col9\" >33.9</td>\n",
       "      <td id=\"T_6018a_row0_col10\" class=\"data row0 col10\" >10.8</td>\n",
       "      <td id=\"T_6018a_row0_col11\" class=\"data row0 col11\" >20.6</td>\n",
       "      <td id=\"T_6018a_row0_col12\" class=\"data row0 col12\" >146.4</td>\n",
       "      <td id=\"T_6018a_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_6018a_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_6018a_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_6018a_row0_col16\" class=\"data row0 col16\" >34.4</td>\n",
       "      <td id=\"T_6018a_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6018a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6018a_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_6018a_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_6018a_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_6018a_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_6018a_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_6018a_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_6018a_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_6018a_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_6018a_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_6018a_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_6018a_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_6018a_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_6018a_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_6018a_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_6018a_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_6018a_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_6018a_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_6018a_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf4d67d60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fa8c1 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_fa8c1_row0_col0, #T_fa8c1_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fa8c1_row0_col1, #T_fa8c1_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fa8c1_row0_col2, #T_fa8c1_row0_col3, #T_fa8c1_row0_col4, #T_fa8c1_row0_col6, #T_fa8c1_row0_col7, #T_fa8c1_row0_col10, #T_fa8c1_row0_col16, #T_fa8c1_row1_col5, #T_fa8c1_row1_col8, #T_fa8c1_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa8c1_row0_col5, #T_fa8c1_row0_col8, #T_fa8c1_row0_col9, #T_fa8c1_row0_col11, #T_fa8c1_row0_col12, #T_fa8c1_row1_col2, #T_fa8c1_row1_col3, #T_fa8c1_row1_col4, #T_fa8c1_row1_col6, #T_fa8c1_row1_col7, #T_fa8c1_row1_col10, #T_fa8c1_row1_col11, #T_fa8c1_row1_col12, #T_fa8c1_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa8c1_row0_col13, #T_fa8c1_row0_col14, #T_fa8c1_row0_col15, #T_fa8c1_row0_col17, #T_fa8c1_row1_col13, #T_fa8c1_row1_col14, #T_fa8c1_row1_col15, #T_fa8c1_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fa8c1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fa8c1_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_fa8c1_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_fa8c1_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_fa8c1_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_fa8c1_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_fa8c1_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_fa8c1_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_fa8c1_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_fa8c1_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_fa8c1_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_fa8c1_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_fa8c1_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_fa8c1_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_fa8c1_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_fa8c1_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_fa8c1_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_fa8c1_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_fa8c1_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fa8c1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fa8c1_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_fa8c1_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_fa8c1_row0_col2\" class=\"data row0 col2\" >38.4</td>\n",
       "      <td id=\"T_fa8c1_row0_col3\" class=\"data row0 col3\" >36.5</td>\n",
       "      <td id=\"T_fa8c1_row0_col4\" class=\"data row0 col4\" >6.6</td>\n",
       "      <td id=\"T_fa8c1_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_fa8c1_row0_col6\" class=\"data row0 col6\" >31.3</td>\n",
       "      <td id=\"T_fa8c1_row0_col7\" class=\"data row0 col7\" >34.1</td>\n",
       "      <td id=\"T_fa8c1_row0_col8\" class=\"data row0 col8\" >7.9</td>\n",
       "      <td id=\"T_fa8c1_row0_col9\" class=\"data row0 col9\" >33.3</td>\n",
       "      <td id=\"T_fa8c1_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_fa8c1_row0_col11\" class=\"data row0 col11\" >48.5</td>\n",
       "      <td id=\"T_fa8c1_row0_col12\" class=\"data row0 col12\" >252.2</td>\n",
       "      <td id=\"T_fa8c1_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_fa8c1_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_fa8c1_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_fa8c1_row0_col16\" class=\"data row0 col16\" >46.5</td>\n",
       "      <td id=\"T_fa8c1_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fa8c1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fa8c1_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_fa8c1_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_fa8c1_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_fa8c1_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_fa8c1_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_fa8c1_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_fa8c1_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_fa8c1_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_fa8c1_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_fa8c1_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_fa8c1_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_fa8c1_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_fa8c1_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_fa8c1_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_fa8c1_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_fa8c1_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_fa8c1_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_fa8c1_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf4d67700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_45522 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_45522_row0_col0, #T_45522_row1_col0, #T_45522_row2_col0, #T_45522_row3_col0, #T_45522_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_45522_row0_col1, #T_45522_row1_col1, #T_45522_row2_col1, #T_45522_row3_col1, #T_45522_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_45522_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row0_col3, #T_45522_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row0_col4, #T_45522_row0_col16, #T_45522_row1_col13, #T_45522_row1_col14, #T_45522_row1_col15, #T_45522_row1_col17, #T_45522_row2_col2, #T_45522_row2_col3, #T_45522_row2_col7, #T_45522_row2_col12, #T_45522_row3_col6, #T_45522_row3_col10, #T_45522_row3_col11, #T_45522_row4_col5, #T_45522_row4_col8, #T_45522_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row0_col5, #T_45522_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row0_col8, #T_45522_row0_col12, #T_45522_row1_col5, #T_45522_row2_col5, #T_45522_row2_col9, #T_45522_row2_col10, #T_45522_row2_col11, #T_45522_row3_col4, #T_45522_row3_col13, #T_45522_row3_col14, #T_45522_row3_col15, #T_45522_row3_col17, #T_45522_row4_col2, #T_45522_row4_col3, #T_45522_row4_col6, #T_45522_row4_col7, #T_45522_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row0_col13, #T_45522_row0_col14, #T_45522_row0_col15, #T_45522_row0_col17, #T_45522_row4_col11, #T_45522_row4_col12, #T_45522_row4_col13, #T_45522_row4_col14, #T_45522_row4_col15, #T_45522_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row1_col9, #T_45522_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_45522_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_45522_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_45522\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_45522_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_45522_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_45522_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_45522_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_45522_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_45522_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_45522_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_45522_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_45522_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_45522_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_45522_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_45522_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_45522_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_45522_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_45522_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_45522_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_45522_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_45522_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_45522_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_45522_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_45522_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_45522_row0_col2\" class=\"data row0 col2\" >38.4</td>\n",
       "      <td id=\"T_45522_row0_col3\" class=\"data row0 col3\" >36.5</td>\n",
       "      <td id=\"T_45522_row0_col4\" class=\"data row0 col4\" >6.6</td>\n",
       "      <td id=\"T_45522_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_45522_row0_col6\" class=\"data row0 col6\" >31.3</td>\n",
       "      <td id=\"T_45522_row0_col7\" class=\"data row0 col7\" >34.1</td>\n",
       "      <td id=\"T_45522_row0_col8\" class=\"data row0 col8\" >7.9</td>\n",
       "      <td id=\"T_45522_row0_col9\" class=\"data row0 col9\" >33.3</td>\n",
       "      <td id=\"T_45522_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_45522_row0_col11\" class=\"data row0 col11\" >48.5</td>\n",
       "      <td id=\"T_45522_row0_col12\" class=\"data row0 col12\" >252.2</td>\n",
       "      <td id=\"T_45522_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_45522_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_45522_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_45522_row0_col16\" class=\"data row0 col16\" >46.5</td>\n",
       "      <td id=\"T_45522_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45522_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_45522_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_45522_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_45522_row1_col2\" class=\"data row1 col2\" >36.7</td>\n",
       "      <td id=\"T_45522_row1_col3\" class=\"data row1 col3\" >35.9</td>\n",
       "      <td id=\"T_45522_row1_col4\" class=\"data row1 col4\" >5.6</td>\n",
       "      <td id=\"T_45522_row1_col5\" class=\"data row1 col5\" >9.4</td>\n",
       "      <td id=\"T_45522_row1_col6\" class=\"data row1 col6\" >33.0</td>\n",
       "      <td id=\"T_45522_row1_col7\" class=\"data row1 col7\" >33.2</td>\n",
       "      <td id=\"T_45522_row1_col8\" class=\"data row1 col8\" >8.3</td>\n",
       "      <td id=\"T_45522_row1_col9\" class=\"data row1 col9\" >31.9</td>\n",
       "      <td id=\"T_45522_row1_col10\" class=\"data row1 col10\" >11.6</td>\n",
       "      <td id=\"T_45522_row1_col11\" class=\"data row1 col11\" >47.8</td>\n",
       "      <td id=\"T_45522_row1_col12\" class=\"data row1 col12\" >264.3</td>\n",
       "      <td id=\"T_45522_row1_col13\" class=\"data row1 col13\" >50.6</td>\n",
       "      <td id=\"T_45522_row1_col14\" class=\"data row1 col14\" >36.7</td>\n",
       "      <td id=\"T_45522_row1_col15\" class=\"data row1 col15\" >43.7</td>\n",
       "      <td id=\"T_45522_row1_col16\" class=\"data row1 col16\" >46.3</td>\n",
       "      <td id=\"T_45522_row1_col17\" class=\"data row1 col17\" >-21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45522_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_45522_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_45522_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_45522_row2_col2\" class=\"data row2 col2\" >38.7</td>\n",
       "      <td id=\"T_45522_row2_col3\" class=\"data row2 col3\" >37.5</td>\n",
       "      <td id=\"T_45522_row2_col4\" class=\"data row2 col4\" >6.4</td>\n",
       "      <td id=\"T_45522_row2_col5\" class=\"data row2 col5\" >9.4</td>\n",
       "      <td id=\"T_45522_row2_col6\" class=\"data row2 col6\" >32.8</td>\n",
       "      <td id=\"T_45522_row2_col7\" class=\"data row2 col7\" >35.1</td>\n",
       "      <td id=\"T_45522_row2_col8\" class=\"data row2 col8\" >9.1</td>\n",
       "      <td id=\"T_45522_row2_col9\" class=\"data row2 col9\" >30.3</td>\n",
       "      <td id=\"T_45522_row2_col10\" class=\"data row2 col10\" >8.9</td>\n",
       "      <td id=\"T_45522_row2_col11\" class=\"data row2 col11\" >44.8</td>\n",
       "      <td id=\"T_45522_row2_col12\" class=\"data row2 col12\" >270.1</td>\n",
       "      <td id=\"T_45522_row2_col13\" class=\"data row2 col13\" >44.9</td>\n",
       "      <td id=\"T_45522_row2_col14\" class=\"data row2 col14\" >33.0</td>\n",
       "      <td id=\"T_45522_row2_col15\" class=\"data row2 col15\" >38.9</td>\n",
       "      <td id=\"T_45522_row2_col16\" class=\"data row2 col16\" >45.7</td>\n",
       "      <td id=\"T_45522_row2_col17\" class=\"data row2 col17\" >-22.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45522_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_45522_row3_col0\" class=\"data row3 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_45522_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_45522_row3_col2\" class=\"data row3 col2\" >37.0</td>\n",
       "      <td id=\"T_45522_row3_col3\" class=\"data row3 col3\" >34.9</td>\n",
       "      <td id=\"T_45522_row3_col4\" class=\"data row3 col4\" >5.2</td>\n",
       "      <td id=\"T_45522_row3_col5\" class=\"data row3 col5\" >10.8</td>\n",
       "      <td id=\"T_45522_row3_col6\" class=\"data row3 col6\" >33.2</td>\n",
       "      <td id=\"T_45522_row3_col7\" class=\"data row3 col7\" >34.2</td>\n",
       "      <td id=\"T_45522_row3_col8\" class=\"data row3 col8\" >8.7</td>\n",
       "      <td id=\"T_45522_row3_col9\" class=\"data row3 col9\" >32.1</td>\n",
       "      <td id=\"T_45522_row3_col10\" class=\"data row3 col10\" >12.6</td>\n",
       "      <td id=\"T_45522_row3_col11\" class=\"data row3 col11\" >48.8</td>\n",
       "      <td id=\"T_45522_row3_col12\" class=\"data row3 col12\" >255.6</td>\n",
       "      <td id=\"T_45522_row3_col13\" class=\"data row3 col13\" >44.1</td>\n",
       "      <td id=\"T_45522_row3_col14\" class=\"data row3 col14\" >32.3</td>\n",
       "      <td id=\"T_45522_row3_col15\" class=\"data row3 col15\" >38.2</td>\n",
       "      <td id=\"T_45522_row3_col16\" class=\"data row3 col16\" >44.8</td>\n",
       "      <td id=\"T_45522_row3_col17\" class=\"data row3 col17\" >-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_45522_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_45522_row4_col0\" class=\"data row4 col0\" >llama-7b</td>\n",
       "      <td id=\"T_45522_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_45522_row4_col2\" class=\"data row4 col2\" >31.8</td>\n",
       "      <td id=\"T_45522_row4_col3\" class=\"data row4 col3\" >34.5</td>\n",
       "      <td id=\"T_45522_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_45522_row4_col5\" class=\"data row4 col5\" >11.8</td>\n",
       "      <td id=\"T_45522_row4_col6\" class=\"data row4 col6\" >30.6</td>\n",
       "      <td id=\"T_45522_row4_col7\" class=\"data row4 col7\" >32.7</td>\n",
       "      <td id=\"T_45522_row4_col8\" class=\"data row4 col8\" >9.6</td>\n",
       "      <td id=\"T_45522_row4_col9\" class=\"data row4 col9\" >38.4</td>\n",
       "      <td id=\"T_45522_row4_col10\" class=\"data row4 col10\" >10.2</td>\n",
       "      <td id=\"T_45522_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_45522_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_45522_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_45522_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_45522_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_45522_row4_col16\" class=\"data row4 col16\" >22.8</td>\n",
       "      <td id=\"T_45522_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf7175090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f2b32 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_f2b32_row0_col0, #T_f2b32_row1_col0, #T_f2b32_row2_col0, #T_f2b32_row3_col0, #T_f2b32_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f2b32_row0_col1, #T_f2b32_row1_col1, #T_f2b32_row2_col1, #T_f2b32_row3_col1, #T_f2b32_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f2b32_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row0_col4, #T_f2b32_row0_col10, #T_f2b32_row0_col12, #T_f2b32_row0_col16, #T_f2b32_row1_col7, #T_f2b32_row1_col11, #T_f2b32_row2_col3, #T_f2b32_row2_col13, #T_f2b32_row2_col15, #T_f2b32_row2_col17, #T_f2b32_row3_col2, #T_f2b32_row3_col6, #T_f2b32_row3_col14, #T_f2b32_row4_col5, #T_f2b32_row4_col8, #T_f2b32_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row0_col5, #T_f2b32_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row0_col8, #T_f2b32_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row0_col11, #T_f2b32_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row0_col13, #T_f2b32_row0_col14, #T_f2b32_row0_col15, #T_f2b32_row0_col17, #T_f2b32_row1_col13, #T_f2b32_row1_col14, #T_f2b32_row1_col15, #T_f2b32_row1_col17, #T_f2b32_row4_col11, #T_f2b32_row4_col12, #T_f2b32_row4_col13, #T_f2b32_row4_col14, #T_f2b32_row4_col15, #T_f2b32_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row1_col8, #T_f2b32_row1_col9, #T_f2b32_row2_col14, #T_f2b32_row3_col5, #T_f2b32_row3_col10, #T_f2b32_row3_col11, #T_f2b32_row3_col12, #T_f2b32_row3_col13, #T_f2b32_row3_col15, #T_f2b32_row3_col17, #T_f2b32_row4_col2, #T_f2b32_row4_col3, #T_f2b32_row4_col4, #T_f2b32_row4_col6, #T_f2b32_row4_col7, #T_f2b32_row4_col10, #T_f2b32_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row1_col12, #T_f2b32_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row2_col4, #T_f2b32_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dc5d4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2b32_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2b32_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f2b32\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f2b32_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_f2b32_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_f2b32_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_f2b32_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_f2b32_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_f2b32_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_f2b32_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_f2b32_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_f2b32_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_f2b32_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_f2b32_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_f2b32_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_f2b32_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_f2b32_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_f2b32_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_f2b32_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_f2b32_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_f2b32_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f2b32_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f2b32_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_f2b32_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_f2b32_row0_col2\" class=\"data row0 col2\" >38.4</td>\n",
       "      <td id=\"T_f2b32_row0_col3\" class=\"data row0 col3\" >36.5</td>\n",
       "      <td id=\"T_f2b32_row0_col4\" class=\"data row0 col4\" >6.6</td>\n",
       "      <td id=\"T_f2b32_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_f2b32_row0_col6\" class=\"data row0 col6\" >31.3</td>\n",
       "      <td id=\"T_f2b32_row0_col7\" class=\"data row0 col7\" >34.1</td>\n",
       "      <td id=\"T_f2b32_row0_col8\" class=\"data row0 col8\" >7.9</td>\n",
       "      <td id=\"T_f2b32_row0_col9\" class=\"data row0 col9\" >33.3</td>\n",
       "      <td id=\"T_f2b32_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_f2b32_row0_col11\" class=\"data row0 col11\" >48.5</td>\n",
       "      <td id=\"T_f2b32_row0_col12\" class=\"data row0 col12\" >252.2</td>\n",
       "      <td id=\"T_f2b32_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_f2b32_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_f2b32_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_f2b32_row0_col16\" class=\"data row0 col16\" >46.5</td>\n",
       "      <td id=\"T_f2b32_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2b32_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f2b32_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_f2b32_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_f2b32_row1_col2\" class=\"data row1 col2\" >37.9</td>\n",
       "      <td id=\"T_f2b32_row1_col3\" class=\"data row1 col3\" >35.1</td>\n",
       "      <td id=\"T_f2b32_row1_col4\" class=\"data row1 col4\" >6.2</td>\n",
       "      <td id=\"T_f2b32_row1_col5\" class=\"data row1 col5\" >11.0</td>\n",
       "      <td id=\"T_f2b32_row1_col6\" class=\"data row1 col6\" >32.6</td>\n",
       "      <td id=\"T_f2b32_row1_col7\" class=\"data row1 col7\" >34.2</td>\n",
       "      <td id=\"T_f2b32_row1_col8\" class=\"data row1 col8\" >7.5</td>\n",
       "      <td id=\"T_f2b32_row1_col9\" class=\"data row1 col9\" >30.0</td>\n",
       "      <td id=\"T_f2b32_row1_col10\" class=\"data row1 col10\" >10.8</td>\n",
       "      <td id=\"T_f2b32_row1_col11\" class=\"data row1 col11\" >50.7</td>\n",
       "      <td id=\"T_f2b32_row1_col12\" class=\"data row1 col12\" >251.4</td>\n",
       "      <td id=\"T_f2b32_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_f2b32_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_f2b32_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_f2b32_row1_col16\" class=\"data row1 col16\" >46.1</td>\n",
       "      <td id=\"T_f2b32_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2b32_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f2b32_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_f2b32_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_f2b32_row2_col2\" class=\"data row2 col2\" >37.3</td>\n",
       "      <td id=\"T_f2b32_row2_col3\" class=\"data row2 col3\" >36.6</td>\n",
       "      <td id=\"T_f2b32_row2_col4\" class=\"data row2 col4\" >5.8</td>\n",
       "      <td id=\"T_f2b32_row2_col5\" class=\"data row2 col5\" >10.6</td>\n",
       "      <td id=\"T_f2b32_row2_col6\" class=\"data row2 col6\" >32.7</td>\n",
       "      <td id=\"T_f2b32_row2_col7\" class=\"data row2 col7\" >33.1</td>\n",
       "      <td id=\"T_f2b32_row2_col8\" class=\"data row2 col8\" >7.9</td>\n",
       "      <td id=\"T_f2b32_row2_col9\" class=\"data row2 col9\" >30.4</td>\n",
       "      <td id=\"T_f2b32_row2_col10\" class=\"data row2 col10\" >11.2</td>\n",
       "      <td id=\"T_f2b32_row2_col11\" class=\"data row2 col11\" >48.9</td>\n",
       "      <td id=\"T_f2b32_row2_col12\" class=\"data row2 col12\" >247.5</td>\n",
       "      <td id=\"T_f2b32_row2_col13\" class=\"data row2 col13\" >50.4</td>\n",
       "      <td id=\"T_f2b32_row2_col14\" class=\"data row2 col14\" >37.5</td>\n",
       "      <td id=\"T_f2b32_row2_col15\" class=\"data row2 col15\" >44.0</td>\n",
       "      <td id=\"T_f2b32_row2_col16\" class=\"data row2 col16\" >45.3</td>\n",
       "      <td id=\"T_f2b32_row2_col17\" class=\"data row2 col17\" >-23.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2b32_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f2b32_row3_col0\" class=\"data row3 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_f2b32_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_f2b32_row3_col2\" class=\"data row3 col2\" >38.9</td>\n",
       "      <td id=\"T_f2b32_row3_col3\" class=\"data row3 col3\" >34.5</td>\n",
       "      <td id=\"T_f2b32_row3_col4\" class=\"data row3 col4\" >5.8</td>\n",
       "      <td id=\"T_f2b32_row3_col5\" class=\"data row3 col5\" >9.0</td>\n",
       "      <td id=\"T_f2b32_row3_col6\" class=\"data row3 col6\" >33.0</td>\n",
       "      <td id=\"T_f2b32_row3_col7\" class=\"data row3 col7\" >33.5</td>\n",
       "      <td id=\"T_f2b32_row3_col8\" class=\"data row3 col8\" >8.2</td>\n",
       "      <td id=\"T_f2b32_row3_col9\" class=\"data row3 col9\" >31.2</td>\n",
       "      <td id=\"T_f2b32_row3_col10\" class=\"data row3 col10\" >10.2</td>\n",
       "      <td id=\"T_f2b32_row3_col11\" class=\"data row3 col11\" >45.5</td>\n",
       "      <td id=\"T_f2b32_row3_col12\" class=\"data row3 col12\" >236.8</td>\n",
       "      <td id=\"T_f2b32_row3_col13\" class=\"data row3 col13\" >49.1</td>\n",
       "      <td id=\"T_f2b32_row3_col14\" class=\"data row3 col14\" >37.6</td>\n",
       "      <td id=\"T_f2b32_row3_col15\" class=\"data row3 col15\" >43.4</td>\n",
       "      <td id=\"T_f2b32_row3_col16\" class=\"data row3 col16\" >44.1</td>\n",
       "      <td id=\"T_f2b32_row3_col17\" class=\"data row3 col17\" >-24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2b32_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f2b32_row4_col0\" class=\"data row4 col0\" >llama-7b</td>\n",
       "      <td id=\"T_f2b32_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_f2b32_row4_col2\" class=\"data row4 col2\" >31.8</td>\n",
       "      <td id=\"T_f2b32_row4_col3\" class=\"data row4 col3\" >34.5</td>\n",
       "      <td id=\"T_f2b32_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_f2b32_row4_col5\" class=\"data row4 col5\" >11.8</td>\n",
       "      <td id=\"T_f2b32_row4_col6\" class=\"data row4 col6\" >30.6</td>\n",
       "      <td id=\"T_f2b32_row4_col7\" class=\"data row4 col7\" >32.7</td>\n",
       "      <td id=\"T_f2b32_row4_col8\" class=\"data row4 col8\" >9.6</td>\n",
       "      <td id=\"T_f2b32_row4_col9\" class=\"data row4 col9\" >38.4</td>\n",
       "      <td id=\"T_f2b32_row4_col10\" class=\"data row4 col10\" >10.2</td>\n",
       "      <td id=\"T_f2b32_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_f2b32_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_f2b32_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_f2b32_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_f2b32_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_f2b32_row4_col16\" class=\"data row4 col16\" >22.8</td>\n",
       "      <td id=\"T_f2b32_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf36ee3e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_13e1d td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_13e1d_row0_col0, #T_13e1d_row1_col0, #T_13e1d_row2_col0, #T_13e1d_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_13e1d_row0_col1, #T_13e1d_row1_col1, #T_13e1d_row2_col1, #T_13e1d_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_13e1d_row0_col2, #T_13e1d_row0_col3, #T_13e1d_row0_col4, #T_13e1d_row0_col5, #T_13e1d_row0_col6, #T_13e1d_row0_col7, #T_13e1d_row0_col8, #T_13e1d_row0_col9, #T_13e1d_row0_col10, #T_13e1d_row0_col13, #T_13e1d_row0_col14, #T_13e1d_row0_col15, #T_13e1d_row0_col17, #T_13e1d_row1_col2, #T_13e1d_row1_col3, #T_13e1d_row1_col4, #T_13e1d_row1_col5, #T_13e1d_row1_col6, #T_13e1d_row1_col7, #T_13e1d_row1_col8, #T_13e1d_row1_col9, #T_13e1d_row1_col10, #T_13e1d_row1_col13, #T_13e1d_row1_col14, #T_13e1d_row1_col15, #T_13e1d_row1_col17, #T_13e1d_row2_col13, #T_13e1d_row2_col14, #T_13e1d_row2_col15, #T_13e1d_row2_col17, #T_13e1d_row3_col11, #T_13e1d_row3_col12, #T_13e1d_row3_col13, #T_13e1d_row3_col14, #T_13e1d_row3_col15, #T_13e1d_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_13e1d_row0_col11, #T_13e1d_row2_col5, #T_13e1d_row2_col8, #T_13e1d_row2_col9, #T_13e1d_row2_col12, #T_13e1d_row3_col2, #T_13e1d_row3_col3, #T_13e1d_row3_col4, #T_13e1d_row3_col6, #T_13e1d_row3_col7, #T_13e1d_row3_col10, #T_13e1d_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_13e1d_row0_col12, #T_13e1d_row0_col16, #T_13e1d_row1_col11, #T_13e1d_row2_col2, #T_13e1d_row2_col3, #T_13e1d_row2_col4, #T_13e1d_row2_col6, #T_13e1d_row2_col7, #T_13e1d_row2_col10, #T_13e1d_row3_col5, #T_13e1d_row3_col8, #T_13e1d_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_13e1d_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_13e1d_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #c83836;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_13e1d_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_13e1d_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_13e1d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_13e1d_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_13e1d_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_13e1d_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_13e1d_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_13e1d_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_13e1d_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_13e1d_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_13e1d_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_13e1d_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_13e1d_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_13e1d_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_13e1d_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_13e1d_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_13e1d_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_13e1d_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_13e1d_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_13e1d_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_13e1d_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_13e1d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_13e1d_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=80000:ep=2</td>\n",
       "      <td id=\"T_13e1d_row0_col1\" class=\"data row0 col1\" >80000</td>\n",
       "      <td id=\"T_13e1d_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_13e1d_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "      <td id=\"T_13e1d_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "      <td id=\"T_13e1d_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_13e1d_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_13e1d_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_13e1d_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_13e1d_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "      <td id=\"T_13e1d_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_13e1d_row0_col11\" class=\"data row0 col11\" >47.2</td>\n",
       "      <td id=\"T_13e1d_row0_col12\" class=\"data row0 col12\" >272.2</td>\n",
       "      <td id=\"T_13e1d_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_13e1d_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_13e1d_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_13e1d_row0_col16\" class=\"data row0 col16\" >159.7</td>\n",
       "      <td id=\"T_13e1d_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13e1d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_13e1d_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=80000:ep=2</td>\n",
       "      <td id=\"T_13e1d_row1_col1\" class=\"data row1 col1\" >80000</td>\n",
       "      <td id=\"T_13e1d_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_13e1d_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_13e1d_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_13e1d_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_13e1d_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_13e1d_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_13e1d_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_13e1d_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_13e1d_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_13e1d_row1_col11\" class=\"data row1 col11\" >49.4</td>\n",
       "      <td id=\"T_13e1d_row1_col12\" class=\"data row1 col12\" >254.6</td>\n",
       "      <td id=\"T_13e1d_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_13e1d_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_13e1d_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_13e1d_row1_col16\" class=\"data row1 col16\" >152.0</td>\n",
       "      <td id=\"T_13e1d_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13e1d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_13e1d_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_13e1d_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_13e1d_row2_col2\" class=\"data row2 col2\" >38.4</td>\n",
       "      <td id=\"T_13e1d_row2_col3\" class=\"data row2 col3\" >36.5</td>\n",
       "      <td id=\"T_13e1d_row2_col4\" class=\"data row2 col4\" >6.6</td>\n",
       "      <td id=\"T_13e1d_row2_col5\" class=\"data row2 col5\" >10.8</td>\n",
       "      <td id=\"T_13e1d_row2_col6\" class=\"data row2 col6\" >31.3</td>\n",
       "      <td id=\"T_13e1d_row2_col7\" class=\"data row2 col7\" >34.1</td>\n",
       "      <td id=\"T_13e1d_row2_col8\" class=\"data row2 col8\" >7.9</td>\n",
       "      <td id=\"T_13e1d_row2_col9\" class=\"data row2 col9\" >33.3</td>\n",
       "      <td id=\"T_13e1d_row2_col10\" class=\"data row2 col10\" >11.8</td>\n",
       "      <td id=\"T_13e1d_row2_col11\" class=\"data row2 col11\" >48.5</td>\n",
       "      <td id=\"T_13e1d_row2_col12\" class=\"data row2 col12\" >252.2</td>\n",
       "      <td id=\"T_13e1d_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_13e1d_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_13e1d_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_13e1d_row2_col16\" class=\"data row2 col16\" >46.5</td>\n",
       "      <td id=\"T_13e1d_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13e1d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_13e1d_row3_col0\" class=\"data row3 col0\" >llama-7b</td>\n",
       "      <td id=\"T_13e1d_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_13e1d_row3_col2\" class=\"data row3 col2\" >31.8</td>\n",
       "      <td id=\"T_13e1d_row3_col3\" class=\"data row3 col3\" >34.5</td>\n",
       "      <td id=\"T_13e1d_row3_col4\" class=\"data row3 col4\" >5.4</td>\n",
       "      <td id=\"T_13e1d_row3_col5\" class=\"data row3 col5\" >11.8</td>\n",
       "      <td id=\"T_13e1d_row3_col6\" class=\"data row3 col6\" >30.6</td>\n",
       "      <td id=\"T_13e1d_row3_col7\" class=\"data row3 col7\" >32.7</td>\n",
       "      <td id=\"T_13e1d_row3_col8\" class=\"data row3 col8\" >9.6</td>\n",
       "      <td id=\"T_13e1d_row3_col9\" class=\"data row3 col9\" >38.4</td>\n",
       "      <td id=\"T_13e1d_row3_col10\" class=\"data row3 col10\" >10.2</td>\n",
       "      <td id=\"T_13e1d_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_13e1d_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_13e1d_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_13e1d_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_13e1d_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_13e1d_row3_col16\" class=\"data row3 col16\" >22.8</td>\n",
       "      <td id=\"T_13e1d_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf7175f00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b5fad td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_b5fad_row0_col0, #T_b5fad_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b5fad_row0_col1, #T_b5fad_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b5fad_row0_col2, #T_b5fad_row0_col3, #T_b5fad_row0_col4, #T_b5fad_row0_col6, #T_b5fad_row0_col7, #T_b5fad_row0_col10, #T_b5fad_row0_col16, #T_b5fad_row1_col5, #T_b5fad_row1_col8, #T_b5fad_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5fad_row0_col5, #T_b5fad_row0_col8, #T_b5fad_row0_col9, #T_b5fad_row0_col11, #T_b5fad_row0_col12, #T_b5fad_row1_col2, #T_b5fad_row1_col3, #T_b5fad_row1_col4, #T_b5fad_row1_col6, #T_b5fad_row1_col7, #T_b5fad_row1_col10, #T_b5fad_row1_col11, #T_b5fad_row1_col12, #T_b5fad_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b5fad_row0_col13, #T_b5fad_row0_col14, #T_b5fad_row0_col15, #T_b5fad_row0_col17, #T_b5fad_row1_col13, #T_b5fad_row1_col14, #T_b5fad_row1_col15, #T_b5fad_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b5fad\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b5fad_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_b5fad_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_b5fad_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_b5fad_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_b5fad_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_b5fad_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_b5fad_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_b5fad_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_b5fad_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_b5fad_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_b5fad_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_b5fad_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_b5fad_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_b5fad_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_b5fad_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_b5fad_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_b5fad_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_b5fad_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b5fad_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b5fad_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_b5fad_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_b5fad_row0_col2\" class=\"data row0 col2\" >38.4</td>\n",
       "      <td id=\"T_b5fad_row0_col3\" class=\"data row0 col3\" >36.5</td>\n",
       "      <td id=\"T_b5fad_row0_col4\" class=\"data row0 col4\" >6.6</td>\n",
       "      <td id=\"T_b5fad_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_b5fad_row0_col6\" class=\"data row0 col6\" >31.3</td>\n",
       "      <td id=\"T_b5fad_row0_col7\" class=\"data row0 col7\" >34.1</td>\n",
       "      <td id=\"T_b5fad_row0_col8\" class=\"data row0 col8\" >7.9</td>\n",
       "      <td id=\"T_b5fad_row0_col9\" class=\"data row0 col9\" >33.3</td>\n",
       "      <td id=\"T_b5fad_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_b5fad_row0_col11\" class=\"data row0 col11\" >48.5</td>\n",
       "      <td id=\"T_b5fad_row0_col12\" class=\"data row0 col12\" >252.2</td>\n",
       "      <td id=\"T_b5fad_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_b5fad_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_b5fad_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_b5fad_row0_col16\" class=\"data row0 col16\" >46.5</td>\n",
       "      <td id=\"T_b5fad_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5fad_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b5fad_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_b5fad_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_b5fad_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_b5fad_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_b5fad_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_b5fad_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_b5fad_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_b5fad_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_b5fad_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_b5fad_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_b5fad_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_b5fad_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_b5fad_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_b5fad_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_b5fad_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_b5fad_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_b5fad_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_b5fad_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf4fd0760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8d278 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_8d278_row0_col0, #T_8d278_row1_col0, #T_8d278_row2_col0, #T_8d278_row3_col0, #T_8d278_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8d278_row0_col1, #T_8d278_row1_col1, #T_8d278_row2_col1, #T_8d278_row3_col1, #T_8d278_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8d278_row0_col2, #T_8d278_row0_col5, #T_8d278_row0_col6, #T_8d278_row0_col10, #T_8d278_row0_col11, #T_8d278_row0_col16, #T_8d278_row1_col7, #T_8d278_row1_col12, #T_8d278_row1_col13, #T_8d278_row1_col15, #T_8d278_row1_col17, #T_8d278_row2_col3, #T_8d278_row3_col14, #T_8d278_row4_col4, #T_8d278_row4_col8, #T_8d278_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row0_col4, #T_8d278_row2_col7, #T_8d278_row2_col8, #T_8d278_row2_col9, #T_8d278_row2_col10, #T_8d278_row2_col14, #T_8d278_row2_col15, #T_8d278_row3_col2, #T_8d278_row3_col3, #T_8d278_row3_col5, #T_8d278_row3_col11, #T_8d278_row3_col12, #T_8d278_row3_col13, #T_8d278_row3_col17, #T_8d278_row4_col6, #T_8d278_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row0_col13, #T_8d278_row0_col14, #T_8d278_row0_col15, #T_8d278_row0_col17, #T_8d278_row4_col11, #T_8d278_row4_col12, #T_8d278_row4_col13, #T_8d278_row4_col14, #T_8d278_row4_col15, #T_8d278_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row1_col6, #T_8d278_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row1_col10, #T_8d278_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8d278_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8d278_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8d278\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8d278_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_8d278_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_8d278_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_8d278_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_8d278_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_8d278_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_8d278_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_8d278_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_8d278_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_8d278_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_8d278_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_8d278_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_8d278_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_8d278_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_8d278_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_8d278_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_8d278_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_8d278_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8d278_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8d278_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_8d278_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_8d278_row0_col2\" class=\"data row0 col2\" >35.0</td>\n",
       "      <td id=\"T_8d278_row0_col3\" class=\"data row0 col3\" >37.0</td>\n",
       "      <td id=\"T_8d278_row0_col4\" class=\"data row0 col4\" >2.8</td>\n",
       "      <td id=\"T_8d278_row0_col5\" class=\"data row0 col5\" >13.4</td>\n",
       "      <td id=\"T_8d278_row0_col6\" class=\"data row0 col6\" >33.7</td>\n",
       "      <td id=\"T_8d278_row0_col7\" class=\"data row0 col7\" >32.5</td>\n",
       "      <td id=\"T_8d278_row0_col8\" class=\"data row0 col8\" >7.7</td>\n",
       "      <td id=\"T_8d278_row0_col9\" class=\"data row0 col9\" >30.1</td>\n",
       "      <td id=\"T_8d278_row0_col10\" class=\"data row0 col10\" >14.6</td>\n",
       "      <td id=\"T_8d278_row0_col11\" class=\"data row0 col11\" >44.8</td>\n",
       "      <td id=\"T_8d278_row0_col12\" class=\"data row0 col12\" >261.7</td>\n",
       "      <td id=\"T_8d278_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_8d278_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_8d278_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_8d278_row0_col16\" class=\"data row0 col16\" >46.7</td>\n",
       "      <td id=\"T_8d278_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d278_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8d278_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_8d278_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_8d278_row1_col2\" class=\"data row1 col2\" >32.6</td>\n",
       "      <td id=\"T_8d278_row1_col3\" class=\"data row1 col3\" >35.4</td>\n",
       "      <td id=\"T_8d278_row1_col4\" class=\"data row1 col4\" >3.8</td>\n",
       "      <td id=\"T_8d278_row1_col5\" class=\"data row1 col5\" >12.8</td>\n",
       "      <td id=\"T_8d278_row1_col6\" class=\"data row1 col6\" >33.4</td>\n",
       "      <td id=\"T_8d278_row1_col7\" class=\"data row1 col7\" >33.4</td>\n",
       "      <td id=\"T_8d278_row1_col8\" class=\"data row1 col8\" >8.3</td>\n",
       "      <td id=\"T_8d278_row1_col9\" class=\"data row1 col9\" >32.0</td>\n",
       "      <td id=\"T_8d278_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_8d278_row1_col11\" class=\"data row1 col11\" >40.4</td>\n",
       "      <td id=\"T_8d278_row1_col12\" class=\"data row1 col12\" >263.0</td>\n",
       "      <td id=\"T_8d278_row1_col13\" class=\"data row1 col13\" >46.2</td>\n",
       "      <td id=\"T_8d278_row1_col14\" class=\"data row1 col14\" >26.6</td>\n",
       "      <td id=\"T_8d278_row1_col15\" class=\"data row1 col15\" >36.5</td>\n",
       "      <td id=\"T_8d278_row1_col16\" class=\"data row1 col16\" >43.9</td>\n",
       "      <td id=\"T_8d278_row1_col17\" class=\"data row1 col17\" >-28.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d278_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8d278_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_8d278_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_8d278_row2_col2\" class=\"data row2 col2\" >34.0</td>\n",
       "      <td id=\"T_8d278_row2_col3\" class=\"data row2 col3\" >37.8</td>\n",
       "      <td id=\"T_8d278_row2_col4\" class=\"data row2 col4\" >4.8</td>\n",
       "      <td id=\"T_8d278_row2_col5\" class=\"data row2 col5\" >12.0</td>\n",
       "      <td id=\"T_8d278_row2_col6\" class=\"data row2 col6\" >32.9</td>\n",
       "      <td id=\"T_8d278_row2_col7\" class=\"data row2 col7\" >30.6</td>\n",
       "      <td id=\"T_8d278_row2_col8\" class=\"data row2 col8\" >7.0</td>\n",
       "      <td id=\"T_8d278_row2_col9\" class=\"data row2 col9\" >28.3</td>\n",
       "      <td id=\"T_8d278_row2_col10\" class=\"data row2 col10\" >6.3</td>\n",
       "      <td id=\"T_8d278_row2_col11\" class=\"data row2 col11\" >36.3</td>\n",
       "      <td id=\"T_8d278_row2_col12\" class=\"data row2 col12\" >244.3</td>\n",
       "      <td id=\"T_8d278_row2_col13\" class=\"data row2 col13\" >44.2</td>\n",
       "      <td id=\"T_8d278_row2_col14\" class=\"data row2 col14\" >25.9</td>\n",
       "      <td id=\"T_8d278_row2_col15\" class=\"data row2 col15\" >35.4</td>\n",
       "      <td id=\"T_8d278_row2_col16\" class=\"data row2 col16\" >41.4</td>\n",
       "      <td id=\"T_8d278_row2_col17\" class=\"data row2 col17\" >-34.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d278_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8d278_row3_col0\" class=\"data row3 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_8d278_row3_col1\" class=\"data row3 col1\" >10000</td>\n",
       "      <td id=\"T_8d278_row3_col2\" class=\"data row3 col2\" >29.4</td>\n",
       "      <td id=\"T_8d278_row3_col3\" class=\"data row3 col3\" >32.9</td>\n",
       "      <td id=\"T_8d278_row3_col4\" class=\"data row3 col4\" >4.6</td>\n",
       "      <td id=\"T_8d278_row3_col5\" class=\"data row3 col5\" >11.4</td>\n",
       "      <td id=\"T_8d278_row3_col6\" class=\"data row3 col6\" >30.8</td>\n",
       "      <td id=\"T_8d278_row3_col7\" class=\"data row3 col7\" >31.8</td>\n",
       "      <td id=\"T_8d278_row3_col8\" class=\"data row3 col8\" >7.8</td>\n",
       "      <td id=\"T_8d278_row3_col9\" class=\"data row3 col9\" >29.7</td>\n",
       "      <td id=\"T_8d278_row3_col10\" class=\"data row3 col10\" >10.0</td>\n",
       "      <td id=\"T_8d278_row3_col11\" class=\"data row3 col11\" >35.9</td>\n",
       "      <td id=\"T_8d278_row3_col12\" class=\"data row3 col12\" >221.6</td>\n",
       "      <td id=\"T_8d278_row3_col13\" class=\"data row3 col13\" >43.9</td>\n",
       "      <td id=\"T_8d278_row3_col14\" class=\"data row3 col14\" >28.9</td>\n",
       "      <td id=\"T_8d278_row3_col15\" class=\"data row3 col15\" >36.4</td>\n",
       "      <td id=\"T_8d278_row3_col16\" class=\"data row3 col16\" >39.6</td>\n",
       "      <td id=\"T_8d278_row3_col17\" class=\"data row3 col17\" >-36.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d278_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8d278_row4_col0\" class=\"data row4 col0\" >llama-7b</td>\n",
       "      <td id=\"T_8d278_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_8d278_row4_col2\" class=\"data row4 col2\" >31.8</td>\n",
       "      <td id=\"T_8d278_row4_col3\" class=\"data row4 col3\" >34.5</td>\n",
       "      <td id=\"T_8d278_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_8d278_row4_col5\" class=\"data row4 col5\" >11.8</td>\n",
       "      <td id=\"T_8d278_row4_col6\" class=\"data row4 col6\" >30.6</td>\n",
       "      <td id=\"T_8d278_row4_col7\" class=\"data row4 col7\" >32.7</td>\n",
       "      <td id=\"T_8d278_row4_col8\" class=\"data row4 col8\" >9.6</td>\n",
       "      <td id=\"T_8d278_row4_col9\" class=\"data row4 col9\" >38.4</td>\n",
       "      <td id=\"T_8d278_row4_col10\" class=\"data row4 col10\" >10.2</td>\n",
       "      <td id=\"T_8d278_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_8d278_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_8d278_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_8d278_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_8d278_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_8d278_row4_col16\" class=\"data row4 col16\" >22.8</td>\n",
       "      <td id=\"T_8d278_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf7136350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_efa8f td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_efa8f_row0_col0, #T_efa8f_row1_col0, #T_efa8f_row2_col0, #T_efa8f_row3_col0, #T_efa8f_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_efa8f_row0_col1, #T_efa8f_row1_col1, #T_efa8f_row2_col1, #T_efa8f_row3_col1, #T_efa8f_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_efa8f_row0_col2, #T_efa8f_row0_col3, #T_efa8f_row0_col11, #T_efa8f_row0_col13, #T_efa8f_row0_col15, #T_efa8f_row0_col16, #T_efa8f_row0_col17, #T_efa8f_row1_col10, #T_efa8f_row2_col5, #T_efa8f_row2_col6, #T_efa8f_row2_col7, #T_efa8f_row2_col12, #T_efa8f_row3_col14, #T_efa8f_row4_col4, #T_efa8f_row4_col8, #T_efa8f_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row0_col5, #T_efa8f_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row1_col4, #T_efa8f_row1_col7, #T_efa8f_row1_col9, #T_efa8f_row1_col12, #T_efa8f_row2_col8, #T_efa8f_row2_col9, #T_efa8f_row2_col10, #T_efa8f_row2_col11, #T_efa8f_row2_col13, #T_efa8f_row2_col14, #T_efa8f_row2_col15, #T_efa8f_row3_col2, #T_efa8f_row3_col3, #T_efa8f_row3_col17, #T_efa8f_row4_col5, #T_efa8f_row4_col6, #T_efa8f_row4_col10, #T_efa8f_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row1_col11, #T_efa8f_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row1_col13, #T_efa8f_row1_col14, #T_efa8f_row1_col15, #T_efa8f_row1_col17, #T_efa8f_row4_col11, #T_efa8f_row4_col12, #T_efa8f_row4_col13, #T_efa8f_row4_col14, #T_efa8f_row4_col15, #T_efa8f_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_efa8f_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_efa8f_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_efa8f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_efa8f_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_efa8f_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_efa8f_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_efa8f_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_efa8f_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_efa8f_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_efa8f_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_efa8f_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_efa8f_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_efa8f_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_efa8f_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_efa8f_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_efa8f_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_efa8f_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_efa8f_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_efa8f_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_efa8f_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_efa8f_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_efa8f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_efa8f_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_efa8f_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_efa8f_row0_col2\" class=\"data row0 col2\" >35.6</td>\n",
       "      <td id=\"T_efa8f_row0_col3\" class=\"data row0 col3\" >37.6</td>\n",
       "      <td id=\"T_efa8f_row0_col4\" class=\"data row0 col4\" >4.8</td>\n",
       "      <td id=\"T_efa8f_row0_col5\" class=\"data row0 col5\" >13.2</td>\n",
       "      <td id=\"T_efa8f_row0_col6\" class=\"data row0 col6\" >33.3</td>\n",
       "      <td id=\"T_efa8f_row0_col7\" class=\"data row0 col7\" >33.2</td>\n",
       "      <td id=\"T_efa8f_row0_col8\" class=\"data row0 col8\" >8.4</td>\n",
       "      <td id=\"T_efa8f_row0_col9\" class=\"data row0 col9\" >31.3</td>\n",
       "      <td id=\"T_efa8f_row0_col10\" class=\"data row0 col10\" >13.0</td>\n",
       "      <td id=\"T_efa8f_row0_col11\" class=\"data row0 col11\" >46.9</td>\n",
       "      <td id=\"T_efa8f_row0_col12\" class=\"data row0 col12\" >280.9</td>\n",
       "      <td id=\"T_efa8f_row0_col13\" class=\"data row0 col13\" >49.2</td>\n",
       "      <td id=\"T_efa8f_row0_col14\" class=\"data row0 col14\" >32.8</td>\n",
       "      <td id=\"T_efa8f_row0_col15\" class=\"data row0 col15\" >41.1</td>\n",
       "      <td id=\"T_efa8f_row0_col16\" class=\"data row0 col16\" >47.2</td>\n",
       "      <td id=\"T_efa8f_row0_col17\" class=\"data row0 col17\" >-19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_efa8f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_efa8f_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_efa8f_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_efa8f_row1_col2\" class=\"data row1 col2\" >35.0</td>\n",
       "      <td id=\"T_efa8f_row1_col3\" class=\"data row1 col3\" >37.0</td>\n",
       "      <td id=\"T_efa8f_row1_col4\" class=\"data row1 col4\" >2.8</td>\n",
       "      <td id=\"T_efa8f_row1_col5\" class=\"data row1 col5\" >13.4</td>\n",
       "      <td id=\"T_efa8f_row1_col6\" class=\"data row1 col6\" >33.7</td>\n",
       "      <td id=\"T_efa8f_row1_col7\" class=\"data row1 col7\" >32.5</td>\n",
       "      <td id=\"T_efa8f_row1_col8\" class=\"data row1 col8\" >7.7</td>\n",
       "      <td id=\"T_efa8f_row1_col9\" class=\"data row1 col9\" >30.1</td>\n",
       "      <td id=\"T_efa8f_row1_col10\" class=\"data row1 col10\" >14.6</td>\n",
       "      <td id=\"T_efa8f_row1_col11\" class=\"data row1 col11\" >44.8</td>\n",
       "      <td id=\"T_efa8f_row1_col12\" class=\"data row1 col12\" >261.7</td>\n",
       "      <td id=\"T_efa8f_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_efa8f_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_efa8f_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_efa8f_row1_col16\" class=\"data row1 col16\" >46.7</td>\n",
       "      <td id=\"T_efa8f_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_efa8f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_efa8f_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_efa8f_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_efa8f_row2_col2\" class=\"data row2 col2\" >35.2</td>\n",
       "      <td id=\"T_efa8f_row2_col3\" class=\"data row2 col3\" >35.4</td>\n",
       "      <td id=\"T_efa8f_row2_col4\" class=\"data row2 col4\" >4.6</td>\n",
       "      <td id=\"T_efa8f_row2_col5\" class=\"data row2 col5\" >14.0</td>\n",
       "      <td id=\"T_efa8f_row2_col6\" class=\"data row2 col6\" >34.5</td>\n",
       "      <td id=\"T_efa8f_row2_col7\" class=\"data row2 col7\" >35.5</td>\n",
       "      <td id=\"T_efa8f_row2_col8\" class=\"data row2 col8\" >7.1</td>\n",
       "      <td id=\"T_efa8f_row2_col9\" class=\"data row2 col9\" >30.1</td>\n",
       "      <td id=\"T_efa8f_row2_col10\" class=\"data row2 col10\" >10.2</td>\n",
       "      <td id=\"T_efa8f_row2_col11\" class=\"data row2 col11\" >44.8</td>\n",
       "      <td id=\"T_efa8f_row2_col12\" class=\"data row2 col12\" >288.3</td>\n",
       "      <td id=\"T_efa8f_row2_col13\" class=\"data row2 col13\" >45.9</td>\n",
       "      <td id=\"T_efa8f_row2_col14\" class=\"data row2 col14\" >28.1</td>\n",
       "      <td id=\"T_efa8f_row2_col15\" class=\"data row2 col15\" >37.0</td>\n",
       "      <td id=\"T_efa8f_row2_col16\" class=\"data row2 col16\" >46.5</td>\n",
       "      <td id=\"T_efa8f_row2_col17\" class=\"data row2 col17\" >-24.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_efa8f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_efa8f_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_efa8f_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_efa8f_row3_col2\" class=\"data row3 col2\" >28.5</td>\n",
       "      <td id=\"T_efa8f_row3_col3\" class=\"data row3 col3\" >31.5</td>\n",
       "      <td id=\"T_efa8f_row3_col4\" class=\"data row3 col4\" >3.8</td>\n",
       "      <td id=\"T_efa8f_row3_col5\" class=\"data row3 col5\" >12.0</td>\n",
       "      <td id=\"T_efa8f_row3_col6\" class=\"data row3 col6\" >34.4</td>\n",
       "      <td id=\"T_efa8f_row3_col7\" class=\"data row3 col7\" >34.5</td>\n",
       "      <td id=\"T_efa8f_row3_col8\" class=\"data row3 col8\" >7.8</td>\n",
       "      <td id=\"T_efa8f_row3_col9\" class=\"data row3 col9\" >31.2</td>\n",
       "      <td id=\"T_efa8f_row3_col10\" class=\"data row3 col10\" >13.2</td>\n",
       "      <td id=\"T_efa8f_row3_col11\" class=\"data row3 col11\" >44.8</td>\n",
       "      <td id=\"T_efa8f_row3_col12\" class=\"data row3 col12\" >283.5</td>\n",
       "      <td id=\"T_efa8f_row3_col13\" class=\"data row3 col13\" >46.8</td>\n",
       "      <td id=\"T_efa8f_row3_col14\" class=\"data row3 col14\" >34.8</td>\n",
       "      <td id=\"T_efa8f_row3_col15\" class=\"data row3 col15\" >40.8</td>\n",
       "      <td id=\"T_efa8f_row3_col16\" class=\"data row3 col16\" >46.2</td>\n",
       "      <td id=\"T_efa8f_row3_col17\" class=\"data row3 col17\" >-24.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_efa8f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_efa8f_row4_col0\" class=\"data row4 col0\" >llama-7b</td>\n",
       "      <td id=\"T_efa8f_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_efa8f_row4_col2\" class=\"data row4 col2\" >31.8</td>\n",
       "      <td id=\"T_efa8f_row4_col3\" class=\"data row4 col3\" >34.5</td>\n",
       "      <td id=\"T_efa8f_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_efa8f_row4_col5\" class=\"data row4 col5\" >11.8</td>\n",
       "      <td id=\"T_efa8f_row4_col6\" class=\"data row4 col6\" >30.6</td>\n",
       "      <td id=\"T_efa8f_row4_col7\" class=\"data row4 col7\" >32.7</td>\n",
       "      <td id=\"T_efa8f_row4_col8\" class=\"data row4 col8\" >9.6</td>\n",
       "      <td id=\"T_efa8f_row4_col9\" class=\"data row4 col9\" >38.4</td>\n",
       "      <td id=\"T_efa8f_row4_col10\" class=\"data row4 col10\" >10.2</td>\n",
       "      <td id=\"T_efa8f_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_efa8f_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_efa8f_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_efa8f_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_efa8f_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_efa8f_row4_col16\" class=\"data row4 col16\" >22.8</td>\n",
       "      <td id=\"T_efa8f_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf36cb6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7b36e td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_7b36e_row0_col0, #T_7b36e_row1_col0, #T_7b36e_row2_col0, #T_7b36e_row3_col0, #T_7b36e_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7b36e_row0_col1, #T_7b36e_row1_col1, #T_7b36e_row2_col1, #T_7b36e_row3_col1, #T_7b36e_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7b36e_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row0_col4, #T_7b36e_row0_col7, #T_7b36e_row0_col8, #T_7b36e_row0_col9, #T_7b36e_row0_col11, #T_7b36e_row2_col13, #T_7b36e_row2_col14, #T_7b36e_row2_col15, #T_7b36e_row2_col17, #T_7b36e_row3_col12, #T_7b36e_row4_col2, #T_7b36e_row4_col3, #T_7b36e_row4_col5, #T_7b36e_row4_col6, #T_7b36e_row4_col10, #T_7b36e_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b36e_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row0_col10, #T_7b36e_row0_col16, #T_7b36e_row1_col3, #T_7b36e_row1_col5, #T_7b36e_row1_col7, #T_7b36e_row1_col12, #T_7b36e_row1_col13, #T_7b36e_row1_col14, #T_7b36e_row1_col15, #T_7b36e_row1_col17, #T_7b36e_row2_col2, #T_7b36e_row2_col3, #T_7b36e_row2_col6, #T_7b36e_row2_col11, #T_7b36e_row4_col4, #T_7b36e_row4_col8, #T_7b36e_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b36e_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row0_col13, #T_7b36e_row0_col14, #T_7b36e_row0_col15, #T_7b36e_row0_col17, #T_7b36e_row3_col13, #T_7b36e_row3_col14, #T_7b36e_row3_col15, #T_7b36e_row3_col17, #T_7b36e_row4_col11, #T_7b36e_row4_col12, #T_7b36e_row4_col13, #T_7b36e_row4_col14, #T_7b36e_row4_col15, #T_7b36e_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b36e_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b36e_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row1_col8, #T_7b36e_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b36e_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b36e_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b36e_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b36e_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b36e_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b36e_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b36e_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b36e_row3_col9, #T_7b36e_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b36e_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b36e_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7b36e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7b36e_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_7b36e_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_7b36e_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_7b36e_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_7b36e_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_7b36e_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_7b36e_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_7b36e_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_7b36e_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_7b36e_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_7b36e_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_7b36e_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_7b36e_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_7b36e_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_7b36e_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_7b36e_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_7b36e_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_7b36e_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7b36e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7b36e_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_7b36e_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_7b36e_row0_col2\" class=\"data row0 col2\" >35.0</td>\n",
       "      <td id=\"T_7b36e_row0_col3\" class=\"data row0 col3\" >37.0</td>\n",
       "      <td id=\"T_7b36e_row0_col4\" class=\"data row0 col4\" >2.8</td>\n",
       "      <td id=\"T_7b36e_row0_col5\" class=\"data row0 col5\" >13.4</td>\n",
       "      <td id=\"T_7b36e_row0_col6\" class=\"data row0 col6\" >33.7</td>\n",
       "      <td id=\"T_7b36e_row0_col7\" class=\"data row0 col7\" >32.5</td>\n",
       "      <td id=\"T_7b36e_row0_col8\" class=\"data row0 col8\" >7.7</td>\n",
       "      <td id=\"T_7b36e_row0_col9\" class=\"data row0 col9\" >30.1</td>\n",
       "      <td id=\"T_7b36e_row0_col10\" class=\"data row0 col10\" >14.6</td>\n",
       "      <td id=\"T_7b36e_row0_col11\" class=\"data row0 col11\" >44.8</td>\n",
       "      <td id=\"T_7b36e_row0_col12\" class=\"data row0 col12\" >261.7</td>\n",
       "      <td id=\"T_7b36e_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_7b36e_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_7b36e_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_7b36e_row0_col16\" class=\"data row0 col16\" >46.7</td>\n",
       "      <td id=\"T_7b36e_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b36e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7b36e_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_7b36e_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_7b36e_row1_col2\" class=\"data row1 col2\" >32.2</td>\n",
       "      <td id=\"T_7b36e_row1_col3\" class=\"data row1 col3\" >38.1</td>\n",
       "      <td id=\"T_7b36e_row1_col4\" class=\"data row1 col4\" >4.4</td>\n",
       "      <td id=\"T_7b36e_row1_col5\" class=\"data row1 col5\" >15.6</td>\n",
       "      <td id=\"T_7b36e_row1_col6\" class=\"data row1 col6\" >33.9</td>\n",
       "      <td id=\"T_7b36e_row1_col7\" class=\"data row1 col7\" >34.9</td>\n",
       "      <td id=\"T_7b36e_row1_col8\" class=\"data row1 col8\" >8.1</td>\n",
       "      <td id=\"T_7b36e_row1_col9\" class=\"data row1 col9\" >32.4</td>\n",
       "      <td id=\"T_7b36e_row1_col10\" class=\"data row1 col10\" >13.2</td>\n",
       "      <td id=\"T_7b36e_row1_col11\" class=\"data row1 col11\" >47.7</td>\n",
       "      <td id=\"T_7b36e_row1_col12\" class=\"data row1 col12\" >268.2</td>\n",
       "      <td id=\"T_7b36e_row1_col13\" class=\"data row1 col13\" >46.6</td>\n",
       "      <td id=\"T_7b36e_row1_col14\" class=\"data row1 col14\" >35.4</td>\n",
       "      <td id=\"T_7b36e_row1_col15\" class=\"data row1 col15\" >41.1</td>\n",
       "      <td id=\"T_7b36e_row1_col16\" class=\"data row1 col16\" >46.6</td>\n",
       "      <td id=\"T_7b36e_row1_col17\" class=\"data row1 col17\" >-17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b36e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7b36e_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_7b36e_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_7b36e_row2_col2\" class=\"data row2 col2\" >38.0</td>\n",
       "      <td id=\"T_7b36e_row2_col3\" class=\"data row2 col3\" >38.1</td>\n",
       "      <td id=\"T_7b36e_row2_col4\" class=\"data row2 col4\" >3.8</td>\n",
       "      <td id=\"T_7b36e_row2_col5\" class=\"data row2 col5\" >13.8</td>\n",
       "      <td id=\"T_7b36e_row2_col6\" class=\"data row2 col6\" >36.4</td>\n",
       "      <td id=\"T_7b36e_row2_col7\" class=\"data row2 col7\" >34.5</td>\n",
       "      <td id=\"T_7b36e_row2_col8\" class=\"data row2 col8\" >7.8</td>\n",
       "      <td id=\"T_7b36e_row2_col9\" class=\"data row2 col9\" >33.1</td>\n",
       "      <td id=\"T_7b36e_row2_col10\" class=\"data row2 col10\" >12.6</td>\n",
       "      <td id=\"T_7b36e_row2_col11\" class=\"data row2 col11\" >48.9</td>\n",
       "      <td id=\"T_7b36e_row2_col12\" class=\"data row2 col12\" >264.1</td>\n",
       "      <td id=\"T_7b36e_row2_col13\" class=\"data row2 col13\" >46.2</td>\n",
       "      <td id=\"T_7b36e_row2_col14\" class=\"data row2 col14\" >32.1</td>\n",
       "      <td id=\"T_7b36e_row2_col15\" class=\"data row2 col15\" >39.2</td>\n",
       "      <td id=\"T_7b36e_row2_col16\" class=\"data row2 col16\" >46.3</td>\n",
       "      <td id=\"T_7b36e_row2_col17\" class=\"data row2 col17\" >-18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b36e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7b36e_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_7b36e_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_7b36e_row3_col2\" class=\"data row3 col2\" >33.4</td>\n",
       "      <td id=\"T_7b36e_row3_col3\" class=\"data row3 col3\" >35.3</td>\n",
       "      <td id=\"T_7b36e_row3_col4\" class=\"data row3 col4\" >4.8</td>\n",
       "      <td id=\"T_7b36e_row3_col5\" class=\"data row3 col5\" >13.2</td>\n",
       "      <td id=\"T_7b36e_row3_col6\" class=\"data row3 col6\" >35.4</td>\n",
       "      <td id=\"T_7b36e_row3_col7\" class=\"data row3 col7\" >33.5</td>\n",
       "      <td id=\"T_7b36e_row3_col8\" class=\"data row3 col8\" >8.1</td>\n",
       "      <td id=\"T_7b36e_row3_col9\" class=\"data row3 col9\" >30.7</td>\n",
       "      <td id=\"T_7b36e_row3_col10\" class=\"data row3 col10\" >12.4</td>\n",
       "      <td id=\"T_7b36e_row3_col11\" class=\"data row3 col11\" >46.2</td>\n",
       "      <td id=\"T_7b36e_row3_col12\" class=\"data row3 col12\" >252.1</td>\n",
       "      <td id=\"T_7b36e_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_7b36e_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_7b36e_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_7b36e_row3_col16\" class=\"data row3 col16\" >45.9</td>\n",
       "      <td id=\"T_7b36e_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b36e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7b36e_row4_col0\" class=\"data row4 col0\" >llama-7b</td>\n",
       "      <td id=\"T_7b36e_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_7b36e_row4_col2\" class=\"data row4 col2\" >31.8</td>\n",
       "      <td id=\"T_7b36e_row4_col3\" class=\"data row4 col3\" >34.5</td>\n",
       "      <td id=\"T_7b36e_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_7b36e_row4_col5\" class=\"data row4 col5\" >11.8</td>\n",
       "      <td id=\"T_7b36e_row4_col6\" class=\"data row4 col6\" >30.6</td>\n",
       "      <td id=\"T_7b36e_row4_col7\" class=\"data row4 col7\" >32.7</td>\n",
       "      <td id=\"T_7b36e_row4_col8\" class=\"data row4 col8\" >9.6</td>\n",
       "      <td id=\"T_7b36e_row4_col9\" class=\"data row4 col9\" >38.4</td>\n",
       "      <td id=\"T_7b36e_row4_col10\" class=\"data row4 col10\" >10.2</td>\n",
       "      <td id=\"T_7b36e_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_7b36e_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_7b36e_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_7b36e_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_7b36e_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_7b36e_row4_col16\" class=\"data row4 col16\" >22.8</td>\n",
       "      <td id=\"T_7b36e_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfd8141c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_786bd td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_786bd_row0_col0, #T_786bd_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_786bd_row0_col1, #T_786bd_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_786bd_row0_col2, #T_786bd_row0_col3, #T_786bd_row0_col5, #T_786bd_row0_col6, #T_786bd_row0_col10, #T_786bd_row0_col16, #T_786bd_row1_col4, #T_786bd_row1_col7, #T_786bd_row1_col8, #T_786bd_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_786bd_row0_col4, #T_786bd_row0_col7, #T_786bd_row0_col8, #T_786bd_row0_col9, #T_786bd_row0_col11, #T_786bd_row0_col12, #T_786bd_row1_col2, #T_786bd_row1_col3, #T_786bd_row1_col5, #T_786bd_row1_col6, #T_786bd_row1_col10, #T_786bd_row1_col11, #T_786bd_row1_col12, #T_786bd_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_786bd_row0_col13, #T_786bd_row0_col14, #T_786bd_row0_col15, #T_786bd_row0_col17, #T_786bd_row1_col13, #T_786bd_row1_col14, #T_786bd_row1_col15, #T_786bd_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_786bd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_786bd_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_786bd_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_786bd_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_786bd_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_786bd_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_786bd_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_786bd_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_786bd_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_786bd_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_786bd_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_786bd_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_786bd_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_786bd_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_786bd_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_786bd_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_786bd_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_786bd_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_786bd_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_786bd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_786bd_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_786bd_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_786bd_row0_col2\" class=\"data row0 col2\" >35.0</td>\n",
       "      <td id=\"T_786bd_row0_col3\" class=\"data row0 col3\" >37.0</td>\n",
       "      <td id=\"T_786bd_row0_col4\" class=\"data row0 col4\" >2.8</td>\n",
       "      <td id=\"T_786bd_row0_col5\" class=\"data row0 col5\" >13.4</td>\n",
       "      <td id=\"T_786bd_row0_col6\" class=\"data row0 col6\" >33.7</td>\n",
       "      <td id=\"T_786bd_row0_col7\" class=\"data row0 col7\" >32.5</td>\n",
       "      <td id=\"T_786bd_row0_col8\" class=\"data row0 col8\" >7.7</td>\n",
       "      <td id=\"T_786bd_row0_col9\" class=\"data row0 col9\" >30.1</td>\n",
       "      <td id=\"T_786bd_row0_col10\" class=\"data row0 col10\" >14.6</td>\n",
       "      <td id=\"T_786bd_row0_col11\" class=\"data row0 col11\" >44.8</td>\n",
       "      <td id=\"T_786bd_row0_col12\" class=\"data row0 col12\" >261.7</td>\n",
       "      <td id=\"T_786bd_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_786bd_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_786bd_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_786bd_row0_col16\" class=\"data row0 col16\" >46.7</td>\n",
       "      <td id=\"T_786bd_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_786bd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_786bd_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_786bd_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_786bd_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_786bd_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_786bd_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_786bd_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_786bd_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_786bd_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_786bd_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_786bd_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_786bd_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_786bd_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_786bd_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_786bd_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_786bd_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_786bd_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_786bd_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_786bd_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfdbc7e20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/4175332628.py:370: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/4175332628.py:376: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4c4bf td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_4c4bf_row0_col0, #T_4c4bf_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4c4bf_row0_col1, #T_4c4bf_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4c4bf_row0_col2, #T_4c4bf_row0_col3, #T_4c4bf_row0_col5, #T_4c4bf_row0_col6, #T_4c4bf_row0_col10, #T_4c4bf_row0_col16, #T_4c4bf_row1_col4, #T_4c4bf_row1_col7, #T_4c4bf_row1_col8, #T_4c4bf_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4c4bf_row0_col4, #T_4c4bf_row0_col7, #T_4c4bf_row0_col8, #T_4c4bf_row0_col9, #T_4c4bf_row0_col11, #T_4c4bf_row0_col12, #T_4c4bf_row1_col2, #T_4c4bf_row1_col3, #T_4c4bf_row1_col5, #T_4c4bf_row1_col6, #T_4c4bf_row1_col10, #T_4c4bf_row1_col11, #T_4c4bf_row1_col12, #T_4c4bf_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4c4bf_row0_col13, #T_4c4bf_row0_col14, #T_4c4bf_row0_col15, #T_4c4bf_row0_col17, #T_4c4bf_row1_col13, #T_4c4bf_row1_col14, #T_4c4bf_row1_col15, #T_4c4bf_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4c4bf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4c4bf_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_4c4bf_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_4c4bf_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_4c4bf_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_4c4bf_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_4c4bf_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_4c4bf_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_4c4bf_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_4c4bf_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_4c4bf_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_4c4bf_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_4c4bf_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_4c4bf_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_4c4bf_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_4c4bf_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_4c4bf_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_4c4bf_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_4c4bf_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4c4bf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4c4bf_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_4c4bf_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_4c4bf_row0_col2\" class=\"data row0 col2\" >35.0</td>\n",
       "      <td id=\"T_4c4bf_row0_col3\" class=\"data row0 col3\" >37.0</td>\n",
       "      <td id=\"T_4c4bf_row0_col4\" class=\"data row0 col4\" >2.8</td>\n",
       "      <td id=\"T_4c4bf_row0_col5\" class=\"data row0 col5\" >13.4</td>\n",
       "      <td id=\"T_4c4bf_row0_col6\" class=\"data row0 col6\" >33.7</td>\n",
       "      <td id=\"T_4c4bf_row0_col7\" class=\"data row0 col7\" >32.5</td>\n",
       "      <td id=\"T_4c4bf_row0_col8\" class=\"data row0 col8\" >7.7</td>\n",
       "      <td id=\"T_4c4bf_row0_col9\" class=\"data row0 col9\" >30.1</td>\n",
       "      <td id=\"T_4c4bf_row0_col10\" class=\"data row0 col10\" >14.6</td>\n",
       "      <td id=\"T_4c4bf_row0_col11\" class=\"data row0 col11\" >44.8</td>\n",
       "      <td id=\"T_4c4bf_row0_col12\" class=\"data row0 col12\" >261.7</td>\n",
       "      <td id=\"T_4c4bf_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_4c4bf_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_4c4bf_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_4c4bf_row0_col16\" class=\"data row0 col16\" >46.7</td>\n",
       "      <td id=\"T_4c4bf_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c4bf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4c4bf_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_4c4bf_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_4c4bf_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_4c4bf_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_4c4bf_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_4c4bf_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_4c4bf_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_4c4bf_row1_col7\" class=\"data row1 col7\" >32.7</td>\n",
       "      <td id=\"T_4c4bf_row1_col8\" class=\"data row1 col8\" >9.6</td>\n",
       "      <td id=\"T_4c4bf_row1_col9\" class=\"data row1 col9\" >38.4</td>\n",
       "      <td id=\"T_4c4bf_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_4c4bf_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_4c4bf_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_4c4bf_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_4c4bf_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_4c4bf_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_4c4bf_row1_col16\" class=\"data row1 col16\" >22.8</td>\n",
       "      <td id=\"T_4c4bf_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf71772b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_sort_rows_by_avg_ranking\n",
    "from llm.evaluate import EvalResults, get_eval_results\n",
    "\n",
    "\n",
    "\n",
    "exp_dir = ''\n",
    "chat_fmt = None\n",
    "sort_rows = True\n",
    "use_normalized_preferred_metric = False\n",
    "\n",
    "\n",
    "# ## investigate code change / package update effect on eval baselines.\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# use_normalized_preferred_metric = False\n",
    "# sort_rows = False\n",
    "# save_dirs = [\n",
    "#     # llama\n",
    "#     ('llama-7b_12.13update_before', '../results/baselines/huggyllama/llama-7b_12.13update_before/'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('llama-7b_10.30update', '../results/baselines/huggyllama/llama-7b_10.30update/'),\n",
    "# #     ('llama-7b_09.23update', '../results/baselines/huggyllama/llama-7b_09.23update/'),\n",
    "# #     ('llama-7b_09.23update_before', '../results/baselines/huggyllama/llama-7b_09.23update_before/'),\n",
    "# #     # llama2\n",
    "#     ('llama2-7b_12.13update_before', '../results/baselines/NousResearch/Llama-2-7b-hf_12.13update_before/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('llama2-7b-chat', '../results/baselines/NousResearch/Llama-2-7b-chat-hf/'),\n",
    "# #     ('llama2-7b_10.30update', '../results/baselines/NousResearch/Llama-2-7b-hf_10.30update/'),\n",
    "# #     ('llama2-7b_original', '../results/baselines/NousResearch/Llama-2-7b-hf_original/'),\n",
    "# #     # mistral\n",
    "# #     ('mistral-7b_10.16update', '../results/baselines/mistralai/Mistral-7B-v0.1_10.16update/'),\n",
    "#     ('mistral-7b-Instruct-v0.1_12.13update_before', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1_12.13update_before'),\n",
    "#     ('mistral-7b-Instruct-v0.1', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     # zephyr\n",
    "#     ('zephyr-7b-beta_12.13update_before', '../results/baselines/HuggingFaceH4/zephyr-7b-beta_12.13update_before'),\n",
    "#     ('zephyr-7b-beta', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "\n",
    "# # baselines\n",
    "# save_dirs = []\n",
    "# save_dirs += [\n",
    "# #     ('gpt2', '../results/baselines/gpt2'),\n",
    "# #     ('gpt2m', '../results/baselines/gpt2-medium'),\n",
    "# #     ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "# #     ('llama2-7b+humanmix', '../results/llama2-7b_humanmix'),\n",
    "# #     ('pythia-1.4b', '../results/baselines/EleutherAI/pythia-1.4b'),\n",
    "# #     ('pythia-2.8b', '../results/baselines/EleutherAI/pythia-2.8b'),\n",
    "# #     ('pythia-6.9b', '../results/baselines/EleutherAI/pythia-6.9b'),\n",
    "# #     ('dolly-v2-7b', '../results/baselines/databricks/dolly-v2-7b'),\n",
    "#     ('mistral-7b-v0.1', '../results/baselines/mistralai/Mistral-7B-v0.1'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b+lima_ep=2', '../results/ft1_ep=2/llama-7b_lima/'),\n",
    "# #     ('mistral-7b+lima_ep=2', '../results/ft1_ep=2/mistral-7b_lima/'), \n",
    "# ]\n",
    "# exp_dir = '../results/oi2/'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "\n",
    "# exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# # exp_dir = '../results/ft2'\n",
    "# # exp_dir = '../results/ft1'\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# # save_dirs = [\n",
    "# #     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "# #     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1/'),\n",
    "# # ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'tuluv1m' in x]\n",
    "\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "# # exp_dir = '../results/oi4'\n",
    "# # exp_dir = '../results/oi4_perf_cross_time'\n",
    "# # exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'\n",
    "# exp_dir = '../results/oi4_flan_v2_vary_subsetsize'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi4_flan2022_1m'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #              ('llama-7b_flan_v2_ep=2', '../results/ft1/llama-7b_flan_v2'),\n",
    "# #              ('llama-7b_humanmix_ep=2', '../results/ft1/llama-7b_humanmix'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "# #              ('llama-7b_cot:flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_cot:flanv2'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# # exp_dir = '../results/oi4_tulu_v1_mix'\n",
    "# exp_dir = '../results/oi4_tulu_v1_mix_ep=3'\n",
    "# use_normalized_preferred_metric = False\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# ###### ultrachat\n",
    "# save_dirs = [\n",
    "#     # baselines \n",
    "#     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "#     ('mistral-7b_ultrachat200k_aftersplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k'),\n",
    "#     ('mistral-7b_ultrachat200k_beforesplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k_beforesplitlongconv'),\n",
    "    \n",
    "#     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     ('mistral-7b_sft-alpha', '../results/baselines/HuggingFaceH4/mistral-7b-sft-alpha'),\n",
    "#     ('mistral-7b-sft-beta', '../results/baselines/HuggingFaceH4/mistral-7b-sft-beta'),\n",
    "#     ('mistral-7b-sft-alpha+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-alpha'),\n",
    "#     ('mistral-7b-sft-beta+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "# # exp_dir = '../results/oi5_ultrachat:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_ultrachat200k:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# exp_dir = '../results/oi5_ultrachat15:mistral-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "# dataset = 'stanford_alpaca'\n",
    "# dataset = 'open_orca_slim'\n",
    "# dataset = 'sharegptv2'\n",
    "# dataset = 'ultrachat200kv2'\n",
    "# dataset = 'wizardlm'\n",
    "# dataset = 'wizardlmv2'\n",
    "# dataset = 'tulu_v2'\n",
    "# dataset = 'flan_v2'\n",
    "# dataset = 'oasst1'\n",
    "# dataset = 'dolly'\n",
    "# dataset_list = [\n",
    "#     'dolly',\n",
    "#     'oasst1', \n",
    "#     'flan_v2', \n",
    "#     'stanford_alpaca', \n",
    "#     'wizardlmv2', \n",
    "#     'sharegptv2', \n",
    "#     'ultrachat200kv2',\n",
    "# ]; finetune_type = 'sft'\n",
    "# dataset_list = [\n",
    "#     'ultrafeedback',\n",
    "# #     'ultrafeedbackfull',\n",
    "# ]; finetune_type = 'pref'\n",
    "dataset_list = [\n",
    "    'dolly',\n",
    "    'flan_v250k',\n",
    "    'stanford_alpaca50k', \n",
    "    'oasst2',\n",
    "    'wizardlm50k', \n",
    "    'sharegpt50k',\n",
    "    'ultrachat50k',\n",
    "]; finetune_type = 'sft'\n",
    "\n",
    "## older\n",
    "# dataset = 'tulu_v1_mix'\n",
    "save_dirs = []\n",
    "save_dirs += [\n",
    "    ('llama-7b', '../results/baselines/huggyllama/llama-7b'),\n",
    "#     ('llama-7b_lima_ep=5', '../results/oi2/llama-7b_lima_ep=5/'),\n",
    "#     ('llama-7b_lima_ep=10', '../results/oi2/llama-7b_lima_ep=10/'),\n",
    "]\n",
    "for dataset in dataset_list:\n",
    "    if dataset == 'tulu_v2':\n",
    "        save_dirs += [('llama-7b_tulu_v2:100k_ep=2', '../results/oi2/llama-7b_tulu_v2:100k_ep=2'),]\n",
    "    elif dataset == 'open_orca_slim':\n",
    "        save_dirs += [('llama-7b_openorcaslim:100k_ep=2', '../results/oi2/llama-7b_openorcaslim:100k_ep=2'),]\n",
    "    elif dataset == 'sharegptv2':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_sharegptv2_ep=2', '../results/oi2/llama-7b_sharegptv2_ep=2'),\n",
    "            ('llama-7b_sharegpt_ep=2', '../results/ft1_ep=2/llama-7b_sharegpt'),]\n",
    "    elif dataset == 'tulu_v1_mix':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "            # oi4_tulu_v1_mix_ep=3 models before transformers update.\n",
    "            # ('llama-7b_tuluv1m:50k_log_prob_decr_<10.16update', '../results/oi4_tulu_v1_mix_ep=3/llama-7b_tuluv1m:50k_log_prob_decr'),\n",
    "        ]\n",
    "    elif dataset == 'ultrafeedback':\n",
    "        exp_dir = f'../results/dpo1/'\n",
    "        save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "    else:\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=2', f'../results/oi2/llama-7b_{dataset}_ep=2'),]\n",
    "    \n",
    "    if finetune_type == 'sft':\n",
    "        exp_dir = f'../results/oi5_{dataset}:llama-7b'\n",
    "    elif finetune_type == 'pref':\n",
    "        exp_dir = f'../results/dpo2_{dataset}:llama-7b+sharegptv2ep2/'\n",
    "    save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'dppmapbd' not in x and 'semdedup' not in x]\n",
    "    \n",
    "    if finetune_type == 'pref':\n",
    "        sft_model_dataset = 'sharegptv2'\n",
    "        save_dirs += [('llama-7b_sharegptv2_ep=2', f'../results/oi2/llama-7b_{sft_model_dataset}_ep=2')]\n",
    "# ## just compare dppmap grad vs. text\n",
    "# save_dirs = [x for x in save_dirs if 'prune:size=10000:ep=10' in x[1] and (\n",
    "#         'random' in x[1] or \n",
    "#         'dppmap' in x[1]\n",
    "#     )\n",
    "# ]\n",
    "#####\n",
    "\n",
    "\n",
    "# ##### code instructions\n",
    "# save_dirs = [\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('codellama-7b', '../results/baselines/codellama/CodeLlama-7b-hf/'),\n",
    "#     ('codellama-7b-instruct', '../results/baselines/codellama/CodeLlama-7b-Python-hf/'),\n",
    "#     ('codellama-7b-python', '../results/baselines/codellama/CodeLlama-7b-Instruct-hf/'),\n",
    "# ]\n",
    "\n",
    "# exp_dir = '../results/oi2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'starcoder' in x]\n",
    "# exp_dir = '../results/oi6_starcoder_ep=5'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstr:codellama-7b'\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstrv2:codellama-7b'\n",
    "# exp_dir = '../results/oi5_starcoder_commentinstrv5:codellama-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "###### \n",
    "\n",
    "from llm.evaluate import detect_oom_evals\n",
    "oom_eval_paths = detect_oom_evals([x for l in [glob.glob(os.path.join(x[1], 'eval/*/*.out')) for x in save_dirs] for x in l])\n",
    "if oom_eval_paths: print(oom_eval_paths)\n",
    "    \n",
    "cols_avg_blacklist = ['AlpacaFarm/Len']\n",
    "\n",
    "# chat_fmt = False\n",
    "chat_fmt = True\n",
    "# chat_fmt = 'both'\n",
    "# chat_fmt = 'auto' # base model no chatfmt, tuned model with chatfmt\n",
    "chat_fmt = 'mix'  # non-alpacaeval no chatfmt, alpacaeval chatfmt\n",
    "alpacafarm_judge = 'chatgpt'\n",
    "alpacafarm_judge = 'alpaca:eval:gpt4:turbo:fn'\n",
    "mtbench_judge = 'gpt:4:1106:preview'\n",
    "\n",
    "ft_args_fields = {\n",
    "    'run_name': ('run_name',),\n",
    "    'model_name_or_path': ('model_args.model_name_or_path', 'model_name_or_path'),\n",
    "    'subsample_mixture': ('data_args.subsample_mixture',),\n",
    "    'max_train_samples': ('data_args.max_train_samples', 'max_train_samples'),\n",
    "    'train_file': ('data_args.train_file', 'train_file'),\n",
    "}\n",
    "\n",
    "cols = []\n",
    "# cols += [f'AlpacaFarm({alpacafarm_judge})/WR',  f'AlpacaFarm({alpacafarm_judge})/ΔWR', f'AlpacaFarm({alpacafarm_judge})/Rep', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "cols += ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1'] \n",
    "cols += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "cols += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "# cols += [f'MTBench({mtbench_judge})/Turn-1']\n",
    "\n",
    "\n",
    "\n",
    "# cols = [f'BBH {x}' for x in ['reasoning', 'nlu', 'knowledge', 'multilingual']]; cols = [x+'/Direct' for x in cols] + [x+'/CoT' for x in cols]\n",
    "# cols = [f'MMLU {x}' for x in ['STEM', 'humanities', 'social sciences', 'other']]; cols = [x+'/0-shot' for x in cols] + [x+'/5-shot' for x in cols]\n",
    "\n",
    "if 'open_orca_slim' in exp_dir:\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'BBH/Direct', 'BBH/CoT']\n",
    "    cols = ['MMLU/0-shot', 'BBH/Direct']\n",
    "if 'starcoder' in exp_dir:\n",
    "    cols = ['Codex-Eval/Pass@1']\n",
    "    chat_fmt = 'both'\n",
    "print(f'chat_fmt={chat_fmt}')\n",
    "df = get_eval_results(save_dirs, chat_fmt=chat_fmt, ft_args_fields=ft_args_fields, use_normalized_preferred_metric=use_normalized_preferred_metric)\n",
    "\n",
    "cols = [x for x in cols if x in df.columns]\n",
    "df = df[list(ft_args_fields.keys()) + cols]\n",
    "if chat_fmt == 'both':\n",
    "    for col_lvl2 in ['', 'chatfmt']:\n",
    "        df[('Average', col_lvl2)] = df[list(set(df.columns) & set([(x, col_lvl2) for x in list(set(cols)-set(cols_avg_blacklist))]))].mean(axis=1)\n",
    "else:\n",
    "    df['Average'] = df[list(set(cols)-set(cols_avg_blacklist))].mean(axis=1)\n",
    "if sort_rows:\n",
    "    df = pd_sort_rows_by_avg_ranking(df); df['ranking'] = -df['ranking']\n",
    "    sort_value_col, sort_value_col_ascending = ('Average', 'chatfmt') if chat_fmt=='both' else 'Average', False\n",
    "#     sort_value_col, sort_value_col_ascending = 'ranking', False\n",
    "    df = df.sort_values(by=sort_value_col, ascending=sort_value_col_ascending)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def compute_total_train_samples(x):\n",
    "    match = re.search(r'size=(\\d+)', x['run_name' if chat_fmt!='both' else ('run_name', '')])\n",
    "    total_train_samples = match.group(1) if match else None\n",
    "    return total_train_samples\n",
    "df.insert(1, 'total_train_samples' if chat_fmt!='both' else ('total_train_samples', ''), df.apply(compute_total_train_samples, axis=1))\n",
    "def extract_dataset_from_train_file(x):\n",
    "    if x is None: return None\n",
    "    x = x.split('/')[-1].split('.jsonl')[0]\n",
    "    if x.endswith('_data'): x = x[:-5]\n",
    "    if x.endswith('_train'): x = x[:-6]\n",
    "    return x\n",
    "df.insert(1, 'dataset' if chat_fmt!='both' else ('dataset', ''), df['train_file'].apply(extract_dataset_from_train_file))\n",
    "df = df.drop('train_file', axis=1)\n",
    "\n",
    "if any(exp_dir.endswith(x) for x in ['ft2']):\n",
    "#     for model_name_contain in ['gpt2', 'llama', 'pythia-1.4b']:\n",
    "#         for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "    for model_name_contain in ['llama']:\n",
    "        for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "#         for total_train_samples in [200000, 400000, 600000]:\n",
    "            dfc = df.copy()\n",
    "            dfc.insert(0, 'total_train_samples',  dfc['subsample_mixture'].apply(\n",
    "                lambda d: sum(list(d.values())) if d else 200000))\n",
    "            dfc = dfc[dfc['total_train_samples'].apply(\n",
    "                lambda x: total_train_samples-20000<x<total_train_samples+20000)]\n",
    "            dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "                lambda x: model_name_contain in x)]\n",
    "            dfc['total_train_samples'] = dfc['total_train_samples'].astype(str)\n",
    "            dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture'])\n",
    "            dfc = dfc.reset_index(drop=True)\n",
    "            if len(dfc):\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .format(precision=2))\n",
    "else:\n",
    "    for model_name_contain in ['llama', 'pythia-1.4b', 'mistral', 'zephyr']:\n",
    "        dfc = df.copy()\n",
    "        dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "            lambda x: model_name_contain in x.lower())]\n",
    "        if not len(dfc): continue\n",
    "        from rosemary import pd_average_col_contains_substr\n",
    "        Ns = sorted(np.unique([int(x) for x in df['total_train_samples'].to_numpy() if x]).tolist())\n",
    "        datasets = sorted(np.unique([x for x in df['dataset'] if x is not None]).tolist())\n",
    "        for dataset in datasets:\n",
    "            for N in Ns+[None]:\n",
    "                dfc = df.copy()\n",
    "                dfc = dfc[dfc['total_train_samples'].apply(lambda x: int(x) == N if x else True)]\n",
    "                dfc = dfc[dfc['dataset'].apply(lambda x: x == dataset if x else True)]\n",
    "                if not len(dfc): continue\n",
    "                col_runname = 'run_name' if chat_fmt != 'both' else ('run_name', '')\n",
    "                substitute = True\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, '_random_', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=10000:ep=10', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=50000:ep=5', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=3', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=1', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=100000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=200000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=400000', substitute=substitute)\n",
    "                #     dfc = dfc.sort_values(['ranking'], ascending=False)\n",
    "                col = ('Average', 'chatfmt') if chat_fmt == 'both' else 'Average'\n",
    "            #     col = 'AlpacaFarm/WR'\n",
    "            #     col = 'MMLU/0-shot'|\n",
    "            #     col = 'GSM/CoT'\n",
    "            #     col = 'BBH/Direct'\n",
    "            #     col = 'TydiQA/GP'\n",
    "                dfc = dfc.sort_values(by=[col], ascending=False)\n",
    "                dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture', 'max_train_samples', 'dataset'], \n",
    "                               axis=1, level=0 if chat_fmt=='both' else None)\n",
    "                dfc = dfc.reset_index(drop=True)\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .applymap(lambda x: f'max-width: 60ch;', subset=['run_name'])\n",
    "                        .set_table_styles([{'selector': 'td', 'props': [('white-space', 'pre-wrap'), ('word-wrap', 'break-word')]}])\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .applymap(lambda x: 'text-decoration: underline;' \\\n",
    "                                  if x in dfc[list(set(dfc.columns) & set([(x, '') for x in cols]))+[col] if chat_fmt=='both' else cols+[col]].values.flatten() and chat_fmt=='both' else '')\n",
    "                        .format(precision=1))\n",
    "\n",
    "# llama-7b_tulu_v1_mix(paper)\n",
    "# MMLU/0-shot, MMLU/5-shot, GSM/Direct, GSM/CoT, BBH/Direct, BBH/CoT, TydiQA/GP, TydiQA/CB, CodexEval/Pass@1, AlpacaEval(vs.Davinci-003)\n",
    "# 44.8       , 47.1       , 7.0       , 25.0   , 38.5      , 38.5   , 43.5,    , 8.0      , 18.6,           , 48.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "deeba0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_name',\n",
       " 'nonchat',\n",
       " 'sort_by',\n",
       " 'total_train_samples',\n",
       " 'model_name_or_path',\n",
       " 'subsample_mixture',\n",
       " 'max_train_samples',\n",
       " 'MMLU/0-shot',\n",
       " 'MMLU/5-shot',\n",
       " 'GSM/Direct',\n",
       " 'GSM/CoT',\n",
       " 'BBH/Direct',\n",
       " 'BBH/CoT',\n",
       " 'TydiQA/CB',\n",
       " 'TydiQA/GP',\n",
       " 'Codex-Eval/Pass@1',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len',\n",
       " 'MTBench(gpt:4:1106:preview)/Turn-1',\n",
       " 'MTBench(gpt:4:1106:preview)/Turn-2',\n",
       " 'MTBench(gpt:4:1106:preview)/Rating',\n",
       " 'Average',\n",
       " 'ranking']"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rosemary import parse_kv_from_string\n",
    "\n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', ]\n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', ]\n",
    "\n",
    "\n",
    "def compute_nonchateval_average_performance(row):\n",
    "    L = [row[k] for k in non_chateval_task_names if k in row]\n",
    "    return np.average(L)\n",
    "\n",
    "\n",
    "def parse_prune_subset_size(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'(?<=pace=)([^_]+)', run_name)\n",
    "    if match:\n",
    "        pace = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(pace)\n",
    "        subset_size = int(kvs['size'] / kvs['ep'])\n",
    "        return subset_size\n",
    "    else:\n",
    "        if run_name.endswith('_ep=2'):\n",
    "            return 50_000\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def parse_sort_by_from_run_name(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'score=([^_]+)', run_name)\n",
    "    if match:\n",
    "        sort_by = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(sort_by)\n",
    "    else:\n",
    "        if run_name.endswith('_ep=2'):\n",
    "            kvs = {0: 'sft_ep=2'}\n",
    "        else:\n",
    "            kvs = {}\n",
    "    return kvs\n",
    "\n",
    "\n",
    "def parse_sort_by_type(row):\n",
    "    d = row['sort_by']\n",
    "    if not d:\n",
    "        return None\n",
    "    if d[0] == 'dppmap':\n",
    "        if d['k']=='vmf' and d['kmd']=='mpnet': #and (d['gamma']==1 or d['gamma'] == 'auto1000'):\n",
    "            return 'vmf+text'\n",
    "        elif d['kemb']=='text+embedding' and d['kmd'] == 'llama7br512p4096':\n",
    "            if d['k']=='rbf': return f\"rbf+text_gamma={d['gamma']}\"\n",
    "            elif d['k'] == 'vmf': return f\"vmf+text_gamma={d['gamma']}\"\n",
    "        elif d['kemb']=='grad+rp+loraB' and d['kmd'] == 'llama7br512p4096':\n",
    "            if d['k']=='rbf': return f\"rbf+grad_gamma={d['gamma']}\"\n",
    "            elif d['k']=='vmf': return f\"vmf+grad_gamma={d['gamma']}\"\n",
    "        else:\n",
    "            print(d)\n",
    "            return None\n",
    "    elif d[0] == 'random':\n",
    "        return 'random'\n",
    "    elif d[0].startswith('sft'):\n",
    "        return d[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "base_model_perf = df[df['run_name'] == 'llama-7b'].to_dict(orient='records')[0]\n",
    "base_model_perf['nonchat'] = compute_nonchateval_average_performance(base_model_perf)\n",
    "\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "dfc.insert(1, 'sort_by' if chat_fmt!='both' else ('sort_by', ''), dfc.apply(parse_sort_by_from_run_name, axis=1))\n",
    "dfc.insert(1, 'sort_by_type' if chat_fmt!='both' else ('sort_by_type', ''), dfc.apply(parse_sort_by_type, axis=1))\n",
    "dfc.insert(1, 'subset_size' if chat_fmt!='both' else ('subset_size', ''), dfc.apply(parse_prune_subset_size, axis=1))\n",
    "dfc.insert(1, 'nonchat' if chat_fmt!='both' else ('nonchat', ''), dfc.apply(compute_nonchateval_average_performance, axis=1))\n",
    "\n",
    "\n",
    "dfc = dfc[dfc['sort_by_type'].notnull()]\n",
    "startswithstrs = ('rbf+text', 'random')\n",
    "startswithstrs = (\n",
    "    'sft_ep=2',\n",
    "    'random', \n",
    "    'vmf+grad_gamma=1',\n",
    "#     'rbf+text_gamma=0.001', \n",
    "#     'vmf+text_gamma=10',\n",
    "#     'rbf+text_gamma=auto1000', \n",
    "#     'vmf+grad_gamma=auto1000',\n",
    ")\n",
    "dfc = dfc[dfc.apply(lambda x: x['sort_by_type'].startswith(startswithstrs)\n",
    "                   , axis=1)]\n",
    "dfc['subset_size'] = dfc['subset_size'].apply(lambda x: int(x) if x else x)\n",
    "# dfc = dfc[dfc['subset_size']>1_000]\n",
    "\n",
    "\n",
    "D = dfc.set_index(['sort_by_type', 'dataset', 'subset_size']).to_dict()\n",
    "from dataclasses import dataclass\n",
    "@dataclass(unsafe_hash=True)\n",
    "class DKey:\n",
    "    sort_by_type: str\n",
    "    dataset: str\n",
    "    subset_size: int\n",
    "def convert_key_to_dataclass(d):\n",
    "    return {DKey(*k): v for k, v in d.items()}\n",
    "D = {k: convert_key_to_dataclass(v) for k, v in D.items()}\n",
    "\n",
    "list(D.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "662539cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 18 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 50_000\n",
    "\n",
    "plt_base_model = True\n",
    "xaxis_type = 'data'\n",
    "# xaxis_type = 'compute'\n",
    "yaxis_type = 'abs'; plt_full_finetune = True\n",
    "# yaxis_type = 'delta_random'; plt_full_finetune = False\n",
    "yaxis_type = 'delta_fullfinetune'; plt_full_finetune = True\n",
    "assert(yaxis_type in ['delta_random', 'abs', 'delta_fullfinetune'])\n",
    "\n",
    "datasets = ['flan_v250k', 'dolly', 'stanford_alpaca50k', 'ultrachat50k', 'wizardlm50k', 'sharegpt50k']\n",
    "# datasets = ['flan_v250k', 'stanford_alpaca50k', 'oasst2', 'ultrachat50k', 'wizardlm50k', 'sharegpt50k']\n",
    "\n",
    "# datasets = list(np.unique(dfc['dataset']))\n",
    "task_names = ['nonchat', 'MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR*',]\n",
    "task_names = []\n",
    "task_names += ['nonchat']\n",
    "# task_names += ['MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1',]\n",
    "# task_names += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "# task_names += [f'MTBench({mtbench_judge})/Rating']\n",
    "# task_names += [f'MTBench({mtbench_judge})/Turn-1']\n",
    "task_names += [f'AlpacaFarm({alpacafarm_judge})/WR*']\n",
    "# task_names += [f'AlpacaFarm({alpacafarm_judge})/WR', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "\n",
    "with plt.style.context('default'): # default\n",
    "\n",
    "    w = 2\n",
    "    ncols = len(datasets)\n",
    "    nrows = len(task_names)\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(w*ncols+3,w*nrows+1), sharey='row', sharex=True)\n",
    "\n",
    "    xticks_data = []\n",
    "\n",
    "    for axi, task_name in enumerate(task_names):\n",
    "        d = D[task_name]\n",
    "        for axj, dataset in enumerate(datasets):\n",
    "            ax = axs.reshape(nrows, ncols)[axi, axj]\n",
    "            sort_by_types = sorted(set(x.sort_by_type for x in d.keys())) # -set(['sft_ep=2'])\n",
    "\n",
    "            for i, sort_by_type in enumerate(sort_by_types):\n",
    "                xs = sorted([x.subset_size for x in d.keys()\n",
    "                             if x.dataset == dataset and x.sort_by_type==sort_by_type])\n",
    "                xticks_data += list(set(xs) - set(xticks_data))\n",
    "                \n",
    "                ys = [d[DKey(sort_by_type, dataset, x)] for x in xs]\n",
    "                if yaxis_type == 'delta_random':\n",
    "                    if not all(DKey('random', dataset, x) in d for x in xs): continue\n",
    "                    ys = [y-d[DKey('random', dataset, x)] for x, y in zip(xs, ys)] \n",
    "                elif yaxis_type == 'delta_fullfinetune':\n",
    "                    if DKey('sft_ep=2', dataset, N) not in d: continue\n",
    "                    ys = [y-d[DKey('sft_ep=2', dataset, N)] for y in ys]\n",
    "                kwargs = {}\n",
    "                if 'random' in sort_by_type:\n",
    "                    kwargs['color'] = 'gray'\n",
    "                elif 'sft_ep=2' in sort_by_type:\n",
    "                    kwargs['color'] = '#FFA500'\n",
    "                xs = xs if xaxis_type == 'data' else [data_to_compute_pct[x] for x in xs]\n",
    "                ax.plot(xs, ys, 'o-', label=sort_by_type, **kwargs)\n",
    "                ax.grid()\n",
    "                \n",
    "            if plt_full_finetune:\n",
    "                k = DKey('sft_ep=2', dataset, N)\n",
    "                if k in d:\n",
    "                    y = 0 if yaxis_type == 'delta_fullfinetune' else d[k]\n",
    "                    ax.axhline(y=y, linestyle='--', color='#FFA500', label='sft_ep=2')\n",
    "                    \n",
    "            if plt_base_model and axi == 0:\n",
    "                k = DKey('sft_ep=2', dataset, N)\n",
    "                if k in d:\n",
    "                    y_fullfinetune = d[k]\n",
    "                    y_base = base_model_perf[task_name]\n",
    "                    y = y_base-y_fullfinetune if yaxis_type == 'delta_fullfinetune' else y_base\n",
    "                    ax.axhline(y=y, linestyle='--', color='#FFE0B2', label='base')\n",
    "                \n",
    "            \n",
    "\n",
    "    for axi, task_name in enumerate(task_names):\n",
    "        task_name_shortened = task_name.replace(f'({mtbench_judge})', '').replace(f'({alpacafarm_judge})', '')\n",
    "        axs.reshape(nrows, ncols)[axi, 0].set_ylabel('△ '+task_name_shortened if yaxis_type.startswith('delta') else task_name_shortened, fontsize=13)\n",
    "        axs.reshape(nrows, ncols)[axi, -1].legend(loc='center left', bbox_to_anchor=(1.1, 0.5))\n",
    "        \n",
    "    xticks_data = np.array(sorted(xticks_data))\n",
    "    xticks_compute = np.array([data_to_compute_pct[x] for x in xticks_data])\n",
    "    xticks = xticks_data if xaxis_type == 'data' else xticks_compute\n",
    "    for axj, dataset in enumerate(datasets):\n",
    "        ax = axs.reshape(nrows, ncols)[nrows-1, axj]\n",
    "        ax.set_xticks(xticks, [f'{x*100:.0f}%' for x in xticks_data/N], fontsize=13, rotation=45)\n",
    "        \n",
    "        ax = axs.reshape(nrows, ncols)[0, axj]\n",
    "        ax.set_title(dataset, fontsize=18)\n",
    "        \n",
    "        ax = axs.reshape(nrows, ncols)[0, axj].twiny()\n",
    "        data_to_compute_pct = {1000: 10, 10000: 30, 20000: 60, 40000: 80, 50000: 100}\n",
    "        ax.set_xticks(xticks, [f'{x*100:.0f}%' for x in xticks_compute/100], fontsize=13, rotation=45)\n",
    "        \n",
    "        \n",
    "    axs.reshape(nrows, ncols)[0, ncols-1].annotate('Compute', xy=(1.2, 1.15), xycoords=\"axes fraction\", ha='left', va='center', fontsize=15)\n",
    "    axs.reshape(nrows, ncols)[nrows-1, ncols-1].annotate('Data', xy=(1.2, -.15), xycoords=\"axes fraction\", ha='left', va='center', fontsize=15)\n",
    "\n",
    "            \n",
    "    space = 0.05\n",
    "    fig.subplots_adjust(wspace=space, hspace=space)  # Adjust the value as needed\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5fdb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e2f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39874bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
