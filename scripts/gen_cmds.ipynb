{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3da1794b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'x86_64', 'cluster': 'ccc', 'queue': None}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "import re\n",
    "from llm.submit import (\n",
    "    multiline_to_singleline,\n",
    "    submit_job_ccc,\n",
    "    submit_job_aimos,\n",
    "    submit_job,\n",
    "        get_run_statistics)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import datetime\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import base64\n",
    "string_to_alphanumeric = lambda s: base64.urlsafe_b64encode(s.encode('utf-8')).decode('utf-8')\n",
    "alphanumeric_to_string = lambda a: base64.urlsafe_b64decode(a).decode('utf-8')\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm, shell_scripts_template_lsf, get_host_info, move_lsf_job_summary_to_save_dir\n",
    "from note_pruning_analysis import open_instruct_dir\n",
    "import getpass\n",
    "\n",
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "info = get_host_info()\n",
    "info.update({'queue': queue})\n",
    "arch, cluster = info['arch'], info['cluster']\n",
    "print(info)\n",
    "\n",
    "os.environ['TORCHELASTIC_ERROR_FILE'] = os.path.join(os.getcwd(), 'torchelastic_error_file') \n",
    "\n",
    "## jobs submitted in notebook inherits env variables.\n",
    "cache_dir = '../../../../mitibm2023/cache'\n",
    "os.environ['WANDB_DIR'] = cache_dir\n",
    "os.makedirs(os.environ['WANDB_DIR'], exist_ok=True)\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_PROJECT'] = 'mitibm'\n",
    "##\n",
    "##\n",
    "\n",
    "shell_scripts_template = shell_scripts_template_slurm \\\n",
    "    if arch == 'ppc64le' else shell_scripts_template_lsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c421d1",
   "metadata": {},
   "source": [
    "# DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c09b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/oi2/llama-7b_sharegptv2_ep=2 using 6 GPUs, 1 batch size per GPU, 1 gradient accumulation steps, 30 effective batch size.\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp7pssto1b', 'job_id': 1354503}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2p8zx1bt', 'job_id': 1354504}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2_mpillk', 'job_id': 1354505}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm\n",
    "debug = False\n",
    "if debug:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'INFO'\n",
    "    os.environ['NCCL_DEBUG'] = 'INFO'\n",
    "else:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'WARNING'\n",
    "    os.environ['NCCL_DEBUG'] = ''\n",
    "num_cpus = 144 if arch == 'ppc64le' else 32\n",
    "cpu_mem =  650 if arch == 'ppc64le' else 64\n",
    "\n",
    "preprocessing_num_workers = 32\n",
    "report_to = 'wandb'\n",
    "mixed_precision = 'bf16' if arch == 'x86_64' else 'fp16'\n",
    "torch_dtype = 'bfloat16' if arch=='x86_64' else 'float32'\n",
    "gradient_checkpointing = True\n",
    "use_fast_tokenizer = True\n",
    "hf_models_dir = 'results/baselines/'\n",
    "resume_from_checkpoint = True # resume from latest checkpoint if exists, otherwise train from scratch\n",
    "num_train_epochs = 2\n",
    "checkpointing_steps = 300 # (50_000 / 32) * 2 / 6 ~= 500 (data size of 50k, bsz=32, ep=2, total save 6 times at most)\n",
    "max_train_steps = None\n",
    "subsample_inds_file_list = [None]\n",
    "dataloader_sampler = 'RandomSampler'\n",
    "overwrite_cache = True\n",
    "\n",
    "\n",
    "# #####\n",
    "# job_name = 'dpo1'\n",
    "\n",
    "# # model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-410m-deduped'; max_seq_length = 2048; abbr_model_name = 'pythia-410m'\n",
    "# # model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "\n",
    "# train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "\n",
    "\n",
    "# M = 60_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 20_000\n",
    "# M = 50_000; pacing_fn_list = [f'prune_size={M}_ep=5']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "    (10_000, 10),\n",
    "#     (30_000, 3),\n",
    "]]\n",
    "\n",
    "gen_output_md = 'llama7br512p4096'\n",
    "# gen_output_md = 'llama7b+sharegptv2ep2+r512p4096'\n",
    "# gen_output_model_name = 'all-mpnet-base-v2'\n",
    "\n",
    "scoring_fn_list = []\n",
    "scoring_fn_list += ['random_s=0']\n",
    "# scoring_fn_list += ['random_s=1']\n",
    "scoring_fn_list += [ \n",
    "    f'dppmap_k=vmf_gamma=1_kmd={gen_output_md}_kemb=grad+rp+loraB',\n",
    "    f'dppmap_k=rbf_gamma=1e-3_kmd={gen_output_md}_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1_kmd=mpnet_kemb=text+embedding',\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'dpo2_{dataset}:{abbr_model_name}'\n",
    "    \n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12\n",
    "# nodes = 2; num_gpus = 1; gpu_type = 'v100'; job_duration = 6; cpu_mem = 100; num_cpus = 32; max_train_steps = 5; checkpointing_steps = 2; report_to = 'tensorboard'\n",
    "\n",
    "    \n",
    "#####\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs = 1 # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "use_deepspeed = True\n",
    "deepspeed_config_file = 'ds_configs/stage3_no_offloading_accelerate.conf'\n",
    "\n",
    "per_device_train_batch_size = 1; total_batch_size = 32\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"{effective_batch_size} effective batch size.\")\n",
    "\n",
    "# reference: https://gist.github.com/pacman100/1cb1f17b2f1b3139a63b764263e70b25\n",
    "launcher = f\"\"\"accelerate launch \\\n",
    "    --mixed_precision {mixed_precision} \\\n",
    "    --num_machines {nodes} \\\n",
    "    --num_processes {num_gpus*nodes} \\\n",
    "    {'--use_deepspeed' if use_deepspeed else ''} \\\n",
    "    {'--deepspeed_config_file '+deepspeed_config_file if use_deepspeed else ''} \\\n",
    "    {'--main_process_ip $master_addr' if use_deepspeed else ''} \\\n",
    "    {'--main_process_port $master_port' if use_deepspeed else ''} \\\n",
    "    {'--machine_rank $SLURM_PROCID' if use_deepspeed else ''} \\\n",
    "    {'--rdzv_backend c10d' if use_deepspeed and nodes>1 else ''} \\\n",
    "    {'--deepspeed_multinode_launcher standard' if use_deepspeed and nodes>1 else ''} \\\n",
    "\"\"\"\n",
    "\n",
    "cmds = []\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    subsample_inds_file_list,\n",
    ")\n",
    "\n",
    "output_dirname_list = []\n",
    "for (subsample_inds_file,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{dataset}\"\n",
    "    if any(job_name == y for y in ['dpo1']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "\n",
    "    if subsample_inds_file:\n",
    "        assert(num_train_epochs==1)\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                s = f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "\n",
    "    if subsample_inds_file is not None:\n",
    "        assert(dataloader_sampler=='SequentialSampler')\n",
    "        assert(num_train_epochs==1)\n",
    "    else:\n",
    "        assert(dataloader_sampler=='RandomSampler')\n",
    "\n",
    "    output_dir = os.path.join('results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join('results', job_name), exist_ok=True)\n",
    "    wandb_run_name = output_dir.replace('results/', '')\n",
    "\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {f'cd .. && CUDA_VISIBLE_DEVICES={os.environ[\"CUDA_VISIBLE_DEVICES\"]} ' if test_run else ''}{launcher}\n",
    "        open_instruct/dpo_tune.py \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --tokenizer_name {model_name_or_path} \\\n",
    "        {'--use_slow_tokenizer' if not  use_fast_tokenizer else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        --train_file {train_file} \\\n",
    "        --max_seq_length {max_seq_length} \\\n",
    "        {'--subsample_inds_file '+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        --dataloader_sampler {dataloader_sampler} \\\n",
    "        --preprocessing_num_workers {preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size {per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
    "        --learning_rate 5e-7 \\\n",
    "        --lr_scheduler_type linear \\\n",
    "        --warmup_ratio 0.1 \\\n",
    "        --weight_decay 0. \\\n",
    "        --num_train_epochs {num_train_epochs} \\\n",
    "        --with_tracking \\\n",
    "        {'--report_to \"'+str(report_to)+'\"' if report_to else ''} \\\n",
    "        --checkpointing_steps {checkpointing_steps} \\\n",
    "        {'--max_train_steps '+str(max_train_steps) if max_train_steps else ''} \\\n",
    "        {'--resume_from_checkpoint' if resume_from_checkpoint else ''} \\\n",
    "        {'--low_cpu_mem_usage' if not use_deepspeed else ''} \\\n",
    "        {'--overwrite_cache' if overwrite_cache else ''} \\\n",
    "        --logging_steps 1 \\\n",
    "        --output_dir {output_dir}\n",
    "    \"\"\"\n",
    "    # if test_run:\n",
    "    #     print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    if test_run:\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64': # ccc\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "        queue=queue,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b79b9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_dpo.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce604bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=5\n",
      "+ cd ..\n",
      "+ CUDA_VISIBLE_DEVICES=2,5\n",
      "+ accelerate launch --mixed_precision fp16 --num_machines 1 --num_processes 2 --use_deepspeed --deepspeed_config_file ds_configs/stage3_no_offloading_accelerate.conf open_instruct/dpo_tune.py --model_name_or_path results/baselines/huggyllama/llama-7b --tokenizer_name results/baselines/huggyllama/llama-7b --gradient_checkpointing --train_file data/processed/ultrafeedback/ultrafeedback_data.jsonl --max_seq_length 2048 --preprocessing_num_workers 32 --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --learning_rate 5e-7 --lr_scheduler_type linear --warmup_ratio 0.1 --weight_decay 0. --num_train_epochs 2 --with_tracking --report_to tensorboard --checkpointing_steps 500 --logging_steps 1 --output_dir results/dpo1/jpt_llama-7b_ultrafeedback\n",
      "[2024-01-08 20:41:08,547] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "[2024-01-08 20:41:17,396] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-08 20:41:17,400] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:662:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,611] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 1\n",
      "Local process index: 1\n",
      "Device: cuda:1\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 251.17it/s]\n",
      "01/08/2024 20:41:25 - WARNING - datasets.builder - Found cached dataset json (/gpfs/u/scratch/PTFM/PTFMqngp/huggingface_cache/datasets/json/default-201ebfceee303348/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 252.78it/s]\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:26,493] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 6.74B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.74s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:16<00:00,  8.11s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:43,556] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 13.48B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.60s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "01/08/2024 20:42:20 - INFO - accelerate.accelerator - Updating DeepSpeed's gradient accumulation steps to 16 from 1.\n",
      "[2024-01-08 20:42:20,382] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.1+23a11a39, git-hash=23a11a39, git-branch=master\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 1\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "[2024-01-08 20:42:20,751] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n",
      "[2024-01-08 20:42:20,779] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\n",
      "[2024-01-08 20:42:20,891] [INFO] [utils.py:786:see_memory_usage] Stage 3 initialize beginning\n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 14.16 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.9 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:118:__init__] Reduce bucket size 16777216\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:119:__init__] Prefetch bucket size 15099494\n",
      "[2024-01-08 20:42:20,995] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 13.64 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n",
      "[2024-01-08 20:42:21,139] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.76 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:21,240] [INFO] [utils.py:786:see_memory_usage] Before creating fp16 partitions\n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.4 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:23,090] [INFO] [utils.py:786:see_memory_usage] After creating fp16 partitions: 4\n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.4 GB         CA 14.6 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.99 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,190] [INFO] [utils.py:786:see_memory_usage] Before creating fp32 partitions\n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.39 GB         CA 14.6 GB         Max_CA 15 GB \n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.81 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,742] [INFO] [utils.py:786:see_memory_usage] After creating fp32 partitions\n",
      "[2024-01-08 20:42:23,743] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 26.61 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,744] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 116.15 GB, percent = 16.7%\n",
      "[2024-01-08 20:42:23,836] [INFO] [utils.py:786:see_memory_usage] Before initializing optimizer states\n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 25.94 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 117.28 GB, percent = 16.8%\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 1; 31.75 GiB total capacity; 25.93 GiB already allocated; 3.34 GiB free; 27.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 0; 31.75 GiB total capacity; 25.94 GiB already allocated; 3.21 GiB free; 27.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 409110) of binary: /gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/python3.10\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 964, in launch_command\r\n",
      "    deepspeed_launcher(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 687, in deepspeed_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "open_instruct/dpo_tune.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 409111)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 409110)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_dpo.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c8b",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune_trainer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19aebd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/baselines/huggyllama/llama-7b using 2 GPUs, 2 batch size per GPU, 32 gradient accumulation steps, Effective batch size 128\n",
      "\n",
      "cd .. && TORCHELASTIC_ERROR_FILE=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/error_file TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 --master_port=10002 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/flan_v2/flan_v2_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=32 --per_device_train_batch_size=2 --gradient_accumulation_steps=32 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=100 --report_to tensorboard wandb --run_name /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_flan_v2:llama-7b/jpt_llama-7b_flan_v2_score=random:s=0_pace=prune:size=10000:ep=10 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=100 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --gradient_checkpointing --torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --overwrite_output_dir --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/flan_v2/random_s=0/inds_prune_size=10000_ep=10.pkl --dataloader_sampler SequentialSampler --use_flash_attn True --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_flan_v2:llama-7b/jpt_llama-7b_flan_v2_score=random:s=0_pace=prune:size=10000:ep=10\"\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_flan_v2:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 192,\n",
      "    \"num_gpus\": 2,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"x86_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "add_hardwarespec_to_dirname = False\n",
    "save_strategy = 'steps'\n",
    "save_steps = 100 if getpass.getuser() in ('PTFMqngp', 'wpq') else 1_000_000\n",
    "save_total_limit = 1\n",
    "preprocessing_num_workers = 32\n",
    "evaluation_strategy = 'no' # set do_eval=False\n",
    "eval_steps = save_steps\n",
    "report_to = 'tensorboard wandb'\n",
    "suffix = None\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0.03\n",
    "dataloader_sampler = None\n",
    "hf_models_dir = 'results/baselines/'\n",
    "subsample_inds_file_list = [None]\n",
    "max_train_samples_list = [None]\n",
    "num_train_epochs_list = [1]\n",
    "scoring_fn_and_pacing_fn = None\n",
    "\n",
    "\n",
    "# ########### sft baselines\n",
    "\n",
    "\n",
    "# job_name = 'oi2'; num_train_epochs_list = [2] \n",
    "# # model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "\n",
    "# # train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca'; \n",
    "# # train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# # train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2'; max_train_samples_list=[100_000]\n",
    "\n",
    "# # train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2'; max_train_samples_list=[100_000]\n",
    "# ###########\n",
    "\n",
    "\n",
    "############ pruning runs\n",
    "\n",
    "# model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048; gen_output_md = 'mistral7br512p4096'\n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048; gen_output_md = 'llama7br512p4096'\n",
    "\n",
    "\n",
    "dataset = 'flan_v2'; train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca';\n",
    "# dataset = 'oasst1'; train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1'; \n",
    "# dataset = 'wizardlmv2'; train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2';\n",
    "# dataset = 'sharegptv2'; train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2';\n",
    "# dataset = 'ultrachat200kv2'; train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2';\n",
    "\n",
    "# dataset = 'open_orca_slim'; train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; \n",
    "# dataset = 'tulu_v2'; train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2';\n",
    "        \n",
    "# M = 80_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 40_000\n",
    "# M = 40_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 20_000\n",
    "# M = 30_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [\n",
    "    f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "        (10_000, 10),\n",
    "        (20_000, 4),\n",
    "        (30_000, 3),\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "scoring_fn_list = [\n",
    "    'random_s=0',\n",
    "#     'random_s=1',\n",
    "#     'log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n',\n",
    "#     'ifd_neg', 'log_pmi_neg',\n",
    "#     'numtoks_input_neg', 'numtoks_output_neg', 'numtoks_total_neg',\n",
    "#     f'dppmap_k=vmf_gamma=1_kmd=mpnet', #_kemb=text+embedding',\n",
    "    f'dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding',\n",
    "    f'dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB',\n",
    "]\n",
    "\n",
    "scoring_fn_list += [ # vary kernel embedding model \n",
    "#     f'dppmap_k=vmf_gamma=auto{subset_size}_kmd={kmd}_kemb=grad+rp+loraB'\n",
    "#     for kmd in ['llama7br256p4096', 'llama7br512p4096', 'pythia1br512p4096']\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'oi5_{dataset}:{abbr_model_name}'\n",
    "############ \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "debug_mode = test_run\n",
    "\n",
    "if arch == 'x86_64':\n",
    "#     nodes = 1; num_gpus = 1; gpu_type = 'a100_80gb'; job_duration = 6\n",
    "    nodes = 1; num_gpus = 2; gpu_type = 'a100_80gb'; job_duration = 6\n",
    "    num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus)\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_checkpointing = True\n",
    "    mixed_precision = 'bf16'; torch_dtype = 'bfloat16'; use_flash_attn = True\n",
    "else:\n",
    "    nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "#     nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12\n",
    "#     nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 18\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_checkpointing = True\n",
    "    mixed_precision = 'fp16'; torch_dtype = 'float32'; use_flash_attn = False\n",
    "    \n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs_list = [1] # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "overwrite_output_dir = True if test_run else False # always continue from ckpt if run from cluster.\n",
    "\n",
    "total_batch_size = 128\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "optimizer = 'adamw_hf'\n",
    "\n",
    "deepspeed = ''; fsdp = False if num_gpus == 1 else \"full_shard auto_wrap\" \n",
    "if 'gpt2' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPT2Block'\n",
    "elif 'llama' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'LlamaDecoderLayer'\n",
    "elif 'mpt' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MPTBlock'\n",
    "elif 'pythia' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPTNeoXLayer'        \n",
    "elif 'mistral' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MistralDecoderLayer'\n",
    "else: raise ValueError('Not sure how to set `fsdp_transformer_layer_cls_to_wrap`')\n",
    "    \n",
    "# deepspeed = './ds_configs/ds_zero3_cpu_offload.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/ds_zero3.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/stage3_no_offloading.conf'; fsdp = False # error with loading... something wrong with the config.\n",
    "# fsdp = False; deepspeed = False\n",
    "\n",
    "if fsdp and deepspeed:\n",
    "    raise ValueError('either fsdp or deepspeed, not both')\n",
    "\n",
    "use_lora = False\n",
    "lora_rank = 256 \n",
    "lora_alpha = lora_rank \n",
    "lora_dropout = 0.05\n",
    "if use_lora:\n",
    "    abbr_model_name += f'+lora(r={lora_rank},a={lora_alpha})'\n",
    "load_in_8bit = False\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"Effective batch size {effective_batch_size}\")\n",
    "\n",
    "\n",
    "if nodes == 1:\n",
    "    exe = 'python' if num_gpus==1 else \\\n",
    "        f\"torchrun --nproc_per_node={num_gpus} --master_port=10002\"\n",
    "else:\n",
    "    exe = f\"torchrun --nnodes={nodes} --nproc_per_node={num_gpus} --rdzv-id=$SLURM_JOB_ID --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT\"\n",
    "\n",
    "if test_run:\n",
    "    exe = f\"CUDA_VISIBLE_DEVICES={','.join(map(str, range(num_gpus)))} {exe}\"\n",
    "if test_run and debug_mode:\n",
    "    exe = 'TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO ' + exe\n",
    "    error_file = os.path.join(open_instruct_dir, 'scripts', 'error_file')\n",
    "    exe = f'TORCHELASTIC_ERROR_FILE={error_file} {exe}'\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "options_list = itertools.product(\n",
    "    num_train_epochs_list,\n",
    "    subsample_inds_file_list,\n",
    "    max_train_samples_list,\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "output_dirname_list = []\n",
    "for (num_train_epochs,\n",
    "     subsample_inds_file,\n",
    "     max_train_samples,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{abbr_train_file}\"\n",
    "    if max_train_samples:\n",
    "        output_dirname += f\":{int(max_train_samples/1000)}k\"\n",
    "            \n",
    "    if any(job_name == y for y in ['oi2']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "        \n",
    "    if subsample_inds_file:\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                return f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            else:\n",
    "                return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "            \n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "            \n",
    "    if add_hardwarespec_to_dirname:\n",
    "        output_dirname += \\\n",
    "            ('_fsdp='+fsdp.split(' ')[0] if fsdp else '')+\\\n",
    "            ('_deepspeed='+os.path.basename(deepspeed).split('.')[0] if deepspeed else '')+\\\n",
    "            ('_gradckpt='+str(gradient_checkpointing) if gradient_checkpointing else '')+\\\n",
    "            '_mbsz='+str(per_device_train_batch_size)+\\\n",
    "            '_dtype='+torch_dtype+\\\n",
    "            ('_mp='+str(mixed_precision) if mixed_precision else '_mp=none')+\\\n",
    "            '_seqlen='+str(max_seq_length)+\\\n",
    "            '_nodes='+str(nodes)\n",
    "    if suffix:\n",
    "        output_dirname += suffix\n",
    "    output_dir = os.path.join(open_instruct_dir, 'results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join(open_instruct_dir, 'results', job_name), exist_ok=True)\n",
    "    wandb_run_name = output_dir.replace('results/', '')\n",
    "    \n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {'cd .. && ' if test_run else ''}{exe}\n",
    "        open_instruct/finetune_trainer.py \\\n",
    "        --model_name_or_path={model_name_or_path} \\\n",
    "        --tokenizer_name={model_name_or_path} \\\n",
    "        {'--load_in_8bit' if load_in_8bit else ''} \\\n",
    "        --use_fast_tokenizer=True \\\n",
    "        --train_file={train_file} \\\n",
    "        --max_seq_length={max_seq_length} \\\n",
    "        {'--max_train_samples='+str(max_train_samples) if max_train_samples else ''} \\\n",
    "        {'--use_lora' if use_lora else ''}\n",
    "        {'--lora_rank='+str(lora_rank) if use_lora else ''}\n",
    "        {'--lora_alpha='+str(lora_alpha) if use_lora else ''}\n",
    "        {'--lora_dropout='+str(lora_dropout) if use_lora else ''}\n",
    "        --do_train \\\n",
    "        --preprocessing_num_workers={preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size={per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
    "        --learning_rate=2e-5 \\\n",
    "        --lr_scheduler_type={lr_scheduler_type} \\\n",
    "        --warmup_ratio={warmup_ratio} \\\n",
    "        --weight_decay=0. \\\n",
    "        --optim={optimizer} \\\n",
    "        --evaluation_strategy={evaluation_strategy} \\\n",
    "        {'--eval_steps='+str(eval_steps) if eval_steps else ''} \\\n",
    "        {'--report_to '+str(report_to) if report_to else ''} \\\n",
    "        --run_name {wandb_run_name} \\\n",
    "        --logging_strategy=steps \\\n",
    "        --logging_first_step \\\n",
    "        --logging_steps=1 \\\n",
    "        --save_strategy={save_strategy} \\\n",
    "        --save_steps={save_steps} \\\n",
    "        --save_total_limit={save_total_limit} \\\n",
    "        --num_train_epochs={num_train_epochs} \\\n",
    "        --ddp_timeout=7200 \\\n",
    "        {'--fsdp=\"'+fsdp+'\"' if fsdp else ''}\n",
    "        {'--fsdp_transformer_layer_cls_to_wrap=\"'+fsdp_transformer_layer_cls_to_wrap+'\"' \n",
    "            if fsdp else ''}\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''}\n",
    "        --torch_dtype={torch_dtype} \\\n",
    "        --dataloader_num_workers=8 \\\n",
    "        {f'--{mixed_precision}=True' if mixed_precision else ''} \\\n",
    "        {'--overwrite_output_dir' if overwrite_output_dir else ''} \\\n",
    "        {'--deepspeed='+deepspeed if deepspeed else ''} \\\n",
    "        {'--subsample_inds_file='+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        {'--dataloader_sampler '+str(dataloader_sampler) if dataloader_sampler else ''} \\\n",
    "        --use_flash_attn {'True' if use_flash_attn else 'False'} \\\n",
    "        --low_cpu_mem_usage \\\n",
    "        --overwrite_cache \\\n",
    "        --output_dir=\"{output_dir}\" \\\n",
    "    \"\"\" \n",
    "    #  --overwrite_cache   # if delete a dataset and need to refresh cache\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "    if test_run:\n",
    "        print()\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64':\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        queue=queue,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12fc2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_sft.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed0c2894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=\n",
      "+ cd ..\n",
      "+ TORCHELASTIC_ERROR_FILE=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/error_file\n",
      "+ TORCH_CPP_LOG_LEVEL=INFO\n",
      "+ NCCL_DEBUG=INFO\n",
      "+ LOGLEVEL=INFO\n",
      "+ CUDA_VISIBLE_DEVICES=0,1\n",
      "+ torchrun --nproc_per_node=2 --master_port=10002 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/dolly/dolly_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=32 --per_device_train_batch_size=2 --gradient_accumulation_steps=32 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=100 --report_to tensorboard --run_name /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi2/jpt_llama-7b_dolly_ep=2 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=100 --save_total_limit=1 --num_train_epochs=2 --ddp_timeout=7200 '--fsdp=full_shard auto_wrap' --fsdp_transformer_layer_cls_to_wrap=LlamaDecoderLayer --gradient_checkpointing --torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --overwrite_output_dir --use_flash_attn True --low_cpu_mem_usage --output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi2/jpt_llama-7b_dolly_ep=2\n",
      "[2024-01-14 16:18:53,802] torch.distributed.run: [WARNING] \n",
      "[2024-01-14 16:18:53,802] torch.distributed.run: [WARNING] *****************************************\n",
      "[2024-01-14 16:18:53,802] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "[2024-01-14 16:18:53,802] torch.distributed.run: [WARNING] *****************************************\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO] Starting elastic_operator with launch configs:\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   entrypoint       : open_instruct/finetune_trainer.py\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   min_nodes        : 1\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   max_nodes        : 1\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   nproc_per_node   : 2\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   run_id           : none\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   rdzv_backend     : static\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   rdzv_endpoint    : 127.0.0.1:10002\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   max_restarts     : 0\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   monitor_interval : 5\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   log_dir          : None\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   metrics_cfg      : {}\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO] \n",
      "[2024-01-14 16:18:53,806] torch.distributed.elastic.agent.server.local_elastic_agent: [INFO] log directory set to: /tmp/torchelastic_ksd7enii/none_h8abwftr\n",
      "[2024-01-14 16:18:53,806] torch.distributed.elastic.agent.server.api: [INFO] [default] starting workers for entrypoint: python3.10\n",
      "[2024-01-14 16:18:53,806] torch.distributed.elastic.agent.server.api: [INFO] [default] Rendezvous'ing worker group\n",
      "[I socket.cpp:576] [c10d] The server socket has started to listen on [::]:10002.\n",
      "[I socket.cpp:849] [c10d] The client socket has connected to [localhost]:10002 on [localhost]:53412.\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO] [default] Rendezvous complete for workers. Result:\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   restart_count=0\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   master_addr=127.0.0.1\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   master_port=10002\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   group_rank=0\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   group_world_size=1\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   local_ranks=[0, 1]\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   role_ranks=[0, 1]\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   global_ranks=[0, 1]\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   role_world_sizes=[2, 2]\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   global_world_sizes=[2, 2]\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO] \n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO] [default] Starting worker group\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.local_elastic_agent: [INFO] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.multiprocessing: [INFO] Setting worker0 reply file to: /tmp/torchelastic_ksd7enii/none_h8abwftr/attempt_0/0/error.json\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.multiprocessing: [INFO] Setting worker1 reply file to: /tmp/torchelastic_ksd7enii/none_h8abwftr/attempt_0/1/error.json\n",
      "[2024-01-14 16:19:02,180] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-14 16:19:02,185] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[I socket.cpp:849] [c10d] The client socket has connected to [localhost]:10002 on [localhost]:55424.\n",
      "[I socket.cpp:849] [c10d] The client socket has connected to [localhost]:10002 on [localhost]:55436.\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/training_args.py:1584: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead \n",
      "  warnings.warn(\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/training_args.py:1584: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead \n",
      "  warnings.warn(\n",
      "Saving args dict to /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi2/jpt_llama-7b_dolly_ep=2.args.json\n",
      "Saving args dict to /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi2/jpt_llama-7b_dolly_ep=2.args.json\n",
      "01/14/2024 16:19:07 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 1distributed training: True, 16-bits training: False\n",
      "01/14/2024 16:19:07 - INFO - __main__ - Training parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=8,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_sampler=RandomSampler,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=7200,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=100.0,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[<FSDPOption.FULL_SHARD: 'full_shard'>, <FSDPOption.AUTO_WRAP: 'auto_wrap'>],\n",
      "fsdp_config={'min_num_params': 0, 'transformer_layer_cls_to_wrap': ['LlamaDecoderLayer'], 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=LlamaDecoderLayer,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=32,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi2/jpt_llama-7b_dolly_ep=2/runs/Jan14_16-19-07_cccxc501,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1.0,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi2/jpt_llama-7b_dolly_ep=2,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=2,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi2/jpt_llama-7b_dolly_ep=2,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=True,\n",
      "save_steps=100,\n",
      "save_strategy=steps,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "01/14/2024 16:19:07 - WARNING - __main__ - Process rank: 1, device: cpu, n_gpu: 1distributed training: True, 16-bits training: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3ab84c08398a775b\n",
      "01/14/2024 16:19:07 - INFO - datasets.builder - Using custom data configuration default-3ab84c08398a775b\n",
      "Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "01/14/2024 16:19:07 - INFO - datasets.info - Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "Generating train split: 14956 examples [00:00, 62021.35 examples/s]\n",
      "Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/dolly/json/default-3ab84c08398a775b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "01/14/2024 16:19:07 - INFO - datasets.builder - Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/dolly/json/default-3ab84c08398a775b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/dolly/json/default-3ab84c08398a775b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/14/2024 16:19:07 - INFO - datasets.info - Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/dolly/json/default-3ab84c08398a775b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "[INFO|configuration_utils.py:715] 2024-01-14 16:19:07,912 >> loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "[INFO|configuration_utils.py:777] 2024-01-14 16:19:07,917 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-14 16:19:07,921 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-14 16:19:07,921 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-14 16:19:07,921 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-14 16:19:07,921 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-14 16:19:07,921 >> loading file tokenizer_config.json\n",
      "[INFO|modeling_utils.py:3118] 2024-01-14 16:19:08,480 >> loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1222] 2024-01-14 16:19:08,481 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "Traceback (most recent call last):\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/open_instruct/finetune_trainer.py\", line 791, in <module>\n",
      "    main()\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/open_instruct/finetune_trainer.py\", line 564, in main\n",
      "Traceback (most recent call last):\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/open_instruct/finetune_trainer.py\", line 791, in <module>\n",
      "    model = AutoModelForCausalLM.from_pretrained(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n",
      "    main()\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/open_instruct/finetune_trainer.py\", line 564, in main\n",
      "    model = AutoModelForCausalLM.from_pretrained(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 3233, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 3233, in from_pretrained\n",
      "    config = cls._check_and_enable_flash_attn_2(config, torch_dtype=torch_dtype, device_map=device_map)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 1273, in _check_and_enable_flash_attn_2\n",
      "    config = cls._check_and_enable_flash_attn_2(config, torch_dtype=torch_dtype, device_map=device_map)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 1273, in _check_and_enable_flash_attn_2\n",
      "    raise ImportError(\n",
      "ImportError: Flash Attention 2 is not available. Please refer to the documentation of https://github.com/Dao-AILab/flash-attention for installing it. Make sure to have at least the version 2.1.0\n",
      "    raise ImportError(\n",
      "ImportError: Flash Attention 2 is not available. Please refer to the documentation of https://github.com/Dao-AILab/flash-attention for installing it. Make sure to have at least the version 2.1.0\n",
      "[2024-01-14 16:19:18,852] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2233944) of binary: /dccstor/data-pruning/miniconda3/envs/open-instruct/bin/python3.10\n",
      "[2024-01-14 16:19:18,857] torch.distributed.elastic.multiprocessing.errors: [INFO] ('local_rank %s FAILED with no error file. Decorate your entrypoint fn with @record for traceback info. See: https://pytorch.org/docs/stable/elastic/errors.html', 0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py\", line 806, in main\n",
      "    run(args)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py\", line 797, in run\n",
      "    elastic_launch(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "open_instruct/finetune_trainer.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2024-01-14_16:19:18\n",
      "  host      : cccxc501.pok.ibm.com\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 2233945)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-01-14_16:19:18\n",
      "  host      : cccxc501.pok.ibm.com\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 2233944)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_sft.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831fe55",
   "metadata": {},
   "source": [
    "# eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "499d6f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mtbench_ann=gpt:4:1106:preview_chatfmt', 'results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=20000:ep=4')\n",
      "('mtbench_ann=gpt:4:1106:preview_chatfmt', 'results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=20000:ep=4')\n",
      "('mtbench_ann=gpt:4:1106:preview_chatfmt', 'results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('mtbench_ann=gpt:4:1106:preview_chatfmt', 'results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('mtbench_ann=gpt:4:1106:preview_chatfmt', 'results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('mtbench_ann=gpt:4:1106:preview_chatfmt', 'results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mtbench_ann=gpt:4:1106:preview_chatfmt', 'results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mtbench_ann=gpt:4:1106:preview_chatfmt', 'results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mtbench_ann=gpt:4:1106:preview_chatfmt', 'results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=20000:ep=4')\n",
      "#cmds:  9 \n",
      "\n",
      "\n",
      "python -m fastchat.llm_judge.gen_model_answer \\\n",
      "\t--model-path results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=20000:ep=4 \\\n",
      "\t--model-id tulu \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--max-new-token 2048 \\\n",
      "\t--answer-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=20000:ep=4/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/model_answer.jsonl \\\n",
      "\t--dtype bfloat16 \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.gen_judgment \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--judge-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/judge_prompts.jsonl \\\n",
      "\t--judge-model gpt-4-1106-preview \\\n",
      "\t--mode single \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--answer-dir results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=20000:ep=4/eval/mtbench_ann=gpt:4:1106:preview_chatfmt \\\n",
      "\t--ref-answer-dir /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/reference_answer \\\n",
      "\t--output-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=20000:ep=4/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.show_result \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--input-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=20000:ep=4/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t--mode single \\\n",
      "\t--save-to-json\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mtbench_ann=gpt:4:1106:preview_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"x86_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m fastchat.llm_judge.gen_model_answer \\\n",
      "\t--model-path results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=20000:ep=4 \\\n",
      "\t--model-id tulu \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--max-new-token 2048 \\\n",
      "\t--answer-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=20000:ep=4/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/model_answer.jsonl \\\n",
      "\t--dtype bfloat16 \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.gen_judgment \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--judge-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/judge_prompts.jsonl \\\n",
      "\t--judge-model gpt-4-1106-preview \\\n",
      "\t--mode single \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--answer-dir results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=20000:ep=4/eval/mtbench_ann=gpt:4:1106:preview_chatfmt \\\n",
      "\t--ref-answer-dir /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/reference_answer \\\n",
      "\t--output-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=20000:ep=4/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.show_result \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--input-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=20000:ep=4/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t--mode single \\\n",
      "\t--save-to-json\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mtbench_ann=gpt:4:1106:preview_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"x86_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m fastchat.llm_judge.gen_model_answer \\\n",
      "\t--model-path results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=10000:ep=10 \\\n",
      "\t--model-id tulu \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--max-new-token 2048 \\\n",
      "\t--answer-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=10000:ep=10/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/model_answer.jsonl \\\n",
      "\t--dtype bfloat16 \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.gen_judgment \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--judge-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/judge_prompts.jsonl \\\n",
      "\t--judge-model gpt-4-1106-preview \\\n",
      "\t--mode single \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--answer-dir results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=10000:ep=10/eval/mtbench_ann=gpt:4:1106:preview_chatfmt \\\n",
      "\t--ref-answer-dir /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/reference_answer \\\n",
      "\t--output-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=10000:ep=10/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.show_result \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--input-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=10000:ep=10/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t--mode single \\\n",
      "\t--save-to-json\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mtbench_ann=gpt:4:1106:preview_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"x86_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m fastchat.llm_judge.gen_model_answer \\\n",
      "\t--model-path results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10 \\\n",
      "\t--model-id tulu \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--max-new-token 2048 \\\n",
      "\t--answer-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/model_answer.jsonl \\\n",
      "\t--dtype bfloat16 \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.gen_judgment \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--judge-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/judge_prompts.jsonl \\\n",
      "\t--judge-model gpt-4-1106-preview \\\n",
      "\t--mode single \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--answer-dir results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/mtbench_ann=gpt:4:1106:preview_chatfmt \\\n",
      "\t--ref-answer-dir /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/reference_answer \\\n",
      "\t--output-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.show_result \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--input-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t--mode single \\\n",
      "\t--save-to-json\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mtbench_ann=gpt:4:1106:preview_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"x86_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m fastchat.llm_judge.gen_model_answer \\\n",
      "\t--model-path results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10 \\\n",
      "\t--model-id tulu \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--max-new-token 2048 \\\n",
      "\t--answer-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/model_answer.jsonl \\\n",
      "\t--dtype bfloat16 \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.gen_judgment \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--judge-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/judge_prompts.jsonl \\\n",
      "\t--judge-model gpt-4-1106-preview \\\n",
      "\t--mode single \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--answer-dir results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/mtbench_ann=gpt:4:1106:preview_chatfmt \\\n",
      "\t--ref-answer-dir /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/reference_answer \\\n",
      "\t--output-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.show_result \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--input-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t--mode single \\\n",
      "\t--save-to-json\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mtbench_ann=gpt:4:1106:preview_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"x86_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m fastchat.llm_judge.gen_model_answer \\\n",
      "\t--model-path results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3 \\\n",
      "\t--model-id tulu \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--max-new-token 2048 \\\n",
      "\t--answer-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/model_answer.jsonl \\\n",
      "\t--dtype bfloat16 \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.gen_judgment \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--judge-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/judge_prompts.jsonl \\\n",
      "\t--judge-model gpt-4-1106-preview \\\n",
      "\t--mode single \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--answer-dir results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt \\\n",
      "\t--ref-answer-dir /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/reference_answer \\\n",
      "\t--output-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.show_result \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--input-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t--mode single \\\n",
      "\t--save-to-json\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mtbench_ann=gpt:4:1106:preview_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"x86_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m fastchat.llm_judge.gen_model_answer \\\n",
      "\t--model-path results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3 \\\n",
      "\t--model-id tulu \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--max-new-token 2048 \\\n",
      "\t--answer-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/model_answer.jsonl \\\n",
      "\t--dtype bfloat16 \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.gen_judgment \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--judge-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/judge_prompts.jsonl \\\n",
      "\t--judge-model gpt-4-1106-preview \\\n",
      "\t--mode single \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--answer-dir results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt \\\n",
      "\t--ref-answer-dir /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/reference_answer \\\n",
      "\t--output-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.show_result \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--input-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t--mode single \\\n",
      "\t--save-to-json\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mtbench_ann=gpt:4:1106:preview_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"x86_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m fastchat.llm_judge.gen_model_answer \\\n",
      "\t--model-path results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=30000:ep=3 \\\n",
      "\t--model-id tulu \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--max-new-token 2048 \\\n",
      "\t--answer-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/model_answer.jsonl \\\n",
      "\t--dtype bfloat16 \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.gen_judgment \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--judge-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/judge_prompts.jsonl \\\n",
      "\t--judge-model gpt-4-1106-preview \\\n",
      "\t--mode single \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--answer-dir results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt \\\n",
      "\t--ref-answer-dir /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/reference_answer \\\n",
      "\t--output-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.show_result \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--input-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t--mode single \\\n",
      "\t--save-to-json\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mtbench_ann=gpt:4:1106:preview_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"x86_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m fastchat.llm_judge.gen_model_answer \\\n",
      "\t--model-path results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=20000:ep=4 \\\n",
      "\t--model-id tulu \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--max-new-token 2048 \\\n",
      "\t--answer-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=20000:ep=4/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/model_answer.jsonl \\\n",
      "\t--dtype bfloat16 \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.gen_judgment \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--judge-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/judge_prompts.jsonl \\\n",
      "\t--judge-model gpt-4-1106-preview \\\n",
      "\t--mode single \\\n",
      "\t--question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl \\\n",
      "\t--answer-dir results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=20000:ep=4/eval/mtbench_ann=gpt:4:1106:preview_chatfmt \\\n",
      "\t--ref-answer-dir /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/reference_answer \\\n",
      "\t--output-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=20000:ep=4/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t&& \\\n",
      "\tpython -m fastchat.llm_judge.show_result \\\n",
      "\t--bench-name mt_bench \\\n",
      "\t--input-file results/oi5_stanford_alpaca:llama-7b/llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=20000:ep=4/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/gpt-4-1106-preview_single.jsonl \\\n",
      "\t--mode single \\\n",
      "\t--save-to-json\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mtbench_ann=gpt:4:1106:preview_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"x86_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from gen_cmds_utils import remove_all_symlinks, create_unique_symlinks, get_chat_formatting_function, get_resource_for_task, OPENAI_MODEL_LIST\n",
    "\n",
    "create_symlinks = False\n",
    "include_checkpoints = False\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "use_slow_tokenizer = True\n",
    "definitely_run_mtbench_on_non_alt7b_queue = False\n",
    "\n",
    "task_names = [\n",
    "    'mmlu_s=0',\n",
    "    'mmlu_s=5', \n",
    "    'gsm_s=8',\n",
    "    'gsm_s=8_cot',\n",
    "    'bbh_s=3',\n",
    "    'bbh_s=3_cot', # max_datapoints_per_task=40 -> 40min.\n",
    "    'humaneval',\n",
    "    'tydiqa_s=1_cb', # 3min\n",
    "    'tydiqa_s=1_gp',\n",
    "    # 'toxigen', # ~1.5hr\n",
    "#     'alpacafarm_ann=gpt35:turbo:1106',\n",
    "    # 'alpacafarm_ann=chatgpt', # ~$1 per eval.\n",
    "]\n",
    "task_names_mtbench = ['mtbench_ann=gpt:4:1106:preview_chatfmt'] # ann=gpt:4, ann=gpt:3.5:turbo:1106, gpt:4:1106:preview (gpt4-turbo)\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:3.5:turbo:1106_chatfmt'] # for debug sake, prefer gpt4\n",
    "task_names_alpacafarm = ['alpacafarm_ann=chatgpt_chatfmt']\n",
    "task_names_chatfmt = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "# # ## baselines eval \n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "# #     'huggyllama/llama-7b', \n",
    "# #     'mistralai/Mistral-7B-v0.1',\n",
    "# #     'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "# #     'NousResearch/Llama-2-7b-hf',\n",
    "# #     'NousResearch/Llama-2-7b-chat-hf',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-beta',\n",
    "# #     'HuggingFaceH4/zephyr-7b-alpha',\n",
    "#     'HuggingFaceH4/zephyr-7b-beta',\n",
    "# #     'codellama/CodeLlama-7b-hf',\n",
    "# #     'codellama/CodeLlama-7b-Python-hf',\n",
    "# #     'codellama/CodeLlama-7b-Instruct-hf',\n",
    "# ]]\n",
    "# # task_names = task_names + task_names_chatfmt\n",
    "# task_names = task_names_mtbench; definitely_run_mtbench_on_non_alt7b_queue = False\n",
    "\n",
    "# # oi5\n",
    "# exp_dir = 'results/oi2'\n",
    "# exp_dir = 'results/oi5_flan_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_dolly:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b'\n",
    "exp_dir = 'results/oi5_stanford_alpaca:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlmv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegptv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_ultrachat200kv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_tulu_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_open_orca_slim:llama-7b'\n",
    "# exp_dir = 'results/dpo1'\n",
    "# exp_dir = 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2'\n",
    "# subdir_filter_fn = lambda x: '10000:ep=10' in x and 'random' in x\n",
    "# task_names = task_names + task_names_chatfmt\n",
    "# task_names = task_names_alpacafarm\n",
    "task_names = task_names_mtbench; definitely_run_mtbench_on_non_alt7b_queue = False\n",
    "# task_names = task_names\n",
    "# task_names = ['alpacafarm_ann=gpt35:turbo:1106_chatfmt']\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "num_gpus = 1\n",
    "if arch == 'x86_64': # ccc\n",
    "    if definitely_run_mtbench_on_non_alt7b_queue:\n",
    "        gpu_type = 'v100'; num_cpus = 5; cpu_mem = 10\n",
    "    else:\n",
    "        gpu_type = 'a100_80gb'; num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus)\n",
    "    use_vllm = True; torch_dtype = 'bfloat16'\n",
    "else:\n",
    "    gpu_type = 'v100'\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    use_vllm = False; torch_dtype = 'float16'\n",
    "    \n",
    "if len(subdir_path_list)==0:\n",
    "    if create_symlinks:\n",
    "        remove_all_symlinks(exp_dir)\n",
    "    subdir_path_list = []\n",
    "    subdirs = list(os.listdir(exp_dir))\n",
    "    subdirs = filter(subdir_filter_fn, subdirs)\n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(exp_dir, subdir)\n",
    "        if include_checkpoints:\n",
    "            subdir_path_list += glob.glob(os.path.join(subdir_path, 'checkpoint-*'))\n",
    "        if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "            continue\n",
    "        subdir_path_list.append(subdir_path)\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not os.path.islink(subdir_path) and \\\n",
    "                not os.path.isfile(os.path.join(subdir_path, 'eval', task_name, 'metrics.json')):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "                print((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "\n",
    "print('#cmds: ', len(list(task_name_and_model)), '\\n')\n",
    "\n",
    "if create_symlinks:\n",
    "    # create symlink for each directory.\n",
    "    symlink_path_dict = create_unique_symlinks(\n",
    "        list([x[1] for x in task_name_and_model]))\n",
    "    options_list = list(map(lambda x: (x[0], symlink_path_dict[x[1]]), task_name_and_model))\n",
    "else:\n",
    "    options_list = task_name_and_model\n",
    "    \n",
    "    \n",
    "\n",
    "info = {}  \n",
    "cmds = []\n",
    "for task_name, model_name_or_path in options_list:\n",
    "    queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "\n",
    "    use_chat_format = 'chatfmt' in task_name\n",
    "    chat_formatting_function = get_chat_formatting_function(model_name_or_path)\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(model_name_or_path, 'ft_args.json'), 'r') as f:\n",
    "            ft_args = json.load(f)\n",
    "        # note `model_name_or_path` could be anything, e.g., soft links with arbitrary names.\n",
    "        # but `ft_args_model_name_or_path` indicates the finetuned model name.\n",
    "        if 'model_args' in ft_args:\n",
    "            ft_args_model_name_or_path = ft_args['model_args']['model_name_or_path']\n",
    "        else:\n",
    "            ft_args_model_name_or_path = ft_args['model_name_or_path']\n",
    "    except:\n",
    "        ft_args_model_name_or_path = model_name_or_path\n",
    "\n",
    "    batch_size, job_duration = get_resource_for_task(\n",
    "        task_name, ft_args_model_name_or_path)\n",
    "    \n",
    "    job_name = f'eval.{task_name}'\n",
    "    run_id = model_name_or_path\n",
    "    save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "    \n",
    "    if task_name.startswith('mmlu'):\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 5)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.mmlu.run_eval \\\n",
    "            --data_dir data/eval/mmlu \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --ntrain {n_shot} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('gsm'):\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 8)\n",
    "        # open-instruct used 200 examples. use higher amount to get a more accurate number\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.gsm.run_eval \\\n",
    "            --data_dir data/eval/gsm/ \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_num_examples 500 \\\n",
    "            --n_shot {n_shot} \\\n",
    "            --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "            {'--use_vllm' if use_vllm else ''} \\\n",
    "            {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('bbh'):\n",
    "        max_num_examples_per_task = 40\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 3)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.bbh.run_eval \\\n",
    "            --data_dir data/eval/bbh/ \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "            --n_shot {n_shot} \\\n",
    "            {'--use_vllm' if use_vllm else ''} \\\n",
    "            {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--max_num_examples_per_task '+str(max_num_examples_per_task) if max_num_examples_per_task else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('humaneval'):\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.codex_humaneval.run_eval \\\n",
    "            --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_new_tokens 512 \\\n",
    "            --eval_pass_at_ks 1 \\\n",
    "            --unbiased_sampling_size_n 3 \\\n",
    "            --temperature 0.1 \\\n",
    "            {'--use_vllm' if use_vllm else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('tydiqa'):\n",
    "        no_context = 'cb' in task_name\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot in [0,1])\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.tydiqa.run_eval \\\n",
    "            --data_dir data/eval/tydiqa \\\n",
    "            --n_shot {n_shot} \\\n",
    "            --max_num_examples_per_lang 100 \\\n",
    "            --max_context_length 512 \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            {'--use_vllm' if use_vllm else ''} \\\n",
    "            {'--no_context' if no_context else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('toxigen'):\n",
    "        # max_prompts_per_group=500 (out of 1000) is open-instruct default.\n",
    "        # eval batch size=1 much faster (llama-7b) not sure why.\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.toxigen.run_eval \\\n",
    "            --data_dir data/eval/toxigen \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size 1 \\\n",
    "            --max_prompts_per_group 200 \\\n",
    "            {'--use_vllm' if use_vllm else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('alpacafarm'):\n",
    "        match = re.search(r'ann=([^_]+)', task_name)\n",
    "        annotators_config = match.group(1)\n",
    "        annotators_config = annotators_config.replace(':', '_')\n",
    "        if not annotators_config in ['chatgpt', 'alpaca_eval_gpt4_0314', 'gpt35_turbo_1106']:\n",
    "            raise ValueError('Just support 2 annotators_config.')\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.alpaca_farm.run_eval \\\n",
    "            --reference_path alpaca_eval_data \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --max_new_tokens 2048 \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --annotators_config {annotators_config} \\\n",
    "            {'--use_vllm' if use_vllm else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('mtbench'):\n",
    "        assert('chatfmt' in task_name)\n",
    "        match = re.search(r'ann=([^_]+)', task_name)\n",
    "        judge_model = match.group(1).replace(':', '-')\n",
    "        if not judge_model in OPENAI_MODEL_LIST:\n",
    "            raise ValueError('fastchat does not support the judge model.')\n",
    "        os.makedirs(save_dir, exist_ok=True) # since not using python file, make the directory now.\n",
    "        fastchat_mtbench_data_dir = os.path.normpath(os.path.join(open_instruct_dir, '../FastChat/fastchat/llm_judge/data'))\n",
    "        question_file = os.path.join(fastchat_mtbench_data_dir, 'mt_bench/question.jsonl')\n",
    "        rating_file = os.path.join(save_dir, f'{judge_model}_single.jsonl')\n",
    "        question_begin, question_end = (0, 1) if False else (None, None)\n",
    "        model_id = os.path.basename(model_name_or_path) if 'results/baselines' in save_dir else 'tulu'\n",
    "        queue = None if definitely_run_mtbench_on_non_alt7b_queue else queue\n",
    "        cmd = \"\"\n",
    "        cmd += f\"\"\"\n",
    "            python -m fastchat.llm_judge.gen_model_answer \\\n",
    "                --model-path {model_name_or_path} \\\n",
    "                --model-id {model_id} \\\n",
    "                --bench-name mt_bench \\\n",
    "                --question-file {question_file} \\\n",
    "                {'--question-begin '+str(question_begin) if question_begin else ''} \\\n",
    "                {'--question-end '+str(question_end) if question_end else ''} \\\n",
    "                --max-new-token 2048 \\\n",
    "                --answer-file {os.path.join(save_dir, 'model_answer.jsonl')} \\\n",
    "                --dtype {torch_dtype} \\\n",
    "            && \\\n",
    "        \"\"\"\n",
    "        cmd += f\"\"\"\n",
    "            python -m fastchat.llm_judge.gen_judgment \\\n",
    "                --bench-name mt_bench \\\n",
    "                --judge-file {os.path.join(fastchat_mtbench_data_dir, 'judge_prompts.jsonl')} \\\n",
    "                --judge-model {judge_model} \\\n",
    "                --mode single \\\n",
    "                --question-file {question_file} \\\n",
    "                --answer-dir {save_dir} \\\n",
    "                --ref-answer-dir {os.path.join(fastchat_mtbench_data_dir, 'mt_bench/reference_answer')} \\\n",
    "                --output-file {rating_file} \\\n",
    "            && \\\n",
    "            python -m fastchat.llm_judge.show_result \\\n",
    "                --bench-name mt_bench \\\n",
    "                --input-file {rating_file} \\\n",
    "                --mode single \\\n",
    "                --save-to-json\n",
    "        \"\"\"\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f'{task_name} not supported.')\n",
    "        \n",
    "    if test_run:\n",
    "        print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd.strip())]))\n",
    "        \n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "    # print(cmd)\n",
    "    \n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=save_dir,\n",
    "    )\n",
    "    if arch == 'x86_64': # ccc\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "        queue=queue,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea7ac978",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_eval.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b3939309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python -m fastchat.llm_judge.gen_model_answer --model-path results/baselines/HuggingFaceH4/zephyr-7b-beta --model-id zephyr-7b-beta --bench-name mt_bench --question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl --max-new-token 2048 --answer-file results/baselines/HuggingFaceH4/zephyr-7b-beta/eval/mtbench_ann=gpt:3.5:turbo:1106_chatfmt/model_answer.jsonl --dtype bfloat16\n",
      "[2024-01-18 17:15:20,386] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Output to results/baselines/HuggingFaceH4/zephyr-7b-beta/eval/mtbench_ann=gpt:3.5:turbo:1106_chatfmt/model_answer.jsonl\n",
      "Loading checkpoint shards: 100%|██████████████████| 8/8 [00:01<00:00,  5.77it/s]\n",
      "  0%|                                                    | 0/80 [00:00<?, ?it/s]/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "  2%|█                                           | 2/80 [00:49<32:55, 25.33s/it]/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████| 80/80 [27:15<00:00, 20.44s/it]\n",
      "+ python -m fastchat.llm_judge.gen_judgment --bench-name mt_bench --judge-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/judge_prompts.jsonl --judge-model gpt-3.5-turbo-1106 --mode single --question-file /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl --answer-dir results/baselines/HuggingFaceH4/zephyr-7b-beta/eval/mtbench_ann=gpt:3.5:turbo:1106_chatfmt --ref-answer-dir /dccstor/data-pruning/wpq/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/reference_answer --output-file results/baselines/HuggingFaceH4/zephyr-7b-beta/eval/mtbench_ann=gpt:3.5:turbo:1106_chatfmt/gpt-3.5-turbo-1106_single.jsonl\n",
      "[2024-01-18 17:42:54,572] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Stats:\n",
      "{\n",
      "    \"bench_name\": \"mt_bench\",\n",
      "    \"mode\": \"single\",\n",
      "    \"judge\": \"gpt-3.5-turbo-1106\",\n",
      "    \"baseline\": null,\n",
      "    \"model_list\": [\n",
      "        \"model_answer\"\n",
      "    ],\n",
      "    \"total_num_questions\": 80,\n",
      "    \"total_num_matches\": 160,\n",
      "    \"output_path\": \"results/baselines/HuggingFaceH4/zephyr-7b-beta/eval/mtbench_ann=gpt:3.5:turbo:1106_chatfmt/gpt-3.5-turbo-1106_single.jsonl\"\n",
      "}\n",
      "  0%|                                                   | 0/160 [00:00<?, ?it/s]\n",
      "Num API calls: 1 Prompt Tokens: 842, Completion Tokens: 113\n",
      "Cost [gpt-4-turbo]: 0.012 (per-example: 0.0118)\n",
      "Cost [gpt-4]: 0.032 (per-example: 0.0320)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.001 (per-example: 0.0011)\n",
      "question: 81, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  1%|▎                                          | 1/160 [00:02<06:31,  2.46s/it]\n",
      "Num API calls: 2 Prompt Tokens: 1288, Completion Tokens: 244\n",
      "Cost [gpt-4-turbo]: 0.020 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 0.053 (per-example: 0.0266)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.002 (per-example: 0.0009)\n",
      "question: 82, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  1%|▌                                          | 2/160 [00:04<05:49,  2.21s/it]\n",
      "Num API calls: 3 Prompt Tokens: 2158, Completion Tokens: 366\n",
      "Cost [gpt-4-turbo]: 0.033 (per-example: 0.0109)\n",
      "Cost [gpt-4]: 0.087 (per-example: 0.0289)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.003 (per-example: 0.0010)\n",
      "question: 83, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  2%|▊                                          | 3/160 [00:08<07:20,  2.80s/it]\n",
      "Num API calls: 4 Prompt Tokens: 2803, Completion Tokens: 445\n",
      "Cost [gpt-4-turbo]: 0.041 (per-example: 0.0103)\n",
      "Cost [gpt-4]: 0.111 (per-example: 0.0277)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.004 (per-example: 0.0009)\n",
      "question: 84, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  2%|█                                          | 4/160 [00:09<06:17,  2.42s/it]\n",
      "Num API calls: 5 Prompt Tokens: 3193, Completion Tokens: 546\n",
      "Cost [gpt-4-turbo]: 0.048 (per-example: 0.0097)\n",
      "Cost [gpt-4]: 0.129 (per-example: 0.0257)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.004 (per-example: 0.0009)\n",
      "question: 85, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  3%|█▎                                         | 5/160 [00:12<06:21,  2.46s/it]\n",
      "Num API calls: 6 Prompt Tokens: 3594, Completion Tokens: 648\n",
      "Cost [gpt-4-turbo]: 0.055 (per-example: 0.0092)\n",
      "Cost [gpt-4]: 0.147 (per-example: 0.0244)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.005 (per-example: 0.0008)\n",
      "question: 86, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  4%|█▌                                         | 6/160 [00:14<06:19,  2.47s/it]\n",
      "Num API calls: 7 Prompt Tokens: 4169, Completion Tokens: 749\n",
      "Cost [gpt-4-turbo]: 0.064 (per-example: 0.0092)\n",
      "Cost [gpt-4]: 0.170 (per-example: 0.0243)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.006 (per-example: 0.0008)\n",
      "question: 87, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  4%|█▉                                         | 7/160 [00:17<06:39,  2.61s/it]\n",
      "Num API calls: 8 Prompt Tokens: 4537, Completion Tokens: 835\n",
      "Cost [gpt-4-turbo]: 0.070 (per-example: 0.0088)\n",
      "Cost [gpt-4]: 0.186 (per-example: 0.0233)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.006 (per-example: 0.0008)\n",
      "question: 88, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  5%|██▏                                        | 8/160 [00:20<07:06,  2.81s/it]\n",
      "Num API calls: 9 Prompt Tokens: 4948, Completion Tokens: 925\n",
      "Cost [gpt-4-turbo]: 0.077 (per-example: 0.0086)\n",
      "Cost [gpt-4]: 0.204 (per-example: 0.0227)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.007 (per-example: 0.0008)\n",
      "question: 89, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  6%|██▍                                        | 9/160 [00:24<07:16,  2.89s/it]\n",
      "Num API calls: 10 Prompt Tokens: 5278, Completion Tokens: 1011\n",
      "Cost [gpt-4-turbo]: 0.083 (per-example: 0.0083)\n",
      "Cost [gpt-4]: 0.219 (per-example: 0.0219)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.007 (per-example: 0.0007)\n",
      "question: 90, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  6%|██▋                                       | 10/160 [00:27<07:17,  2.92s/it]\n",
      "Num API calls: 11 Prompt Tokens: 5655, Completion Tokens: 1094\n",
      "Cost [gpt-4-turbo]: 0.089 (per-example: 0.0081)\n",
      "Cost [gpt-4]: 0.235 (per-example: 0.0214)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.008 (per-example: 0.0007)\n",
      "question: 91, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  7%|██▉                                       | 11/160 [00:28<06:25,  2.59s/it]\n",
      "Num API calls: 12 Prompt Tokens: 5993, Completion Tokens: 1209\n",
      "Cost [gpt-4-turbo]: 0.096 (per-example: 0.0080)\n",
      "Cost [gpt-4]: 0.252 (per-example: 0.0210)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.008 (per-example: 0.0007)\n",
      "question: 92, turn: 1, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  8%|███▏                                      | 12/160 [00:31<06:33,  2.66s/it]\n",
      "Num API calls: 13 Prompt Tokens: 6641, Completion Tokens: 1301\n",
      "Cost [gpt-4-turbo]: 0.105 (per-example: 0.0081)\n",
      "Cost [gpt-4]: 0.277 (per-example: 0.0213)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.009 (per-example: 0.0007)\n",
      "question: 93, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  8%|███▍                                      | 13/160 [00:35<07:03,  2.88s/it]\n",
      "Num API calls: 14 Prompt Tokens: 7418, Completion Tokens: 1432\n",
      "Cost [gpt-4-turbo]: 0.117 (per-example: 0.0084)\n",
      "Cost [gpt-4]: 0.308 (per-example: 0.0220)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.010 (per-example: 0.0007)\n",
      "question: 94, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9%|███▋                                      | 14/160 [00:39<08:25,  3.47s/it]\n",
      "Num API calls: 15 Prompt Tokens: 7947, Completion Tokens: 1510\n",
      "Cost [gpt-4-turbo]: 0.125 (per-example: 0.0083)\n",
      "Cost [gpt-4]: 0.329 (per-example: 0.0219)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.011 (per-example: 0.0007)\n",
      "question: 95, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      "  9%|███▉                                      | 15/160 [00:42<07:59,  3.31s/it]\n",
      "Num API calls: 16 Prompt Tokens: 8457, Completion Tokens: 1600\n",
      "Cost [gpt-4-turbo]: 0.133 (per-example: 0.0083)\n",
      "Cost [gpt-4]: 0.350 (per-example: 0.0219)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.012 (per-example: 0.0007)\n",
      "question: 96, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 10%|████▏                                     | 16/160 [00:45<07:33,  3.15s/it]\n",
      "Num API calls: 17 Prompt Tokens: 9197, Completion Tokens: 1696\n",
      "Cost [gpt-4-turbo]: 0.143 (per-example: 0.0084)\n",
      "Cost [gpt-4]: 0.378 (per-example: 0.0222)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.013 (per-example: 0.0007)\n",
      "question: 97, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 11%|████▍                                     | 17/160 [00:49<07:57,  3.34s/it]\n",
      "Num API calls: 18 Prompt Tokens: 9557, Completion Tokens: 1783\n",
      "Cost [gpt-4-turbo]: 0.149 (per-example: 0.0083)\n",
      "Cost [gpt-4]: 0.394 (per-example: 0.0219)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.013 (per-example: 0.0007)\n",
      "question: 98, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 11%|████▋                                     | 18/160 [00:52<07:50,  3.31s/it]\n",
      "Num API calls: 19 Prompt Tokens: 9950, Completion Tokens: 1905\n",
      "Cost [gpt-4-turbo]: 0.157 (per-example: 0.0082)\n",
      "Cost [gpt-4]: 0.413 (per-example: 0.0217)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.014 (per-example: 0.0007)\n",
      "question: 99, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 12%|████▉                                     | 19/160 [00:56<07:51,  3.34s/it]\n",
      "Num API calls: 20 Prompt Tokens: 10554, Completion Tokens: 2018\n",
      "Cost [gpt-4-turbo]: 0.166 (per-example: 0.0083)\n",
      "Cost [gpt-4]: 0.438 (per-example: 0.0219)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.015 (per-example: 0.0007)\n",
      "question: 100, turn: 1, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 12%|█████▎                                    | 20/160 [01:00<08:19,  3.57s/it]\n",
      "Num API calls: 21 Prompt Tokens: 11018, Completion Tokens: 2116\n",
      "Cost [gpt-4-turbo]: 0.174 (per-example: 0.0083)\n",
      "Cost [gpt-4]: 0.458 (per-example: 0.0218)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.015 (per-example: 0.0007)\n",
      "question: 131, turn: 1, model: model_answer, score: 6, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 13%|█████▌                                    | 21/160 [01:02<07:07,  3.08s/it]\n",
      "Num API calls: 22 Prompt Tokens: 11458, Completion Tokens: 2174\n",
      "Cost [gpt-4-turbo]: 0.180 (per-example: 0.0082)\n",
      "Cost [gpt-4]: 0.474 (per-example: 0.0216)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.016 (per-example: 0.0007)\n",
      "question: 132, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 14%|█████▊                                    | 22/160 [01:05<07:01,  3.05s/it]\n",
      "Num API calls: 23 Prompt Tokens: 12036, Completion Tokens: 2271\n",
      "Cost [gpt-4-turbo]: 0.188 (per-example: 0.0082)\n",
      "Cost [gpt-4]: 0.497 (per-example: 0.0216)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.017 (per-example: 0.0007)\n",
      "question: 133, turn: 1, model: model_answer, score: 7, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 14%|██████                                    | 23/160 [01:07<06:20,  2.78s/it]\n",
      "Num API calls: 24 Prompt Tokens: 12408, Completion Tokens: 2356\n",
      "Cost [gpt-4-turbo]: 0.195 (per-example: 0.0081)\n",
      "Cost [gpt-4]: 0.514 (per-example: 0.0214)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.017 (per-example: 0.0007)\n",
      "question: 134, turn: 1, model: model_answer, score: 7, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 15%|██████▎                                   | 24/160 [01:10<06:18,  2.78s/it]\n",
      "Num API calls: 25 Prompt Tokens: 12810, Completion Tokens: 2422\n",
      "Cost [gpt-4-turbo]: 0.201 (per-example: 0.0080)\n",
      "Cost [gpt-4]: 0.530 (per-example: 0.0212)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.018 (per-example: 0.0007)\n",
      "question: 135, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 16%|██████▌                                   | 25/160 [01:14<07:29,  3.33s/it]\n",
      "Num API calls: 26 Prompt Tokens: 13303, Completion Tokens: 2483\n",
      "Cost [gpt-4-turbo]: 0.208 (per-example: 0.0080)\n",
      "Cost [gpt-4]: 0.548 (per-example: 0.0211)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.018 (per-example: 0.0007)\n",
      "question: 136, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 16%|██████▊                                   | 26/160 [01:15<06:03,  2.71s/it]\n",
      "Num API calls: 27 Prompt Tokens: 13719, Completion Tokens: 2576\n",
      "Cost [gpt-4-turbo]: 0.214 (per-example: 0.0079)\n",
      "Cost [gpt-4]: 0.566 (per-example: 0.0210)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.019 (per-example: 0.0007)\n",
      "question: 137, turn: 1, model: model_answer, score: 7, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 17%|███████                                   | 27/160 [01:18<06:13,  2.81s/it]\n",
      "Num API calls: 28 Prompt Tokens: 14412, Completion Tokens: 2655\n",
      "Cost [gpt-4-turbo]: 0.224 (per-example: 0.0080)\n",
      "Cost [gpt-4]: 0.592 (per-example: 0.0211)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.020 (per-example: 0.0007)\n",
      "question: 138, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 18%|███████▎                                  | 28/160 [01:20<05:35,  2.54s/it]\n",
      "Num API calls: 29 Prompt Tokens: 14972, Completion Tokens: 2757\n",
      "Cost [gpt-4-turbo]: 0.232 (per-example: 0.0080)\n",
      "Cost [gpt-4]: 0.615 (per-example: 0.0212)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.020 (per-example: 0.0007)\n",
      "question: 139, turn: 1, model: model_answer, score: 7, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 18%|███████▌                                  | 29/160 [01:23<05:35,  2.56s/it]\n",
      "Num API calls: 30 Prompt Tokens: 15435, Completion Tokens: 2846\n",
      "Cost [gpt-4-turbo]: 0.240 (per-example: 0.0080)\n",
      "Cost [gpt-4]: 0.634 (per-example: 0.0211)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.021 (per-example: 0.0007)\n",
      "question: 140, turn: 1, model: model_answer, score: 7, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 19%|███████▉                                  | 30/160 [01:25<04:53,  2.26s/it]\n",
      "Num API calls: 31 Prompt Tokens: 15906, Completion Tokens: 2926\n",
      "Cost [gpt-4-turbo]: 0.247 (per-example: 0.0080)\n",
      "Cost [gpt-4]: 0.653 (per-example: 0.0211)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.022 (per-example: 0.0007)\n",
      "question: 141, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 19%|████████▏                                 | 31/160 [01:26<04:20,  2.02s/it]\n",
      "Num API calls: 32 Prompt Tokens: 16315, Completion Tokens: 3016\n",
      "Cost [gpt-4-turbo]: 0.254 (per-example: 0.0079)\n",
      "Cost [gpt-4]: 0.670 (per-example: 0.0210)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.022 (per-example: 0.0007)\n",
      "question: 142, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 20%|████████▍                                 | 32/160 [01:29<04:50,  2.27s/it]\n",
      "Num API calls: 33 Prompt Tokens: 17118, Completion Tokens: 3163\n",
      "Cost [gpt-4-turbo]: 0.266 (per-example: 0.0081)\n",
      "Cost [gpt-4]: 0.703 (per-example: 0.0213)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.023 (per-example: 0.0007)\n",
      "question: 143, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 21%|████████▋                                 | 33/160 [01:31<04:44,  2.24s/it]\n",
      "Num API calls: 34 Prompt Tokens: 17568, Completion Tokens: 3301\n",
      "Cost [gpt-4-turbo]: 0.275 (per-example: 0.0081)\n",
      "Cost [gpt-4]: 0.725 (per-example: 0.0213)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.024 (per-example: 0.0007)\n",
      "question: 144, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 21%|████████▉                                 | 34/160 [01:33<04:45,  2.27s/it]\n",
      "Num API calls: 35 Prompt Tokens: 18127, Completion Tokens: 3389\n",
      "Cost [gpt-4-turbo]: 0.283 (per-example: 0.0081)\n",
      "Cost [gpt-4]: 0.747 (per-example: 0.0213)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.025 (per-example: 0.0007)\n",
      "question: 145, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22%|█████████▏                                | 35/160 [01:36<04:49,  2.31s/it]\n",
      "Num API calls: 36 Prompt Tokens: 18924, Completion Tokens: 3472\n",
      "Cost [gpt-4-turbo]: 0.293 (per-example: 0.0081)\n",
      "Cost [gpt-4]: 0.776 (per-example: 0.0216)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.026 (per-example: 0.0007)\n",
      "question: 146, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 22%|█████████▍                                | 36/160 [01:38<04:32,  2.19s/it]\n",
      "Num API calls: 37 Prompt Tokens: 19468, Completion Tokens: 3620\n",
      "Cost [gpt-4-turbo]: 0.303 (per-example: 0.0082)\n",
      "Cost [gpt-4]: 0.801 (per-example: 0.0217)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.027 (per-example: 0.0007)\n",
      "question: 147, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 23%|█████████▋                                | 37/160 [01:42<05:31,  2.69s/it]\n",
      "Num API calls: 38 Prompt Tokens: 20210, Completion Tokens: 3725\n",
      "Cost [gpt-4-turbo]: 0.314 (per-example: 0.0083)\n",
      "Cost [gpt-4]: 0.830 (per-example: 0.0218)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.028 (per-example: 0.0007)\n",
      "question: 148, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 24%|█████████▉                                | 38/160 [01:43<04:49,  2.37s/it]\n",
      "Num API calls: 39 Prompt Tokens: 20986, Completion Tokens: 3821\n",
      "Cost [gpt-4-turbo]: 0.324 (per-example: 0.0083)\n",
      "Cost [gpt-4]: 0.859 (per-example: 0.0220)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.029 (per-example: 0.0007)\n",
      "question: 149, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 24%|██████████▏                               | 39/160 [01:45<04:18,  2.14s/it]\n",
      "Num API calls: 40 Prompt Tokens: 21567, Completion Tokens: 3896\n",
      "Cost [gpt-4-turbo]: 0.333 (per-example: 0.0083)\n",
      "Cost [gpt-4]: 0.881 (per-example: 0.0220)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.029 (per-example: 0.0007)\n",
      "question: 150, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 25%|██████████▌                               | 40/160 [01:47<04:07,  2.06s/it]\n",
      "Num API calls: 41 Prompt Tokens: 22303, Completion Tokens: 4016\n",
      "Cost [gpt-4-turbo]: 0.344 (per-example: 0.0084)\n",
      "Cost [gpt-4]: 0.910 (per-example: 0.0222)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.030 (per-example: 0.0007)\n",
      "question: 151, turn: 1, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 26%|██████████▊                               | 41/160 [01:50<04:51,  2.45s/it]\n",
      "Num API calls: 42 Prompt Tokens: 22766, Completion Tokens: 4103\n",
      "Cost [gpt-4-turbo]: 0.351 (per-example: 0.0084)\n",
      "Cost [gpt-4]: 0.929 (per-example: 0.0221)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.031 (per-example: 0.0007)\n",
      "question: 152, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 26%|███████████                               | 42/160 [01:51<04:15,  2.17s/it]\n",
      "Num API calls: 43 Prompt Tokens: 23554, Completion Tokens: 4270\n",
      "Cost [gpt-4-turbo]: 0.364 (per-example: 0.0085)\n",
      "Cost [gpt-4]: 0.963 (per-example: 0.0224)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.032 (per-example: 0.0007)\n",
      "question: 153, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 27%|███████████▎                              | 43/160 [01:54<04:17,  2.20s/it]\n",
      "Num API calls: 44 Prompt Tokens: 24529, Completion Tokens: 4410\n",
      "Cost [gpt-4-turbo]: 0.378 (per-example: 0.0086)\n",
      "Cost [gpt-4]: 1.000 (per-example: 0.0227)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.033 (per-example: 0.0008)\n",
      "question: 154, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 28%|███████████▌                              | 44/160 [01:58<05:41,  2.94s/it]\n",
      "Num API calls: 45 Prompt Tokens: 25230, Completion Tokens: 4509\n",
      "Cost [gpt-4-turbo]: 0.388 (per-example: 0.0086)\n",
      "Cost [gpt-4]: 1.027 (per-example: 0.0228)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.034 (per-example: 0.0008)\n",
      "question: 155, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 28%|███████████▊                              | 45/160 [02:00<04:48,  2.51s/it]\n",
      "Num API calls: 46 Prompt Tokens: 25861, Completion Tokens: 4613\n",
      "Cost [gpt-4-turbo]: 0.397 (per-example: 0.0086)\n",
      "Cost [gpt-4]: 1.053 (per-example: 0.0229)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.035 (per-example: 0.0008)\n",
      "question: 156, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 29%|████████████                              | 46/160 [02:02<04:28,  2.35s/it]\n",
      "Num API calls: 47 Prompt Tokens: 26262, Completion Tokens: 4720\n",
      "Cost [gpt-4-turbo]: 0.404 (per-example: 0.0086)\n",
      "Cost [gpt-4]: 1.071 (per-example: 0.0228)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.036 (per-example: 0.0008)\n",
      "question: 157, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 29%|████████████▎                             | 47/160 [02:05<05:00,  2.66s/it]\n",
      "Num API calls: 48 Prompt Tokens: 26737, Completion Tokens: 4807\n",
      "Cost [gpt-4-turbo]: 0.412 (per-example: 0.0086)\n",
      "Cost [gpt-4]: 1.091 (per-example: 0.0227)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.036 (per-example: 0.0008)\n",
      "question: 158, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 30%|████████████▌                             | 48/160 [02:07<04:15,  2.28s/it]\n",
      "Num API calls: 49 Prompt Tokens: 27385, Completion Tokens: 4939\n",
      "Cost [gpt-4-turbo]: 0.422 (per-example: 0.0086)\n",
      "Cost [gpt-4]: 1.118 (per-example: 0.0228)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.037 (per-example: 0.0008)\n",
      "question: 159, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 31%|████████████▊                             | 49/160 [02:09<04:13,  2.28s/it]\n",
      "Num API calls: 50 Prompt Tokens: 27897, Completion Tokens: 5045\n",
      "Cost [gpt-4-turbo]: 0.430 (per-example: 0.0086)\n",
      "Cost [gpt-4]: 1.140 (per-example: 0.0228)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.038 (per-example: 0.0008)\n",
      "question: 160, turn: 1, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1')\n",
      " 31%|█████████████▏                            | 50/160 [02:12<04:36,  2.52s/it]\n",
      "Num API calls: 51 Prompt Tokens: 28163, Completion Tokens: 5143\n",
      "Cost [gpt-4-turbo]: 0.436 (per-example: 0.0085)\n",
      "Cost [gpt-4]: 1.153 (per-example: 0.0226)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.038 (per-example: 0.0008)\n",
      "question: 101, turn: 1, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 32%|█████████████▍                            | 51/160 [02:15<04:38,  2.56s/it]\n",
      "Num API calls: 52 Prompt Tokens: 28472, Completion Tokens: 5297\n",
      "Cost [gpt-4-turbo]: 0.444 (per-example: 0.0085)\n",
      "Cost [gpt-4]: 1.172 (per-example: 0.0225)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.039 (per-example: 0.0008)\n",
      "question: 102, turn: 1, model: model_answer, score: 6, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 32%|█████████████▋                            | 52/160 [02:18<05:14,  2.91s/it]\n",
      "Num API calls: 53 Prompt Tokens: 29219, Completion Tokens: 5441\n",
      "Cost [gpt-4-turbo]: 0.455 (per-example: 0.0086)\n",
      "Cost [gpt-4]: 1.203 (per-example: 0.0227)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.040 (per-example: 0.0008)\n",
      "question: 103, turn: 1, model: model_answer, score: 6, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 33%|█████████████▉                            | 53/160 [02:21<05:08,  2.89s/it]\n",
      "Num API calls: 54 Prompt Tokens: 29473, Completion Tokens: 5499\n",
      "Cost [gpt-4-turbo]: 0.460 (per-example: 0.0085)\n",
      "Cost [gpt-4]: 1.214 (per-example: 0.0225)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.040 (per-example: 0.0007)\n",
      "question: 104, turn: 1, model: model_answer, score: 2, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 34%|██████████████▏                           | 54/160 [02:24<04:51,  2.75s/it]\n",
      "Num API calls: 55 Prompt Tokens: 30388, Completion Tokens: 5553\n",
      "Cost [gpt-4-turbo]: 0.470 (per-example: 0.0086)\n",
      "Cost [gpt-4]: 1.245 (per-example: 0.0226)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.041 (per-example: 0.0008)\n",
      "question: 105, turn: 1, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 34%|██████████████▍                           | 55/160 [02:26<04:36,  2.64s/it]\n",
      "Num API calls: 56 Prompt Tokens: 30674, Completion Tokens: 5641\n",
      "Cost [gpt-4-turbo]: 0.476 (per-example: 0.0085)\n",
      "Cost [gpt-4]: 1.259 (per-example: 0.0225)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.042 (per-example: 0.0007)\n",
      "question: 106, turn: 1, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|██████████████▋                           | 56/160 [02:29<04:29,  2.59s/it]\n",
      "Num API calls: 57 Prompt Tokens: 30877, Completion Tokens: 5677\n",
      "Cost [gpt-4-turbo]: 0.479 (per-example: 0.0084)\n",
      "Cost [gpt-4]: 1.267 (per-example: 0.0222)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.042 (per-example: 0.0007)\n",
      "question: 107, turn: 1, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 36%|██████████████▉                           | 57/160 [02:31<04:16,  2.49s/it]\n",
      "Num API calls: 58 Prompt Tokens: 31131, Completion Tokens: 5774\n",
      "Cost [gpt-4-turbo]: 0.485 (per-example: 0.0084)\n",
      "Cost [gpt-4]: 1.280 (per-example: 0.0221)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.043 (per-example: 0.0007)\n",
      "question: 108, turn: 1, model: model_answer, score: 6, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 36%|███████████████▏                          | 58/160 [02:32<03:48,  2.24s/it]\n",
      "Num API calls: 59 Prompt Tokens: 31726, Completion Tokens: 5896\n",
      "Cost [gpt-4-turbo]: 0.494 (per-example: 0.0084)\n",
      "Cost [gpt-4]: 1.306 (per-example: 0.0221)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.044 (per-example: 0.0007)\n",
      "question: 109, turn: 1, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 37%|███████████████▍                          | 59/160 [02:36<04:35,  2.72s/it]\n",
      "Num API calls: 60 Prompt Tokens: 32203, Completion Tokens: 5965\n",
      "Cost [gpt-4-turbo]: 0.501 (per-example: 0.0083)\n",
      "Cost [gpt-4]: 1.324 (per-example: 0.0221)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.044 (per-example: 0.0007)\n",
      "question: 110, turn: 1, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 38%|███████████████▊                          | 60/160 [02:39<04:27,  2.67s/it]\n",
      "Num API calls: 61 Prompt Tokens: 33178, Completion Tokens: 6125\n",
      "Cost [gpt-4-turbo]: 0.516 (per-example: 0.0085)\n",
      "Cost [gpt-4]: 1.363 (per-example: 0.0223)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.045 (per-example: 0.0007)\n",
      "question: 111, turn: 1, model: model_answer, score: 2, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 38%|████████████████                          | 61/160 [02:41<04:19,  2.62s/it]\n",
      "Num API calls: 62 Prompt Tokens: 33518, Completion Tokens: 6271\n",
      "Cost [gpt-4-turbo]: 0.523 (per-example: 0.0084)\n",
      "Cost [gpt-4]: 1.382 (per-example: 0.0223)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.046 (per-example: 0.0007)\n",
      "question: 112, turn: 1, model: model_answer, score: 7, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 39%|████████████████▎                         | 62/160 [02:45<04:51,  2.97s/it]\n",
      "Num API calls: 63 Prompt Tokens: 34128, Completion Tokens: 6464\n",
      "Cost [gpt-4-turbo]: 0.535 (per-example: 0.0085)\n",
      "Cost [gpt-4]: 1.412 (per-example: 0.0224)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.047 (per-example: 0.0007)\n",
      "question: 113, turn: 1, model: model_answer, score: 2, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 39%|████████████████▌                         | 63/160 [02:48<04:49,  2.99s/it]\n",
      "Num API calls: 64 Prompt Tokens: 35262, Completion Tokens: 6623\n",
      "Cost [gpt-4-turbo]: 0.551 (per-example: 0.0086)\n",
      "Cost [gpt-4]: 1.455 (per-example: 0.0227)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.049 (per-example: 0.0008)\n",
      "question: 114, turn: 1, model: model_answer, score: 2, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 40%|████████████████▊                         | 64/160 [02:52<05:11,  3.24s/it]\n",
      "Num API calls: 65 Prompt Tokens: 35954, Completion Tokens: 6761\n",
      "Cost [gpt-4-turbo]: 0.562 (per-example: 0.0087)\n",
      "Cost [gpt-4]: 1.484 (per-example: 0.0228)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.049 (per-example: 0.0008)\n",
      "question: 115, turn: 1, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 41%|█████████████████                         | 65/160 [02:54<04:39,  2.95s/it]\n",
      "Num API calls: 66 Prompt Tokens: 36645, Completion Tokens: 6859\n",
      "Cost [gpt-4-turbo]: 0.572 (per-example: 0.0087)\n",
      "Cost [gpt-4]: 1.511 (per-example: 0.0229)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.050 (per-example: 0.0008)\n",
      "question: 116, turn: 1, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 41%|█████████████████▎                        | 66/160 [02:57<04:41,  3.00s/it]\n",
      "Num API calls: 67 Prompt Tokens: 37291, Completion Tokens: 6983\n",
      "Cost [gpt-4-turbo]: 0.582 (per-example: 0.0087)\n",
      "Cost [gpt-4]: 1.538 (per-example: 0.0230)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.051 (per-example: 0.0008)\n",
      "question: 117, turn: 1, model: model_answer, score: 4, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 42%|█████████████████▌                        | 67/160 [02:59<04:10,  2.70s/it]\n",
      "Num API calls: 68 Prompt Tokens: 37908, Completion Tokens: 7141\n",
      "Cost [gpt-4-turbo]: 0.593 (per-example: 0.0087)\n",
      "Cost [gpt-4]: 1.566 (per-example: 0.0230)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.052 (per-example: 0.0008)\n",
      "question: 118, turn: 1, model: model_answer, score: 2, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 42%|█████████████████▊                        | 68/160 [03:02<04:18,  2.81s/it]\n",
      "Num API calls: 69 Prompt Tokens: 38350, Completion Tokens: 7216\n",
      "Cost [gpt-4-turbo]: 0.600 (per-example: 0.0087)\n",
      "Cost [gpt-4]: 1.583 (per-example: 0.0229)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.053 (per-example: 0.0008)\n",
      "question: 119, turn: 1, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 43%|██████████████████                        | 69/160 [03:04<03:41,  2.43s/it]\n",
      "Num API calls: 70 Prompt Tokens: 38754, Completion Tokens: 7301\n",
      "Cost [gpt-4-turbo]: 0.607 (per-example: 0.0087)\n",
      "Cost [gpt-4]: 1.601 (per-example: 0.0229)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.053 (per-example: 0.0008)\n",
      "question: 120, turn: 1, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 44%|██████████████████▍                       | 70/160 [03:06<03:39,  2.44s/it]\n",
      "Num API calls: 71 Prompt Tokens: 39658, Completion Tokens: 7737\n",
      "Cost [gpt-4-turbo]: 0.629 (per-example: 0.0089)\n",
      "Cost [gpt-4]: 1.654 (per-example: 0.0233)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.055 (per-example: 0.0008)\n",
      "question: 121, turn: 1, model: model_answer, score: 4, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 44%|██████████████████▋                       | 71/160 [03:15<06:14,  4.20s/it]\n",
      "Num API calls: 72 Prompt Tokens: 40333, Completion Tokens: 8029\n",
      "Cost [gpt-4-turbo]: 0.644 (per-example: 0.0089)\n",
      "Cost [gpt-4]: 1.692 (per-example: 0.0235)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.056 (per-example: 0.0008)\n",
      "question: 122, turn: 1, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 45%|██████████████████▉                       | 72/160 [03:20<06:37,  4.51s/it]\n",
      "Num API calls: 73 Prompt Tokens: 41693, Completion Tokens: 8192\n",
      "Cost [gpt-4-turbo]: 0.663 (per-example: 0.0091)\n",
      "Cost [gpt-4]: 1.742 (per-example: 0.0239)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.058 (per-example: 0.0008)\n",
      "question: 123, turn: 1, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 46%|███████████████████▏                      | 73/160 [03:24<06:17,  4.33s/it]\n",
      "Num API calls: 74 Prompt Tokens: 42272, Completion Tokens: 8380\n",
      "Cost [gpt-4-turbo]: 0.674 (per-example: 0.0091)\n",
      "Cost [gpt-4]: 1.771 (per-example: 0.0239)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.059 (per-example: 0.0008)\n",
      "question: 124, turn: 1, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 46%|███████████████████▍                      | 74/160 [03:28<05:55,  4.13s/it]\n",
      "Num API calls: 75 Prompt Tokens: 43464, Completion Tokens: 8672\n",
      "Cost [gpt-4-turbo]: 0.695 (per-example: 0.0093)\n",
      "Cost [gpt-4]: 1.824 (per-example: 0.0243)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.061 (per-example: 0.0008)\n",
      "question: 125, turn: 1, model: model_answer, score: 2, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 47%|███████████████████▋                      | 75/160 [03:32<05:50,  4.12s/it]\n",
      "Num API calls: 76 Prompt Tokens: 44548, Completion Tokens: 8810\n",
      "Cost [gpt-4-turbo]: 0.710 (per-example: 0.0093)\n",
      "Cost [gpt-4]: 1.865 (per-example: 0.0245)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.062 (per-example: 0.0008)\n",
      "question: 126, turn: 1, model: model_answer, score: 2, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 48%|███████████████████▉                      | 76/160 [03:35<05:14,  3.74s/it]\n",
      "Num API calls: 77 Prompt Tokens: 45244, Completion Tokens: 9074\n",
      "Cost [gpt-4-turbo]: 0.725 (per-example: 0.0094)\n",
      "Cost [gpt-4]: 1.902 (per-example: 0.0247)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.063 (per-example: 0.0008)\n",
      "question: 127, turn: 1, model: model_answer, score: 7, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████▏                     | 77/160 [03:40<06:04,  4.39s/it]\n",
      "Num API calls: 78 Prompt Tokens: 45939, Completion Tokens: 9272\n",
      "Cost [gpt-4-turbo]: 0.738 (per-example: 0.0095)\n",
      "Cost [gpt-4]: 1.934 (per-example: 0.0248)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.064 (per-example: 0.0008)\n",
      "question: 128, turn: 1, model: model_answer, score: 2, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 49%|████████████████████▍                     | 78/160 [03:45<05:56,  4.35s/it]\n",
      "Num API calls: 79 Prompt Tokens: 46915, Completion Tokens: 9807\n",
      "Cost [gpt-4-turbo]: 0.763 (per-example: 0.0097)\n",
      "Cost [gpt-4]: 1.996 (per-example: 0.0253)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.067 (per-example: 0.0008)\n",
      "question: 129, turn: 1, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 49%|████████████████████▋                     | 79/160 [03:54<07:40,  5.68s/it]\n",
      "Num API calls: 80 Prompt Tokens: 47836, Completion Tokens: 9975\n",
      "Cost [gpt-4-turbo]: 0.778 (per-example: 0.0097)\n",
      "Cost [gpt-4]: 2.034 (per-example: 0.0254)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.068 (per-example: 0.0008)\n",
      "question: 130, turn: 1, model: model_answer, score: 2, judge: ('gpt-3.5-turbo-1106', 'single-math-v1')\n",
      " 50%|█████████████████████                     | 80/160 [03:57<06:31,  4.89s/it]\n",
      "Num API calls: 81 Prompt Tokens: 49275, Completion Tokens: 10142\n",
      "Cost [gpt-4-turbo]: 0.797 (per-example: 0.0098)\n",
      "Cost [gpt-4]: 2.087 (per-example: 0.0258)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.070 (per-example: 0.0009)\n",
      "question: 81, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 51%|█████████████████████▎                    | 81/160 [04:00<06:02,  4.59s/it]\n",
      "Num API calls: 82 Prompt Tokens: 50117, Completion Tokens: 10256\n",
      "Cost [gpt-4-turbo]: 0.809 (per-example: 0.0099)\n",
      "Cost [gpt-4]: 2.119 (per-example: 0.0258)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.071 (per-example: 0.0009)\n",
      "question: 82, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 51%|█████████████████████▌                    | 82/160 [04:03<05:20,  4.11s/it]\n",
      "Num API calls: 83 Prompt Tokens: 51267, Completion Tokens: 10344\n",
      "Cost [gpt-4-turbo]: 0.823 (per-example: 0.0099)\n",
      "Cost [gpt-4]: 2.159 (per-example: 0.0260)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.072 (per-example: 0.0009)\n",
      "question: 83, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 52%|█████████████████████▊                    | 83/160 [04:06<04:42,  3.67s/it]\n",
      "Num API calls: 84 Prompt Tokens: 52511, Completion Tokens: 10482\n",
      "Cost [gpt-4-turbo]: 0.840 (per-example: 0.0100)\n",
      "Cost [gpt-4]: 2.204 (per-example: 0.0262)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.073 (per-example: 0.0009)\n",
      "question: 84, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 52%|██████████████████████                    | 84/160 [04:10<04:41,  3.71s/it]\n",
      "Num API calls: 85 Prompt Tokens: 53306, Completion Tokens: 10596\n",
      "Cost [gpt-4-turbo]: 0.851 (per-example: 0.0100)\n",
      "Cost [gpt-4]: 2.235 (per-example: 0.0263)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.074 (per-example: 0.0009)\n",
      "question: 85, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 53%|██████████████████████▎                   | 85/160 [04:13<04:22,  3.49s/it]\n",
      "Num API calls: 86 Prompt Tokens: 53945, Completion Tokens: 10713\n",
      "Cost [gpt-4-turbo]: 0.861 (per-example: 0.0100)\n",
      "Cost [gpt-4]: 2.261 (per-example: 0.0263)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.075 (per-example: 0.0009)\n",
      "question: 86, turn: 2, model: model_answer, score: -1, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 54%|██████████████████████▌                   | 86/160 [04:16<04:20,  3.52s/it]\n",
      "Num API calls: 87 Prompt Tokens: 54575, Completion Tokens: 10806\n",
      "Cost [gpt-4-turbo]: 0.870 (per-example: 0.0100)\n",
      "Cost [gpt-4]: 2.286 (per-example: 0.0263)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.076 (per-example: 0.0009)\n",
      "question: 87, turn: 2, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 54%|██████████████████████▊                   | 87/160 [04:19<04:01,  3.31s/it]\n",
      "Num API calls: 88 Prompt Tokens: 55059, Completion Tokens: 10899\n",
      "Cost [gpt-4-turbo]: 0.878 (per-example: 0.0100)\n",
      "Cost [gpt-4]: 2.306 (per-example: 0.0262)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.077 (per-example: 0.0009)\n",
      "question: 88, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 55%|███████████████████████                   | 88/160 [04:22<03:43,  3.11s/it]\n",
      "Num API calls: 89 Prompt Tokens: 55653, Completion Tokens: 11002\n",
      "Cost [gpt-4-turbo]: 0.887 (per-example: 0.0100)\n",
      "Cost [gpt-4]: 2.330 (per-example: 0.0262)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.078 (per-example: 0.0009)\n",
      "question: 89, turn: 2, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 56%|███████████████████████▎                  | 89/160 [04:24<03:10,  2.69s/it]\n",
      "Num API calls: 90 Prompt Tokens: 56114, Completion Tokens: 11080\n",
      "Cost [gpt-4-turbo]: 0.894 (per-example: 0.0099)\n",
      "Cost [gpt-4]: 2.348 (per-example: 0.0261)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.078 (per-example: 0.0009)\n",
      "question: 90, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 56%|███████████████████████▋                  | 90/160 [04:27<03:13,  2.76s/it]\n",
      "Num API calls: 91 Prompt Tokens: 56684, Completion Tokens: 11170\n",
      "Cost [gpt-4-turbo]: 0.902 (per-example: 0.0099)\n",
      "Cost [gpt-4]: 2.371 (per-example: 0.0261)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.079 (per-example: 0.0009)\n",
      "question: 91, turn: 2, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 57%|███████████████████████▉                  | 91/160 [04:30<03:16,  2.85s/it]\n",
      "Num API calls: 92 Prompt Tokens: 57183, Completion Tokens: 11284\n",
      "Cost [gpt-4-turbo]: 0.910 (per-example: 0.0099)\n",
      "Cost [gpt-4]: 2.393 (per-example: 0.0260)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.080 (per-example: 0.0009)\n",
      "question: 92, turn: 2, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 57%|████████████████████████▏                 | 92/160 [04:31<02:53,  2.55s/it]\n",
      "Num API calls: 93 Prompt Tokens: 58259, Completion Tokens: 11413\n",
      "Cost [gpt-4-turbo]: 0.925 (per-example: 0.0099)\n",
      "Cost [gpt-4]: 2.433 (per-example: 0.0262)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.081 (per-example: 0.0009)\n",
      "question: 93, turn: 2, model: model_answer, score: -1, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 58%|████████████████████████▍                 | 93/160 [04:35<03:01,  2.71s/it]\n",
      "Num API calls: 94 Prompt Tokens: 59504, Completion Tokens: 11546\n",
      "Cost [gpt-4-turbo]: 0.941 (per-example: 0.0100)\n",
      "Cost [gpt-4]: 2.478 (per-example: 0.0264)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.083 (per-example: 0.0009)\n",
      "question: 94, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 59%|████████████████████████▋                 | 94/160 [04:37<02:57,  2.69s/it]\n",
      "Num API calls: 95 Prompt Tokens: 60128, Completion Tokens: 11656\n",
      "Cost [gpt-4-turbo]: 0.951 (per-example: 0.0100)\n",
      "Cost [gpt-4]: 2.503 (per-example: 0.0263)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.083 (per-example: 0.0009)\n",
      "question: 95, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 59%|████████████████████████▉                 | 95/160 [04:39<02:37,  2.42s/it]\n",
      "Num API calls: 96 Prompt Tokens: 61040, Completion Tokens: 11768\n",
      "Cost [gpt-4-turbo]: 0.963 (per-example: 0.0100)\n",
      "Cost [gpt-4]: 2.537 (per-example: 0.0264)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.085 (per-example: 0.0009)\n",
      "question: 96, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 60%|█████████████████████████▏                | 96/160 [04:43<02:56,  2.76s/it]\n",
      "Num API calls: 97 Prompt Tokens: 62201, Completion Tokens: 11871\n",
      "Cost [gpt-4-turbo]: 0.978 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.578 (per-example: 0.0266)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.086 (per-example: 0.0009)\n",
      "question: 97, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 61%|█████████████████████████▍                | 97/160 [04:45<02:52,  2.74s/it]\n",
      "Num API calls: 98 Prompt Tokens: 62831, Completion Tokens: 12004\n",
      "Cost [gpt-4-turbo]: 0.988 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.605 (per-example: 0.0266)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.087 (per-example: 0.0009)\n",
      "question: 98, turn: 2, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████▋                | 98/160 [04:47<02:36,  2.52s/it]\n",
      "Num API calls: 99 Prompt Tokens: 63435, Completion Tokens: 12124\n",
      "Cost [gpt-4-turbo]: 0.998 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.630 (per-example: 0.0266)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.088 (per-example: 0.0009)\n",
      "question: 99, turn: 2, model: model_answer, score: 7, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 62%|█████████████████████████▉                | 99/160 [04:49<02:23,  2.36s/it]\n",
      "Num API calls: 100 Prompt Tokens: 64459, Completion Tokens: 12275\n",
      "Cost [gpt-4-turbo]: 1.013 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.670 (per-example: 0.0267)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.089 (per-example: 0.0009)\n",
      "question: 100, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 62%|█████████████████████████▋               | 100/160 [04:54<03:02,  3.03s/it]\n",
      "Num API calls: 101 Prompt Tokens: 65154, Completion Tokens: 12336\n",
      "Cost [gpt-4-turbo]: 1.022 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.695 (per-example: 0.0267)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.090 (per-example: 0.0009)\n",
      "question: 131, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 63%|█████████████████████████▉               | 101/160 [04:55<02:25,  2.46s/it]\n",
      "Num API calls: 102 Prompt Tokens: 65738, Completion Tokens: 12435\n",
      "Cost [gpt-4-turbo]: 1.030 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.718 (per-example: 0.0266)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.091 (per-example: 0.0009)\n",
      "question: 132, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 64%|██████████████████████████▏              | 102/160 [04:58<02:38,  2.72s/it]\n",
      "Num API calls: 103 Prompt Tokens: 66417, Completion Tokens: 12511\n",
      "Cost [gpt-4-turbo]: 1.039 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.743 (per-example: 0.0266)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.091 (per-example: 0.0009)\n",
      "question: 133, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 64%|██████████████████████████▍              | 103/160 [05:00<02:20,  2.47s/it]\n",
      "Num API calls: 104 Prompt Tokens: 67099, Completion Tokens: 12605\n",
      "Cost [gpt-4-turbo]: 1.049 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.769 (per-example: 0.0266)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.092 (per-example: 0.0009)\n",
      "question: 134, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 65%|██████████████████████████▋              | 104/160 [05:02<02:03,  2.20s/it]\n",
      "Num API calls: 105 Prompt Tokens: 67678, Completion Tokens: 12716\n",
      "Cost [gpt-4-turbo]: 1.058 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.793 (per-example: 0.0266)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.093 (per-example: 0.0009)\n",
      "question: 135, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 66%|██████████████████████████▉              | 105/160 [05:04<01:54,  2.08s/it]\n",
      "Num API calls: 106 Prompt Tokens: 68267, Completion Tokens: 12806\n",
      "Cost [gpt-4-turbo]: 1.067 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.816 (per-example: 0.0266)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.094 (per-example: 0.0009)\n",
      "question: 136, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 66%|███████████████████████████▏             | 106/160 [05:05<01:49,  2.03s/it]\n",
      "Num API calls: 107 Prompt Tokens: 68791, Completion Tokens: 12922\n",
      "Cost [gpt-4-turbo]: 1.076 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.839 (per-example: 0.0265)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.095 (per-example: 0.0009)\n",
      "question: 137, turn: 2, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 67%|███████████████████████████▍             | 107/160 [05:08<01:49,  2.06s/it]\n",
      "Num API calls: 108 Prompt Tokens: 69685, Completion Tokens: 13027\n",
      "Cost [gpt-4-turbo]: 1.088 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.872 (per-example: 0.0266)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.096 (per-example: 0.0009)\n",
      "question: 138, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 68%|███████████████████████████▋             | 108/160 [05:09<01:43,  1.98s/it]\n",
      "Num API calls: 109 Prompt Tokens: 70578, Completion Tokens: 13117\n",
      "Cost [gpt-4-turbo]: 1.099 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.904 (per-example: 0.0266)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.097 (per-example: 0.0009)\n",
      "question: 139, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 68%|███████████████████████████▉             | 109/160 [05:12<01:52,  2.20s/it]\n",
      "Num API calls: 110 Prompt Tokens: 71694, Completion Tokens: 13199\n",
      "Cost [gpt-4-turbo]: 1.113 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.943 (per-example: 0.0268)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.098 (per-example: 0.0009)\n",
      "question: 140, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 69%|████████████████████████████▏            | 110/160 [05:14<01:40,  2.01s/it]\n",
      "Num API calls: 111 Prompt Tokens: 72278, Completion Tokens: 13337\n",
      "Cost [gpt-4-turbo]: 1.123 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.969 (per-example: 0.0267)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.099 (per-example: 0.0009)\n",
      "question: 141, turn: 2, model: model_answer, score: -1, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 69%|████████████████████████████▍            | 111/160 [05:16<01:45,  2.15s/it]\n",
      "Num API calls: 112 Prompt Tokens: 72975, Completion Tokens: 13458\n",
      "Cost [gpt-4-turbo]: 1.133 (per-example: 0.0101)\n",
      "Cost [gpt-4]: 2.997 (per-example: 0.0268)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.100 (per-example: 0.0009)\n",
      "question: 142, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 70%|████████████████████████████▋            | 112/160 [05:19<01:52,  2.34s/it]\n",
      "Num API calls: 113 Prompt Tokens: 74477, Completion Tokens: 13585\n",
      "Cost [gpt-4-turbo]: 1.152 (per-example: 0.0102)\n",
      "Cost [gpt-4]: 3.049 (per-example: 0.0270)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.102 (per-example: 0.0009)\n",
      "question: 143, turn: 2, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 71%|████████████████████████████▉            | 113/160 [05:23<02:17,  2.93s/it]\n",
      "Num API calls: 114 Prompt Tokens: 75038, Completion Tokens: 13649\n",
      "Cost [gpt-4-turbo]: 1.160 (per-example: 0.0102)\n",
      "Cost [gpt-4]: 3.070 (per-example: 0.0269)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.102 (per-example: 0.0009)\n",
      "question: 144, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 71%|█████████████████████████████▏           | 114/160 [05:26<02:11,  2.87s/it]\n",
      "Num API calls: 115 Prompt Tokens: 75830, Completion Tokens: 13724\n",
      "Cost [gpt-4-turbo]: 1.170 (per-example: 0.0102)\n",
      "Cost [gpt-4]: 3.098 (per-example: 0.0269)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.103 (per-example: 0.0009)\n",
      "question: 145, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 72%|█████████████████████████████▍           | 115/160 [05:29<02:15,  3.00s/it]\n",
      "Num API calls: 116 Prompt Tokens: 76944, Completion Tokens: 13844\n",
      "Cost [gpt-4-turbo]: 1.185 (per-example: 0.0102)\n",
      "Cost [gpt-4]: 3.139 (per-example: 0.0271)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.105 (per-example: 0.0009)\n",
      "question: 146, turn: 2, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 72%|█████████████████████████████▋           | 116/160 [05:33<02:21,  3.22s/it]\n",
      "Num API calls: 117 Prompt Tokens: 77844, Completion Tokens: 13956\n",
      "Cost [gpt-4-turbo]: 1.197 (per-example: 0.0102)\n",
      "Cost [gpt-4]: 3.173 (per-example: 0.0271)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.106 (per-example: 0.0009)\n",
      "question: 147, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 73%|█████████████████████████████▉           | 117/160 [05:36<02:21,  3.29s/it]\n",
      "Num API calls: 118 Prompt Tokens: 79015, Completion Tokens: 14084\n",
      "Cost [gpt-4-turbo]: 1.213 (per-example: 0.0103)\n",
      "Cost [gpt-4]: 3.215 (per-example: 0.0272)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.107 (per-example: 0.0009)\n",
      "question: 148, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 74%|██████████████████████████████▏          | 118/160 [05:40<02:27,  3.51s/it]\n",
      "Num API calls: 119 Prompt Tokens: 79964, Completion Tokens: 14187\n",
      "Cost [gpt-4-turbo]: 1.225 (per-example: 0.0103)\n",
      "Cost [gpt-4]: 3.250 (per-example: 0.0273)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.108 (per-example: 0.0009)\n",
      "question: 149, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74%|██████████████████████████████▍          | 119/160 [05:43<02:07,  3.11s/it]\n",
      "Num API calls: 120 Prompt Tokens: 80941, Completion Tokens: 14318\n",
      "Cost [gpt-4-turbo]: 1.239 (per-example: 0.0103)\n",
      "Cost [gpt-4]: 3.287 (per-example: 0.0274)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.110 (per-example: 0.0009)\n",
      "question: 150, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 75%|██████████████████████████████▊          | 120/160 [05:46<02:02,  3.05s/it]\n",
      "Num API calls: 121 Prompt Tokens: 82070, Completion Tokens: 14443\n",
      "Cost [gpt-4-turbo]: 1.254 (per-example: 0.0104)\n",
      "Cost [gpt-4]: 3.329 (per-example: 0.0275)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.111 (per-example: 0.0009)\n",
      "question: 151, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 76%|███████████████████████████████          | 121/160 [05:49<02:02,  3.15s/it]\n",
      "Num API calls: 122 Prompt Tokens: 82857, Completion Tokens: 14628\n",
      "Cost [gpt-4-turbo]: 1.267 (per-example: 0.0104)\n",
      "Cost [gpt-4]: 3.363 (per-example: 0.0276)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.112 (per-example: 0.0009)\n",
      "question: 152, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 76%|███████████████████████████████▎         | 122/160 [05:54<02:16,  3.60s/it]\n",
      "Num API calls: 123 Prompt Tokens: 84194, Completion Tokens: 14741\n",
      "Cost [gpt-4-turbo]: 1.284 (per-example: 0.0104)\n",
      "Cost [gpt-4]: 3.410 (per-example: 0.0277)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.114 (per-example: 0.0009)\n",
      "question: 153, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 77%|███████████████████████████████▌         | 123/160 [05:56<01:55,  3.13s/it]\n",
      "Num API calls: 124 Prompt Tokens: 85536, Completion Tokens: 14858\n",
      "Cost [gpt-4-turbo]: 1.301 (per-example: 0.0105)\n",
      "Cost [gpt-4]: 3.458 (per-example: 0.0279)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.115 (per-example: 0.0009)\n",
      "question: 154, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 78%|███████████████████████████████▊         | 124/160 [05:58<01:47,  2.98s/it]\n",
      "Num API calls: 125 Prompt Tokens: 86585, Completion Tokens: 14982\n",
      "Cost [gpt-4-turbo]: 1.315 (per-example: 0.0105)\n",
      "Cost [gpt-4]: 3.496 (per-example: 0.0280)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.117 (per-example: 0.0009)\n",
      "question: 155, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 78%|████████████████████████████████         | 125/160 [06:01<01:44,  2.99s/it]\n",
      "Num API calls: 126 Prompt Tokens: 87728, Completion Tokens: 15150\n",
      "Cost [gpt-4-turbo]: 1.332 (per-example: 0.0106)\n",
      "Cost [gpt-4]: 3.541 (per-example: 0.0281)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.118 (per-example: 0.0009)\n",
      "question: 156, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 79%|████████████████████████████████▎        | 126/160 [06:05<01:51,  3.28s/it]\n",
      "Num API calls: 127 Prompt Tokens: 88745, Completion Tokens: 15315\n",
      "Cost [gpt-4-turbo]: 1.347 (per-example: 0.0106)\n",
      "Cost [gpt-4]: 3.581 (per-example: 0.0282)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.119 (per-example: 0.0009)\n",
      "question: 157, turn: 2, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 79%|████████████████████████████████▌        | 127/160 [06:08<01:42,  3.11s/it]\n",
      "Num API calls: 128 Prompt Tokens: 91153, Completion Tokens: 15441\n",
      "Cost [gpt-4-turbo]: 1.375 (per-example: 0.0107)\n",
      "Cost [gpt-4]: 3.661 (per-example: 0.0286)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.122 (per-example: 0.0010)\n",
      "question: 158, turn: 2, model: model_answer, score: 7, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 80%|████████████████████████████████▊        | 128/160 [06:10<01:30,  2.83s/it]\n",
      "Num API calls: 129 Prompt Tokens: 92414, Completion Tokens: 15600\n",
      "Cost [gpt-4-turbo]: 1.392 (per-example: 0.0108)\n",
      "Cost [gpt-4]: 3.708 (per-example: 0.0287)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.124 (per-example: 0.0010)\n",
      "question: 159, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 81%|█████████████████████████████████        | 129/160 [06:13<01:30,  2.92s/it]\n",
      "Num API calls: 130 Prompt Tokens: 93640, Completion Tokens: 15727\n",
      "Cost [gpt-4-turbo]: 1.408 (per-example: 0.0108)\n",
      "Cost [gpt-4]: 3.753 (per-example: 0.0289)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.125 (per-example: 0.0010)\n",
      "question: 160, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-v1-multi-turn')\n",
      " 81%|█████████████████████████████████▎       | 130/160 [06:16<01:27,  2.90s/it]\n",
      "Num API calls: 131 Prompt Tokens: 94174, Completion Tokens: 15803\n",
      "Cost [gpt-4-turbo]: 1.416 (per-example: 0.0108)\n",
      "Cost [gpt-4]: 3.773 (per-example: 0.0288)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.126 (per-example: 0.0010)\n",
      "question: 101, turn: 2, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 82%|█████████████████████████████████▌       | 131/160 [06:18<01:18,  2.71s/it]\n",
      "Num API calls: 132 Prompt Tokens: 94720, Completion Tokens: 15884\n",
      "Cost [gpt-4-turbo]: 1.424 (per-example: 0.0108)\n",
      "Cost [gpt-4]: 3.795 (per-example: 0.0287)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.126 (per-example: 0.0010)\n",
      "question: 102, turn: 2, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 82%|█████████████████████████████████▊       | 132/160 [06:20<01:08,  2.45s/it]\n",
      "Num API calls: 133 Prompt Tokens: 95922, Completion Tokens: 16018\n",
      "Cost [gpt-4-turbo]: 1.440 (per-example: 0.0108)\n",
      "Cost [gpt-4]: 3.839 (per-example: 0.0289)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.128 (per-example: 0.0010)\n",
      "question: 103, turn: 2, model: model_answer, score: 7, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 83%|██████████████████████████████████       | 133/160 [06:24<01:18,  2.89s/it]\n",
      "Num API calls: 134 Prompt Tokens: 96410, Completion Tokens: 16083\n",
      "Cost [gpt-4-turbo]: 1.447 (per-example: 0.0108)\n",
      "Cost [gpt-4]: 3.857 (per-example: 0.0288)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.129 (per-example: 0.0010)\n",
      "question: 104, turn: 2, model: model_answer, score: 2, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 84%|██████████████████████████████████▎      | 134/160 [06:27<01:17,  2.99s/it]\n",
      "Num API calls: 135 Prompt Tokens: 97714, Completion Tokens: 16148\n",
      "Cost [gpt-4-turbo]: 1.462 (per-example: 0.0108)\n",
      "Cost [gpt-4]: 3.900 (per-example: 0.0289)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.130 (per-example: 0.0010)\n",
      "question: 105, turn: 2, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 84%|██████████████████████████████████▌      | 135/160 [06:29<01:07,  2.70s/it]\n",
      "Num API calls: 136 Prompt Tokens: 98379, Completion Tokens: 16238\n",
      "Cost [gpt-4-turbo]: 1.471 (per-example: 0.0108)\n",
      "Cost [gpt-4]: 3.926 (per-example: 0.0289)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.131 (per-example: 0.0010)\n",
      "question: 106, turn: 2, model: model_answer, score: 9, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 85%|██████████████████████████████████▊      | 136/160 [06:32<01:03,  2.65s/it]\n",
      "Num API calls: 137 Prompt Tokens: 99302, Completion Tokens: 16325\n",
      "Cost [gpt-4-turbo]: 1.483 (per-example: 0.0108)\n",
      "Cost [gpt-4]: 3.959 (per-example: 0.0289)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.132 (per-example: 0.0010)\n",
      "question: 107, turn: 2, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 86%|███████████████████████████████████      | 137/160 [06:34<00:54,  2.36s/it]\n",
      "Num API calls: 138 Prompt Tokens: 99728, Completion Tokens: 16415\n",
      "Cost [gpt-4-turbo]: 1.490 (per-example: 0.0108)\n",
      "Cost [gpt-4]: 3.977 (per-example: 0.0288)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.133 (per-example: 0.0010)\n",
      "question: 108, turn: 2, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 86%|███████████████████████████████████▎     | 138/160 [06:36<00:52,  2.37s/it]\n",
      "Num API calls: 139 Prompt Tokens: 100698, Completion Tokens: 16504\n",
      "Cost [gpt-4-turbo]: 1.502 (per-example: 0.0108)\n",
      "Cost [gpt-4]: 4.011 (per-example: 0.0289)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.134 (per-example: 0.0010)\n",
      "question: 109, turn: 2, model: model_answer, score: 4, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 87%|███████████████████████████████████▌     | 139/160 [06:39<00:55,  2.63s/it]\n",
      "Num API calls: 140 Prompt Tokens: 102002, Completion Tokens: 16725\n",
      "Cost [gpt-4-turbo]: 1.522 (per-example: 0.0109)\n",
      "Cost [gpt-4]: 4.064 (per-example: 0.0290)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.135 (per-example: 0.0010)\n",
      "question: 110, turn: 2, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████▉     | 140/160 [06:43<00:58,  2.92s/it]\n",
      "Num API calls: 141 Prompt Tokens: 103598, Completion Tokens: 16788\n",
      "Cost [gpt-4-turbo]: 1.540 (per-example: 0.0109)\n",
      "Cost [gpt-4]: 4.115 (per-example: 0.0292)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.137 (per-example: 0.0010)\n",
      "question: 111, turn: 2, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 88%|████████████████████████████████████▏    | 141/160 [06:47<01:00,  3.17s/it]\n",
      "Num API calls: 142 Prompt Tokens: 104222, Completion Tokens: 16898\n",
      "Cost [gpt-4-turbo]: 1.549 (per-example: 0.0109)\n",
      "Cost [gpt-4]: 4.141 (per-example: 0.0292)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.138 (per-example: 0.0010)\n",
      "question: 112, turn: 2, model: model_answer, score: 4, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 89%|████████████████████████████████████▍    | 142/160 [06:49<00:55,  3.06s/it]\n",
      "Num API calls: 143 Prompt Tokens: 105376, Completion Tokens: 17049\n",
      "Cost [gpt-4-turbo]: 1.565 (per-example: 0.0109)\n",
      "Cost [gpt-4]: 4.184 (per-example: 0.0293)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.139 (per-example: 0.0010)\n",
      "question: 113, turn: 2, model: model_answer, score: 4, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 89%|████████████████████████████████████▋    | 143/160 [06:52<00:48,  2.86s/it]\n",
      "Num API calls: 144 Prompt Tokens: 107893, Completion Tokens: 17221\n",
      "Cost [gpt-4-turbo]: 1.596 (per-example: 0.0111)\n",
      "Cost [gpt-4]: 4.270 (per-example: 0.0297)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.142 (per-example: 0.0010)\n",
      "question: 114, turn: 2, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 90%|████████████████████████████████████▉    | 144/160 [06:56<00:51,  3.20s/it]\n",
      "Num API calls: 145 Prompt Tokens: 108981, Completion Tokens: 17372\n",
      "Cost [gpt-4-turbo]: 1.611 (per-example: 0.0111)\n",
      "Cost [gpt-4]: 4.312 (per-example: 0.0297)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.144 (per-example: 0.0010)\n",
      "question: 115, turn: 2, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 91%|█████████████████████████████████████▏   | 145/160 [07:01<00:55,  3.67s/it]\n",
      "Num API calls: 146 Prompt Tokens: 110050, Completion Tokens: 17474\n",
      "Cost [gpt-4-turbo]: 1.625 (per-example: 0.0111)\n",
      "Cost [gpt-4]: 4.350 (per-example: 0.0298)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.145 (per-example: 0.0010)\n",
      "question: 116, turn: 2, model: model_answer, score: 8, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 91%|█████████████████████████████████████▍   | 146/160 [07:04<00:50,  3.62s/it]\n",
      "Num API calls: 147 Prompt Tokens: 111086, Completion Tokens: 17600\n",
      "Cost [gpt-4-turbo]: 1.639 (per-example: 0.0111)\n",
      "Cost [gpt-4]: 4.389 (per-example: 0.0299)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.146 (per-example: 0.0010)\n",
      "question: 117, turn: 2, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 92%|█████████████████████████████████████▋   | 147/160 [07:07<00:44,  3.41s/it]\n",
      "Num API calls: 148 Prompt Tokens: 112191, Completion Tokens: 17725\n",
      "Cost [gpt-4-turbo]: 1.654 (per-example: 0.0112)\n",
      "Cost [gpt-4]: 4.429 (per-example: 0.0299)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.148 (per-example: 0.0010)\n",
      "question: 118, turn: 2, model: model_answer, score: 4, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 92%|█████████████████████████████████████▉   | 148/160 [07:09<00:36,  3.04s/it]\n",
      "Num API calls: 149 Prompt Tokens: 113292, Completion Tokens: 17797\n",
      "Cost [gpt-4-turbo]: 1.667 (per-example: 0.0112)\n",
      "Cost [gpt-4]: 4.467 (per-example: 0.0300)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.149 (per-example: 0.0010)\n",
      "question: 119, turn: 2, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 93%|██████████████████████████████████████▏  | 149/160 [07:12<00:31,  2.88s/it]\n",
      "Num API calls: 150 Prompt Tokens: 114530, Completion Tokens: 17983\n",
      "Cost [gpt-4-turbo]: 1.685 (per-example: 0.0112)\n",
      "Cost [gpt-4]: 4.515 (per-example: 0.0301)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.150 (per-example: 0.0010)\n",
      "question: 120, turn: 2, model: model_answer, score: 4, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 94%|██████████████████████████████████████▍  | 150/160 [07:15<00:29,  2.90s/it]\n",
      "Num API calls: 151 Prompt Tokens: 116357, Completion Tokens: 18105\n",
      "Cost [gpt-4-turbo]: 1.707 (per-example: 0.0113)\n",
      "Cost [gpt-4]: 4.577 (per-example: 0.0303)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.153 (per-example: 0.0010)\n",
      "question: 121, turn: 2, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 94%|██████████████████████████████████████▋  | 151/160 [07:19<00:30,  3.38s/it]\n",
      "Num API calls: 152 Prompt Tokens: 117792, Completion Tokens: 18261\n",
      "Cost [gpt-4-turbo]: 1.726 (per-example: 0.0114)\n",
      "Cost [gpt-4]: 4.629 (per-example: 0.0305)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.154 (per-example: 0.0010)\n",
      "question: 122, turn: 2, model: model_answer, score: 2, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 95%|██████████████████████████████████████▉  | 152/160 [07:22<00:25,  3.17s/it]\n",
      "Num API calls: 153 Prompt Tokens: 119875, Completion Tokens: 18487\n",
      "Cost [gpt-4-turbo]: 1.753 (per-example: 0.0115)\n",
      "Cost [gpt-4]: 4.705 (per-example: 0.0308)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.157 (per-example: 0.0010)\n",
      "question: 123, turn: 2, model: model_answer, score: 7, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 96%|███████████████████████████████████████▏ | 153/160 [07:25<00:22,  3.26s/it]\n",
      "Num API calls: 154 Prompt Tokens: 121353, Completion Tokens: 18583\n",
      "Cost [gpt-4-turbo]: 1.771 (per-example: 0.0115)\n",
      "Cost [gpt-4]: 4.756 (per-example: 0.0309)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.159 (per-example: 0.0010)\n",
      "question: 124, turn: 2, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 96%|███████████████████████████████████████▍ | 154/160 [07:28<00:18,  3.04s/it]\n",
      "Num API calls: 155 Prompt Tokens: 123307, Completion Tokens: 18738\n",
      "Cost [gpt-4-turbo]: 1.795 (per-example: 0.0116)\n",
      "Cost [gpt-4]: 4.823 (per-example: 0.0311)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.161 (per-example: 0.0010)\n",
      "question: 125, turn: 2, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 97%|███████████████████████████████████████▋ | 155/160 [07:31<00:14,  2.95s/it]\n",
      "Num API calls: 156 Prompt Tokens: 125152, Completion Tokens: 18919\n",
      "Cost [gpt-4-turbo]: 1.819 (per-example: 0.0117)\n",
      "Cost [gpt-4]: 4.890 (per-example: 0.0313)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.163 (per-example: 0.0010)\n",
      "question: 126, turn: 2, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 98%|███████████████████████████████████████▉ | 156/160 [07:34<00:13,  3.25s/it]\n",
      "Num API calls: 157 Prompt Tokens: 126875, Completion Tokens: 19035\n",
      "Cost [gpt-4-turbo]: 1.840 (per-example: 0.0117)\n",
      "Cost [gpt-4]: 4.948 (per-example: 0.0315)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.165 (per-example: 0.0011)\n",
      "question: 127, turn: 2, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 98%|████████████████████████████████████████▏| 157/160 [07:37<00:08,  2.97s/it]\n",
      "Num API calls: 158 Prompt Tokens: 128283, Completion Tokens: 19177\n",
      "Cost [gpt-4-turbo]: 1.858 (per-example: 0.0118)\n",
      "Cost [gpt-4]: 4.999 (per-example: 0.0316)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.167 (per-example: 0.0011)\n",
      "question: 128, turn: 2, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 99%|████████████████████████████████████████▍| 158/160 [07:39<00:05,  2.79s/it]\n",
      "Num API calls: 159 Prompt Tokens: 130124, Completion Tokens: 19305\n",
      "Cost [gpt-4-turbo]: 1.880 (per-example: 0.0118)\n",
      "Cost [gpt-4]: 5.062 (per-example: 0.0318)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.169 (per-example: 0.0011)\n",
      "question: 129, turn: 2, model: model_answer, score: 3, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      " 99%|████████████████████████████████████████▋| 159/160 [07:43<00:03,  3.06s/it]\n",
      "Num API calls: 160 Prompt Tokens: 131836, Completion Tokens: 19395\n",
      "Cost [gpt-4-turbo]: 1.900 (per-example: 0.0119)\n",
      "Cost [gpt-4]: 5.119 (per-example: 0.0320)\n",
      "Cost [gpt-3.5-turbo-1106]: 0.171 (per-example: 0.0011)\n",
      "question: 130, turn: 2, model: model_answer, score: 10, judge: ('gpt-3.5-turbo-1106', 'single-math-v1-multi-turn')\n",
      "100%|█████████████████████████████████████████| 160/160 [07:46<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ python -m fastchat.llm_judge.show_result --bench-name mt_bench --input-file results/baselines/HuggingFaceH4/zephyr-7b-beta/eval/mtbench_ann=gpt:3.5:turbo:1106_chatfmt/gpt-3.5-turbo-1106_single.jsonl --mode single --save-to-json\n",
      "Mode: single\n",
      "Input file: results/baselines/HuggingFaceH4/zephyr-7b-beta/eval/mtbench_ann=gpt:3.5:turbo:1106_chatfmt/gpt-3.5-turbo-1106_single.jsonl\n",
      "\n",
      "########## First turn ##########\n",
      "                   score\n",
      "model        turn       \n",
      "model_answer 1     7.275\n",
      "\n",
      "########## Second turn ##########\n",
      "                      score\n",
      "model        turn          \n",
      "model_answer 2     7.649351\n",
      "\n",
      "########## Average ##########\n",
      "                 score\n",
      "model                 \n",
      "model_answer  7.458599\n",
      "Input file: results/baselines/HuggingFaceH4/zephyr-7b-beta/eval/mtbench_ann=gpt:3.5:turbo:1106_chatfmt/gpt-3.5-turbo-1106_single.jsonl\n",
      "Save metrics to \n",
      "\tresults/baselines/HuggingFaceH4/zephyr-7b-beta/eval/mtbench_ann=gpt:3.5:turbo:1106_chatfmt/metrics.json\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_eval.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859d6d6",
   "metadata": {},
   "source": [
    "# Visualize Eval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b033ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./1223352.out does not have `--save_dir` specified. Probably still running.\n",
      "Move ./1223732.out -> /dccstor/data-pruning/results/baselines/huggyllama/llama-7b/eval/gsm_s=8_cot/1223732.out.lsf\n"
     ]
    }
   ],
   "source": [
    "# if job successfully ran, lsf system will generate a summary in log_dir,\n",
    "# call this function to move lsf summary to save_dir if job is successful.\n",
    "move_lsf_job_summary_to_save_dir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4392e9ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_fmt=mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3128142/1984785548.py:366: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3128142/1984785548.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_81527 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_81527_row0_col0, #T_81527_row1_col0, #T_81527_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_81527_row0_col1, #T_81527_row1_col1, #T_81527_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_81527_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_81527_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81527_row0_col4, #T_81527_row0_col7, #T_81527_row0_col10, #T_81527_row0_col12, #T_81527_row1_col4, #T_81527_row2_col2, #T_81527_row2_col3, #T_81527_row2_col5, #T_81527_row2_col6, #T_81527_row2_col8, #T_81527_row2_col9, #T_81527_row2_col11, #T_81527_row2_col13, #T_81527_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_81527_row0_col5, #T_81527_row0_col6, #T_81527_row0_col8, #T_81527_row0_col9, #T_81527_row0_col11, #T_81527_row0_col13, #T_81527_row1_col2, #T_81527_row1_col3, #T_81527_row1_col10, #T_81527_row1_col14, #T_81527_row2_col4, #T_81527_row2_col7, #T_81527_row2_col10, #T_81527_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_81527_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81527_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81527_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81527_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81527_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81527_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81527_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_81527_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_81527_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_81527\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_81527_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_81527_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_81527_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_81527_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_81527_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_81527_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_81527_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_81527_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_81527_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_81527_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_81527_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_81527_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_81527_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_81527_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_81527_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_81527_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_81527_row0_col0\" class=\"data row0 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_81527_row0_col1\" class=\"data row0 col1\" >10000</td>\n",
       "      <td id=\"T_81527_row0_col2\" class=\"data row0 col2\" >32.3</td>\n",
       "      <td id=\"T_81527_row0_col3\" class=\"data row0 col3\" >36.0</td>\n",
       "      <td id=\"T_81527_row0_col4\" class=\"data row0 col4\" >6.0</td>\n",
       "      <td id=\"T_81527_row0_col5\" class=\"data row0 col5\" >13.0</td>\n",
       "      <td id=\"T_81527_row0_col6\" class=\"data row0 col6\" >32.5</td>\n",
       "      <td id=\"T_81527_row0_col7\" class=\"data row0 col7\" >33.0</td>\n",
       "      <td id=\"T_81527_row0_col8\" class=\"data row0 col8\" >10.6</td>\n",
       "      <td id=\"T_81527_row0_col9\" class=\"data row0 col9\" >42.6</td>\n",
       "      <td id=\"T_81527_row0_col10\" class=\"data row0 col10\" >10.6</td>\n",
       "      <td id=\"T_81527_row0_col11\" class=\"data row0 col11\" >23.0</td>\n",
       "      <td id=\"T_81527_row0_col12\" class=\"data row0 col12\" >299.9</td>\n",
       "      <td id=\"T_81527_row0_col13\" class=\"data row0 col13\" >24.0</td>\n",
       "      <td id=\"T_81527_row0_col14\" class=\"data row0 col14\" >-18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81527_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_81527_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_81527_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_81527_row1_col2\" class=\"data row1 col2\" >34.0</td>\n",
       "      <td id=\"T_81527_row1_col3\" class=\"data row1 col3\" >37.3</td>\n",
       "      <td id=\"T_81527_row1_col4\" class=\"data row1 col4\" >6.0</td>\n",
       "      <td id=\"T_81527_row1_col5\" class=\"data row1 col5\" >12.0</td>\n",
       "      <td id=\"T_81527_row1_col6\" class=\"data row1 col6\" >31.9</td>\n",
       "      <td id=\"T_81527_row1_col7\" class=\"data row1 col7\" >34.3</td>\n",
       "      <td id=\"T_81527_row1_col8\" class=\"data row1 col8\" >10.3</td>\n",
       "      <td id=\"T_81527_row1_col9\" class=\"data row1 col9\" >40.2</td>\n",
       "      <td id=\"T_81527_row1_col10\" class=\"data row1 col10\" >10.8</td>\n",
       "      <td id=\"T_81527_row1_col11\" class=\"data row1 col11\" >22.5</td>\n",
       "      <td id=\"T_81527_row1_col12\" class=\"data row1 col12\" >515.8</td>\n",
       "      <td id=\"T_81527_row1_col13\" class=\"data row1 col13\" >23.9</td>\n",
       "      <td id=\"T_81527_row1_col14\" class=\"data row1 col14\" >-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81527_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_81527_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_81527_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_81527_row2_col2\" class=\"data row2 col2\" >32.0</td>\n",
       "      <td id=\"T_81527_row2_col3\" class=\"data row2 col3\" >35.5</td>\n",
       "      <td id=\"T_81527_row2_col4\" class=\"data row2 col4\" >6.2</td>\n",
       "      <td id=\"T_81527_row2_col5\" class=\"data row2 col5\" >11.2</td>\n",
       "      <td id=\"T_81527_row2_col6\" class=\"data row2 col6\" >30.6</td>\n",
       "      <td id=\"T_81527_row2_col7\" class=\"data row2 col7\" >34.7</td>\n",
       "      <td id=\"T_81527_row2_col8\" class=\"data row2 col8\" >9.5</td>\n",
       "      <td id=\"T_81527_row2_col9\" class=\"data row2 col9\" >39.0</td>\n",
       "      <td id=\"T_81527_row2_col10\" class=\"data row2 col10\" >10.8</td>\n",
       "      <td id=\"T_81527_row2_col11\" class=\"data row2 col11\" >18.6</td>\n",
       "      <td id=\"T_81527_row2_col12\" class=\"data row2 col12\" >771.2</td>\n",
       "      <td id=\"T_81527_row2_col13\" class=\"data row2 col13\" >22.8</td>\n",
       "      <td id=\"T_81527_row2_col14\" class=\"data row2 col14\" >-22.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14ffa87aab00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3128142/1984785548.py:366: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3128142/1984785548.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7395e td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_7395e_row0_col0, #T_7395e_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7395e_row0_col1, #T_7395e_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7395e_row0_col2, #T_7395e_row0_col3, #T_7395e_row0_col4, #T_7395e_row0_col5, #T_7395e_row0_col7, #T_7395e_row0_col8, #T_7395e_row0_col9, #T_7395e_row0_col10, #T_7395e_row0_col11, #T_7395e_row0_col12, #T_7395e_row0_col14, #T_7395e_row1_col2, #T_7395e_row1_col3, #T_7395e_row1_col5, #T_7395e_row1_col6, #T_7395e_row1_col7, #T_7395e_row1_col8, #T_7395e_row1_col9, #T_7395e_row1_col10, #T_7395e_row1_col11, #T_7395e_row1_col12, #T_7395e_row1_col13, #T_7395e_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7395e_row0_col6, #T_7395e_row0_col13, #T_7395e_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7395e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7395e_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_7395e_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_7395e_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_7395e_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_7395e_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_7395e_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_7395e_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_7395e_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_7395e_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_7395e_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_7395e_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_7395e_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_7395e_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_7395e_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_7395e_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7395e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7395e_row0_col0\" class=\"data row0 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_7395e_row0_col1\" class=\"data row0 col1\" >10000</td>\n",
       "      <td id=\"T_7395e_row0_col2\" class=\"data row0 col2\" >32.5</td>\n",
       "      <td id=\"T_7395e_row0_col3\" class=\"data row0 col3\" >33.9</td>\n",
       "      <td id=\"T_7395e_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_7395e_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_7395e_row0_col6\" class=\"data row0 col6\" >32.1</td>\n",
       "      <td id=\"T_7395e_row0_col7\" class=\"data row0 col7\" >32.0</td>\n",
       "      <td id=\"T_7395e_row0_col8\" class=\"data row0 col8\" >10.3</td>\n",
       "      <td id=\"T_7395e_row0_col9\" class=\"data row0 col9\" >40.4</td>\n",
       "      <td id=\"T_7395e_row0_col10\" class=\"data row0 col10\" >10.6</td>\n",
       "      <td id=\"T_7395e_row0_col11\" class=\"data row0 col11\" >10.0</td>\n",
       "      <td id=\"T_7395e_row0_col12\" class=\"data row0 col12\" >113.1</td>\n",
       "      <td id=\"T_7395e_row0_col13\" class=\"data row0 col13\" >22.0</td>\n",
       "      <td id=\"T_7395e_row0_col14\" class=\"data row0 col14\" >-24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7395e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7395e_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_7395e_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_7395e_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_7395e_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_7395e_row1_col4\" class=\"data row1 col4\" >7.2</td>\n",
       "      <td id=\"T_7395e_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_7395e_row1_col6\" class=\"data row1 col6\" >31.9</td>\n",
       "      <td id=\"T_7395e_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_7395e_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_7395e_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_7395e_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_7395e_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_7395e_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_7395e_row1_col13\" class=\"data row1 col13\" >19.6</td>\n",
       "      <td id=\"T_7395e_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14ffa87aa500>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3128142/1984785548.py:366: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3128142/1984785548.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f5259 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_f5259_row0_col0, #T_f5259_row1_col0, #T_f5259_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f5259_row0_col1, #T_f5259_row1_col1, #T_f5259_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f5259_row0_col2, #T_f5259_row0_col3, #T_f5259_row0_col7, #T_f5259_row0_col8, #T_f5259_row0_col10, #T_f5259_row0_col14, #T_f5259_row1_col4, #T_f5259_row1_col5, #T_f5259_row1_col6, #T_f5259_row1_col9, #T_f5259_row1_col12, #T_f5259_row2_col7, #T_f5259_row2_col11, #T_f5259_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f5259_row0_col4, #T_f5259_row0_col5, #T_f5259_row0_col6, #T_f5259_row0_col12, #T_f5259_row0_col13, #T_f5259_row1_col2, #T_f5259_row1_col3, #T_f5259_row1_col7, #T_f5259_row1_col10, #T_f5259_row1_col11, #T_f5259_row1_col14, #T_f5259_row2_col8, #T_f5259_row2_col9, #T_f5259_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f5259_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f5259_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f5259_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f5259_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f5259_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f5259_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f5259_row2_col4, #T_f5259_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f5259_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f5259_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d55042;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f5259_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f5259\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5259_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_f5259_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_f5259_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_f5259_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_f5259_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_f5259_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_f5259_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_f5259_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_f5259_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_f5259_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_f5259_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_f5259_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_f5259_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_f5259_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_f5259_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5259_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f5259_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_f5259_row0_col1\" class=\"data row0 col1\" >10000</td>\n",
       "      <td id=\"T_f5259_row0_col2\" class=\"data row0 col2\" >32.0</td>\n",
       "      <td id=\"T_f5259_row0_col3\" class=\"data row0 col3\" >36.3</td>\n",
       "      <td id=\"T_f5259_row0_col4\" class=\"data row0 col4\" >6.0</td>\n",
       "      <td id=\"T_f5259_row0_col5\" class=\"data row0 col5\" >12.8</td>\n",
       "      <td id=\"T_f5259_row0_col6\" class=\"data row0 col6\" >32.8</td>\n",
       "      <td id=\"T_f5259_row0_col7\" class=\"data row0 col7\" >33.1</td>\n",
       "      <td id=\"T_f5259_row0_col8\" class=\"data row0 col8\" >10.1</td>\n",
       "      <td id=\"T_f5259_row0_col9\" class=\"data row0 col9\" >39.2</td>\n",
       "      <td id=\"T_f5259_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_f5259_row0_col11\" class=\"data row0 col11\" >37.7</td>\n",
       "      <td id=\"T_f5259_row0_col12\" class=\"data row0 col12\" >289.9</td>\n",
       "      <td id=\"T_f5259_row0_col13\" class=\"data row0 col13\" >25.0</td>\n",
       "      <td id=\"T_f5259_row0_col14\" class=\"data row0 col14\" >-19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5259_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f5259_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_f5259_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_f5259_row1_col2\" class=\"data row1 col2\" >33.9</td>\n",
       "      <td id=\"T_f5259_row1_col3\" class=\"data row1 col3\" >37.2</td>\n",
       "      <td id=\"T_f5259_row1_col4\" class=\"data row1 col4\" >5.2</td>\n",
       "      <td id=\"T_f5259_row1_col5\" class=\"data row1 col5\" >10.4</td>\n",
       "      <td id=\"T_f5259_row1_col6\" class=\"data row1 col6\" >31.1</td>\n",
       "      <td id=\"T_f5259_row1_col7\" class=\"data row1 col7\" >34.2</td>\n",
       "      <td id=\"T_f5259_row1_col8\" class=\"data row1 col8\" >10.5</td>\n",
       "      <td id=\"T_f5259_row1_col9\" class=\"data row1 col9\" >38.1</td>\n",
       "      <td id=\"T_f5259_row1_col10\" class=\"data row1 col10\" >11.2</td>\n",
       "      <td id=\"T_f5259_row1_col11\" class=\"data row1 col11\" >37.7</td>\n",
       "      <td id=\"T_f5259_row1_col12\" class=\"data row1 col12\" >270.4</td>\n",
       "      <td id=\"T_f5259_row1_col13\" class=\"data row1 col13\" >25.0</td>\n",
       "      <td id=\"T_f5259_row1_col14\" class=\"data row1 col14\" >-18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5259_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f5259_row2_col0\" class=\"data row2 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_f5259_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_f5259_row2_col2\" class=\"data row2 col2\" >33.6</td>\n",
       "      <td id=\"T_f5259_row2_col3\" class=\"data row2 col3\" >36.6</td>\n",
       "      <td id=\"T_f5259_row2_col4\" class=\"data row2 col4\" >5.6</td>\n",
       "      <td id=\"T_f5259_row2_col5\" class=\"data row2 col5\" >11.6</td>\n",
       "      <td id=\"T_f5259_row2_col6\" class=\"data row2 col6\" >32.1</td>\n",
       "      <td id=\"T_f5259_row2_col7\" class=\"data row2 col7\" >33.1</td>\n",
       "      <td id=\"T_f5259_row2_col8\" class=\"data row2 col8\" >10.7</td>\n",
       "      <td id=\"T_f5259_row2_col9\" class=\"data row2 col9\" >39.7</td>\n",
       "      <td id=\"T_f5259_row2_col10\" class=\"data row2 col10\" >11.2</td>\n",
       "      <td id=\"T_f5259_row2_col11\" class=\"data row2 col11\" >31.7</td>\n",
       "      <td id=\"T_f5259_row2_col12\" class=\"data row2 col12\" >288.0</td>\n",
       "      <td id=\"T_f5259_row2_col13\" class=\"data row2 col13\" >24.6</td>\n",
       "      <td id=\"T_f5259_row2_col14\" class=\"data row2 col14\" >-18.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14ffa87aa740>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3128142/1984785548.py:366: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3128142/1984785548.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9abe8 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_9abe8_row0_col0, #T_9abe8_row1_col0, #T_9abe8_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9abe8_row0_col1, #T_9abe8_row1_col1, #T_9abe8_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9abe8_row0_col2, #T_9abe8_row0_col10, #T_9abe8_row0_col13, #T_9abe8_row0_col14, #T_9abe8_row1_col4, #T_9abe8_row1_col11, #T_9abe8_row2_col3, #T_9abe8_row2_col5, #T_9abe8_row2_col6, #T_9abe8_row2_col7, #T_9abe8_row2_col8, #T_9abe8_row2_col9, #T_9abe8_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9abe8_row0_col3, #T_9abe8_row0_col4, #T_9abe8_row0_col5, #T_9abe8_row0_col7, #T_9abe8_row0_col8, #T_9abe8_row0_col9, #T_9abe8_row1_col2, #T_9abe8_row1_col6, #T_9abe8_row1_col12, #T_9abe8_row1_col14, #T_9abe8_row2_col4, #T_9abe8_row2_col10, #T_9abe8_row2_col11, #T_9abe8_row2_col13, #T_9abe8_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9abe8_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9abe8_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9abe8_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9abe8_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9abe8_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9abe8_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9abe8_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9abe8_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9abe8_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9abe8_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9abe8_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9abe8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9abe8_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_9abe8_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_9abe8_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_9abe8_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_9abe8_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_9abe8_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_9abe8_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_9abe8_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_9abe8_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_9abe8_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_9abe8_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_9abe8_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_9abe8_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_9abe8_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_9abe8_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9abe8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9abe8_row0_col0\" class=\"data row0 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_9abe8_row0_col1\" class=\"data row0 col1\" >10000</td>\n",
       "      <td id=\"T_9abe8_row0_col2\" class=\"data row0 col2\" >33.9</td>\n",
       "      <td id=\"T_9abe8_row0_col3\" class=\"data row0 col3\" >35.8</td>\n",
       "      <td id=\"T_9abe8_row0_col4\" class=\"data row0 col4\" >6.2</td>\n",
       "      <td id=\"T_9abe8_row0_col5\" class=\"data row0 col5\" >12.0</td>\n",
       "      <td id=\"T_9abe8_row0_col6\" class=\"data row0 col6\" >30.7</td>\n",
       "      <td id=\"T_9abe8_row0_col7\" class=\"data row0 col7\" >32.8</td>\n",
       "      <td id=\"T_9abe8_row0_col8\" class=\"data row0 col8\" >9.9</td>\n",
       "      <td id=\"T_9abe8_row0_col9\" class=\"data row0 col9\" >36.9</td>\n",
       "      <td id=\"T_9abe8_row0_col10\" class=\"data row0 col10\" >14.2</td>\n",
       "      <td id=\"T_9abe8_row0_col11\" class=\"data row0 col11\" >40.6</td>\n",
       "      <td id=\"T_9abe8_row0_col12\" class=\"data row0 col12\" >441.8</td>\n",
       "      <td id=\"T_9abe8_row0_col13\" class=\"data row0 col13\" >25.3</td>\n",
       "      <td id=\"T_9abe8_row0_col14\" class=\"data row0 col14\" >-18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9abe8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9abe8_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlmv2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_9abe8_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_9abe8_row1_col2\" class=\"data row1 col2\" >31.8</td>\n",
       "      <td id=\"T_9abe8_row1_col3\" class=\"data row1 col3\" >36.0</td>\n",
       "      <td id=\"T_9abe8_row1_col4\" class=\"data row1 col4\" >6.6</td>\n",
       "      <td id=\"T_9abe8_row1_col5\" class=\"data row1 col5\" >12.6</td>\n",
       "      <td id=\"T_9abe8_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_9abe8_row1_col7\" class=\"data row1 col7\" >33.8</td>\n",
       "      <td id=\"T_9abe8_row1_col8\" class=\"data row1 col8\" >10.1</td>\n",
       "      <td id=\"T_9abe8_row1_col9\" class=\"data row1 col9\" >37.1</td>\n",
       "      <td id=\"T_9abe8_row1_col10\" class=\"data row1 col10\" >10.0</td>\n",
       "      <td id=\"T_9abe8_row1_col11\" class=\"data row1 col11\" >44.0</td>\n",
       "      <td id=\"T_9abe8_row1_col12\" class=\"data row1 col12\" >399.6</td>\n",
       "      <td id=\"T_9abe8_row1_col13\" class=\"data row1 col13\" >25.3</td>\n",
       "      <td id=\"T_9abe8_row1_col14\" class=\"data row1 col14\" >-18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9abe8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9abe8_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlmv2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_9abe8_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_9abe8_row2_col2\" class=\"data row2 col2\" >32.3</td>\n",
       "      <td id=\"T_9abe8_row2_col3\" class=\"data row2 col3\" >36.1</td>\n",
       "      <td id=\"T_9abe8_row2_col4\" class=\"data row2 col4\" >6.2</td>\n",
       "      <td id=\"T_9abe8_row2_col5\" class=\"data row2 col5\" >14.0</td>\n",
       "      <td id=\"T_9abe8_row2_col6\" class=\"data row2 col6\" >32.1</td>\n",
       "      <td id=\"T_9abe8_row2_col7\" class=\"data row2 col7\" >34.0</td>\n",
       "      <td id=\"T_9abe8_row2_col8\" class=\"data row2 col8\" >10.2</td>\n",
       "      <td id=\"T_9abe8_row2_col9\" class=\"data row2 col9\" >37.4</td>\n",
       "      <td id=\"T_9abe8_row2_col10\" class=\"data row2 col10\" >8.7</td>\n",
       "      <td id=\"T_9abe8_row2_col11\" class=\"data row2 col11\" >34.0</td>\n",
       "      <td id=\"T_9abe8_row2_col12\" class=\"data row2 col12\" >462.0</td>\n",
       "      <td id=\"T_9abe8_row2_col13\" class=\"data row2 col13\" >24.5</td>\n",
       "      <td id=\"T_9abe8_row2_col14\" class=\"data row2 col14\" >-18.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14ffa87a81c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3128142/1984785548.py:366: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3128142/1984785548.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bc3cd td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_bc3cd_row0_col0, #T_bc3cd_row1_col0, #T_bc3cd_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bc3cd_row0_col1, #T_bc3cd_row1_col1, #T_bc3cd_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bc3cd_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc3cd_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc3cd_row0_col4, #T_bc3cd_row0_col7, #T_bc3cd_row0_col11, #T_bc3cd_row0_col13, #T_bc3cd_row0_col14, #T_bc3cd_row1_col2, #T_bc3cd_row1_col3, #T_bc3cd_row1_col4, #T_bc3cd_row1_col8, #T_bc3cd_row1_col9, #T_bc3cd_row2_col5, #T_bc3cd_row2_col6, #T_bc3cd_row2_col10, #T_bc3cd_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc3cd_row0_col5, #T_bc3cd_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc3cd_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc3cd_row0_col8, #T_bc3cd_row0_col10, #T_bc3cd_row1_col5, #T_bc3cd_row1_col6, #T_bc3cd_row1_col7, #T_bc3cd_row1_col10, #T_bc3cd_row1_col11, #T_bc3cd_row1_col12, #T_bc3cd_row1_col14, #T_bc3cd_row2_col2, #T_bc3cd_row2_col3, #T_bc3cd_row2_col4, #T_bc3cd_row2_col9, #T_bc3cd_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc3cd_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc3cd_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc3cd_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc3cd_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc3cd_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc3cd_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bc3cd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bc3cd_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_bc3cd_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_bc3cd_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_bc3cd_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_bc3cd_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_bc3cd_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_bc3cd_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_bc3cd_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_bc3cd_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_bc3cd_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_bc3cd_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_bc3cd_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_bc3cd_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_bc3cd_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_bc3cd_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bc3cd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bc3cd_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=20000:ep=4</td>\n",
       "      <td id=\"T_bc3cd_row0_col1\" class=\"data row0 col1\" >20000</td>\n",
       "      <td id=\"T_bc3cd_row0_col2\" class=\"data row0 col2\" >34.0</td>\n",
       "      <td id=\"T_bc3cd_row0_col3\" class=\"data row0 col3\" >36.8</td>\n",
       "      <td id=\"T_bc3cd_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_bc3cd_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_bc3cd_row0_col6\" class=\"data row0 col6\" >33.1</td>\n",
       "      <td id=\"T_bc3cd_row0_col7\" class=\"data row0 col7\" >34.9</td>\n",
       "      <td id=\"T_bc3cd_row0_col8\" class=\"data row0 col8\" >10.4</td>\n",
       "      <td id=\"T_bc3cd_row0_col9\" class=\"data row0 col9\" >43.2</td>\n",
       "      <td id=\"T_bc3cd_row0_col10\" class=\"data row0 col10\" >10.8</td>\n",
       "      <td id=\"T_bc3cd_row0_col11\" class=\"data row0 col11\" >20.1</td>\n",
       "      <td id=\"T_bc3cd_row0_col12\" class=\"data row0 col12\" >562.2</td>\n",
       "      <td id=\"T_bc3cd_row0_col13\" class=\"data row0 col13\" >24.2</td>\n",
       "      <td id=\"T_bc3cd_row0_col14\" class=\"data row0 col14\" >-12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bc3cd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bc3cd_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_score=random:s=0_pace=prune:size=20000:ep=4</td>\n",
       "      <td id=\"T_bc3cd_row1_col1\" class=\"data row1 col1\" >20000</td>\n",
       "      <td id=\"T_bc3cd_row1_col2\" class=\"data row1 col2\" >34.6</td>\n",
       "      <td id=\"T_bc3cd_row1_col3\" class=\"data row1 col3\" >36.9</td>\n",
       "      <td id=\"T_bc3cd_row1_col4\" class=\"data row1 col4\" >6.4</td>\n",
       "      <td id=\"T_bc3cd_row1_col5\" class=\"data row1 col5\" >9.6</td>\n",
       "      <td id=\"T_bc3cd_row1_col6\" class=\"data row1 col6\" >32.4</td>\n",
       "      <td id=\"T_bc3cd_row1_col7\" class=\"data row1 col7\" >32.9</td>\n",
       "      <td id=\"T_bc3cd_row1_col8\" class=\"data row1 col8\" >10.7</td>\n",
       "      <td id=\"T_bc3cd_row1_col9\" class=\"data row1 col9\" >43.9</td>\n",
       "      <td id=\"T_bc3cd_row1_col10\" class=\"data row1 col10\" >10.8</td>\n",
       "      <td id=\"T_bc3cd_row1_col11\" class=\"data row1 col11\" >17.5</td>\n",
       "      <td id=\"T_bc3cd_row1_col12\" class=\"data row1 col12\" >454.3</td>\n",
       "      <td id=\"T_bc3cd_row1_col13\" class=\"data row1 col13\" >23.6</td>\n",
       "      <td id=\"T_bc3cd_row1_col14\" class=\"data row1 col14\" >-15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bc3cd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bc3cd_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=20000:ep=4</td>\n",
       "      <td id=\"T_bc3cd_row2_col1\" class=\"data row2 col1\" >20000</td>\n",
       "      <td id=\"T_bc3cd_row2_col2\" class=\"data row2 col2\" >33.7</td>\n",
       "      <td id=\"T_bc3cd_row2_col3\" class=\"data row2 col3\" >36.2</td>\n",
       "      <td id=\"T_bc3cd_row2_col4\" class=\"data row2 col4\" >6.2</td>\n",
       "      <td id=\"T_bc3cd_row2_col5\" class=\"data row2 col5\" >12.2</td>\n",
       "      <td id=\"T_bc3cd_row2_col6\" class=\"data row2 col6\" >33.7</td>\n",
       "      <td id=\"T_bc3cd_row2_col7\" class=\"data row2 col7\" >33.6</td>\n",
       "      <td id=\"T_bc3cd_row2_col8\" class=\"data row2 col8\" >10.4</td>\n",
       "      <td id=\"T_bc3cd_row2_col9\" class=\"data row2 col9\" >39.4</td>\n",
       "      <td id=\"T_bc3cd_row2_col10\" class=\"data row2 col10\" >11.4</td>\n",
       "      <td id=\"T_bc3cd_row2_col11\" class=\"data row2 col11\" >18.7</td>\n",
       "      <td id=\"T_bc3cd_row2_col12\" class=\"data row2 col12\" >684.6</td>\n",
       "      <td id=\"T_bc3cd_row2_col13\" class=\"data row2 col13\" >23.6</td>\n",
       "      <td id=\"T_bc3cd_row2_col14\" class=\"data row2 col14\" >-14.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14ffa87aa500>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3128142/1984785548.py:366: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3128142/1984785548.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_045fb td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_045fb_row0_col0, #T_045fb_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_045fb_row0_col1, #T_045fb_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_045fb_row0_col2, #T_045fb_row0_col3, #T_045fb_row0_col6, #T_045fb_row0_col7, #T_045fb_row0_col8, #T_045fb_row0_col9, #T_045fb_row0_col10, #T_045fb_row1_col3, #T_045fb_row1_col4, #T_045fb_row1_col5, #T_045fb_row1_col6, #T_045fb_row1_col11, #T_045fb_row1_col12, #T_045fb_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_045fb_row0_col4, #T_045fb_row0_col5, #T_045fb_row0_col11, #T_045fb_row0_col12, #T_045fb_row0_col13, #T_045fb_row1_col2, #T_045fb_row1_col7, #T_045fb_row1_col8, #T_045fb_row1_col9, #T_045fb_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_045fb_row0_col14, #T_045fb_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_045fb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_045fb_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_045fb_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_045fb_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_045fb_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_045fb_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_045fb_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_045fb_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_045fb_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_045fb_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_045fb_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_045fb_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_045fb_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_045fb_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_045fb_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_045fb_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_045fb_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_045fb_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=20000:ep=4</td>\n",
       "      <td id=\"T_045fb_row0_col1\" class=\"data row0 col1\" >20000</td>\n",
       "      <td id=\"T_045fb_row0_col2\" class=\"data row0 col2\" >33.6</td>\n",
       "      <td id=\"T_045fb_row0_col3\" class=\"data row0 col3\" >35.6</td>\n",
       "      <td id=\"T_045fb_row0_col4\" class=\"data row0 col4\" >6.8</td>\n",
       "      <td id=\"T_045fb_row0_col5\" class=\"data row0 col5\" >14.2</td>\n",
       "      <td id=\"T_045fb_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_045fb_row0_col7\" class=\"data row0 col7\" >32.8</td>\n",
       "      <td id=\"T_045fb_row0_col8\" class=\"data row0 col8\" >10.1</td>\n",
       "      <td id=\"T_045fb_row0_col9\" class=\"data row0 col9\" >40.0</td>\n",
       "      <td id=\"T_045fb_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_045fb_row0_col11\" class=\"data row0 col11\" >12.6</td>\n",
       "      <td id=\"T_045fb_row0_col12\" class=\"data row0 col12\" >446.7</td>\n",
       "      <td id=\"T_045fb_row0_col13\" class=\"data row0 col13\" >21.9</td>\n",
       "      <td id=\"T_045fb_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_045fb_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_045fb_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=20000:ep=4</td>\n",
       "      <td id=\"T_045fb_row1_col1\" class=\"data row1 col1\" >20000</td>\n",
       "      <td id=\"T_045fb_row1_col2\" class=\"data row1 col2\" >35.6</td>\n",
       "      <td id=\"T_045fb_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_045fb_row1_col4\" class=\"data row1 col4\" >6.4</td>\n",
       "      <td id=\"T_045fb_row1_col5\" class=\"data row1 col5\" >13.6</td>\n",
       "      <td id=\"T_045fb_row1_col6\" class=\"data row1 col6\" >32.1</td>\n",
       "      <td id=\"T_045fb_row1_col7\" class=\"data row1 col7\" >33.1</td>\n",
       "      <td id=\"T_045fb_row1_col8\" class=\"data row1 col8\" >11.1</td>\n",
       "      <td id=\"T_045fb_row1_col9\" class=\"data row1 col9\" >41.4</td>\n",
       "      <td id=\"T_045fb_row1_col10\" class=\"data row1 col10\" >12.0</td>\n",
       "      <td id=\"T_045fb_row1_col11\" class=\"data row1 col11\" >8.5</td>\n",
       "      <td id=\"T_045fb_row1_col12\" class=\"data row1 col12\" >187.9</td>\n",
       "      <td id=\"T_045fb_row1_col13\" class=\"data row1 col13\" >21.5</td>\n",
       "      <td id=\"T_045fb_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14ffa87aa770>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3128142/1984785548.py:366: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3128142/1984785548.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a04a4 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_a04a4_row0_col0, #T_a04a4_row1_col0, #T_a04a4_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a04a4_row0_col1, #T_a04a4_row1_col1, #T_a04a4_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a04a4_row0_col2, #T_a04a4_row0_col3, #T_a04a4_row0_col5, #T_a04a4_row0_col6, #T_a04a4_row0_col8, #T_a04a4_row0_col11, #T_a04a4_row0_col12, #T_a04a4_row0_col13, #T_a04a4_row0_col14, #T_a04a4_row1_col4, #T_a04a4_row1_col7, #T_a04a4_row2_col9, #T_a04a4_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a04a4_row0_col4, #T_a04a4_row0_col10, #T_a04a4_row1_col2, #T_a04a4_row1_col3, #T_a04a4_row1_col6, #T_a04a4_row1_col9, #T_a04a4_row1_col14, #T_a04a4_row2_col5, #T_a04a4_row2_col7, #T_a04a4_row2_col8, #T_a04a4_row2_col11, #T_a04a4_row2_col12, #T_a04a4_row2_col13, #T_a04a4_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a04a4_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a04a4_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a04a4_row1_col5, #T_a04a4_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a04a4_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a04a4_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a04a4_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a04a4_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a04a4_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a04a4_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a04a4_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a04a4_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a04a4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a04a4_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_a04a4_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_a04a4_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_a04a4_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_a04a4_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_a04a4_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_a04a4_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_a04a4_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_a04a4_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_a04a4_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_a04a4_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_a04a4_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_a04a4_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_a04a4_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_a04a4_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a04a4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a04a4_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=20000:ep=4</td>\n",
       "      <td id=\"T_a04a4_row0_col1\" class=\"data row0 col1\" >20000</td>\n",
       "      <td id=\"T_a04a4_row0_col2\" class=\"data row0 col2\" >34.0</td>\n",
       "      <td id=\"T_a04a4_row0_col3\" class=\"data row0 col3\" >37.0</td>\n",
       "      <td id=\"T_a04a4_row0_col4\" class=\"data row0 col4\" >5.0</td>\n",
       "      <td id=\"T_a04a4_row0_col5\" class=\"data row0 col5\" >11.6</td>\n",
       "      <td id=\"T_a04a4_row0_col6\" class=\"data row0 col6\" >32.8</td>\n",
       "      <td id=\"T_a04a4_row0_col7\" class=\"data row0 col7\" >33.6</td>\n",
       "      <td id=\"T_a04a4_row0_col8\" class=\"data row0 col8\" >10.8</td>\n",
       "      <td id=\"T_a04a4_row0_col9\" class=\"data row0 col9\" >39.4</td>\n",
       "      <td id=\"T_a04a4_row0_col10\" class=\"data row0 col10\" >10.6</td>\n",
       "      <td id=\"T_a04a4_row0_col11\" class=\"data row0 col11\" >36.7</td>\n",
       "      <td id=\"T_a04a4_row0_col12\" class=\"data row0 col12\" >314.2</td>\n",
       "      <td id=\"T_a04a4_row0_col13\" class=\"data row0 col13\" >25.1</td>\n",
       "      <td id=\"T_a04a4_row0_col14\" class=\"data row0 col14\" >-15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a04a4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a04a4_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=20000:ep=4</td>\n",
       "      <td id=\"T_a04a4_row1_col1\" class=\"data row1 col1\" >20000</td>\n",
       "      <td id=\"T_a04a4_row1_col2\" class=\"data row1 col2\" >32.2</td>\n",
       "      <td id=\"T_a04a4_row1_col3\" class=\"data row1 col3\" >35.8</td>\n",
       "      <td id=\"T_a04a4_row1_col4\" class=\"data row1 col4\" >6.0</td>\n",
       "      <td id=\"T_a04a4_row1_col5\" class=\"data row1 col5\" >11.4</td>\n",
       "      <td id=\"T_a04a4_row1_col6\" class=\"data row1 col6\" >31.7</td>\n",
       "      <td id=\"T_a04a4_row1_col7\" class=\"data row1 col7\" >33.7</td>\n",
       "      <td id=\"T_a04a4_row1_col8\" class=\"data row1 col8\" >10.3</td>\n",
       "      <td id=\"T_a04a4_row1_col9\" class=\"data row1 col9\" >38.8</td>\n",
       "      <td id=\"T_a04a4_row1_col10\" class=\"data row1 col10\" >11.4</td>\n",
       "      <td id=\"T_a04a4_row1_col11\" class=\"data row1 col11\" >35.0</td>\n",
       "      <td id=\"T_a04a4_row1_col12\" class=\"data row1 col12\" >304.9</td>\n",
       "      <td id=\"T_a04a4_row1_col13\" class=\"data row1 col13\" >24.6</td>\n",
       "      <td id=\"T_a04a4_row1_col14\" class=\"data row1 col14\" >-20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a04a4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a04a4_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=20000:ep=4</td>\n",
       "      <td id=\"T_a04a4_row2_col1\" class=\"data row2 col1\" >20000</td>\n",
       "      <td id=\"T_a04a4_row2_col2\" class=\"data row2 col2\" >32.7</td>\n",
       "      <td id=\"T_a04a4_row2_col3\" class=\"data row2 col3\" >35.8</td>\n",
       "      <td id=\"T_a04a4_row2_col4\" class=\"data row2 col4\" >5.6</td>\n",
       "      <td id=\"T_a04a4_row2_col5\" class=\"data row2 col5\" >11.0</td>\n",
       "      <td id=\"T_a04a4_row2_col6\" class=\"data row2 col6\" >32.2</td>\n",
       "      <td id=\"T_a04a4_row2_col7\" class=\"data row2 col7\" >31.8</td>\n",
       "      <td id=\"T_a04a4_row2_col8\" class=\"data row2 col8\" >10.3</td>\n",
       "      <td id=\"T_a04a4_row2_col9\" class=\"data row2 col9\" >40.7</td>\n",
       "      <td id=\"T_a04a4_row2_col10\" class=\"data row2 col10\" >13.8</td>\n",
       "      <td id=\"T_a04a4_row2_col11\" class=\"data row2 col11\" >31.5</td>\n",
       "      <td id=\"T_a04a4_row2_col12\" class=\"data row2 col12\" >286.6</td>\n",
       "      <td id=\"T_a04a4_row2_col13\" class=\"data row2 col13\" >24.5</td>\n",
       "      <td id=\"T_a04a4_row2_col14\" class=\"data row2 col14\" >-20.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14ffa87a8670>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3128142/1984785548.py:366: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3128142/1984785548.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_170e9 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_170e9_row0_col0, #T_170e9_row1_col0, #T_170e9_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_170e9_row0_col1, #T_170e9_row1_col1, #T_170e9_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_170e9_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_170e9_row0_col3, #T_170e9_row0_col6, #T_170e9_row0_col8, #T_170e9_row1_col4, #T_170e9_row1_col5, #T_170e9_row1_col9, #T_170e9_row1_col12, #T_170e9_row2_col2, #T_170e9_row2_col7, #T_170e9_row2_col10, #T_170e9_row2_col11, #T_170e9_row2_col13, #T_170e9_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_170e9_row0_col4, #T_170e9_row0_col10, #T_170e9_row0_col13, #T_170e9_row0_col14, #T_170e9_row1_col2, #T_170e9_row1_col3, #T_170e9_row1_col6, #T_170e9_row1_col7, #T_170e9_row1_col11, #T_170e9_row2_col4, #T_170e9_row2_col5, #T_170e9_row2_col8, #T_170e9_row2_col9, #T_170e9_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_170e9_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_170e9_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_170e9_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_170e9_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_170e9_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_170e9_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_170e9_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_170e9_row1_col13, #T_170e9_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_170e9_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_170e9_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_170e9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_170e9_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_170e9_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_170e9_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_170e9_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_170e9_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_170e9_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_170e9_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_170e9_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_170e9_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_170e9_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_170e9_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_170e9_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_170e9_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_170e9_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_170e9_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_170e9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_170e9_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlmv2_score=random:s=0_pace=prune:size=20000:ep=4</td>\n",
       "      <td id=\"T_170e9_row0_col1\" class=\"data row0 col1\" >20000</td>\n",
       "      <td id=\"T_170e9_row0_col2\" class=\"data row0 col2\" >34.2</td>\n",
       "      <td id=\"T_170e9_row0_col3\" class=\"data row0 col3\" >35.4</td>\n",
       "      <td id=\"T_170e9_row0_col4\" class=\"data row0 col4\" >6.0</td>\n",
       "      <td id=\"T_170e9_row0_col5\" class=\"data row0 col5\" >12.8</td>\n",
       "      <td id=\"T_170e9_row0_col6\" class=\"data row0 col6\" >32.6</td>\n",
       "      <td id=\"T_170e9_row0_col7\" class=\"data row0 col7\" >34.5</td>\n",
       "      <td id=\"T_170e9_row0_col8\" class=\"data row0 col8\" >10.2</td>\n",
       "      <td id=\"T_170e9_row0_col9\" class=\"data row0 col9\" >37.3</td>\n",
       "      <td id=\"T_170e9_row0_col10\" class=\"data row0 col10\" >14.2</td>\n",
       "      <td id=\"T_170e9_row0_col11\" class=\"data row0 col11\" >40.1</td>\n",
       "      <td id=\"T_170e9_row0_col12\" class=\"data row0 col12\" >478.8</td>\n",
       "      <td id=\"T_170e9_row0_col13\" class=\"data row0 col13\" >25.7</td>\n",
       "      <td id=\"T_170e9_row0_col14\" class=\"data row0 col14\" >-13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_170e9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_170e9_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlmv2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=20000:ep=4</td>\n",
       "      <td id=\"T_170e9_row1_col1\" class=\"data row1 col1\" >20000</td>\n",
       "      <td id=\"T_170e9_row1_col2\" class=\"data row1 col2\" >34.3</td>\n",
       "      <td id=\"T_170e9_row1_col3\" class=\"data row1 col3\" >36.0</td>\n",
       "      <td id=\"T_170e9_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_170e9_row1_col5\" class=\"data row1 col5\" >12.2</td>\n",
       "      <td id=\"T_170e9_row1_col6\" class=\"data row1 col6\" >33.4</td>\n",
       "      <td id=\"T_170e9_row1_col7\" class=\"data row1 col7\" >35.4</td>\n",
       "      <td id=\"T_170e9_row1_col8\" class=\"data row1 col8\" >10.3</td>\n",
       "      <td id=\"T_170e9_row1_col9\" class=\"data row1 col9\" >36.0</td>\n",
       "      <td id=\"T_170e9_row1_col10\" class=\"data row1 col10\" >10.6</td>\n",
       "      <td id=\"T_170e9_row1_col11\" class=\"data row1 col11\" >40.5</td>\n",
       "      <td id=\"T_170e9_row1_col12\" class=\"data row1 col12\" >407.0</td>\n",
       "      <td id=\"T_170e9_row1_col13\" class=\"data row1 col13\" >25.4</td>\n",
       "      <td id=\"T_170e9_row1_col14\" class=\"data row1 col14\" >-15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_170e9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_170e9_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlmv2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=20000:ep=4</td>\n",
       "      <td id=\"T_170e9_row2_col1\" class=\"data row2 col1\" >20000</td>\n",
       "      <td id=\"T_170e9_row2_col2\" class=\"data row2 col2\" >33.5</td>\n",
       "      <td id=\"T_170e9_row2_col3\" class=\"data row2 col3\" >35.7</td>\n",
       "      <td id=\"T_170e9_row2_col4\" class=\"data row2 col4\" >6.0</td>\n",
       "      <td id=\"T_170e9_row2_col5\" class=\"data row2 col5\" >13.4</td>\n",
       "      <td id=\"T_170e9_row2_col6\" class=\"data row2 col6\" >33.0</td>\n",
       "      <td id=\"T_170e9_row2_col7\" class=\"data row2 col7\" >33.4</td>\n",
       "      <td id=\"T_170e9_row2_col8\" class=\"data row2 col8\" >10.5</td>\n",
       "      <td id=\"T_170e9_row2_col9\" class=\"data row2 col9\" >37.4</td>\n",
       "      <td id=\"T_170e9_row2_col10\" class=\"data row2 col10\" >9.1</td>\n",
       "      <td id=\"T_170e9_row2_col11\" class=\"data row2 col11\" >38.2</td>\n",
       "      <td id=\"T_170e9_row2_col12\" class=\"data row2 col12\" >561.4</td>\n",
       "      <td id=\"T_170e9_row2_col13\" class=\"data row2 col13\" >25.0</td>\n",
       "      <td id=\"T_170e9_row2_col14\" class=\"data row2 col14\" >-16.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14ffa87a8f70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3128142/1984785548.py:366: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3128142/1984785548.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e54a8 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_e54a8_row0_col0, #T_e54a8_row1_col0, #T_e54a8_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e54a8_row0_col1, #T_e54a8_row1_col1, #T_e54a8_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e54a8_row0_col2, #T_e54a8_row0_col4, #T_e54a8_row0_col5, #T_e54a8_row0_col6, #T_e54a8_row0_col7, #T_e54a8_row0_col9, #T_e54a8_row0_col10, #T_e54a8_row0_col13, #T_e54a8_row0_col14, #T_e54a8_row1_col3, #T_e54a8_row1_col11, #T_e54a8_row1_col12, #T_e54a8_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e54a8_row0_col3, #T_e54a8_row0_col11, #T_e54a8_row0_col12, #T_e54a8_row1_col2, #T_e54a8_row1_col4, #T_e54a8_row1_col5, #T_e54a8_row1_col7, #T_e54a8_row1_col8, #T_e54a8_row1_col9, #T_e54a8_row1_col10, #T_e54a8_row1_col14, #T_e54a8_row2_col6, #T_e54a8_row2_col7, #T_e54a8_row2_col10, #T_e54a8_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e54a8_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e54a8_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e54a8_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e54a8_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e54a8_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e54a8_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e54a8_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e54a8_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e54a8_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e54a8_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e54a8_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e54a8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e54a8_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_e54a8_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_e54a8_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_e54a8_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_e54a8_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_e54a8_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_e54a8_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_e54a8_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_e54a8_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_e54a8_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_e54a8_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_e54a8_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_e54a8_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_e54a8_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_e54a8_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e54a8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e54a8_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_e54a8_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_e54a8_row0_col2\" class=\"data row0 col2\" >34.7</td>\n",
       "      <td id=\"T_e54a8_row0_col3\" class=\"data row0 col3\" >36.6</td>\n",
       "      <td id=\"T_e54a8_row0_col4\" class=\"data row0 col4\" >7.6</td>\n",
       "      <td id=\"T_e54a8_row0_col5\" class=\"data row0 col5\" >12.6</td>\n",
       "      <td id=\"T_e54a8_row0_col6\" class=\"data row0 col6\" >33.5</td>\n",
       "      <td id=\"T_e54a8_row0_col7\" class=\"data row0 col7\" >35.0</td>\n",
       "      <td id=\"T_e54a8_row0_col8\" class=\"data row0 col8\" >10.5</td>\n",
       "      <td id=\"T_e54a8_row0_col9\" class=\"data row0 col9\" >44.6</td>\n",
       "      <td id=\"T_e54a8_row0_col10\" class=\"data row0 col10\" >11.0</td>\n",
       "      <td id=\"T_e54a8_row0_col11\" class=\"data row0 col11\" >15.8</td>\n",
       "      <td id=\"T_e54a8_row0_col12\" class=\"data row0 col12\" >478.5</td>\n",
       "      <td id=\"T_e54a8_row0_col13\" class=\"data row0 col13\" >24.2</td>\n",
       "      <td id=\"T_e54a8_row0_col14\" class=\"data row0 col14\" >-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e54a8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e54a8_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_e54a8_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_e54a8_row1_col2\" class=\"data row1 col2\" >34.0</td>\n",
       "      <td id=\"T_e54a8_row1_col3\" class=\"data row1 col3\" >37.1</td>\n",
       "      <td id=\"T_e54a8_row1_col4\" class=\"data row1 col4\" >6.2</td>\n",
       "      <td id=\"T_e54a8_row1_col5\" class=\"data row1 col5\" >11.6</td>\n",
       "      <td id=\"T_e54a8_row1_col6\" class=\"data row1 col6\" >33.4</td>\n",
       "      <td id=\"T_e54a8_row1_col7\" class=\"data row1 col7\" >34.7</td>\n",
       "      <td id=\"T_e54a8_row1_col8\" class=\"data row1 col8\" >9.9</td>\n",
       "      <td id=\"T_e54a8_row1_col9\" class=\"data row1 col9\" >42.3</td>\n",
       "      <td id=\"T_e54a8_row1_col10\" class=\"data row1 col10\" >10.8</td>\n",
       "      <td id=\"T_e54a8_row1_col11\" class=\"data row1 col11\" >19.8</td>\n",
       "      <td id=\"T_e54a8_row1_col12\" class=\"data row1 col12\" >565.9</td>\n",
       "      <td id=\"T_e54a8_row1_col13\" class=\"data row1 col13\" >24.0</td>\n",
       "      <td id=\"T_e54a8_row1_col14\" class=\"data row1 col14\" >-14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e54a8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e54a8_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_e54a8_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_e54a8_row2_col2\" class=\"data row2 col2\" >34.1</td>\n",
       "      <td id=\"T_e54a8_row2_col3\" class=\"data row2 col3\" >36.8</td>\n",
       "      <td id=\"T_e54a8_row2_col4\" class=\"data row2 col4\" >6.6</td>\n",
       "      <td id=\"T_e54a8_row2_col5\" class=\"data row2 col5\" >11.8</td>\n",
       "      <td id=\"T_e54a8_row2_col6\" class=\"data row2 col6\" >32.2</td>\n",
       "      <td id=\"T_e54a8_row2_col7\" class=\"data row2 col7\" >34.7</td>\n",
       "      <td id=\"T_e54a8_row2_col8\" class=\"data row2 col8\" >10.7</td>\n",
       "      <td id=\"T_e54a8_row2_col9\" class=\"data row2 col9\" >43.1</td>\n",
       "      <td id=\"T_e54a8_row2_col10\" class=\"data row2 col10\" >10.8</td>\n",
       "      <td id=\"T_e54a8_row2_col11\" class=\"data row2 col11\" >17.4</td>\n",
       "      <td id=\"T_e54a8_row2_col12\" class=\"data row2 col12\" >535.2</td>\n",
       "      <td id=\"T_e54a8_row2_col13\" class=\"data row2 col13\" >23.8</td>\n",
       "      <td id=\"T_e54a8_row2_col14\" class=\"data row2 col14\" >-12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14ffa87aabf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3128142/1984785548.py:366: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3128142/1984785548.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fa742 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_fa742_row0_col0, #T_fa742_row1_col0, #T_fa742_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fa742_row0_col1, #T_fa742_row1_col1, #T_fa742_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fa742_row0_col2, #T_fa742_row0_col3, #T_fa742_row0_col10, #T_fa742_row0_col13, #T_fa742_row1_col4, #T_fa742_row1_col5, #T_fa742_row1_col6, #T_fa742_row1_col11, #T_fa742_row1_col12, #T_fa742_row1_col14, #T_fa742_row2_col7, #T_fa742_row2_col8, #T_fa742_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa742_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa742_row0_col5, #T_fa742_row0_col6, #T_fa742_row0_col7, #T_fa742_row0_col14, #T_fa742_row1_col2, #T_fa742_row1_col3, #T_fa742_row1_col8, #T_fa742_row1_col9, #T_fa742_row2_col4, #T_fa742_row2_col10, #T_fa742_row2_col11, #T_fa742_row2_col12, #T_fa742_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa742_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa742_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa742_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa742_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa742_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa742_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa742_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa742_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa742_row2_col3, #T_fa742_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa742_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa742_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fa742\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fa742_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_fa742_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_fa742_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_fa742_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_fa742_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_fa742_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_fa742_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_fa742_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_fa742_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_fa742_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_fa742_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_fa742_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_fa742_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_fa742_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_fa742_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fa742_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fa742_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_fa742_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_fa742_row0_col2\" class=\"data row0 col2\" >37.6</td>\n",
       "      <td id=\"T_fa742_row0_col3\" class=\"data row0 col3\" >38.7</td>\n",
       "      <td id=\"T_fa742_row0_col4\" class=\"data row0 col4\" >6.2</td>\n",
       "      <td id=\"T_fa742_row0_col5\" class=\"data row0 col5\" >13.6</td>\n",
       "      <td id=\"T_fa742_row0_col6\" class=\"data row0 col6\" >31.3</td>\n",
       "      <td id=\"T_fa742_row0_col7\" class=\"data row0 col7\" >31.6</td>\n",
       "      <td id=\"T_fa742_row0_col8\" class=\"data row0 col8\" >11.1</td>\n",
       "      <td id=\"T_fa742_row0_col9\" class=\"data row0 col9\" >42.7</td>\n",
       "      <td id=\"T_fa742_row0_col10\" class=\"data row0 col10\" >13.0</td>\n",
       "      <td id=\"T_fa742_row0_col11\" class=\"data row0 col11\" >8.9</td>\n",
       "      <td id=\"T_fa742_row0_col12\" class=\"data row0 col12\" >194.7</td>\n",
       "      <td id=\"T_fa742_row0_col13\" class=\"data row0 col13\" >23.5</td>\n",
       "      <td id=\"T_fa742_row0_col14\" class=\"data row0 col14\" >-15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fa742_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fa742_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_fa742_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_fa742_row1_col2\" class=\"data row1 col2\" >33.6</td>\n",
       "      <td id=\"T_fa742_row1_col3\" class=\"data row1 col3\" >34.9</td>\n",
       "      <td id=\"T_fa742_row1_col4\" class=\"data row1 col4\" >6.6</td>\n",
       "      <td id=\"T_fa742_row1_col5\" class=\"data row1 col5\" >14.8</td>\n",
       "      <td id=\"T_fa742_row1_col6\" class=\"data row1 col6\" >35.4</td>\n",
       "      <td id=\"T_fa742_row1_col7\" class=\"data row1 col7\" >31.9</td>\n",
       "      <td id=\"T_fa742_row1_col8\" class=\"data row1 col8\" >10.8</td>\n",
       "      <td id=\"T_fa742_row1_col9\" class=\"data row1 col9\" >40.0</td>\n",
       "      <td id=\"T_fa742_row1_col10\" class=\"data row1 col10\" >12.0</td>\n",
       "      <td id=\"T_fa742_row1_col11\" class=\"data row1 col11\" >11.6</td>\n",
       "      <td id=\"T_fa742_row1_col12\" class=\"data row1 col12\" >498.7</td>\n",
       "      <td id=\"T_fa742_row1_col13\" class=\"data row1 col13\" >23.2</td>\n",
       "      <td id=\"T_fa742_row1_col14\" class=\"data row1 col14\" >-15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fa742_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fa742_row2_col0\" class=\"data row2 col0\" >llama-7b_flan_v2_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_fa742_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_fa742_row2_col2\" class=\"data row2 col2\" >34.7</td>\n",
       "      <td id=\"T_fa742_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_fa742_row2_col4\" class=\"data row2 col4\" >5.8</td>\n",
       "      <td id=\"T_fa742_row2_col5\" class=\"data row2 col5\" >13.8</td>\n",
       "      <td id=\"T_fa742_row2_col6\" class=\"data row2 col6\" >32.0</td>\n",
       "      <td id=\"T_fa742_row2_col7\" class=\"data row2 col7\" >34.1</td>\n",
       "      <td id=\"T_fa742_row2_col8\" class=\"data row2 col8\" >11.7</td>\n",
       "      <td id=\"T_fa742_row2_col9\" class=\"data row2 col9\" >42.9</td>\n",
       "      <td id=\"T_fa742_row2_col10\" class=\"data row2 col10\" >10.4</td>\n",
       "      <td id=\"T_fa742_row2_col11\" class=\"data row2 col11\" >8.8</td>\n",
       "      <td id=\"T_fa742_row2_col12\" class=\"data row2 col12\" >150.5</td>\n",
       "      <td id=\"T_fa742_row2_col13\" class=\"data row2 col13\" >21.6</td>\n",
       "      <td id=\"T_fa742_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14ffa87a8850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3128142/1984785548.py:366: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3128142/1984785548.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a3cac td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_a3cac_row0_col0, #T_a3cac_row1_col0, #T_a3cac_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a3cac_row0_col1, #T_a3cac_row1_col1, #T_a3cac_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a3cac_row0_col2, #T_a3cac_row0_col3, #T_a3cac_row0_col6, #T_a3cac_row0_col8, #T_a3cac_row0_col10, #T_a3cac_row0_col11, #T_a3cac_row0_col12, #T_a3cac_row0_col13, #T_a3cac_row0_col14, #T_a3cac_row1_col4, #T_a3cac_row1_col5, #T_a3cac_row1_col9, #T_a3cac_row2_col4, #T_a3cac_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3cac_row0_col4, #T_a3cac_row0_col7, #T_a3cac_row1_col2, #T_a3cac_row1_col6, #T_a3cac_row1_col7, #T_a3cac_row1_col8, #T_a3cac_row1_col11, #T_a3cac_row1_col12, #T_a3cac_row2_col3, #T_a3cac_row2_col5, #T_a3cac_row2_col9, #T_a3cac_row2_col10, #T_a3cac_row2_col13, #T_a3cac_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3cac_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3cac_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3cac_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3cac_row1_col10, #T_a3cac_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3cac_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3cac_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3cac_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3cac_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3cac_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3cac_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a3cac\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a3cac_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_a3cac_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_a3cac_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_a3cac_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_a3cac_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_a3cac_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_a3cac_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_a3cac_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_a3cac_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_a3cac_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_a3cac_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_a3cac_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_a3cac_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_a3cac_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_a3cac_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a3cac_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a3cac_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_a3cac_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_a3cac_row0_col2\" class=\"data row0 col2\" >33.8</td>\n",
       "      <td id=\"T_a3cac_row0_col3\" class=\"data row0 col3\" >35.7</td>\n",
       "      <td id=\"T_a3cac_row0_col4\" class=\"data row0 col4\" >5.8</td>\n",
       "      <td id=\"T_a3cac_row0_col5\" class=\"data row0 col5\" >10.6</td>\n",
       "      <td id=\"T_a3cac_row0_col6\" class=\"data row0 col6\" >32.5</td>\n",
       "      <td id=\"T_a3cac_row0_col7\" class=\"data row0 col7\" >33.2</td>\n",
       "      <td id=\"T_a3cac_row0_col8\" class=\"data row0 col8\" >10.5</td>\n",
       "      <td id=\"T_a3cac_row0_col9\" class=\"data row0 col9\" >40.1</td>\n",
       "      <td id=\"T_a3cac_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_a3cac_row0_col11\" class=\"data row0 col11\" >36.8</td>\n",
       "      <td id=\"T_a3cac_row0_col12\" class=\"data row0 col12\" >298.9</td>\n",
       "      <td id=\"T_a3cac_row0_col13\" class=\"data row0 col13\" >25.2</td>\n",
       "      <td id=\"T_a3cac_row0_col14\" class=\"data row0 col14\" >-16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3cac_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a3cac_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_a3cac_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_a3cac_row1_col2\" class=\"data row1 col2\" >31.5</td>\n",
       "      <td id=\"T_a3cac_row1_col3\" class=\"data row1 col3\" >35.3</td>\n",
       "      <td id=\"T_a3cac_row1_col4\" class=\"data row1 col4\" >6.4</td>\n",
       "      <td id=\"T_a3cac_row1_col5\" class=\"data row1 col5\" >11.4</td>\n",
       "      <td id=\"T_a3cac_row1_col6\" class=\"data row1 col6\" >32.2</td>\n",
       "      <td id=\"T_a3cac_row1_col7\" class=\"data row1 col7\" >33.2</td>\n",
       "      <td id=\"T_a3cac_row1_col8\" class=\"data row1 col8\" >10.1</td>\n",
       "      <td id=\"T_a3cac_row1_col9\" class=\"data row1 col9\" >40.5</td>\n",
       "      <td id=\"T_a3cac_row1_col10\" class=\"data row1 col10\" >12.8</td>\n",
       "      <td id=\"T_a3cac_row1_col11\" class=\"data row1 col11\" >33.0</td>\n",
       "      <td id=\"T_a3cac_row1_col12\" class=\"data row1 col12\" >264.5</td>\n",
       "      <td id=\"T_a3cac_row1_col13\" class=\"data row1 col13\" >24.6</td>\n",
       "      <td id=\"T_a3cac_row1_col14\" class=\"data row1 col14\" >-19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3cac_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a3cac_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_a3cac_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_a3cac_row2_col2\" class=\"data row2 col2\" >31.7</td>\n",
       "      <td id=\"T_a3cac_row2_col3\" class=\"data row2 col3\" >35.0</td>\n",
       "      <td id=\"T_a3cac_row2_col4\" class=\"data row2 col4\" >6.4</td>\n",
       "      <td id=\"T_a3cac_row2_col5\" class=\"data row2 col5\" >9.2</td>\n",
       "      <td id=\"T_a3cac_row2_col6\" class=\"data row2 col6\" >32.3</td>\n",
       "      <td id=\"T_a3cac_row2_col7\" class=\"data row2 col7\" >33.3</td>\n",
       "      <td id=\"T_a3cac_row2_col8\" class=\"data row2 col8\" >10.4</td>\n",
       "      <td id=\"T_a3cac_row2_col9\" class=\"data row2 col9\" >39.6</td>\n",
       "      <td id=\"T_a3cac_row2_col10\" class=\"data row2 col10\" >12.6</td>\n",
       "      <td id=\"T_a3cac_row2_col11\" class=\"data row2 col11\" >34.9</td>\n",
       "      <td id=\"T_a3cac_row2_col12\" class=\"data row2 col12\" >266.5</td>\n",
       "      <td id=\"T_a3cac_row2_col13\" class=\"data row2 col13\" >24.5</td>\n",
       "      <td id=\"T_a3cac_row2_col14\" class=\"data row2 col14\" >-20.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14ffa87a8fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3128142/1984785548.py:366: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3128142/1984785548.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f3953 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_f3953_row0_col0, #T_f3953_row1_col0, #T_f3953_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f3953_row0_col1, #T_f3953_row1_col1, #T_f3953_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f3953_row0_col2, #T_f3953_row0_col3, #T_f3953_row0_col4, #T_f3953_row0_col5, #T_f3953_row0_col9, #T_f3953_row0_col10, #T_f3953_row0_col11, #T_f3953_row0_col13, #T_f3953_row0_col14, #T_f3953_row1_col6, #T_f3953_row1_col7, #T_f3953_row2_col8, #T_f3953_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f3953_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f3953_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c83836;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f3953_row0_col8, #T_f3953_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f3953_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f3953_row1_col2, #T_f3953_row1_col3, #T_f3953_row1_col4, #T_f3953_row1_col5, #T_f3953_row1_col8, #T_f3953_row1_col12, #T_f3953_row1_col14, #T_f3953_row2_col6, #T_f3953_row2_col7, #T_f3953_row2_col9, #T_f3953_row2_col10, #T_f3953_row2_col11, #T_f3953_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f3953_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f3953_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f3953_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f3953_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f3953_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f3953_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f3953_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f3953_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f3953\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f3953_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_f3953_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_f3953_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_f3953_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_f3953_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_f3953_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_f3953_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_f3953_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_f3953_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_f3953_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_f3953_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_f3953_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_f3953_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_f3953_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_f3953_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f3953_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f3953_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlmv2_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_f3953_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_f3953_row0_col2\" class=\"data row0 col2\" >34.5</td>\n",
       "      <td id=\"T_f3953_row0_col3\" class=\"data row0 col3\" >36.0</td>\n",
       "      <td id=\"T_f3953_row0_col4\" class=\"data row0 col4\" >6.8</td>\n",
       "      <td id=\"T_f3953_row0_col5\" class=\"data row0 col5\" >13.0</td>\n",
       "      <td id=\"T_f3953_row0_col6\" class=\"data row0 col6\" >33.1</td>\n",
       "      <td id=\"T_f3953_row0_col7\" class=\"data row0 col7\" >34.5</td>\n",
       "      <td id=\"T_f3953_row0_col8\" class=\"data row0 col8\" >10.1</td>\n",
       "      <td id=\"T_f3953_row0_col9\" class=\"data row0 col9\" >37.9</td>\n",
       "      <td id=\"T_f3953_row0_col10\" class=\"data row0 col10\" >14.4</td>\n",
       "      <td id=\"T_f3953_row0_col11\" class=\"data row0 col11\" >41.7</td>\n",
       "      <td id=\"T_f3953_row0_col12\" class=\"data row0 col12\" >446.3</td>\n",
       "      <td id=\"T_f3953_row0_col13\" class=\"data row0 col13\" >26.2</td>\n",
       "      <td id=\"T_f3953_row0_col14\" class=\"data row0 col14\" >-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3953_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f3953_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlmv2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_f3953_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_f3953_row1_col2\" class=\"data row1 col2\" >32.4</td>\n",
       "      <td id=\"T_f3953_row1_col3\" class=\"data row1 col3\" >34.6</td>\n",
       "      <td id=\"T_f3953_row1_col4\" class=\"data row1 col4\" >5.0</td>\n",
       "      <td id=\"T_f3953_row1_col5\" class=\"data row1 col5\" >10.8</td>\n",
       "      <td id=\"T_f3953_row1_col6\" class=\"data row1 col6\" >34.2</td>\n",
       "      <td id=\"T_f3953_row1_col7\" class=\"data row1 col7\" >34.6</td>\n",
       "      <td id=\"T_f3953_row1_col8\" class=\"data row1 col8\" >9.9</td>\n",
       "      <td id=\"T_f3953_row1_col9\" class=\"data row1 col9\" >37.1</td>\n",
       "      <td id=\"T_f3953_row1_col10\" class=\"data row1 col10\" >12.4</td>\n",
       "      <td id=\"T_f3953_row1_col11\" class=\"data row1 col11\" >41.1</td>\n",
       "      <td id=\"T_f3953_row1_col12\" class=\"data row1 col12\" >398.3</td>\n",
       "      <td id=\"T_f3953_row1_col13\" class=\"data row1 col13\" >25.2</td>\n",
       "      <td id=\"T_f3953_row1_col14\" class=\"data row1 col14\" >-18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f3953_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f3953_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlmv2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_f3953_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_f3953_row2_col2\" class=\"data row2 col2\" >33.5</td>\n",
       "      <td id=\"T_f3953_row2_col3\" class=\"data row2 col3\" >35.9</td>\n",
       "      <td id=\"T_f3953_row2_col4\" class=\"data row2 col4\" >6.4</td>\n",
       "      <td id=\"T_f3953_row2_col5\" class=\"data row2 col5\" >11.8</td>\n",
       "      <td id=\"T_f3953_row2_col6\" class=\"data row2 col6\" >32.7</td>\n",
       "      <td id=\"T_f3953_row2_col7\" class=\"data row2 col7\" >33.0</td>\n",
       "      <td id=\"T_f3953_row2_col8\" class=\"data row2 col8\" >10.4</td>\n",
       "      <td id=\"T_f3953_row2_col9\" class=\"data row2 col9\" >36.9</td>\n",
       "      <td id=\"T_f3953_row2_col10\" class=\"data row2 col10\" >10.4</td>\n",
       "      <td id=\"T_f3953_row2_col11\" class=\"data row2 col11\" >39.8</td>\n",
       "      <td id=\"T_f3953_row2_col12\" class=\"data row2 col12\" >492.9</td>\n",
       "      <td id=\"T_f3953_row2_col13\" class=\"data row2 col13\" >25.1</td>\n",
       "      <td id=\"T_f3953_row2_col14\" class=\"data row2 col14\" >-17.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14ffa87aaa10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_sort_rows_by_avg_ranking\n",
    "from llm.evaluate import EvalResults, get_eval_results\n",
    "\n",
    "\n",
    "\n",
    "exp_dir = ''\n",
    "chat_fmt = None\n",
    "sort_rows = True\n",
    "use_normalized_preferred_metric = False\n",
    "\n",
    "\n",
    "# ## investigate code change / package update effect on eval baselines.\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# use_normalized_preferred_metric = False\n",
    "# sort_rows = False\n",
    "# save_dirs = [\n",
    "#     # llama\n",
    "#     ('llama-7b_12.13update_before', '../results/baselines/huggyllama/llama-7b_12.13update_before/'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('llama-7b_10.30update', '../results/baselines/huggyllama/llama-7b_10.30update/'),\n",
    "# #     ('llama-7b_09.23update', '../results/baselines/huggyllama/llama-7b_09.23update/'),\n",
    "# #     ('llama-7b_09.23update_before', '../results/baselines/huggyllama/llama-7b_09.23update_before/'),\n",
    "# #     # llama2\n",
    "#     ('llama2-7b_12.13update_before', '../results/baselines/NousResearch/Llama-2-7b-hf_12.13update_before/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('llama2-7b-chat', '../results/baselines/NousResearch/Llama-2-7b-chat-hf/'),\n",
    "# #     ('llama2-7b_10.30update', '../results/baselines/NousResearch/Llama-2-7b-hf_10.30update/'),\n",
    "# #     ('llama2-7b_original', '../results/baselines/NousResearch/Llama-2-7b-hf_original/'),\n",
    "# #     # mistral\n",
    "# #     ('mistral-7b_10.16update', '../results/baselines/mistralai/Mistral-7B-v0.1_10.16update/'),\n",
    "#     ('mistral-7b-Instruct-v0.1_12.13update_before', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1_12.13update_before'),\n",
    "#     ('mistral-7b-Instruct-v0.1', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     # zephyr\n",
    "#     ('zephyr-7b-beta_12.13update_before', '../results/baselines/HuggingFaceH4/zephyr-7b-beta_12.13update_before'),\n",
    "#     ('zephyr-7b-beta', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "\n",
    "# # baselines\n",
    "# save_dirs = []\n",
    "# save_dirs += [\n",
    "# #     ('gpt2', '../results/baselines/gpt2'),\n",
    "# #     ('gpt2m', '../results/baselines/gpt2-medium'),\n",
    "# #     ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "# #     ('llama2-7b+humanmix', '../results/llama2-7b_humanmix'),\n",
    "# #     ('pythia-1.4b', '../results/baselines/EleutherAI/pythia-1.4b'),\n",
    "# #     ('pythia-2.8b', '../results/baselines/EleutherAI/pythia-2.8b'),\n",
    "# #     ('pythia-6.9b', '../results/baselines/EleutherAI/pythia-6.9b'),\n",
    "# #     ('dolly-v2-7b', '../results/baselines/databricks/dolly-v2-7b'),\n",
    "#     ('mistral-7b-v0.1', '../results/baselines/mistralai/Mistral-7B-v0.1'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b+lima_ep=2', '../results/ft1_ep=2/llama-7b_lima/'),\n",
    "# #     ('mistral-7b+lima_ep=2', '../results/ft1_ep=2/mistral-7b_lima/'), \n",
    "# ]\n",
    "# exp_dir = '../results/oi2/'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "\n",
    "# exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# # exp_dir = '../results/ft2'\n",
    "# # exp_dir = '../results/ft1'\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# # save_dirs = [\n",
    "# #     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "# #     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1/'),\n",
    "# # ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'tuluv1m' in x]\n",
    "\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "# # exp_dir = '../results/oi4'\n",
    "# # exp_dir = '../results/oi4_perf_cross_time'\n",
    "# # exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'\n",
    "# exp_dir = '../results/oi4_flan_v2_vary_subsetsize'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi4_flan2022_1m'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #              ('llama-7b_flan_v2_ep=2', '../results/ft1/llama-7b_flan_v2'),\n",
    "# #              ('llama-7b_humanmix_ep=2', '../results/ft1/llama-7b_humanmix'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "# #              ('llama-7b_cot:flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_cot:flanv2'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# # exp_dir = '../results/oi4_tulu_v1_mix'\n",
    "# exp_dir = '../results/oi4_tulu_v1_mix_ep=3'\n",
    "# use_normalized_preferred_metric = False\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# ###### ultrachat\n",
    "# save_dirs = [\n",
    "#     # baselines \n",
    "#     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "#     ('mistral-7b_ultrachat200k_aftersplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k'),\n",
    "#     ('mistral-7b_ultrachat200k_beforesplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k_beforesplitlongconv'),\n",
    "    \n",
    "#     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     ('mistral-7b_sft-alpha', '../results/baselines/HuggingFaceH4/mistral-7b-sft-alpha'),\n",
    "#     ('mistral-7b-sft-beta', '../results/baselines/HuggingFaceH4/mistral-7b-sft-beta'),\n",
    "#     ('mistral-7b-sft-alpha+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-alpha'),\n",
    "#     ('mistral-7b-sft-beta+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "# # exp_dir = '../results/oi5_ultrachat:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_ultrachat200k:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# exp_dir = '../results/oi5_ultrachat15:mistral-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "# dataset = 'stanford_alpaca'\n",
    "# dataset = 'open_orca_slim'\n",
    "# dataset = 'sharegptv2'\n",
    "# dataset = 'ultrachat200kv2'\n",
    "# dataset = 'wizardlm'\n",
    "# dataset = 'wizardlmv2'\n",
    "# dataset = 'tulu_v2'\n",
    "# dataset = 'flan_v2'\n",
    "# dataset = 'oasst1'\n",
    "# dataset = 'dolly'\n",
    "dataset_list = [\n",
    "    'dolly',\n",
    "    'oasst1', \n",
    "    'flan_v2', \n",
    "    'stanford_alpaca', \n",
    "    'wizardlmv2', \n",
    "    'sharegptv2', \n",
    "    'ultrachat200kv2',\n",
    "]; finetune_type = 'sft'\n",
    "# dataset_list = [\n",
    "#     'ultrafeedback',\n",
    "#     'ultrafeedbackfull',\n",
    "# ]; finetune_type = 'pref'\n",
    "\n",
    "## older\n",
    "# dataset = 'tulu_v1_mix'\n",
    "save_dirs = []\n",
    "save_dirs += [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b'),\n",
    "#     ('llama-7b_lima_ep=5', '../results/oi2/llama-7b_lima_ep=5/'),\n",
    "#     ('llama-7b_lima_ep=10', '../results/oi2/llama-7b_lima_ep=10/'),\n",
    "]\n",
    "for dataset in dataset_list:\n",
    "    if dataset == 'tulu_v2':\n",
    "        save_dirs += [('llama-7b_tulu_v2:100k_ep=2', '../results/oi2/llama-7b_tulu_v2:100k_ep=2'),]\n",
    "    elif dataset == 'open_orca_slim':\n",
    "        save_dirs += [('llama-7b_openorcaslim:100k_ep=2', '../results/oi2/llama-7b_openorcaslim:100k_ep=2'),]\n",
    "    elif dataset == 'sharegptv2':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_sharegptv2_ep=2', '../results/oi2/llama-7b_sharegptv2_ep=2'),\n",
    "            ('llama-7b_sharegpt_ep=2', '../results/ft1_ep=2/llama-7b_sharegpt'),]\n",
    "    elif dataset == 'tulu_v1_mix':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "            # oi4_tulu_v1_mix_ep=3 models before transformers update.\n",
    "            # ('llama-7b_tuluv1m:50k_log_prob_decr_<10.16update', '../results/oi4_tulu_v1_mix_ep=3/llama-7b_tuluv1m:50k_log_prob_decr'),\n",
    "        ]\n",
    "    elif dataset == 'ultrafeedback':\n",
    "        exp_dir = f'../results/dpo1/'\n",
    "        save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "    else:\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=2', f'../results/oi2/llama-7b_{dataset}_ep=2'),]\n",
    "    \n",
    "    if finetune_type == 'sft':\n",
    "        exp_dir = f'../results/oi5_{dataset}:llama-7b'\n",
    "    elif finetune_type == 'pref':\n",
    "        exp_dir = f'../results/dpo2_{dataset}:llama-7b+sharegptv2ep2/'\n",
    "    save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'dppmapbd' not in x and 'semdedup' not in x]\n",
    "    \n",
    "    if finetune_type == 'pref':\n",
    "        sft_model_dataset = 'sharegptv2'\n",
    "        save_dirs += [('llama-7b_sharegptv2_ep=2', f'../results/oi2/llama-7b_{sft_model_dataset}_ep=2')]\n",
    "# ## just compare dppmap grad vs. text\n",
    "# save_dirs = [x for x in save_dirs if 'prune:size=10000:ep=10' in x[1] and (\n",
    "#         'random' in x[1] or \n",
    "#         'dppmap' in x[1]\n",
    "#     )\n",
    "# ]\n",
    "#####\n",
    "\n",
    "\n",
    "# ##### code instructions\n",
    "# save_dirs = [\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('codellama-7b', '../results/baselines/codellama/CodeLlama-7b-hf/'),\n",
    "#     ('codellama-7b-instruct', '../results/baselines/codellama/CodeLlama-7b-Python-hf/'),\n",
    "#     ('codellama-7b-python', '../results/baselines/codellama/CodeLlama-7b-Instruct-hf/'),\n",
    "# ]\n",
    "\n",
    "# exp_dir = '../results/oi2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'starcoder' in x]\n",
    "# exp_dir = '../results/oi6_starcoder_ep=5'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstr:codellama-7b'\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstrv2:codellama-7b'\n",
    "# exp_dir = '../results/oi5_starcoder_commentinstrv5:codellama-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "###### \n",
    "\n",
    "from llm.evaluate import detect_oom_evals\n",
    "oom_eval_paths = detect_oom_evals([x for l in [glob.glob(os.path.join(x[1], 'eval/*/*.out')) for x in save_dirs] for x in l])\n",
    "if oom_eval_paths: print(oom_eval_paths)\n",
    "    \n",
    "cols_avg_blacklist = ['AlpacaFarm/Len']\n",
    "\n",
    "# chat_fmt = False\n",
    "chat_fmt = True\n",
    "# chat_fmt = 'both'\n",
    "# chat_fmt = 'auto' # base model no chatfmt, tuned model with chatfmt\n",
    "chat_fmt = 'mix'  # non-alpacaeval no chatfmt, alpacaeval chatfmt\n",
    "ft_args_fields = {\n",
    "    'run_name': ('run_name',),\n",
    "    'model_name_or_path': ('model_args.model_name_or_path', 'model_name_or_path'),\n",
    "    'subsample_mixture': ('data_args.subsample_mixture',),\n",
    "    'max_train_samples': ('data_args.max_train_samples', 'max_train_samples'),\n",
    "    'train_file': ('data_args.train_file', 'train_file'),\n",
    "}\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "#     cols = ['MMLU/0-shot', 'GSM/Direct', 'BBH/Direct', 'TydiQA/CB', 'Codex-Eval/Pass@1']\n",
    "\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR']\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT']\n",
    "\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR']\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR']\n",
    "# cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1'] #  'ToxiGen/Acc'\n",
    "cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR*', 'AlpacaFarm/Len'] \n",
    "# cols = ['AlpacaFarm/WR', 'AlpacaFarm/ΔWR', 'AlpacaFarm/Len']\n",
    "# cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR*'] \n",
    "# cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR', 'AlpacaFarm/ΔWR', 'AlpacaFarm/Len'] \n",
    "\n",
    "\n",
    "# cols = [f'BBH {x}' for x in ['reasoning', 'nlu', 'knowledge', 'multilingual']]; cols = [x+'/Direct' for x in cols] + [x+'/CoT' for x in cols]\n",
    "# cols = [f'MMLU {x}' for x in ['STEM', 'humanities', 'social sciences', 'other']]; cols = [x+'/0-shot' for x in cols] + [x+'/5-shot' for x in cols]\n",
    "\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR', 'AlpacaFarm/Rep', 'AlpacaFarm/WR*'] #  'ToxiGen/Acc'\n",
    "#     cols = ['AlpacaFarm/WR', 'AlpacaFarm/Rep', 'AlpacaFarm/WR*']\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR'] #  entire, without tydiqa, which has high variance\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', ] #  entire, without tydiqa, which has high variance\n",
    "if 'open_orca_slim' in exp_dir:\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'BBH/Direct', 'BBH/CoT']\n",
    "    cols = ['MMLU/0-shot', 'BBH/Direct']\n",
    "if 'starcoder' in exp_dir:\n",
    "    cols = ['Codex-Eval/Pass@1']\n",
    "    chat_fmt = 'both'\n",
    "print(f'chat_fmt={chat_fmt}')\n",
    "df = get_eval_results(save_dirs, chat_fmt=chat_fmt, ft_args_fields=ft_args_fields, use_normalized_preferred_metric=use_normalized_preferred_metric)\n",
    "\n",
    "cols = [x for x in cols if x in df.columns]\n",
    "df = df[list(ft_args_fields.keys()) + cols]\n",
    "if chat_fmt == 'both':\n",
    "    for col_lvl2 in ['', 'chatfmt']:\n",
    "        df[('Average', col_lvl2)] = df[list(set(df.columns) & set([(x, col_lvl2) for x in list(set(cols)-set(cols_avg_blacklist))]))].mean(axis=1)\n",
    "else:\n",
    "    df['Average'] = df[list(set(cols)-set(cols_avg_blacklist))].mean(axis=1)\n",
    "if sort_rows:\n",
    "    df = pd_sort_rows_by_avg_ranking(df); df['ranking'] = -df['ranking']\n",
    "    sort_value_col, sort_value_col_ascending = ('Average', 'chatfmt') if chat_fmt=='both' else 'Average', False\n",
    "#     sort_value_col, sort_value_col_ascending = 'ranking', False\n",
    "    df = df.sort_values(by=sort_value_col, ascending=sort_value_col_ascending)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def compute_total_train_samples(x):\n",
    "    match = re.search(r'size=(\\d+)', x['run_name' if chat_fmt!='both' else ('run_name', '')])\n",
    "    total_train_samples = match.group(1) if match else None\n",
    "    return total_train_samples\n",
    "df.insert(1, 'total_train_samples' if chat_fmt!='both' else ('total_train_samples', ''), df.apply(compute_total_train_samples, axis=1))\n",
    "def extract_dataset_from_train_file(x):\n",
    "    if x is None: return None\n",
    "    x = x.split('/')[-1].split('.jsonl')[0]\n",
    "    if x.endswith('_data'): x = x[:-5]\n",
    "    if x.endswith('_train'): x = x[:-6]\n",
    "    return x\n",
    "df.insert(1, 'dataset' if chat_fmt!='both' else ('dataset', ''), df['train_file'].apply(extract_dataset_from_train_file))\n",
    "df = df.drop('train_file', axis=1)\n",
    "\n",
    "if any(exp_dir.endswith(x) for x in ['ft2']):\n",
    "#     for model_name_contain in ['gpt2', 'llama', 'pythia-1.4b']:\n",
    "#         for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "    for model_name_contain in ['llama']:\n",
    "        for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "#         for total_train_samples in [200000, 400000, 600000]:\n",
    "            dfc = df.copy()\n",
    "            dfc.insert(0, 'total_train_samples',  dfc['subsample_mixture'].apply(\n",
    "                lambda d: sum(list(d.values())) if d else 200000))\n",
    "            dfc = dfc[dfc['total_train_samples'].apply(\n",
    "                lambda x: total_train_samples-20000<x<total_train_samples+20000)]\n",
    "            dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "                lambda x: model_name_contain in x)]\n",
    "            dfc['total_train_samples'] = dfc['total_train_samples'].astype(str)\n",
    "            dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture'])\n",
    "            dfc = dfc.reset_index(drop=True)\n",
    "            if len(dfc):\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .format(precision=2))\n",
    "else:\n",
    "    for model_name_contain in ['llama', 'pythia-1.4b', 'mistral', 'zephyr']:\n",
    "        dfc = df.copy()\n",
    "        dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "            lambda x: model_name_contain in x.lower())]\n",
    "        if not len(dfc): continue\n",
    "        from rosemary import pd_average_col_contains_substr\n",
    "        Ns = sorted(np.unique([int(x) for x in df['total_train_samples'].to_numpy() if x]).tolist())\n",
    "        datasets = sorted(np.unique([x for x in df['dataset'] if x is not None]).tolist())\n",
    "        for N in Ns+[None]:\n",
    "            for dataset in datasets:\n",
    "                dfc = df.copy()\n",
    "                dfc = dfc[dfc['total_train_samples'].apply(lambda x: int(x) == N if x else True)]\n",
    "                dfc = dfc[dfc['dataset'].apply(lambda x: x == dataset if x else True)]\n",
    "                if not len(dfc): continue\n",
    "                col_runname = 'run_name' if chat_fmt != 'both' else ('run_name', '')\n",
    "                substitute = True\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, '_random_', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=10000:ep=10', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=50000:ep=5', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=3', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=1', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=100000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=200000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=400000', substitute=substitute)\n",
    "                #     dfc = dfc.sort_values(['ranking'], ascending=False)\n",
    "                col = ('Average', 'chatfmt') if chat_fmt == 'both' else 'Average'\n",
    "            #     col = 'AlpacaFarm/WR'\n",
    "            #     col = 'MMLU/0-shot'|\n",
    "            #     col = 'GSM/CoT'\n",
    "            #     col = 'BBH/Direct'\n",
    "            #     col = 'TydiQA/GP'\n",
    "                dfc = dfc.sort_values(by=[col], ascending=False)\n",
    "                dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture', 'max_train_samples', 'dataset'], \n",
    "                               axis=1, level=0 if chat_fmt=='both' else None)\n",
    "                dfc = dfc.reset_index(drop=True)\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .applymap(lambda x: f'max-width: 60ch;', subset=['run_name'])\n",
    "                        .set_table_styles([{'selector': 'td', 'props': [('white-space', 'pre-wrap'), ('word-wrap', 'break-word')]}])\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .applymap(lambda x: 'text-decoration: underline;' \\\n",
    "                                  if x in dfc[list(set(dfc.columns) & set([(x, '') for x in cols]))+[col] if chat_fmt=='both' else cols+[col]].values.flatten() and chat_fmt=='both' else '')\n",
    "                        .format(precision=1))\n",
    "\n",
    "# llama-7b_tulu_v1_mix(paper)\n",
    "# MMLU/0-shot, MMLU/5-shot, GSM/Direct, GSM/CoT, BBH/Direct, BBH/CoT, TydiQA/GP, TydiQA/CB, CodexEval/Pass@1, AlpacaEval(vs.Davinci-003)\n",
    "# 44.8       , 47.1       , 7.0       , 25.0   , 38.5      , 38.5   , 43.5,    , 8.0      , 18.6,           , 48.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "deeba0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['run_name',\n",
       " 'nonchat',\n",
       " 'sort_by',\n",
       " 'total_train_samples',\n",
       " 'model_name_or_path',\n",
       " 'subsample_mixture',\n",
       " 'max_train_samples',\n",
       " 'MMLU/0-shot',\n",
       " 'MMLU/5-shot',\n",
       " 'GSM/Direct',\n",
       " 'GSM/CoT',\n",
       " 'BBH/Direct',\n",
       " 'BBH/CoT',\n",
       " 'TydiQA/CB',\n",
       " 'TydiQA/GP',\n",
       " 'Codex-Eval/Pass@1',\n",
       " 'AlpacaFarm/WR*',\n",
       " 'AlpacaFarm/Len',\n",
       " 'Average',\n",
       " 'ranking']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rosemary import parse_kv_from_string\n",
    "\n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', ]\n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', ]\n",
    "\n",
    "def compute_nonchateval_average_performance(row):\n",
    "    L = [row[k] for k in non_chateval_task_names if k in row]\n",
    "    return np.average(L)\n",
    "\n",
    "def parse_prune_subset_size(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'(?<=pace=)([^_]+)', run_name)\n",
    "    if match:\n",
    "        pace = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(pace)\n",
    "        return int(kvs['size'] / kvs['ep'])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_sort_by_from_run_name(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'score=([^_]+)', run_name)\n",
    "    if match:\n",
    "        sort_by = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(sort_by)\n",
    "    else:\n",
    "        kvs = {}\n",
    "    return kvs\n",
    "\n",
    "\n",
    "def parse_sort_by_type(row):\n",
    "    d = row['sort_by']\n",
    "    if 'gamma' in d:\n",
    "        if d['gamma'] == 1e-3:\n",
    "            print(d)\n",
    "    if not d:\n",
    "        return None\n",
    "    if d[0] == 'dppmap':\n",
    "        if d['k']=='vmf' and d['kmd']=='mpnet': #and (d['gamma']==1 or d['gamma'] == 'auto1000'):\n",
    "            return 'vmf+text'\n",
    "        elif d['k']=='rbf' and d['kemb']=='text+embedding' and d['kmd'] == 'llama7br512p4096':\n",
    "            return f\"rbf+text_gamma={d['gamma']}\"\n",
    "        elif d['k']=='vmf' and d['kemb']=='grad+rp+loraB' and d['kmd'] == 'llama7br512p4096':\n",
    "            return f\"vmf+grad_gamma={d['gamma']}\"\n",
    "        else:\n",
    "            return None\n",
    "    elif d[0] == 'random':\n",
    "        return 'random'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "dfc.insert(1, 'sort_by' if chat_fmt!='both' else ('sort_by', ''), dfc.apply(parse_sort_by_from_run_name, axis=1))\n",
    "dfc.insert(1, 'sort_by_type' if chat_fmt!='both' else ('sort_by_type', ''), dfc.apply(parse_sort_by_type, axis=1))\n",
    "dfc.insert(1, 'subset_size' if chat_fmt!='both' else ('subset_size', ''), dfc.apply(parse_prune_subset_size, axis=1))\n",
    "dfc.insert(1, 'nonchat' if chat_fmt!='both' else ('nonchat', ''), dfc.apply(compute_nonchateval_average_performance, axis=1))\n",
    "\n",
    "\n",
    "dfc = dfc[dfc['sort_by_type'].notnull()]\n",
    "startswithstrs = ('rbf+text', 'random')\n",
    "startswithstrs = (\n",
    "    'random', \n",
    "    'rbf+text_gamma=0.001', \n",
    "    'vmf+grad_gamma=1',\n",
    "#     'rbf+text_gamma=auto1000', \n",
    "    'vmf+grad_gamma=auto1000',\n",
    ")\n",
    "dfc = dfc[dfc.apply(lambda x: x['sort_by_type'].startswith(startswithstrs)\n",
    "                   , axis=1)]\n",
    "dfc['subset_size'] = dfc['subset_size'].apply(lambda x: int(x) if x else x)\n",
    "dfc = dfc[dfc['subset_size']<=10_000]\n",
    "\n",
    "\n",
    "D = dfc.set_index(['sort_by_type', 'dataset', 'subset_size']).to_dict()\n",
    "from dataclasses import dataclass\n",
    "@dataclass(unsafe_hash=True)\n",
    "class DKey:\n",
    "    sort_by_type: str\n",
    "    dataset: str\n",
    "    subset_size: int\n",
    "def convert_key_to_dataclass(d):\n",
    "    return {DKey(*k): v for k, v in d.items()}\n",
    "D = {k: convert_key_to_dataclass(v) for k, v in D.items()}\n",
    "\n",
    "list(D.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "662539cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 21 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "yaxis_type = 'abs'\n",
    "# yaxis_type = 'delta_random'\n",
    "assert(yaxis_type in ['delta_random', 'abs'])\n",
    "datasets = ['flan_v2', 'dolly', 'stanford_alpaca', 'oasst1', 'ultrachat200kv2', 'wizardlmv2', 'sharegptv2']\n",
    "task_names = ['nonchat', 'MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR*',]\n",
    "task_names = ['nonchat', 'AlpacaFarm/WR', 'AlpacaFarm/ΔWR', 'AlpacaFarm/Len']\n",
    "task_names = ['nonchat', 'AlpacaFarm/WR*', 'AlpacaFarm/Len',]\n",
    "\n",
    "\n",
    "# task_names = ['AlpacaFarm/WR*',]\n",
    "\n",
    "# datasets = ['stanford_alpaca', 'wizardlmv2']\n",
    "# task_names = ['nonchat', 'MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "\n",
    "\n",
    "\n",
    "w = 2\n",
    "ncols = len(datasets)\n",
    "nrows = len(task_names)\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(w*ncols+2,w*nrows), sharey='row', sharex=True)\n",
    "\n",
    "xs_possible = []\n",
    "\n",
    "for axi, task_name in enumerate(task_names):\n",
    "    d = D[task_name]\n",
    "    for axj, dataset in enumerate(datasets):\n",
    "        ax = axs.reshape(nrows, ncols)[axi, axj]\n",
    "        sort_by_types = sorted(set(x.sort_by_type for x in d.keys()))\n",
    "\n",
    "        for i, sort_by_type in enumerate(sort_by_types):\n",
    "            xs = sorted([x.subset_size for x in d.keys()\n",
    "                         if x.dataset == dataset and x.sort_by_type==sort_by_type])\n",
    "            xs_possible += list(set(xs) - set(xs_possible))\n",
    "            ys = [d[DKey(sort_by_type, dataset, x)] for x in xs]\n",
    "            if yaxis_type == 'delta_random':\n",
    "                if not all(DKey('random', dataset, x) in d for x in xs): continue\n",
    "                ys = [y-d[DKey('random', dataset, x)] for x, y in zip(xs, ys)] \n",
    "            if 'random' in sort_by_type:\n",
    "                marker_style = 'o-'\n",
    "            else:\n",
    "                marker_style = 'o-'\n",
    "            ax.plot(xs, ys, marker_style, label=sort_by_type)\n",
    "        \n",
    "#         ax.set_yscale('log')\n",
    "            \n",
    "for axi, task_name in enumerate(task_names):\n",
    "    axs.reshape(nrows, ncols)[axi, 0].set_ylabel('△ '+task_name if yaxis_type.startswith('delta') else task_name, fontsize=13)\n",
    "    axs.reshape(nrows, ncols)[axi, -1].legend(loc='center left', bbox_to_anchor=(1.1, 0.5))\n",
    "for axj, dataset in enumerate(datasets):\n",
    "    axs.reshape(nrows, ncols)[0, axj].set_title(dataset, fontsize=15)\n",
    "    axs.reshape(nrows, ncols)[0, axj].set_xticks(xs_possible, xs_possible)\n",
    "\n",
    "space = 0.05\n",
    "fig.subplots_adjust(wspace=space, hspace=space)  # Adjust the value as needed\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fa5fdb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncols, nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab59d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de328f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
