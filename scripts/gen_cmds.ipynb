{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "3da1794b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'x86_64', 'cluster': 'ccc', 'queue': 'alt_7d'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "import re\n",
    "from llm.submit import (\n",
    "    multiline_to_singleline,\n",
    "    submit_job_ccc,\n",
    "    submit_job_aimos,\n",
    "    submit_job,\n",
    "        get_run_statistics)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import datetime\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import base64\n",
    "string_to_alphanumeric = lambda s: base64.urlsafe_b64encode(s.encode('utf-8')).decode('utf-8')\n",
    "alphanumeric_to_string = lambda a: base64.urlsafe_b64decode(a).decode('utf-8')\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm, shell_scripts_template_lsf, get_host_info, move_lsf_job_summary_to_save_dir\n",
    "from note_pruning_analysis import open_instruct_dir, assets_dir\n",
    "os.makedirs(assets_dir, exist_ok=True)\n",
    "\n",
    "import getpass\n",
    "\n",
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "info = get_host_info()\n",
    "info.update({'queue': queue})\n",
    "arch, cluster = info['arch'], info['cluster']\n",
    "print(info)\n",
    "\n",
    "os.environ['TORCHELASTIC_ERROR_FILE'] = os.path.join(os.getcwd(), 'torchelastic_error_file') \n",
    "\n",
    "## jobs submitted in notebook inherits env variables.\n",
    "cache_dir = os.path.normpath(os.path.join(os.getcwd(), '../../../../mitibm2023/cache')) \\\n",
    "    if arch == 'ppc64le' else '/dccstor/data-pruning/cache'\n",
    "os.environ['WANDB_DIR'] = cache_dir\n",
    "os.makedirs(os.environ['WANDB_DIR'], exist_ok=True, mode=0o777)\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_PROJECT'] = 'mitibm'\n",
    "##\n",
    "##\n",
    "\n",
    "shell_scripts_template = shell_scripts_template_slurm \\\n",
    "    if arch == 'ppc64le' else shell_scripts_template_lsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c421d1",
   "metadata": {},
   "source": [
    "# DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c09b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/oi2/llama-7b_sharegptv2_ep=2 using 6 GPUs, 1 batch size per GPU, 1 gradient accumulation steps, 30 effective batch size.\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp7pssto1b', 'job_id': 1354503}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2p8zx1bt', 'job_id': 1354504}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2_mpillk', 'job_id': 1354505}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm\n",
    "debug = False\n",
    "if debug:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'INFO'\n",
    "    os.environ['NCCL_DEBUG'] = 'INFO'\n",
    "else:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'WARNING'\n",
    "    os.environ['NCCL_DEBUG'] = ''\n",
    "num_cpus = 144 if arch == 'ppc64le' else 32\n",
    "cpu_mem =  650 if arch == 'ppc64le' else 64\n",
    "\n",
    "preprocessing_num_workers = 32\n",
    "report_to = 'wandb'\n",
    "mixed_precision = 'bf16' if arch == 'x86_64' else 'fp16'\n",
    "torch_dtype = 'bfloat16' if arch=='x86_64' else 'float32'\n",
    "gradient_checkpointing = True\n",
    "use_fast_tokenizer = True\n",
    "hf_models_dir = 'results/baselines/'\n",
    "resume_from_checkpoint = True # resume from latest checkpoint if exists, otherwise train from scratch\n",
    "num_train_epochs = 2\n",
    "checkpointing_steps = 300 # (50_000 / 32) * 2 / 6 ~= 500 (data size of 50k, bsz=32, ep=2, total save 6 times at most)\n",
    "max_train_steps = None\n",
    "subsample_inds_file_list = [None]\n",
    "dataloader_sampler = 'RandomSampler'\n",
    "overwrite_cache = True\n",
    "\n",
    "\n",
    "# #####\n",
    "# job_name = 'dpo1'\n",
    "\n",
    "# # model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-410m-deduped'; max_seq_length = 2048; abbr_model_name = 'pythia-410m'\n",
    "# # model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "\n",
    "# train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "# train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "train_file = 'data/processed/hh_rlhf/hh_rlhf_data.jsonl'; dataset = 'hh_rlhf'\n",
    "\n",
    "# M = 60_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 20_000\n",
    "# M = 50_000; pacing_fn_list = [f'prune_size={M}_ep=5']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "    (10_000, 10), # 1k\n",
    "#     (30_000, 3),  # 10k\n",
    "#     (60_000, 3),  # 20k\n",
    "]]\n",
    "\n",
    "gen_output_md = 'llama7br512p4096'\n",
    "# gen_output_md = 'llama7b+sharegptv2ep2+r512p4096'\n",
    "# gen_output_model_name = 'all-mpnet-base-v2'\n",
    "\n",
    "scoring_fn_list = []\n",
    "scoring_fn_list += ['random_s=0']\n",
    "# scoring_fn_list += ['random_s=1']\n",
    "scoring_fn_list += [ \n",
    "#     f'dppmap_k=vmf_gamma=1_kmd={gen_output_md}_kemb=grad+rp+loraB',\n",
    "#     f'dppmap_k=rbf_gamma=1e-3_kmd={gen_output_md}_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1_kmd=mpnet_kemb=text+embedding',\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'dpo2_{dataset}:{abbr_model_name}'\n",
    "    \n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12\n",
    "# nodes = 2; num_gpus = 1; gpu_type = 'v100'; job_duration = 6; cpu_mem = 100; num_cpus = 32; max_train_steps = 5; checkpointing_steps = 2; report_to = 'tensorboard'\n",
    "    \n",
    "#####\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs = 1 # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "use_deepspeed = True\n",
    "deepspeed_config_file = 'ds_configs/stage3_no_offloading_accelerate.conf'\n",
    "\n",
    "per_device_train_batch_size = 1; total_batch_size = 32\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"{effective_batch_size} effective batch size.\")\n",
    "\n",
    "# reference: https://gist.github.com/pacman100/1cb1f17b2f1b3139a63b764263e70b25\n",
    "launcher = f\"\"\"accelerate launch \\\n",
    "    --mixed_precision {mixed_precision} \\\n",
    "    --num_machines {nodes} \\\n",
    "    --num_processes {num_gpus*nodes} \\\n",
    "    {'--use_deepspeed' if use_deepspeed else ''} \\\n",
    "    {'--deepspeed_config_file '+deepspeed_config_file if use_deepspeed else ''} \\\n",
    "    {'--main_process_ip $master_addr' if use_deepspeed else ''} \\\n",
    "    {'--main_process_port $master_port' if use_deepspeed else ''} \\\n",
    "    {'--machine_rank $SLURM_PROCID' if use_deepspeed else ''} \\\n",
    "    {'--rdzv_backend c10d' if use_deepspeed and nodes>1 else ''} \\\n",
    "    {'--deepspeed_multinode_launcher standard' if use_deepspeed and nodes>1 else ''} \\\n",
    "\"\"\"\n",
    "\n",
    "cmds = []\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    subsample_inds_file_list,\n",
    ")\n",
    "\n",
    "output_dirname_list = []\n",
    "for (subsample_inds_file,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{dataset}\"\n",
    "    if any(job_name == y for y in ['dpo1']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "\n",
    "    if subsample_inds_file:\n",
    "        assert(num_train_epochs==1)\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                s = f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "\n",
    "    if subsample_inds_file is not None:\n",
    "        assert(dataloader_sampler=='SequentialSampler')\n",
    "        assert(num_train_epochs==1)\n",
    "    else:\n",
    "        assert(dataloader_sampler=='RandomSampler')\n",
    "\n",
    "    output_dir = os.path.join('results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join('results', job_name), exist_ok=True)\n",
    "    wandb_run_name = output_dir.replace('results/', '')\n",
    "\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {f'cd .. && CUDA_VISIBLE_DEVICES={os.environ[\"CUDA_VISIBLE_DEVICES\"]} ' if test_run else ''}{launcher}\n",
    "        open_instruct/dpo_tune.py \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --tokenizer_name {model_name_or_path} \\\n",
    "        {'--use_slow_tokenizer' if not  use_fast_tokenizer else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        --train_file {train_file} \\\n",
    "        --max_seq_length {max_seq_length} \\\n",
    "        {'--subsample_inds_file '+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        --dataloader_sampler {dataloader_sampler} \\\n",
    "        --preprocessing_num_workers {preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size {per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
    "        --learning_rate 5e-7 \\\n",
    "        --lr_scheduler_type linear \\\n",
    "        --warmup_ratio 0.1 \\\n",
    "        --weight_decay 0. \\\n",
    "        --num_train_epochs {num_train_epochs} \\\n",
    "        --with_tracking \\\n",
    "        {'--report_to \"'+str(report_to)+'\"' if report_to else ''} \\\n",
    "        --checkpointing_steps {checkpointing_steps} \\\n",
    "        {'--max_train_steps '+str(max_train_steps) if max_train_steps else ''} \\\n",
    "        {'--resume_from_checkpoint' if resume_from_checkpoint else ''} \\\n",
    "        {'--low_cpu_mem_usage' if not use_deepspeed else ''} \\\n",
    "        {'--overwrite_cache' if overwrite_cache else ''} \\\n",
    "        --logging_steps 1 \\\n",
    "        --output_dir {output_dir}\n",
    "    \"\"\"\n",
    "    # if test_run:\n",
    "    #     print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    if test_run:\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64': # ccc\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "        queue=queue,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda1f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prune: {1k@10, 10k@3}, datasets={dolly, stanford_alpaca}, scoring={random, dppmapx2}\n",
    "# need to gen curriculum for 50k sft datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b79b9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_dpo.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce604bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=5\n",
      "+ cd ..\n",
      "+ CUDA_VISIBLE_DEVICES=2,5\n",
      "+ accelerate launch --mixed_precision fp16 --num_machines 1 --num_processes 2 --use_deepspeed --deepspeed_config_file ds_configs/stage3_no_offloading_accelerate.conf open_instruct/dpo_tune.py --model_name_or_path results/baselines/huggyllama/llama-7b --tokenizer_name results/baselines/huggyllama/llama-7b --gradient_checkpointing --train_file data/processed/ultrafeedback/ultrafeedback_data.jsonl --max_seq_length 2048 --preprocessing_num_workers 32 --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --learning_rate 5e-7 --lr_scheduler_type linear --warmup_ratio 0.1 --weight_decay 0. --num_train_epochs 2 --with_tracking --report_to tensorboard --checkpointing_steps 500 --logging_steps 1 --output_dir results/dpo1/jpt_llama-7b_ultrafeedback\n",
      "[2024-01-08 20:41:08,547] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "[2024-01-08 20:41:17,396] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-08 20:41:17,400] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:662:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,611] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 1\n",
      "Local process index: 1\n",
      "Device: cuda:1\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 251.17it/s]\n",
      "01/08/2024 20:41:25 - WARNING - datasets.builder - Found cached dataset json (/gpfs/u/scratch/PTFM/PTFMqngp/huggingface_cache/datasets/json/default-201ebfceee303348/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 252.78it/s]\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:26,493] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 6.74B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.74s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:16<00:00,  8.11s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:43,556] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 13.48B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.60s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "01/08/2024 20:42:20 - INFO - accelerate.accelerator - Updating DeepSpeed's gradient accumulation steps to 16 from 1.\n",
      "[2024-01-08 20:42:20,382] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.1+23a11a39, git-hash=23a11a39, git-branch=master\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 1\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "[2024-01-08 20:42:20,751] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n",
      "[2024-01-08 20:42:20,779] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\n",
      "[2024-01-08 20:42:20,891] [INFO] [utils.py:786:see_memory_usage] Stage 3 initialize beginning\n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 14.16 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.9 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:118:__init__] Reduce bucket size 16777216\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:119:__init__] Prefetch bucket size 15099494\n",
      "[2024-01-08 20:42:20,995] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 13.64 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n",
      "[2024-01-08 20:42:21,139] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.76 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:21,240] [INFO] [utils.py:786:see_memory_usage] Before creating fp16 partitions\n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.4 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:23,090] [INFO] [utils.py:786:see_memory_usage] After creating fp16 partitions: 4\n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.4 GB         CA 14.6 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.99 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,190] [INFO] [utils.py:786:see_memory_usage] Before creating fp32 partitions\n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.39 GB         CA 14.6 GB         Max_CA 15 GB \n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.81 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,742] [INFO] [utils.py:786:see_memory_usage] After creating fp32 partitions\n",
      "[2024-01-08 20:42:23,743] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 26.61 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,744] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 116.15 GB, percent = 16.7%\n",
      "[2024-01-08 20:42:23,836] [INFO] [utils.py:786:see_memory_usage] Before initializing optimizer states\n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 25.94 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 117.28 GB, percent = 16.8%\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 1; 31.75 GiB total capacity; 25.93 GiB already allocated; 3.34 GiB free; 27.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 0; 31.75 GiB total capacity; 25.94 GiB already allocated; 3.21 GiB free; 27.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 409110) of binary: /gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/python3.10\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 964, in launch_command\r\n",
      "    deepspeed_launcher(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 687, in deepspeed_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "open_instruct/dpo_tune.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 409111)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 409110)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_dpo.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c8b",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune_trainer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "19aebd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=10_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/baselines/huggyllama/llama-7b using 4 GPUs, 1 batch size per GPU, 32 gradient accumulation steps, Effective batch size 128\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 64,\n",
      "    \"cpu_mem\": 384,\n",
      "    \"num_gpus\": 4,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_wizardlm50k:llama-7b -mem 384g -cores 1x64+4 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/wizardlm/wizardlm50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=32 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=90000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/wizardlm50k/random_s=0/inds_prune_size=90000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=90000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=90000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1514459}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 64,\n",
      "    \"cpu_mem\": 384,\n",
      "    \"num_gpus\": 4,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_wizardlm50k:llama-7b -mem 384g -cores 1x64+4 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/wizardlm/wizardlm50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=32 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/wizardlm50k/dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding/inds_prune_size=90000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1514460}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 64,\n",
      "    \"cpu_mem\": 384,\n",
      "    \"num_gpus\": 4,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_wizardlm50k:llama-7b -mem 384g -cores 1x64+4 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/wizardlm/wizardlm50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=32 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/wizardlm50k/dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB/inds_prune_size=90000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1514461}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 64,\n",
      "    \"cpu_mem\": 384,\n",
      "    \"num_gpus\": 4,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_wizardlm50k:llama-7b -mem 384g -cores 1x64+4 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/wizardlm/wizardlm50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=32 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/wizardlm50k/dppmap_k=vmf_gamma=10_kmd=llama7br512p4096_kemb=text+embedding/inds_prune_size=90000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1514462}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "add_hardwarespec_to_dirname = False\n",
    "save_strategy = 'steps'\n",
    "save_steps = 200 if getpass.getuser() in ('PTFMqngp', 'wpq') else 1_000_000\n",
    "save_total_limit = 1\n",
    "preprocessing_num_workers = 32\n",
    "evaluation_strategy = 'no' # set do_eval=False\n",
    "eval_steps = save_steps\n",
    "report_to = 'tensorboard wandb'\n",
    "suffix = None\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0.03\n",
    "dataloader_sampler = None\n",
    "hf_models_dir = 'results/baselines/'\n",
    "subsample_inds_file_list = [None]\n",
    "max_train_samples_list = [None]\n",
    "num_train_epochs_list = [1]\n",
    "scoring_fn_and_pacing_fn = None\n",
    "\n",
    "\n",
    "# ########### sft baselines\n",
    "\n",
    "\n",
    "# job_name = 'oi2'; num_train_epochs_list = [3]\n",
    "# # model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "\n",
    "# # train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca'; \n",
    "# # train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# # train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2'; max_train_samples_list=[100_000]\n",
    "\n",
    "# ## 50k sft datasets\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# # train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "# ## additional ones : {wizardlm50k, oasst2, lima, gpt4_alpaca50k, flan_v250k}\n",
    "# # train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "# # train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# # train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# # train_file = 'data/processed/gpt4_alpaca/gpt4_alpaca50k_data.jsonl'; abbr_train_file = 'gpt4_alpaca'; \n",
    "# # train_file = 'data/processed/lima/lima_data.jsonl'; abbr_train_file = 'lima'; num_train_epochs_list = [3]\n",
    "\n",
    "# # mix\n",
    "# train_file = 'data/processed/mix/mix_all50k_data.jsonl'; abbr_train_file = 'mix_all50k'; num_train_epochs_list = [2]\n",
    "\n",
    "\n",
    "\n",
    "# # train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2'; max_train_samples_list=[100_000]\n",
    "# ###########\n",
    "\n",
    "\n",
    "############ pruning runs\n",
    "\n",
    "# model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048; gen_output_md = 'mistral7br512p4096'\n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048; gen_output_md = 'llama7br512p4096'\n",
    "\n",
    "\n",
    "# # 50k sft datasets\n",
    "# dataset = 'flan_v250k'; train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca50k'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "dataset = 'wizardlm50k'; train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "# dataset = 'sharegpt50k'; train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "# dataset = 'ultrachat50k'; train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "\n",
    "# dataset = 'flan_v2'; train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca';\n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# dataset = 'wizardlmv2'; train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2';\n",
    "# dataset = 'sharegptv2'; train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2';\n",
    "# dataset = 'ultrachat200kv2'; train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2';\n",
    "\n",
    "\n",
    "# dataset = 'oasst1'; train_file = 'data/processed/oasst/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# dataset = 'open_orca_slim'; train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; \n",
    "# dataset = 'tulu_v2'; train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2';\n",
    "        \n",
    "# M = 80_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 40_000\n",
    "# M = 40_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 20_000\n",
    "# M = 30_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [\n",
    "    f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "#         (10_000, 10), # -> 1k, 2%\n",
    "#         (30_000, 3),  # -> 10k, 20%\n",
    "#         (60_000, 3),  # -> 20k, 40%\n",
    "        (90_000, 3),  # -> 30k, 60%\n",
    "#         (120_000, 3),  # -> 40k, 80%\n",
    "    ]\n",
    "]\n",
    "#         + [running] 10k prune size. 4 datasets, compare {vmf,rbf} x {text,grad}\n",
    "\n",
    "\n",
    "        \n",
    "kmd = 'llama7br512p4096'\n",
    "scoring_fn_list = [\n",
    "    'random_s=0',\n",
    "#     'random_s=1',\n",
    "#     'log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n',\n",
    "#     'ifd_neg', 'log_pmi_neg',\n",
    "#     'numtoks_input_neg', 'numtoks_output_neg', 'numtoks_total_neg',\n",
    "#     f'dppmap_k=vmf_gamma=1_kmd=mpnet_kemb=text+embedding', #_kemb=text+embedding',\n",
    "    ## dedup\n",
    "#     f'dedup_dist=cd_md=mpnet_emb=text+embedding',\n",
    "#     f'dedup_dist=cd_md={kmd}_emb=text+embedding',\n",
    "#     f'dedup_dist=cd_md={kmd}_emb=grad+rp+loraB',\n",
    "    ##\n",
    "    f'dppmap_k=rbf_gamma=1e-3_kmd={kmd}_kemb=text+embedding',\n",
    "    f'dppmap_k=vmf_gamma=1_kmd={kmd}_kemb=grad+rp+loraB',\n",
    "    # added baseline\n",
    "    f'dppmap_k=vmf_gamma=10_kmd={kmd}_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1e-2_kmd={kmd}_kemb=grad+rp+loraB',\n",
    "    ## arccos kernel\n",
    "#     'dppmap_k=acos0_kmd=llama7br512p4096_kemb=grad+rp+loraB',\n",
    "#     'dppmap_k=acos0_kmd=llama7br512p4096_kemb=text+embedding',\n",
    "#     'dppmap_k=acos1_kmd=llama7br512p4096_kemb=grad+rp+loraB',\n",
    "]\n",
    "\n",
    "scoring_fn_list += [ # vary kernel embedding model \n",
    "#     f'dppmap_k=vmf_gamma=auto{subset_size}_kmd={kmd}_kemb=grad+rp+loraB'\n",
    "#     for kmd in ['llama7br256p4096', 'llama7br512p4096', 'pythia1br512p4096']\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'oi5_{dataset}:{abbr_model_name}'\n",
    "############ \n",
    "\n",
    "\n",
    "    \n",
    "# add_hardwarespec_to_dirname = True\n",
    "# job_name += '_debug' # wpq debug\n",
    "# max_train_samples_list=[128*2]\n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "debug_mode = test_run\n",
    "\n",
    "if arch == 'x86_64':\n",
    "#     nodes = 1; num_gpus = 8; gpu_type = 'a100_80gb'; job_duration = 6\n",
    "    nodes = 1; num_gpus = 4; gpu_type = 'a100_80gb'; job_duration = 6 \n",
    "    num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus); preprocessing_num_workers = 128 # tok takes quite a bit.\n",
    "    per_device_train_batch_size = 1\n",
    "    gradient_checkpointing = False\n",
    "    mixed_precision = 'bf16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = True \n",
    "    save_model_torch_dtype = 'bfloat16' # typically save fp32 weights, but for disk space sake, convert to bf16.\n",
    "else:\n",
    "    nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_checkpointing = True\n",
    "    mixed_precision = 'fp16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = False\n",
    "    save_model_torch_dtype = None\n",
    "\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs_list = [1] # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "overwrite_output_dir = True if test_run else False # always continue from ckpt if run from cluster.\n",
    "\n",
    "total_batch_size = 128\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "optimizer = 'adamw_hf'\n",
    "\n",
    "deepspeed = ''; fsdp = False if num_gpus == 1 else \"full_shard auto_wrap\" \n",
    "if 'gpt2' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPT2Block'\n",
    "elif 'llama' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'LlamaDecoderLayer'\n",
    "elif 'mpt' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MPTBlock'\n",
    "elif 'pythia' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPTNeoXLayer'        \n",
    "elif 'mistral' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MistralDecoderLayer'\n",
    "else: raise ValueError('Not sure how to set `fsdp_transformer_layer_cls_to_wrap`')\n",
    "    \n",
    "# deepspeed = './ds_configs/ds_zero3_cpu_offload.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/ds_zero3.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/stage3_no_offloading.conf'; fsdp = False # error with loading... something wrong with the config.\n",
    "# fsdp = False; deepspeed = False\n",
    "\n",
    "if fsdp and deepspeed:\n",
    "    raise ValueError('either fsdp or deepspeed, not both')\n",
    "\n",
    "use_lora = False\n",
    "lora_rank = 256 \n",
    "lora_alpha = lora_rank \n",
    "lora_dropout = 0.05\n",
    "if use_lora:\n",
    "    abbr_model_name += f'+lora(r={lora_rank},a={lora_alpha})'\n",
    "load_in_8bit = False\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"Effective batch size {effective_batch_size}\")\n",
    "\n",
    "\n",
    "if nodes == 1:\n",
    "    exe = 'python' if num_gpus==1 else \\\n",
    "        f\"torchrun --nnodes 1 --nproc_per_node={num_gpus} --rdzv_backend=c10d --rdzv_endpoint=localhost:0\" # assigns random port. https://github.com/pytorch/pytorch/issues/73320\n",
    "else:\n",
    "    exe = f\"torchrun --nnodes={nodes} --nproc_per_node={num_gpus} --rdzv-id=${'SLURM_JOB_ID' if arch == 'ppcle64' else 'LSB_JOBID'} --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT\"\n",
    "\n",
    "if test_run:\n",
    "    exe = f\"CUDA_VISIBLE_DEVICES={','.join(map(str, range(num_gpus)))} {exe}\"\n",
    "if test_run and debug_mode:\n",
    "    exe = 'TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO ' + exe\n",
    "    error_file = os.path.join(open_instruct_dir, 'scripts', 'error_file')\n",
    "    exe = f'TORCHELASTIC_ERROR_FILE={error_file} {exe}'\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    raise ValueError(f'train_file={train_file} does not exists')\n",
    "\n",
    "options_list = itertools.product(\n",
    "    num_train_epochs_list,\n",
    "    subsample_inds_file_list,\n",
    "    max_train_samples_list,\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "output_dirname_list = []\n",
    "for (num_train_epochs,\n",
    "     subsample_inds_file,\n",
    "     max_train_samples,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{abbr_train_file}\"\n",
    "    if max_train_samples:\n",
    "        output_dirname += f\":{int(max_train_samples/1000)}k\"\n",
    "            \n",
    "    if any(job_name == y for y in ['oi2']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "        \n",
    "    if subsample_inds_file:\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                return f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            else:\n",
    "                return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "            \n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "            \n",
    "    if add_hardwarespec_to_dirname:\n",
    "        output_dirname += \\\n",
    "            ('_fsdp='+fsdp.split(' ')[0] if fsdp else '')+\\\n",
    "            ('_deepspeed='+os.path.basename(deepspeed).split('.')[0] if deepspeed else '')+\\\n",
    "            ('_gradckpt='+str(gradient_checkpointing) if gradient_checkpointing else '')+\\\n",
    "            '_mbsz='+str(per_device_train_batch_size)+\\\n",
    "            ('_dtype='+torch_dtype if torch_dtype is not None else '')+\\\n",
    "            ('_mp='+str(mixed_precision) if mixed_precision else '_mp=none')+\\\n",
    "            '_seqlen='+str(max_seq_length)+\\\n",
    "            '_nodes='+str(nodes)+\\\n",
    "            '_ngpus='+str(num_gpus)+\\\n",
    "            ('_fa2' if use_flash_attn else '')\n",
    "    if suffix:\n",
    "        output_dirname += suffix\n",
    "    output_dir = os.path.join(open_instruct_dir, 'results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join(open_instruct_dir, 'results', job_name), exist_ok=True)\n",
    "    if arch == 'x86_64':\n",
    "        wandb_run_name = 'ccc'+output_dir[output_dir.find('results'):][7:] # e.g., ccc/oi2/run_name\n",
    "    else:\n",
    "        wandb_run_name = output_dir.replace('results/', '') # e.g., oi2/run_name\n",
    "    \n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {'cd .. && ' if test_run else ''}{exe}\n",
    "        open_instruct/finetune_trainer.py \\\n",
    "        --model_name_or_path={model_name_or_path} \\\n",
    "        --tokenizer_name={model_name_or_path} \\\n",
    "        {'--load_in_8bit' if load_in_8bit else ''} \\\n",
    "        --use_fast_tokenizer=True \\\n",
    "        --train_file={train_file} \\\n",
    "        --max_seq_length={max_seq_length} \\\n",
    "        {'--max_train_samples='+str(max_train_samples) if max_train_samples else ''} \\\n",
    "        {'--use_lora' if use_lora else ''} \\\n",
    "        {'--lora_rank='+str(lora_rank) if use_lora else ''} \\\n",
    "        {'--lora_alpha='+str(lora_alpha) if use_lora else ''} \\\n",
    "        {'--lora_dropout='+str(lora_dropout) if use_lora else ''} \\\n",
    "        --do_train \\\n",
    "        --preprocessing_num_workers={preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size={per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
    "        --learning_rate=2e-5 \\\n",
    "        --lr_scheduler_type={lr_scheduler_type} \\\n",
    "        --warmup_ratio={warmup_ratio} \\\n",
    "        --weight_decay=0. \\\n",
    "        --optim={optimizer} \\\n",
    "        --evaluation_strategy={evaluation_strategy} \\\n",
    "        {'--eval_steps='+str(eval_steps) if eval_steps else ''} \\\n",
    "        {'--report_to '+str(report_to) if report_to else ''} \\\n",
    "        --run_name {wandb_run_name} \\\n",
    "        --logging_strategy=steps \\\n",
    "        --logging_first_step \\\n",
    "        --logging_steps=1 \\\n",
    "        --save_strategy={save_strategy} \\\n",
    "        --save_steps={save_steps} \\\n",
    "        --save_total_limit={save_total_limit} \\\n",
    "        --num_train_epochs={num_train_epochs} \\\n",
    "        --ddp_timeout=7200 \\\n",
    "        {'--fsdp=\"'+fsdp+'\"' if fsdp else ''} \\\n",
    "        {'--fsdp_transformer_layer_cls_to_wrap=\"'+fsdp_transformer_layer_cls_to_wrap+'\"' \n",
    "            if fsdp else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        {'--torch_dtype='+str(torch_dtype) if torch_dtype else ''} \\\n",
    "        {'--save_model_torch_dtype='+str(save_model_torch_dtype) if save_model_torch_dtype else ''} \\\n",
    "        --dataloader_num_workers=8 \\\n",
    "        {f'--{mixed_precision}=True' if mixed_precision else ''} \\\n",
    "        {f'--tf32=True' if use_tf32 else ''} \\\n",
    "        {'--overwrite_output_dir' if overwrite_output_dir else ''} \\\n",
    "        {'--deepspeed='+deepspeed if deepspeed else ''} \\\n",
    "        {'--subsample_inds_file='+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        {'--dataloader_sampler '+str(dataloader_sampler) if dataloader_sampler else ''} \\\n",
    "        --use_flash_attn {'True' if use_flash_attn else 'False'} \\\n",
    "        --low_cpu_mem_usage \\\n",
    "        --overwrite_cache \\\n",
    "        --output_dir=\"{output_dir}\" \\\n",
    "    \"\"\" \n",
    "    #  --overwrite_cache   # if delete a dataset and need to refresh cache\n",
    "\n",
    "    if test_run:\n",
    "        print()\n",
    "        print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64':\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        queue=queue,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12fc2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_sft.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed0c2894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ cd ..\n",
      "+ TORCHELASTIC_ERROR_FILE=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/error_file\n",
      "+ TORCH_CPP_LOG_LEVEL=INFO\n",
      "+ NCCL_DEBUG=INFO\n",
      "+ LOGLEVEL=INFO\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/oasst1/oasst1_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=32 --per_device_train_batch_size=1 --gradient_accumulation_steps=128 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=200 --report_to tensorboard wandb --run_name /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=200 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --overwrite_output_dir --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl --dataloader_sampler SequentialSampler --use_flash_attn True --low_cpu_mem_usage --overwrite_cache --output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10\n",
      "[2024-01-19 02:04:37,834] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Saving args dict to /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10.args.json\n",
      "01/19/2024 02:04:39 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "01/19/2024 02:04:39 - INFO - __main__ - Training parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=8,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_sampler=SequentialSampler,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=7200,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=200.0,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=128,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10/runs/Jan19_02-04-39_cccxc552,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1.0,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard', 'wandb'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=True,\n",
      "save_steps=200,\n",
      "save_strategy=steps,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=True,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "Using custom data configuration default-b03eccd42e843020\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Using custom data configuration default-b03eccd42e843020\n",
      "Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "[INFO|configuration_utils.py:715] 2024-01-19 02:04:39,135 >> loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "[INFO|configuration_utils.py:777] 2024-01-19 02:04:39,136 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3118] 2024-01-19 02:04:39,229 >> loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1222] 2024-01-19 02:04:39,229 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[WARNING|modeling_utils.py:1304] 2024-01-19 02:04:39,230 >> You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:39,230 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.07it/s]\n",
      "[INFO|modeling_utils.py:3950] 2024-01-19 02:04:41,778 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:3958] 2024-01-19 02:04:41,778 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:749] 2024-01-19 02:04:41,781 >> loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:41,781 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "01/19/2024 02:04:41 - INFO - __main__ - [wpq] model.dtype=torch.bfloat16\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1648] 2024-01-19 02:04:41,845 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spawning 32 processes\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Spawning 32 processes\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 0/33717 [00:Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 22/33717 [00Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   1%| | 361/33717 [0Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):   3%| | 1001/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   5%| | 1719/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   7%| | 2251/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):  12%| | 4021/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  14%|▏| 4841/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  18%|▏| 5957/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32): 100%|█| 33717/33717 \n",
      "Concatenating 32 shards\n",
      "01/19/2024 02:04:55 - INFO - datasets.arrow_dataset - Concatenating 32 shards\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - __main__ - Subsample dataset according to indices: /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl\n",
      "01/19/2024 02:04:56 - INFO - __main__ - subsample_inds_file has 10000 indices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[wpq] Example 0 of train_dataset: \r\n",
      "{'dataset': 'oasst1', 'id': 'oasst1_20480', 'messages': [{'role': 'user', 'content': 'Cómo manejar un carro manual'}, {'role': 'assistant', 'content': 'Lo primero que tienes que hacer, si nunca has conducido un coche manual, es familiarizarte con el embrague y palanca de cambios. Si conduces habitualmente un coche automático, estarás acostumbrado a no utilizar para nada el pie izquierdo ni la palanca del cambio. Encontrarás tres pedales, siendo el embrague el que está situado a la izquierda y el que tendrás que pisar cada vez que cambies de marcha. Por otro lado, la palanca del cambio se ubica siempre en la consola central.\\n\\nPara arrancar un coche manual, es necesario seguir una serie de pasos que, al principio, pueden parecer muchos, pero que, con el tiempo, acabarás haciéndolos sin darte cuenta:\\n\\n1) Comprueba que la palanca del cambio está en punto muerto\\n2) Coloca el pie derecho en el pedal del freno\\n3) Arranca el motor\\n4) Pisa el embrague con el pie izquierdo\\n5) Coloca la palanca del cambio en la primera marcha, sin levantar el pedal del freno\\n6) Suelta el freno de mano\\n7) Suelta el pedal del freno\\nYa estás listo para iniciar la marcha, soltando suavemente el embrague, a medida que aceleras.\\n\\nUna vez que ya estás en marcha, debes hacer un uso correcto del cambio manual para cambiar las marchas de forma correcta. Un uso incorrecto de la caja de cambios manual puede repercutir negativamente en tu seguridad y también afectar gravemente al embrague y a la transmisión, lo que se traduce en serias averías de coste muy elevado. Para evitarlo, te explicamos cómo debes proceder:\\n\\nUna vez que hayas arrancado, pisa el acelerador muy lentamente. Notarás que el régimen del motor aumenta. En ese momento, comienza a soltar suavemente el pedal del embrague. Verás que el motor vuelve a bajar de vueltas. En ese momento, puedes presionar un poco más el acelerador y el coche comenzará a avanzar.\\n\\nAhora llega el momento de meter la segunda marcha. Dependiendo del tipo de coche y combustible, podrás circular a un régimen de giro más bajo o alto. El régimen de giro en coche de gasolina, por lo general, oscila entre loas 2.500 y 3.000 vueltas. Si el motor está sobrealimentado por turbo, te permitirá circular por debajo de ese rango, ya que algunos coches turbos modernos entregan la totalidad de su par motor, incluso por debajo de las 2.000 vueltas.\\n\\nUn coche con motor turbodiésel te permite circular a un régimen muy bajo, por debajo de las 2.000 vueltas, ya que la entrega de par se produce antes que en un motor de gasolina.\\n\\nCuando el coche alcance un régimen de vueltas apropiado, suelta el pedal del acelerador y vuelve a pisar el embrague. Coge la palanca del cambio y baja para meter segunda. Suelta el embrague y presiona nuevamente el acelerador. A partir de aquí, cada vez que quieras cambiar de marcha, deberás repetir el mismo proceso: soltar el acelerador, pisar embrague, meter la marcha, soltar embrague y volver a acelerar.\\n\\n¡Buen viaje!'}], 'input_ids': tensor([    1,   529, 29989,  1792, 29989, 29958,    13, 29907, 29980,  4346,\r\n",
      "          767, 29872,  4758,   443,  1559,   307, 12219,    13, 29966, 29989,\r\n",
      "          465, 22137, 29989, 29958,    13,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'labels': tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:593] 2024-01-19 02:04:57,333 >> Using auto half precision backend\n",
      "[INFO|trainer.py:738] 2024-01-19 02:04:57,494 >> The following columns in the training set don't have a corresponding argument in `LlamaForCausalLM.forward` and have been ignored: messages, id, dataset. If messages, id, dataset are not expected by `LlamaForCausalLM.forward`,  you can safely ignore this message.\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1723] 2024-01-19 02:04:57,514 >> ***** Running training *****\n",
      "[INFO|trainer.py:1724] 2024-01-19 02:04:57,514 >>   Num examples = 10,000\n",
      "[INFO|trainer.py:1725] 2024-01-19 02:04:57,514 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1726] 2024-01-19 02:04:57,514 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:1729] 2024-01-19 02:04:57,514 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1730] 2024-01-19 02:04:57,514 >>   Gradient Accumulation steps = 128\n",
      "[INFO|trainer.py:1731] 2024-01-19 02:04:57,514 >>   Total optimization steps = 78\n",
      "[INFO|trainer.py:1732] 2024-01-19 02:04:57,515 >>   Number of trainable parameters = 6,738,423,808\n",
      "[INFO|integration_utils.py:718] 2024-01-19 02:04:57,519 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "  0%|                                                    | 0/78 [00:00<?, ?it/s][WARNING|logging.py:314] 2024-01-19 02:05:01,563 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,569 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,572 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,576 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,577 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 1.6425, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}         \n",
      "{'loss': 1.7168, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.03}        \n",
      "  3%|█▏                                          | 2/78 [00:42<26:54, 21.24s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash gen_cmds_sft.sh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:177\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:646\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGCONT)\n\u001b[0;32m--> 646\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_sft.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831fe55",
   "metadata": {},
   "source": [
    "# eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "499d6f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt', 'results/oi2/llama-7b_mix_all50k_ep=2')\n",
      "('alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt', 'results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=numtoks:total:neg_pace=prune:size=30000:ep=3')\n",
      "('alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=numtoks:output:neg_pace=prune:size=30000:ep=3')\n",
      "('alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=log:prob:neg_pace=prune:size=30000:ep=3')\n",
      "('alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=el2n:agg=mean_pace=prune:size=30000:ep=3')\n",
      "('alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=grad:loraB:l2n_pace=prune:size=30000:ep=3')\n",
      "('alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=numtoks:input:neg_pace=prune:size=30000:ep=3')\n",
      "#cmds:  8 \n",
      "\n",
      "\n",
      "python -m eval.alpaca_farm.run_eval \\\n",
      "\t--reference_path alpaca_eval_data \\\n",
      "\t--model_name_or_path \"results/oi2/llama-7b_mix_all50k_ep=2\" \\\n",
      "\t--max_new_tokens 2048 \\\n",
      "\t--save_dir \"results/oi2/llama-7b_mix_all50k_ep=2/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\" \\\n",
      "\t--eval_batch_size 10 \\\n",
      "\t--annotators_config alpaca_eval_gpt4_turbo_fn \\\n",
      "\t--use_vllm \\\n",
      "\t--use_chat_format \\\n",
      "\t--chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format \\\n",
      "\t--use_slow_tokenizer \\\n",
      "\t--torch_dtype bfloat16\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m eval.alpaca_farm.run_eval \\\n",
      "\t--reference_path alpaca_eval_data \\\n",
      "\t--model_name_or_path \"results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3\" \\\n",
      "\t--max_new_tokens 2048 \\\n",
      "\t--save_dir \"results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\" \\\n",
      "\t--eval_batch_size 10 \\\n",
      "\t--annotators_config alpaca_eval_gpt4_turbo_fn \\\n",
      "\t--use_vllm \\\n",
      "\t--use_chat_format \\\n",
      "\t--chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format \\\n",
      "\t--use_slow_tokenizer \\\n",
      "\t--torch_dtype bfloat16\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m eval.alpaca_farm.run_eval \\\n",
      "\t--reference_path alpaca_eval_data \\\n",
      "\t--model_name_or_path \"results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=el2n:agg=mean_pace=prune:size=30000:ep=3\" \\\n",
      "\t--max_new_tokens 2048 \\\n",
      "\t--save_dir \"results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=el2n:agg=mean_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\" \\\n",
      "\t--eval_batch_size 10 \\\n",
      "\t--annotators_config alpaca_eval_gpt4_turbo_fn \\\n",
      "\t--use_vllm \\\n",
      "\t--use_chat_format \\\n",
      "\t--chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format \\\n",
      "\t--use_slow_tokenizer \\\n",
      "\t--torch_dtype bfloat16\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m eval.alpaca_farm.run_eval \\\n",
      "\t--reference_path alpaca_eval_data \\\n",
      "\t--model_name_or_path \"results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=grad:loraB:l2n_pace=prune:size=30000:ep=3\" \\\n",
      "\t--max_new_tokens 2048 \\\n",
      "\t--save_dir \"results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=grad:loraB:l2n_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\" \\\n",
      "\t--eval_batch_size 10 \\\n",
      "\t--annotators_config alpaca_eval_gpt4_turbo_fn \\\n",
      "\t--use_vllm \\\n",
      "\t--use_chat_format \\\n",
      "\t--chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format \\\n",
      "\t--use_slow_tokenizer \\\n",
      "\t--torch_dtype bfloat16\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m eval.alpaca_farm.run_eval \\\n",
      "\t--reference_path alpaca_eval_data \\\n",
      "\t--model_name_or_path \"results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=log:prob:neg_pace=prune:size=30000:ep=3\" \\\n",
      "\t--max_new_tokens 2048 \\\n",
      "\t--save_dir \"results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=log:prob:neg_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\" \\\n",
      "\t--eval_batch_size 10 \\\n",
      "\t--annotators_config alpaca_eval_gpt4_turbo_fn \\\n",
      "\t--use_vllm \\\n",
      "\t--use_chat_format \\\n",
      "\t--chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format \\\n",
      "\t--use_slow_tokenizer \\\n",
      "\t--torch_dtype bfloat16\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m eval.alpaca_farm.run_eval \\\n",
      "\t--reference_path alpaca_eval_data \\\n",
      "\t--model_name_or_path \"results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=numtoks:input:neg_pace=prune:size=30000:ep=3\" \\\n",
      "\t--max_new_tokens 2048 \\\n",
      "\t--save_dir \"results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=numtoks:input:neg_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\" \\\n",
      "\t--eval_batch_size 10 \\\n",
      "\t--annotators_config alpaca_eval_gpt4_turbo_fn \\\n",
      "\t--use_vllm \\\n",
      "\t--use_chat_format \\\n",
      "\t--chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format \\\n",
      "\t--use_slow_tokenizer \\\n",
      "\t--torch_dtype bfloat16\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m eval.alpaca_farm.run_eval \\\n",
      "\t--reference_path alpaca_eval_data \\\n",
      "\t--model_name_or_path \"results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=numtoks:output:neg_pace=prune:size=30000:ep=3\" \\\n",
      "\t--max_new_tokens 2048 \\\n",
      "\t--save_dir \"results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=numtoks:output:neg_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\" \\\n",
      "\t--eval_batch_size 10 \\\n",
      "\t--annotators_config alpaca_eval_gpt4_turbo_fn \\\n",
      "\t--use_vllm \\\n",
      "\t--use_chat_format \\\n",
      "\t--chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format \\\n",
      "\t--use_slow_tokenizer \\\n",
      "\t--torch_dtype bfloat16\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "python -m eval.alpaca_farm.run_eval \\\n",
      "\t--reference_path alpaca_eval_data \\\n",
      "\t--model_name_or_path \"results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=numtoks:total:neg_pace=prune:size=30000:ep=3\" \\\n",
      "\t--max_new_tokens 2048 \\\n",
      "\t--save_dir \"results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=numtoks:total:neg_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\" \\\n",
      "\t--eval_batch_size 10 \\\n",
      "\t--annotators_config alpaca_eval_gpt4_turbo_fn \\\n",
      "\t--use_vllm \\\n",
      "\t--use_chat_format \\\n",
      "\t--chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format \\\n",
      "\t--use_slow_tokenizer \\\n",
      "\t--torch_dtype bfloat16\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from gen_cmds_utils import remove_all_symlinks, create_unique_symlinks, get_chat_formatting_function, get_resource_for_task, OPENAI_MODEL_LIST\n",
    "\n",
    "\n",
    "create_symlinks = False\n",
    "include_checkpoints = False\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "use_slow_tokenizer = True\n",
    "launch_one_job_per_model = True\n",
    "\n",
    "task_names = [\n",
    "    'mmlu_s=0',\n",
    "    'mmlu_s=5', \n",
    "    'gsm_s=8',\n",
    "    'gsm_s=8_cot',\n",
    "    'bbh_s=3',\n",
    "    'bbh_s=3_cot', # max_datapoints_per_task=40 -> 40min.\n",
    "    'humaneval',\n",
    "    'tydiqa_s=1_cb', # 3min\n",
    "    'tydiqa_s=1_gp',\n",
    "    # 'toxigen', # ~1.5hr\n",
    "#     'alpacafarm_ann=gpt35:turbo:1106',\n",
    "    # 'alpacafarm_ann=chatgpt', # ~$1 per eval.\n",
    "]\n",
    "task_names_chatfmt = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "\n",
    "task_names_mtbench = ['mtbench_ann=gpt:4:1106:preview_chatfmt'] # ann=gpt:4, ann=gpt:3.5:turbo:1106, gpt:4:1106:preview (gpt4-turbo)\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:3.5:turbo:1106_chatfmt'] # for debug sake, prefer gpt4\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:4_chatfmt']\n",
    "# task_names_alpacafarm = ['alpacafarm_ann=chatgpt_chatfmt']\n",
    "task_names_alpacafarm = ['alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt']\n",
    "task_names_chateval = task_names_mtbench + task_names_alpacafarm\n",
    "\n",
    "\n",
    "# # ## baselines eval \n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "# #     'huggyllama/llama-7b', \n",
    "# #     'mistralai/Mistral-7B-v0.1',\n",
    "# #     'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "# #     'NousResearch/Llama-2-7b-hf',\n",
    "# #     'NousResearch/Llama-2-7b-chat-hf',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-beta',\n",
    "# #     'HuggingFaceH4/zephyr-7b-alpha',\n",
    "#     'HuggingFaceH4/zephyr-7b-beta',\n",
    "# #     'codellama/CodeLlama-7b-hf',\n",
    "# #     'codellama/CodeLlama-7b-Python-hf',\n",
    "# #     'codellama/CodeLlama-7b-Instruct-hf',\n",
    "# ]]\n",
    "# # task_names = task_names + task_names_chatfmt\n",
    "# task_names = task_names_mtbench\n",
    "\n",
    "# # oi5\n",
    "# exp_dir = 'results/oi2'\n",
    "# exp_dir = 'results/oi5_flan_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_dolly:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlm50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegpt50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b_debug'\n",
    "# exp_dir = 'results/oi5_stanford_alpaca:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlmv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegptv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_ultrachat200kv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_tulu_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_open_orca_slim:llama-7b'\n",
    "# exp_dir = 'results/dpo1'\n",
    "# exp_dir = 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2'\n",
    "exp_dirs = [\n",
    "#     'results/baselines/huggyllama',\n",
    "    'results/oi2',\n",
    "    'results/oi5_dolly:llama-7b',\n",
    "    'results/oi5_flan_v250k:llama-7b',\n",
    "    'results/oi5_stanford_alpaca50k:llama-7b',\n",
    "    'results/oi5_oasst2:llama-7b',\n",
    "    'results/oi5_wizardlm50k:llama-7b',\n",
    "    'results/oi5_sharegpt50k:llama-7b',\n",
    "    'results/oi5_ultrachat50k:llama-7b',\n",
    "]\n",
    "# exp_dirs = [\n",
    "#     'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2',\n",
    "# ]\n",
    "\n",
    "# subdir_filter_fn = lambda x: 'llama-7b_mix_all50k_ep=2' in x\n",
    "# subdir_filter_fn = lambda x: 'sharegpt' in x and 'prune:size=90000:ep=3' in x and ('vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding' in x or 'vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB' in x)\n",
    "task_names = task_names + task_names_chatfmt;\n",
    "# task_names = ['alpacafarm_ann=alpaca:eval:gpt4_chatfmt']\n",
    "# task_names = ['mtbench_ann=gpt:4_chatfmt'] \n",
    "task_names = task_names_alpacafarm; \n",
    "# task_names = task_names_mtbench\n",
    "# task_names = task_names + task_names_chatfmt + task_names_mtbench\n",
    "# task_names = task_names\n",
    "# task_names = ['alpacafarm_ann=gpt35:turbo:1106_chatfmt']\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "num_gpus = 1\n",
    "if arch == 'x86_64': # ccc\n",
    "    gpu_type = 'a100_80gb'; num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus)\n",
    "    use_vllm = True; torch_dtype = 'bfloat16'\n",
    "else:\n",
    "    gpu_type = 'v100'\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    use_vllm = False; torch_dtype = 'float16'\n",
    "    \n",
    "    \n",
    "if len(subdir_path_list)==0:\n",
    "    subdir_path_list = []\n",
    "    for exp_dir in exp_dirs:\n",
    "        if create_symlinks:\n",
    "            remove_all_symlinks(exp_dir)\n",
    "        subdirs = list(os.listdir(exp_dir))\n",
    "        subdirs = filter(subdir_filter_fn, subdirs)\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(exp_dir, subdir)\n",
    "            if include_checkpoints:\n",
    "                subdir_path_list += glob.glob(os.path.join(subdir_path, 'checkpoint-*'))\n",
    "            if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "                continue\n",
    "            subdir_path_list.append(subdir_path)\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not os.path.islink(subdir_path) and \\\n",
    "                not os.path.isfile(os.path.join(subdir_path, 'eval', task_name, 'metrics.json')):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "                print((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "\n",
    "print('#cmds: ', len(list(task_name_and_model)), '\\n')\n",
    "\n",
    "if create_symlinks:\n",
    "    # create symlink for each directory.\n",
    "    symlink_path_dict = create_unique_symlinks(\n",
    "        list([x[1] for x in task_name_and_model]))\n",
    "    options_list = list(map(lambda x: (x[0], symlink_path_dict[x[1]]), task_name_and_model))\n",
    "else:\n",
    "    options_list = task_name_and_model\n",
    "    \n",
    "    \n",
    "dfo = pd.DataFrame(options_list, columns=['task_name', 'model_name_or_path'])\n",
    "model_and_task_list = dfo.groupby('model_name_or_path')['task_name'].agg(list).to_dict()\n",
    "\n",
    "\n",
    "info = {}  \n",
    "cmds = []\n",
    "for model_name_or_path, task_name_list in model_and_task_list.items():\n",
    "    num_tasks = len(task_name_list)\n",
    "    cmds_per_model = []\n",
    "    for i, task_name in enumerate(task_name_list):\n",
    "        queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else \\\n",
    "            ('alt_7d' if task_name.startswith('mtbench') else 'alt_1h')\n",
    "\n",
    "        use_chat_format = 'chatfmt' in task_name\n",
    "        chat_formatting_function = get_chat_formatting_function(model_name_or_path)\n",
    "\n",
    "        try:\n",
    "            with open(os.path.join(model_name_or_path, 'ft_args.json'), 'r') as f:\n",
    "                ft_args = json.load(f)\n",
    "            # note `model_name_or_path` could be anything, e.g., soft links with arbitrary names.\n",
    "            # but `ft_args_model_name_or_path` indicates the finetuned model name.\n",
    "            if 'model_args' in ft_args:\n",
    "                ft_args_model_name_or_path = ft_args['model_args']['model_name_or_path']\n",
    "            else:\n",
    "                ft_args_model_name_or_path = ft_args['model_name_or_path']\n",
    "        except:\n",
    "            ft_args_model_name_or_path = model_name_or_path\n",
    "\n",
    "        batch_size, job_duration = get_resource_for_task(\n",
    "            task_name, ft_args_model_name_or_path)\n",
    "\n",
    "        job_name = f'eval.{task_name}'\n",
    "        save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "\n",
    "        if task_name.startswith('mmlu'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 5)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.mmlu.run_eval \\\n",
    "                --data_dir data/eval/mmlu \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --ntrain {n_shot} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('gsm'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 8)\n",
    "            # open-instruct used 200 examples. use higher amount to get a more accurate number\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.gsm.run_eval \\\n",
    "                --data_dir data/eval/gsm/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_num_examples 500 \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('bbh'):\n",
    "            max_num_examples_per_task = 40\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 3)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.bbh.run_eval \\\n",
    "                --data_dir data/eval/bbh/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                --n_shot {n_shot} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--max_num_examples_per_task '+str(max_num_examples_per_task) if max_num_examples_per_task else ''} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('humaneval'):\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.codex_humaneval.run_eval \\\n",
    "                --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens 512 \\\n",
    "                --eval_pass_at_ks 1 \\\n",
    "                --unbiased_sampling_size_n 1 \\\n",
    "                --temperature 0.1 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('tydiqa'):\n",
    "            no_context = 'cb' in task_name\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot in [0,1])\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.tydiqa.run_eval \\\n",
    "                --data_dir data/eval/tydiqa \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_num_examples_per_lang 100 \\\n",
    "                --max_context_length 512 \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_context' if no_context else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('toxigen'):\n",
    "            # max_prompts_per_group=500 (out of 1000) is open-instruct default.\n",
    "            # eval batch size=1 much faster (llama-7b) not sure why.\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.toxigen.run_eval \\\n",
    "                --data_dir data/eval/toxigen \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size 3 \\\n",
    "                --max_prompts_per_group 200 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('alpacafarm'):\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            annotators_config = match.group(1)\n",
    "            annotators_config = annotators_config.replace(':', '_')\n",
    "            if not annotators_config in ['chatgpt', 'alpaca_eval_gpt4_0314', 'gpt35_turbo_1106', 'alpaca_eval_gpt4_turbo_fn', 'alpaca_eval_gpt4']:\n",
    "                raise ValueError('Just support 2 annotators_config.')\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.alpaca_farm.run_eval \\\n",
    "                --reference_path alpaca_eval_data \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --max_new_tokens 2048 \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --annotators_config {annotators_config} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('mtbench'):\n",
    "            assert('chatfmt' in task_name)\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            judge_model = match.group(1).replace(':', '-')\n",
    "            if not judge_model in OPENAI_MODEL_LIST:\n",
    "                raise ValueError('fastchat does not support the judge model.')\n",
    "            os.makedirs(save_dir, exist_ok=True) # since not using python file, make the directory now.\n",
    "            fastchat_mtbench_data_dir = os.path.normpath(os.path.join(open_instruct_dir, '../FastChat/fastchat/llm_judge/data'))\n",
    "            question_file = os.path.join(fastchat_mtbench_data_dir, 'mt_bench/question.jsonl')\n",
    "            rating_file = os.path.join(save_dir, f'{judge_model}_single.jsonl')\n",
    "            question_begin, question_end = (0, 1) if False else (None, None)\n",
    "            model_id = os.path.basename(model_name_or_path) if 'results/baselines' in save_dir else 'tulu'\n",
    "            cmd = \"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_model_answer \\\n",
    "                    --model-path {model_name_or_path} \\\n",
    "                    --model-id {model_id} \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --question-file {question_file} \\\n",
    "                    {'--question-begin '+str(question_begin) if question_begin else ''} \\\n",
    "                    {'--question-end '+str(question_end) if question_end else ''} \\\n",
    "                    --max-new-token 2048 \\\n",
    "                    --answer-file {os.path.join(save_dir, 'model_answer.jsonl')} \\\n",
    "                    --dtype {torch_dtype} \\\n",
    "                && \\\n",
    "            \"\"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_judgment \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --judge-file {os.path.join(fastchat_mtbench_data_dir, 'judge_prompts.jsonl')} \\\n",
    "                    --judge-model {judge_model} \\\n",
    "                    --mode single \\\n",
    "                    --question-file {question_file} \\\n",
    "                    --answer-dir {save_dir} \\\n",
    "                    --ref-answer-dir {os.path.join(fastchat_mtbench_data_dir, 'mt_bench/reference_answer')} \\\n",
    "                    --output-file {rating_file} \\\n",
    "                && \\\n",
    "                python -m fastchat.llm_judge.show_result \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --input-file {rating_file} \\\n",
    "                    --mode single \\\n",
    "                    --save-to-json\n",
    "            \"\"\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'{task_name} not supported.')\n",
    "            \n",
    "        if task_name.startswith('alpacafarm') and (getpass.getuser() not in ('PTFMqngp', 'wpq')):\n",
    "            queue = 'alt_6h'\n",
    "\n",
    "        if test_run:\n",
    "            print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd.strip())]))\n",
    "\n",
    "        cmd = multiline_to_singleline(cmd)\n",
    "        cmds.append(cmd)\n",
    "        cmds_per_model.append(cmd)\n",
    "        \n",
    "        if launch_one_job_per_model:\n",
    "            shell_scripts = shell_scripts_template.format(\n",
    "                conda_env='open-instruct',\n",
    "                cwd=os.path.dirname(os.getcwd()),\n",
    "                cmd=cmd,\n",
    "                log_dir=os.getcwd(),\n",
    "                save_dir=save_dir,\n",
    "            )\n",
    "            if arch == 'x86_64': # ccc\n",
    "                shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "            out = submit_job(\n",
    "                shell_scripts, \n",
    "                job_name=job_name,\n",
    "                num_cpus=num_cpus,\n",
    "                cpu_mem=cpu_mem,\n",
    "                num_gpus=num_gpus,\n",
    "                gpu_type=gpu_type,\n",
    "                test_run=test_run,\n",
    "                job_duration=job_duration,\n",
    "                queue=queue,\n",
    "            )\n",
    "        else:\n",
    "            if i + 1 == num_tasks:\n",
    "                assert(len(cmds_per_model) == num_tasks)\n",
    "                cmd = ' && '.join(cmds_per_model)\n",
    "                if test_run:\n",
    "                    print(cmd)\n",
    "                shell_scripts = shell_scripts_template.format(\n",
    "                    conda_env='open-instruct',\n",
    "                    cwd=os.path.dirname(os.getcwd()),\n",
    "                    cmd=cmd,\n",
    "                    log_dir=os.getcwd(),\n",
    "                    save_dir=os.getcwd(), # just delete afterwards.\n",
    "                )\n",
    "                if arch == 'x86_64': # ccc\n",
    "                    shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "                out = submit_job(\n",
    "                    shell_scripts, \n",
    "                    job_name=f'eval.{os.path.basename(model_name_or_path)}',\n",
    "                    num_cpus=num_cpus,\n",
    "                    cpu_mem=cpu_mem,\n",
    "                    num_gpus=num_gpus,\n",
    "                    gpu_type=gpu_type,\n",
    "                    test_run=test_run,\n",
    "                    job_duration=6,\n",
    "                    queue=None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_6b',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ea7ac978",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_eval.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b3939309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10 --max_new_tokens 2048 --save_dir results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt --eval_batch_size 10 --annotators_config alpaca_eval_gpt4_turbo_fn --use_vllm --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype bfloat16\n",
      "[2024-01-21 21:11:36,716] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:loading data and model...\n",
      "INFO 01-21 21:11:39 llm_engine.py:73] Initializing an LLM engine with config: model='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10', tokenizer='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO 01-21 21:11:39 tokenizer.py:32] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "MegaBlocks not found. Please install it by `pip install megablocks`. Note that MegaBlocks depends on mosaicml-turbo, which only supports Python 3.10 for now.\n",
      "STK not found: please see https://github.com/stanford-futuredata/stk\n",
      "INFO 01-21 21:11:53 llm_engine.py:222] # GPU blocks: 7451, # CPU blocks: 512\n",
      "Processed prompts: 100%|██████████████████████| 805/805 [01:01<00:00, 13.00it/s]\n",
      "INFO:root:Evaluating the llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10-greedy-long outputs.\n",
      "INFO:root:Creating the annotator from `alpaca_eval_gpt4_turbo_fn`.\n",
      "WARNING:root:Saving_path is given but not 'auto', make sure that it's different for different seeds.\n",
      "Annotation chunk:   0%|                                   | 0/7 [00:00<?, ?it/s]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:02<06:07,  2.90s/it]\u001b[A\n",
      "prompt_batches:   2%|▋                          | 3/128 [00:03<01:52,  1.11it/s]\u001b[A\n",
      "prompt_batches:   3%|▊                          | 4/128 [00:06<03:40,  1.78s/it]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/128 [00:11<02:02,  1.04s/it]\u001b[A\n",
      "prompt_batches:   9%|██▍                       | 12/128 [00:14<02:13,  1.15s/it]\u001b[A\n",
      "prompt_batches:  14%|███▋                      | 18/128 [00:14<01:00,  1.81it/s]\u001b[A\n",
      "prompt_batches:  16%|████                      | 20/128 [00:15<01:02,  1.73it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:18<01:16,  1.38it/s]\u001b[A\n",
      "prompt_batches:  18%|████▋                     | 23/128 [00:18<01:08,  1.52it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:21<01:29,  1.16it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/128 [00:21<01:17,  1.31it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:23<01:36,  1.05it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:25<01:27,  1.12it/s]\u001b[A\n",
      "prompt_batches:  25%|██████▌                   | 32/128 [00:29<01:47,  1.12s/it]\u001b[A\n",
      "prompt_batches:  30%|███████▋                  | 38/128 [00:34<01:27,  1.03it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/128 [00:36<01:25,  1.03it/s]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:38<01:15,  1.12it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▎                | 46/128 [00:46<01:56,  1.42s/it]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:47<01:01,  1.21it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▌              | 57/128 [00:49<00:49,  1.43it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▊              | 58/128 [00:50<00:54,  1.29it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 59/128 [00:53<01:04,  1.08it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:54<00:48,  1.36it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▊             | 63/128 [00:55<00:52,  1.23it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 64/128 [00:56<00:56,  1.13it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 65/128 [00:56<00:47,  1.32it/s]\u001b[A\n",
      "prompt_batches:  53%|█████████████▊            | 68/128 [00:58<00:39,  1.53it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [01:11<02:16,  2.36s/it]\u001b[A\n",
      "prompt_batches:  66%|█████████████████▎        | 85/128 [01:11<00:25,  1.69it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:13<00:21,  1.79it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:19<00:37,  1.02it/s]\u001b[A\n",
      "prompt_batches:  78%|███████████████████▌     | 100/128 [01:21<00:16,  1.71it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:25<00:17,  1.45it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:28<00:12,  1.55it/s]\u001b[A\n",
      "prompt_batches:  86%|█████████████████████▍   | 110/128 [01:28<00:10,  1.76it/s]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▎  | 114/128 [01:29<00:06,  2.21it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:30<00:07,  1.70it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 117/128 [01:32<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 119/128 [01:33<00:05,  1.66it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▋ | 121/128 [01:35<00:04,  1.46it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▍| 125/128 [01:36<00:01,  2.04it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 126/128 [01:36<00:01,  1.92it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:37<00:00,  1.31it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 97.8 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  14%|███▊                       | 1/7 [01:37<09:47, 97.89s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:05<12:20,  5.83s/it]\u001b[A\n",
      "prompt_batches:   5%|█▍                         | 7/128 [00:15<03:59,  1.98s/it]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:19<02:12,  1.16s/it]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:19<01:50,  1.02it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:20<01:07,  1.59it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:22<01:22,  1.28it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:23<01:03,  1.63it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/128 [00:24<01:05,  1.56it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:24<00:58,  1.73it/s]\u001b[A\n",
      "prompt_batches:  22%|█████▋                    | 28/128 [00:25<01:02,  1.59it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/128 [00:26<01:06,  1.48it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:26<01:08,  1.42it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▎                   | 31/128 [00:29<01:45,  1.09s/it]\u001b[A\n",
      "prompt_batches:  27%|██████▉                   | 34/128 [00:29<00:52,  1.78it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 36/128 [00:29<00:42,  2.14it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/128 [00:30<00:38,  2.34it/s]\u001b[A\n",
      "prompt_batches:  30%|███████▋                  | 38/128 [00:38<03:11,  2.12s/it]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:40<01:28,  1.04s/it]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:41<00:43,  1.79it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:42<00:36,  2.06it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▏              | 55/128 [00:43<00:40,  1.81it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▌              | 57/128 [00:46<00:54,  1.31it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:47<00:33,  1.97it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 64/128 [00:55<01:15,  1.18s/it]\u001b[A\n",
      "prompt_batches:  56%|██████████████▋           | 72/128 [00:55<00:32,  1.71it/s]\u001b[A\n",
      "prompt_batches:  57%|██████████████▊           | 73/128 [00:56<00:32,  1.71it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 74/128 [01:05<01:23,  1.54s/it]\u001b[A\n",
      "prompt_batches:  67%|█████████████████▍        | 86/128 [01:06<00:24,  1.71it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▋        | 87/128 [01:07<00:23,  1.74it/s]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▉        | 88/128 [01:07<00:21,  1.82it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:08<00:22,  1.76it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:12<00:43,  1.13s/it]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 95/128 [01:13<00:19,  1.67it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:13<00:20,  1.57it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:15<00:25,  1.23it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:17<00:18,  1.44it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:19<00:19,  1.31it/s]\u001b[A\n",
      "prompt_batches:  84%|████████████████████▉    | 107/128 [01:20<00:10,  2.09it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:20<00:10,  1.95it/s]\u001b[A\n",
      "prompt_batches:  86%|█████████████████████▍   | 110/128 [01:22<00:10,  1.67it/s]\u001b[A\n",
      "prompt_batches:  88%|█████████████████████▉   | 112/128 [01:24<00:12,  1.33it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:25<00:07,  1.82it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▋  | 116/128 [01:27<00:08,  1.43it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 117/128 [01:27<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 119/128 [01:28<00:05,  1.71it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▍ | 120/128 [01:30<00:06,  1.17it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:32<00:05,  1.03it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:33<00:00,  1.37it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 93.5 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  29%|███████▋                   | 2/7 [03:11<07:56, 95.40s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:03<07:34,  3.58s/it]\u001b[A\n",
      "prompt_batches:   2%|▍                          | 2/128 [00:06<06:45,  3.22s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/128 [00:07<01:14,  1.60it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/128 [00:08<01:16,  1.54it/s]\u001b[A\n",
      "prompt_batches:   9%|██▏                       | 11/128 [00:09<01:20,  1.45it/s]\u001b[A\n",
      "prompt_batches:   9%|██▍                       | 12/128 [00:10<01:29,  1.30it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:10<01:00,  1.89it/s]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:12<01:07,  1.65it/s]\u001b[A\n",
      "prompt_batches:  13%|███▍                      | 17/128 [00:13<01:10,  1.57it/s]\u001b[A\n",
      "prompt_batches:  14%|███▋                      | 18/128 [00:14<01:21,  1.35it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:15<01:08,  1.57it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:16<01:17,  1.36it/s]\u001b[A\n",
      "prompt_batches:  18%|████▋                     | 23/128 [00:17<01:23,  1.26it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:18<01:07,  1.53it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:20<01:06,  1.51it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:23<01:22,  1.18it/s]\u001b[A\n",
      "prompt_batches:  26%|██████▋                   | 33/128 [00:23<00:54,  1.75it/s]\u001b[A\n",
      "prompt_batches:  27%|███████                   | 35/128 [00:24<00:48,  1.93it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 36/128 [00:25<00:53,  1.73it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/128 [00:25<00:50,  1.82it/s]\u001b[A\n",
      "prompt_batches:  30%|███████▉                  | 39/128 [00:27<00:51,  1.74it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/128 [00:29<01:28,  1.01s/it]\u001b[A\n",
      "prompt_batches:  34%|████████▉                 | 44/128 [00:30<00:42,  1.97it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████▏                | 45/128 [00:32<01:06,  1.24it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▎                | 46/128 [00:32<00:55,  1.47it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▊                | 48/128 [00:32<00:37,  2.12it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▉                | 49/128 [00:34<01:00,  1.30it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:34<00:39,  1.95it/s]\u001b[A\n",
      "prompt_batches:  42%|██████████▉               | 54/128 [00:38<01:00,  1.22it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▏              | 55/128 [00:39<00:57,  1.28it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▍              | 56/128 [00:40<01:05,  1.09it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 59/128 [00:43<01:06,  1.05it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:43<00:40,  1.65it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▊             | 63/128 [00:44<00:40,  1.59it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 65/128 [00:46<00:46,  1.37it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 66/128 [00:46<00:38,  1.61it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▌            | 67/128 [00:46<00:34,  1.78it/s]\u001b[A\n",
      "prompt_batches:  54%|██████████████            | 69/128 [00:47<00:27,  2.11it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [00:49<00:48,  1.18it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▍           | 71/128 [00:50<00:50,  1.13it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▏          | 75/128 [00:51<00:25,  2.05it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▍          | 76/128 [00:54<00:45,  1.14it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████          | 79/128 [00:54<00:28,  1.72it/s]\u001b[A\n",
      "prompt_batches:  63%|████████████████▍         | 81/128 [00:55<00:25,  1.81it/s]\u001b[A\n",
      "prompt_batches:  64%|████████████████▋         | 82/128 [00:57<00:32,  1.42it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 83/128 [01:00<00:55,  1.24s/it]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▉        | 88/128 [01:01<00:22,  1.76it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:02<00:24,  1.60it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 91/128 [01:05<00:33,  1.10it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▋       | 92/128 [01:06<00:35,  1.03it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:07<00:19,  1.63it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:07<00:16,  1.85it/s]\u001b[A\n",
      "prompt_batches:  77%|███████████████████▉      | 98/128 [01:08<00:18,  1.62it/s]\u001b[A\n",
      "prompt_batches:  77%|████████████████████      | 99/128 [01:10<00:25,  1.13it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:11<00:20,  1.29it/s]\u001b[A\n",
      "prompt_batches:  80%|███████████████████▉     | 102/128 [01:12<00:16,  1.55it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 104/128 [01:12<00:14,  1.70it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▌    | 105/128 [01:15<00:22,  1.02it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:16<00:13,  1.53it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▎   | 109/128 [01:17<00:14,  1.33it/s]\u001b[A\n",
      "prompt_batches:  87%|█████████████████████▋   | 111/128 [01:19<00:15,  1.10it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:23<00:11,  1.16it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▋  | 116/128 [01:28<00:18,  1.51s/it]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:29<00:04,  1.36it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:32<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 92.2 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation chunk:  43%|███████████▌               | 3/7 [04:43<06:15, 93.97s/it]INFO:root:Annotating 127 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 127 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/127 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/127 [00:03<07:05,  3.38s/it]\u001b[A\n",
      "prompt_batches:   2%|▍                          | 2/127 [00:04<03:43,  1.79s/it]\u001b[A\n",
      "prompt_batches:   5%|█▎                         | 6/127 [00:04<01:06,  1.81it/s]\u001b[A\n",
      "prompt_batches:   6%|█▍                         | 7/127 [00:06<01:38,  1.22it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/127 [00:06<00:56,  2.05it/s]\u001b[A\n",
      "prompt_batches:   9%|██▎                       | 11/127 [00:10<01:59,  1.03s/it]\u001b[A\n",
      "prompt_batches:  10%|██▋                       | 13/127 [00:11<01:41,  1.12it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/127 [00:12<01:31,  1.24it/s]\u001b[A\n",
      "prompt_batches:  13%|███▍                      | 17/127 [00:14<01:24,  1.30it/s]\u001b[A\n",
      "prompt_batches:  15%|███▉                      | 19/127 [00:15<01:13,  1.48it/s]\u001b[A\n",
      "prompt_batches:  17%|████▎                     | 21/127 [00:15<00:59,  1.77it/s]\u001b[A\n",
      "prompt_batches:  19%|████▉                     | 24/127 [00:18<01:04,  1.59it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/127 [00:19<01:00,  1.66it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/127 [00:23<01:36,  1.02it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/127 [00:24<00:41,  2.16it/s]\u001b[A\n",
      "prompt_batches:  31%|███████▉                  | 39/127 [00:26<00:49,  1.79it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/127 [00:26<00:44,  1.94it/s]\u001b[A\n",
      "prompt_batches:  33%|████████▌                 | 42/127 [00:27<00:39,  2.17it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████                 | 44/127 [00:27<00:32,  2.56it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████▏                | 45/127 [00:28<00:28,  2.84it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▍                | 46/127 [00:28<00:36,  2.23it/s]\u001b[A\n",
      "prompt_batches:  37%|█████████▌                | 47/127 [00:29<00:42,  1.86it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▊                | 48/127 [00:31<01:08,  1.15it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▋               | 52/127 [00:32<00:40,  1.87it/s]\u001b[A\n",
      "prompt_batches:  42%|██████████▊               | 53/127 [00:34<00:47,  1.56it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████               | 54/127 [00:35<00:52,  1.40it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▎              | 55/127 [00:35<00:53,  1.35it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▊              | 58/127 [00:37<00:41,  1.65it/s]\u001b[A\n",
      "prompt_batches:  46%|████████████              | 59/127 [00:37<00:40,  1.68it/s]\u001b[A\n",
      "prompt_batches:  47%|████████████▎             | 60/127 [00:38<00:36,  1.85it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▋             | 62/127 [00:39<00:43,  1.49it/s]\u001b[A\n",
      "prompt_batches:  50%|████████████▉             | 63/127 [00:42<01:10,  1.10s/it]\u001b[A\n",
      "prompt_batches:  54%|█████████████▉            | 68/127 [00:43<00:28,  2.08it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▎           | 70/127 [00:45<00:41,  1.36it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▌           | 71/127 [00:51<01:21,  1.45s/it]\u001b[A\n",
      "prompt_batches:  59%|███████████████▎          | 75/127 [00:52<00:45,  1.15it/s]\u001b[A\n",
      "prompt_batches:  61%|███████████████▊          | 77/127 [00:53<00:37,  1.32it/s]\u001b[A\n",
      "prompt_batches:  63%|████████████████▍         | 80/127 [00:53<00:24,  1.93it/s]\u001b[A\n",
      "prompt_batches:  64%|████████████████▌         | 81/127 [00:55<00:32,  1.43it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 82/127 [00:56<00:34,  1.32it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▉         | 83/127 [00:56<00:29,  1.50it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▌        | 86/127 [00:56<00:17,  2.41it/s]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▊        | 87/127 [00:58<00:25,  1.54it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 90/127 [01:00<00:22,  1.64it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▊       | 92/127 [01:00<00:18,  1.90it/s]\u001b[A\n",
      "prompt_batches:  73%|███████████████████       | 93/127 [01:01<00:17,  1.94it/s]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▏      | 94/127 [01:01<00:17,  1.93it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▍      | 95/127 [01:02<00:15,  2.08it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 96/127 [01:03<00:23,  1.33it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▊      | 97/127 [01:03<00:18,  1.59it/s]\u001b[A\n",
      "prompt_batches:  78%|████████████████████▎     | 99/127 [01:04<00:15,  1.78it/s]\u001b[A\n",
      "prompt_batches:  80%|███████████████████▉     | 101/127 [01:06<00:16,  1.61it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 102/127 [01:08<00:21,  1.16it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▍    | 104/127 [01:10<00:20,  1.10it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 107/127 [01:10<00:11,  1.69it/s]\u001b[A\n",
      "prompt_batches:  87%|█████████████████████▋   | 110/127 [01:16<00:19,  1.13s/it]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 116/127 [01:18<00:07,  1.39it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 121/127 [01:19<00:03,  1.93it/s]\u001b[A\n",
      "prompt_batches:  96%|████████████████████████ | 122/127 [01:21<00:03,  1.47it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 123/127 [01:24<00:03,  1.10it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 127/127 [01:27<00:00,  1.45it/s]\u001b[A\n",
      "INFO:root:Completed 127 examples in 87.5 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation chunk:  57%|███████████████▍           | 4/7 [06:11<04:34, 91.46s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:04<10:20,  4.88s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/128 [00:07<01:36,  1.25it/s]\u001b[A\n",
      "prompt_batches:   7%|█▉                         | 9/128 [00:07<01:24,  1.41it/s]\u001b[A\n",
      "prompt_batches:  10%|██▋                       | 13/128 [00:08<00:53,  2.16it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:10<01:12,  1.57it/s]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:10<01:02,  1.80it/s]\u001b[A\n",
      "prompt_batches:  15%|███▊                      | 19/128 [00:12<01:00,  1.79it/s]\u001b[A\n",
      "prompt_batches:  16%|████                      | 20/128 [00:13<01:08,  1.58it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:13<00:59,  1.79it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:14<00:59,  1.78it/s]\u001b[A\n",
      "prompt_batches:  19%|████▉                     | 24/128 [00:16<01:22,  1.25it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:17<00:54,  1.86it/s]\u001b[A\n",
      "prompt_batches:  22%|█████▋                    | 28/128 [00:18<00:55,  1.79it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/128 [00:18<00:57,  1.72it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:21<01:35,  1.02it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▎                   | 31/128 [00:26<03:17,  2.04s/it]\u001b[A\n",
      "prompt_batches:  32%|████████▎                 | 41/128 [00:29<01:00,  1.44it/s]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:30<00:55,  1.52it/s]\u001b[A\n",
      "prompt_batches:  37%|█████████▌                | 47/128 [00:32<00:51,  1.59it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:33<00:38,  1.99it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▌               | 52/128 [00:36<00:51,  1.48it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:36<00:52,  1.43it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▍              | 56/128 [00:37<00:38,  1.85it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▊              | 58/128 [00:38<00:31,  2.20it/s]\u001b[A\n",
      "prompt_batches:  47%|████████████▏             | 60/128 [00:45<01:26,  1.26s/it]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 66/128 [00:46<00:42,  1.47it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▌            | 67/128 [00:47<00:47,  1.27it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [00:49<00:39,  1.49it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▋           | 72/128 [00:49<00:32,  1.72it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 74/128 [00:52<00:40,  1.35it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▍          | 76/128 [00:52<00:33,  1.55it/s]\u001b[A\n",
      "prompt_batches:  60%|███████████████▋          | 77/128 [00:55<00:46,  1.10it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████          | 79/128 [00:57<00:45,  1.09it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████▎         | 80/128 [00:57<00:42,  1.14it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 83/128 [00:59<00:34,  1.31it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▋        | 87/128 [01:01<00:24,  1.65it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:02<00:21,  1.80it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:02<00:19,  1.98it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 91/128 [01:05<00:39,  1.07s/it]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 95/128 [01:07<00:22,  1.45it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:08<00:24,  1.31it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:09<00:24,  1.27it/s]\u001b[A\n",
      "prompt_batches:  77%|████████████████████      | 99/128 [01:10<00:19,  1.47it/s]\u001b[A\n",
      "prompt_batches:  78%|███████████████████▌     | 100/128 [01:11<00:20,  1.38it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:11<00:18,  1.43it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:12<00:16,  1.54it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 104/128 [01:13<00:17,  1.41it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▌    | 105/128 [01:15<00:22,  1.01it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:18<00:18,  1.07it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▎   | 109/128 [01:20<00:21,  1.12s/it]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▎  | 114/128 [01:22<00:10,  1.35it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:26<00:15,  1.21s/it]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:26<00:03,  1.94it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 124/128 [01:28<00:02,  1.81it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 126/128 [01:29<00:01,  1.73it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:32<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 92.2 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  71%|███████████████████▎       | 5/7 [07:43<03:03, 91.78s/it]INFO:root:Annotating 124 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 124 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/124 [00:04<08:16,  4.04s/it]\u001b[A\n",
      "prompt_batches:   5%|█▎                         | 6/124 [00:05<01:25,  1.38it/s]\u001b[A\n",
      "prompt_batches:   6%|█▌                         | 7/124 [00:07<01:57,  1.00s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/124 [00:07<01:38,  1.18it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/124 [00:08<01:05,  1.73it/s]\u001b[A\n",
      "prompt_batches:  10%|██▌                       | 12/124 [00:10<01:38,  1.14it/s]\u001b[A\n",
      "prompt_batches:  12%|███▏                      | 15/124 [00:11<00:59,  1.84it/s]\u001b[A\n",
      "prompt_batches:  14%|███▌                      | 17/124 [00:13<01:13,  1.46it/s]\u001b[A\n",
      "prompt_batches:  15%|███▉                      | 19/124 [00:15<01:21,  1.28it/s]\u001b[A\n",
      "prompt_batches:  19%|████▊                     | 23/124 [00:16<00:56,  1.80it/s]\u001b[A\n",
      "prompt_batches:  19%|█████                     | 24/124 [00:17<01:09,  1.44it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 26/124 [00:20<01:18,  1.25it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 29/124 [00:20<00:57,  1.66it/s]\u001b[A\n",
      "prompt_batches:  25%|██████▌                   | 31/124 [00:22<00:59,  1.57it/s]\u001b[A\n",
      "prompt_batches:  26%|██████▋                   | 32/124 [00:23<01:08,  1.35it/s]\u001b[A\n",
      "prompt_batches:  27%|██████▉                   | 33/124 [00:24<01:03,  1.44it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 35/124 [00:26<01:11,  1.24it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 36/124 [00:27<01:11,  1.24it/s]\u001b[A\n",
      "prompt_batches:  32%|████████▍                 | 40/124 [00:28<00:42,  1.99it/s]\u001b[A\n",
      "prompt_batches:  33%|████████▌                 | 41/124 [00:29<01:00,  1.38it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▍                | 45/124 [00:32<00:54,  1.46it/s]\u001b[A\n",
      "prompt_batches:  39%|██████████                | 48/124 [00:33<00:39,  1.92it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 49/124 [00:36<01:05,  1.14it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▎              | 54/124 [00:37<00:37,  1.89it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▋              | 56/124 [00:38<00:35,  1.89it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 57/124 [00:40<00:53,  1.25it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▎             | 59/124 [00:40<00:39,  1.63it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 62/124 [00:41<00:31,  1.97it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 63/124 [00:42<00:35,  1.71it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 64/124 [00:43<00:35,  1.71it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▋            | 65/124 [00:44<00:42,  1.38it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▎           | 68/124 [00:45<00:30,  1.85it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▍           | 69/124 [00:46<00:27,  1.97it/s]\u001b[A\n",
      "prompt_batches:  57%|██████████████▉           | 71/124 [00:47<00:31,  1.66it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 72/124 [00:47<00:27,  1.87it/s]\u001b[A\n",
      "prompt_batches:  60%|███████████████▋          | 75/124 [00:54<01:06,  1.35s/it]\u001b[A\n",
      "prompt_batches:  61%|███████████████▉          | 76/124 [00:55<00:54,  1.13s/it]\u001b[A\n",
      "prompt_batches:  65%|████████████████▉         | 81/124 [00:55<00:22,  1.89it/s]\u001b[A\n",
      "prompt_batches:  67%|█████████████████▍        | 83/124 [00:56<00:24,  1.66it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▌        | 84/124 [00:59<00:35,  1.12it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 88/124 [01:00<00:22,  1.61it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▋       | 89/124 [01:00<00:19,  1.77it/s]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 92/124 [01:02<00:18,  1.74it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 93/124 [01:04<00:22,  1.36it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 94/124 [01:05<00:26,  1.12it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████▊     | 99/124 [01:07<00:13,  1.87it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▏    | 100/124 [01:07<00:13,  1.82it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 101/124 [01:08<00:11,  1.95it/s]\u001b[A\n",
      "prompt_batches:  83%|████████████████████▊    | 103/124 [01:08<00:08,  2.44it/s]\u001b[A\n",
      "prompt_batches:  84%|████████████████████▉    | 104/124 [01:09<00:08,  2.41it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▏   | 105/124 [01:12<00:19,  1.02s/it]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▏  | 110/124 [01:16<00:12,  1.11it/s]\u001b[A\n",
      "prompt_batches:  92%|██████████████████████▉  | 114/124 [01:17<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 115/124 [01:17<00:05,  1.62it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▍ | 116/124 [01:19<00:05,  1.40it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▌ | 117/124 [01:19<00:05,  1.38it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 118/124 [01:20<00:04,  1.36it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 120/124 [01:21<00:02,  1.79it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 122/124 [01:23<00:01,  1.27it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 124/124 [01:24<00:00,  1.47it/s]\u001b[A\n",
      "INFO:root:Completed 124 examples in 84.6 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  86%|███████████████████████▏   | 6/7 [09:08<01:29, 89.38s/it]INFO:root:Annotating 37 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 37 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                    | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   3%|▊                           | 1/37 [00:03<02:03,  3.43s/it]\u001b[A\n",
      "prompt_batches:  16%|████▌                       | 6/37 [00:04<00:21,  1.45it/s]\u001b[A\n",
      "prompt_batches:  19%|█████▎                      | 7/37 [00:05<00:19,  1.55it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▊                     | 9/37 [00:07<00:22,  1.26it/s]\u001b[A\n",
      "prompt_batches:  30%|████████                   | 11/37 [00:08<00:17,  1.46it/s]\u001b[A\n",
      "prompt_batches:  32%|████████▊                  | 12/37 [00:11<00:27,  1.08s/it]\u001b[A\n",
      "prompt_batches:  41%|██████████▉                | 15/37 [00:12<00:15,  1.39it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▊             | 19/37 [00:12<00:07,  2.40it/s]\u001b[A\n",
      "prompt_batches:  54%|██████████████▌            | 20/37 [00:14<00:10,  1.61it/s]\u001b[A\n",
      "prompt_batches:  59%|████████████████           | 22/37 [00:15<00:08,  1.77it/s]\u001b[A\n",
      "prompt_batches:  65%|█████████████████▌         | 24/37 [00:17<00:10,  1.28it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▉        | 26/37 [00:20<00:10,  1.03it/s]\u001b[A\n",
      "prompt_batches:  84%|██████████████████████▌    | 31/37 [00:21<00:03,  1.68it/s]\u001b[A\n",
      "prompt_batches:  89%|████████████████████████   | 33/37 [00:24<00:02,  1.36it/s]\u001b[A\n",
      "prompt_batches: 100%|███████████████████████████| 37/37 [00:26<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 37 examples in 26.8 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk: 100%|███████████████████████████| 7/7 [09:35<00:00, 82.20s/it]\n",
      "/dccstor/data-pruning/wpq/github/mitibm2023/external/alpaca_eval/src/alpaca_eval/metrics.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  series_preferences[series_preferences == 0] = 1.5\n",
      "INFO:root:Saving all results to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Price (per-example / total) = 0.0191 / 15.29\n",
      "Time  (per-example / total) = 0.7184 / 574.70\n",
      "                                                                                                                           model  win_rate  standard_error  n_wins  n_wins_base  n_draws  n_total       mode  avg_length  avg_output_tok_length  price\n",
      "0  llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10-greedy-long     19.32            1.39     153          647        5      805  community         607                 172.59  15.29\n",
      "Map: 100%|███████████████████████████| 805/805 [00:00<00:00, 2978.74 examples/s]\n",
      "Filter (num_proc=4): 100%|███████████| 805/805 [00:00<00:00, 4447.74 examples/s]\n",
      "Creating json from Arrow format: 100%|███████████| 1/1 [00:00<00:00, 178.53ba/s]\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3 --max_new_tokens 2048 --save_dir results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt --eval_batch_size 10 --annotators_config alpaca_eval_gpt4_turbo_fn --use_vllm --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype bfloat16\n",
      "[2024-01-21 21:22:39,160] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:loading data and model...\n",
      "INFO 01-21 21:22:41 llm_engine.py:73] Initializing an LLM engine with config: model='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3', tokenizer='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO 01-21 21:22:41 tokenizer.py:32] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "MegaBlocks not found. Please install it by `pip install megablocks`. Note that MegaBlocks depends on mosaicml-turbo, which only supports Python 3.10 for now.\n",
      "STK not found: please see https://github.com/stanford-futuredata/stk\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/eval/alpaca_farm/run_eval.py\", line 160, in <module>\n",
      "    main(args)\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/eval/alpaca_farm/run_eval.py\", line 38, in main\n",
      "    model = vllm.LLM(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/entrypoints/llm.py\", line 93, in __init__\n",
      "    self.llm_engine = LLMEngine.from_engine_args(engine_args)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 246, in from_engine_args\n",
      "    engine = cls(*engine_configs,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 109, in __init__\n",
      "    self._init_workers(distributed_init_method)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 145, in _init_workers\n",
      "    self._run_workers(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 750, in _run_workers\n",
      "    self._run_workers_in_batch(workers, method, *args, **kwargs))\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 724, in _run_workers_in_batch\n",
      "    output = executor(*args, **kwargs)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/worker/worker.py\", line 72, in load_model\n",
      "    self.model_runner.load_model()\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 36, in load_model\n",
      "    self.model = get_model(self.model_config)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/model_loader.py\", line 124, in get_model\n",
      "    model.load_weights(model_config.model, model_config.download_dir,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 335, in load_weights\n",
      "    weight_loader(param, loaded_weight, shard_id)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 303, in weight_loader\n",
      "    param_data.copy_(loaded_weight)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_eval.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859d6d6",
   "metadata": {},
   "source": [
    "# Visualize Eval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1b033ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move ./1397708.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/bbh_s=3_cot_chatfmt/1397708.out.lsf\n",
      "Job ./1388986.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/mmlu_s=0_chatfmt\n",
      "Job ./1389187.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=0_chatfmt\n",
      "Move ./1397603.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3/eval/mmlu_s=5/1397603.out.lsf\n",
      "Move ./1397594.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=5_chatfmt/1397594.out.lsf\n",
      "Move ./1398282.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp/1398282.out.lsf\n",
      "Job ./1397600.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_cb_chatfmt\n",
      "Move ./1397652.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/bbh_s=3/1397652.out.lsf\n",
      "Job ./1394502.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=0\n",
      "Job ./1396996.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "./1394831.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1396995.out exited with error code. --save_dir=results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Move ./1398502.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/1398502.out.lsf\n",
      "Move ./1397699.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/bbh_s=3_cot/1397699.out.lsf\n",
      "Move ./1397702.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_gp/1397702.out.lsf\n",
      "Move ./1398283.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_cb/1398283.out.lsf\n",
      "Job ./1397663.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/humaneval_chatfmt\n",
      "Job ./1388963.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/bbh_s=3\n",
      "Job ./1389159.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp\n",
      "Job ./1397561.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/gsm_s=8_cot\n",
      "./1388921.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1388458.out exited with error code. --save_dir=results/oi2/llama-7b_sharegpt50k_ep=2/eval/mmlu_s=0\n",
      "./1388192.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1397164.out exited with error code. --save_dir=results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/mmlu_s=5\n",
      "Move ./1397678.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/humaneval_chatfmt/1397678.out.lsf\n",
      "Job ./1397644.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/bbh_s=3_cot_chatfmt\n",
      "Job ./1397642.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/gsm_s=8_cot_chatfmt\n",
      "./1394835.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1393671.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/humaneval\n",
      "Job ./1397168.out exited with error code. --save_dir=results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/bbh_s=3_cot\n",
      "Move ./1397655.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_cb/1397655.out.lsf\n",
      "Job ./1397003.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Job ./1396671.out exited with error code. --save_dir=results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/gsm_s=8_chatfmt\n",
      "./1388919.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1397615.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3/eval/bbh_s=3_chatfmt\n",
      "Job ./1388463.out exited with error code. --save_dir=results/oi2/llama-7b_sharegpt50k_ep=2/eval/mmlu_s=5_chatfmt\n",
      "Job ./1397072.out exited with error code. --save_dir=results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3/eval/humaneval\n",
      "Job ./1388948.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/tydiqa_s=1_cb\n",
      "./1396744.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1389161.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/mmlu_s=0_chatfmt\n",
      "Job ./1388971.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/gsm_s=8_cot_chatfmt\n",
      "Job ./1393673.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_gp\n",
      "Move ./1397671.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/tydiqa_s=1_gp/1397671.out.lsf\n",
      "Move ./1397689.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/bbh_s=3_chatfmt/1397689.out.lsf\n",
      "Job ./1394503.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/mmlu_s=0\n",
      "Move ./1397648.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/mmlu_s=0/1397648.out.lsf\n",
      "./1396354.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1396997.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Move ./1398299.out -> /dccstor/data-pruning/results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/1398299.out.lsf\n",
      "Job ./1396413.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp\n",
      "Job ./1393687.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/gsm_s=8_cot\n",
      "Move ./1397703.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/mmlu_s=0_chatfmt/1397703.out.lsf\n",
      "Job ./1397014.out exited with error code. --save_dir=results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "./1397179.out does not have `--save_dir` specified. Probably still running.\n",
      "Move ./1397700.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/humaneval/1397700.out.lsf\n",
      "Job ./1388947.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/humaneval\n",
      "Job ./1389097.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/gsm_s=8_cot\n",
      "Job ./1388991.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/bbh_s=3_cot_chatfmt\n",
      "Job ./1397093.out exited with error code. --save_dir=results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/gsm_s=8\n",
      "Job ./1388976.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp_chatfmt\n",
      "Job ./1396720.out exited with error code. --save_dir=results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3/eval/humaneval\n",
      "Job ./1388969.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=5_chatfmt\n",
      "Job ./1396437.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/bbh_s=3_cot_chatfmt\n",
      "Job ./1397004.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Job ./1393700.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_cb_chatfmt\n",
      "Job ./1389178.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/mmlu_s=5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/model_outputs/sft/llama-7b+lora:r=512:a=11585+proj=4096;/1389415.out.lsf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:816\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './1389415.out' -> '/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/model_outputs/sft/llama-7b+lora:r=512:a=11585+proj=4096;/1389415.out.lsf'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# if job successfully ran, lsf system will generate a summary in log_dir,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# call this function to move lsf summary to save_dir if job is successful.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmove_lsf_job_summary_to_save_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/wpq/github/mitibm2023/src/llm/submit.py:464\u001b[0m, in \u001b[0;36mmove_lsf_job_summary_to_save_dir\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m    462\u001b[0m     target_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, save_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(out_file)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.lsf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    463\u001b[0m     target_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(target_path)\n\u001b[0;32m--> 464\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMove \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExited with exit code\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m t:\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:836\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    834\u001b[0m         rmtree(src)\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 836\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    433\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 434\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m             \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[1;32m    259\u001b[0m                 \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/model_outputs/sft/llama-7b+lora:r=512:a=11585+proj=4096;/1389415.out.lsf'"
     ]
    }
   ],
   "source": [
    "# if job successfully ran, lsf system will generate a summary in log_dir,\n",
    "# call this function to move lsf summary to save_dir if job is successful.\n",
    "move_lsf_job_summary_to_save_dir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "4392e9ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_fmt=mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_00d0d td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_00d0d_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_00d0d_row0_col1, #T_00d0d_row0_col2, #T_00d0d_row0_col3, #T_00d0d_row0_col4, #T_00d0d_row0_col5, #T_00d0d_row0_col6, #T_00d0d_row0_col7, #T_00d0d_row0_col8, #T_00d0d_row0_col9, #T_00d0d_row0_col10, #T_00d0d_row0_col11, #T_00d0d_row0_col12, #T_00d0d_row0_col13, #T_00d0d_row0_col14, #T_00d0d_row0_col15, #T_00d0d_row0_col16, #T_00d0d_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_00d0d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_00d0d_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_00d0d_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_00d0d_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_00d0d_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_00d0d_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_00d0d_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_00d0d_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_00d0d_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_00d0d_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_00d0d_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_00d0d_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_00d0d_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_00d0d_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_00d0d_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_00d0d_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_00d0d_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_00d0d_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_00d0d_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_00d0d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_00d0d_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_00d0d_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_00d0d_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_00d0d_row0_col3\" class=\"data row0 col3\" >0.0</td>\n",
       "      <td id=\"T_00d0d_row0_col4\" class=\"data row0 col4\" >0.1</td>\n",
       "      <td id=\"T_00d0d_row0_col5\" class=\"data row0 col5\" >2011.0</td>\n",
       "      <td id=\"T_00d0d_row0_col6\" class=\"data row0 col6\" >-95.7</td>\n",
       "      <td id=\"T_00d0d_row0_col7\" class=\"data row0 col7\" >31.8</td>\n",
       "      <td id=\"T_00d0d_row0_col8\" class=\"data row0 col8\" >34.5</td>\n",
       "      <td id=\"T_00d0d_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_00d0d_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_00d0d_row0_col11\" class=\"data row0 col11\" >30.6</td>\n",
       "      <td id=\"T_00d0d_row0_col12\" class=\"data row0 col12\" >32.7</td>\n",
       "      <td id=\"T_00d0d_row0_col13\" class=\"data row0 col13\" >9.6</td>\n",
       "      <td id=\"T_00d0d_row0_col14\" class=\"data row0 col14\" >38.4</td>\n",
       "      <td id=\"T_00d0d_row0_col15\" class=\"data row0 col15\" >10.2</td>\n",
       "      <td id=\"T_00d0d_row0_col16\" class=\"data row0 col16\" >163.1</td>\n",
       "      <td id=\"T_00d0d_row0_col17\" class=\"data row0 col17\" >-65.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb4b60eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_17edd td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_17edd_row0_col0, #T_17edd_row1_col0, #T_17edd_row2_col0, #T_17edd_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_17edd_row0_col1, #T_17edd_row0_col2, #T_17edd_row0_col6, #T_17edd_row0_col9, #T_17edd_row0_col11, #T_17edd_row0_col13, #T_17edd_row0_col14, #T_17edd_row0_col17, #T_17edd_row1_col1, #T_17edd_row1_col2, #T_17edd_row1_col15, #T_17edd_row2_col1, #T_17edd_row2_col2, #T_17edd_row2_col7, #T_17edd_row2_col8, #T_17edd_row2_col10, #T_17edd_row3_col1, #T_17edd_row3_col2, #T_17edd_row3_col3, #T_17edd_row3_col4, #T_17edd_row3_col5, #T_17edd_row3_col12, #T_17edd_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17edd_row0_col3, #T_17edd_row0_col4, #T_17edd_row0_col5, #T_17edd_row0_col10, #T_17edd_row0_col12, #T_17edd_row0_col16, #T_17edd_row1_col8, #T_17edd_row2_col6, #T_17edd_row2_col11, #T_17edd_row2_col13, #T_17edd_row2_col14, #T_17edd_row3_col7, #T_17edd_row3_col9, #T_17edd_row3_col15, #T_17edd_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17edd_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17edd_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17edd_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17edd_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17edd_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row2_col3, #T_17edd_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17edd_row2_col5, #T_17edd_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17edd_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17edd_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17edd_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17edd_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17edd_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_17edd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_17edd_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_17edd_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_17edd_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_17edd_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_17edd_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_17edd_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_17edd_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_17edd_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_17edd_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_17edd_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_17edd_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_17edd_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_17edd_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_17edd_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_17edd_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_17edd_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_17edd_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_17edd_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_17edd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_17edd_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_17edd_row0_col1\" class=\"data row0 col1\" >10000.0</td>\n",
       "      <td id=\"T_17edd_row0_col2\" class=\"data row0 col2\" >1000.0</td>\n",
       "      <td id=\"T_17edd_row0_col3\" class=\"data row0 col3\" >22.5</td>\n",
       "      <td id=\"T_17edd_row0_col4\" class=\"data row0 col4\" >22.5</td>\n",
       "      <td id=\"T_17edd_row0_col5\" class=\"data row0 col5\" >155.0</td>\n",
       "      <td id=\"T_17edd_row0_col6\" class=\"data row0 col6\" >-4.8</td>\n",
       "      <td id=\"T_17edd_row0_col7\" class=\"data row0 col7\" >34.7</td>\n",
       "      <td id=\"T_17edd_row0_col8\" class=\"data row0 col8\" >37.0</td>\n",
       "      <td id=\"T_17edd_row0_col9\" class=\"data row0 col9\" >3.4</td>\n",
       "      <td id=\"T_17edd_row0_col10\" class=\"data row0 col10\" >10.0</td>\n",
       "      <td id=\"T_17edd_row0_col11\" class=\"data row0 col11\" >30.9</td>\n",
       "      <td id=\"T_17edd_row0_col12\" class=\"data row0 col12\" >30.1</td>\n",
       "      <td id=\"T_17edd_row0_col13\" class=\"data row0 col13\" >6.4</td>\n",
       "      <td id=\"T_17edd_row0_col14\" class=\"data row0 col14\" >35.4</td>\n",
       "      <td id=\"T_17edd_row0_col15\" class=\"data row0 col15\" >10.4</td>\n",
       "      <td id=\"T_17edd_row0_col16\" class=\"data row0 col16\" >30.3</td>\n",
       "      <td id=\"T_17edd_row0_col17\" class=\"data row0 col17\" >-83.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17edd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_17edd_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_17edd_row1_col1\" class=\"data row1 col1\" >10000.0</td>\n",
       "      <td id=\"T_17edd_row1_col2\" class=\"data row1 col2\" >1000.0</td>\n",
       "      <td id=\"T_17edd_row1_col3\" class=\"data row1 col3\" >19.2</td>\n",
       "      <td id=\"T_17edd_row1_col4\" class=\"data row1 col4\" >19.3</td>\n",
       "      <td id=\"T_17edd_row1_col5\" class=\"data row1 col5\" >95.0</td>\n",
       "      <td id=\"T_17edd_row1_col6\" class=\"data row1 col6\" >-1.9</td>\n",
       "      <td id=\"T_17edd_row1_col7\" class=\"data row1 col7\" >33.3</td>\n",
       "      <td id=\"T_17edd_row1_col8\" class=\"data row1 col8\" >37.1</td>\n",
       "      <td id=\"T_17edd_row1_col9\" class=\"data row1 col9\" >4.6</td>\n",
       "      <td id=\"T_17edd_row1_col10\" class=\"data row1 col10\" >9.4</td>\n",
       "      <td id=\"T_17edd_row1_col11\" class=\"data row1 col11\" >31.4</td>\n",
       "      <td id=\"T_17edd_row1_col12\" class=\"data row1 col12\" >28.7</td>\n",
       "      <td id=\"T_17edd_row1_col13\" class=\"data row1 col13\" >7.3</td>\n",
       "      <td id=\"T_17edd_row1_col14\" class=\"data row1 col14\" >35.9</td>\n",
       "      <td id=\"T_17edd_row1_col15\" class=\"data row1 col15\" >7.5</td>\n",
       "      <td id=\"T_17edd_row1_col16\" class=\"data row1 col16\" >25.1</td>\n",
       "      <td id=\"T_17edd_row1_col17\" class=\"data row1 col17\" >-80.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17edd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_17edd_row2_col0\" class=\"data row2 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_17edd_row2_col1\" class=\"data row2 col1\" >10000.0</td>\n",
       "      <td id=\"T_17edd_row2_col2\" class=\"data row2 col2\" >1000.0</td>\n",
       "      <td id=\"T_17edd_row2_col3\" class=\"data row2 col3\" >15.5</td>\n",
       "      <td id=\"T_17edd_row2_col4\" class=\"data row2 col4\" >15.5</td>\n",
       "      <td id=\"T_17edd_row2_col5\" class=\"data row2 col5\" >67.0</td>\n",
       "      <td id=\"T_17edd_row2_col6\" class=\"data row2 col6\" >-0.2</td>\n",
       "      <td id=\"T_17edd_row2_col7\" class=\"data row2 col7\" >30.9</td>\n",
       "      <td id=\"T_17edd_row2_col8\" class=\"data row2 col8\" >34.8</td>\n",
       "      <td id=\"T_17edd_row2_col9\" class=\"data row2 col9\" >5.0</td>\n",
       "      <td id=\"T_17edd_row2_col10\" class=\"data row2 col10\" >8.4</td>\n",
       "      <td id=\"T_17edd_row2_col11\" class=\"data row2 col11\" >32.9</td>\n",
       "      <td id=\"T_17edd_row2_col12\" class=\"data row2 col12\" >25.7</td>\n",
       "      <td id=\"T_17edd_row2_col13\" class=\"data row2 col13\" >8.0</td>\n",
       "      <td id=\"T_17edd_row2_col14\" class=\"data row2 col14\" >41.0</td>\n",
       "      <td id=\"T_17edd_row2_col15\" class=\"data row2 col15\" >7.9</td>\n",
       "      <td id=\"T_17edd_row2_col16\" class=\"data row2 col16\" >22.5</td>\n",
       "      <td id=\"T_17edd_row2_col17\" class=\"data row2 col17\" >-78.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17edd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_17edd_row3_col0\" class=\"data row3 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_17edd_row3_col1\" class=\"data row3 col1\" >10000.0</td>\n",
       "      <td id=\"T_17edd_row3_col2\" class=\"data row3 col2\" >1000.0</td>\n",
       "      <td id=\"T_17edd_row3_col3\" class=\"data row3 col3\" >14.5</td>\n",
       "      <td id=\"T_17edd_row3_col4\" class=\"data row3 col4\" >14.5</td>\n",
       "      <td id=\"T_17edd_row3_col5\" class=\"data row3 col5\" >55.0</td>\n",
       "      <td id=\"T_17edd_row3_col6\" class=\"data row3 col6\" >-1.1</td>\n",
       "      <td id=\"T_17edd_row3_col7\" class=\"data row3 col7\" >36.7</td>\n",
       "      <td id=\"T_17edd_row3_col8\" class=\"data row3 col8\" >37.1</td>\n",
       "      <td id=\"T_17edd_row3_col9\" class=\"data row3 col9\" >5.6</td>\n",
       "      <td id=\"T_17edd_row3_col10\" class=\"data row3 col10\" >9.0</td>\n",
       "      <td id=\"T_17edd_row3_col11\" class=\"data row3 col11\" >31.6</td>\n",
       "      <td id=\"T_17edd_row3_col12\" class=\"data row3 col12\" >23.0</td>\n",
       "      <td id=\"T_17edd_row3_col13\" class=\"data row3 col13\" >7.4</td>\n",
       "      <td id=\"T_17edd_row3_col14\" class=\"data row3 col14\" >40.0</td>\n",
       "      <td id=\"T_17edd_row3_col15\" class=\"data row3 col15\" >11.0</td>\n",
       "      <td id=\"T_17edd_row3_col16\" class=\"data row3 col16\" >21.9</td>\n",
       "      <td id=\"T_17edd_row3_col17\" class=\"data row3 col17\" >-73.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb6446260>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f5776 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_f5776_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f5776_row0_col1, #T_f5776_row0_col2, #T_f5776_row0_col3, #T_f5776_row0_col4, #T_f5776_row0_col5, #T_f5776_row0_col6, #T_f5776_row0_col7, #T_f5776_row0_col8, #T_f5776_row0_col9, #T_f5776_row0_col10, #T_f5776_row0_col11, #T_f5776_row0_col12, #T_f5776_row0_col13, #T_f5776_row0_col14, #T_f5776_row0_col15, #T_f5776_row0_col16, #T_f5776_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f5776\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5776_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_f5776_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_f5776_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_f5776_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_f5776_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_f5776_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_f5776_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_f5776_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_f5776_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_f5776_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_f5776_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_f5776_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_f5776_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_f5776_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_f5776_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_f5776_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_f5776_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_f5776_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5776_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f5776_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_f5776_row0_col1\" class=\"data row0 col1\" >29912</td>\n",
       "      <td id=\"T_f5776_row0_col2\" class=\"data row0 col2\" >14956</td>\n",
       "      <td id=\"T_f5776_row0_col3\" class=\"data row0 col3\" >11.1</td>\n",
       "      <td id=\"T_f5776_row0_col4\" class=\"data row0 col4\" >11.1</td>\n",
       "      <td id=\"T_f5776_row0_col5\" class=\"data row0 col5\" >53.0</td>\n",
       "      <td id=\"T_f5776_row0_col6\" class=\"data row0 col6\" >-13.3</td>\n",
       "      <td id=\"T_f5776_row0_col7\" class=\"data row0 col7\" >38.5</td>\n",
       "      <td id=\"T_f5776_row0_col8\" class=\"data row0 col8\" >38.5</td>\n",
       "      <td id=\"T_f5776_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_f5776_row0_col10\" class=\"data row0 col10\" >10.8</td>\n",
       "      <td id=\"T_f5776_row0_col11\" class=\"data row0 col11\" >34.0</td>\n",
       "      <td id=\"T_f5776_row0_col12\" class=\"data row0 col12\" >31.3</td>\n",
       "      <td id=\"T_f5776_row0_col13\" class=\"data row0 col13\" >9.0</td>\n",
       "      <td id=\"T_f5776_row0_col14\" class=\"data row0 col14\" >44.0</td>\n",
       "      <td id=\"T_f5776_row0_col15\" class=\"data row0 col15\" >10.4</td>\n",
       "      <td id=\"T_f5776_row0_col16\" class=\"data row0 col16\" >21.8</td>\n",
       "      <td id=\"T_f5776_row0_col17\" class=\"data row0 col17\" >-63.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb4b290c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bb77f td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_bb77f_row0_col0, #T_bb77f_row1_col0, #T_bb77f_row2_col0, #T_bb77f_row3_col0, #T_bb77f_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bb77f_row0_col1, #T_bb77f_row0_col2, #T_bb77f_row0_col14, #T_bb77f_row0_col15, #T_bb77f_row1_col1, #T_bb77f_row1_col2, #T_bb77f_row1_col11, #T_bb77f_row1_col13, #T_bb77f_row1_col15, #T_bb77f_row1_col17, #T_bb77f_row2_col1, #T_bb77f_row2_col2, #T_bb77f_row2_col9, #T_bb77f_row2_col10, #T_bb77f_row3_col1, #T_bb77f_row3_col2, #T_bb77f_row3_col3, #T_bb77f_row3_col4, #T_bb77f_row3_col6, #T_bb77f_row3_col7, #T_bb77f_row3_col8, #T_bb77f_row4_col1, #T_bb77f_row4_col2, #T_bb77f_row4_col5, #T_bb77f_row4_col12, #T_bb77f_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row0_col3, #T_bb77f_row0_col4, #T_bb77f_row0_col5, #T_bb77f_row0_col8, #T_bb77f_row0_col9, #T_bb77f_row0_col12, #T_bb77f_row0_col16, #T_bb77f_row0_col17, #T_bb77f_row1_col10, #T_bb77f_row2_col11, #T_bb77f_row3_col13, #T_bb77f_row3_col14, #T_bb77f_row3_col15, #T_bb77f_row4_col6, #T_bb77f_row4_col7, #T_bb77f_row4_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row0_col11, #T_bb77f_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row1_col3, #T_bb77f_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row2_col3, #T_bb77f_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row2_col12, #T_bb77f_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row3_col10, #T_bb77f_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row4_col3, #T_bb77f_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bb77f_row4_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bb77f_row4_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bb77f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bb77f_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_bb77f_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_bb77f_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_bb77f_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_bb77f_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_bb77f_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_bb77f_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_bb77f_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_bb77f_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_bb77f_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_bb77f_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_bb77f_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_bb77f_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_bb77f_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_bb77f_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_bb77f_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_bb77f_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_bb77f_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bb77f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bb77f_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_bb77f_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_bb77f_row0_col2\" class=\"data row0 col2\" >10000</td>\n",
       "      <td id=\"T_bb77f_row0_col3\" class=\"data row0 col3\" >17.6</td>\n",
       "      <td id=\"T_bb77f_row0_col4\" class=\"data row0 col4\" >17.6</td>\n",
       "      <td id=\"T_bb77f_row0_col5\" class=\"data row0 col5\" >73.0</td>\n",
       "      <td id=\"T_bb77f_row0_col6\" class=\"data row0 col6\" >-8.9</td>\n",
       "      <td id=\"T_bb77f_row0_col7\" class=\"data row0 col7\" >36.6</td>\n",
       "      <td id=\"T_bb77f_row0_col8\" class=\"data row0 col8\" >39.2</td>\n",
       "      <td id=\"T_bb77f_row0_col9\" class=\"data row0 col9\" >5.6</td>\n",
       "      <td id=\"T_bb77f_row0_col10\" class=\"data row0 col10\" >9.6</td>\n",
       "      <td id=\"T_bb77f_row0_col11\" class=\"data row0 col11\" >33.5</td>\n",
       "      <td id=\"T_bb77f_row0_col12\" class=\"data row0 col12\" >33.1</td>\n",
       "      <td id=\"T_bb77f_row0_col13\" class=\"data row0 col13\" >7.5</td>\n",
       "      <td id=\"T_bb77f_row0_col14\" class=\"data row0 col14\" >37.7</td>\n",
       "      <td id=\"T_bb77f_row0_col15\" class=\"data row0 col15\" >10.4</td>\n",
       "      <td id=\"T_bb77f_row0_col16\" class=\"data row0 col16\" >24.0</td>\n",
       "      <td id=\"T_bb77f_row0_col17\" class=\"data row0 col17\" >-68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb77f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bb77f_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_bb77f_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_bb77f_row1_col2\" class=\"data row1 col2\" >10000</td>\n",
       "      <td id=\"T_bb77f_row1_col3\" class=\"data row1 col3\" >15.0</td>\n",
       "      <td id=\"T_bb77f_row1_col4\" class=\"data row1 col4\" >15.0</td>\n",
       "      <td id=\"T_bb77f_row1_col5\" class=\"data row1 col5\" >58.0</td>\n",
       "      <td id=\"T_bb77f_row1_col6\" class=\"data row1 col6\" >-6.8</td>\n",
       "      <td id=\"T_bb77f_row1_col7\" class=\"data row1 col7\" >36.6</td>\n",
       "      <td id=\"T_bb77f_row1_col8\" class=\"data row1 col8\" >37.2</td>\n",
       "      <td id=\"T_bb77f_row1_col9\" class=\"data row1 col9\" >4.0</td>\n",
       "      <td id=\"T_bb77f_row1_col10\" class=\"data row1 col10\" >13.0</td>\n",
       "      <td id=\"T_bb77f_row1_col11\" class=\"data row1 col11\" >30.9</td>\n",
       "      <td id=\"T_bb77f_row1_col12\" class=\"data row1 col12\" >31.5</td>\n",
       "      <td id=\"T_bb77f_row1_col13\" class=\"data row1 col13\" >7.0</td>\n",
       "      <td id=\"T_bb77f_row1_col14\" class=\"data row1 col14\" >41.3</td>\n",
       "      <td id=\"T_bb77f_row1_col15\" class=\"data row1 col15\" >10.4</td>\n",
       "      <td id=\"T_bb77f_row1_col16\" class=\"data row1 col16\" >22.5</td>\n",
       "      <td id=\"T_bb77f_row1_col17\" class=\"data row1 col17\" >-80.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb77f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bb77f_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_bb77f_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_bb77f_row2_col2\" class=\"data row2 col2\" >10000</td>\n",
       "      <td id=\"T_bb77f_row2_col3\" class=\"data row2 col3\" >13.9</td>\n",
       "      <td id=\"T_bb77f_row2_col4\" class=\"data row2 col4\" >13.9</td>\n",
       "      <td id=\"T_bb77f_row2_col5\" class=\"data row2 col5\" >63.0</td>\n",
       "      <td id=\"T_bb77f_row2_col6\" class=\"data row2 col6\" >-9.7</td>\n",
       "      <td id=\"T_bb77f_row2_col7\" class=\"data row2 col7\" >36.9</td>\n",
       "      <td id=\"T_bb77f_row2_col8\" class=\"data row2 col8\" >37.1</td>\n",
       "      <td id=\"T_bb77f_row2_col9\" class=\"data row2 col9\" >3.0</td>\n",
       "      <td id=\"T_bb77f_row2_col10\" class=\"data row2 col10\" >9.4</td>\n",
       "      <td id=\"T_bb77f_row2_col11\" class=\"data row2 col11\" >34.1</td>\n",
       "      <td id=\"T_bb77f_row2_col12\" class=\"data row2 col12\" >30.3</td>\n",
       "      <td id=\"T_bb77f_row2_col13\" class=\"data row2 col13\" >8.0</td>\n",
       "      <td id=\"T_bb77f_row2_col14\" class=\"data row2 col14\" >40.9</td>\n",
       "      <td id=\"T_bb77f_row2_col15\" class=\"data row2 col15\" >10.6</td>\n",
       "      <td id=\"T_bb77f_row2_col16\" class=\"data row2 col16\" >22.4</td>\n",
       "      <td id=\"T_bb77f_row2_col17\" class=\"data row2 col17\" >-77.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb77f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bb77f_row3_col0\" class=\"data row3 col0\" >llama-7b_dolly_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_bb77f_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_bb77f_row3_col2\" class=\"data row3 col2\" >10000</td>\n",
       "      <td id=\"T_bb77f_row3_col3\" class=\"data row3 col3\" >12.0</td>\n",
       "      <td id=\"T_bb77f_row3_col4\" class=\"data row3 col4\" >12.0</td>\n",
       "      <td id=\"T_bb77f_row3_col5\" class=\"data row3 col5\" >65.0</td>\n",
       "      <td id=\"T_bb77f_row3_col6\" class=\"data row3 col6\" >-10.3</td>\n",
       "      <td id=\"T_bb77f_row3_col7\" class=\"data row3 col7\" >36.1</td>\n",
       "      <td id=\"T_bb77f_row3_col8\" class=\"data row3 col8\" >35.0</td>\n",
       "      <td id=\"T_bb77f_row3_col9\" class=\"data row3 col9\" >4.4</td>\n",
       "      <td id=\"T_bb77f_row3_col10\" class=\"data row3 col10\" >10.2</td>\n",
       "      <td id=\"T_bb77f_row3_col11\" class=\"data row3 col11\" >31.2</td>\n",
       "      <td id=\"T_bb77f_row3_col12\" class=\"data row3 col12\" >30.3</td>\n",
       "      <td id=\"T_bb77f_row3_col13\" class=\"data row3 col13\" >8.6</td>\n",
       "      <td id=\"T_bb77f_row3_col14\" class=\"data row3 col14\" >42.1</td>\n",
       "      <td id=\"T_bb77f_row3_col15\" class=\"data row3 col15\" >11.6</td>\n",
       "      <td id=\"T_bb77f_row3_col16\" class=\"data row3 col16\" >22.2</td>\n",
       "      <td id=\"T_bb77f_row3_col17\" class=\"data row3 col17\" >-78.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb77f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_bb77f_row4_col0\" class=\"data row4 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-2:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_bb77f_row4_col1\" class=\"data row4 col1\" >30000</td>\n",
       "      <td id=\"T_bb77f_row4_col2\" class=\"data row4 col2\" >10000</td>\n",
       "      <td id=\"T_bb77f_row4_col3\" class=\"data row4 col3\" >14.0</td>\n",
       "      <td id=\"T_bb77f_row4_col4\" class=\"data row4 col4\" >14.0</td>\n",
       "      <td id=\"T_bb77f_row4_col5\" class=\"data row4 col5\" >43.0</td>\n",
       "      <td id=\"T_bb77f_row4_col6\" class=\"data row4 col6\" >-3.0</td>\n",
       "      <td id=\"T_bb77f_row4_col7\" class=\"data row4 col7\" >38.1</td>\n",
       "      <td id=\"T_bb77f_row4_col8\" class=\"data row4 col8\" >37.1</td>\n",
       "      <td id=\"T_bb77f_row4_col9\" class=\"data row4 col9\" >5.0</td>\n",
       "      <td id=\"T_bb77f_row4_col10\" class=\"data row4 col10\" >10.2</td>\n",
       "      <td id=\"T_bb77f_row4_col11\" class=\"data row4 col11\" >32.0</td>\n",
       "      <td id=\"T_bb77f_row4_col12\" class=\"data row4 col12\" >28.1</td>\n",
       "      <td id=\"T_bb77f_row4_col13\" class=\"data row4 col13\" >8.4</td>\n",
       "      <td id=\"T_bb77f_row4_col14\" class=\"data row4 col14\" >40.4</td>\n",
       "      <td id=\"T_bb77f_row4_col15\" class=\"data row4 col15\" >11.6</td>\n",
       "      <td id=\"T_bb77f_row4_col16\" class=\"data row4 col16\" >21.4</td>\n",
       "      <td id=\"T_bb77f_row4_col17\" class=\"data row4 col17\" >-70.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb4b61b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4c406 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_4c406_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4c406_row0_col1, #T_4c406_row0_col2, #T_4c406_row0_col3, #T_4c406_row0_col4, #T_4c406_row0_col5, #T_4c406_row0_col6, #T_4c406_row0_col7, #T_4c406_row0_col8, #T_4c406_row0_col9, #T_4c406_row0_col10, #T_4c406_row0_col11, #T_4c406_row0_col12, #T_4c406_row0_col13, #T_4c406_row0_col14, #T_4c406_row0_col15, #T_4c406_row0_col16, #T_4c406_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4c406\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4c406_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_4c406_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_4c406_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_4c406_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_4c406_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_4c406_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_4c406_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_4c406_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_4c406_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_4c406_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_4c406_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_4c406_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_4c406_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_4c406_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_4c406_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_4c406_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_4c406_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_4c406_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4c406_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4c406_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=3</td>\n",
       "      <td id=\"T_4c406_row0_col1\" class=\"data row0 col1\" >44868</td>\n",
       "      <td id=\"T_4c406_row0_col2\" class=\"data row0 col2\" >14956</td>\n",
       "      <td id=\"T_4c406_row0_col3\" class=\"data row0 col3\" >14.3</td>\n",
       "      <td id=\"T_4c406_row0_col4\" class=\"data row0 col4\" >14.3</td>\n",
       "      <td id=\"T_4c406_row0_col5\" class=\"data row0 col5\" >59.0</td>\n",
       "      <td id=\"T_4c406_row0_col6\" class=\"data row0 col6\" >-7.2</td>\n",
       "      <td id=\"T_4c406_row0_col7\" class=\"data row0 col7\" >38.7</td>\n",
       "      <td id=\"T_4c406_row0_col8\" class=\"data row0 col8\" >37.9</td>\n",
       "      <td id=\"T_4c406_row0_col9\" class=\"data row0 col9\" >5.0</td>\n",
       "      <td id=\"T_4c406_row0_col10\" class=\"data row0 col10\" >9.8</td>\n",
       "      <td id=\"T_4c406_row0_col11\" class=\"data row0 col11\" >34.1</td>\n",
       "      <td id=\"T_4c406_row0_col12\" class=\"data row0 col12\" >31.8</td>\n",
       "      <td id=\"T_4c406_row0_col13\" class=\"data row0 col13\" >8.4</td>\n",
       "      <td id=\"T_4c406_row0_col14\" class=\"data row0 col14\" >42.0</td>\n",
       "      <td id=\"T_4c406_row0_col15\" class=\"data row0 col15\" >9.1</td>\n",
       "      <td id=\"T_4c406_row0_col16\" class=\"data row0 col16\" >22.9</td>\n",
       "      <td id=\"T_4c406_row0_col17\" class=\"data row0 col17\" >-67.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb6b26e30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0e4f7 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_0e4f7_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0e4f7_row0_col1, #T_0e4f7_row0_col2, #T_0e4f7_row0_col3, #T_0e4f7_row0_col4, #T_0e4f7_row0_col5, #T_0e4f7_row0_col6, #T_0e4f7_row0_col7, #T_0e4f7_row0_col8, #T_0e4f7_row0_col9, #T_0e4f7_row0_col10, #T_0e4f7_row0_col11, #T_0e4f7_row0_col12, #T_0e4f7_row0_col13, #T_0e4f7_row0_col14, #T_0e4f7_row0_col15, #T_0e4f7_row0_col16, #T_0e4f7_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0e4f7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0e4f7_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_0e4f7_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_0e4f7_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_0e4f7_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_0e4f7_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_0e4f7_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_0e4f7_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_0e4f7_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_0e4f7_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_0e4f7_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_0e4f7_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_0e4f7_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_0e4f7_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_0e4f7_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_0e4f7_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_0e4f7_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_0e4f7_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_0e4f7_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0e4f7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0e4f7_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_0e4f7_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_0e4f7_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_0e4f7_row0_col3\" class=\"data row0 col3\" >0.0</td>\n",
       "      <td id=\"T_0e4f7_row0_col4\" class=\"data row0 col4\" >0.1</td>\n",
       "      <td id=\"T_0e4f7_row0_col5\" class=\"data row0 col5\" >2011.0</td>\n",
       "      <td id=\"T_0e4f7_row0_col6\" class=\"data row0 col6\" >-95.7</td>\n",
       "      <td id=\"T_0e4f7_row0_col7\" class=\"data row0 col7\" >31.8</td>\n",
       "      <td id=\"T_0e4f7_row0_col8\" class=\"data row0 col8\" >34.5</td>\n",
       "      <td id=\"T_0e4f7_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_0e4f7_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_0e4f7_row0_col11\" class=\"data row0 col11\" >30.6</td>\n",
       "      <td id=\"T_0e4f7_row0_col12\" class=\"data row0 col12\" >32.7</td>\n",
       "      <td id=\"T_0e4f7_row0_col13\" class=\"data row0 col13\" >9.6</td>\n",
       "      <td id=\"T_0e4f7_row0_col14\" class=\"data row0 col14\" >38.4</td>\n",
       "      <td id=\"T_0e4f7_row0_col15\" class=\"data row0 col15\" >10.2</td>\n",
       "      <td id=\"T_0e4f7_row0_col16\" class=\"data row0 col16\" >163.1</td>\n",
       "      <td id=\"T_0e4f7_row0_col17\" class=\"data row0 col17\" >-65.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb7045840>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_84251 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_84251_row0_col0, #T_84251_row1_col0, #T_84251_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_84251_row0_col1, #T_84251_row0_col2, #T_84251_row0_col6, #T_84251_row0_col7, #T_84251_row0_col8, #T_84251_row0_col11, #T_84251_row1_col1, #T_84251_row1_col2, #T_84251_row1_col5, #T_84251_row2_col1, #T_84251_row2_col2, #T_84251_row2_col3, #T_84251_row2_col4, #T_84251_row2_col5, #T_84251_row2_col9, #T_84251_row2_col10, #T_84251_row2_col12, #T_84251_row2_col13, #T_84251_row2_col14, #T_84251_row2_col15, #T_84251_row2_col16, #T_84251_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84251_row0_col3, #T_84251_row0_col4, #T_84251_row0_col5, #T_84251_row0_col10, #T_84251_row0_col12, #T_84251_row0_col13, #T_84251_row0_col14, #T_84251_row0_col15, #T_84251_row0_col16, #T_84251_row1_col6, #T_84251_row1_col7, #T_84251_row1_col8, #T_84251_row1_col9, #T_84251_row1_col17, #T_84251_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84251_row0_col9, #T_84251_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84251_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84251_row1_col3, #T_84251_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84251_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84251_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84251_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84251_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84251_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84251_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84251_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_84251_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_84251_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_84251\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_84251_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_84251_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_84251_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_84251_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_84251_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_84251_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_84251_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_84251_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_84251_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_84251_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_84251_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_84251_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_84251_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_84251_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_84251_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_84251_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_84251_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_84251_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_84251_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_84251_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_84251_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_84251_row0_col2\" class=\"data row0 col2\" >10000</td>\n",
       "      <td id=\"T_84251_row0_col3\" class=\"data row0 col3\" >7.8</td>\n",
       "      <td id=\"T_84251_row0_col4\" class=\"data row0 col4\" >7.8</td>\n",
       "      <td id=\"T_84251_row0_col5\" class=\"data row0 col5\" >28.0</td>\n",
       "      <td id=\"T_84251_row0_col6\" class=\"data row0 col6\" >-4.8</td>\n",
       "      <td id=\"T_84251_row0_col7\" class=\"data row0 col7\" >34.9</td>\n",
       "      <td id=\"T_84251_row0_col8\" class=\"data row0 col8\" >34.1</td>\n",
       "      <td id=\"T_84251_row0_col9\" class=\"data row0 col9\" >5.0</td>\n",
       "      <td id=\"T_84251_row0_col10\" class=\"data row0 col10\" >15.4</td>\n",
       "      <td id=\"T_84251_row0_col11\" class=\"data row0 col11\" >31.7</td>\n",
       "      <td id=\"T_84251_row0_col12\" class=\"data row0 col12\" >34.0</td>\n",
       "      <td id=\"T_84251_row0_col13\" class=\"data row0 col13\" >8.9</td>\n",
       "      <td id=\"T_84251_row0_col14\" class=\"data row0 col14\" >42.2</td>\n",
       "      <td id=\"T_84251_row0_col15\" class=\"data row0 col15\" >10.6</td>\n",
       "      <td id=\"T_84251_row0_col16\" class=\"data row0 col16\" >19.7</td>\n",
       "      <td id=\"T_84251_row0_col17\" class=\"data row0 col17\" >-70.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84251_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_84251_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v250k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_84251_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_84251_row1_col2\" class=\"data row1 col2\" >10000</td>\n",
       "      <td id=\"T_84251_row1_col3\" class=\"data row1 col3\" >5.1</td>\n",
       "      <td id=\"T_84251_row1_col4\" class=\"data row1 col4\" >5.1</td>\n",
       "      <td id=\"T_84251_row1_col5\" class=\"data row1 col5\" >12.0</td>\n",
       "      <td id=\"T_84251_row1_col6\" class=\"data row1 col6\" >-2.9</td>\n",
       "      <td id=\"T_84251_row1_col7\" class=\"data row1 col7\" >42.0</td>\n",
       "      <td id=\"T_84251_row1_col8\" class=\"data row1 col8\" >42.2</td>\n",
       "      <td id=\"T_84251_row1_col9\" class=\"data row1 col9\" >5.6</td>\n",
       "      <td id=\"T_84251_row1_col10\" class=\"data row1 col10\" >12.0</td>\n",
       "      <td id=\"T_84251_row1_col11\" class=\"data row1 col11\" >33.9</td>\n",
       "      <td id=\"T_84251_row1_col12\" class=\"data row1 col12\" >33.3</td>\n",
       "      <td id=\"T_84251_row1_col13\" class=\"data row1 col13\" >8.1</td>\n",
       "      <td id=\"T_84251_row1_col14\" class=\"data row1 col14\" >38.6</td>\n",
       "      <td id=\"T_84251_row1_col15\" class=\"data row1 col15\" >9.1</td>\n",
       "      <td id=\"T_84251_row1_col16\" class=\"data row1 col16\" >18.8</td>\n",
       "      <td id=\"T_84251_row1_col17\" class=\"data row1 col17\" >-58.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84251_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_84251_row2_col0\" class=\"data row2 col0\" >llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_84251_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_84251_row2_col2\" class=\"data row2 col2\" >10000</td>\n",
       "      <td id=\"T_84251_row2_col3\" class=\"data row2 col3\" >4.3</td>\n",
       "      <td id=\"T_84251_row2_col4\" class=\"data row2 col4\" >4.3</td>\n",
       "      <td id=\"T_84251_row2_col5\" class=\"data row2 col5\" >12.0</td>\n",
       "      <td id=\"T_84251_row2_col6\" class=\"data row2 col6\" >-3.2</td>\n",
       "      <td id=\"T_84251_row2_col7\" class=\"data row2 col7\" >41.6</td>\n",
       "      <td id=\"T_84251_row2_col8\" class=\"data row2 col8\" >40.0</td>\n",
       "      <td id=\"T_84251_row2_col9\" class=\"data row2 col9\" >3.4</td>\n",
       "      <td id=\"T_84251_row2_col10\" class=\"data row2 col10\" >10.8</td>\n",
       "      <td id=\"T_84251_row2_col11\" class=\"data row2 col11\" >36.2</td>\n",
       "      <td id=\"T_84251_row2_col12\" class=\"data row2 col12\" >32.4</td>\n",
       "      <td id=\"T_84251_row2_col13\" class=\"data row2 col13\" >7.4</td>\n",
       "      <td id=\"T_84251_row2_col14\" class=\"data row2 col14\" >37.3</td>\n",
       "      <td id=\"T_84251_row2_col15\" class=\"data row2 col15\" >8.9</td>\n",
       "      <td id=\"T_84251_row2_col16\" class=\"data row2 col16\" >18.1</td>\n",
       "      <td id=\"T_84251_row2_col17\" class=\"data row2 col17\" >-72.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb72a5240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8fdd8 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_8fdd8_row0_col0, #T_8fdd8_row1_col0, #T_8fdd8_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8fdd8_row0_col1, #T_8fdd8_row0_col2, #T_8fdd8_row0_col9, #T_8fdd8_row0_col12, #T_8fdd8_row1_col1, #T_8fdd8_row1_col2, #T_8fdd8_row1_col3, #T_8fdd8_row1_col4, #T_8fdd8_row1_col5, #T_8fdd8_row1_col14, #T_8fdd8_row2_col1, #T_8fdd8_row2_col2, #T_8fdd8_row2_col6, #T_8fdd8_row2_col7, #T_8fdd8_row2_col8, #T_8fdd8_row2_col10, #T_8fdd8_row2_col11, #T_8fdd8_row2_col13, #T_8fdd8_row2_col15, #T_8fdd8_row2_col16, #T_8fdd8_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8fdd8_row0_col3, #T_8fdd8_row0_col4, #T_8fdd8_row0_col5, #T_8fdd8_row0_col6, #T_8fdd8_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8fdd8_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8fdd8_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8fdd8_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8fdd8_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f2c9b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8fdd8_row0_col13, #T_8fdd8_row0_col14, #T_8fdd8_row0_col15, #T_8fdd8_row0_col16, #T_8fdd8_row1_col6, #T_8fdd8_row1_col7, #T_8fdd8_row1_col8, #T_8fdd8_row1_col9, #T_8fdd8_row1_col10, #T_8fdd8_row1_col11, #T_8fdd8_row1_col15, #T_8fdd8_row1_col17, #T_8fdd8_row2_col3, #T_8fdd8_row2_col4, #T_8fdd8_row2_col5, #T_8fdd8_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8fdd8_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8fdd8_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8fdd8_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8fdd8_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8fdd8_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8fdd8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8fdd8_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_8fdd8_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_8fdd8_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_8fdd8_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_8fdd8_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_8fdd8_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_8fdd8_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_8fdd8_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_8fdd8_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_8fdd8_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_8fdd8_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_8fdd8_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_8fdd8_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_8fdd8_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_8fdd8_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_8fdd8_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_8fdd8_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_8fdd8_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8fdd8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8fdd8_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_8fdd8_row0_col1\" class=\"data row0 col1\" >60000</td>\n",
       "      <td id=\"T_8fdd8_row0_col2\" class=\"data row0 col2\" >20000</td>\n",
       "      <td id=\"T_8fdd8_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "      <td id=\"T_8fdd8_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "      <td id=\"T_8fdd8_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_8fdd8_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_8fdd8_row0_col7\" class=\"data row0 col7\" >43.4</td>\n",
       "      <td id=\"T_8fdd8_row0_col8\" class=\"data row0 col8\" >41.5</td>\n",
       "      <td id=\"T_8fdd8_row0_col9\" class=\"data row0 col9\" >3.6</td>\n",
       "      <td id=\"T_8fdd8_row0_col10\" class=\"data row0 col10\" >12.6</td>\n",
       "      <td id=\"T_8fdd8_row0_col11\" class=\"data row0 col11\" >35.3</td>\n",
       "      <td id=\"T_8fdd8_row0_col12\" class=\"data row0 col12\" >32.7</td>\n",
       "      <td id=\"T_8fdd8_row0_col13\" class=\"data row0 col13\" >8.1</td>\n",
       "      <td id=\"T_8fdd8_row0_col14\" class=\"data row0 col14\" >42.8</td>\n",
       "      <td id=\"T_8fdd8_row0_col15\" class=\"data row0 col15\" >9.3</td>\n",
       "      <td id=\"T_8fdd8_row0_col16\" class=\"data row0 col16\" >25.5</td>\n",
       "      <td id=\"T_8fdd8_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fdd8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8fdd8_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_8fdd8_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_8fdd8_row1_col2\" class=\"data row1 col2\" >20000</td>\n",
       "      <td id=\"T_8fdd8_row1_col3\" class=\"data row1 col3\" >4.8</td>\n",
       "      <td id=\"T_8fdd8_row1_col4\" class=\"data row1 col4\" >4.8</td>\n",
       "      <td id=\"T_8fdd8_row1_col5\" class=\"data row1 col5\" >12.0</td>\n",
       "      <td id=\"T_8fdd8_row1_col6\" class=\"data row1 col6\" >-3.7</td>\n",
       "      <td id=\"T_8fdd8_row1_col7\" class=\"data row1 col7\" >44.3</td>\n",
       "      <td id=\"T_8fdd8_row1_col8\" class=\"data row1 col8\" >45.1</td>\n",
       "      <td id=\"T_8fdd8_row1_col9\" class=\"data row1 col9\" >4.4</td>\n",
       "      <td id=\"T_8fdd8_row1_col10\" class=\"data row1 col10\" >14.8</td>\n",
       "      <td id=\"T_8fdd8_row1_col11\" class=\"data row1 col11\" >36.3</td>\n",
       "      <td id=\"T_8fdd8_row1_col12\" class=\"data row1 col12\" >34.3</td>\n",
       "      <td id=\"T_8fdd8_row1_col13\" class=\"data row1 col13\" >8.0</td>\n",
       "      <td id=\"T_8fdd8_row1_col14\" class=\"data row1 col14\" >40.2</td>\n",
       "      <td id=\"T_8fdd8_row1_col15\" class=\"data row1 col15\" >9.3</td>\n",
       "      <td id=\"T_8fdd8_row1_col16\" class=\"data row1 col16\" >19.6</td>\n",
       "      <td id=\"T_8fdd8_row1_col17\" class=\"data row1 col17\" >-57.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fdd8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8fdd8_row2_col0\" class=\"data row2 col0\" >llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_8fdd8_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_8fdd8_row2_col2\" class=\"data row2 col2\" >20000</td>\n",
       "      <td id=\"T_8fdd8_row2_col3\" class=\"data row2 col3\" >5.3</td>\n",
       "      <td id=\"T_8fdd8_row2_col4\" class=\"data row2 col4\" >5.3</td>\n",
       "      <td id=\"T_8fdd8_row2_col5\" class=\"data row2 col5\" >21.0</td>\n",
       "      <td id=\"T_8fdd8_row2_col6\" class=\"data row2 col6\" >-4.2</td>\n",
       "      <td id=\"T_8fdd8_row2_col7\" class=\"data row2 col7\" >40.6</td>\n",
       "      <td id=\"T_8fdd8_row2_col8\" class=\"data row2 col8\" >41.1</td>\n",
       "      <td id=\"T_8fdd8_row2_col9\" class=\"data row2 col9\" >4.0</td>\n",
       "      <td id=\"T_8fdd8_row2_col10\" class=\"data row2 col10\" >12.4</td>\n",
       "      <td id=\"T_8fdd8_row2_col11\" class=\"data row2 col11\" >33.7</td>\n",
       "      <td id=\"T_8fdd8_row2_col12\" class=\"data row2 col12\" >35.6</td>\n",
       "      <td id=\"T_8fdd8_row2_col13\" class=\"data row2 col13\" >7.9</td>\n",
       "      <td id=\"T_8fdd8_row2_col14\" class=\"data row2 col14\" >40.4</td>\n",
       "      <td id=\"T_8fdd8_row2_col15\" class=\"data row2 col15\" >8.7</td>\n",
       "      <td id=\"T_8fdd8_row2_col16\" class=\"data row2 col16\" >19.4</td>\n",
       "      <td id=\"T_8fdd8_row2_col17\" class=\"data row2 col17\" >-64.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb7cfaf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bce16 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_bce16_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bce16_row0_col1, #T_bce16_row0_col2, #T_bce16_row0_col3, #T_bce16_row0_col4, #T_bce16_row0_col5, #T_bce16_row0_col6, #T_bce16_row0_col7, #T_bce16_row0_col8, #T_bce16_row0_col9, #T_bce16_row0_col10, #T_bce16_row0_col11, #T_bce16_row0_col12, #T_bce16_row0_col13, #T_bce16_row0_col14, #T_bce16_row0_col15, #T_bce16_row0_col16, #T_bce16_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bce16\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bce16_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_bce16_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_bce16_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_bce16_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_bce16_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_bce16_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_bce16_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_bce16_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_bce16_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_bce16_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_bce16_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_bce16_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_bce16_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_bce16_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_bce16_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_bce16_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_bce16_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_bce16_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bce16_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bce16_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_bce16_row0_col1\" class=\"data row0 col1\" >100000</td>\n",
       "      <td id=\"T_bce16_row0_col2\" class=\"data row0 col2\" >50000</td>\n",
       "      <td id=\"T_bce16_row0_col3\" class=\"data row0 col3\" >4.2</td>\n",
       "      <td id=\"T_bce16_row0_col4\" class=\"data row0 col4\" >4.2</td>\n",
       "      <td id=\"T_bce16_row0_col5\" class=\"data row0 col5\" >11.0</td>\n",
       "      <td id=\"T_bce16_row0_col6\" class=\"data row0 col6\" >-3.7</td>\n",
       "      <td id=\"T_bce16_row0_col7\" class=\"data row0 col7\" >44.3</td>\n",
       "      <td id=\"T_bce16_row0_col8\" class=\"data row0 col8\" >45.7</td>\n",
       "      <td id=\"T_bce16_row0_col9\" class=\"data row0 col9\" >3.0</td>\n",
       "      <td id=\"T_bce16_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_bce16_row0_col11\" class=\"data row0 col11\" >36.8</td>\n",
       "      <td id=\"T_bce16_row0_col12\" class=\"data row0 col12\" >34.4</td>\n",
       "      <td id=\"T_bce16_row0_col13\" class=\"data row0 col13\" >8.4</td>\n",
       "      <td id=\"T_bce16_row0_col14\" class=\"data row0 col14\" >43.3</td>\n",
       "      <td id=\"T_bce16_row0_col15\" class=\"data row0 col15\" >8.5</td>\n",
       "      <td id=\"T_bce16_row0_col16\" class=\"data row0 col16\" >19.4</td>\n",
       "      <td id=\"T_bce16_row0_col17\" class=\"data row0 col17\" >-61.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb441e320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f8c99 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_f8c99_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f8c99_row0_col1, #T_f8c99_row0_col2, #T_f8c99_row0_col3, #T_f8c99_row0_col4, #T_f8c99_row0_col5, #T_f8c99_row0_col6, #T_f8c99_row0_col7, #T_f8c99_row0_col8, #T_f8c99_row0_col9, #T_f8c99_row0_col10, #T_f8c99_row0_col11, #T_f8c99_row0_col12, #T_f8c99_row0_col13, #T_f8c99_row0_col14, #T_f8c99_row0_col15, #T_f8c99_row0_col16, #T_f8c99_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f8c99\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f8c99_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_f8c99_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_f8c99_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_f8c99_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_f8c99_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_f8c99_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_f8c99_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_f8c99_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_f8c99_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_f8c99_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_f8c99_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_f8c99_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_f8c99_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_f8c99_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_f8c99_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_f8c99_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_f8c99_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_f8c99_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f8c99_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f8c99_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=3</td>\n",
       "      <td id=\"T_f8c99_row0_col1\" class=\"data row0 col1\" >150000</td>\n",
       "      <td id=\"T_f8c99_row0_col2\" class=\"data row0 col2\" >50000</td>\n",
       "      <td id=\"T_f8c99_row0_col3\" class=\"data row0 col3\" >3.9</td>\n",
       "      <td id=\"T_f8c99_row0_col4\" class=\"data row0 col4\" >3.9</td>\n",
       "      <td id=\"T_f8c99_row0_col5\" class=\"data row0 col5\" >12.0</td>\n",
       "      <td id=\"T_f8c99_row0_col6\" class=\"data row0 col6\" >-3.0</td>\n",
       "      <td id=\"T_f8c99_row0_col7\" class=\"data row0 col7\" >44.3</td>\n",
       "      <td id=\"T_f8c99_row0_col8\" class=\"data row0 col8\" >46.5</td>\n",
       "      <td id=\"T_f8c99_row0_col9\" class=\"data row0 col9\" >4.6</td>\n",
       "      <td id=\"T_f8c99_row0_col10\" class=\"data row0 col10\" >13.6</td>\n",
       "      <td id=\"T_f8c99_row0_col11\" class=\"data row0 col11\" >35.0</td>\n",
       "      <td id=\"T_f8c99_row0_col12\" class=\"data row0 col12\" >34.1</td>\n",
       "      <td id=\"T_f8c99_row0_col13\" class=\"data row0 col13\" >7.7</td>\n",
       "      <td id=\"T_f8c99_row0_col14\" class=\"data row0 col14\" >41.1</td>\n",
       "      <td id=\"T_f8c99_row0_col15\" class=\"data row0 col15\" >11.0</td>\n",
       "      <td id=\"T_f8c99_row0_col16\" class=\"data row0 col16\" >19.6</td>\n",
       "      <td id=\"T_f8c99_row0_col17\" class=\"data row0 col17\" >-56.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb466a590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c55f2 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_c55f2_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c55f2_row0_col1, #T_c55f2_row0_col2, #T_c55f2_row0_col3, #T_c55f2_row0_col4, #T_c55f2_row0_col5, #T_c55f2_row0_col6, #T_c55f2_row0_col7, #T_c55f2_row0_col8, #T_c55f2_row0_col9, #T_c55f2_row0_col10, #T_c55f2_row0_col11, #T_c55f2_row0_col12, #T_c55f2_row0_col13, #T_c55f2_row0_col14, #T_c55f2_row0_col15, #T_c55f2_row0_col16, #T_c55f2_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c55f2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c55f2_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_c55f2_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_c55f2_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_c55f2_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_c55f2_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_c55f2_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_c55f2_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_c55f2_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_c55f2_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_c55f2_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_c55f2_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_c55f2_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_c55f2_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_c55f2_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_c55f2_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_c55f2_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_c55f2_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_c55f2_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c55f2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c55f2_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_c55f2_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_c55f2_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_c55f2_row0_col3\" class=\"data row0 col3\" >0.0</td>\n",
       "      <td id=\"T_c55f2_row0_col4\" class=\"data row0 col4\" >0.1</td>\n",
       "      <td id=\"T_c55f2_row0_col5\" class=\"data row0 col5\" >2011.0</td>\n",
       "      <td id=\"T_c55f2_row0_col6\" class=\"data row0 col6\" >-95.7</td>\n",
       "      <td id=\"T_c55f2_row0_col7\" class=\"data row0 col7\" >31.8</td>\n",
       "      <td id=\"T_c55f2_row0_col8\" class=\"data row0 col8\" >34.5</td>\n",
       "      <td id=\"T_c55f2_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_c55f2_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_c55f2_row0_col11\" class=\"data row0 col11\" >30.6</td>\n",
       "      <td id=\"T_c55f2_row0_col12\" class=\"data row0 col12\" >32.7</td>\n",
       "      <td id=\"T_c55f2_row0_col13\" class=\"data row0 col13\" >9.6</td>\n",
       "      <td id=\"T_c55f2_row0_col14\" class=\"data row0 col14\" >38.4</td>\n",
       "      <td id=\"T_c55f2_row0_col15\" class=\"data row0 col15\" >10.2</td>\n",
       "      <td id=\"T_c55f2_row0_col16\" class=\"data row0 col16\" >163.1</td>\n",
       "      <td id=\"T_c55f2_row0_col17\" class=\"data row0 col17\" >-65.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb74e0040>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fd6d4 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_fd6d4_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fd6d4_row0_col1, #T_fd6d4_row0_col2, #T_fd6d4_row0_col3, #T_fd6d4_row0_col4, #T_fd6d4_row0_col5, #T_fd6d4_row0_col6, #T_fd6d4_row0_col7, #T_fd6d4_row0_col8, #T_fd6d4_row0_col9, #T_fd6d4_row0_col10, #T_fd6d4_row0_col11, #T_fd6d4_row0_col12, #T_fd6d4_row0_col13, #T_fd6d4_row0_col14, #T_fd6d4_row0_col15, #T_fd6d4_row0_col16, #T_fd6d4_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fd6d4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fd6d4_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_fd6d4_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_fd6d4_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_fd6d4_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_fd6d4_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_fd6d4_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_fd6d4_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_fd6d4_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_fd6d4_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_fd6d4_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_fd6d4_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_fd6d4_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_fd6d4_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_fd6d4_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_fd6d4_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_fd6d4_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_fd6d4_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_fd6d4_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fd6d4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fd6d4_row0_col0\" class=\"data row0 col0\" >llama-7b_gpt4_alpaca_ep=3</td>\n",
       "      <td id=\"T_fd6d4_row0_col1\" class=\"data row0 col1\" >150000</td>\n",
       "      <td id=\"T_fd6d4_row0_col2\" class=\"data row0 col2\" >50000</td>\n",
       "      <td id=\"T_fd6d4_row0_col3\" class=\"data row0 col3\" >54.6</td>\n",
       "      <td id=\"T_fd6d4_row0_col4\" class=\"data row0 col4\" >54.8</td>\n",
       "      <td id=\"T_fd6d4_row0_col5\" class=\"data row0 col5\" >201.0</td>\n",
       "      <td id=\"T_fd6d4_row0_col6\" class=\"data row0 col6\" >-2.4</td>\n",
       "      <td id=\"T_fd6d4_row0_col7\" class=\"data row0 col7\" >41.0</td>\n",
       "      <td id=\"T_fd6d4_row0_col8\" class=\"data row0 col8\" >40.2</td>\n",
       "      <td id=\"T_fd6d4_row0_col9\" class=\"data row0 col9\" >5.0</td>\n",
       "      <td id=\"T_fd6d4_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_fd6d4_row0_col11\" class=\"data row0 col11\" >33.5</td>\n",
       "      <td id=\"T_fd6d4_row0_col12\" class=\"data row0 col12\" >34.4</td>\n",
       "      <td id=\"T_fd6d4_row0_col13\" class=\"data row0 col13\" >6.0</td>\n",
       "      <td id=\"T_fd6d4_row0_col14\" class=\"data row0 col14\" >24.1</td>\n",
       "      <td id=\"T_fd6d4_row0_col15\" class=\"data row0 col15\" >14.0</td>\n",
       "      <td id=\"T_fd6d4_row0_col16\" class=\"data row0 col16\" >39.8</td>\n",
       "      <td id=\"T_fd6d4_row0_col17\" class=\"data row0 col17\" >-41.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb6bf66b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5d2be td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_5d2be_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5d2be_row0_col1, #T_5d2be_row0_col2, #T_5d2be_row0_col3, #T_5d2be_row0_col4, #T_5d2be_row0_col5, #T_5d2be_row0_col6, #T_5d2be_row0_col7, #T_5d2be_row0_col8, #T_5d2be_row0_col9, #T_5d2be_row0_col10, #T_5d2be_row0_col11, #T_5d2be_row0_col12, #T_5d2be_row0_col13, #T_5d2be_row0_col14, #T_5d2be_row0_col15, #T_5d2be_row0_col16, #T_5d2be_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5d2be\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5d2be_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_5d2be_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_5d2be_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_5d2be_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_5d2be_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_5d2be_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_5d2be_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_5d2be_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_5d2be_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_5d2be_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_5d2be_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_5d2be_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_5d2be_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_5d2be_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_5d2be_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_5d2be_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_5d2be_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_5d2be_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5d2be_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5d2be_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_5d2be_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_5d2be_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_5d2be_row0_col3\" class=\"data row0 col3\" >0.0</td>\n",
       "      <td id=\"T_5d2be_row0_col4\" class=\"data row0 col4\" >0.1</td>\n",
       "      <td id=\"T_5d2be_row0_col5\" class=\"data row0 col5\" >2011.0</td>\n",
       "      <td id=\"T_5d2be_row0_col6\" class=\"data row0 col6\" >-95.7</td>\n",
       "      <td id=\"T_5d2be_row0_col7\" class=\"data row0 col7\" >31.8</td>\n",
       "      <td id=\"T_5d2be_row0_col8\" class=\"data row0 col8\" >34.5</td>\n",
       "      <td id=\"T_5d2be_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_5d2be_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_5d2be_row0_col11\" class=\"data row0 col11\" >30.6</td>\n",
       "      <td id=\"T_5d2be_row0_col12\" class=\"data row0 col12\" >32.7</td>\n",
       "      <td id=\"T_5d2be_row0_col13\" class=\"data row0 col13\" >9.6</td>\n",
       "      <td id=\"T_5d2be_row0_col14\" class=\"data row0 col14\" >38.4</td>\n",
       "      <td id=\"T_5d2be_row0_col15\" class=\"data row0 col15\" >10.2</td>\n",
       "      <td id=\"T_5d2be_row0_col16\" class=\"data row0 col16\" >163.1</td>\n",
       "      <td id=\"T_5d2be_row0_col17\" class=\"data row0 col17\" >-65.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb6ba80a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4bf19 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_4bf19_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4bf19_row0_col1, #T_4bf19_row0_col2, #T_4bf19_row0_col3, #T_4bf19_row0_col4, #T_4bf19_row0_col5, #T_4bf19_row0_col6, #T_4bf19_row0_col7, #T_4bf19_row0_col8, #T_4bf19_row0_col9, #T_4bf19_row0_col10, #T_4bf19_row0_col11, #T_4bf19_row0_col12, #T_4bf19_row0_col13, #T_4bf19_row0_col14, #T_4bf19_row0_col15, #T_4bf19_row0_col16, #T_4bf19_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4bf19\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4bf19_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_4bf19_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_4bf19_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_4bf19_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_4bf19_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_4bf19_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_4bf19_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_4bf19_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_4bf19_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_4bf19_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_4bf19_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_4bf19_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_4bf19_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_4bf19_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_4bf19_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_4bf19_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_4bf19_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_4bf19_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4bf19_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4bf19_row0_col0\" class=\"data row0 col0\" >llama-7b_lima_ep=3</td>\n",
       "      <td id=\"T_4bf19_row0_col1\" class=\"data row0 col1\" >3090</td>\n",
       "      <td id=\"T_4bf19_row0_col2\" class=\"data row0 col2\" >1030</td>\n",
       "      <td id=\"T_4bf19_row0_col3\" class=\"data row0 col3\" >16.8</td>\n",
       "      <td id=\"T_4bf19_row0_col4\" class=\"data row0 col4\" >17.2</td>\n",
       "      <td id=\"T_4bf19_row0_col5\" class=\"data row0 col5\" >226.0</td>\n",
       "      <td id=\"T_4bf19_row0_col6\" class=\"data row0 col6\" >-33.7</td>\n",
       "      <td id=\"T_4bf19_row0_col7\" class=\"data row0 col7\" >25.5</td>\n",
       "      <td id=\"T_4bf19_row0_col8\" class=\"data row0 col8\" >28.2</td>\n",
       "      <td id=\"T_4bf19_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_4bf19_row0_col10\" class=\"data row0 col10\" >9.2</td>\n",
       "      <td id=\"T_4bf19_row0_col11\" class=\"data row0 col11\" >31.0</td>\n",
       "      <td id=\"T_4bf19_row0_col12\" class=\"data row0 col12\" >34.5</td>\n",
       "      <td id=\"T_4bf19_row0_col13\" class=\"data row0 col13\" >9.5</td>\n",
       "      <td id=\"T_4bf19_row0_col14\" class=\"data row0 col14\" >35.1</td>\n",
       "      <td id=\"T_4bf19_row0_col15\" class=\"data row0 col15\" >9.8</td>\n",
       "      <td id=\"T_4bf19_row0_col16\" class=\"data row0 col16\" >31.9</td>\n",
       "      <td id=\"T_4bf19_row0_col17\" class=\"data row0 col17\" >-71.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb5322650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6f71a td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_6f71a_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6f71a_row0_col1, #T_6f71a_row0_col2, #T_6f71a_row0_col3, #T_6f71a_row0_col4, #T_6f71a_row0_col5, #T_6f71a_row0_col6, #T_6f71a_row0_col7, #T_6f71a_row0_col8, #T_6f71a_row0_col9, #T_6f71a_row0_col10, #T_6f71a_row0_col11, #T_6f71a_row0_col12, #T_6f71a_row0_col13, #T_6f71a_row0_col14, #T_6f71a_row0_col15, #T_6f71a_row0_col16, #T_6f71a_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6f71a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6f71a_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_6f71a_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_6f71a_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_6f71a_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_6f71a_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_6f71a_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_6f71a_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_6f71a_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_6f71a_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_6f71a_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_6f71a_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_6f71a_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_6f71a_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_6f71a_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_6f71a_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_6f71a_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_6f71a_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_6f71a_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6f71a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6f71a_row0_col0\" class=\"data row0 col0\" >llama-7b_lima_ep=10</td>\n",
       "      <td id=\"T_6f71a_row0_col1\" class=\"data row0 col1\" >10300</td>\n",
       "      <td id=\"T_6f71a_row0_col2\" class=\"data row0 col2\" >1030</td>\n",
       "      <td id=\"T_6f71a_row0_col3\" class=\"data row0 col3\" >29.1</td>\n",
       "      <td id=\"T_6f71a_row0_col4\" class=\"data row0 col4\" >29.7</td>\n",
       "      <td id=\"T_6f71a_row0_col5\" class=\"data row0 col5\" >231.0</td>\n",
       "      <td id=\"T_6f71a_row0_col6\" class=\"data row0 col6\" >-4.2</td>\n",
       "      <td id=\"T_6f71a_row0_col7\" class=\"data row0 col7\" >25.7</td>\n",
       "      <td id=\"T_6f71a_row0_col8\" class=\"data row0 col8\" >29.6</td>\n",
       "      <td id=\"T_6f71a_row0_col9\" class=\"data row0 col9\" >5.0</td>\n",
       "      <td id=\"T_6f71a_row0_col10\" class=\"data row0 col10\" >11.0</td>\n",
       "      <td id=\"T_6f71a_row0_col11\" class=\"data row0 col11\" >32.2</td>\n",
       "      <td id=\"T_6f71a_row0_col12\" class=\"data row0 col12\" >30.1</td>\n",
       "      <td id=\"T_6f71a_row0_col13\" class=\"data row0 col13\" >7.3</td>\n",
       "      <td id=\"T_6f71a_row0_col14\" class=\"data row0 col14\" >29.2</td>\n",
       "      <td id=\"T_6f71a_row0_col15\" class=\"data row0 col15\" >6.1</td>\n",
       "      <td id=\"T_6f71a_row0_col16\" class=\"data row0 col16\" >35.5</td>\n",
       "      <td id=\"T_6f71a_row0_col17\" class=\"data row0 col17\" >-82.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb4b60130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d9bd4 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_d9bd4_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d9bd4_row0_col1, #T_d9bd4_row0_col2, #T_d9bd4_row0_col3, #T_d9bd4_row0_col4, #T_d9bd4_row0_col5, #T_d9bd4_row0_col6, #T_d9bd4_row0_col7, #T_d9bd4_row0_col8, #T_d9bd4_row0_col9, #T_d9bd4_row0_col10, #T_d9bd4_row0_col11, #T_d9bd4_row0_col12, #T_d9bd4_row0_col13, #T_d9bd4_row0_col14, #T_d9bd4_row0_col15, #T_d9bd4_row0_col16, #T_d9bd4_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d9bd4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d9bd4_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d9bd4_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_d9bd4_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_d9bd4_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_d9bd4_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_d9bd4_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_d9bd4_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_d9bd4_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d9bd4_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d9bd4_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_d9bd4_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_d9bd4_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_d9bd4_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_d9bd4_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d9bd4_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d9bd4_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d9bd4_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_d9bd4_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d9bd4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d9bd4_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_d9bd4_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_d9bd4_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_d9bd4_row0_col3\" class=\"data row0 col3\" >0.0</td>\n",
       "      <td id=\"T_d9bd4_row0_col4\" class=\"data row0 col4\" >0.1</td>\n",
       "      <td id=\"T_d9bd4_row0_col5\" class=\"data row0 col5\" >2011.0</td>\n",
       "      <td id=\"T_d9bd4_row0_col6\" class=\"data row0 col6\" >-95.7</td>\n",
       "      <td id=\"T_d9bd4_row0_col7\" class=\"data row0 col7\" >31.8</td>\n",
       "      <td id=\"T_d9bd4_row0_col8\" class=\"data row0 col8\" >34.5</td>\n",
       "      <td id=\"T_d9bd4_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_d9bd4_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_d9bd4_row0_col11\" class=\"data row0 col11\" >30.6</td>\n",
       "      <td id=\"T_d9bd4_row0_col12\" class=\"data row0 col12\" >32.7</td>\n",
       "      <td id=\"T_d9bd4_row0_col13\" class=\"data row0 col13\" >9.6</td>\n",
       "      <td id=\"T_d9bd4_row0_col14\" class=\"data row0 col14\" >38.4</td>\n",
       "      <td id=\"T_d9bd4_row0_col15\" class=\"data row0 col15\" >10.2</td>\n",
       "      <td id=\"T_d9bd4_row0_col16\" class=\"data row0 col16\" >163.1</td>\n",
       "      <td id=\"T_d9bd4_row0_col17\" class=\"data row0 col17\" >-65.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb7cf8b80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a60c8 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_a60c8_row0_col0, #T_a60c8_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a60c8_row0_col1, #T_a60c8_row0_col2, #T_a60c8_row0_col7, #T_a60c8_row0_col10, #T_a60c8_row0_col12, #T_a60c8_row0_col14, #T_a60c8_row0_col15, #T_a60c8_row1_col1, #T_a60c8_row1_col2, #T_a60c8_row1_col3, #T_a60c8_row1_col4, #T_a60c8_row1_col5, #T_a60c8_row1_col6, #T_a60c8_row1_col8, #T_a60c8_row1_col9, #T_a60c8_row1_col11, #T_a60c8_row1_col13, #T_a60c8_row1_col16, #T_a60c8_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a60c8_row0_col3, #T_a60c8_row0_col4, #T_a60c8_row0_col5, #T_a60c8_row0_col6, #T_a60c8_row0_col8, #T_a60c8_row0_col9, #T_a60c8_row0_col11, #T_a60c8_row0_col13, #T_a60c8_row0_col16, #T_a60c8_row0_col17, #T_a60c8_row1_col7, #T_a60c8_row1_col10, #T_a60c8_row1_col12, #T_a60c8_row1_col14, #T_a60c8_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a60c8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a60c8_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_a60c8_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_a60c8_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_a60c8_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_a60c8_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_a60c8_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_a60c8_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_a60c8_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_a60c8_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_a60c8_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_a60c8_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_a60c8_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_a60c8_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_a60c8_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_a60c8_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_a60c8_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_a60c8_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_a60c8_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a60c8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a60c8_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_a60c8_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_a60c8_row0_col2\" class=\"data row0 col2\" >10000</td>\n",
       "      <td id=\"T_a60c8_row0_col3\" class=\"data row0 col3\" >40.1</td>\n",
       "      <td id=\"T_a60c8_row0_col4\" class=\"data row0 col4\" >40.3</td>\n",
       "      <td id=\"T_a60c8_row0_col5\" class=\"data row0 col5\" >173.0</td>\n",
       "      <td id=\"T_a60c8_row0_col6\" class=\"data row0 col6\" >-8.4</td>\n",
       "      <td id=\"T_a60c8_row0_col7\" class=\"data row0 col7\" >33.1</td>\n",
       "      <td id=\"T_a60c8_row0_col8\" class=\"data row0 col8\" >36.7</td>\n",
       "      <td id=\"T_a60c8_row0_col9\" class=\"data row0 col9\" >6.2</td>\n",
       "      <td id=\"T_a60c8_row0_col10\" class=\"data row0 col10\" >11.0</td>\n",
       "      <td id=\"T_a60c8_row0_col11\" class=\"data row0 col11\" >33.9</td>\n",
       "      <td id=\"T_a60c8_row0_col12\" class=\"data row0 col12\" >32.5</td>\n",
       "      <td id=\"T_a60c8_row0_col13\" class=\"data row0 col13\" >8.0</td>\n",
       "      <td id=\"T_a60c8_row0_col14\" class=\"data row0 col14\" >29.1</td>\n",
       "      <td id=\"T_a60c8_row0_col15\" class=\"data row0 col15\" >7.9</td>\n",
       "      <td id=\"T_a60c8_row0_col16\" class=\"data row0 col16\" >34.1</td>\n",
       "      <td id=\"T_a60c8_row0_col17\" class=\"data row0 col17\" >-68.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a60c8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a60c8_row1_col0\" class=\"data row1 col0\" >llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_a60c8_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_a60c8_row1_col2\" class=\"data row1 col2\" >10000</td>\n",
       "      <td id=\"T_a60c8_row1_col3\" class=\"data row1 col3\" >33.1</td>\n",
       "      <td id=\"T_a60c8_row1_col4\" class=\"data row1 col4\" >33.2</td>\n",
       "      <td id=\"T_a60c8_row1_col5\" class=\"data row1 col5\" >124.0</td>\n",
       "      <td id=\"T_a60c8_row1_col6\" class=\"data row1 col6\" >-8.6</td>\n",
       "      <td id=\"T_a60c8_row1_col7\" class=\"data row1 col7\" >33.7</td>\n",
       "      <td id=\"T_a60c8_row1_col8\" class=\"data row1 col8\" >35.7</td>\n",
       "      <td id=\"T_a60c8_row1_col9\" class=\"data row1 col9\" >5.4</td>\n",
       "      <td id=\"T_a60c8_row1_col10\" class=\"data row1 col10\" >12.4</td>\n",
       "      <td id=\"T_a60c8_row1_col11\" class=\"data row1 col11\" >33.6</td>\n",
       "      <td id=\"T_a60c8_row1_col12\" class=\"data row1 col12\" >34.1</td>\n",
       "      <td id=\"T_a60c8_row1_col13\" class=\"data row1 col13\" >7.4</td>\n",
       "      <td id=\"T_a60c8_row1_col14\" class=\"data row1 col14\" >31.7</td>\n",
       "      <td id=\"T_a60c8_row1_col15\" class=\"data row1 col15\" >11.0</td>\n",
       "      <td id=\"T_a60c8_row1_col16\" class=\"data row1 col16\" >29.7</td>\n",
       "      <td id=\"T_a60c8_row1_col17\" class=\"data row1 col17\" >-68.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb4b60eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d1275 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_d1275_row0_col0, #T_d1275_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d1275_row0_col1, #T_d1275_row0_col2, #T_d1275_row0_col3, #T_d1275_row0_col4, #T_d1275_row0_col6, #T_d1275_row0_col9, #T_d1275_row0_col11, #T_d1275_row0_col15, #T_d1275_row0_col17, #T_d1275_row1_col1, #T_d1275_row1_col2, #T_d1275_row1_col5, #T_d1275_row1_col7, #T_d1275_row1_col8, #T_d1275_row1_col10, #T_d1275_row1_col12, #T_d1275_row1_col13, #T_d1275_row1_col14, #T_d1275_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d1275_row0_col5, #T_d1275_row0_col7, #T_d1275_row0_col8, #T_d1275_row0_col10, #T_d1275_row0_col12, #T_d1275_row0_col13, #T_d1275_row0_col14, #T_d1275_row0_col16, #T_d1275_row1_col3, #T_d1275_row1_col4, #T_d1275_row1_col6, #T_d1275_row1_col9, #T_d1275_row1_col11, #T_d1275_row1_col15, #T_d1275_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d1275\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d1275_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d1275_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_d1275_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_d1275_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_d1275_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_d1275_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_d1275_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_d1275_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d1275_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d1275_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_d1275_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_d1275_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_d1275_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_d1275_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d1275_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d1275_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d1275_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_d1275_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d1275_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d1275_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_d1275_row0_col1\" class=\"data row0 col1\" >60000</td>\n",
       "      <td id=\"T_d1275_row0_col2\" class=\"data row0 col2\" >20000</td>\n",
       "      <td id=\"T_d1275_row0_col3\" class=\"data row0 col3\" >38.4</td>\n",
       "      <td id=\"T_d1275_row0_col4\" class=\"data row0 col4\" >38.7</td>\n",
       "      <td id=\"T_d1275_row0_col5\" class=\"data row0 col5\" >159.0</td>\n",
       "      <td id=\"T_d1275_row0_col6\" class=\"data row0 col6\" >-8.6</td>\n",
       "      <td id=\"T_d1275_row0_col7\" class=\"data row0 col7\" >35.8</td>\n",
       "      <td id=\"T_d1275_row0_col8\" class=\"data row0 col8\" >37.5</td>\n",
       "      <td id=\"T_d1275_row0_col9\" class=\"data row0 col9\" >4.6</td>\n",
       "      <td id=\"T_d1275_row0_col10\" class=\"data row0 col10\" >12.2</td>\n",
       "      <td id=\"T_d1275_row0_col11\" class=\"data row0 col11\" >30.4</td>\n",
       "      <td id=\"T_d1275_row0_col12\" class=\"data row0 col12\" >33.9</td>\n",
       "      <td id=\"T_d1275_row0_col13\" class=\"data row0 col13\" >8.5</td>\n",
       "      <td id=\"T_d1275_row0_col14\" class=\"data row0 col14\" >33.1</td>\n",
       "      <td id=\"T_d1275_row0_col15\" class=\"data row0 col15\" >9.8</td>\n",
       "      <td id=\"T_d1275_row0_col16\" class=\"data row0 col16\" >33.3</td>\n",
       "      <td id=\"T_d1275_row0_col17\" class=\"data row0 col17\" >-66.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1275_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d1275_row1_col0\" class=\"data row1 col0\" >llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_d1275_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_d1275_row1_col2\" class=\"data row1 col2\" >20000</td>\n",
       "      <td id=\"T_d1275_row1_col3\" class=\"data row1 col3\" >40.6</td>\n",
       "      <td id=\"T_d1275_row1_col4\" class=\"data row1 col4\" >40.7</td>\n",
       "      <td id=\"T_d1275_row1_col5\" class=\"data row1 col5\" >146.0</td>\n",
       "      <td id=\"T_d1275_row1_col6\" class=\"data row1 col6\" >-4.2</td>\n",
       "      <td id=\"T_d1275_row1_col7\" class=\"data row1 col7\" >34.5</td>\n",
       "      <td id=\"T_d1275_row1_col8\" class=\"data row1 col8\" >35.7</td>\n",
       "      <td id=\"T_d1275_row1_col9\" class=\"data row1 col9\" >5.4</td>\n",
       "      <td id=\"T_d1275_row1_col10\" class=\"data row1 col10\" >11.0</td>\n",
       "      <td id=\"T_d1275_row1_col11\" class=\"data row1 col11\" >33.7</td>\n",
       "      <td id=\"T_d1275_row1_col12\" class=\"data row1 col12\" >33.7</td>\n",
       "      <td id=\"T_d1275_row1_col13\" class=\"data row1 col13\" >7.6</td>\n",
       "      <td id=\"T_d1275_row1_col14\" class=\"data row1 col14\" >28.9</td>\n",
       "      <td id=\"T_d1275_row1_col15\" class=\"data row1 col15\" >13.0</td>\n",
       "      <td id=\"T_d1275_row1_col16\" class=\"data row1 col16\" >32.8</td>\n",
       "      <td id=\"T_d1275_row1_col17\" class=\"data row1 col17\" >-64.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb7cfb9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e4ccd td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_e4ccd_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e4ccd_row0_col1, #T_e4ccd_row0_col2, #T_e4ccd_row0_col3, #T_e4ccd_row0_col4, #T_e4ccd_row0_col5, #T_e4ccd_row0_col6, #T_e4ccd_row0_col7, #T_e4ccd_row0_col8, #T_e4ccd_row0_col9, #T_e4ccd_row0_col10, #T_e4ccd_row0_col11, #T_e4ccd_row0_col12, #T_e4ccd_row0_col13, #T_e4ccd_row0_col14, #T_e4ccd_row0_col15, #T_e4ccd_row0_col16, #T_e4ccd_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e4ccd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e4ccd_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_e4ccd_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_e4ccd_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_e4ccd_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_e4ccd_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_e4ccd_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_e4ccd_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_e4ccd_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_e4ccd_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_e4ccd_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_e4ccd_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_e4ccd_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_e4ccd_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_e4ccd_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_e4ccd_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_e4ccd_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_e4ccd_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_e4ccd_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e4ccd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e4ccd_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_e4ccd_row0_col1\" class=\"data row0 col1\" >96688</td>\n",
       "      <td id=\"T_e4ccd_row0_col2\" class=\"data row0 col2\" >48344</td>\n",
       "      <td id=\"T_e4ccd_row0_col3\" class=\"data row0 col3\" >38.3</td>\n",
       "      <td id=\"T_e4ccd_row0_col4\" class=\"data row0 col4\" >38.4</td>\n",
       "      <td id=\"T_e4ccd_row0_col5\" class=\"data row0 col5\" >137.0</td>\n",
       "      <td id=\"T_e4ccd_row0_col6\" class=\"data row0 col6\" >-4.6</td>\n",
       "      <td id=\"T_e4ccd_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_e4ccd_row0_col8\" class=\"data row0 col8\" >34.6</td>\n",
       "      <td id=\"T_e4ccd_row0_col9\" class=\"data row0 col9\" >5.2</td>\n",
       "      <td id=\"T_e4ccd_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_e4ccd_row0_col11\" class=\"data row0 col11\" >32.6</td>\n",
       "      <td id=\"T_e4ccd_row0_col12\" class=\"data row0 col12\" >32.8</td>\n",
       "      <td id=\"T_e4ccd_row0_col13\" class=\"data row0 col13\" >8.9</td>\n",
       "      <td id=\"T_e4ccd_row0_col14\" class=\"data row0 col14\" >31.9</td>\n",
       "      <td id=\"T_e4ccd_row0_col15\" class=\"data row0 col15\" >9.8</td>\n",
       "      <td id=\"T_e4ccd_row0_col16\" class=\"data row0 col16\" >31.3</td>\n",
       "      <td id=\"T_e4ccd_row0_col17\" class=\"data row0 col17\" >-71.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb72a5030>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a75f3 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_a75f3_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a75f3_row0_col1, #T_a75f3_row0_col2, #T_a75f3_row0_col3, #T_a75f3_row0_col4, #T_a75f3_row0_col5, #T_a75f3_row0_col6, #T_a75f3_row0_col7, #T_a75f3_row0_col8, #T_a75f3_row0_col9, #T_a75f3_row0_col10, #T_a75f3_row0_col11, #T_a75f3_row0_col12, #T_a75f3_row0_col13, #T_a75f3_row0_col14, #T_a75f3_row0_col15, #T_a75f3_row0_col16, #T_a75f3_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a75f3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a75f3_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_a75f3_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_a75f3_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_a75f3_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_a75f3_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_a75f3_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_a75f3_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_a75f3_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_a75f3_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_a75f3_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_a75f3_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_a75f3_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_a75f3_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_a75f3_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_a75f3_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_a75f3_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_a75f3_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_a75f3_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a75f3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a75f3_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_ep=3</td>\n",
       "      <td id=\"T_a75f3_row0_col1\" class=\"data row0 col1\" >145032</td>\n",
       "      <td id=\"T_a75f3_row0_col2\" class=\"data row0 col2\" >48344</td>\n",
       "      <td id=\"T_a75f3_row0_col3\" class=\"data row0 col3\" >43.6</td>\n",
       "      <td id=\"T_a75f3_row0_col4\" class=\"data row0 col4\" >43.9</td>\n",
       "      <td id=\"T_a75f3_row0_col5\" class=\"data row0 col5\" >163.0</td>\n",
       "      <td id=\"T_a75f3_row0_col6\" class=\"data row0 col6\" >-2.2</td>\n",
       "      <td id=\"T_a75f3_row0_col7\" class=\"data row0 col7\" >34.2</td>\n",
       "      <td id=\"T_a75f3_row0_col8\" class=\"data row0 col8\" >34.8</td>\n",
       "      <td id=\"T_a75f3_row0_col9\" class=\"data row0 col9\" >4.0</td>\n",
       "      <td id=\"T_a75f3_row0_col10\" class=\"data row0 col10\" >12.2</td>\n",
       "      <td id=\"T_a75f3_row0_col11\" class=\"data row0 col11\" >33.5</td>\n",
       "      <td id=\"T_a75f3_row0_col12\" class=\"data row0 col12\" >32.1</td>\n",
       "      <td id=\"T_a75f3_row0_col13\" class=\"data row0 col13\" >8.2</td>\n",
       "      <td id=\"T_a75f3_row0_col14\" class=\"data row0 col14\" >30.6</td>\n",
       "      <td id=\"T_a75f3_row0_col15\" class=\"data row0 col15\" >10.4</td>\n",
       "      <td id=\"T_a75f3_row0_col16\" class=\"data row0 col16\" >34.5</td>\n",
       "      <td id=\"T_a75f3_row0_col17\" class=\"data row0 col17\" >-64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb74e1810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fc1aa td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_fc1aa_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fc1aa_row0_col1, #T_fc1aa_row0_col2, #T_fc1aa_row0_col3, #T_fc1aa_row0_col4, #T_fc1aa_row0_col5, #T_fc1aa_row0_col6, #T_fc1aa_row0_col7, #T_fc1aa_row0_col8, #T_fc1aa_row0_col9, #T_fc1aa_row0_col10, #T_fc1aa_row0_col11, #T_fc1aa_row0_col12, #T_fc1aa_row0_col13, #T_fc1aa_row0_col14, #T_fc1aa_row0_col15, #T_fc1aa_row0_col16, #T_fc1aa_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fc1aa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fc1aa_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_fc1aa_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_fc1aa_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_fc1aa_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_fc1aa_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_fc1aa_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_fc1aa_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_fc1aa_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_fc1aa_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_fc1aa_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_fc1aa_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_fc1aa_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_fc1aa_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_fc1aa_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_fc1aa_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_fc1aa_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_fc1aa_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_fc1aa_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fc1aa_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fc1aa_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_fc1aa_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_fc1aa_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_fc1aa_row0_col3\" class=\"data row0 col3\" >0.0</td>\n",
       "      <td id=\"T_fc1aa_row0_col4\" class=\"data row0 col4\" >0.1</td>\n",
       "      <td id=\"T_fc1aa_row0_col5\" class=\"data row0 col5\" >2011.0</td>\n",
       "      <td id=\"T_fc1aa_row0_col6\" class=\"data row0 col6\" >-95.7</td>\n",
       "      <td id=\"T_fc1aa_row0_col7\" class=\"data row0 col7\" >31.8</td>\n",
       "      <td id=\"T_fc1aa_row0_col8\" class=\"data row0 col8\" >34.5</td>\n",
       "      <td id=\"T_fc1aa_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_fc1aa_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_fc1aa_row0_col11\" class=\"data row0 col11\" >30.6</td>\n",
       "      <td id=\"T_fc1aa_row0_col12\" class=\"data row0 col12\" >32.7</td>\n",
       "      <td id=\"T_fc1aa_row0_col13\" class=\"data row0 col13\" >9.6</td>\n",
       "      <td id=\"T_fc1aa_row0_col14\" class=\"data row0 col14\" >38.4</td>\n",
       "      <td id=\"T_fc1aa_row0_col15\" class=\"data row0 col15\" >10.2</td>\n",
       "      <td id=\"T_fc1aa_row0_col16\" class=\"data row0 col16\" >163.1</td>\n",
       "      <td id=\"T_fc1aa_row0_col17\" class=\"data row0 col17\" >-65.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb7cf8b80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5c163 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_5c163_row0_col0, #T_5c163_row1_col0, #T_5c163_row2_col0, #T_5c163_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5c163_row0_col1, #T_5c163_row0_col2, #T_5c163_row0_col8, #T_5c163_row0_col12, #T_5c163_row1_col1, #T_5c163_row1_col2, #T_5c163_row1_col11, #T_5c163_row2_col1, #T_5c163_row2_col2, #T_5c163_row2_col3, #T_5c163_row2_col4, #T_5c163_row2_col5, #T_5c163_row3_col1, #T_5c163_row3_col2, #T_5c163_row3_col6, #T_5c163_row3_col7, #T_5c163_row3_col9, #T_5c163_row3_col10, #T_5c163_row3_col13, #T_5c163_row3_col14, #T_5c163_row3_col15, #T_5c163_row3_col16, #T_5c163_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c163_row0_col3, #T_5c163_row0_col4, #T_5c163_row0_col5, #T_5c163_row0_col10, #T_5c163_row0_col15, #T_5c163_row0_col16, #T_5c163_row0_col17, #T_5c163_row1_col8, #T_5c163_row1_col12, #T_5c163_row2_col6, #T_5c163_row2_col7, #T_5c163_row2_col9, #T_5c163_row2_col11, #T_5c163_row2_col13, #T_5c163_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c163_row0_col6, #T_5c163_row0_col7, #T_5c163_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c163_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c163_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c163_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c163_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e16751;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c163_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row2_col15, #T_5c163_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c163_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c163_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c163_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c163_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5c163_row3_col8, #T_5c163_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5c163_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5c163\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5c163_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_5c163_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_5c163_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_5c163_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_5c163_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_5c163_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_5c163_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_5c163_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_5c163_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_5c163_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_5c163_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_5c163_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_5c163_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_5c163_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_5c163_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_5c163_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_5c163_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_5c163_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5c163_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5c163_row0_col0\" class=\"data row0 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_5c163_row0_col1\" class=\"data row0 col1\" >10000.0</td>\n",
       "      <td id=\"T_5c163_row0_col2\" class=\"data row0 col2\" >1000.0</td>\n",
       "      <td id=\"T_5c163_row0_col3\" class=\"data row0 col3\" >51.0</td>\n",
       "      <td id=\"T_5c163_row0_col4\" class=\"data row0 col4\" >51.6</td>\n",
       "      <td id=\"T_5c163_row0_col5\" class=\"data row0 col5\" >253.0</td>\n",
       "      <td id=\"T_5c163_row0_col6\" class=\"data row0 col6\" >-2.0</td>\n",
       "      <td id=\"T_5c163_row0_col7\" class=\"data row0 col7\" >30.9</td>\n",
       "      <td id=\"T_5c163_row0_col8\" class=\"data row0 col8\" >33.0</td>\n",
       "      <td id=\"T_5c163_row0_col9\" class=\"data row0 col9\" >6.4</td>\n",
       "      <td id=\"T_5c163_row0_col10\" class=\"data row0 col10\" >13.6</td>\n",
       "      <td id=\"T_5c163_row0_col11\" class=\"data row0 col11\" >33.5</td>\n",
       "      <td id=\"T_5c163_row0_col12\" class=\"data row0 col12\" >30.7</td>\n",
       "      <td id=\"T_5c163_row0_col13\" class=\"data row0 col13\" >7.3</td>\n",
       "      <td id=\"T_5c163_row0_col14\" class=\"data row0 col14\" >28.3</td>\n",
       "      <td id=\"T_5c163_row0_col15\" class=\"data row0 col15\" >12.2</td>\n",
       "      <td id=\"T_5c163_row0_col16\" class=\"data row0 col16\" >42.3</td>\n",
       "      <td id=\"T_5c163_row0_col17\" class=\"data row0 col17\" >-50.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c163_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5c163_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_5c163_row1_col1\" class=\"data row1 col1\" >10000.0</td>\n",
       "      <td id=\"T_5c163_row1_col2\" class=\"data row1 col2\" >1000.0</td>\n",
       "      <td id=\"T_5c163_row1_col3\" class=\"data row1 col3\" >46.8</td>\n",
       "      <td id=\"T_5c163_row1_col4\" class=\"data row1 col4\" >47.0</td>\n",
       "      <td id=\"T_5c163_row1_col5\" class=\"data row1 col5\" >251.0</td>\n",
       "      <td id=\"T_5c163_row1_col6\" class=\"data row1 col6\" >-2.0</td>\n",
       "      <td id=\"T_5c163_row1_col7\" class=\"data row1 col7\" >31.7</td>\n",
       "      <td id=\"T_5c163_row1_col8\" class=\"data row1 col8\" >37.0</td>\n",
       "      <td id=\"T_5c163_row1_col9\" class=\"data row1 col9\" >6.0</td>\n",
       "      <td id=\"T_5c163_row1_col10\" class=\"data row1 col10\" >9.6</td>\n",
       "      <td id=\"T_5c163_row1_col11\" class=\"data row1 col11\" >31.2</td>\n",
       "      <td id=\"T_5c163_row1_col12\" class=\"data row1 col12\" >33.1</td>\n",
       "      <td id=\"T_5c163_row1_col13\" class=\"data row1 col13\" >7.0</td>\n",
       "      <td id=\"T_5c163_row1_col14\" class=\"data row1 col14\" >30.0</td>\n",
       "      <td id=\"T_5c163_row1_col15\" class=\"data row1 col15\" >11.8</td>\n",
       "      <td id=\"T_5c163_row1_col16\" class=\"data row1 col16\" >41.5</td>\n",
       "      <td id=\"T_5c163_row1_col17\" class=\"data row1 col17\" >-58.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c163_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5c163_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_5c163_row2_col1\" class=\"data row2 col1\" >10000.0</td>\n",
       "      <td id=\"T_5c163_row2_col2\" class=\"data row2 col2\" >1000.0</td>\n",
       "      <td id=\"T_5c163_row2_col3\" class=\"data row2 col3\" >42.2</td>\n",
       "      <td id=\"T_5c163_row2_col4\" class=\"data row2 col4\" >42.4</td>\n",
       "      <td id=\"T_5c163_row2_col5\" class=\"data row2 col5\" >205.0</td>\n",
       "      <td id=\"T_5c163_row2_col6\" class=\"data row2 col6\" >-1.7</td>\n",
       "      <td id=\"T_5c163_row2_col7\" class=\"data row2 col7\" >32.9</td>\n",
       "      <td id=\"T_5c163_row2_col8\" class=\"data row2 col8\" >34.7</td>\n",
       "      <td id=\"T_5c163_row2_col9\" class=\"data row2 col9\" >6.8</td>\n",
       "      <td id=\"T_5c163_row2_col10\" class=\"data row2 col10\" >12.0</td>\n",
       "      <td id=\"T_5c163_row2_col11\" class=\"data row2 col11\" >35.0</td>\n",
       "      <td id=\"T_5c163_row2_col12\" class=\"data row2 col12\" >31.4</td>\n",
       "      <td id=\"T_5c163_row2_col13\" class=\"data row2 col13\" >8.9</td>\n",
       "      <td id=\"T_5c163_row2_col14\" class=\"data row2 col14\" >32.1</td>\n",
       "      <td id=\"T_5c163_row2_col15\" class=\"data row2 col15\" >8.7</td>\n",
       "      <td id=\"T_5c163_row2_col16\" class=\"data row2 col16\" >37.7</td>\n",
       "      <td id=\"T_5c163_row2_col17\" class=\"data row2 col17\" >-51.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c163_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5c163_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_5c163_row3_col1\" class=\"data row3 col1\" >10000.0</td>\n",
       "      <td id=\"T_5c163_row3_col2\" class=\"data row3 col2\" >1000.0</td>\n",
       "      <td id=\"T_5c163_row3_col3\" class=\"data row3 col3\" >42.7</td>\n",
       "      <td id=\"T_5c163_row3_col4\" class=\"data row3 col4\" >42.7</td>\n",
       "      <td id=\"T_5c163_row3_col5\" class=\"data row3 col5\" >215.0</td>\n",
       "      <td id=\"T_5c163_row3_col6\" class=\"data row3 col6\" >-2.1</td>\n",
       "      <td id=\"T_5c163_row3_col7\" class=\"data row3 col7\" >29.8</td>\n",
       "      <td id=\"T_5c163_row3_col8\" class=\"data row3 col8\" >35.1</td>\n",
       "      <td id=\"T_5c163_row3_col9\" class=\"data row3 col9\" >4.8</td>\n",
       "      <td id=\"T_5c163_row3_col10\" class=\"data row3 col10\" >9.4</td>\n",
       "      <td id=\"T_5c163_row3_col11\" class=\"data row3 col11\" >32.7</td>\n",
       "      <td id=\"T_5c163_row3_col12\" class=\"data row3 col12\" >31.9</td>\n",
       "      <td id=\"T_5c163_row3_col13\" class=\"data row3 col13\" >6.1</td>\n",
       "      <td id=\"T_5c163_row3_col14\" class=\"data row3 col14\" >24.6</td>\n",
       "      <td id=\"T_5c163_row3_col15\" class=\"data row3 col15\" >8.5</td>\n",
       "      <td id=\"T_5c163_row3_col16\" class=\"data row3 col16\" >37.0</td>\n",
       "      <td id=\"T_5c163_row3_col17\" class=\"data row3 col17\" >-74.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb6bf5a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_44a64 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_44a64_row0_col0, #T_44a64_row1_col0, #T_44a64_row2_col0, #T_44a64_row3_col0, #T_44a64_row4_col0, #T_44a64_row5_col0, #T_44a64_row6_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_44a64_row0_col1, #T_44a64_row0_col2, #T_44a64_row0_col12, #T_44a64_row1_col1, #T_44a64_row1_col2, #T_44a64_row1_col7, #T_44a64_row1_col10, #T_44a64_row2_col1, #T_44a64_row2_col2, #T_44a64_row2_col6, #T_44a64_row2_col11, #T_44a64_row2_col15, #T_44a64_row3_col1, #T_44a64_row3_col2, #T_44a64_row3_col9, #T_44a64_row4_col1, #T_44a64_row4_col2, #T_44a64_row5_col1, #T_44a64_row5_col2, #T_44a64_row5_col12, #T_44a64_row6_col1, #T_44a64_row6_col2, #T_44a64_row6_col3, #T_44a64_row6_col4, #T_44a64_row6_col5, #T_44a64_row6_col8, #T_44a64_row6_col13, #T_44a64_row6_col14, #T_44a64_row6_col16, #T_44a64_row6_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row0_col5, #T_44a64_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row0_col9, #T_44a64_row0_col13, #T_44a64_row0_col14, #T_44a64_row0_col15, #T_44a64_row0_col16, #T_44a64_row0_col17, #T_44a64_row1_col3, #T_44a64_row1_col4, #T_44a64_row1_col5, #T_44a64_row1_col11, #T_44a64_row2_col7, #T_44a64_row2_col14, #T_44a64_row3_col8, #T_44a64_row4_col10, #T_44a64_row5_col6, #T_44a64_row6_col6, #T_44a64_row6_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row1_col9, #T_44a64_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row1_col14, #T_44a64_row5_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row1_col15, #T_44a64_row5_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row1_col16, #T_44a64_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row2_col10, #T_44a64_row6_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row3_col5, #T_44a64_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row3_col16, #T_44a64_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row4_col5, #T_44a64_row5_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row4_col11, #T_44a64_row6_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row4_col13, #T_44a64_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row4_col14, #T_44a64_row5_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row4_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row5_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row5_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row5_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row6_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_44a64_row6_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_44a64_row6_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_44a64\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_44a64_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_44a64_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_44a64_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_44a64_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_44a64_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_44a64_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_44a64_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_44a64_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_44a64_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_44a64_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_44a64_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_44a64_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_44a64_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_44a64_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_44a64_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_44a64_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_44a64_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_44a64_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_44a64_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_44a64_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_score=dppmap:k=acos0:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_44a64_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_44a64_row0_col2\" class=\"data row0 col2\" >10000</td>\n",
       "      <td id=\"T_44a64_row0_col3\" class=\"data row0 col3\" >50.9</td>\n",
       "      <td id=\"T_44a64_row0_col4\" class=\"data row0 col4\" >50.9</td>\n",
       "      <td id=\"T_44a64_row0_col5\" class=\"data row0 col5\" >235.0</td>\n",
       "      <td id=\"T_44a64_row0_col6\" class=\"data row0 col6\" >-5.2</td>\n",
       "      <td id=\"T_44a64_row0_col7\" class=\"data row0 col7\" >35.3</td>\n",
       "      <td id=\"T_44a64_row0_col8\" class=\"data row0 col8\" >37.7</td>\n",
       "      <td id=\"T_44a64_row0_col9\" class=\"data row0 col9\" >7.0</td>\n",
       "      <td id=\"T_44a64_row0_col10\" class=\"data row0 col10\" >13.4</td>\n",
       "      <td id=\"T_44a64_row0_col11\" class=\"data row0 col11\" >33.5</td>\n",
       "      <td id=\"T_44a64_row0_col12\" class=\"data row0 col12\" >33.3</td>\n",
       "      <td id=\"T_44a64_row0_col13\" class=\"data row0 col13\" >9.1</td>\n",
       "      <td id=\"T_44a64_row0_col14\" class=\"data row0 col14\" >33.6</td>\n",
       "      <td id=\"T_44a64_row0_col15\" class=\"data row0 col15\" >14.6</td>\n",
       "      <td id=\"T_44a64_row0_col16\" class=\"data row0 col16\" >42.3</td>\n",
       "      <td id=\"T_44a64_row0_col17\" class=\"data row0 col17\" >-34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44a64_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_44a64_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_44a64_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_44a64_row1_col2\" class=\"data row1 col2\" >10000</td>\n",
       "      <td id=\"T_44a64_row1_col3\" class=\"data row1 col3\" >52.4</td>\n",
       "      <td id=\"T_44a64_row1_col4\" class=\"data row1 col4\" >52.7</td>\n",
       "      <td id=\"T_44a64_row1_col5\" class=\"data row1 col5\" >237.0</td>\n",
       "      <td id=\"T_44a64_row1_col6\" class=\"data row1 col6\" >-3.7</td>\n",
       "      <td id=\"T_44a64_row1_col7\" class=\"data row1 col7\" >33.9</td>\n",
       "      <td id=\"T_44a64_row1_col8\" class=\"data row1 col8\" >35.2</td>\n",
       "      <td id=\"T_44a64_row1_col9\" class=\"data row1 col9\" >5.2</td>\n",
       "      <td id=\"T_44a64_row1_col10\" class=\"data row1 col10\" >11.0</td>\n",
       "      <td id=\"T_44a64_row1_col11\" class=\"data row1 col11\" >34.1</td>\n",
       "      <td id=\"T_44a64_row1_col12\" class=\"data row1 col12\" >34.2</td>\n",
       "      <td id=\"T_44a64_row1_col13\" class=\"data row1 col13\" >8.9</td>\n",
       "      <td id=\"T_44a64_row1_col14\" class=\"data row1 col14\" >32.8</td>\n",
       "      <td id=\"T_44a64_row1_col15\" class=\"data row1 col15\" >14.0</td>\n",
       "      <td id=\"T_44a64_row1_col16\" class=\"data row1 col16\" >42.1</td>\n",
       "      <td id=\"T_44a64_row1_col17\" class=\"data row1 col17\" >-40.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44a64_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_44a64_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_44a64_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_44a64_row2_col2\" class=\"data row2 col2\" >10000</td>\n",
       "      <td id=\"T_44a64_row2_col3\" class=\"data row2 col3\" >48.9</td>\n",
       "      <td id=\"T_44a64_row2_col4\" class=\"data row2 col4\" >49.3</td>\n",
       "      <td id=\"T_44a64_row2_col5\" class=\"data row2 col5\" >216.0</td>\n",
       "      <td id=\"T_44a64_row2_col6\" class=\"data row2 col6\" >-5.5</td>\n",
       "      <td id=\"T_44a64_row2_col7\" class=\"data row2 col7\" >37.9</td>\n",
       "      <td id=\"T_44a64_row2_col8\" class=\"data row2 col8\" >37.7</td>\n",
       "      <td id=\"T_44a64_row2_col9\" class=\"data row2 col9\" >6.0</td>\n",
       "      <td id=\"T_44a64_row2_col10\" class=\"data row2 col10\" >13.0</td>\n",
       "      <td id=\"T_44a64_row2_col11\" class=\"data row2 col11\" >30.6</td>\n",
       "      <td id=\"T_44a64_row2_col12\" class=\"data row2 col12\" >33.9</td>\n",
       "      <td id=\"T_44a64_row2_col13\" class=\"data row2 col13\" >8.7</td>\n",
       "      <td id=\"T_44a64_row2_col14\" class=\"data row2 col14\" >33.6</td>\n",
       "      <td id=\"T_44a64_row2_col15\" class=\"data row2 col15\" >11.4</td>\n",
       "      <td id=\"T_44a64_row2_col16\" class=\"data row2 col16\" >40.1</td>\n",
       "      <td id=\"T_44a64_row2_col17\" class=\"data row2 col17\" >-44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44a64_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_44a64_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_44a64_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_44a64_row3_col2\" class=\"data row3 col2\" >10000</td>\n",
       "      <td id=\"T_44a64_row3_col3\" class=\"data row3 col3\" >51.6</td>\n",
       "      <td id=\"T_44a64_row3_col4\" class=\"data row3 col4\" >52.4</td>\n",
       "      <td id=\"T_44a64_row3_col5\" class=\"data row3 col5\" >206.0</td>\n",
       "      <td id=\"T_44a64_row3_col6\" class=\"data row3 col6\" >-3.9</td>\n",
       "      <td id=\"T_44a64_row3_col7\" class=\"data row3 col7\" >34.2</td>\n",
       "      <td id=\"T_44a64_row3_col8\" class=\"data row3 col8\" >37.8</td>\n",
       "      <td id=\"T_44a64_row3_col9\" class=\"data row3 col9\" >4.4</td>\n",
       "      <td id=\"T_44a64_row3_col10\" class=\"data row3 col10\" >12.8</td>\n",
       "      <td id=\"T_44a64_row3_col11\" class=\"data row3 col11\" >33.1</td>\n",
       "      <td id=\"T_44a64_row3_col12\" class=\"data row3 col12\" >34.4</td>\n",
       "      <td id=\"T_44a64_row3_col13\" class=\"data row3 col13\" >7.8</td>\n",
       "      <td id=\"T_44a64_row3_col14\" class=\"data row3 col14\" >32.3</td>\n",
       "      <td id=\"T_44a64_row3_col15\" class=\"data row3 col15\" >13.4</td>\n",
       "      <td id=\"T_44a64_row3_col16\" class=\"data row3 col16\" >39.7</td>\n",
       "      <td id=\"T_44a64_row3_col17\" class=\"data row3 col17\" >-46.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44a64_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_44a64_row4_col0\" class=\"data row4 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_44a64_row4_col1\" class=\"data row4 col1\" >30000</td>\n",
       "      <td id=\"T_44a64_row4_col2\" class=\"data row4 col2\" >10000</td>\n",
       "      <td id=\"T_44a64_row4_col3\" class=\"data row4 col3\" >47.8</td>\n",
       "      <td id=\"T_44a64_row4_col4\" class=\"data row4 col4\" >47.9</td>\n",
       "      <td id=\"T_44a64_row4_col5\" class=\"data row4 col5\" >213.0</td>\n",
       "      <td id=\"T_44a64_row4_col6\" class=\"data row4 col6\" >-3.1</td>\n",
       "      <td id=\"T_44a64_row4_col7\" class=\"data row4 col7\" >35.0</td>\n",
       "      <td id=\"T_44a64_row4_col8\" class=\"data row4 col8\" >35.7</td>\n",
       "      <td id=\"T_44a64_row4_col9\" class=\"data row4 col9\" >5.8</td>\n",
       "      <td id=\"T_44a64_row4_col10\" class=\"data row4 col10\" >14.4</td>\n",
       "      <td id=\"T_44a64_row4_col11\" class=\"data row4 col11\" >32.8</td>\n",
       "      <td id=\"T_44a64_row4_col12\" class=\"data row4 col12\" >34.5</td>\n",
       "      <td id=\"T_44a64_row4_col13\" class=\"data row4 col13\" >7.5</td>\n",
       "      <td id=\"T_44a64_row4_col14\" class=\"data row4 col14\" >31.3</td>\n",
       "      <td id=\"T_44a64_row4_col15\" class=\"data row4 col15\" >12.8</td>\n",
       "      <td id=\"T_44a64_row4_col16\" class=\"data row4 col16\" >39.6</td>\n",
       "      <td id=\"T_44a64_row4_col17\" class=\"data row4 col17\" >-49.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44a64_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_44a64_row5_col0\" class=\"data row5 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-2:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_44a64_row5_col1\" class=\"data row5 col1\" >30000</td>\n",
       "      <td id=\"T_44a64_row5_col2\" class=\"data row5 col2\" >10000</td>\n",
       "      <td id=\"T_44a64_row5_col3\" class=\"data row5 col3\" >39.4</td>\n",
       "      <td id=\"T_44a64_row5_col4\" class=\"data row5 col4\" >39.6</td>\n",
       "      <td id=\"T_44a64_row5_col5\" class=\"data row5 col5\" >139.0</td>\n",
       "      <td id=\"T_44a64_row5_col6\" class=\"data row5 col6\" >-2.4</td>\n",
       "      <td id=\"T_44a64_row5_col7\" class=\"data row5 col7\" >37.8</td>\n",
       "      <td id=\"T_44a64_row5_col8\" class=\"data row5 col8\" >34.9</td>\n",
       "      <td id=\"T_44a64_row5_col9\" class=\"data row5 col9\" >5.2</td>\n",
       "      <td id=\"T_44a64_row5_col10\" class=\"data row5 col10\" >13.6</td>\n",
       "      <td id=\"T_44a64_row5_col11\" class=\"data row5 col11\" >31.3</td>\n",
       "      <td id=\"T_44a64_row5_col12\" class=\"data row5 col12\" >33.3</td>\n",
       "      <td id=\"T_44a64_row5_col13\" class=\"data row5 col13\" >7.5</td>\n",
       "      <td id=\"T_44a64_row5_col14\" class=\"data row5 col14\" >32.8</td>\n",
       "      <td id=\"T_44a64_row5_col15\" class=\"data row5 col15\" >14.0</td>\n",
       "      <td id=\"T_44a64_row5_col16\" class=\"data row5 col16\" >32.8</td>\n",
       "      <td id=\"T_44a64_row5_col17\" class=\"data row5 col17\" >-60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44a64_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_44a64_row6_col0\" class=\"data row6 col0\" >llama-7b_sharegpt50k_score=dppmap:k=acos1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_44a64_row6_col1\" class=\"data row6 col1\" >30000</td>\n",
       "      <td id=\"T_44a64_row6_col2\" class=\"data row6 col2\" >10000</td>\n",
       "      <td id=\"T_44a64_row6_col3\" class=\"data row6 col3\" >36.5</td>\n",
       "      <td id=\"T_44a64_row6_col4\" class=\"data row6 col4\" >36.6</td>\n",
       "      <td id=\"T_44a64_row6_col5\" class=\"data row6 col5\" >135.0</td>\n",
       "      <td id=\"T_44a64_row6_col6\" class=\"data row6 col6\" >-2.4</td>\n",
       "      <td id=\"T_44a64_row6_col7\" class=\"data row6 col7\" >35.6</td>\n",
       "      <td id=\"T_44a64_row6_col8\" class=\"data row6 col8\" >34.0</td>\n",
       "      <td id=\"T_44a64_row6_col9\" class=\"data row6 col9\" >5.0</td>\n",
       "      <td id=\"T_44a64_row6_col10\" class=\"data row6 col10\" >13.0</td>\n",
       "      <td id=\"T_44a64_row6_col11\" class=\"data row6 col11\" >32.8</td>\n",
       "      <td id=\"T_44a64_row6_col12\" class=\"data row6 col12\" >35.5</td>\n",
       "      <td id=\"T_44a64_row6_col13\" class=\"data row6 col13\" >7.1</td>\n",
       "      <td id=\"T_44a64_row6_col14\" class=\"data row6 col14\" >31.0</td>\n",
       "      <td id=\"T_44a64_row6_col15\" class=\"data row6 col15\" >12.2</td>\n",
       "      <td id=\"T_44a64_row6_col16\" class=\"data row6 col16\" >31.7</td>\n",
       "      <td id=\"T_44a64_row6_col17\" class=\"data row6 col17\" >-63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb74e1810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_394f1 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_394f1_row0_col0, #T_394f1_row1_col0, #T_394f1_row2_col0, #T_394f1_row3_col0, #T_394f1_row4_col0, #T_394f1_row5_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_394f1_row0_col1, #T_394f1_row0_col2, #T_394f1_row1_col1, #T_394f1_row1_col2, #T_394f1_row1_col3, #T_394f1_row1_col4, #T_394f1_row2_col1, #T_394f1_row2_col2, #T_394f1_row2_col6, #T_394f1_row3_col1, #T_394f1_row3_col2, #T_394f1_row3_col13, #T_394f1_row3_col14, #T_394f1_row4_col1, #T_394f1_row4_col2, #T_394f1_row4_col9, #T_394f1_row4_col10, #T_394f1_row4_col12, #T_394f1_row4_col15, #T_394f1_row4_col17, #T_394f1_row5_col1, #T_394f1_row5_col2, #T_394f1_row5_col5, #T_394f1_row5_col7, #T_394f1_row5_col8, #T_394f1_row5_col11, #T_394f1_row5_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row0_col4, #T_394f1_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row0_col5, #T_394f1_row0_col8, #T_394f1_row0_col9, #T_394f1_row0_col10, #T_394f1_row0_col11, #T_394f1_row0_col16, #T_394f1_row0_col17, #T_394f1_row1_col6, #T_394f1_row1_col7, #T_394f1_row1_col13, #T_394f1_row1_col15, #T_394f1_row2_col3, #T_394f1_row2_col4, #T_394f1_row2_col9, #T_394f1_row2_col11, #T_394f1_row3_col12, #T_394f1_row5_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row0_col6, #T_394f1_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row0_col12, #T_394f1_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row0_col14, #T_394f1_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #dc5d4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row1_col5, #T_394f1_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row1_col10, #T_394f1_row1_col14, #T_394f1_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row1_col12, #T_394f1_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row2_col5, #T_394f1_row3_col15, #T_394f1_row5_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row2_col8, #T_394f1_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row2_col10, #T_394f1_row5_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row2_col12, #T_394f1_row5_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row2_col15, #T_394f1_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row2_col16, #T_394f1_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row3_col9, #T_394f1_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row3_col17, #T_394f1_row4_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row4_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row5_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_394f1_row5_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #b3cdfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_394f1_row5_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_394f1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_394f1_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_394f1_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_394f1_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_394f1_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_394f1_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_394f1_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_394f1_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_394f1_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_394f1_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_394f1_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_394f1_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_394f1_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_394f1_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_394f1_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_394f1_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_394f1_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_394f1_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_394f1_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_394f1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_394f1_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_score=dppmap:k=acos0:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_394f1_row0_col1\" class=\"data row0 col1\" >60000</td>\n",
       "      <td id=\"T_394f1_row0_col2\" class=\"data row0 col2\" >20000</td>\n",
       "      <td id=\"T_394f1_row0_col3\" class=\"data row0 col3\" >50.9</td>\n",
       "      <td id=\"T_394f1_row0_col4\" class=\"data row0 col4\" >51.2</td>\n",
       "      <td id=\"T_394f1_row0_col5\" class=\"data row0 col5\" >235.0</td>\n",
       "      <td id=\"T_394f1_row0_col6\" class=\"data row0 col6\" >-3.9</td>\n",
       "      <td id=\"T_394f1_row0_col7\" class=\"data row0 col7\" >39.2</td>\n",
       "      <td id=\"T_394f1_row0_col8\" class=\"data row0 col8\" >39.6</td>\n",
       "      <td id=\"T_394f1_row0_col9\" class=\"data row0 col9\" >6.4</td>\n",
       "      <td id=\"T_394f1_row0_col10\" class=\"data row0 col10\" >17.4</td>\n",
       "      <td id=\"T_394f1_row0_col11\" class=\"data row0 col11\" >32.4</td>\n",
       "      <td id=\"T_394f1_row0_col12\" class=\"data row0 col12\" >34.3</td>\n",
       "      <td id=\"T_394f1_row0_col13\" class=\"data row0 col13\" >7.9</td>\n",
       "      <td id=\"T_394f1_row0_col14\" class=\"data row0 col14\" >34.5</td>\n",
       "      <td id=\"T_394f1_row0_col15\" class=\"data row0 col15\" >12.2</td>\n",
       "      <td id=\"T_394f1_row0_col16\" class=\"data row0 col16\" >42.9</td>\n",
       "      <td id=\"T_394f1_row0_col17\" class=\"data row0 col17\" >-31.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_394f1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_394f1_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_394f1_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_394f1_row1_col2\" class=\"data row1 col2\" >20000</td>\n",
       "      <td id=\"T_394f1_row1_col3\" class=\"data row1 col3\" >50.4</td>\n",
       "      <td id=\"T_394f1_row1_col4\" class=\"data row1 col4\" >50.6</td>\n",
       "      <td id=\"T_394f1_row1_col5\" class=\"data row1 col5\" >233.0</td>\n",
       "      <td id=\"T_394f1_row1_col6\" class=\"data row1 col6\" >-2.7</td>\n",
       "      <td id=\"T_394f1_row1_col7\" class=\"data row1 col7\" >40.2</td>\n",
       "      <td id=\"T_394f1_row1_col8\" class=\"data row1 col8\" >37.6</td>\n",
       "      <td id=\"T_394f1_row1_col9\" class=\"data row1 col9\" >5.6</td>\n",
       "      <td id=\"T_394f1_row1_col10\" class=\"data row1 col10\" >14.0</td>\n",
       "      <td id=\"T_394f1_row1_col11\" class=\"data row1 col11\" >32.2</td>\n",
       "      <td id=\"T_394f1_row1_col12\" class=\"data row1 col12\" >33.5</td>\n",
       "      <td id=\"T_394f1_row1_col13\" class=\"data row1 col13\" >8.2</td>\n",
       "      <td id=\"T_394f1_row1_col14\" class=\"data row1 col14\" >32.7</td>\n",
       "      <td id=\"T_394f1_row1_col15\" class=\"data row1 col15\" >12.4</td>\n",
       "      <td id=\"T_394f1_row1_col16\" class=\"data row1 col16\" >42.1</td>\n",
       "      <td id=\"T_394f1_row1_col17\" class=\"data row1 col17\" >-36.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_394f1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_394f1_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_394f1_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_394f1_row2_col2\" class=\"data row2 col2\" >20000</td>\n",
       "      <td id=\"T_394f1_row2_col3\" class=\"data row2 col3\" >54.6</td>\n",
       "      <td id=\"T_394f1_row2_col4\" class=\"data row2 col4\" >55.0</td>\n",
       "      <td id=\"T_394f1_row2_col5\" class=\"data row2 col5\" >220.0</td>\n",
       "      <td id=\"T_394f1_row2_col6\" class=\"data row2 col6\" >-4.3</td>\n",
       "      <td id=\"T_394f1_row2_col7\" class=\"data row2 col7\" >40.0</td>\n",
       "      <td id=\"T_394f1_row2_col8\" class=\"data row2 col8\" >39.4</td>\n",
       "      <td id=\"T_394f1_row2_col9\" class=\"data row2 col9\" >6.4</td>\n",
       "      <td id=\"T_394f1_row2_col10\" class=\"data row2 col10\" >14.4</td>\n",
       "      <td id=\"T_394f1_row2_col11\" class=\"data row2 col11\" >32.4</td>\n",
       "      <td id=\"T_394f1_row2_col12\" class=\"data row2 col12\" >34.6</td>\n",
       "      <td id=\"T_394f1_row2_col13\" class=\"data row2 col13\" >7.8</td>\n",
       "      <td id=\"T_394f1_row2_col14\" class=\"data row2 col14\" >34.4</td>\n",
       "      <td id=\"T_394f1_row2_col15\" class=\"data row2 col15\" >11.4</td>\n",
       "      <td id=\"T_394f1_row2_col16\" class=\"data row2 col16\" >42.0</td>\n",
       "      <td id=\"T_394f1_row2_col17\" class=\"data row2 col17\" >-32.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_394f1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_394f1_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_394f1_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_394f1_row3_col2\" class=\"data row3 col2\" >20000</td>\n",
       "      <td id=\"T_394f1_row3_col3\" class=\"data row3 col3\" >50.8</td>\n",
       "      <td id=\"T_394f1_row3_col4\" class=\"data row3 col4\" >51.1</td>\n",
       "      <td id=\"T_394f1_row3_col5\" class=\"data row3 col5\" >225.0</td>\n",
       "      <td id=\"T_394f1_row3_col6\" class=\"data row3 col6\" >-3.9</td>\n",
       "      <td id=\"T_394f1_row3_col7\" class=\"data row3 col7\" >39.6</td>\n",
       "      <td id=\"T_394f1_row3_col8\" class=\"data row3 col8\" >38.6</td>\n",
       "      <td id=\"T_394f1_row3_col9\" class=\"data row3 col9\" >6.2</td>\n",
       "      <td id=\"T_394f1_row3_col10\" class=\"data row3 col10\" >14.0</td>\n",
       "      <td id=\"T_394f1_row3_col11\" class=\"data row3 col11\" >32.3</td>\n",
       "      <td id=\"T_394f1_row3_col12\" class=\"data row3 col12\" >35.9</td>\n",
       "      <td id=\"T_394f1_row3_col13\" class=\"data row3 col13\" >7.5</td>\n",
       "      <td id=\"T_394f1_row3_col14\" class=\"data row3 col14\" >30.6</td>\n",
       "      <td id=\"T_394f1_row3_col15\" class=\"data row3 col15\" >11.0</td>\n",
       "      <td id=\"T_394f1_row3_col16\" class=\"data row3 col16\" >41.4</td>\n",
       "      <td id=\"T_394f1_row3_col17\" class=\"data row3 col17\" >-40.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_394f1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_394f1_row4_col0\" class=\"data row4 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_394f1_row4_col1\" class=\"data row4 col1\" >60000</td>\n",
       "      <td id=\"T_394f1_row4_col2\" class=\"data row4 col2\" >20000</td>\n",
       "      <td id=\"T_394f1_row4_col3\" class=\"data row4 col3\" >54.4</td>\n",
       "      <td id=\"T_394f1_row4_col4\" class=\"data row4 col4\" >54.7</td>\n",
       "      <td id=\"T_394f1_row4_col5\" class=\"data row4 col5\" >216.0</td>\n",
       "      <td id=\"T_394f1_row4_col6\" class=\"data row4 col6\" >-3.4</td>\n",
       "      <td id=\"T_394f1_row4_col7\" class=\"data row4 col7\" >40.0</td>\n",
       "      <td id=\"T_394f1_row4_col8\" class=\"data row4 col8\" >39.5</td>\n",
       "      <td id=\"T_394f1_row4_col9\" class=\"data row4 col9\" >4.2</td>\n",
       "      <td id=\"T_394f1_row4_col10\" class=\"data row4 col10\" >10.8</td>\n",
       "      <td id=\"T_394f1_row4_col11\" class=\"data row4 col11\" >31.9</td>\n",
       "      <td id=\"T_394f1_row4_col12\" class=\"data row4 col12\" >33.2</td>\n",
       "      <td id=\"T_394f1_row4_col13\" class=\"data row4 col13\" >7.9</td>\n",
       "      <td id=\"T_394f1_row4_col14\" class=\"data row4 col14\" >32.6</td>\n",
       "      <td id=\"T_394f1_row4_col15\" class=\"data row4 col15\" >9.8</td>\n",
       "      <td id=\"T_394f1_row4_col16\" class=\"data row4 col16\" >40.9</td>\n",
       "      <td id=\"T_394f1_row4_col17\" class=\"data row4 col17\" >-48.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_394f1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_394f1_row5_col0\" class=\"data row5 col0\" >llama-7b_sharegpt50k_score=dppmap:k=acos1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_394f1_row5_col1\" class=\"data row5 col1\" >60000</td>\n",
       "      <td id=\"T_394f1_row5_col2\" class=\"data row5 col2\" >20000</td>\n",
       "      <td id=\"T_394f1_row5_col3\" class=\"data row5 col3\" >51.1</td>\n",
       "      <td id=\"T_394f1_row5_col4\" class=\"data row5 col4\" >51.2</td>\n",
       "      <td id=\"T_394f1_row5_col5\" class=\"data row5 col5\" >207.0</td>\n",
       "      <td id=\"T_394f1_row5_col6\" class=\"data row5 col6\" >-3.1</td>\n",
       "      <td id=\"T_394f1_row5_col7\" class=\"data row5 col7\" >38.5</td>\n",
       "      <td id=\"T_394f1_row5_col8\" class=\"data row5 col8\" >36.5</td>\n",
       "      <td id=\"T_394f1_row5_col9\" class=\"data row5 col9\" >6.0</td>\n",
       "      <td id=\"T_394f1_row5_col10\" class=\"data row5 col10\" >14.4</td>\n",
       "      <td id=\"T_394f1_row5_col11\" class=\"data row5 col11\" >30.8</td>\n",
       "      <td id=\"T_394f1_row5_col12\" class=\"data row5 col12\" >34.6</td>\n",
       "      <td id=\"T_394f1_row5_col13\" class=\"data row5 col13\" >7.8</td>\n",
       "      <td id=\"T_394f1_row5_col14\" class=\"data row5 col14\" >35.0</td>\n",
       "      <td id=\"T_394f1_row5_col15\" class=\"data row5 col15\" >11.0</td>\n",
       "      <td id=\"T_394f1_row5_col16\" class=\"data row5 col16\" >40.1</td>\n",
       "      <td id=\"T_394f1_row5_col17\" class=\"data row5 col17\" >-42.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb710c3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dc2db td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_dc2db_row0_col0, #T_dc2db_row1_col0, #T_dc2db_row2_col0, #T_dc2db_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_dc2db_row0_col1, #T_dc2db_row0_col2, #T_dc2db_row0_col7, #T_dc2db_row0_col10, #T_dc2db_row1_col1, #T_dc2db_row1_col2, #T_dc2db_row1_col6, #T_dc2db_row1_col11, #T_dc2db_row1_col15, #T_dc2db_row1_col17, #T_dc2db_row2_col1, #T_dc2db_row2_col2, #T_dc2db_row2_col5, #T_dc2db_row2_col9, #T_dc2db_row3_col1, #T_dc2db_row3_col2, #T_dc2db_row3_col3, #T_dc2db_row3_col4, #T_dc2db_row3_col8, #T_dc2db_row3_col12, #T_dc2db_row3_col13, #T_dc2db_row3_col14, #T_dc2db_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dc2db_row0_col3, #T_dc2db_row0_col4, #T_dc2db_row0_col6, #T_dc2db_row0_col8, #T_dc2db_row0_col12, #T_dc2db_row0_col15, #T_dc2db_row0_col16, #T_dc2db_row0_col17, #T_dc2db_row1_col5, #T_dc2db_row1_col14, #T_dc2db_row2_col7, #T_dc2db_row2_col10, #T_dc2db_row2_col13, #T_dc2db_row3_col9, #T_dc2db_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dc2db_row0_col5, #T_dc2db_row0_col9, #T_dc2db_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dc2db_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dc2db_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dc2db_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dc2db_row1_col9, #T_dc2db_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dc2db_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dc2db_row2_col6, #T_dc2db_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dc2db_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dc2db_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dc2db_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dc2db_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dc2db_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dc2db_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dc2db\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dc2db_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_dc2db_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_dc2db_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_dc2db_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_dc2db_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_dc2db_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_dc2db_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_dc2db_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_dc2db_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_dc2db_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_dc2db_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_dc2db_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_dc2db_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_dc2db_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_dc2db_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_dc2db_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_dc2db_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_dc2db_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dc2db_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_dc2db_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_dc2db_row0_col1\" class=\"data row0 col1\" >90000</td>\n",
       "      <td id=\"T_dc2db_row0_col2\" class=\"data row0 col2\" >30000</td>\n",
       "      <td id=\"T_dc2db_row0_col3\" class=\"data row0 col3\" >56.8</td>\n",
       "      <td id=\"T_dc2db_row0_col4\" class=\"data row0 col4\" >56.9</td>\n",
       "      <td id=\"T_dc2db_row0_col5\" class=\"data row0 col5\" >225.0</td>\n",
       "      <td id=\"T_dc2db_row0_col6\" class=\"data row0 col6\" >-2.4</td>\n",
       "      <td id=\"T_dc2db_row0_col7\" class=\"data row0 col7\" >40.1</td>\n",
       "      <td id=\"T_dc2db_row0_col8\" class=\"data row0 col8\" >40.3</td>\n",
       "      <td id=\"T_dc2db_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_dc2db_row0_col10\" class=\"data row0 col10\" >14.6</td>\n",
       "      <td id=\"T_dc2db_row0_col11\" class=\"data row0 col11\" >32.2</td>\n",
       "      <td id=\"T_dc2db_row0_col12\" class=\"data row0 col12\" >36.1</td>\n",
       "      <td id=\"T_dc2db_row0_col13\" class=\"data row0 col13\" >8.1</td>\n",
       "      <td id=\"T_dc2db_row0_col14\" class=\"data row0 col14\" >33.1</td>\n",
       "      <td id=\"T_dc2db_row0_col15\" class=\"data row0 col15\" >13.2</td>\n",
       "      <td id=\"T_dc2db_row0_col16\" class=\"data row0 col16\" >43.0</td>\n",
       "      <td id=\"T_dc2db_row0_col17\" class=\"data row0 col17\" >-24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc2db_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_dc2db_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_dc2db_row1_col1\" class=\"data row1 col1\" >90000</td>\n",
       "      <td id=\"T_dc2db_row1_col2\" class=\"data row1 col2\" >30000</td>\n",
       "      <td id=\"T_dc2db_row1_col3\" class=\"data row1 col3\" >53.6</td>\n",
       "      <td id=\"T_dc2db_row1_col4\" class=\"data row1 col4\" >54.1</td>\n",
       "      <td id=\"T_dc2db_row1_col5\" class=\"data row1 col5\" >235.0</td>\n",
       "      <td id=\"T_dc2db_row1_col6\" class=\"data row1 col6\" >-3.6</td>\n",
       "      <td id=\"T_dc2db_row1_col7\" class=\"data row1 col7\" >40.1</td>\n",
       "      <td id=\"T_dc2db_row1_col8\" class=\"data row1 col8\" >38.6</td>\n",
       "      <td id=\"T_dc2db_row1_col9\" class=\"data row1 col9\" >5.8</td>\n",
       "      <td id=\"T_dc2db_row1_col10\" class=\"data row1 col10\" >15.4</td>\n",
       "      <td id=\"T_dc2db_row1_col11\" class=\"data row1 col11\" >29.4</td>\n",
       "      <td id=\"T_dc2db_row1_col12\" class=\"data row1 col12\" >35.1</td>\n",
       "      <td id=\"T_dc2db_row1_col13\" class=\"data row1 col13\" >8.1</td>\n",
       "      <td id=\"T_dc2db_row1_col14\" class=\"data row1 col14\" >34.2</td>\n",
       "      <td id=\"T_dc2db_row1_col15\" class=\"data row1 col15\" >11.0</td>\n",
       "      <td id=\"T_dc2db_row1_col16\" class=\"data row1 col16\" >42.8</td>\n",
       "      <td id=\"T_dc2db_row1_col17\" class=\"data row1 col17\" >-32.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc2db_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_dc2db_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_dc2db_row2_col1\" class=\"data row2 col1\" >90000</td>\n",
       "      <td id=\"T_dc2db_row2_col2\" class=\"data row2 col2\" >30000</td>\n",
       "      <td id=\"T_dc2db_row2_col3\" class=\"data row2 col3\" >53.9</td>\n",
       "      <td id=\"T_dc2db_row2_col4\" class=\"data row2 col4\" >53.9</td>\n",
       "      <td id=\"T_dc2db_row2_col5\" class=\"data row2 col5\" >223.0</td>\n",
       "      <td id=\"T_dc2db_row2_col6\" class=\"data row2 col6\" >-3.4</td>\n",
       "      <td id=\"T_dc2db_row2_col7\" class=\"data row2 col7\" >40.6</td>\n",
       "      <td id=\"T_dc2db_row2_col8\" class=\"data row2 col8\" >38.5</td>\n",
       "      <td id=\"T_dc2db_row2_col9\" class=\"data row2 col9\" >5.2</td>\n",
       "      <td id=\"T_dc2db_row2_col10\" class=\"data row2 col10\" >16.6</td>\n",
       "      <td id=\"T_dc2db_row2_col11\" class=\"data row2 col11\" >33.1</td>\n",
       "      <td id=\"T_dc2db_row2_col12\" class=\"data row2 col12\" >34.5</td>\n",
       "      <td id=\"T_dc2db_row2_col13\" class=\"data row2 col13\" >8.3</td>\n",
       "      <td id=\"T_dc2db_row2_col14\" class=\"data row2 col14\" >33.8</td>\n",
       "      <td id=\"T_dc2db_row2_col15\" class=\"data row2 col15\" >12.2</td>\n",
       "      <td id=\"T_dc2db_row2_col16\" class=\"data row2 col16\" >42.3</td>\n",
       "      <td id=\"T_dc2db_row2_col17\" class=\"data row2 col17\" >-28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dc2db_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_dc2db_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_dc2db_row3_col1\" class=\"data row3 col1\" >90000</td>\n",
       "      <td id=\"T_dc2db_row3_col2\" class=\"data row3 col2\" >30000</td>\n",
       "      <td id=\"T_dc2db_row3_col3\" class=\"data row3 col3\" >53.1</td>\n",
       "      <td id=\"T_dc2db_row3_col4\" class=\"data row3 col4\" >53.1</td>\n",
       "      <td id=\"T_dc2db_row3_col5\" class=\"data row3 col5\" >225.0</td>\n",
       "      <td id=\"T_dc2db_row3_col6\" class=\"data row3 col6\" >-3.0</td>\n",
       "      <td id=\"T_dc2db_row3_col7\" class=\"data row3 col7\" >40.2</td>\n",
       "      <td id=\"T_dc2db_row3_col8\" class=\"data row3 col8\" >38.5</td>\n",
       "      <td id=\"T_dc2db_row3_col9\" class=\"data row3 col9\" >6.4</td>\n",
       "      <td id=\"T_dc2db_row3_col10\" class=\"data row3 col10\" >15.0</td>\n",
       "      <td id=\"T_dc2db_row3_col11\" class=\"data row3 col11\" >34.0</td>\n",
       "      <td id=\"T_dc2db_row3_col12\" class=\"data row3 col12\" >34.3</td>\n",
       "      <td id=\"T_dc2db_row3_col13\" class=\"data row3 col13\" >7.9</td>\n",
       "      <td id=\"T_dc2db_row3_col14\" class=\"data row3 col14\" >32.5</td>\n",
       "      <td id=\"T_dc2db_row3_col15\" class=\"data row3 col15\" >12.6</td>\n",
       "      <td id=\"T_dc2db_row3_col16\" class=\"data row3 col16\" >42.3</td>\n",
       "      <td id=\"T_dc2db_row3_col17\" class=\"data row3 col17\" >-27.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb70468c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_022fa td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_022fa_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_022fa_row0_col1, #T_022fa_row0_col2, #T_022fa_row0_col3, #T_022fa_row0_col4, #T_022fa_row0_col5, #T_022fa_row0_col6, #T_022fa_row0_col7, #T_022fa_row0_col8, #T_022fa_row0_col9, #T_022fa_row0_col10, #T_022fa_row0_col11, #T_022fa_row0_col12, #T_022fa_row0_col13, #T_022fa_row0_col14, #T_022fa_row0_col15, #T_022fa_row0_col16, #T_022fa_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_022fa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_022fa_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_022fa_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_022fa_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_022fa_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_022fa_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_022fa_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_022fa_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_022fa_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_022fa_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_022fa_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_022fa_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_022fa_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_022fa_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_022fa_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_022fa_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_022fa_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_022fa_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_022fa_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_022fa_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_022fa_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_022fa_row0_col1\" class=\"data row0 col1\" >100000</td>\n",
       "      <td id=\"T_022fa_row0_col2\" class=\"data row0 col2\" >50000</td>\n",
       "      <td id=\"T_022fa_row0_col3\" class=\"data row0 col3\" >46.3</td>\n",
       "      <td id=\"T_022fa_row0_col4\" class=\"data row0 col4\" >46.3</td>\n",
       "      <td id=\"T_022fa_row0_col5\" class=\"data row0 col5\" >207.0</td>\n",
       "      <td id=\"T_022fa_row0_col6\" class=\"data row0 col6\" >-4.1</td>\n",
       "      <td id=\"T_022fa_row0_col7\" class=\"data row0 col7\" >39.0</td>\n",
       "      <td id=\"T_022fa_row0_col8\" class=\"data row0 col8\" >38.8</td>\n",
       "      <td id=\"T_022fa_row0_col9\" class=\"data row0 col9\" >6.4</td>\n",
       "      <td id=\"T_022fa_row0_col10\" class=\"data row0 col10\" >16.0</td>\n",
       "      <td id=\"T_022fa_row0_col11\" class=\"data row0 col11\" >29.9</td>\n",
       "      <td id=\"T_022fa_row0_col12\" class=\"data row0 col12\" >34.4</td>\n",
       "      <td id=\"T_022fa_row0_col13\" class=\"data row0 col13\" >8.0</td>\n",
       "      <td id=\"T_022fa_row0_col14\" class=\"data row0 col14\" >34.9</td>\n",
       "      <td id=\"T_022fa_row0_col15\" class=\"data row0 col15\" >13.2</td>\n",
       "      <td id=\"T_022fa_row0_col16\" class=\"data row0 col16\" >39.7</td>\n",
       "      <td id=\"T_022fa_row0_col17\" class=\"data row0 col17\" >-39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb74e1810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bac88 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_bac88_row0_col0, #T_bac88_row1_col0, #T_bac88_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bac88_row0_col1, #T_bac88_row0_col2, #T_bac88_row0_col7, #T_bac88_row0_col11, #T_bac88_row0_col13, #T_bac88_row0_col14, #T_bac88_row0_col17, #T_bac88_row1_col1, #T_bac88_row1_col2, #T_bac88_row1_col5, #T_bac88_row1_col9, #T_bac88_row1_col11, #T_bac88_row2_col1, #T_bac88_row2_col2, #T_bac88_row2_col3, #T_bac88_row2_col4, #T_bac88_row2_col6, #T_bac88_row2_col8, #T_bac88_row2_col10, #T_bac88_row2_col12, #T_bac88_row2_col15, #T_bac88_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bac88_row0_col3, #T_bac88_row0_col4, #T_bac88_row0_col5, #T_bac88_row0_col8, #T_bac88_row0_col9, #T_bac88_row0_col15, #T_bac88_row0_col16, #T_bac88_row1_col6, #T_bac88_row1_col7, #T_bac88_row1_col10, #T_bac88_row1_col12, #T_bac88_row2_col11, #T_bac88_row2_col13, #T_bac88_row2_col14, #T_bac88_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bac88_row0_col6, #T_bac88_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bac88_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bac88_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bac88_row1_col3, #T_bac88_row1_col4, #T_bac88_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bac88_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bac88_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bac88_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bac88_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bac88_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bac88_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bac88_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bac88\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bac88_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_bac88_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_bac88_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_bac88_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_bac88_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_bac88_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_bac88_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_bac88_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_bac88_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_bac88_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_bac88_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_bac88_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_bac88_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_bac88_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_bac88_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_bac88_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_bac88_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_bac88_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bac88_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bac88_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=120000:ep=3</td>\n",
       "      <td id=\"T_bac88_row0_col1\" class=\"data row0 col1\" >120000</td>\n",
       "      <td id=\"T_bac88_row0_col2\" class=\"data row0 col2\" >40000</td>\n",
       "      <td id=\"T_bac88_row0_col3\" class=\"data row0 col3\" >55.8</td>\n",
       "      <td id=\"T_bac88_row0_col4\" class=\"data row0 col4\" >55.9</td>\n",
       "      <td id=\"T_bac88_row0_col5\" class=\"data row0 col5\" >232.0</td>\n",
       "      <td id=\"T_bac88_row0_col6\" class=\"data row0 col6\" >-2.7</td>\n",
       "      <td id=\"T_bac88_row0_col7\" class=\"data row0 col7\" >38.5</td>\n",
       "      <td id=\"T_bac88_row0_col8\" class=\"data row0 col8\" >40.8</td>\n",
       "      <td id=\"T_bac88_row0_col9\" class=\"data row0 col9\" >7.0</td>\n",
       "      <td id=\"T_bac88_row0_col10\" class=\"data row0 col10\" >14.6</td>\n",
       "      <td id=\"T_bac88_row0_col11\" class=\"data row0 col11\" >31.4</td>\n",
       "      <td id=\"T_bac88_row0_col12\" class=\"data row0 col12\" >34.0</td>\n",
       "      <td id=\"T_bac88_row0_col13\" class=\"data row0 col13\" >7.4</td>\n",
       "      <td id=\"T_bac88_row0_col14\" class=\"data row0 col14\" >30.6</td>\n",
       "      <td id=\"T_bac88_row0_col15\" class=\"data row0 col15\" >14.6</td>\n",
       "      <td id=\"T_bac88_row0_col16\" class=\"data row0 col16\" >43.1</td>\n",
       "      <td id=\"T_bac88_row0_col17\" class=\"data row0 col17\" >-33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bac88_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bac88_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=120000:ep=3</td>\n",
       "      <td id=\"T_bac88_row1_col1\" class=\"data row1 col1\" >120000</td>\n",
       "      <td id=\"T_bac88_row1_col2\" class=\"data row1 col2\" >40000</td>\n",
       "      <td id=\"T_bac88_row1_col3\" class=\"data row1 col3\" >55.4</td>\n",
       "      <td id=\"T_bac88_row1_col4\" class=\"data row1 col4\" >55.5</td>\n",
       "      <td id=\"T_bac88_row1_col5\" class=\"data row1 col5\" >228.0</td>\n",
       "      <td id=\"T_bac88_row1_col6\" class=\"data row1 col6\" >-2.4</td>\n",
       "      <td id=\"T_bac88_row1_col7\" class=\"data row1 col7\" >40.1</td>\n",
       "      <td id=\"T_bac88_row1_col8\" class=\"data row1 col8\" >40.6</td>\n",
       "      <td id=\"T_bac88_row1_col9\" class=\"data row1 col9\" >5.8</td>\n",
       "      <td id=\"T_bac88_row1_col10\" class=\"data row1 col10\" >16.8</td>\n",
       "      <td id=\"T_bac88_row1_col11\" class=\"data row1 col11\" >31.4</td>\n",
       "      <td id=\"T_bac88_row1_col12\" class=\"data row1 col12\" >35.8</td>\n",
       "      <td id=\"T_bac88_row1_col13\" class=\"data row1 col13\" >7.5</td>\n",
       "      <td id=\"T_bac88_row1_col14\" class=\"data row1 col14\" >32.3</td>\n",
       "      <td id=\"T_bac88_row1_col15\" class=\"data row1 col15\" >12.8</td>\n",
       "      <td id=\"T_bac88_row1_col16\" class=\"data row1 col16\" >43.1</td>\n",
       "      <td id=\"T_bac88_row1_col17\" class=\"data row1 col17\" >-29.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bac88_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bac88_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=120000:ep=3</td>\n",
       "      <td id=\"T_bac88_row2_col1\" class=\"data row2 col1\" >120000</td>\n",
       "      <td id=\"T_bac88_row2_col2\" class=\"data row2 col2\" >40000</td>\n",
       "      <td id=\"T_bac88_row2_col3\" class=\"data row2 col3\" >55.3</td>\n",
       "      <td id=\"T_bac88_row2_col4\" class=\"data row2 col4\" >55.4</td>\n",
       "      <td id=\"T_bac88_row2_col5\" class=\"data row2 col5\" >229.0</td>\n",
       "      <td id=\"T_bac88_row2_col6\" class=\"data row2 col6\" >-3.1</td>\n",
       "      <td id=\"T_bac88_row2_col7\" class=\"data row2 col7\" >39.4</td>\n",
       "      <td id=\"T_bac88_row2_col8\" class=\"data row2 col8\" >39.3</td>\n",
       "      <td id=\"T_bac88_row2_col9\" class=\"data row2 col9\" >6.6</td>\n",
       "      <td id=\"T_bac88_row2_col10\" class=\"data row2 col10\" >14.4</td>\n",
       "      <td id=\"T_bac88_row2_col11\" class=\"data row2 col11\" >33.8</td>\n",
       "      <td id=\"T_bac88_row2_col12\" class=\"data row2 col12\" >33.7</td>\n",
       "      <td id=\"T_bac88_row2_col13\" class=\"data row2 col13\" >8.3</td>\n",
       "      <td id=\"T_bac88_row2_col14\" class=\"data row2 col14\" >33.9</td>\n",
       "      <td id=\"T_bac88_row2_col15\" class=\"data row2 col15\" >11.0</td>\n",
       "      <td id=\"T_bac88_row2_col16\" class=\"data row2 col16\" >42.8</td>\n",
       "      <td id=\"T_bac88_row2_col17\" class=\"data row2 col17\" >-26.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb70468c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8e396 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_8e396_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8e396_row0_col1, #T_8e396_row0_col2, #T_8e396_row0_col3, #T_8e396_row0_col4, #T_8e396_row0_col5, #T_8e396_row0_col6, #T_8e396_row0_col7, #T_8e396_row0_col8, #T_8e396_row0_col9, #T_8e396_row0_col10, #T_8e396_row0_col11, #T_8e396_row0_col12, #T_8e396_row0_col13, #T_8e396_row0_col14, #T_8e396_row0_col15, #T_8e396_row0_col16, #T_8e396_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8e396\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8e396_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_8e396_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_8e396_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_8e396_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_8e396_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_8e396_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_8e396_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_8e396_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_8e396_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_8e396_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_8e396_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_8e396_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_8e396_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_8e396_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_8e396_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_8e396_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_8e396_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_8e396_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8e396_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8e396_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=3</td>\n",
       "      <td id=\"T_8e396_row0_col1\" class=\"data row0 col1\" >150000</td>\n",
       "      <td id=\"T_8e396_row0_col2\" class=\"data row0 col2\" >50000</td>\n",
       "      <td id=\"T_8e396_row0_col3\" class=\"data row0 col3\" >56.0</td>\n",
       "      <td id=\"T_8e396_row0_col4\" class=\"data row0 col4\" >56.2</td>\n",
       "      <td id=\"T_8e396_row0_col5\" class=\"data row0 col5\" >232.0</td>\n",
       "      <td id=\"T_8e396_row0_col6\" class=\"data row0 col6\" >-2.1</td>\n",
       "      <td id=\"T_8e396_row0_col7\" class=\"data row0 col7\" >40.6</td>\n",
       "      <td id=\"T_8e396_row0_col8\" class=\"data row0 col8\" >40.9</td>\n",
       "      <td id=\"T_8e396_row0_col9\" class=\"data row0 col9\" >6.6</td>\n",
       "      <td id=\"T_8e396_row0_col10\" class=\"data row0 col10\" >15.0</td>\n",
       "      <td id=\"T_8e396_row0_col11\" class=\"data row0 col11\" >31.0</td>\n",
       "      <td id=\"T_8e396_row0_col12\" class=\"data row0 col12\" >34.7</td>\n",
       "      <td id=\"T_8e396_row0_col13\" class=\"data row0 col13\" >7.4</td>\n",
       "      <td id=\"T_8e396_row0_col14\" class=\"data row0 col14\" >33.1</td>\n",
       "      <td id=\"T_8e396_row0_col15\" class=\"data row0 col15\" >10.8</td>\n",
       "      <td id=\"T_8e396_row0_col16\" class=\"data row0 col16\" >43.2</td>\n",
       "      <td id=\"T_8e396_row0_col17\" class=\"data row0 col17\" >-29.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb6d178e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6c189 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_6c189_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6c189_row0_col1, #T_6c189_row0_col2, #T_6c189_row0_col3, #T_6c189_row0_col4, #T_6c189_row0_col5, #T_6c189_row0_col6, #T_6c189_row0_col7, #T_6c189_row0_col8, #T_6c189_row0_col9, #T_6c189_row0_col10, #T_6c189_row0_col11, #T_6c189_row0_col12, #T_6c189_row0_col13, #T_6c189_row0_col14, #T_6c189_row0_col15, #T_6c189_row0_col16, #T_6c189_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6c189\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6c189_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_6c189_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_6c189_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_6c189_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_6c189_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_6c189_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_6c189_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_6c189_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_6c189_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_6c189_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_6c189_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_6c189_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_6c189_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_6c189_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_6c189_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_6c189_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_6c189_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_6c189_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6c189_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6c189_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_6c189_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_6c189_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_6c189_row0_col3\" class=\"data row0 col3\" >0.0</td>\n",
       "      <td id=\"T_6c189_row0_col4\" class=\"data row0 col4\" >0.1</td>\n",
       "      <td id=\"T_6c189_row0_col5\" class=\"data row0 col5\" >2011.0</td>\n",
       "      <td id=\"T_6c189_row0_col6\" class=\"data row0 col6\" >-95.7</td>\n",
       "      <td id=\"T_6c189_row0_col7\" class=\"data row0 col7\" >31.8</td>\n",
       "      <td id=\"T_6c189_row0_col8\" class=\"data row0 col8\" >34.5</td>\n",
       "      <td id=\"T_6c189_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_6c189_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_6c189_row0_col11\" class=\"data row0 col11\" >30.6</td>\n",
       "      <td id=\"T_6c189_row0_col12\" class=\"data row0 col12\" >32.7</td>\n",
       "      <td id=\"T_6c189_row0_col13\" class=\"data row0 col13\" >9.6</td>\n",
       "      <td id=\"T_6c189_row0_col14\" class=\"data row0 col14\" >38.4</td>\n",
       "      <td id=\"T_6c189_row0_col15\" class=\"data row0 col15\" >10.2</td>\n",
       "      <td id=\"T_6c189_row0_col16\" class=\"data row0 col16\" >163.1</td>\n",
       "      <td id=\"T_6c189_row0_col17\" class=\"data row0 col17\" >-65.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb6446740>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7362f td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_7362f_row0_col0, #T_7362f_row1_col0, #T_7362f_row2_col0, #T_7362f_row3_col0, #T_7362f_row4_col0, #T_7362f_row5_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7362f_row0_col1, #T_7362f_row0_col2, #T_7362f_row0_col11, #T_7362f_row1_col1, #T_7362f_row1_col2, #T_7362f_row1_col6, #T_7362f_row1_col15, #T_7362f_row2_col1, #T_7362f_row2_col2, #T_7362f_row2_col9, #T_7362f_row3_col1, #T_7362f_row3_col2, #T_7362f_row4_col1, #T_7362f_row4_col2, #T_7362f_row4_col3, #T_7362f_row4_col4, #T_7362f_row4_col8, #T_7362f_row4_col13, #T_7362f_row4_col14, #T_7362f_row5_col1, #T_7362f_row5_col2, #T_7362f_row5_col5, #T_7362f_row5_col7, #T_7362f_row5_col10, #T_7362f_row5_col12, #T_7362f_row5_col16, #T_7362f_row5_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row0_col5, #T_7362f_row0_col8, #T_7362f_row0_col14, #T_7362f_row0_col15, #T_7362f_row0_col16, #T_7362f_row0_col17, #T_7362f_row1_col3, #T_7362f_row1_col4, #T_7362f_row1_col7, #T_7362f_row1_col10, #T_7362f_row1_col12, #T_7362f_row1_col13, #T_7362f_row2_col6, #T_7362f_row2_col11, #T_7362f_row4_col9, #T_7362f_row4_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row0_col6, #T_7362f_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row0_col7, #T_7362f_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d55042;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row0_col9, #T_7362f_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row0_col10, #T_7362f_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row1_col11, #T_7362f_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row1_col16, #T_7362f_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #ba162b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row2_col17, #T_7362f_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row3_col10, #T_7362f_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row5_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7362f_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row5_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row5_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7362f_row5_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7362f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7362f_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_7362f_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_7362f_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_7362f_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_7362f_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_7362f_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_7362f_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_7362f_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_7362f_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_7362f_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_7362f_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_7362f_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_7362f_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_7362f_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_7362f_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_7362f_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_7362f_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_7362f_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7362f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7362f_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=acos0:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_7362f_row0_col1\" class=\"data row0 col1\" >10000.0</td>\n",
       "      <td id=\"T_7362f_row0_col2\" class=\"data row0 col2\" >1000.0</td>\n",
       "      <td id=\"T_7362f_row0_col3\" class=\"data row0 col3\" >27.5</td>\n",
       "      <td id=\"T_7362f_row0_col4\" class=\"data row0 col4\" >27.5</td>\n",
       "      <td id=\"T_7362f_row0_col5\" class=\"data row0 col5\" >101.0</td>\n",
       "      <td id=\"T_7362f_row0_col6\" class=\"data row0 col6\" >-2.4</td>\n",
       "      <td id=\"T_7362f_row0_col7\" class=\"data row0 col7\" >36.6</td>\n",
       "      <td id=\"T_7362f_row0_col8\" class=\"data row0 col8\" >37.4</td>\n",
       "      <td id=\"T_7362f_row0_col9\" class=\"data row0 col9\" >6.4</td>\n",
       "      <td id=\"T_7362f_row0_col10\" class=\"data row0 col10\" >9.2</td>\n",
       "      <td id=\"T_7362f_row0_col11\" class=\"data row0 col11\" >31.2</td>\n",
       "      <td id=\"T_7362f_row0_col12\" class=\"data row0 col12\" >29.3</td>\n",
       "      <td id=\"T_7362f_row0_col13\" class=\"data row0 col13\" >7.9</td>\n",
       "      <td id=\"T_7362f_row0_col14\" class=\"data row0 col14\" >37.7</td>\n",
       "      <td id=\"T_7362f_row0_col15\" class=\"data row0 col15\" >10.4</td>\n",
       "      <td id=\"T_7362f_row0_col16\" class=\"data row0 col16\" >27.7</td>\n",
       "      <td id=\"T_7362f_row0_col17\" class=\"data row0 col17\" >-64.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7362f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7362f_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_7362f_row1_col1\" class=\"data row1 col1\" >10000.0</td>\n",
       "      <td id=\"T_7362f_row1_col2\" class=\"data row1 col2\" >1000.0</td>\n",
       "      <td id=\"T_7362f_row1_col3\" class=\"data row1 col3\" >27.5</td>\n",
       "      <td id=\"T_7362f_row1_col4\" class=\"data row1 col4\" >27.6</td>\n",
       "      <td id=\"T_7362f_row1_col5\" class=\"data row1 col5\" >99.0</td>\n",
       "      <td id=\"T_7362f_row1_col6\" class=\"data row1 col6\" >-2.6</td>\n",
       "      <td id=\"T_7362f_row1_col7\" class=\"data row1 col7\" >37.8</td>\n",
       "      <td id=\"T_7362f_row1_col8\" class=\"data row1 col8\" >36.8</td>\n",
       "      <td id=\"T_7362f_row1_col9\" class=\"data row1 col9\" >4.8</td>\n",
       "      <td id=\"T_7362f_row1_col10\" class=\"data row1 col10\" >11.2</td>\n",
       "      <td id=\"T_7362f_row1_col11\" class=\"data row1 col11\" >31.5</td>\n",
       "      <td id=\"T_7362f_row1_col12\" class=\"data row1 col12\" >31.2</td>\n",
       "      <td id=\"T_7362f_row1_col13\" class=\"data row1 col13\" >8.4</td>\n",
       "      <td id=\"T_7362f_row1_col14\" class=\"data row1 col14\" >35.9</td>\n",
       "      <td id=\"T_7362f_row1_col15\" class=\"data row1 col15\" >8.9</td>\n",
       "      <td id=\"T_7362f_row1_col16\" class=\"data row1 col16\" >27.6</td>\n",
       "      <td id=\"T_7362f_row1_col17\" class=\"data row1 col17\" >-65.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7362f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7362f_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_7362f_row2_col1\" class=\"data row2 col1\" >10000.0</td>\n",
       "      <td id=\"T_7362f_row2_col2\" class=\"data row2 col2\" >1000.0</td>\n",
       "      <td id=\"T_7362f_row2_col3\" class=\"data row2 col3\" >25.5</td>\n",
       "      <td id=\"T_7362f_row2_col4\" class=\"data row2 col4\" >25.5</td>\n",
       "      <td id=\"T_7362f_row2_col5\" class=\"data row2 col5\" >93.0</td>\n",
       "      <td id=\"T_7362f_row2_col6\" class=\"data row2 col6\" >-1.2</td>\n",
       "      <td id=\"T_7362f_row2_col7\" class=\"data row2 col7\" >25.7</td>\n",
       "      <td id=\"T_7362f_row2_col8\" class=\"data row2 col8\" >33.5</td>\n",
       "      <td id=\"T_7362f_row2_col9\" class=\"data row2 col9\" >3.8</td>\n",
       "      <td id=\"T_7362f_row2_col10\" class=\"data row2 col10\" >6.0</td>\n",
       "      <td id=\"T_7362f_row2_col11\" class=\"data row2 col11\" >33.2</td>\n",
       "      <td id=\"T_7362f_row2_col12\" class=\"data row2 col12\" >31.0</td>\n",
       "      <td id=\"T_7362f_row2_col13\" class=\"data row2 col13\" >7.0</td>\n",
       "      <td id=\"T_7362f_row2_col14\" class=\"data row2 col14\" >29.7</td>\n",
       "      <td id=\"T_7362f_row2_col15\" class=\"data row2 col15\" >9.6</td>\n",
       "      <td id=\"T_7362f_row2_col16\" class=\"data row2 col16\" >24.8</td>\n",
       "      <td id=\"T_7362f_row2_col17\" class=\"data row2 col17\" >-85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7362f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7362f_row3_col0\" class=\"data row3 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_7362f_row3_col1\" class=\"data row3 col1\" >10000.0</td>\n",
       "      <td id=\"T_7362f_row3_col2\" class=\"data row3 col2\" >1000.0</td>\n",
       "      <td id=\"T_7362f_row3_col3\" class=\"data row3 col3\" >23.0</td>\n",
       "      <td id=\"T_7362f_row3_col4\" class=\"data row3 col4\" >23.0</td>\n",
       "      <td id=\"T_7362f_row3_col5\" class=\"data row3 col5\" >81.0</td>\n",
       "      <td id=\"T_7362f_row3_col6\" class=\"data row3 col6\" >-2.4</td>\n",
       "      <td id=\"T_7362f_row3_col7\" class=\"data row3 col7\" >32.1</td>\n",
       "      <td id=\"T_7362f_row3_col8\" class=\"data row3 col8\" >36.6</td>\n",
       "      <td id=\"T_7362f_row3_col9\" class=\"data row3 col9\" >6.2</td>\n",
       "      <td id=\"T_7362f_row3_col10\" class=\"data row3 col10\" >7.4</td>\n",
       "      <td id=\"T_7362f_row3_col11\" class=\"data row3 col11\" >32.0</td>\n",
       "      <td id=\"T_7362f_row3_col12\" class=\"data row3 col12\" >30.1</td>\n",
       "      <td id=\"T_7362f_row3_col13\" class=\"data row3 col13\" >5.9</td>\n",
       "      <td id=\"T_7362f_row3_col14\" class=\"data row3 col14\" >27.0</td>\n",
       "      <td id=\"T_7362f_row3_col15\" class=\"data row3 col15\" >9.1</td>\n",
       "      <td id=\"T_7362f_row3_col16\" class=\"data row3 col16\" >23.9</td>\n",
       "      <td id=\"T_7362f_row3_col17\" class=\"data row3 col17\" >-85.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7362f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7362f_row4_col0\" class=\"data row4 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=acos0:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_7362f_row4_col1\" class=\"data row4 col1\" >10000.0</td>\n",
       "      <td id=\"T_7362f_row4_col2\" class=\"data row4 col2\" >1000.0</td>\n",
       "      <td id=\"T_7362f_row4_col3\" class=\"data row4 col3\" >21.4</td>\n",
       "      <td id=\"T_7362f_row4_col4\" class=\"data row4 col4\" >21.6</td>\n",
       "      <td id=\"T_7362f_row4_col5\" class=\"data row4 col5\" >80.0</td>\n",
       "      <td id=\"T_7362f_row4_col6\" class=\"data row4 col6\" >-2.1</td>\n",
       "      <td id=\"T_7362f_row4_col7\" class=\"data row4 col7\" >26.7</td>\n",
       "      <td id=\"T_7362f_row4_col8\" class=\"data row4 col8\" >27.6</td>\n",
       "      <td id=\"T_7362f_row4_col9\" class=\"data row4 col9\" >7.0</td>\n",
       "      <td id=\"T_7362f_row4_col10\" class=\"data row4 col10\" >8.8</td>\n",
       "      <td id=\"T_7362f_row4_col11\" class=\"data row4 col11\" >31.4</td>\n",
       "      <td id=\"T_7362f_row4_col12\" class=\"data row4 col12\" >30.8</td>\n",
       "      <td id=\"T_7362f_row4_col13\" class=\"data row4 col13\" >5.6</td>\n",
       "      <td id=\"T_7362f_row4_col14\" class=\"data row4 col14\" >24.6</td>\n",
       "      <td id=\"T_7362f_row4_col15\" class=\"data row4 col15\" >10.4</td>\n",
       "      <td id=\"T_7362f_row4_col16\" class=\"data row4 col16\" >22.6</td>\n",
       "      <td id=\"T_7362f_row4_col17\" class=\"data row4 col17\" >-85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7362f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7362f_row5_col0\" class=\"data row5 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_7362f_row5_col1\" class=\"data row5 col1\" >10000.0</td>\n",
       "      <td id=\"T_7362f_row5_col2\" class=\"data row5 col2\" >1000.0</td>\n",
       "      <td id=\"T_7362f_row5_col3\" class=\"data row5 col3\" >22.7</td>\n",
       "      <td id=\"T_7362f_row5_col4\" class=\"data row5 col4\" >22.7</td>\n",
       "      <td id=\"T_7362f_row5_col5\" class=\"data row5 col5\" >70.0</td>\n",
       "      <td id=\"T_7362f_row5_col6\" class=\"data row5 col6\" >-1.7</td>\n",
       "      <td id=\"T_7362f_row5_col7\" class=\"data row5 col7\" >25.2</td>\n",
       "      <td id=\"T_7362f_row5_col8\" class=\"data row5 col8\" >30.3</td>\n",
       "      <td id=\"T_7362f_row5_col9\" class=\"data row5 col9\" >4.0</td>\n",
       "      <td id=\"T_7362f_row5_col10\" class=\"data row5 col10\" >5.6</td>\n",
       "      <td id=\"T_7362f_row5_col11\" class=\"data row5 col11\" >32.2</td>\n",
       "      <td id=\"T_7362f_row5_col12\" class=\"data row5 col12\" >19.7</td>\n",
       "      <td id=\"T_7362f_row5_col13\" class=\"data row5 col13\" >7.6</td>\n",
       "      <td id=\"T_7362f_row5_col14\" class=\"data row5 col14\" >34.2</td>\n",
       "      <td id=\"T_7362f_row5_col15\" class=\"data row5 col15\" >9.3</td>\n",
       "      <td id=\"T_7362f_row5_col16\" class=\"data row5 col16\" >21.7</td>\n",
       "      <td id=\"T_7362f_row5_col17\" class=\"data row5 col17\" >-88.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb72a4f40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_25f8d td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_25f8d_row0_col0, #T_25f8d_row1_col0, #T_25f8d_row2_col0, #T_25f8d_row3_col0, #T_25f8d_row4_col0, #T_25f8d_row5_col0, #T_25f8d_row6_col0, #T_25f8d_row7_col0, #T_25f8d_row8_col0, #T_25f8d_row9_col0, #T_25f8d_row10_col0, #T_25f8d_row11_col0, #T_25f8d_row12_col0, #T_25f8d_row13_col0, #T_25f8d_row14_col0, #T_25f8d_row15_col0, #T_25f8d_row16_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_25f8d_row0_col1, #T_25f8d_row0_col2, #T_25f8d_row0_col15, #T_25f8d_row1_col1, #T_25f8d_row1_col2, #T_25f8d_row2_col1, #T_25f8d_row2_col2, #T_25f8d_row3_col1, #T_25f8d_row3_col2, #T_25f8d_row4_col1, #T_25f8d_row4_col2, #T_25f8d_row4_col11, #T_25f8d_row4_col13, #T_25f8d_row5_col1, #T_25f8d_row5_col2, #T_25f8d_row5_col15, #T_25f8d_row6_col1, #T_25f8d_row6_col2, #T_25f8d_row6_col15, #T_25f8d_row6_col17, #T_25f8d_row7_col1, #T_25f8d_row7_col2, #T_25f8d_row8_col1, #T_25f8d_row8_col2, #T_25f8d_row8_col6, #T_25f8d_row9_col1, #T_25f8d_row9_col2, #T_25f8d_row9_col15, #T_25f8d_row10_col1, #T_25f8d_row10_col2, #T_25f8d_row11_col1, #T_25f8d_row11_col2, #T_25f8d_row11_col14, #T_25f8d_row12_col1, #T_25f8d_row12_col2, #T_25f8d_row12_col9, #T_25f8d_row13_col1, #T_25f8d_row13_col2, #T_25f8d_row13_col15, #T_25f8d_row14_col1, #T_25f8d_row14_col2, #T_25f8d_row14_col7, #T_25f8d_row14_col8, #T_25f8d_row14_col15, #T_25f8d_row15_col1, #T_25f8d_row15_col2, #T_25f8d_row15_col10, #T_25f8d_row15_col15, #T_25f8d_row16_col1, #T_25f8d_row16_col2, #T_25f8d_row16_col3, #T_25f8d_row16_col4, #T_25f8d_row16_col5, #T_25f8d_row16_col12, #T_25f8d_row16_col15, #T_25f8d_row16_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row0_col3, #T_25f8d_row0_col4, #T_25f8d_row0_col5, #T_25f8d_row0_col16, #T_25f8d_row1_col5, #T_25f8d_row1_col10, #T_25f8d_row2_col7, #T_25f8d_row2_col8, #T_25f8d_row2_col13, #T_25f8d_row5_col11, #T_25f8d_row8_col9, #T_25f8d_row10_col10, #T_25f8d_row10_col12, #T_25f8d_row11_col15, #T_25f8d_row16_col6, #T_25f8d_row16_col14, #T_25f8d_row16_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row0_col6, #T_25f8d_row5_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row0_col9, #T_25f8d_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row0_col10, #T_25f8d_row9_col12, #T_25f8d_row13_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row0_col11, #T_25f8d_row1_col14, #T_25f8d_row8_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row0_col12, #T_25f8d_row4_col8, #T_25f8d_row11_col8, #T_25f8d_row12_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row0_col14, #T_25f8d_row1_col9, #T_25f8d_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row1_col3, #T_25f8d_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row1_col6, #T_25f8d_row7_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row1_col8, #T_25f8d_row9_col9, #T_25f8d_row13_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row2_col3, #T_25f8d_row2_col4, #T_25f8d_row2_col5, #T_25f8d_row2_col6, #T_25f8d_row2_col17, #T_25f8d_row10_col3, #T_25f8d_row10_col4, #T_25f8d_row10_col5, #T_25f8d_row10_col6, #T_25f8d_row10_col17, #T_25f8d_row11_col3, #T_25f8d_row11_col4, #T_25f8d_row11_col5, #T_25f8d_row11_col6, #T_25f8d_row11_col17, #T_25f8d_row12_col3, #T_25f8d_row12_col4, #T_25f8d_row12_col5, #T_25f8d_row12_col6, #T_25f8d_row12_col17, #T_25f8d_row13_col3, #T_25f8d_row13_col4, #T_25f8d_row13_col5, #T_25f8d_row13_col6, #T_25f8d_row13_col17, #T_25f8d_row14_col3, #T_25f8d_row14_col4, #T_25f8d_row14_col5, #T_25f8d_row14_col6, #T_25f8d_row14_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row2_col11, #T_25f8d_row7_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row2_col12, #T_25f8d_row3_col3, #T_25f8d_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row2_col15, #T_25f8d_row5_col9, #T_25f8d_row11_col9, #T_25f8d_row16_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row2_col16, #T_25f8d_row7_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row3_col10, #T_25f8d_row6_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row3_col12, #T_25f8d_row7_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row3_col13, #T_25f8d_row15_col3, #T_25f8d_row15_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row3_col14, #T_25f8d_row14_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row3_col16, #T_25f8d_row12_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row4_col3, #T_25f8d_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row4_col9, #T_25f8d_row4_col17, #T_25f8d_row6_col9, #T_25f8d_row7_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row4_col10, #T_25f8d_row14_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #dc5d4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row4_col12, #T_25f8d_row6_col6, #T_25f8d_row6_col12, #T_25f8d_row7_col12, #T_25f8d_row11_col12, #T_25f8d_row15_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f2c9b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row4_col14, #T_25f8d_row10_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row4_col15, #T_25f8d_row9_col3, #T_25f8d_row9_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row5_col3, #T_25f8d_row5_col4, #T_25f8d_row7_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row5_col5, #T_25f8d_row15_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e16751;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row5_col8, #T_25f8d_row6_col8, #T_25f8d_row10_col16, #T_25f8d_row11_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row5_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row5_col12, #T_25f8d_row8_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row5_col13, #T_25f8d_row6_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row5_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row5_col16, #T_25f8d_row9_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row5_col17, #T_25f8d_row8_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row6_col3, #T_25f8d_row6_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row6_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row6_col7, #T_25f8d_row9_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row6_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row6_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row6_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row7_col3, #T_25f8d_row7_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row7_col5, #T_25f8d_row9_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row7_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row7_col10, #T_25f8d_row15_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row7_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row7_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row7_col15, #T_25f8d_row8_col13, #T_25f8d_row8_col16, #T_25f8d_row13_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row8_col4, #T_25f8d_row11_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row8_col5, #T_25f8d_row12_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row8_col10, #T_25f8d_row12_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row8_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row8_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row8_col14, #T_25f8d_row13_col9, #T_25f8d_row14_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row8_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row8_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row9_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row9_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row9_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row9_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row9_col14, #T_25f8d_row16_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row9_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row9_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row10_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row10_col8, #T_25f8d_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f1ccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row10_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row10_col11, #T_25f8d_row12_col11, #T_25f8d_row16_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row10_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row10_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row11_col7, #T_25f8d_row11_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row11_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row12_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row12_col14, #T_25f8d_row15_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row12_col16, #T_25f8d_row14_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row13_col12, #T_25f8d_row16_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row13_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row13_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row13_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row14_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row14_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row14_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row15_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row15_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row15_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row15_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row15_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_25f8d_row15_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row16_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_25f8d_row16_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_25f8d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_25f8d_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_25f8d_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_25f8d_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_25f8d_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_25f8d_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_25f8d_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_25f8d_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_25f8d_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_25f8d_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_25f8d_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_25f8d_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_25f8d_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_25f8d_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_25f8d_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_25f8d_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_25f8d_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_25f8d_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_25f8d_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_25f8d_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=acos0:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row0_col2\" class=\"data row0 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row0_col3\" class=\"data row0 col3\" >27.6</td>\n",
       "      <td id=\"T_25f8d_row0_col4\" class=\"data row0 col4\" >27.6</td>\n",
       "      <td id=\"T_25f8d_row0_col5\" class=\"data row0 col5\" >86.0</td>\n",
       "      <td id=\"T_25f8d_row0_col6\" class=\"data row0 col6\" >-3.9</td>\n",
       "      <td id=\"T_25f8d_row0_col7\" class=\"data row0 col7\" >32.8</td>\n",
       "      <td id=\"T_25f8d_row0_col8\" class=\"data row0 col8\" >36.4</td>\n",
       "      <td id=\"T_25f8d_row0_col9\" class=\"data row0 col9\" >4.2</td>\n",
       "      <td id=\"T_25f8d_row0_col10\" class=\"data row0 col10\" >8.6</td>\n",
       "      <td id=\"T_25f8d_row0_col11\" class=\"data row0 col11\" >33.1</td>\n",
       "      <td id=\"T_25f8d_row0_col12\" class=\"data row0 col12\" >30.6</td>\n",
       "      <td id=\"T_25f8d_row0_col13\" class=\"data row0 col13\" >8.0</td>\n",
       "      <td id=\"T_25f8d_row0_col14\" class=\"data row0 col14\" >37.6</td>\n",
       "      <td id=\"T_25f8d_row0_col15\" class=\"data row0 col15\" >8.5</td>\n",
       "      <td id=\"T_25f8d_row0_col16\" class=\"data row0 col16\" >25.9</td>\n",
       "      <td id=\"T_25f8d_row0_col17\" class=\"data row0 col17\" >-76.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_25f8d_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row1_col2\" class=\"data row1 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row1_col3\" class=\"data row1 col3\" >25.3</td>\n",
       "      <td id=\"T_25f8d_row1_col4\" class=\"data row1 col4\" >25.3</td>\n",
       "      <td id=\"T_25f8d_row1_col5\" class=\"data row1 col5\" >86.0</td>\n",
       "      <td id=\"T_25f8d_row1_col6\" class=\"data row1 col6\" >-3.1</td>\n",
       "      <td id=\"T_25f8d_row1_col7\" class=\"data row1 col7\" >27.3</td>\n",
       "      <td id=\"T_25f8d_row1_col8\" class=\"data row1 col8\" >30.3</td>\n",
       "      <td id=\"T_25f8d_row1_col9\" class=\"data row1 col9\" >5.0</td>\n",
       "      <td id=\"T_25f8d_row1_col10\" class=\"data row1 col10\" >9.8</td>\n",
       "      <td id=\"T_25f8d_row1_col11\" class=\"data row1 col11\" >34.8</td>\n",
       "      <td id=\"T_25f8d_row1_col12\" class=\"data row1 col12\" >33.4</td>\n",
       "      <td id=\"T_25f8d_row1_col13\" class=\"data row1 col13\" >7.8</td>\n",
       "      <td id=\"T_25f8d_row1_col14\" class=\"data row1 col14\" >37.4</td>\n",
       "      <td id=\"T_25f8d_row1_col15\" class=\"data row1 col15\" >9.6</td>\n",
       "      <td id=\"T_25f8d_row1_col16\" class=\"data row1 col16\" >25.3</td>\n",
       "      <td id=\"T_25f8d_row1_col17\" class=\"data row1 col17\" >-70.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_25f8d_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca50k_score=numtoks:input:neg_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row2_col2\" class=\"data row2 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_25f8d_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "      <td id=\"T_25f8d_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_25f8d_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "      <td id=\"T_25f8d_row2_col7\" class=\"data row2 col7\" >42.8</td>\n",
       "      <td id=\"T_25f8d_row2_col8\" class=\"data row2 col8\" >44.8</td>\n",
       "      <td id=\"T_25f8d_row2_col9\" class=\"data row2 col9\" >4.2</td>\n",
       "      <td id=\"T_25f8d_row2_col10\" class=\"data row2 col10\" >6.4</td>\n",
       "      <td id=\"T_25f8d_row2_col11\" class=\"data row2 col11\" >34.4</td>\n",
       "      <td id=\"T_25f8d_row2_col12\" class=\"data row2 col12\" >33.7</td>\n",
       "      <td id=\"T_25f8d_row2_col13\" class=\"data row2 col13\" >8.9</td>\n",
       "      <td id=\"T_25f8d_row2_col14\" class=\"data row2 col14\" >40.7</td>\n",
       "      <td id=\"T_25f8d_row2_col15\" class=\"data row2 col15\" >10.4</td>\n",
       "      <td id=\"T_25f8d_row2_col16\" class=\"data row2 col16\" >25.1</td>\n",
       "      <td id=\"T_25f8d_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_25f8d_row3_col0\" class=\"data row3 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row3_col2\" class=\"data row3 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row3_col3\" class=\"data row3 col3\" >24.7</td>\n",
       "      <td id=\"T_25f8d_row3_col4\" class=\"data row3 col4\" >24.7</td>\n",
       "      <td id=\"T_25f8d_row3_col5\" class=\"data row3 col5\" >76.0</td>\n",
       "      <td id=\"T_25f8d_row3_col6\" class=\"data row3 col6\" >-2.4</td>\n",
       "      <td id=\"T_25f8d_row3_col7\" class=\"data row3 col7\" >35.6</td>\n",
       "      <td id=\"T_25f8d_row3_col8\" class=\"data row3 col8\" >38.3</td>\n",
       "      <td id=\"T_25f8d_row3_col9\" class=\"data row3 col9\" >5.0</td>\n",
       "      <td id=\"T_25f8d_row3_col10\" class=\"data row3 col10\" >5.2</td>\n",
       "      <td id=\"T_25f8d_row3_col11\" class=\"data row3 col11\" >31.3</td>\n",
       "      <td id=\"T_25f8d_row3_col12\" class=\"data row3 col12\" >31.9</td>\n",
       "      <td id=\"T_25f8d_row3_col13\" class=\"data row3 col13\" >7.1</td>\n",
       "      <td id=\"T_25f8d_row3_col14\" class=\"data row3 col14\" >35.8</td>\n",
       "      <td id=\"T_25f8d_row3_col15\" class=\"data row3 col15\" >8.7</td>\n",
       "      <td id=\"T_25f8d_row3_col16\" class=\"data row3 col16\" >24.8</td>\n",
       "      <td id=\"T_25f8d_row3_col17\" class=\"data row3 col17\" >-76.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_25f8d_row4_col0\" class=\"data row4 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row4_col1\" class=\"data row4 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row4_col2\" class=\"data row4 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row4_col3\" class=\"data row4 col3\" >23.8</td>\n",
       "      <td id=\"T_25f8d_row4_col4\" class=\"data row4 col4\" >23.8</td>\n",
       "      <td id=\"T_25f8d_row4_col5\" class=\"data row4 col5\" >73.0</td>\n",
       "      <td id=\"T_25f8d_row4_col6\" class=\"data row4 col6\" >-3.0</td>\n",
       "      <td id=\"T_25f8d_row4_col7\" class=\"data row4 col7\" >37.4</td>\n",
       "      <td id=\"T_25f8d_row4_col8\" class=\"data row4 col8\" >38.5</td>\n",
       "      <td id=\"T_25f8d_row4_col9\" class=\"data row4 col9\" >4.6</td>\n",
       "      <td id=\"T_25f8d_row4_col10\" class=\"data row4 col10\" >9.2</td>\n",
       "      <td id=\"T_25f8d_row4_col11\" class=\"data row4 col11\" >30.0</td>\n",
       "      <td id=\"T_25f8d_row4_col12\" class=\"data row4 col12\" >29.8</td>\n",
       "      <td id=\"T_25f8d_row4_col13\" class=\"data row4 col13\" >6.6</td>\n",
       "      <td id=\"T_25f8d_row4_col14\" class=\"data row4 col14\" >35.4</td>\n",
       "      <td id=\"T_25f8d_row4_col15\" class=\"data row4 col15\" >11.2</td>\n",
       "      <td id=\"T_25f8d_row4_col16\" class=\"data row4 col16\" >24.6</td>\n",
       "      <td id=\"T_25f8d_row4_col17\" class=\"data row4 col17\" >-76.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_25f8d_row5_col0\" class=\"data row5 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=mpnet:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row5_col1\" class=\"data row5 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row5_col2\" class=\"data row5 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row5_col3\" class=\"data row5 col3\" >22.7</td>\n",
       "      <td id=\"T_25f8d_row5_col4\" class=\"data row5 col4\" >22.7</td>\n",
       "      <td id=\"T_25f8d_row5_col5\" class=\"data row5 col5\" >70.0</td>\n",
       "      <td id=\"T_25f8d_row5_col6\" class=\"data row5 col6\" >-3.9</td>\n",
       "      <td id=\"T_25f8d_row5_col7\" class=\"data row5 col7\" >40.1</td>\n",
       "      <td id=\"T_25f8d_row5_col8\" class=\"data row5 col8\" >38.1</td>\n",
       "      <td id=\"T_25f8d_row5_col9\" class=\"data row5 col9\" >4.8</td>\n",
       "      <td id=\"T_25f8d_row5_col10\" class=\"data row5 col10\" >6.8</td>\n",
       "      <td id=\"T_25f8d_row5_col11\" class=\"data row5 col11\" >35.6</td>\n",
       "      <td id=\"T_25f8d_row5_col12\" class=\"data row5 col12\" >31.8</td>\n",
       "      <td id=\"T_25f8d_row5_col13\" class=\"data row5 col13\" >6.8</td>\n",
       "      <td id=\"T_25f8d_row5_col14\" class=\"data row5 col14\" >33.2</td>\n",
       "      <td id=\"T_25f8d_row5_col15\" class=\"data row5 col15\" >8.5</td>\n",
       "      <td id=\"T_25f8d_row5_col16\" class=\"data row5 col16\" >24.4</td>\n",
       "      <td id=\"T_25f8d_row5_col17\" class=\"data row5 col17\" >-74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_25f8d_row6_col0\" class=\"data row6 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=acos0:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row6_col1\" class=\"data row6 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row6_col2\" class=\"data row6 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row6_col3\" class=\"data row6 col3\" >25.6</td>\n",
       "      <td id=\"T_25f8d_row6_col4\" class=\"data row6 col4\" >25.6</td>\n",
       "      <td id=\"T_25f8d_row6_col5\" class=\"data row6 col5\" >72.0</td>\n",
       "      <td id=\"T_25f8d_row6_col6\" class=\"data row6 col6\" >-2.2</td>\n",
       "      <td id=\"T_25f8d_row6_col7\" class=\"data row6 col7\" >34.8</td>\n",
       "      <td id=\"T_25f8d_row6_col8\" class=\"data row6 col8\" >38.1</td>\n",
       "      <td id=\"T_25f8d_row6_col9\" class=\"data row6 col9\" >4.6</td>\n",
       "      <td id=\"T_25f8d_row6_col10\" class=\"data row6 col10\" >7.2</td>\n",
       "      <td id=\"T_25f8d_row6_col11\" class=\"data row6 col11\" >30.5</td>\n",
       "      <td id=\"T_25f8d_row6_col12\" class=\"data row6 col12\" >29.8</td>\n",
       "      <td id=\"T_25f8d_row6_col13\" class=\"data row6 col13\" >6.7</td>\n",
       "      <td id=\"T_25f8d_row6_col14\" class=\"data row6 col14\" >33.2</td>\n",
       "      <td id=\"T_25f8d_row6_col15\" class=\"data row6 col15\" >8.5</td>\n",
       "      <td id=\"T_25f8d_row6_col16\" class=\"data row6 col16\" >24.2</td>\n",
       "      <td id=\"T_25f8d_row6_col17\" class=\"data row6 col17\" >-83.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_25f8d_row7_col0\" class=\"data row7 col0\" >llama-7b_stanford_alpaca50k_score=dedup:dist=cd:md=mpnet:emb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row7_col1\" class=\"data row7 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row7_col2\" class=\"data row7 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row7_col3\" class=\"data row7 col3\" >20.6</td>\n",
       "      <td id=\"T_25f8d_row7_col4\" class=\"data row7 col4\" >20.6</td>\n",
       "      <td id=\"T_25f8d_row7_col5\" class=\"data row7 col5\" >69.0</td>\n",
       "      <td id=\"T_25f8d_row7_col6\" class=\"data row7 col6\" >-3.1</td>\n",
       "      <td id=\"T_25f8d_row7_col7\" class=\"data row7 col7\" >37.8</td>\n",
       "      <td id=\"T_25f8d_row7_col8\" class=\"data row7 col8\" >38.3</td>\n",
       "      <td id=\"T_25f8d_row7_col9\" class=\"data row7 col9\" >4.6</td>\n",
       "      <td id=\"T_25f8d_row7_col10\" class=\"data row7 col10\" >7.0</td>\n",
       "      <td id=\"T_25f8d_row7_col11\" class=\"data row7 col11\" >34.4</td>\n",
       "      <td id=\"T_25f8d_row7_col12\" class=\"data row7 col12\" >29.8</td>\n",
       "      <td id=\"T_25f8d_row7_col13\" class=\"data row7 col13\" >7.9</td>\n",
       "      <td id=\"T_25f8d_row7_col14\" class=\"data row7 col14\" >34.9</td>\n",
       "      <td id=\"T_25f8d_row7_col15\" class=\"data row7 col15\" >11.0</td>\n",
       "      <td id=\"T_25f8d_row7_col16\" class=\"data row7 col16\" >24.1</td>\n",
       "      <td id=\"T_25f8d_row7_col17\" class=\"data row7 col17\" >-69.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_25f8d_row8_col0\" class=\"data row8 col0\" >llama-7b_stanford_alpaca50k_score=dedup:dist=cd:md=llama7br512p4096:emb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row8_col1\" class=\"data row8 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row8_col2\" class=\"data row8 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row8_col3\" class=\"data row8 col3\" >19.3</td>\n",
       "      <td id=\"T_25f8d_row8_col4\" class=\"data row8 col4\" >19.3</td>\n",
       "      <td id=\"T_25f8d_row8_col5\" class=\"data row8 col5\" >67.0</td>\n",
       "      <td id=\"T_25f8d_row8_col6\" class=\"data row8 col6\" >-4.0</td>\n",
       "      <td id=\"T_25f8d_row8_col7\" class=\"data row8 col7\" >37.6</td>\n",
       "      <td id=\"T_25f8d_row8_col8\" class=\"data row8 col8\" >37.4</td>\n",
       "      <td id=\"T_25f8d_row8_col9\" class=\"data row8 col9\" >6.2</td>\n",
       "      <td id=\"T_25f8d_row8_col10\" class=\"data row8 col10\" >6.0</td>\n",
       "      <td id=\"T_25f8d_row8_col11\" class=\"data row8 col11\" >33.0</td>\n",
       "      <td id=\"T_25f8d_row8_col12\" class=\"data row8 col12\" >28.4</td>\n",
       "      <td id=\"T_25f8d_row8_col13\" class=\"data row8 col13\" >8.1</td>\n",
       "      <td id=\"T_25f8d_row8_col14\" class=\"data row8 col14\" >38.2</td>\n",
       "      <td id=\"T_25f8d_row8_col15\" class=\"data row8 col15\" >9.8</td>\n",
       "      <td id=\"T_25f8d_row8_col16\" class=\"data row8 col16\" >23.6</td>\n",
       "      <td id=\"T_25f8d_row8_col17\" class=\"data row8 col17\" >-71.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_25f8d_row9_col0\" class=\"data row9 col0\" >llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row9_col1\" class=\"data row9 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row9_col2\" class=\"data row9 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row9_col3\" class=\"data row9 col3\" >22.4</td>\n",
       "      <td id=\"T_25f8d_row9_col4\" class=\"data row9 col4\" >22.4</td>\n",
       "      <td id=\"T_25f8d_row9_col5\" class=\"data row9 col5\" >69.0</td>\n",
       "      <td id=\"T_25f8d_row9_col6\" class=\"data row9 col6\" >-1.7</td>\n",
       "      <td id=\"T_25f8d_row9_col7\" class=\"data row9 col7\" >30.9</td>\n",
       "      <td id=\"T_25f8d_row9_col8\" class=\"data row9 col8\" >33.6</td>\n",
       "      <td id=\"T_25f8d_row9_col9\" class=\"data row9 col9\" >4.0</td>\n",
       "      <td id=\"T_25f8d_row9_col10\" class=\"data row9 col10\" >5.6</td>\n",
       "      <td id=\"T_25f8d_row9_col11\" class=\"data row9 col11\" >34.5</td>\n",
       "      <td id=\"T_25f8d_row9_col12\" class=\"data row9 col12\" >32.3</td>\n",
       "      <td id=\"T_25f8d_row9_col13\" class=\"data row9 col13\" >7.9</td>\n",
       "      <td id=\"T_25f8d_row9_col14\" class=\"data row9 col14\" >36.8</td>\n",
       "      <td id=\"T_25f8d_row9_col15\" class=\"data row9 col15\" >8.5</td>\n",
       "      <td id=\"T_25f8d_row9_col16\" class=\"data row9 col16\" >23.6</td>\n",
       "      <td id=\"T_25f8d_row9_col17\" class=\"data row9 col17\" >-77.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_25f8d_row10_col0\" class=\"data row10 col0\" >llama-7b_stanford_alpaca50k_score=numtoks:output:neg_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row10_col1\" class=\"data row10 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row10_col2\" class=\"data row10 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row10_col3\" class=\"data row10 col3\" >nan</td>\n",
       "      <td id=\"T_25f8d_row10_col4\" class=\"data row10 col4\" >nan</td>\n",
       "      <td id=\"T_25f8d_row10_col5\" class=\"data row10 col5\" >nan</td>\n",
       "      <td id=\"T_25f8d_row10_col6\" class=\"data row10 col6\" >nan</td>\n",
       "      <td id=\"T_25f8d_row10_col7\" class=\"data row10 col7\" >35.2</td>\n",
       "      <td id=\"T_25f8d_row10_col8\" class=\"data row10 col8\" >37.4</td>\n",
       "      <td id=\"T_25f8d_row10_col9\" class=\"data row10 col9\" >4.4</td>\n",
       "      <td id=\"T_25f8d_row10_col10\" class=\"data row10 col10\" >9.8</td>\n",
       "      <td id=\"T_25f8d_row10_col11\" class=\"data row10 col11\" >34.6</td>\n",
       "      <td id=\"T_25f8d_row10_col12\" class=\"data row10 col12\" >36.2</td>\n",
       "      <td id=\"T_25f8d_row10_col13\" class=\"data row10 col13\" >8.2</td>\n",
       "      <td id=\"T_25f8d_row10_col14\" class=\"data row10 col14\" >35.4</td>\n",
       "      <td id=\"T_25f8d_row10_col15\" class=\"data row10 col15\" >9.1</td>\n",
       "      <td id=\"T_25f8d_row10_col16\" class=\"data row10 col16\" >23.4</td>\n",
       "      <td id=\"T_25f8d_row10_col17\" class=\"data row10 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_25f8d_row11_col0\" class=\"data row11 col0\" >llama-7b_stanford_alpaca50k_score=el2n:agg=mean_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row11_col1\" class=\"data row11 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row11_col2\" class=\"data row11 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row11_col3\" class=\"data row11 col3\" >nan</td>\n",
       "      <td id=\"T_25f8d_row11_col4\" class=\"data row11 col4\" >nan</td>\n",
       "      <td id=\"T_25f8d_row11_col5\" class=\"data row11 col5\" >nan</td>\n",
       "      <td id=\"T_25f8d_row11_col6\" class=\"data row11 col6\" >nan</td>\n",
       "      <td id=\"T_25f8d_row11_col7\" class=\"data row11 col7\" >38.1</td>\n",
       "      <td id=\"T_25f8d_row11_col8\" class=\"data row11 col8\" >38.5</td>\n",
       "      <td id=\"T_25f8d_row11_col9\" class=\"data row11 col9\" >4.8</td>\n",
       "      <td id=\"T_25f8d_row11_col10\" class=\"data row11 col10\" >8.0</td>\n",
       "      <td id=\"T_25f8d_row11_col11\" class=\"data row11 col11\" >34.3</td>\n",
       "      <td id=\"T_25f8d_row11_col12\" class=\"data row11 col12\" >29.8</td>\n",
       "      <td id=\"T_25f8d_row11_col13\" class=\"data row11 col13\" >7.2</td>\n",
       "      <td id=\"T_25f8d_row11_col14\" class=\"data row11 col14\" >32.6</td>\n",
       "      <td id=\"T_25f8d_row11_col15\" class=\"data row11 col15\" >12.2</td>\n",
       "      <td id=\"T_25f8d_row11_col16\" class=\"data row11 col16\" >22.8</td>\n",
       "      <td id=\"T_25f8d_row11_col17\" class=\"data row11 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_25f8d_row12_col0\" class=\"data row12 col0\" >llama-7b_stanford_alpaca50k_score=log:prob:neg_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row12_col1\" class=\"data row12 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row12_col2\" class=\"data row12 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row12_col3\" class=\"data row12 col3\" >nan</td>\n",
       "      <td id=\"T_25f8d_row12_col4\" class=\"data row12 col4\" >nan</td>\n",
       "      <td id=\"T_25f8d_row12_col5\" class=\"data row12 col5\" >nan</td>\n",
       "      <td id=\"T_25f8d_row12_col6\" class=\"data row12 col6\" >nan</td>\n",
       "      <td id=\"T_25f8d_row12_col7\" class=\"data row12 col7\" >36.3</td>\n",
       "      <td id=\"T_25f8d_row12_col8\" class=\"data row12 col8\" >39.2</td>\n",
       "      <td id=\"T_25f8d_row12_col9\" class=\"data row12 col9\" >3.4</td>\n",
       "      <td id=\"T_25f8d_row12_col10\" class=\"data row12 col10\" >6.0</td>\n",
       "      <td id=\"T_25f8d_row12_col11\" class=\"data row12 col11\" >34.6</td>\n",
       "      <td id=\"T_25f8d_row12_col12\" class=\"data row12 col12\" >31.2</td>\n",
       "      <td id=\"T_25f8d_row12_col13\" class=\"data row12 col13\" >8.1</td>\n",
       "      <td id=\"T_25f8d_row12_col14\" class=\"data row12 col14\" >33.8</td>\n",
       "      <td id=\"T_25f8d_row12_col15\" class=\"data row12 col15\" >11.6</td>\n",
       "      <td id=\"T_25f8d_row12_col16\" class=\"data row12 col16\" >22.7</td>\n",
       "      <td id=\"T_25f8d_row12_col17\" class=\"data row12 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_25f8d_row13_col0\" class=\"data row13 col0\" >llama-7b_stanford_alpaca50k_score=grad:loraB:l2n_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row13_col1\" class=\"data row13 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row13_col2\" class=\"data row13 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row13_col3\" class=\"data row13 col3\" >nan</td>\n",
       "      <td id=\"T_25f8d_row13_col4\" class=\"data row13 col4\" >nan</td>\n",
       "      <td id=\"T_25f8d_row13_col5\" class=\"data row13 col5\" >nan</td>\n",
       "      <td id=\"T_25f8d_row13_col6\" class=\"data row13 col6\" >nan</td>\n",
       "      <td id=\"T_25f8d_row13_col7\" class=\"data row13 col7\" >36.4</td>\n",
       "      <td id=\"T_25f8d_row13_col8\" class=\"data row13 col8\" >37.3</td>\n",
       "      <td id=\"T_25f8d_row13_col9\" class=\"data row13 col9\" >5.2</td>\n",
       "      <td id=\"T_25f8d_row13_col10\" class=\"data row13 col10\" >8.6</td>\n",
       "      <td id=\"T_25f8d_row13_col11\" class=\"data row13 col11\" >31.2</td>\n",
       "      <td id=\"T_25f8d_row13_col12\" class=\"data row13 col12\" >34.9</td>\n",
       "      <td id=\"T_25f8d_row13_col13\" class=\"data row13 col13\" >7.5</td>\n",
       "      <td id=\"T_25f8d_row13_col14\" class=\"data row13 col14\" >34.4</td>\n",
       "      <td id=\"T_25f8d_row13_col15\" class=\"data row13 col15\" >8.5</td>\n",
       "      <td id=\"T_25f8d_row13_col16\" class=\"data row13 col16\" >22.7</td>\n",
       "      <td id=\"T_25f8d_row13_col17\" class=\"data row13 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_25f8d_row14_col0\" class=\"data row14 col0\" >llama-7b_stanford_alpaca50k_score=numtoks:total:neg_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row14_col1\" class=\"data row14 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row14_col2\" class=\"data row14 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row14_col3\" class=\"data row14 col3\" >nan</td>\n",
       "      <td id=\"T_25f8d_row14_col4\" class=\"data row14 col4\" >nan</td>\n",
       "      <td id=\"T_25f8d_row14_col5\" class=\"data row14 col5\" >nan</td>\n",
       "      <td id=\"T_25f8d_row14_col6\" class=\"data row14 col6\" >nan</td>\n",
       "      <td id=\"T_25f8d_row14_col7\" class=\"data row14 col7\" >23.8</td>\n",
       "      <td id=\"T_25f8d_row14_col8\" class=\"data row14 col8\" >26.3</td>\n",
       "      <td id=\"T_25f8d_row14_col9\" class=\"data row14 col9\" >5.2</td>\n",
       "      <td id=\"T_25f8d_row14_col10\" class=\"data row14 col10\" >9.2</td>\n",
       "      <td id=\"T_25f8d_row14_col11\" class=\"data row14 col11\" >33.1</td>\n",
       "      <td id=\"T_25f8d_row14_col12\" class=\"data row14 col12\" >34.0</td>\n",
       "      <td id=\"T_25f8d_row14_col13\" class=\"data row14 col13\" >7.4</td>\n",
       "      <td id=\"T_25f8d_row14_col14\" class=\"data row14 col14\" >36.0</td>\n",
       "      <td id=\"T_25f8d_row14_col15\" class=\"data row14 col15\" >8.5</td>\n",
       "      <td id=\"T_25f8d_row14_col16\" class=\"data row14 col16\" >20.4</td>\n",
       "      <td id=\"T_25f8d_row14_col17\" class=\"data row14 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_25f8d_row15_col0\" class=\"data row15 col0\" >llama-7b_stanford_alpaca50k_score=dedup:dist=cd:md=llama7br512p4096:emb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row15_col1\" class=\"data row15 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row15_col2\" class=\"data row15 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row15_col3\" class=\"data row15 col3\" >13.5</td>\n",
       "      <td id=\"T_25f8d_row15_col4\" class=\"data row15 col4\" >13.5</td>\n",
       "      <td id=\"T_25f8d_row15_col5\" class=\"data row15 col5\" >33.0</td>\n",
       "      <td id=\"T_25f8d_row15_col6\" class=\"data row15 col6\" >-1.9</td>\n",
       "      <td id=\"T_25f8d_row15_col7\" class=\"data row15 col7\" >41.9</td>\n",
       "      <td id=\"T_25f8d_row15_col8\" class=\"data row15 col8\" >42.4</td>\n",
       "      <td id=\"T_25f8d_row15_col9\" class=\"data row15 col9\" >3.8</td>\n",
       "      <td id=\"T_25f8d_row15_col10\" class=\"data row15 col10\" >4.8</td>\n",
       "      <td id=\"T_25f8d_row15_col11\" class=\"data row15 col11\" >33.8</td>\n",
       "      <td id=\"T_25f8d_row15_col12\" class=\"data row15 col12\" >22.0</td>\n",
       "      <td id=\"T_25f8d_row15_col13\" class=\"data row15 col13\" >7.6</td>\n",
       "      <td id=\"T_25f8d_row15_col14\" class=\"data row15 col14\" >36.5</td>\n",
       "      <td id=\"T_25f8d_row15_col15\" class=\"data row15 col15\" >8.5</td>\n",
       "      <td id=\"T_25f8d_row15_col16\" class=\"data row15 col16\" >19.9</td>\n",
       "      <td id=\"T_25f8d_row15_col17\" class=\"data row15 col17\" >-74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25f8d_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_25f8d_row16_col0\" class=\"data row16 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-2:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_25f8d_row16_col1\" class=\"data row16 col1\" >30000</td>\n",
       "      <td id=\"T_25f8d_row16_col2\" class=\"data row16 col2\" >10000</td>\n",
       "      <td id=\"T_25f8d_row16_col3\" class=\"data row16 col3\" >8.9</td>\n",
       "      <td id=\"T_25f8d_row16_col4\" class=\"data row16 col4\" >8.9</td>\n",
       "      <td id=\"T_25f8d_row16_col5\" class=\"data row16 col5\" >24.0</td>\n",
       "      <td id=\"T_25f8d_row16_col6\" class=\"data row16 col6\" >-1.1</td>\n",
       "      <td id=\"T_25f8d_row16_col7\" class=\"data row16 col7\" >41.2</td>\n",
       "      <td id=\"T_25f8d_row16_col8\" class=\"data row16 col8\" >41.4</td>\n",
       "      <td id=\"T_25f8d_row16_col9\" class=\"data row16 col9\" >4.8</td>\n",
       "      <td id=\"T_25f8d_row16_col10\" class=\"data row16 col10\" >5.8</td>\n",
       "      <td id=\"T_25f8d_row16_col11\" class=\"data row16 col11\" >32.8</td>\n",
       "      <td id=\"T_25f8d_row16_col12\" class=\"data row16 col12\" >19.9</td>\n",
       "      <td id=\"T_25f8d_row16_col13\" class=\"data row16 col13\" >8.7</td>\n",
       "      <td id=\"T_25f8d_row16_col14\" class=\"data row16 col14\" >41.3</td>\n",
       "      <td id=\"T_25f8d_row16_col15\" class=\"data row16 col15\" >8.5</td>\n",
       "      <td id=\"T_25f8d_row16_col16\" class=\"data row16 col16\" >18.9</td>\n",
       "      <td id=\"T_25f8d_row16_col17\" class=\"data row16 col17\" >-68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb72a5000>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_24ed2 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_24ed2_row0_col0, #T_24ed2_row1_col0, #T_24ed2_row2_col0, #T_24ed2_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_24ed2_row0_col1, #T_24ed2_row0_col2, #T_24ed2_row1_col1, #T_24ed2_row1_col2, #T_24ed2_row1_col6, #T_24ed2_row1_col8, #T_24ed2_row1_col10, #T_24ed2_row1_col11, #T_24ed2_row1_col12, #T_24ed2_row1_col17, #T_24ed2_row2_col1, #T_24ed2_row2_col2, #T_24ed2_row2_col9, #T_24ed2_row2_col13, #T_24ed2_row2_col14, #T_24ed2_row2_col15, #T_24ed2_row3_col1, #T_24ed2_row3_col2, #T_24ed2_row3_col3, #T_24ed2_row3_col4, #T_24ed2_row3_col5, #T_24ed2_row3_col7, #T_24ed2_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row0_col3, #T_24ed2_row0_col4, #T_24ed2_row0_col12, #T_24ed2_row0_col16, #T_24ed2_row0_col17, #T_24ed2_row1_col4, #T_24ed2_row1_col5, #T_24ed2_row1_col9, #T_24ed2_row1_col13, #T_24ed2_row1_col15, #T_24ed2_row2_col6, #T_24ed2_row2_col7, #T_24ed2_row2_col8, #T_24ed2_row2_col11, #T_24ed2_row3_col10, #T_24ed2_row3_col14, #T_24ed2_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_24ed2_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row0_col9, #T_24ed2_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_24ed2_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_24ed2_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_24ed2_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_24ed2_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row2_col3, #T_24ed2_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_24ed2_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_24ed2_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_24ed2_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_24ed2_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_24ed2_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_24ed2_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_24ed2_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_24ed2_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_24ed2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_24ed2_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_24ed2_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_24ed2_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_24ed2_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_24ed2_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_24ed2_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_24ed2_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_24ed2_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_24ed2_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_24ed2_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_24ed2_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_24ed2_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_24ed2_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_24ed2_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_24ed2_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_24ed2_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_24ed2_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_24ed2_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_24ed2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_24ed2_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_24ed2_row0_col1\" class=\"data row0 col1\" >60000</td>\n",
       "      <td id=\"T_24ed2_row0_col2\" class=\"data row0 col2\" >20000</td>\n",
       "      <td id=\"T_24ed2_row0_col3\" class=\"data row0 col3\" >25.7</td>\n",
       "      <td id=\"T_24ed2_row0_col4\" class=\"data row0 col4\" >25.7</td>\n",
       "      <td id=\"T_24ed2_row0_col5\" class=\"data row0 col5\" >73.0</td>\n",
       "      <td id=\"T_24ed2_row0_col6\" class=\"data row0 col6\" >-2.6</td>\n",
       "      <td id=\"T_24ed2_row0_col7\" class=\"data row0 col7\" >40.3</td>\n",
       "      <td id=\"T_24ed2_row0_col8\" class=\"data row0 col8\" >41.3</td>\n",
       "      <td id=\"T_24ed2_row0_col9\" class=\"data row0 col9\" >4.2</td>\n",
       "      <td id=\"T_24ed2_row0_col10\" class=\"data row0 col10\" >6.2</td>\n",
       "      <td id=\"T_24ed2_row0_col11\" class=\"data row0 col11\" >32.4</td>\n",
       "      <td id=\"T_24ed2_row0_col12\" class=\"data row0 col12\" >33.3</td>\n",
       "      <td id=\"T_24ed2_row0_col13\" class=\"data row0 col13\" >7.6</td>\n",
       "      <td id=\"T_24ed2_row0_col14\" class=\"data row0 col14\" >35.3</td>\n",
       "      <td id=\"T_24ed2_row0_col15\" class=\"data row0 col15\" >8.1</td>\n",
       "      <td id=\"T_24ed2_row0_col16\" class=\"data row0 col16\" >25.4</td>\n",
       "      <td id=\"T_24ed2_row0_col17\" class=\"data row0 col17\" >-67.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_24ed2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_24ed2_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_24ed2_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_24ed2_row1_col2\" class=\"data row1 col2\" >20000</td>\n",
       "      <td id=\"T_24ed2_row1_col3\" class=\"data row1 col3\" >25.6</td>\n",
       "      <td id=\"T_24ed2_row1_col4\" class=\"data row1 col4\" >25.7</td>\n",
       "      <td id=\"T_24ed2_row1_col5\" class=\"data row1 col5\" >80.0</td>\n",
       "      <td id=\"T_24ed2_row1_col6\" class=\"data row1 col6\" >-3.7</td>\n",
       "      <td id=\"T_24ed2_row1_col7\" class=\"data row1 col7\" >38.7</td>\n",
       "      <td id=\"T_24ed2_row1_col8\" class=\"data row1 col8\" >38.1</td>\n",
       "      <td id=\"T_24ed2_row1_col9\" class=\"data row1 col9\" >4.8</td>\n",
       "      <td id=\"T_24ed2_row1_col10\" class=\"data row1 col10\" >6.0</td>\n",
       "      <td id=\"T_24ed2_row1_col11\" class=\"data row1 col11\" >31.3</td>\n",
       "      <td id=\"T_24ed2_row1_col12\" class=\"data row1 col12\" >31.8</td>\n",
       "      <td id=\"T_24ed2_row1_col13\" class=\"data row1 col13\" >7.7</td>\n",
       "      <td id=\"T_24ed2_row1_col14\" class=\"data row1 col14\" >35.6</td>\n",
       "      <td id=\"T_24ed2_row1_col15\" class=\"data row1 col15\" >9.1</td>\n",
       "      <td id=\"T_24ed2_row1_col16\" class=\"data row1 col16\" >25.4</td>\n",
       "      <td id=\"T_24ed2_row1_col17\" class=\"data row1 col17\" >-73.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_24ed2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_24ed2_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_24ed2_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_24ed2_row2_col2\" class=\"data row2 col2\" >20000</td>\n",
       "      <td id=\"T_24ed2_row2_col3\" class=\"data row2 col3\" >23.4</td>\n",
       "      <td id=\"T_24ed2_row2_col4\" class=\"data row2 col4\" >23.4</td>\n",
       "      <td id=\"T_24ed2_row2_col5\" class=\"data row2 col5\" >74.0</td>\n",
       "      <td id=\"T_24ed2_row2_col6\" class=\"data row2 col6\" >-2.4</td>\n",
       "      <td id=\"T_24ed2_row2_col7\" class=\"data row2 col7\" >41.9</td>\n",
       "      <td id=\"T_24ed2_row2_col8\" class=\"data row2 col8\" >41.9</td>\n",
       "      <td id=\"T_24ed2_row2_col9\" class=\"data row2 col9\" >3.4</td>\n",
       "      <td id=\"T_24ed2_row2_col10\" class=\"data row2 col10\" >6.6</td>\n",
       "      <td id=\"T_24ed2_row2_col11\" class=\"data row2 col11\" >33.7</td>\n",
       "      <td id=\"T_24ed2_row2_col12\" class=\"data row2 col12\" >32.1</td>\n",
       "      <td id=\"T_24ed2_row2_col13\" class=\"data row2 col13\" >6.8</td>\n",
       "      <td id=\"T_24ed2_row2_col14\" class=\"data row2 col14\" >34.7</td>\n",
       "      <td id=\"T_24ed2_row2_col15\" class=\"data row2 col15\" >6.9</td>\n",
       "      <td id=\"T_24ed2_row2_col16\" class=\"data row2 col16\" >25.1</td>\n",
       "      <td id=\"T_24ed2_row2_col17\" class=\"data row2 col17\" >-70.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_24ed2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_24ed2_row3_col0\" class=\"data row3 col0\" >llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_24ed2_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_24ed2_row3_col2\" class=\"data row3 col2\" >20000</td>\n",
       "      <td id=\"T_24ed2_row3_col3\" class=\"data row3 col3\" >22.4</td>\n",
       "      <td id=\"T_24ed2_row3_col4\" class=\"data row3 col4\" >22.4</td>\n",
       "      <td id=\"T_24ed2_row3_col5\" class=\"data row3 col5\" >72.0</td>\n",
       "      <td id=\"T_24ed2_row3_col6\" class=\"data row3 col6\" >-2.5</td>\n",
       "      <td id=\"T_24ed2_row3_col7\" class=\"data row3 col7\" >38.4</td>\n",
       "      <td id=\"T_24ed2_row3_col8\" class=\"data row3 col8\" >38.5</td>\n",
       "      <td id=\"T_24ed2_row3_col9\" class=\"data row3 col9\" >4.0</td>\n",
       "      <td id=\"T_24ed2_row3_col10\" class=\"data row3 col10\" >8.2</td>\n",
       "      <td id=\"T_24ed2_row3_col11\" class=\"data row3 col11\" >32.5</td>\n",
       "      <td id=\"T_24ed2_row3_col12\" class=\"data row3 col12\" >32.0</td>\n",
       "      <td id=\"T_24ed2_row3_col13\" class=\"data row3 col13\" >7.5</td>\n",
       "      <td id=\"T_24ed2_row3_col14\" class=\"data row3 col14\" >38.2</td>\n",
       "      <td id=\"T_24ed2_row3_col15\" class=\"data row3 col15\" >9.1</td>\n",
       "      <td id=\"T_24ed2_row3_col16\" class=\"data row3 col16\" >24.8</td>\n",
       "      <td id=\"T_24ed2_row3_col17\" class=\"data row3 col17\" >-72.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb6bf66b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dc0e1 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_dc0e1_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_dc0e1_row0_col1, #T_dc0e1_row0_col2, #T_dc0e1_row0_col3, #T_dc0e1_row0_col4, #T_dc0e1_row0_col5, #T_dc0e1_row0_col6, #T_dc0e1_row0_col7, #T_dc0e1_row0_col8, #T_dc0e1_row0_col9, #T_dc0e1_row0_col10, #T_dc0e1_row0_col11, #T_dc0e1_row0_col12, #T_dc0e1_row0_col13, #T_dc0e1_row0_col14, #T_dc0e1_row0_col15, #T_dc0e1_row0_col16, #T_dc0e1_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dc0e1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dc0e1_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_dc0e1_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_dc0e1_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_dc0e1_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_dc0e1_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_dc0e1_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_dc0e1_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_dc0e1_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_dc0e1_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_dc0e1_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_dc0e1_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_dc0e1_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_dc0e1_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_dc0e1_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_dc0e1_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_dc0e1_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_dc0e1_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_dc0e1_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dc0e1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_dc0e1_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_dc0e1_row0_col1\" class=\"data row0 col1\" >100000</td>\n",
       "      <td id=\"T_dc0e1_row0_col2\" class=\"data row0 col2\" >50000</td>\n",
       "      <td id=\"T_dc0e1_row0_col3\" class=\"data row0 col3\" >20.6</td>\n",
       "      <td id=\"T_dc0e1_row0_col4\" class=\"data row0 col4\" >20.6</td>\n",
       "      <td id=\"T_dc0e1_row0_col5\" class=\"data row0 col5\" >67.0</td>\n",
       "      <td id=\"T_dc0e1_row0_col6\" class=\"data row0 col6\" >-3.4</td>\n",
       "      <td id=\"T_dc0e1_row0_col7\" class=\"data row0 col7\" >42.2</td>\n",
       "      <td id=\"T_dc0e1_row0_col8\" class=\"data row0 col8\" >42.6</td>\n",
       "      <td id=\"T_dc0e1_row0_col9\" class=\"data row0 col9\" >4.0</td>\n",
       "      <td id=\"T_dc0e1_row0_col10\" class=\"data row0 col10\" >5.0</td>\n",
       "      <td id=\"T_dc0e1_row0_col11\" class=\"data row0 col11\" >33.6</td>\n",
       "      <td id=\"T_dc0e1_row0_col12\" class=\"data row0 col12\" >31.7</td>\n",
       "      <td id=\"T_dc0e1_row0_col13\" class=\"data row0 col13\" >7.2</td>\n",
       "      <td id=\"T_dc0e1_row0_col14\" class=\"data row0 col14\" >33.9</td>\n",
       "      <td id=\"T_dc0e1_row0_col15\" class=\"data row0 col15\" >10.8</td>\n",
       "      <td id=\"T_dc0e1_row0_col16\" class=\"data row0 col16\" >24.3</td>\n",
       "      <td id=\"T_dc0e1_row0_col17\" class=\"data row0 col17\" >-70.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb72a50f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_60463 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_60463_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_60463_row0_col1, #T_60463_row0_col2, #T_60463_row0_col3, #T_60463_row0_col4, #T_60463_row0_col5, #T_60463_row0_col6, #T_60463_row0_col7, #T_60463_row0_col8, #T_60463_row0_col9, #T_60463_row0_col10, #T_60463_row0_col11, #T_60463_row0_col12, #T_60463_row0_col13, #T_60463_row0_col14, #T_60463_row0_col15, #T_60463_row0_col16, #T_60463_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_60463\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_60463_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_60463_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_60463_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_60463_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_60463_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_60463_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_60463_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_60463_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_60463_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_60463_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_60463_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_60463_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_60463_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_60463_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_60463_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_60463_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_60463_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_60463_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_60463_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_60463_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_ep=3</td>\n",
       "      <td id=\"T_60463_row0_col1\" class=\"data row0 col1\" >150000</td>\n",
       "      <td id=\"T_60463_row0_col2\" class=\"data row0 col2\" >50000</td>\n",
       "      <td id=\"T_60463_row0_col3\" class=\"data row0 col3\" >24.5</td>\n",
       "      <td id=\"T_60463_row0_col4\" class=\"data row0 col4\" >24.5</td>\n",
       "      <td id=\"T_60463_row0_col5\" class=\"data row0 col5\" >72.0</td>\n",
       "      <td id=\"T_60463_row0_col6\" class=\"data row0 col6\" >-2.0</td>\n",
       "      <td id=\"T_60463_row0_col7\" class=\"data row0 col7\" >41.8</td>\n",
       "      <td id=\"T_60463_row0_col8\" class=\"data row0 col8\" >41.6</td>\n",
       "      <td id=\"T_60463_row0_col9\" class=\"data row0 col9\" >4.0</td>\n",
       "      <td id=\"T_60463_row0_col10\" class=\"data row0 col10\" >5.0</td>\n",
       "      <td id=\"T_60463_row0_col11\" class=\"data row0 col11\" >33.1</td>\n",
       "      <td id=\"T_60463_row0_col12\" class=\"data row0 col12\" >31.4</td>\n",
       "      <td id=\"T_60463_row0_col13\" class=\"data row0 col13\" >6.5</td>\n",
       "      <td id=\"T_60463_row0_col14\" class=\"data row0 col14\" >33.8</td>\n",
       "      <td id=\"T_60463_row0_col15\" class=\"data row0 col15\" >9.8</td>\n",
       "      <td id=\"T_60463_row0_col16\" class=\"data row0 col16\" >25.1</td>\n",
       "      <td id=\"T_60463_row0_col17\" class=\"data row0 col17\" >-69.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb4b60130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ff108 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_ff108_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ff108_row0_col1, #T_ff108_row0_col2, #T_ff108_row0_col3, #T_ff108_row0_col4, #T_ff108_row0_col5, #T_ff108_row0_col6, #T_ff108_row0_col7, #T_ff108_row0_col8, #T_ff108_row0_col9, #T_ff108_row0_col10, #T_ff108_row0_col11, #T_ff108_row0_col12, #T_ff108_row0_col13, #T_ff108_row0_col14, #T_ff108_row0_col15, #T_ff108_row0_col16, #T_ff108_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ff108\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ff108_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_ff108_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_ff108_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_ff108_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_ff108_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_ff108_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_ff108_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_ff108_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_ff108_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_ff108_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_ff108_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_ff108_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_ff108_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_ff108_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_ff108_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_ff108_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_ff108_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_ff108_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ff108_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ff108_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_ff108_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_ff108_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_ff108_row0_col3\" class=\"data row0 col3\" >0.0</td>\n",
       "      <td id=\"T_ff108_row0_col4\" class=\"data row0 col4\" >0.1</td>\n",
       "      <td id=\"T_ff108_row0_col5\" class=\"data row0 col5\" >2011.0</td>\n",
       "      <td id=\"T_ff108_row0_col6\" class=\"data row0 col6\" >-95.7</td>\n",
       "      <td id=\"T_ff108_row0_col7\" class=\"data row0 col7\" >31.8</td>\n",
       "      <td id=\"T_ff108_row0_col8\" class=\"data row0 col8\" >34.5</td>\n",
       "      <td id=\"T_ff108_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_ff108_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_ff108_row0_col11\" class=\"data row0 col11\" >30.6</td>\n",
       "      <td id=\"T_ff108_row0_col12\" class=\"data row0 col12\" >32.7</td>\n",
       "      <td id=\"T_ff108_row0_col13\" class=\"data row0 col13\" >9.6</td>\n",
       "      <td id=\"T_ff108_row0_col14\" class=\"data row0 col14\" >38.4</td>\n",
       "      <td id=\"T_ff108_row0_col15\" class=\"data row0 col15\" >10.2</td>\n",
       "      <td id=\"T_ff108_row0_col16\" class=\"data row0 col16\" >163.1</td>\n",
       "      <td id=\"T_ff108_row0_col17\" class=\"data row0 col17\" >-65.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb4a44700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d4bfb td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_d4bfb_row0_col0, #T_d4bfb_row1_col0, #T_d4bfb_row2_col0, #T_d4bfb_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d4bfb_row0_col1, #T_d4bfb_row0_col2, #T_d4bfb_row0_col9, #T_d4bfb_row1_col1, #T_d4bfb_row1_col2, #T_d4bfb_row1_col8, #T_d4bfb_row1_col11, #T_d4bfb_row1_col12, #T_d4bfb_row2_col1, #T_d4bfb_row2_col2, #T_d4bfb_row2_col3, #T_d4bfb_row2_col4, #T_d4bfb_row2_col6, #T_d4bfb_row3_col1, #T_d4bfb_row3_col2, #T_d4bfb_row3_col5, #T_d4bfb_row3_col7, #T_d4bfb_row3_col10, #T_d4bfb_row3_col11, #T_d4bfb_row3_col13, #T_d4bfb_row3_col14, #T_d4bfb_row3_col15, #T_d4bfb_row3_col16, #T_d4bfb_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4bfb_row0_col3, #T_d4bfb_row0_col4, #T_d4bfb_row0_col5, #T_d4bfb_row0_col6, #T_d4bfb_row0_col7, #T_d4bfb_row0_col8, #T_d4bfb_row0_col10, #T_d4bfb_row0_col11, #T_d4bfb_row0_col16, #T_d4bfb_row0_col17, #T_d4bfb_row1_col9, #T_d4bfb_row1_col13, #T_d4bfb_row1_col14, #T_d4bfb_row2_col12, #T_d4bfb_row2_col15, #T_d4bfb_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4bfb_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4bfb_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4bfb_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4bfb_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4bfb_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4bfb_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4bfb_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4bfb_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4bfb_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4bfb_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d4bfb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d4bfb_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d4bfb_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_d4bfb_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_d4bfb_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_d4bfb_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_d4bfb_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_d4bfb_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_d4bfb_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d4bfb_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d4bfb_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_d4bfb_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_d4bfb_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_d4bfb_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_d4bfb_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d4bfb_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d4bfb_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d4bfb_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_d4bfb_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d4bfb_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d4bfb_row0_col0\" class=\"data row0 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_d4bfb_row0_col1\" class=\"data row0 col1\" >10000.0</td>\n",
       "      <td id=\"T_d4bfb_row0_col2\" class=\"data row0 col2\" >1000.0</td>\n",
       "      <td id=\"T_d4bfb_row0_col3\" class=\"data row0 col3\" >45.3</td>\n",
       "      <td id=\"T_d4bfb_row0_col4\" class=\"data row0 col4\" >45.4</td>\n",
       "      <td id=\"T_d4bfb_row0_col5\" class=\"data row0 col5\" >184.0</td>\n",
       "      <td id=\"T_d4bfb_row0_col6\" class=\"data row0 col6\" >-0.7</td>\n",
       "      <td id=\"T_d4bfb_row0_col7\" class=\"data row0 col7\" >38.4</td>\n",
       "      <td id=\"T_d4bfb_row0_col8\" class=\"data row0 col8\" >38.0</td>\n",
       "      <td id=\"T_d4bfb_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_d4bfb_row0_col10\" class=\"data row0 col10\" >12.0</td>\n",
       "      <td id=\"T_d4bfb_row0_col11\" class=\"data row0 col11\" >33.1</td>\n",
       "      <td id=\"T_d4bfb_row0_col12\" class=\"data row0 col12\" >28.3</td>\n",
       "      <td id=\"T_d4bfb_row0_col13\" class=\"data row0 col13\" >7.8</td>\n",
       "      <td id=\"T_d4bfb_row0_col14\" class=\"data row0 col14\" >31.2</td>\n",
       "      <td id=\"T_d4bfb_row0_col15\" class=\"data row0 col15\" >10.0</td>\n",
       "      <td id=\"T_d4bfb_row0_col16\" class=\"data row0 col16\" >36.8</td>\n",
       "      <td id=\"T_d4bfb_row0_col17\" class=\"data row0 col17\" >-53.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4bfb_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d4bfb_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_d4bfb_row1_col1\" class=\"data row1 col1\" >10000.0</td>\n",
       "      <td id=\"T_d4bfb_row1_col2\" class=\"data row1 col2\" >1000.0</td>\n",
       "      <td id=\"T_d4bfb_row1_col3\" class=\"data row1 col3\" >42.0</td>\n",
       "      <td id=\"T_d4bfb_row1_col4\" class=\"data row1 col4\" >42.3</td>\n",
       "      <td id=\"T_d4bfb_row1_col5\" class=\"data row1 col5\" >160.0</td>\n",
       "      <td id=\"T_d4bfb_row1_col6\" class=\"data row1 col6\" >-1.0</td>\n",
       "      <td id=\"T_d4bfb_row1_col7\" class=\"data row1 col7\" >35.5</td>\n",
       "      <td id=\"T_d4bfb_row1_col8\" class=\"data row1 col8\" >36.7</td>\n",
       "      <td id=\"T_d4bfb_row1_col9\" class=\"data row1 col9\" >7.2</td>\n",
       "      <td id=\"T_d4bfb_row1_col10\" class=\"data row1 col10\" >9.8</td>\n",
       "      <td id=\"T_d4bfb_row1_col11\" class=\"data row1 col11\" >30.5</td>\n",
       "      <td id=\"T_d4bfb_row1_col12\" class=\"data row1 col12\" >28.1</td>\n",
       "      <td id=\"T_d4bfb_row1_col13\" class=\"data row1 col13\" >8.8</td>\n",
       "      <td id=\"T_d4bfb_row1_col14\" class=\"data row1 col14\" >32.4</td>\n",
       "      <td id=\"T_d4bfb_row1_col15\" class=\"data row1 col15\" >8.9</td>\n",
       "      <td id=\"T_d4bfb_row1_col16\" class=\"data row1 col16\" >33.9</td>\n",
       "      <td id=\"T_d4bfb_row1_col17\" class=\"data row1 col17\" >-62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4bfb_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d4bfb_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_d4bfb_row2_col1\" class=\"data row2 col1\" >10000.0</td>\n",
       "      <td id=\"T_d4bfb_row2_col2\" class=\"data row2 col2\" >1000.0</td>\n",
       "      <td id=\"T_d4bfb_row2_col3\" class=\"data row2 col3\" >40.5</td>\n",
       "      <td id=\"T_d4bfb_row2_col4\" class=\"data row2 col4\" >40.7</td>\n",
       "      <td id=\"T_d4bfb_row2_col5\" class=\"data row2 col5\" >156.0</td>\n",
       "      <td id=\"T_d4bfb_row2_col6\" class=\"data row2 col6\" >-1.9</td>\n",
       "      <td id=\"T_d4bfb_row2_col7\" class=\"data row2 col7\" >35.1</td>\n",
       "      <td id=\"T_d4bfb_row2_col8\" class=\"data row2 col8\" >36.9</td>\n",
       "      <td id=\"T_d4bfb_row2_col9\" class=\"data row2 col9\" >5.6</td>\n",
       "      <td id=\"T_d4bfb_row2_col10\" class=\"data row2 col10\" >9.4</td>\n",
       "      <td id=\"T_d4bfb_row2_col11\" class=\"data row2 col11\" >32.3</td>\n",
       "      <td id=\"T_d4bfb_row2_col12\" class=\"data row2 col12\" >30.9</td>\n",
       "      <td id=\"T_d4bfb_row2_col13\" class=\"data row2 col13\" >7.7</td>\n",
       "      <td id=\"T_d4bfb_row2_col14\" class=\"data row2 col14\" >29.6</td>\n",
       "      <td id=\"T_d4bfb_row2_col15\" class=\"data row2 col15\" >11.0</td>\n",
       "      <td id=\"T_d4bfb_row2_col16\" class=\"data row2 col16\" >33.4</td>\n",
       "      <td id=\"T_d4bfb_row2_col17\" class=\"data row2 col17\" >-66.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4bfb_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d4bfb_row3_col0\" class=\"data row3 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_d4bfb_row3_col1\" class=\"data row3 col1\" >10000.0</td>\n",
       "      <td id=\"T_d4bfb_row3_col2\" class=\"data row3 col2\" >1000.0</td>\n",
       "      <td id=\"T_d4bfb_row3_col3\" class=\"data row3 col3\" >41.8</td>\n",
       "      <td id=\"T_d4bfb_row3_col4\" class=\"data row3 col4\" >42.2</td>\n",
       "      <td id=\"T_d4bfb_row3_col5\" class=\"data row3 col5\" >152.0</td>\n",
       "      <td id=\"T_d4bfb_row3_col6\" class=\"data row3 col6\" >-0.7</td>\n",
       "      <td id=\"T_d4bfb_row3_col7\" class=\"data row3 col7\" >33.7</td>\n",
       "      <td id=\"T_d4bfb_row3_col8\" class=\"data row3 col8\" >37.8</td>\n",
       "      <td id=\"T_d4bfb_row3_col9\" class=\"data row3 col9\" >6.6</td>\n",
       "      <td id=\"T_d4bfb_row3_col10\" class=\"data row3 col10\" >8.6</td>\n",
       "      <td id=\"T_d4bfb_row3_col11\" class=\"data row3 col11\" >30.5</td>\n",
       "      <td id=\"T_d4bfb_row3_col12\" class=\"data row3 col12\" >30.1</td>\n",
       "      <td id=\"T_d4bfb_row3_col13\" class=\"data row3 col13\" >7.1</td>\n",
       "      <td id=\"T_d4bfb_row3_col14\" class=\"data row3 col14\" >27.6</td>\n",
       "      <td id=\"T_d4bfb_row3_col15\" class=\"data row3 col15\" >6.3</td>\n",
       "      <td id=\"T_d4bfb_row3_col16\" class=\"data row3 col16\" >32.6</td>\n",
       "      <td id=\"T_d4bfb_row3_col17\" class=\"data row3 col17\" >-74.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb46680d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_de8b5 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_de8b5_row0_col0, #T_de8b5_row1_col0, #T_de8b5_row2_col0, #T_de8b5_row3_col0, #T_de8b5_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_de8b5_row0_col1, #T_de8b5_row0_col2, #T_de8b5_row0_col7, #T_de8b5_row0_col10, #T_de8b5_row0_col12, #T_de8b5_row1_col1, #T_de8b5_row1_col2, #T_de8b5_row1_col8, #T_de8b5_row1_col9, #T_de8b5_row2_col1, #T_de8b5_row2_col2, #T_de8b5_row2_col3, #T_de8b5_row2_col4, #T_de8b5_row2_col10, #T_de8b5_row2_col15, #T_de8b5_row3_col1, #T_de8b5_row3_col2, #T_de8b5_row3_col6, #T_de8b5_row3_col10, #T_de8b5_row4_col1, #T_de8b5_row4_col2, #T_de8b5_row4_col5, #T_de8b5_row4_col11, #T_de8b5_row4_col13, #T_de8b5_row4_col14, #T_de8b5_row4_col16, #T_de8b5_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de8b5_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de8b5_row0_col5, #T_de8b5_row0_col16, #T_de8b5_row1_col3, #T_de8b5_row1_col4, #T_de8b5_row1_col6, #T_de8b5_row1_col10, #T_de8b5_row1_col11, #T_de8b5_row1_col14, #T_de8b5_row1_col15, #T_de8b5_row1_col17, #T_de8b5_row2_col7, #T_de8b5_row2_col9, #T_de8b5_row2_col12, #T_de8b5_row2_col13, #T_de8b5_row3_col8, #T_de8b5_row4_col9, #T_de8b5_row4_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de8b5_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row0_col9, #T_de8b5_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de8b5_row0_col13, #T_de8b5_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de8b5_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de8b5_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de8b5_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de8b5_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row2_col11, #T_de8b5_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de8b5_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de8b5_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de8b5_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de8b5_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_de8b5_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_de8b5_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_de8b5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_de8b5_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_de8b5_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_de8b5_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_de8b5_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_de8b5_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_de8b5_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_de8b5_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_de8b5_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_de8b5_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_de8b5_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_de8b5_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_de8b5_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_de8b5_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_de8b5_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_de8b5_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_de8b5_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_de8b5_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_de8b5_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_de8b5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_de8b5_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_de8b5_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_de8b5_row0_col2\" class=\"data row0 col2\" >10000</td>\n",
       "      <td id=\"T_de8b5_row0_col3\" class=\"data row0 col3\" >47.8</td>\n",
       "      <td id=\"T_de8b5_row0_col4\" class=\"data row0 col4\" >48.2</td>\n",
       "      <td id=\"T_de8b5_row0_col5\" class=\"data row0 col5\" >196.0</td>\n",
       "      <td id=\"T_de8b5_row0_col6\" class=\"data row0 col6\" >-3.1</td>\n",
       "      <td id=\"T_de8b5_row0_col7\" class=\"data row0 col7\" >36.7</td>\n",
       "      <td id=\"T_de8b5_row0_col8\" class=\"data row0 col8\" >35.9</td>\n",
       "      <td id=\"T_de8b5_row0_col9\" class=\"data row0 col9\" >5.6</td>\n",
       "      <td id=\"T_de8b5_row0_col10\" class=\"data row0 col10\" >9.4</td>\n",
       "      <td id=\"T_de8b5_row0_col11\" class=\"data row0 col11\" >33.0</td>\n",
       "      <td id=\"T_de8b5_row0_col12\" class=\"data row0 col12\" >33.2</td>\n",
       "      <td id=\"T_de8b5_row0_col13\" class=\"data row0 col13\" >8.3</td>\n",
       "      <td id=\"T_de8b5_row0_col14\" class=\"data row0 col14\" >31.9</td>\n",
       "      <td id=\"T_de8b5_row0_col15\" class=\"data row0 col15\" >11.6</td>\n",
       "      <td id=\"T_de8b5_row0_col16\" class=\"data row0 col16\" >38.0</td>\n",
       "      <td id=\"T_de8b5_row0_col17\" class=\"data row0 col17\" >-52.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de8b5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_de8b5_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_de8b5_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_de8b5_row1_col2\" class=\"data row1 col2\" >10000</td>\n",
       "      <td id=\"T_de8b5_row1_col3\" class=\"data row1 col3\" >48.8</td>\n",
       "      <td id=\"T_de8b5_row1_col4\" class=\"data row1 col4\" >49.2</td>\n",
       "      <td id=\"T_de8b5_row1_col5\" class=\"data row1 col5\" >178.0</td>\n",
       "      <td id=\"T_de8b5_row1_col6\" class=\"data row1 col6\" >-2.7</td>\n",
       "      <td id=\"T_de8b5_row1_col7\" class=\"data row1 col7\" >37.0</td>\n",
       "      <td id=\"T_de8b5_row1_col8\" class=\"data row1 col8\" >34.9</td>\n",
       "      <td id=\"T_de8b5_row1_col9\" class=\"data row1 col9\" >5.2</td>\n",
       "      <td id=\"T_de8b5_row1_col10\" class=\"data row1 col10\" >10.8</td>\n",
       "      <td id=\"T_de8b5_row1_col11\" class=\"data row1 col11\" >33.2</td>\n",
       "      <td id=\"T_de8b5_row1_col12\" class=\"data row1 col12\" >34.2</td>\n",
       "      <td id=\"T_de8b5_row1_col13\" class=\"data row1 col13\" >8.7</td>\n",
       "      <td id=\"T_de8b5_row1_col14\" class=\"data row1 col14\" >32.1</td>\n",
       "      <td id=\"T_de8b5_row1_col15\" class=\"data row1 col15\" >12.6</td>\n",
       "      <td id=\"T_de8b5_row1_col16\" class=\"data row1 col16\" >37.1</td>\n",
       "      <td id=\"T_de8b5_row1_col17\" class=\"data row1 col17\" >-48.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de8b5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_de8b5_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_de8b5_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_de8b5_row2_col2\" class=\"data row2 col2\" >10000</td>\n",
       "      <td id=\"T_de8b5_row2_col3\" class=\"data row2 col3\" >44.8</td>\n",
       "      <td id=\"T_de8b5_row2_col4\" class=\"data row2 col4\" >44.8</td>\n",
       "      <td id=\"T_de8b5_row2_col5\" class=\"data row2 col5\" >180.0</td>\n",
       "      <td id=\"T_de8b5_row2_col6\" class=\"data row2 col6\" >-3.5</td>\n",
       "      <td id=\"T_de8b5_row2_col7\" class=\"data row2 col7\" >38.7</td>\n",
       "      <td id=\"T_de8b5_row2_col8\" class=\"data row2 col8\" >37.5</td>\n",
       "      <td id=\"T_de8b5_row2_col9\" class=\"data row2 col9\" >6.4</td>\n",
       "      <td id=\"T_de8b5_row2_col10\" class=\"data row2 col10\" >9.4</td>\n",
       "      <td id=\"T_de8b5_row2_col11\" class=\"data row2 col11\" >32.8</td>\n",
       "      <td id=\"T_de8b5_row2_col12\" class=\"data row2 col12\" >35.1</td>\n",
       "      <td id=\"T_de8b5_row2_col13\" class=\"data row2 col13\" >9.1</td>\n",
       "      <td id=\"T_de8b5_row2_col14\" class=\"data row2 col14\" >30.3</td>\n",
       "      <td id=\"T_de8b5_row2_col15\" class=\"data row2 col15\" >8.9</td>\n",
       "      <td id=\"T_de8b5_row2_col16\" class=\"data row2 col16\" >36.5</td>\n",
       "      <td id=\"T_de8b5_row2_col17\" class=\"data row2 col17\" >-52.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de8b5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_de8b5_row3_col0\" class=\"data row3 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_de8b5_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_de8b5_row3_col2\" class=\"data row3 col2\" >10000</td>\n",
       "      <td id=\"T_de8b5_row3_col3\" class=\"data row3 col3\" >45.9</td>\n",
       "      <td id=\"T_de8b5_row3_col4\" class=\"data row3 col4\" >46.1</td>\n",
       "      <td id=\"T_de8b5_row3_col5\" class=\"data row3 col5\" >165.0</td>\n",
       "      <td id=\"T_de8b5_row3_col6\" class=\"data row3 col6\" >-3.6</td>\n",
       "      <td id=\"T_de8b5_row3_col7\" class=\"data row3 col7\" >38.2</td>\n",
       "      <td id=\"T_de8b5_row3_col8\" class=\"data row3 col8\" >38.5</td>\n",
       "      <td id=\"T_de8b5_row3_col9\" class=\"data row3 col9\" >6.0</td>\n",
       "      <td id=\"T_de8b5_row3_col10\" class=\"data row3 col10\" >9.4</td>\n",
       "      <td id=\"T_de8b5_row3_col11\" class=\"data row3 col11\" >32.5</td>\n",
       "      <td id=\"T_de8b5_row3_col12\" class=\"data row3 col12\" >33.7</td>\n",
       "      <td id=\"T_de8b5_row3_col13\" class=\"data row3 col13\" >8.3</td>\n",
       "      <td id=\"T_de8b5_row3_col14\" class=\"data row3 col14\" >29.7</td>\n",
       "      <td id=\"T_de8b5_row3_col15\" class=\"data row3 col15\" >10.2</td>\n",
       "      <td id=\"T_de8b5_row3_col16\" class=\"data row3 col16\" >35.4</td>\n",
       "      <td id=\"T_de8b5_row3_col17\" class=\"data row3 col17\" >-56.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de8b5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_de8b5_row4_col0\" class=\"data row4 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-2:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_de8b5_row4_col1\" class=\"data row4 col1\" >30000</td>\n",
       "      <td id=\"T_de8b5_row4_col2\" class=\"data row4 col2\" >10000</td>\n",
       "      <td id=\"T_de8b5_row4_col3\" class=\"data row4 col3\" >45.5</td>\n",
       "      <td id=\"T_de8b5_row4_col4\" class=\"data row4 col4\" >45.7</td>\n",
       "      <td id=\"T_de8b5_row4_col5\" class=\"data row4 col5\" >159.0</td>\n",
       "      <td id=\"T_de8b5_row4_col6\" class=\"data row4 col6\" >-3.2</td>\n",
       "      <td id=\"T_de8b5_row4_col7\" class=\"data row4 col7\" >37.3</td>\n",
       "      <td id=\"T_de8b5_row4_col8\" class=\"data row4 col8\" >37.8</td>\n",
       "      <td id=\"T_de8b5_row4_col9\" class=\"data row4 col9\" >6.4</td>\n",
       "      <td id=\"T_de8b5_row4_col10\" class=\"data row4 col10\" >9.8</td>\n",
       "      <td id=\"T_de8b5_row4_col11\" class=\"data row4 col11\" >31.9</td>\n",
       "      <td id=\"T_de8b5_row4_col12\" class=\"data row4 col12\" >34.4</td>\n",
       "      <td id=\"T_de8b5_row4_col13\" class=\"data row4 col13\" >7.1</td>\n",
       "      <td id=\"T_de8b5_row4_col14\" class=\"data row4 col14\" >28.2</td>\n",
       "      <td id=\"T_de8b5_row4_col15\" class=\"data row4 col15\" >12.6</td>\n",
       "      <td id=\"T_de8b5_row4_col16\" class=\"data row4 col16\" >34.8</td>\n",
       "      <td id=\"T_de8b5_row4_col17\" class=\"data row4 col17\" >-60.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb6bf6440>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c58cb td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_c58cb_row0_col0, #T_c58cb_row1_col0, #T_c58cb_row2_col0, #T_c58cb_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c58cb_row0_col1, #T_c58cb_row0_col2, #T_c58cb_row0_col7, #T_c58cb_row0_col12, #T_c58cb_row1_col1, #T_c58cb_row1_col2, #T_c58cb_row1_col9, #T_c58cb_row1_col11, #T_c58cb_row2_col1, #T_c58cb_row2_col2, #T_c58cb_row2_col6, #T_c58cb_row2_col13, #T_c58cb_row2_col14, #T_c58cb_row3_col1, #T_c58cb_row3_col2, #T_c58cb_row3_col3, #T_c58cb_row3_col4, #T_c58cb_row3_col5, #T_c58cb_row3_col8, #T_c58cb_row3_col10, #T_c58cb_row3_col15, #T_c58cb_row3_col16, #T_c58cb_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c58cb_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row0_col5, #T_c58cb_row0_col6, #T_c58cb_row0_col8, #T_c58cb_row0_col16, #T_c58cb_row1_col7, #T_c58cb_row1_col10, #T_c58cb_row1_col12, #T_c58cb_row1_col13, #T_c58cb_row1_col14, #T_c58cb_row1_col15, #T_c58cb_row1_col17, #T_c58cb_row2_col3, #T_c58cb_row2_col4, #T_c58cb_row2_col9, #T_c58cb_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c58cb_row0_col9, #T_c58cb_row1_col6, #T_c58cb_row3_col6, #T_c58cb_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row0_col10, #T_c58cb_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row0_col15, #T_c58cb_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row1_col3, #T_c58cb_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row1_col5, #T_c58cb_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c58cb_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c58cb_row2_col7, #T_c58cb_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row2_col11, #T_c58cb_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c58cb_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c58cb_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c58cb_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c58cb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c58cb_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_c58cb_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_c58cb_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_c58cb_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_c58cb_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_c58cb_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_c58cb_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_c58cb_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_c58cb_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_c58cb_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_c58cb_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_c58cb_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_c58cb_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_c58cb_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_c58cb_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_c58cb_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_c58cb_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_c58cb_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c58cb_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c58cb_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_c58cb_row0_col1\" class=\"data row0 col1\" >60000</td>\n",
       "      <td id=\"T_c58cb_row0_col2\" class=\"data row0 col2\" >20000</td>\n",
       "      <td id=\"T_c58cb_row0_col3\" class=\"data row0 col3\" >48.9</td>\n",
       "      <td id=\"T_c58cb_row0_col4\" class=\"data row0 col4\" >49.4</td>\n",
       "      <td id=\"T_c58cb_row0_col5\" class=\"data row0 col5\" >181.0</td>\n",
       "      <td id=\"T_c58cb_row0_col6\" class=\"data row0 col6\" >-2.0</td>\n",
       "      <td id=\"T_c58cb_row0_col7\" class=\"data row0 col7\" >37.3</td>\n",
       "      <td id=\"T_c58cb_row0_col8\" class=\"data row0 col8\" >36.6</td>\n",
       "      <td id=\"T_c58cb_row0_col9\" class=\"data row0 col9\" >5.8</td>\n",
       "      <td id=\"T_c58cb_row0_col10\" class=\"data row0 col10\" >10.6</td>\n",
       "      <td id=\"T_c58cb_row0_col11\" class=\"data row0 col11\" >32.7</td>\n",
       "      <td id=\"T_c58cb_row0_col12\" class=\"data row0 col12\" >33.1</td>\n",
       "      <td id=\"T_c58cb_row0_col13\" class=\"data row0 col13\" >7.9</td>\n",
       "      <td id=\"T_c58cb_row0_col14\" class=\"data row0 col14\" >30.4</td>\n",
       "      <td id=\"T_c58cb_row0_col15\" class=\"data row0 col15\" >11.2</td>\n",
       "      <td id=\"T_c58cb_row0_col16\" class=\"data row0 col16\" >37.1</td>\n",
       "      <td id=\"T_c58cb_row0_col17\" class=\"data row0 col17\" >-51.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c58cb_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c58cb_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_c58cb_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_c58cb_row1_col2\" class=\"data row1 col2\" >20000</td>\n",
       "      <td id=\"T_c58cb_row1_col3\" class=\"data row1 col3\" >49.1</td>\n",
       "      <td id=\"T_c58cb_row1_col4\" class=\"data row1 col4\" >49.3</td>\n",
       "      <td id=\"T_c58cb_row1_col5\" class=\"data row1 col5\" >171.0</td>\n",
       "      <td id=\"T_c58cb_row1_col6\" class=\"data row1 col6\" >-2.2</td>\n",
       "      <td id=\"T_c58cb_row1_col7\" class=\"data row1 col7\" >39.4</td>\n",
       "      <td id=\"T_c58cb_row1_col8\" class=\"data row1 col8\" >35.9</td>\n",
       "      <td id=\"T_c58cb_row1_col9\" class=\"data row1 col9\" >5.6</td>\n",
       "      <td id=\"T_c58cb_row1_col10\" class=\"data row1 col10\" >11.8</td>\n",
       "      <td id=\"T_c58cb_row1_col11\" class=\"data row1 col11\" >32.3</td>\n",
       "      <td id=\"T_c58cb_row1_col12\" class=\"data row1 col12\" >34.6</td>\n",
       "      <td id=\"T_c58cb_row1_col13\" class=\"data row1 col13\" >8.5</td>\n",
       "      <td id=\"T_c58cb_row1_col14\" class=\"data row1 col14\" >31.8</td>\n",
       "      <td id=\"T_c58cb_row1_col15\" class=\"data row1 col15\" >11.6</td>\n",
       "      <td id=\"T_c58cb_row1_col16\" class=\"data row1 col16\" >36.8</td>\n",
       "      <td id=\"T_c58cb_row1_col17\" class=\"data row1 col17\" >-44.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c58cb_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c58cb_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_c58cb_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_c58cb_row2_col2\" class=\"data row2 col2\" >20000</td>\n",
       "      <td id=\"T_c58cb_row2_col3\" class=\"data row2 col3\" >50.7</td>\n",
       "      <td id=\"T_c58cb_row2_col4\" class=\"data row2 col4\" >50.7</td>\n",
       "      <td id=\"T_c58cb_row2_col5\" class=\"data row2 col5\" >171.0</td>\n",
       "      <td id=\"T_c58cb_row2_col6\" class=\"data row2 col6\" >-2.4</td>\n",
       "      <td id=\"T_c58cb_row2_col7\" class=\"data row2 col7\" >37.9</td>\n",
       "      <td id=\"T_c58cb_row2_col8\" class=\"data row2 col8\" >35.1</td>\n",
       "      <td id=\"T_c58cb_row2_col9\" class=\"data row2 col9\" >6.2</td>\n",
       "      <td id=\"T_c58cb_row2_col10\" class=\"data row2 col10\" >11.0</td>\n",
       "      <td id=\"T_c58cb_row2_col11\" class=\"data row2 col11\" >32.6</td>\n",
       "      <td id=\"T_c58cb_row2_col12\" class=\"data row2 col12\" >34.2</td>\n",
       "      <td id=\"T_c58cb_row2_col13\" class=\"data row2 col13\" >7.5</td>\n",
       "      <td id=\"T_c58cb_row2_col14\" class=\"data row2 col14\" >30.0</td>\n",
       "      <td id=\"T_c58cb_row2_col15\" class=\"data row2 col15\" >10.8</td>\n",
       "      <td id=\"T_c58cb_row2_col16\" class=\"data row2 col16\" >36.6</td>\n",
       "      <td id=\"T_c58cb_row2_col17\" class=\"data row2 col17\" >-54.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c58cb_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c58cb_row3_col0\" class=\"data row3 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_c58cb_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_c58cb_row3_col2\" class=\"data row3 col2\" >20000</td>\n",
       "      <td id=\"T_c58cb_row3_col3\" class=\"data row3 col3\" >45.5</td>\n",
       "      <td id=\"T_c58cb_row3_col4\" class=\"data row3 col4\" >45.8</td>\n",
       "      <td id=\"T_c58cb_row3_col5\" class=\"data row3 col5\" >170.0</td>\n",
       "      <td id=\"T_c58cb_row3_col6\" class=\"data row3 col6\" >-2.2</td>\n",
       "      <td id=\"T_c58cb_row3_col7\" class=\"data row3 col7\" >38.9</td>\n",
       "      <td id=\"T_c58cb_row3_col8\" class=\"data row3 col8\" >34.5</td>\n",
       "      <td id=\"T_c58cb_row3_col9\" class=\"data row3 col9\" >5.8</td>\n",
       "      <td id=\"T_c58cb_row3_col10\" class=\"data row3 col10\" >9.0</td>\n",
       "      <td id=\"T_c58cb_row3_col11\" class=\"data row3 col11\" >33.0</td>\n",
       "      <td id=\"T_c58cb_row3_col12\" class=\"data row3 col12\" >33.5</td>\n",
       "      <td id=\"T_c58cb_row3_col13\" class=\"data row3 col13\" >8.2</td>\n",
       "      <td id=\"T_c58cb_row3_col14\" class=\"data row3 col14\" >31.2</td>\n",
       "      <td id=\"T_c58cb_row3_col15\" class=\"data row3 col15\" >10.2</td>\n",
       "      <td id=\"T_c58cb_row3_col16\" class=\"data row3 col16\" >35.6</td>\n",
       "      <td id=\"T_c58cb_row3_col17\" class=\"data row3 col17\" >-56.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb6bf66b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ef7af td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_ef7af_row0_col0, #T_ef7af_row1_col0, #T_ef7af_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ef7af_row0_col1, #T_ef7af_row0_col2, #T_ef7af_row0_col7, #T_ef7af_row1_col1, #T_ef7af_row1_col2, #T_ef7af_row1_col5, #T_ef7af_row1_col9, #T_ef7af_row2_col1, #T_ef7af_row2_col2, #T_ef7af_row2_col3, #T_ef7af_row2_col4, #T_ef7af_row2_col6, #T_ef7af_row2_col8, #T_ef7af_row2_col10, #T_ef7af_row2_col11, #T_ef7af_row2_col12, #T_ef7af_row2_col13, #T_ef7af_row2_col14, #T_ef7af_row2_col15, #T_ef7af_row2_col16, #T_ef7af_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ef7af_row0_col3, #T_ef7af_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ef7af_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ef7af_row0_col5, #T_ef7af_row0_col8, #T_ef7af_row0_col10, #T_ef7af_row0_col11, #T_ef7af_row0_col12, #T_ef7af_row0_col14, #T_ef7af_row0_col16, #T_ef7af_row0_col17, #T_ef7af_row1_col3, #T_ef7af_row1_col4, #T_ef7af_row1_col6, #T_ef7af_row1_col7, #T_ef7af_row1_col13, #T_ef7af_row1_col15, #T_ef7af_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ef7af_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ef7af_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ef7af_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ef7af_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ef7af_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ef7af_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ef7af_row1_col11, #T_ef7af_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ef7af_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ef7af_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ef7af_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ef7af_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d55042;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ef7af\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ef7af_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_ef7af_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_ef7af_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_ef7af_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_ef7af_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_ef7af_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_ef7af_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_ef7af_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_ef7af_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_ef7af_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_ef7af_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_ef7af_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_ef7af_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_ef7af_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_ef7af_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_ef7af_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_ef7af_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_ef7af_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ef7af_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ef7af_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_ef7af_row0_col1\" class=\"data row0 col1\" >90000</td>\n",
       "      <td id=\"T_ef7af_row0_col2\" class=\"data row0 col2\" >30000</td>\n",
       "      <td id=\"T_ef7af_row0_col3\" class=\"data row0 col3\" >51.1</td>\n",
       "      <td id=\"T_ef7af_row0_col4\" class=\"data row0 col4\" >51.3</td>\n",
       "      <td id=\"T_ef7af_row0_col5\" class=\"data row0 col5\" >180.0</td>\n",
       "      <td id=\"T_ef7af_row0_col6\" class=\"data row0 col6\" >-1.5</td>\n",
       "      <td id=\"T_ef7af_row0_col7\" class=\"data row0 col7\" >36.7</td>\n",
       "      <td id=\"T_ef7af_row0_col8\" class=\"data row0 col8\" >37.4</td>\n",
       "      <td id=\"T_ef7af_row0_col9\" class=\"data row0 col9\" >5.6</td>\n",
       "      <td id=\"T_ef7af_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_ef7af_row0_col11\" class=\"data row0 col11\" >33.5</td>\n",
       "      <td id=\"T_ef7af_row0_col12\" class=\"data row0 col12\" >35.5</td>\n",
       "      <td id=\"T_ef7af_row0_col13\" class=\"data row0 col13\" >7.8</td>\n",
       "      <td id=\"T_ef7af_row0_col14\" class=\"data row0 col14\" >32.6</td>\n",
       "      <td id=\"T_ef7af_row0_col15\" class=\"data row0 col15\" >10.2</td>\n",
       "      <td id=\"T_ef7af_row0_col16\" class=\"data row0 col16\" >37.8</td>\n",
       "      <td id=\"T_ef7af_row0_col17\" class=\"data row0 col17\" >-40.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef7af_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ef7af_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_ef7af_row1_col1\" class=\"data row1 col1\" >90000</td>\n",
       "      <td id=\"T_ef7af_row1_col2\" class=\"data row1 col2\" >30000</td>\n",
       "      <td id=\"T_ef7af_row1_col3\" class=\"data row1 col3\" >51.4</td>\n",
       "      <td id=\"T_ef7af_row1_col4\" class=\"data row1 col4\" >51.4</td>\n",
       "      <td id=\"T_ef7af_row1_col5\" class=\"data row1 col5\" >173.0</td>\n",
       "      <td id=\"T_ef7af_row1_col6\" class=\"data row1 col6\" >-1.2</td>\n",
       "      <td id=\"T_ef7af_row1_col7\" class=\"data row1 col7\" >38.8</td>\n",
       "      <td id=\"T_ef7af_row1_col8\" class=\"data row1 col8\" >36.3</td>\n",
       "      <td id=\"T_ef7af_row1_col9\" class=\"data row1 col9\" >5.4</td>\n",
       "      <td id=\"T_ef7af_row1_col10\" class=\"data row1 col10\" >11.0</td>\n",
       "      <td id=\"T_ef7af_row1_col11\" class=\"data row1 col11\" >32.3</td>\n",
       "      <td id=\"T_ef7af_row1_col12\" class=\"data row1 col12\" >35.3</td>\n",
       "      <td id=\"T_ef7af_row1_col13\" class=\"data row1 col13\" >8.2</td>\n",
       "      <td id=\"T_ef7af_row1_col14\" class=\"data row1 col14\" >32.5</td>\n",
       "      <td id=\"T_ef7af_row1_col15\" class=\"data row1 col15\" >10.8</td>\n",
       "      <td id=\"T_ef7af_row1_col16\" class=\"data row1 col16\" >37.3</td>\n",
       "      <td id=\"T_ef7af_row1_col17\" class=\"data row1 col17\" >-42.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ef7af_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ef7af_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_ef7af_row2_col1\" class=\"data row2 col1\" >90000</td>\n",
       "      <td id=\"T_ef7af_row2_col2\" class=\"data row2 col2\" >30000</td>\n",
       "      <td id=\"T_ef7af_row2_col3\" class=\"data row2 col3\" >51.0</td>\n",
       "      <td id=\"T_ef7af_row2_col4\" class=\"data row2 col4\" >51.1</td>\n",
       "      <td id=\"T_ef7af_row2_col5\" class=\"data row2 col5\" >178.0</td>\n",
       "      <td id=\"T_ef7af_row2_col6\" class=\"data row2 col6\" >-2.2</td>\n",
       "      <td id=\"T_ef7af_row2_col7\" class=\"data row2 col7\" >38.6</td>\n",
       "      <td id=\"T_ef7af_row2_col8\" class=\"data row2 col8\" >35.5</td>\n",
       "      <td id=\"T_ef7af_row2_col9\" class=\"data row2 col9\" >5.8</td>\n",
       "      <td id=\"T_ef7af_row2_col10\" class=\"data row2 col10\" >10.8</td>\n",
       "      <td id=\"T_ef7af_row2_col11\" class=\"data row2 col11\" >30.6</td>\n",
       "      <td id=\"T_ef7af_row2_col12\" class=\"data row2 col12\" >35.2</td>\n",
       "      <td id=\"T_ef7af_row2_col13\" class=\"data row2 col13\" >7.7</td>\n",
       "      <td id=\"T_ef7af_row2_col14\" class=\"data row2 col14\" >32.4</td>\n",
       "      <td id=\"T_ef7af_row2_col15\" class=\"data row2 col15\" >9.3</td>\n",
       "      <td id=\"T_ef7af_row2_col16\" class=\"data row2 col16\" >37.2</td>\n",
       "      <td id=\"T_ef7af_row2_col17\" class=\"data row2 col17\" >-52.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb6bf58d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_43c20 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_43c20_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_43c20_row0_col1, #T_43c20_row0_col2, #T_43c20_row0_col3, #T_43c20_row0_col4, #T_43c20_row0_col5, #T_43c20_row0_col6, #T_43c20_row0_col7, #T_43c20_row0_col8, #T_43c20_row0_col9, #T_43c20_row0_col10, #T_43c20_row0_col11, #T_43c20_row0_col12, #T_43c20_row0_col13, #T_43c20_row0_col14, #T_43c20_row0_col15, #T_43c20_row0_col16, #T_43c20_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_43c20\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_43c20_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_43c20_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_43c20_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_43c20_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_43c20_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_43c20_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_43c20_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_43c20_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_43c20_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_43c20_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_43c20_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_43c20_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_43c20_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_43c20_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_43c20_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_43c20_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_43c20_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_43c20_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_43c20_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_43c20_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_43c20_row0_col1\" class=\"data row0 col1\" >100000</td>\n",
       "      <td id=\"T_43c20_row0_col2\" class=\"data row0 col2\" >50000</td>\n",
       "      <td id=\"T_43c20_row0_col3\" class=\"data row0 col3\" >48.5</td>\n",
       "      <td id=\"T_43c20_row0_col4\" class=\"data row0 col4\" >49.0</td>\n",
       "      <td id=\"T_43c20_row0_col5\" class=\"data row0 col5\" >173.0</td>\n",
       "      <td id=\"T_43c20_row0_col6\" class=\"data row0 col6\" >-2.2</td>\n",
       "      <td id=\"T_43c20_row0_col7\" class=\"data row0 col7\" >38.4</td>\n",
       "      <td id=\"T_43c20_row0_col8\" class=\"data row0 col8\" >36.5</td>\n",
       "      <td id=\"T_43c20_row0_col9\" class=\"data row0 col9\" >6.6</td>\n",
       "      <td id=\"T_43c20_row0_col10\" class=\"data row0 col10\" >10.8</td>\n",
       "      <td id=\"T_43c20_row0_col11\" class=\"data row0 col11\" >31.3</td>\n",
       "      <td id=\"T_43c20_row0_col12\" class=\"data row0 col12\" >34.1</td>\n",
       "      <td id=\"T_43c20_row0_col13\" class=\"data row0 col13\" >7.9</td>\n",
       "      <td id=\"T_43c20_row0_col14\" class=\"data row0 col14\" >33.3</td>\n",
       "      <td id=\"T_43c20_row0_col15\" class=\"data row0 col15\" >11.8</td>\n",
       "      <td id=\"T_43c20_row0_col16\" class=\"data row0 col16\" >36.8</td>\n",
       "      <td id=\"T_43c20_row0_col17\" class=\"data row0 col17\" >-48.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb7cfb9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3bfe8 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_3bfe8_row0_col0, #T_3bfe8_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3bfe8_row0_col1, #T_3bfe8_row0_col2, #T_3bfe8_row0_col3, #T_3bfe8_row0_col4, #T_3bfe8_row0_col6, #T_3bfe8_row0_col12, #T_3bfe8_row0_col14, #T_3bfe8_row0_col15, #T_3bfe8_row1_col1, #T_3bfe8_row1_col2, #T_3bfe8_row1_col5, #T_3bfe8_row1_col7, #T_3bfe8_row1_col8, #T_3bfe8_row1_col9, #T_3bfe8_row1_col10, #T_3bfe8_row1_col11, #T_3bfe8_row1_col13, #T_3bfe8_row1_col16, #T_3bfe8_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bfe8_row0_col5, #T_3bfe8_row0_col7, #T_3bfe8_row0_col8, #T_3bfe8_row0_col9, #T_3bfe8_row0_col10, #T_3bfe8_row0_col11, #T_3bfe8_row0_col13, #T_3bfe8_row0_col16, #T_3bfe8_row0_col17, #T_3bfe8_row1_col3, #T_3bfe8_row1_col4, #T_3bfe8_row1_col6, #T_3bfe8_row1_col12, #T_3bfe8_row1_col14, #T_3bfe8_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3bfe8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3bfe8_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_3bfe8_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_3bfe8_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_3bfe8_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_3bfe8_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_3bfe8_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_3bfe8_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_3bfe8_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_3bfe8_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_3bfe8_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_3bfe8_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_3bfe8_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_3bfe8_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_3bfe8_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_3bfe8_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_3bfe8_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_3bfe8_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_3bfe8_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3bfe8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3bfe8_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=120000:ep=3</td>\n",
       "      <td id=\"T_3bfe8_row0_col1\" class=\"data row0 col1\" >120000</td>\n",
       "      <td id=\"T_3bfe8_row0_col2\" class=\"data row0 col2\" >40000</td>\n",
       "      <td id=\"T_3bfe8_row0_col3\" class=\"data row0 col3\" >51.4</td>\n",
       "      <td id=\"T_3bfe8_row0_col4\" class=\"data row0 col4\" >51.9</td>\n",
       "      <td id=\"T_3bfe8_row0_col5\" class=\"data row0 col5\" >181.0</td>\n",
       "      <td id=\"T_3bfe8_row0_col6\" class=\"data row0 col6\" >-2.1</td>\n",
       "      <td id=\"T_3bfe8_row0_col7\" class=\"data row0 col7\" >38.6</td>\n",
       "      <td id=\"T_3bfe8_row0_col8\" class=\"data row0 col8\" >37.1</td>\n",
       "      <td id=\"T_3bfe8_row0_col9\" class=\"data row0 col9\" >5.2</td>\n",
       "      <td id=\"T_3bfe8_row0_col10\" class=\"data row0 col10\" >12.4</td>\n",
       "      <td id=\"T_3bfe8_row0_col11\" class=\"data row0 col11\" >32.2</td>\n",
       "      <td id=\"T_3bfe8_row0_col12\" class=\"data row0 col12\" >33.6</td>\n",
       "      <td id=\"T_3bfe8_row0_col13\" class=\"data row0 col13\" >7.8</td>\n",
       "      <td id=\"T_3bfe8_row0_col14\" class=\"data row0 col14\" >32.5</td>\n",
       "      <td id=\"T_3bfe8_row0_col15\" class=\"data row0 col15\" >9.8</td>\n",
       "      <td id=\"T_3bfe8_row0_col16\" class=\"data row0 col16\" >37.8</td>\n",
       "      <td id=\"T_3bfe8_row0_col17\" class=\"data row0 col17\" >-47.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bfe8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3bfe8_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=120000:ep=3</td>\n",
       "      <td id=\"T_3bfe8_row1_col1\" class=\"data row1 col1\" >120000</td>\n",
       "      <td id=\"T_3bfe8_row1_col2\" class=\"data row1 col2\" >40000</td>\n",
       "      <td id=\"T_3bfe8_row1_col3\" class=\"data row1 col3\" >52.5</td>\n",
       "      <td id=\"T_3bfe8_row1_col4\" class=\"data row1 col4\" >52.7</td>\n",
       "      <td id=\"T_3bfe8_row1_col5\" class=\"data row1 col5\" >173.0</td>\n",
       "      <td id=\"T_3bfe8_row1_col6\" class=\"data row1 col6\" >-1.5</td>\n",
       "      <td id=\"T_3bfe8_row1_col7\" class=\"data row1 col7\" >37.8</td>\n",
       "      <td id=\"T_3bfe8_row1_col8\" class=\"data row1 col8\" >37.0</td>\n",
       "      <td id=\"T_3bfe8_row1_col9\" class=\"data row1 col9\" >4.8</td>\n",
       "      <td id=\"T_3bfe8_row1_col10\" class=\"data row1 col10\" >10.8</td>\n",
       "      <td id=\"T_3bfe8_row1_col11\" class=\"data row1 col11\" >30.9</td>\n",
       "      <td id=\"T_3bfe8_row1_col12\" class=\"data row1 col12\" >34.7</td>\n",
       "      <td id=\"T_3bfe8_row1_col13\" class=\"data row1 col13\" >7.6</td>\n",
       "      <td id=\"T_3bfe8_row1_col14\" class=\"data row1 col14\" >32.9</td>\n",
       "      <td id=\"T_3bfe8_row1_col15\" class=\"data row1 col15\" >11.6</td>\n",
       "      <td id=\"T_3bfe8_row1_col16\" class=\"data row1 col16\" >37.3</td>\n",
       "      <td id=\"T_3bfe8_row1_col17\" class=\"data row1 col17\" >-48.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb7045840>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d3ce1 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_d3ce1_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d3ce1_row0_col1, #T_d3ce1_row0_col2, #T_d3ce1_row0_col3, #T_d3ce1_row0_col4, #T_d3ce1_row0_col5, #T_d3ce1_row0_col6, #T_d3ce1_row0_col7, #T_d3ce1_row0_col8, #T_d3ce1_row0_col9, #T_d3ce1_row0_col10, #T_d3ce1_row0_col11, #T_d3ce1_row0_col12, #T_d3ce1_row0_col13, #T_d3ce1_row0_col14, #T_d3ce1_row0_col15, #T_d3ce1_row0_col16, #T_d3ce1_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d3ce1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d3ce1_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d3ce1_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_d3ce1_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_d3ce1_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_d3ce1_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_d3ce1_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_d3ce1_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_d3ce1_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d3ce1_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d3ce1_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_d3ce1_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_d3ce1_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_d3ce1_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_d3ce1_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d3ce1_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d3ce1_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d3ce1_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_d3ce1_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d3ce1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d3ce1_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=3</td>\n",
       "      <td id=\"T_d3ce1_row0_col1\" class=\"data row0 col1\" >150000</td>\n",
       "      <td id=\"T_d3ce1_row0_col2\" class=\"data row0 col2\" >50000</td>\n",
       "      <td id=\"T_d3ce1_row0_col3\" class=\"data row0 col3\" >52.5</td>\n",
       "      <td id=\"T_d3ce1_row0_col4\" class=\"data row0 col4\" >52.7</td>\n",
       "      <td id=\"T_d3ce1_row0_col5\" class=\"data row0 col5\" >176.0</td>\n",
       "      <td id=\"T_d3ce1_row0_col6\" class=\"data row0 col6\" >-1.2</td>\n",
       "      <td id=\"T_d3ce1_row0_col7\" class=\"data row0 col7\" >39.1</td>\n",
       "      <td id=\"T_d3ce1_row0_col8\" class=\"data row0 col8\" >36.6</td>\n",
       "      <td id=\"T_d3ce1_row0_col9\" class=\"data row0 col9\" >5.6</td>\n",
       "      <td id=\"T_d3ce1_row0_col10\" class=\"data row0 col10\" >10.0</td>\n",
       "      <td id=\"T_d3ce1_row0_col11\" class=\"data row0 col11\" >30.7</td>\n",
       "      <td id=\"T_d3ce1_row0_col12\" class=\"data row0 col12\" >33.4</td>\n",
       "      <td id=\"T_d3ce1_row0_col13\" class=\"data row0 col13\" >7.9</td>\n",
       "      <td id=\"T_d3ce1_row0_col14\" class=\"data row0 col14\" >32.5</td>\n",
       "      <td id=\"T_d3ce1_row0_col15\" class=\"data row0 col15\" >10.4</td>\n",
       "      <td id=\"T_d3ce1_row0_col16\" class=\"data row0 col16\" >37.4</td>\n",
       "      <td id=\"T_d3ce1_row0_col17\" class=\"data row0 col17\" >-49.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb72a4f40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_72005 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_72005_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_72005_row0_col1, #T_72005_row0_col2, #T_72005_row0_col3, #T_72005_row0_col4, #T_72005_row0_col5, #T_72005_row0_col6, #T_72005_row0_col7, #T_72005_row0_col8, #T_72005_row0_col9, #T_72005_row0_col10, #T_72005_row0_col11, #T_72005_row0_col12, #T_72005_row0_col13, #T_72005_row0_col14, #T_72005_row0_col15, #T_72005_row0_col16, #T_72005_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_72005\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_72005_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_72005_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_72005_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_72005_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_72005_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_72005_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_72005_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_72005_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_72005_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_72005_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_72005_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_72005_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_72005_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_72005_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_72005_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_72005_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_72005_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_72005_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_72005_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_72005_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_72005_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_72005_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_72005_row0_col3\" class=\"data row0 col3\" >0.0</td>\n",
       "      <td id=\"T_72005_row0_col4\" class=\"data row0 col4\" >0.1</td>\n",
       "      <td id=\"T_72005_row0_col5\" class=\"data row0 col5\" >2011.0</td>\n",
       "      <td id=\"T_72005_row0_col6\" class=\"data row0 col6\" >-95.7</td>\n",
       "      <td id=\"T_72005_row0_col7\" class=\"data row0 col7\" >31.8</td>\n",
       "      <td id=\"T_72005_row0_col8\" class=\"data row0 col8\" >34.5</td>\n",
       "      <td id=\"T_72005_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_72005_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_72005_row0_col11\" class=\"data row0 col11\" >30.6</td>\n",
       "      <td id=\"T_72005_row0_col12\" class=\"data row0 col12\" >32.7</td>\n",
       "      <td id=\"T_72005_row0_col13\" class=\"data row0 col13\" >9.6</td>\n",
       "      <td id=\"T_72005_row0_col14\" class=\"data row0 col14\" >38.4</td>\n",
       "      <td id=\"T_72005_row0_col15\" class=\"data row0 col15\" >10.2</td>\n",
       "      <td id=\"T_72005_row0_col16\" class=\"data row0 col16\" >163.1</td>\n",
       "      <td id=\"T_72005_row0_col17\" class=\"data row0 col17\" >-65.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb441e320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1a7fd td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_1a7fd_row0_col0, #T_1a7fd_row1_col0, #T_1a7fd_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_1a7fd_row0_col1, #T_1a7fd_row0_col2, #T_1a7fd_row0_col6, #T_1a7fd_row0_col9, #T_1a7fd_row1_col1, #T_1a7fd_row1_col2, #T_1a7fd_row1_col12, #T_1a7fd_row1_col13, #T_1a7fd_row1_col14, #T_1a7fd_row1_col15, #T_1a7fd_row2_col1, #T_1a7fd_row2_col2, #T_1a7fd_row2_col3, #T_1a7fd_row2_col4, #T_1a7fd_row2_col5, #T_1a7fd_row2_col7, #T_1a7fd_row2_col8, #T_1a7fd_row2_col10, #T_1a7fd_row2_col11, #T_1a7fd_row2_col16, #T_1a7fd_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1a7fd_row0_col3, #T_1a7fd_row0_col4, #T_1a7fd_row0_col5, #T_1a7fd_row0_col10, #T_1a7fd_row0_col11, #T_1a7fd_row0_col12, #T_1a7fd_row0_col13, #T_1a7fd_row0_col14, #T_1a7fd_row0_col15, #T_1a7fd_row0_col16, #T_1a7fd_row0_col17, #T_1a7fd_row1_col7, #T_1a7fd_row1_col8, #T_1a7fd_row1_col9, #T_1a7fd_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1a7fd_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1a7fd_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1a7fd_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1a7fd_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1a7fd_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1a7fd_row1_col6, #T_1a7fd_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1a7fd_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1a7fd_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1a7fd_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1a7fd_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1a7fd_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1a7fd_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1a7fd_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1a7fd_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1a7fd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1a7fd_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_1a7fd_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_1a7fd_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_1a7fd_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_1a7fd_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_1a7fd_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_1a7fd_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_1a7fd_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_1a7fd_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_1a7fd_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_1a7fd_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_1a7fd_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_1a7fd_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_1a7fd_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_1a7fd_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_1a7fd_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_1a7fd_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_1a7fd_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1a7fd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1a7fd_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_1a7fd_row0_col1\" class=\"data row0 col1\" >10000.0</td>\n",
       "      <td id=\"T_1a7fd_row0_col2\" class=\"data row0 col2\" >1000.0</td>\n",
       "      <td id=\"T_1a7fd_row0_col3\" class=\"data row0 col3\" >40.4</td>\n",
       "      <td id=\"T_1a7fd_row0_col4\" class=\"data row0 col4\" >40.7</td>\n",
       "      <td id=\"T_1a7fd_row0_col5\" class=\"data row0 col5\" >171.0</td>\n",
       "      <td id=\"T_1a7fd_row0_col6\" class=\"data row0 col6\" >-2.2</td>\n",
       "      <td id=\"T_1a7fd_row0_col7\" class=\"data row0 col7\" >32.6</td>\n",
       "      <td id=\"T_1a7fd_row0_col8\" class=\"data row0 col8\" >35.4</td>\n",
       "      <td id=\"T_1a7fd_row0_col9\" class=\"data row0 col9\" >3.8</td>\n",
       "      <td id=\"T_1a7fd_row0_col10\" class=\"data row0 col10\" >12.8</td>\n",
       "      <td id=\"T_1a7fd_row0_col11\" class=\"data row0 col11\" >33.4</td>\n",
       "      <td id=\"T_1a7fd_row0_col12\" class=\"data row0 col12\" >33.4</td>\n",
       "      <td id=\"T_1a7fd_row0_col13\" class=\"data row0 col13\" >8.3</td>\n",
       "      <td id=\"T_1a7fd_row0_col14\" class=\"data row0 col14\" >32.0</td>\n",
       "      <td id=\"T_1a7fd_row0_col15\" class=\"data row0 col15\" >10.2</td>\n",
       "      <td id=\"T_1a7fd_row0_col16\" class=\"data row0 col16\" >34.8</td>\n",
       "      <td id=\"T_1a7fd_row0_col17\" class=\"data row0 col17\" >-62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1a7fd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1a7fd_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_1a7fd_row1_col1\" class=\"data row1 col1\" >10000.0</td>\n",
       "      <td id=\"T_1a7fd_row1_col2\" class=\"data row1 col2\" >1000.0</td>\n",
       "      <td id=\"T_1a7fd_row1_col3\" class=\"data row1 col3\" >36.3</td>\n",
       "      <td id=\"T_1a7fd_row1_col4\" class=\"data row1 col4\" >36.8</td>\n",
       "      <td id=\"T_1a7fd_row1_col5\" class=\"data row1 col5\" >170.0</td>\n",
       "      <td id=\"T_1a7fd_row1_col6\" class=\"data row1 col6\" >-1.9</td>\n",
       "      <td id=\"T_1a7fd_row1_col7\" class=\"data row1 col7\" >34.0</td>\n",
       "      <td id=\"T_1a7fd_row1_col8\" class=\"data row1 col8\" >37.8</td>\n",
       "      <td id=\"T_1a7fd_row1_col9\" class=\"data row1 col9\" >4.8</td>\n",
       "      <td id=\"T_1a7fd_row1_col10\" class=\"data row1 col10\" >12.0</td>\n",
       "      <td id=\"T_1a7fd_row1_col11\" class=\"data row1 col11\" >32.9</td>\n",
       "      <td id=\"T_1a7fd_row1_col12\" class=\"data row1 col12\" >30.6</td>\n",
       "      <td id=\"T_1a7fd_row1_col13\" class=\"data row1 col13\" >7.0</td>\n",
       "      <td id=\"T_1a7fd_row1_col14\" class=\"data row1 col14\" >28.3</td>\n",
       "      <td id=\"T_1a7fd_row1_col15\" class=\"data row1 col15\" >6.3</td>\n",
       "      <td id=\"T_1a7fd_row1_col16\" class=\"data row1 col16\" >33.5</td>\n",
       "      <td id=\"T_1a7fd_row1_col17\" class=\"data row1 col17\" >-72.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1a7fd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1a7fd_row2_col0\" class=\"data row2 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_1a7fd_row2_col1\" class=\"data row2 col1\" >10000.0</td>\n",
       "      <td id=\"T_1a7fd_row2_col2\" class=\"data row2 col2\" >1000.0</td>\n",
       "      <td id=\"T_1a7fd_row2_col3\" class=\"data row2 col3\" >35.9</td>\n",
       "      <td id=\"T_1a7fd_row2_col4\" class=\"data row2 col4\" >36.0</td>\n",
       "      <td id=\"T_1a7fd_row2_col5\" class=\"data row2 col5\" >136.0</td>\n",
       "      <td id=\"T_1a7fd_row2_col6\" class=\"data row2 col6\" >-1.4</td>\n",
       "      <td id=\"T_1a7fd_row2_col7\" class=\"data row2 col7\" >29.4</td>\n",
       "      <td id=\"T_1a7fd_row2_col8\" class=\"data row2 col8\" >32.9</td>\n",
       "      <td id=\"T_1a7fd_row2_col9\" class=\"data row2 col9\" >4.6</td>\n",
       "      <td id=\"T_1a7fd_row2_col10\" class=\"data row2 col10\" >11.4</td>\n",
       "      <td id=\"T_1a7fd_row2_col11\" class=\"data row2 col11\" >30.8</td>\n",
       "      <td id=\"T_1a7fd_row2_col12\" class=\"data row2 col12\" >31.8</td>\n",
       "      <td id=\"T_1a7fd_row2_col13\" class=\"data row2 col13\" >7.8</td>\n",
       "      <td id=\"T_1a7fd_row2_col14\" class=\"data row2 col14\" >29.7</td>\n",
       "      <td id=\"T_1a7fd_row2_col15\" class=\"data row2 col15\" >10.0</td>\n",
       "      <td id=\"T_1a7fd_row2_col16\" class=\"data row2 col16\" >30.4</td>\n",
       "      <td id=\"T_1a7fd_row2_col17\" class=\"data row2 col17\" >-77.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb74e1900>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5e6af td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_5e6af_row0_col0, #T_5e6af_row1_col0, #T_5e6af_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5e6af_row0_col1, #T_5e6af_row0_col2, #T_5e6af_row0_col11, #T_5e6af_row0_col12, #T_5e6af_row1_col1, #T_5e6af_row1_col2, #T_5e6af_row1_col3, #T_5e6af_row1_col4, #T_5e6af_row1_col5, #T_5e6af_row1_col6, #T_5e6af_row1_col13, #T_5e6af_row1_col14, #T_5e6af_row1_col15, #T_5e6af_row1_col17, #T_5e6af_row2_col1, #T_5e6af_row2_col2, #T_5e6af_row2_col7, #T_5e6af_row2_col8, #T_5e6af_row2_col9, #T_5e6af_row2_col10, #T_5e6af_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5e6af_row0_col3, #T_5e6af_row0_col4, #T_5e6af_row0_col7, #T_5e6af_row0_col8, #T_5e6af_row0_col9, #T_5e6af_row0_col13, #T_5e6af_row0_col14, #T_5e6af_row0_col16, #T_5e6af_row0_col17, #T_5e6af_row1_col10, #T_5e6af_row1_col11, #T_5e6af_row1_col12, #T_5e6af_row2_col5, #T_5e6af_row2_col6, #T_5e6af_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5e6af_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5e6af_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5e6af_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5e6af_row0_col15, #T_5e6af_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5e6af_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5e6af_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5e6af_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5e6af_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5e6af_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5e6af_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5e6af_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5e6af_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5e6af_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5e6af_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5e6af\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5e6af_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_5e6af_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_5e6af_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_5e6af_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_5e6af_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_5e6af_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_5e6af_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_5e6af_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_5e6af_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_5e6af_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_5e6af_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_5e6af_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_5e6af_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_5e6af_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_5e6af_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_5e6af_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_5e6af_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_5e6af_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5e6af_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5e6af_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_5e6af_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_5e6af_row0_col2\" class=\"data row0 col2\" >10000</td>\n",
       "      <td id=\"T_5e6af_row0_col3\" class=\"data row0 col3\" >46.9</td>\n",
       "      <td id=\"T_5e6af_row0_col4\" class=\"data row0 col4\" >47.3</td>\n",
       "      <td id=\"T_5e6af_row0_col5\" class=\"data row0 col5\" >172.0</td>\n",
       "      <td id=\"T_5e6af_row0_col6\" class=\"data row0 col6\" >-4.3</td>\n",
       "      <td id=\"T_5e6af_row0_col7\" class=\"data row0 col7\" >35.6</td>\n",
       "      <td id=\"T_5e6af_row0_col8\" class=\"data row0 col8\" >37.6</td>\n",
       "      <td id=\"T_5e6af_row0_col9\" class=\"data row0 col9\" >4.8</td>\n",
       "      <td id=\"T_5e6af_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_5e6af_row0_col11\" class=\"data row0 col11\" >33.3</td>\n",
       "      <td id=\"T_5e6af_row0_col12\" class=\"data row0 col12\" >33.2</td>\n",
       "      <td id=\"T_5e6af_row0_col13\" class=\"data row0 col13\" >8.4</td>\n",
       "      <td id=\"T_5e6af_row0_col14\" class=\"data row0 col14\" >31.3</td>\n",
       "      <td id=\"T_5e6af_row0_col15\" class=\"data row0 col15\" >13.0</td>\n",
       "      <td id=\"T_5e6af_row0_col16\" class=\"data row0 col16\" >36.3</td>\n",
       "      <td id=\"T_5e6af_row0_col17\" class=\"data row0 col17\" >-52.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e6af_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5e6af_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_5e6af_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_5e6af_row1_col2\" class=\"data row1 col2\" >10000</td>\n",
       "      <td id=\"T_5e6af_row1_col3\" class=\"data row1 col3\" >44.8</td>\n",
       "      <td id=\"T_5e6af_row1_col4\" class=\"data row1 col4\" >44.9</td>\n",
       "      <td id=\"T_5e6af_row1_col5\" class=\"data row1 col5\" >170.0</td>\n",
       "      <td id=\"T_5e6af_row1_col6\" class=\"data row1 col6\" >-4.6</td>\n",
       "      <td id=\"T_5e6af_row1_col7\" class=\"data row1 col7\" >35.2</td>\n",
       "      <td id=\"T_5e6af_row1_col8\" class=\"data row1 col8\" >35.4</td>\n",
       "      <td id=\"T_5e6af_row1_col9\" class=\"data row1 col9\" >4.6</td>\n",
       "      <td id=\"T_5e6af_row1_col10\" class=\"data row1 col10\" >14.0</td>\n",
       "      <td id=\"T_5e6af_row1_col11\" class=\"data row1 col11\" >34.5</td>\n",
       "      <td id=\"T_5e6af_row1_col12\" class=\"data row1 col12\" >35.5</td>\n",
       "      <td id=\"T_5e6af_row1_col13\" class=\"data row1 col13\" >7.1</td>\n",
       "      <td id=\"T_5e6af_row1_col14\" class=\"data row1 col14\" >30.1</td>\n",
       "      <td id=\"T_5e6af_row1_col15\" class=\"data row1 col15\" >10.2</td>\n",
       "      <td id=\"T_5e6af_row1_col16\" class=\"data row1 col16\" >35.5</td>\n",
       "      <td id=\"T_5e6af_row1_col17\" class=\"data row1 col17\" >-62.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e6af_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5e6af_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_5e6af_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_5e6af_row2_col2\" class=\"data row2 col2\" >10000</td>\n",
       "      <td id=\"T_5e6af_row2_col3\" class=\"data row2 col3\" >44.8</td>\n",
       "      <td id=\"T_5e6af_row2_col4\" class=\"data row2 col4\" >45.2</td>\n",
       "      <td id=\"T_5e6af_row2_col5\" class=\"data row2 col5\" >177.0</td>\n",
       "      <td id=\"T_5e6af_row2_col6\" class=\"data row2 col6\" >-4.2</td>\n",
       "      <td id=\"T_5e6af_row2_col7\" class=\"data row2 col7\" >28.5</td>\n",
       "      <td id=\"T_5e6af_row2_col8\" class=\"data row2 col8\" >31.5</td>\n",
       "      <td id=\"T_5e6af_row2_col9\" class=\"data row2 col9\" >3.8</td>\n",
       "      <td id=\"T_5e6af_row2_col10\" class=\"data row2 col10\" >12.0</td>\n",
       "      <td id=\"T_5e6af_row2_col11\" class=\"data row2 col11\" >34.4</td>\n",
       "      <td id=\"T_5e6af_row2_col12\" class=\"data row2 col12\" >34.5</td>\n",
       "      <td id=\"T_5e6af_row2_col13\" class=\"data row2 col13\" >7.8</td>\n",
       "      <td id=\"T_5e6af_row2_col14\" class=\"data row2 col14\" >31.2</td>\n",
       "      <td id=\"T_5e6af_row2_col15\" class=\"data row2 col15\" >13.2</td>\n",
       "      <td id=\"T_5e6af_row2_col16\" class=\"data row2 col16\" >35.4</td>\n",
       "      <td id=\"T_5e6af_row2_col17\" class=\"data row2 col17\" >-62.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb7cfaec0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ebaab td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_ebaab_row0_col0, #T_ebaab_row1_col0, #T_ebaab_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ebaab_row0_col1, #T_ebaab_row0_col2, #T_ebaab_row0_col6, #T_ebaab_row0_col9, #T_ebaab_row0_col13, #T_ebaab_row1_col1, #T_ebaab_row1_col2, #T_ebaab_row1_col7, #T_ebaab_row1_col11, #T_ebaab_row2_col1, #T_ebaab_row2_col2, #T_ebaab_row2_col3, #T_ebaab_row2_col4, #T_ebaab_row2_col5, #T_ebaab_row2_col8, #T_ebaab_row2_col10, #T_ebaab_row2_col12, #T_ebaab_row2_col14, #T_ebaab_row2_col15, #T_ebaab_row2_col16, #T_ebaab_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ebaab_row0_col3, #T_ebaab_row0_col4, #T_ebaab_row0_col5, #T_ebaab_row0_col7, #T_ebaab_row0_col8, #T_ebaab_row0_col11, #T_ebaab_row0_col14, #T_ebaab_row0_col16, #T_ebaab_row0_col17, #T_ebaab_row1_col5, #T_ebaab_row1_col8, #T_ebaab_row1_col10, #T_ebaab_row1_col12, #T_ebaab_row1_col15, #T_ebaab_row2_col6, #T_ebaab_row2_col9, #T_ebaab_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ebaab_row0_col10, #T_ebaab_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ebaab_row0_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ebaab_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ebaab_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ebaab_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ebaab_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ebaab_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ebaab_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ebaab_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ebaab_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ebaab_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ebaab_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ebaab\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ebaab_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_ebaab_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_ebaab_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_ebaab_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_ebaab_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_ebaab_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_ebaab_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_ebaab_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_ebaab_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_ebaab_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_ebaab_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_ebaab_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_ebaab_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_ebaab_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_ebaab_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_ebaab_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_ebaab_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_ebaab_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ebaab_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ebaab_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_ebaab_row0_col1\" class=\"data row0 col1\" >60000</td>\n",
       "      <td id=\"T_ebaab_row0_col2\" class=\"data row0 col2\" >20000</td>\n",
       "      <td id=\"T_ebaab_row0_col3\" class=\"data row0 col3\" >48.9</td>\n",
       "      <td id=\"T_ebaab_row0_col4\" class=\"data row0 col4\" >49.1</td>\n",
       "      <td id=\"T_ebaab_row0_col5\" class=\"data row0 col5\" >179.0</td>\n",
       "      <td id=\"T_ebaab_row0_col6\" class=\"data row0 col6\" >-3.2</td>\n",
       "      <td id=\"T_ebaab_row0_col7\" class=\"data row0 col7\" >38.0</td>\n",
       "      <td id=\"T_ebaab_row0_col8\" class=\"data row0 col8\" >38.1</td>\n",
       "      <td id=\"T_ebaab_row0_col9\" class=\"data row0 col9\" >3.8</td>\n",
       "      <td id=\"T_ebaab_row0_col10\" class=\"data row0 col10\" >13.8</td>\n",
       "      <td id=\"T_ebaab_row0_col11\" class=\"data row0 col11\" >36.4</td>\n",
       "      <td id=\"T_ebaab_row0_col12\" class=\"data row0 col12\" >34.5</td>\n",
       "      <td id=\"T_ebaab_row0_col13\" class=\"data row0 col13\" >7.8</td>\n",
       "      <td id=\"T_ebaab_row0_col14\" class=\"data row0 col14\" >33.1</td>\n",
       "      <td id=\"T_ebaab_row0_col15\" class=\"data row0 col15\" >12.6</td>\n",
       "      <td id=\"T_ebaab_row0_col16\" class=\"data row0 col16\" >37.9</td>\n",
       "      <td id=\"T_ebaab_row0_col17\" class=\"data row0 col17\" >-42.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ebaab_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ebaab_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_ebaab_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_ebaab_row1_col2\" class=\"data row1 col2\" >20000</td>\n",
       "      <td id=\"T_ebaab_row1_col3\" class=\"data row1 col3\" >47.7</td>\n",
       "      <td id=\"T_ebaab_row1_col4\" class=\"data row1 col4\" >47.8</td>\n",
       "      <td id=\"T_ebaab_row1_col5\" class=\"data row1 col5\" >179.0</td>\n",
       "      <td id=\"T_ebaab_row1_col6\" class=\"data row1 col6\" >-3.1</td>\n",
       "      <td id=\"T_ebaab_row1_col7\" class=\"data row1 col7\" >32.2</td>\n",
       "      <td id=\"T_ebaab_row1_col8\" class=\"data row1 col8\" >38.1</td>\n",
       "      <td id=\"T_ebaab_row1_col9\" class=\"data row1 col9\" >4.4</td>\n",
       "      <td id=\"T_ebaab_row1_col10\" class=\"data row1 col10\" >15.6</td>\n",
       "      <td id=\"T_ebaab_row1_col11\" class=\"data row1 col11\" >33.9</td>\n",
       "      <td id=\"T_ebaab_row1_col12\" class=\"data row1 col12\" >34.9</td>\n",
       "      <td id=\"T_ebaab_row1_col13\" class=\"data row1 col13\" >8.1</td>\n",
       "      <td id=\"T_ebaab_row1_col14\" class=\"data row1 col14\" >32.4</td>\n",
       "      <td id=\"T_ebaab_row1_col15\" class=\"data row1 col15\" >13.2</td>\n",
       "      <td id=\"T_ebaab_row1_col16\" class=\"data row1 col16\" >37.2</td>\n",
       "      <td id=\"T_ebaab_row1_col17\" class=\"data row1 col17\" >-44.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ebaab_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ebaab_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_ebaab_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_ebaab_row2_col2\" class=\"data row2 col2\" >20000</td>\n",
       "      <td id=\"T_ebaab_row2_col3\" class=\"data row2 col3\" >46.2</td>\n",
       "      <td id=\"T_ebaab_row2_col4\" class=\"data row2 col4\" >46.8</td>\n",
       "      <td id=\"T_ebaab_row2_col5\" class=\"data row2 col5\" >173.0</td>\n",
       "      <td id=\"T_ebaab_row2_col6\" class=\"data row2 col6\" >-2.9</td>\n",
       "      <td id=\"T_ebaab_row2_col7\" class=\"data row2 col7\" >33.4</td>\n",
       "      <td id=\"T_ebaab_row2_col8\" class=\"data row2 col8\" >35.3</td>\n",
       "      <td id=\"T_ebaab_row2_col9\" class=\"data row2 col9\" >4.8</td>\n",
       "      <td id=\"T_ebaab_row2_col10\" class=\"data row2 col10\" >13.2</td>\n",
       "      <td id=\"T_ebaab_row2_col11\" class=\"data row2 col11\" >35.4</td>\n",
       "      <td id=\"T_ebaab_row2_col12\" class=\"data row2 col12\" >33.5</td>\n",
       "      <td id=\"T_ebaab_row2_col13\" class=\"data row2 col13\" >8.1</td>\n",
       "      <td id=\"T_ebaab_row2_col14\" class=\"data row2 col14\" >30.7</td>\n",
       "      <td id=\"T_ebaab_row2_col15\" class=\"data row2 col15\" >12.4</td>\n",
       "      <td id=\"T_ebaab_row2_col16\" class=\"data row2 col16\" >36.1</td>\n",
       "      <td id=\"T_ebaab_row2_col17\" class=\"data row2 col17\" >-53.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb74e1810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b0400 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_b0400_row0_col0, #T_b0400_row1_col0, #T_b0400_row2_col0, #T_b0400_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b0400_row0_col1, #T_b0400_row0_col2, #T_b0400_row0_col7, #T_b0400_row0_col11, #T_b0400_row1_col1, #T_b0400_row1_col2, #T_b0400_row1_col6, #T_b0400_row1_col9, #T_b0400_row1_col10, #T_b0400_row2_col1, #T_b0400_row2_col2, #T_b0400_row2_col5, #T_b0400_row2_col13, #T_b0400_row2_col15, #T_b0400_row3_col1, #T_b0400_row3_col2, #T_b0400_row3_col3, #T_b0400_row3_col4, #T_b0400_row3_col8, #T_b0400_row3_col12, #T_b0400_row3_col14, #T_b0400_row3_col16, #T_b0400_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0400_row0_col3, #T_b0400_row0_col4, #T_b0400_row0_col9, #T_b0400_row0_col10, #T_b0400_row0_col12, #T_b0400_row0_col14, #T_b0400_row0_col15, #T_b0400_row0_col16, #T_b0400_row0_col17, #T_b0400_row1_col11, #T_b0400_row2_col7, #T_b0400_row2_col8, #T_b0400_row3_col5, #T_b0400_row3_col6, #T_b0400_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0400_row0_col5, #T_b0400_row1_col3, #T_b0400_row1_col5, #T_b0400_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row0_col6, #T_b0400_row1_col4, #T_b0400_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0400_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0400_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0400_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row1_col12, #T_b0400_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0400_row1_col15, #T_b0400_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0400_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0400_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0400_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0400_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0400_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b0400\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b0400_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_b0400_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_b0400_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_b0400_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_b0400_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_b0400_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_b0400_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_b0400_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_b0400_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_b0400_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_b0400_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_b0400_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_b0400_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_b0400_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_b0400_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_b0400_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_b0400_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_b0400_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b0400_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b0400_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_b0400_row0_col1\" class=\"data row0 col1\" >90000</td>\n",
       "      <td id=\"T_b0400_row0_col2\" class=\"data row0 col2\" >30000</td>\n",
       "      <td id=\"T_b0400_row0_col3\" class=\"data row0 col3\" >51.0</td>\n",
       "      <td id=\"T_b0400_row0_col4\" class=\"data row0 col4\" >51.1</td>\n",
       "      <td id=\"T_b0400_row0_col5\" class=\"data row0 col5\" >180.0</td>\n",
       "      <td id=\"T_b0400_row0_col6\" class=\"data row0 col6\" >-2.7</td>\n",
       "      <td id=\"T_b0400_row0_col7\" class=\"data row0 col7\" >33.4</td>\n",
       "      <td id=\"T_b0400_row0_col8\" class=\"data row0 col8\" >36.8</td>\n",
       "      <td id=\"T_b0400_row0_col9\" class=\"data row0 col9\" >5.4</td>\n",
       "      <td id=\"T_b0400_row0_col10\" class=\"data row0 col10\" >15.2</td>\n",
       "      <td id=\"T_b0400_row0_col11\" class=\"data row0 col11\" >31.9</td>\n",
       "      <td id=\"T_b0400_row0_col12\" class=\"data row0 col12\" >35.8</td>\n",
       "      <td id=\"T_b0400_row0_col13\" class=\"data row0 col13\" >8.0</td>\n",
       "      <td id=\"T_b0400_row0_col14\" class=\"data row0 col14\" >32.1</td>\n",
       "      <td id=\"T_b0400_row0_col15\" class=\"data row0 col15\" >14.0</td>\n",
       "      <td id=\"T_b0400_row0_col16\" class=\"data row0 col16\" >37.9</td>\n",
       "      <td id=\"T_b0400_row0_col17\" class=\"data row0 col17\" >-42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0400_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b0400_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_b0400_row1_col1\" class=\"data row1 col1\" >90000</td>\n",
       "      <td id=\"T_b0400_row1_col2\" class=\"data row1 col2\" >30000</td>\n",
       "      <td id=\"T_b0400_row1_col3\" class=\"data row1 col3\" >49.4</td>\n",
       "      <td id=\"T_b0400_row1_col4\" class=\"data row1 col4\" >49.9</td>\n",
       "      <td id=\"T_b0400_row1_col5\" class=\"data row1 col5\" >180.0</td>\n",
       "      <td id=\"T_b0400_row1_col6\" class=\"data row1 col6\" >-3.6</td>\n",
       "      <td id=\"T_b0400_row1_col7\" class=\"data row1 col7\" >38.5</td>\n",
       "      <td id=\"T_b0400_row1_col8\" class=\"data row1 col8\" >37.9</td>\n",
       "      <td id=\"T_b0400_row1_col9\" class=\"data row1 col9\" >3.8</td>\n",
       "      <td id=\"T_b0400_row1_col10\" class=\"data row1 col10\" >12.2</td>\n",
       "      <td id=\"T_b0400_row1_col11\" class=\"data row1 col11\" >34.3</td>\n",
       "      <td id=\"T_b0400_row1_col12\" class=\"data row1 col12\" >34.6</td>\n",
       "      <td id=\"T_b0400_row1_col13\" class=\"data row1 col13\" >7.8</td>\n",
       "      <td id=\"T_b0400_row1_col14\" class=\"data row1 col14\" >31.1</td>\n",
       "      <td id=\"T_b0400_row1_col15\" class=\"data row1 col15\" >12.8</td>\n",
       "      <td id=\"T_b0400_row1_col16\" class=\"data row1 col16\" >37.6</td>\n",
       "      <td id=\"T_b0400_row1_col17\" class=\"data row1 col17\" >-46.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0400_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b0400_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_b0400_row2_col1\" class=\"data row2 col1\" >90000</td>\n",
       "      <td id=\"T_b0400_row2_col2\" class=\"data row2 col2\" >30000</td>\n",
       "      <td id=\"T_b0400_row2_col3\" class=\"data row2 col3\" >49.3</td>\n",
       "      <td id=\"T_b0400_row2_col4\" class=\"data row2 col4\" >49.3</td>\n",
       "      <td id=\"T_b0400_row2_col5\" class=\"data row2 col5\" >178.0</td>\n",
       "      <td id=\"T_b0400_row2_col6\" class=\"data row2 col6\" >-2.7</td>\n",
       "      <td id=\"T_b0400_row2_col7\" class=\"data row2 col7\" >39.2</td>\n",
       "      <td id=\"T_b0400_row2_col8\" class=\"data row2 col8\" >38.7</td>\n",
       "      <td id=\"T_b0400_row2_col9\" class=\"data row2 col9\" >4.2</td>\n",
       "      <td id=\"T_b0400_row2_col10\" class=\"data row2 col10\" >13.2</td>\n",
       "      <td id=\"T_b0400_row2_col11\" class=\"data row2 col11\" >33.9</td>\n",
       "      <td id=\"T_b0400_row2_col12\" class=\"data row2 col12\" >34.9</td>\n",
       "      <td id=\"T_b0400_row2_col13\" class=\"data row2 col13\" >7.6</td>\n",
       "      <td id=\"T_b0400_row2_col14\" class=\"data row2 col14\" >31.1</td>\n",
       "      <td id=\"T_b0400_row2_col15\" class=\"data row2 col15\" >11.6</td>\n",
       "      <td id=\"T_b0400_row2_col16\" class=\"data row2 col16\" >37.6</td>\n",
       "      <td id=\"T_b0400_row2_col17\" class=\"data row2 col17\" >-44.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0400_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b0400_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_b0400_row3_col1\" class=\"data row3 col1\" >90000</td>\n",
       "      <td id=\"T_b0400_row3_col2\" class=\"data row3 col2\" >30000</td>\n",
       "      <td id=\"T_b0400_row3_col3\" class=\"data row3 col3\" >48.6</td>\n",
       "      <td id=\"T_b0400_row3_col4\" class=\"data row3 col4\" >48.6</td>\n",
       "      <td id=\"T_b0400_row3_col5\" class=\"data row3 col5\" >184.0</td>\n",
       "      <td id=\"T_b0400_row3_col6\" class=\"data row3 col6\" >-2.0</td>\n",
       "      <td id=\"T_b0400_row3_col7\" class=\"data row3 col7\" >34.2</td>\n",
       "      <td id=\"T_b0400_row3_col8\" class=\"data row3 col8\" >36.5</td>\n",
       "      <td id=\"T_b0400_row3_col9\" class=\"data row3 col9\" >5.2</td>\n",
       "      <td id=\"T_b0400_row3_col10\" class=\"data row3 col10\" >12.6</td>\n",
       "      <td id=\"T_b0400_row3_col11\" class=\"data row3 col11\" >33.1</td>\n",
       "      <td id=\"T_b0400_row3_col12\" class=\"data row3 col12\" >33.5</td>\n",
       "      <td id=\"T_b0400_row3_col13\" class=\"data row3 col13\" >8.1</td>\n",
       "      <td id=\"T_b0400_row3_col14\" class=\"data row3 col14\" >30.8</td>\n",
       "      <td id=\"T_b0400_row3_col15\" class=\"data row3 col15\" >12.8</td>\n",
       "      <td id=\"T_b0400_row3_col16\" class=\"data row3 col16\" >37.4</td>\n",
       "      <td id=\"T_b0400_row3_col17\" class=\"data row3 col17\" >-48.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb6b26d70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_59075 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_59075_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_59075_row0_col1, #T_59075_row0_col2, #T_59075_row0_col3, #T_59075_row0_col4, #T_59075_row0_col5, #T_59075_row0_col6, #T_59075_row0_col7, #T_59075_row0_col8, #T_59075_row0_col9, #T_59075_row0_col10, #T_59075_row0_col11, #T_59075_row0_col12, #T_59075_row0_col13, #T_59075_row0_col14, #T_59075_row0_col15, #T_59075_row0_col16, #T_59075_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_59075\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_59075_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_59075_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_59075_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_59075_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_59075_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_59075_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_59075_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_59075_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_59075_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_59075_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_59075_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_59075_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_59075_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_59075_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_59075_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_59075_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_59075_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_59075_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_59075_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_59075_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_59075_row0_col1\" class=\"data row0 col1\" >100000</td>\n",
       "      <td id=\"T_59075_row0_col2\" class=\"data row0 col2\" >50000</td>\n",
       "      <td id=\"T_59075_row0_col3\" class=\"data row0 col3\" >44.8</td>\n",
       "      <td id=\"T_59075_row0_col4\" class=\"data row0 col4\" >45.0</td>\n",
       "      <td id=\"T_59075_row0_col5\" class=\"data row0 col5\" >174.0</td>\n",
       "      <td id=\"T_59075_row0_col6\" class=\"data row0 col6\" >-3.0</td>\n",
       "      <td id=\"T_59075_row0_col7\" class=\"data row0 col7\" >35.0</td>\n",
       "      <td id=\"T_59075_row0_col8\" class=\"data row0 col8\" >37.0</td>\n",
       "      <td id=\"T_59075_row0_col9\" class=\"data row0 col9\" >2.8</td>\n",
       "      <td id=\"T_59075_row0_col10\" class=\"data row0 col10\" >13.4</td>\n",
       "      <td id=\"T_59075_row0_col11\" class=\"data row0 col11\" >33.7</td>\n",
       "      <td id=\"T_59075_row0_col12\" class=\"data row0 col12\" >32.5</td>\n",
       "      <td id=\"T_59075_row0_col13\" class=\"data row0 col13\" >7.7</td>\n",
       "      <td id=\"T_59075_row0_col14\" class=\"data row0 col14\" >30.1</td>\n",
       "      <td id=\"T_59075_row0_col15\" class=\"data row0 col15\" >14.6</td>\n",
       "      <td id=\"T_59075_row0_col16\" class=\"data row0 col16\" >36.0</td>\n",
       "      <td id=\"T_59075_row0_col17\" class=\"data row0 col17\" >-59.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb72a4fa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330579/1462538419.py:313: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f1dc9 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_f1dc9_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f1dc9_row0_col1, #T_f1dc9_row0_col2, #T_f1dc9_row0_col3, #T_f1dc9_row0_col4, #T_f1dc9_row0_col5, #T_f1dc9_row0_col6, #T_f1dc9_row0_col7, #T_f1dc9_row0_col8, #T_f1dc9_row0_col9, #T_f1dc9_row0_col10, #T_f1dc9_row0_col11, #T_f1dc9_row0_col12, #T_f1dc9_row0_col13, #T_f1dc9_row0_col14, #T_f1dc9_row0_col15, #T_f1dc9_row0_col16, #T_f1dc9_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f1dc9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f1dc9_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_f1dc9_level0_col1\" class=\"col_heading level0 col1\" >compute</th>\n",
       "      <th id=\"T_f1dc9_level0_col2\" class=\"col_heading level0 col2\" >subset_size</th>\n",
       "      <th id=\"T_f1dc9_level0_col3\" class=\"col_heading level0 col3\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_f1dc9_level0_col4\" class=\"col_heading level0 col4\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th id=\"T_f1dc9_level0_col5\" class=\"col_heading level0 col5\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th id=\"T_f1dc9_level0_col6\" class=\"col_heading level0 col6\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th id=\"T_f1dc9_level0_col7\" class=\"col_heading level0 col7\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_f1dc9_level0_col8\" class=\"col_heading level0 col8\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_f1dc9_level0_col9\" class=\"col_heading level0 col9\" >GSM/Direct</th>\n",
       "      <th id=\"T_f1dc9_level0_col10\" class=\"col_heading level0 col10\" >GSM/CoT</th>\n",
       "      <th id=\"T_f1dc9_level0_col11\" class=\"col_heading level0 col11\" >BBH/Direct</th>\n",
       "      <th id=\"T_f1dc9_level0_col12\" class=\"col_heading level0 col12\" >BBH/CoT</th>\n",
       "      <th id=\"T_f1dc9_level0_col13\" class=\"col_heading level0 col13\" >TydiQA/CB</th>\n",
       "      <th id=\"T_f1dc9_level0_col14\" class=\"col_heading level0 col14\" >TydiQA/GP</th>\n",
       "      <th id=\"T_f1dc9_level0_col15\" class=\"col_heading level0 col15\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_f1dc9_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_f1dc9_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f1dc9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f1dc9_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_ep=3</td>\n",
       "      <td id=\"T_f1dc9_row0_col1\" class=\"data row0 col1\" >150000</td>\n",
       "      <td id=\"T_f1dc9_row0_col2\" class=\"data row0 col2\" >50000</td>\n",
       "      <td id=\"T_f1dc9_row0_col3\" class=\"data row0 col3\" >50.3</td>\n",
       "      <td id=\"T_f1dc9_row0_col4\" class=\"data row0 col4\" >50.4</td>\n",
       "      <td id=\"T_f1dc9_row0_col5\" class=\"data row0 col5\" >187.0</td>\n",
       "      <td id=\"T_f1dc9_row0_col6\" class=\"data row0 col6\" >-2.4</td>\n",
       "      <td id=\"T_f1dc9_row0_col7\" class=\"data row0 col7\" >39.4</td>\n",
       "      <td id=\"T_f1dc9_row0_col8\" class=\"data row0 col8\" >39.0</td>\n",
       "      <td id=\"T_f1dc9_row0_col9\" class=\"data row0 col9\" >3.6</td>\n",
       "      <td id=\"T_f1dc9_row0_col10\" class=\"data row0 col10\" >14.4</td>\n",
       "      <td id=\"T_f1dc9_row0_col11\" class=\"data row0 col11\" >34.2</td>\n",
       "      <td id=\"T_f1dc9_row0_col12\" class=\"data row0 col12\" >35.1</td>\n",
       "      <td id=\"T_f1dc9_row0_col13\" class=\"data row0 col13\" >7.8</td>\n",
       "      <td id=\"T_f1dc9_row0_col14\" class=\"data row0 col14\" >30.5</td>\n",
       "      <td id=\"T_f1dc9_row0_col15\" class=\"data row0 col15\" >14.0</td>\n",
       "      <td id=\"T_f1dc9_row0_col16\" class=\"data row0 col16\" >38.7</td>\n",
       "      <td id=\"T_f1dc9_row0_col17\" class=\"data row0 col17\" >-38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x150bb6d17160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_sort_rows_by_avg_ranking\n",
    "from llm.evaluate import EvalResults, get_eval_results\n",
    "from llm.evaluate import get_eval_results_with_useful_cols\n",
    "\n",
    "\n",
    "exp_dir = ''\n",
    "chat_fmt = None\n",
    "sort_rows = True\n",
    "use_normalized_preferred_metric = False\n",
    "\n",
    "\n",
    "# ## investigate code change / package update effect on eval baselines.\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# use_normalized_preferred_metric = False\n",
    "# sort_rows = False\n",
    "# save_dirs = [\n",
    "#     # llama\n",
    "#     ('llama-7b_12.13update_before', '../results/baselines/huggyllama/llama-7b_12.13update_before/'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('llama-7b_10.30update', '../results/baselines/huggyllama/llama-7b_10.30update/'),\n",
    "# #     ('llama-7b_09.23update', '../results/baselines/huggyllama/llama-7b_09.23update/'),\n",
    "# #     ('llama-7b_09.23update_before', '../results/baselines/huggyllama/llama-7b_09.23update_before/'),\n",
    "# #     # llama2\n",
    "#     ('llama2-7b_12.13update_before', '../results/baselines/NousResearch/Llama-2-7b-hf_12.13update_before/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('llama2-7b-chat', '../results/baselines/NousResearch/Llama-2-7b-chat-hf/'),\n",
    "# #     ('llama2-7b_10.30update', '../results/baselines/NousResearch/Llama-2-7b-hf_10.30update/'),\n",
    "# #     ('llama2-7b_original', '../results/baselines/NousResearch/Llama-2-7b-hf_original/'),\n",
    "# #     # mistral\n",
    "# #     ('mistral-7b_10.16update', '../results/baselines/mistralai/Mistral-7B-v0.1_10.16update/'),\n",
    "#     ('mistral-7b-Instruct-v0.1_12.13update_before', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1_12.13update_before'),\n",
    "#     ('mistral-7b-Instruct-v0.1', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     # zephyr\n",
    "#     ('zephyr-7b-beta_12.13update_before', '../results/baselines/HuggingFaceH4/zephyr-7b-beta_12.13update_before'),\n",
    "#     ('zephyr-7b-beta', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "\n",
    "# # baselines\n",
    "# save_dirs = []\n",
    "# save_dirs += [\n",
    "# #     ('gpt2', '../results/baselines/gpt2'),\n",
    "# #     ('gpt2m', '../results/baselines/gpt2-medium'),\n",
    "# #     ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "# #     ('llama2-7b+humanmix', '../results/llama2-7b_humanmix'),\n",
    "# #     ('pythia-1.4b', '../results/baselines/EleutherAI/pythia-1.4b'),\n",
    "# #     ('pythia-2.8b', '../results/baselines/EleutherAI/pythia-2.8b'),\n",
    "# #     ('pythia-6.9b', '../results/baselines/EleutherAI/pythia-6.9b'),\n",
    "# #     ('dolly-v2-7b', '../results/baselines/databricks/dolly-v2-7b'),\n",
    "#     ('mistral-7b-v0.1', '../results/baselines/mistralai/Mistral-7B-v0.1'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b+lima_ep=2', '../results/ft1_ep=2/llama-7b_lima/'),\n",
    "# #     ('mistral-7b+lima_ep=2', '../results/ft1_ep=2/mistral-7b_lima/'), \n",
    "# ]\n",
    "# exp_dir = '../results/oi2/'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "\n",
    "# exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# # exp_dir = '../results/ft2'\n",
    "# # exp_dir = '../results/ft1'\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# # save_dirs = [\n",
    "# #     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "# #     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1/'),\n",
    "# # ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'tuluv1m' in x]\n",
    "\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "# # exp_dir = '../results/oi4'\n",
    "# # exp_dir = '../results/oi4_perf_cross_time'\n",
    "# # exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'\n",
    "# exp_dir = '../results/oi4_flan_v2_vary_subsetsize'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi4_flan2022_1m'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #              ('llama-7b_flan_v2_ep=2', '../results/ft1/llama-7b_flan_v2'),\n",
    "# #              ('llama-7b_humanmix_ep=2', '../results/ft1/llama-7b_humanmix'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "# #              ('llama-7b_cot:flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_cot:flanv2'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# # exp_dir = '../results/oi4_tulu_v1_mix'\n",
    "# exp_dir = '../results/oi4_tulu_v1_mix_ep=3'\n",
    "# use_normalized_preferred_metric = False\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# ###### ultrachat\n",
    "# save_dirs = [\n",
    "#     # baselines \n",
    "#     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "#     ('mistral-7b_ultrachat200k_aftersplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k'),\n",
    "#     ('mistral-7b_ultrachat200k_beforesplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k_beforesplitlongconv'),\n",
    "    \n",
    "#     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     ('mistral-7b_sft-alpha', '../results/baselines/HuggingFaceH4/mistral-7b-sft-alpha'),\n",
    "#     ('mistral-7b-sft-beta', '../results/baselines/HuggingFaceH4/mistral-7b-sft-beta'),\n",
    "#     ('mistral-7b-sft-alpha+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-alpha'),\n",
    "#     ('mistral-7b-sft-beta+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "# # exp_dir = '../results/oi5_ultrachat:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_ultrachat200k:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# exp_dir = '../results/oi5_ultrachat15:mistral-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "# dataset = 'stanford_alpaca'\n",
    "# dataset = 'open_orca_slim'\n",
    "# dataset = 'sharegptv2'\n",
    "# dataset = 'ultrachat200kv2'\n",
    "# dataset = 'wizardlm'\n",
    "# dataset = 'wizardlmv2'\n",
    "# dataset = 'tulu_v2'\n",
    "# dataset = 'flan_v2'\n",
    "# dataset = 'oasst1'\n",
    "# dataset = 'dolly'\n",
    "# dataset_list = [\n",
    "#     'dolly',\n",
    "#     'oasst1', \n",
    "#     'flan_v2', \n",
    "#     'stanford_alpaca', \n",
    "#     'wizardlmv2', \n",
    "#     'sharegptv2', \n",
    "#     'ultrachat200kv2',\n",
    "# ]; finetune_type = 'sft'\n",
    "dataset_list = [\n",
    "    'ultrafeedback',\n",
    "]; finetune_type = 'pref'\n",
    "dataset_list = [\n",
    "    # add to get entire list of ep=3 full finetunes\n",
    "    'flan_v250k',\n",
    "    'oasst2',\n",
    "    'wizardlm50k', \n",
    "    'lima',\n",
    "    'gpt4_alpaca',\n",
    "    #\n",
    "    'dolly',\n",
    "    'stanford_alpaca50k', \n",
    "    'sharegpt50k',\n",
    "    'ultrachat50k',\n",
    "]; finetune_type = 'sft'\n",
    "# dataset_list = ['stanford_alpaca50k']; finetune_type = 'sft'\n",
    "\n",
    "## older\n",
    "# dataset = 'tulu_v1_mix'\n",
    "save_dirs = []\n",
    "save_dirs += [\n",
    "    ('llama-7b', '../results/baselines/huggyllama/llama-7b'),\n",
    "#     ('llama-7b_lima_ep=5', '../results/oi2/llama-7b_lima_ep=5/'),\n",
    "#     ('llama-7b_lima_ep=10', '../results/oi2/llama-7b_lima_ep=10/'),\n",
    "]\n",
    "for dataset in dataset_list:\n",
    "    if dataset == 'tulu_v2':\n",
    "        save_dirs += [('llama-7b_tulu_v2:100k_ep=2', '../results/oi2/llama-7b_tulu_v2:100k_ep=2'),]\n",
    "    elif dataset == 'open_orca_slim':\n",
    "        save_dirs += [('llama-7b_openorcaslim:100k_ep=2', '../results/oi2/llama-7b_openorcaslim:100k_ep=2'),]\n",
    "    elif dataset == 'sharegptv2':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_sharegptv2_ep=2', '../results/oi2/llama-7b_sharegptv2_ep=2'),\n",
    "            ('llama-7b_sharegpt_ep=2', '../results/ft1_ep=2/llama-7b_sharegpt'),]\n",
    "    elif dataset == 'tulu_v1_mix':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "            # oi4_tulu_v1_mix_ep=3 models before transformers update.\n",
    "            # ('llama-7b_tuluv1m:50k_log_prob_decr_<10.16update', '../results/oi4_tulu_v1_mix_ep=3/llama-7b_tuluv1m:50k_log_prob_decr'),\n",
    "        ]\n",
    "    elif dataset == 'ultrafeedback':\n",
    "        exp_dir = f'../results/dpo1/'\n",
    "        if os.path.isdir(exp_dir):\n",
    "            save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "    else:\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=2', f'../results/oi2/llama-7b_{dataset}_ep=2'),]\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=3', f'../results/oi2/llama-7b_{dataset}_ep=3'),]\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=10', f'../results/oi2/llama-7b_{dataset}_ep=10'),]\n",
    "    \n",
    "    if finetune_type == 'sft':\n",
    "        exp_dir = f'../results/oi5_{dataset}:llama-7b'\n",
    "    elif finetune_type == 'pref':\n",
    "        exp_dir = f'../results/dpo2_{dataset}:llama-7b+sharegptv2ep2/'\n",
    "    if os.path.isdir(exp_dir):\n",
    "        save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'dppmapbd' not in x and 'semdedup' not in x]\n",
    "    \n",
    "    if finetune_type == 'pref':\n",
    "        sft_model_dataset = 'sharegptv2'\n",
    "        save_dirs += [('llama-7b_sharegptv2_ep=2', f'../results/oi2/llama-7b_{sft_model_dataset}_ep=2')]\n",
    "# ## just compare dppmap grad vs. text\n",
    "# save_dirs = [x for x in save_dirs if 'prune:size=10000:ep=10' in x[1] and (\n",
    "#         'random' in x[1] or \n",
    "#         'dppmap' in x[1]\n",
    "#     )\n",
    "# ]\n",
    "save_dirs = [x for x in save_dirs if ('size=80000:ep=2' not in x[1]) and ('size=80000:ep=3' not in x[1])]\n",
    "save_dirs = [x for x in save_dirs if os.path.isdir(x[1])]\n",
    "#####\n",
    "\n",
    "# ##### code instructions\n",
    "# save_dirs = [\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('codellama-7b', '../results/baselines/codellama/CodeLlama-7b-hf/'),\n",
    "#     ('codellama-7b-instruct', '../results/baselines/codellama/CodeLlama-7b-Python-hf/'),\n",
    "#     ('codellama-7b-python', '../results/baselines/codellama/CodeLlama-7b-Instruct-hf/'),\n",
    "# ]\n",
    "\n",
    "# exp_dir = '../results/oi2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'starcoder' in x]\n",
    "# exp_dir = '../results/oi6_starcoder_ep=5'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstr:codellama-7b'\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstrv2:codellama-7b'\n",
    "# exp_dir = '../results/oi5_starcoder_commentinstrv5:codellama-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "###### \n",
    "\n",
    "from llm.evaluate import detect_oom_evals\n",
    "oom_eval_paths = detect_oom_evals([x for l in [glob.glob(os.path.join(x[1], 'eval/*/*.out')) for x in save_dirs] for x in l])\n",
    "if oom_eval_paths: print(oom_eval_paths)\n",
    "    \n",
    "\n",
    "# chat_fmt = False\n",
    "# chat_fmt = True\n",
    "# chat_fmt = 'both'\n",
    "# chat_fmt = 'auto' # base model no chatfmt, tuned model with chatfmt\n",
    "chat_fmt = 'mix'  # non-alpacaeval no chatfmt, alpacaeval chatfmt\n",
    "\n",
    "alpacafarm_judge = 'chatgpt'\n",
    "alpacafarm_judge = 'alpaca:eval:gpt4'\n",
    "alpacafarm_judge = 'alpaca:eval:gpt4:turbo:fn'\n",
    "mtbench_judge = 'gpt:4:1106:preview'\n",
    "mtbench_judge = 'gpt:4'\n",
    "cols = []\n",
    "# cols += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/Len*', f'AlpacaFarm({alpacafarm_judge})/LenMed', f'AlpacaFarm({alpacafarm_judge})/Len', f'AlpacaFarm({alpacafarm_judge})/Rep2']\n",
    "cols += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/WR', f'AlpacaFarm({alpacafarm_judge})/LenMed', f'AlpacaFarm({alpacafarm_judge})/Rep2']\n",
    "# cols += [f'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*', f'AlpacaFarm(alpaca:eval:gpt4)/WR*']\n",
    "cols += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "# cols += [f'MTBench({mtbench_judge})/Turn-1']\n",
    "# cols += [f'MTBench(gpt:4:1106:preview)/Rating', f'MTBench(gpt:4)/Rating']\n",
    "cols += ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1'] \n",
    "\n",
    "\n",
    "print(f'chat_fmt={chat_fmt}')\n",
    "df = get_eval_results_with_useful_cols(save_dirs, chat_fmt=chat_fmt, cols=cols)\n",
    "\n",
    "\n",
    "for model_name_contain in ['llama', 'pythia-1.4b', 'mistral', 'zephyr']:\n",
    "    dfc = df.copy()\n",
    "    dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "        lambda x: model_name_contain in x.lower())]\n",
    "    if not len(dfc): continue\n",
    "    from rosemary import pd_average_col_contains_substr\n",
    "    Ns = sorted(np.unique([int(x) for x in list(df['compute']) if not np.isnan(x)]).tolist())\n",
    "    datasets = sorted(np.unique([x for x in df['dataset'] if x is not None]).tolist())\n",
    "    for dataset in datasets:\n",
    "        for N in Ns+[None]:\n",
    "            dfc = df.copy()\n",
    "            dfc = dfc[dfc['compute'].apply(lambda x: x == N if (not np.isnan(x) or x is not None) else True)]\n",
    "            dfc = dfc[dfc['dataset'].apply(lambda x: x == dataset if x else True)]\n",
    "            if not len(dfc): continue\n",
    "            col_runname = 'run_name' if chat_fmt != 'both' else ('run_name', '')\n",
    "            substitute = True\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, '_random_', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=10000:ep=10', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=50000:ep=5', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=3', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=1', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=100000', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=200000', substitute=substitute)\n",
    "            dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=400000', substitute=substitute)\n",
    "            #     dfc = dfc.sort_values(['ranking'], ascending=False)\n",
    "            col = ('Average', 'chatfmt') if chat_fmt == 'both' else 'Average'\n",
    "        #     col = 'AlpacaFarm/WR'\n",
    "        #     col = 'MMLU/0-shot'|\n",
    "        #     col = 'GSM/CoT'\n",
    "        #     col = 'BBH/Direct'\n",
    "        #     col = 'TydiQA/GP'\n",
    "            dfc = dfc.sort_values(by=[col], ascending=False)\n",
    "            dfc = dfc.drop(columns=['model_name_or_path', 'dataset'], \n",
    "                           axis=1, level=0 if chat_fmt=='both' else None)\n",
    "            dfc = dfc.reset_index(drop=True)\n",
    "            display(dfc\n",
    "                    .style\n",
    "                    .applymap(lambda x: f'max-width: 60ch;', subset=['run_name'])\n",
    "                    .set_table_styles([{'selector': 'td', 'props': [('white-space', 'pre-wrap'), ('word-wrap', 'break-word')]}])\n",
    "                    .set_properties(**{'text-align': 'left'})\n",
    "                    .background_gradient(cmap ='coolwarm')\n",
    "#                     .applymap(lambda x: 'text-decoration: underline;' \\\n",
    "#                               if x in dfc[list(set(dfc.columns) & set([(x, '') for x in cols]))+[col] if chat_fmt=='both' else cols+[col]].values.flatten() and chat_fmt=='both' else '')\n",
    "                    .format(precision=1))\n",
    "\n",
    "# llama-7b_tulu_v1_mix(paper)\n",
    "# MMLU/0-shot, MMLU/5-shot, GSM/Direct, GSM/CoT, BBH/Direct, BBH/CoT, TydiQA/GP, TydiQA/CB, CodexEval/Pass@1, AlpacaEval(vs.Davinci-003)\n",
    "# 44.8       , 47.1       , 7.0       , 25.0   , 38.5      , 38.5   , 43.5,    , 8.0      , 18.6,           , 48.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "43fdcb8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>compute</th>\n",
       "      <th>subset_size</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th>AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR</th>\n",
       "      <th>AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed</th>\n",
       "      <th>AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2</th>\n",
       "      <th>MMLU/0-shot</th>\n",
       "      <th>MMLU/5-shot</th>\n",
       "      <th>GSM/Direct</th>\n",
       "      <th>GSM/CoT</th>\n",
       "      <th>BBH/Direct</th>\n",
       "      <th>BBH/CoT</th>\n",
       "      <th>TydiQA/CB</th>\n",
       "      <th>TydiQA/GP</th>\n",
       "      <th>Codex-Eval/Pass@1</th>\n",
       "      <th>Average</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama-7b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>llama-7b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124224</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>-95.652174</td>\n",
       "      <td>31.818829</td>\n",
       "      <td>34.475146</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.8</td>\n",
       "      <td>30.648148</td>\n",
       "      <td>32.685185</td>\n",
       "      <td>9.618017</td>\n",
       "      <td>38.449168</td>\n",
       "      <td>10.162602</td>\n",
       "      <td>163.117627</td>\n",
       "      <td>-65.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama-7b_sharegpt50k_ep=3</td>\n",
       "      <td>150000</td>\n",
       "      <td>50000</td>\n",
       "      <td>sharegpt50k</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>55.962733</td>\n",
       "      <td>56.211180</td>\n",
       "      <td>232.0</td>\n",
       "      <td>-2.111801</td>\n",
       "      <td>40.585387</td>\n",
       "      <td>40.920097</td>\n",
       "      <td>6.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.018519</td>\n",
       "      <td>34.722222</td>\n",
       "      <td>7.404910</td>\n",
       "      <td>33.076438</td>\n",
       "      <td>10.772358</td>\n",
       "      <td>43.243234</td>\n",
       "      <td>-29.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=120000:ep=3</td>\n",
       "      <td>120000</td>\n",
       "      <td>40000</td>\n",
       "      <td>sharegpt50k</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>55.776398</td>\n",
       "      <td>55.900621</td>\n",
       "      <td>232.0</td>\n",
       "      <td>-2.732919</td>\n",
       "      <td>38.505911</td>\n",
       "      <td>40.820396</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>31.388889</td>\n",
       "      <td>33.981481</td>\n",
       "      <td>7.374776</td>\n",
       "      <td>30.609401</td>\n",
       "      <td>14.634146</td>\n",
       "      <td>43.066085</td>\n",
       "      <td>-33.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=120000:ep=3</td>\n",
       "      <td>120000</td>\n",
       "      <td>40000</td>\n",
       "      <td>sharegpt50k</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>55.403727</td>\n",
       "      <td>55.527950</td>\n",
       "      <td>228.0</td>\n",
       "      <td>-2.360248</td>\n",
       "      <td>40.086882</td>\n",
       "      <td>40.592508</td>\n",
       "      <td>5.8</td>\n",
       "      <td>16.8</td>\n",
       "      <td>31.388889</td>\n",
       "      <td>35.833333</td>\n",
       "      <td>7.516569</td>\n",
       "      <td>32.287148</td>\n",
       "      <td>12.804878</td>\n",
       "      <td>43.052434</td>\n",
       "      <td>-29.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3</td>\n",
       "      <td>90000</td>\n",
       "      <td>30000</td>\n",
       "      <td>sharegpt50k</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>56.770186</td>\n",
       "      <td>56.894410</td>\n",
       "      <td>225.0</td>\n",
       "      <td>-2.360248</td>\n",
       "      <td>40.051275</td>\n",
       "      <td>40.321891</td>\n",
       "      <td>5.4</td>\n",
       "      <td>14.6</td>\n",
       "      <td>32.222222</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>8.114699</td>\n",
       "      <td>33.072397</td>\n",
       "      <td>13.211382</td>\n",
       "      <td>43.031487</td>\n",
       "      <td>-24.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>llama-7b_flan_v250k_ep=2</td>\n",
       "      <td>100000</td>\n",
       "      <td>50000</td>\n",
       "      <td>flan_v250k</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>4.223602</td>\n",
       "      <td>4.223602</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-3.726708</td>\n",
       "      <td>44.324170</td>\n",
       "      <td>45.719983</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>36.759259</td>\n",
       "      <td>34.444444</td>\n",
       "      <td>8.399034</td>\n",
       "      <td>43.318997</td>\n",
       "      <td>8.536585</td>\n",
       "      <td>19.386382</td>\n",
       "      <td>-61.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td>60000</td>\n",
       "      <td>20000</td>\n",
       "      <td>flan_v250k</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>5.279503</td>\n",
       "      <td>5.279503</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-4.223602</td>\n",
       "      <td>40.620994</td>\n",
       "      <td>41.140863</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>33.703704</td>\n",
       "      <td>35.555556</td>\n",
       "      <td>7.891699</td>\n",
       "      <td>40.396945</td>\n",
       "      <td>8.739837</td>\n",
       "      <td>19.368077</td>\n",
       "      <td>-64.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-2:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>stanford_alpaca50k</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>8.881988</td>\n",
       "      <td>8.881988</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1.118012</td>\n",
       "      <td>41.240564</td>\n",
       "      <td>41.439966</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>32.777778</td>\n",
       "      <td>19.907407</td>\n",
       "      <td>8.730517</td>\n",
       "      <td>41.305526</td>\n",
       "      <td>8.536585</td>\n",
       "      <td>18.860331</td>\n",
       "      <td>-67.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>llama-7b_flan_v250k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>flan_v250k</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>5.093168</td>\n",
       "      <td>5.093168</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-2.857143</td>\n",
       "      <td>42.023928</td>\n",
       "      <td>42.159237</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.888889</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>8.141089</td>\n",
       "      <td>38.614081</td>\n",
       "      <td>9.146341</td>\n",
       "      <td>18.787392</td>\n",
       "      <td>-58.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>flan_v250k</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-3.229814</td>\n",
       "      <td>41.646489</td>\n",
       "      <td>39.965817</td>\n",
       "      <td>3.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>36.203704</td>\n",
       "      <td>32.407407</td>\n",
       "      <td>7.411876</td>\n",
       "      <td>37.258603</td>\n",
       "      <td>8.943089</td>\n",
       "      <td>18.106046</td>\n",
       "      <td>-72.678571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                         run_name  \\\n",
       "0                                                                                                                        llama-7b   \n",
       "1                                                                                                       llama-7b_sharegpt50k_ep=3   \n",
       "2         llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=120000:ep=3   \n",
       "3             llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=120000:ep=3   \n",
       "4              llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3   \n",
       "..                                                                                                                            ...   \n",
       "114                                                                                                      llama-7b_flan_v250k_ep=2   \n",
       "115             llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3   \n",
       "116  llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-2:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3   \n",
       "117                                                               llama-7b_flan_v250k_score=random:s=0_pace=prune:size=30000:ep=3   \n",
       "118         llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3   \n",
       "\n",
       "     compute  subset_size             dataset  \\\n",
       "0          0            0                None   \n",
       "1     150000        50000         sharegpt50k   \n",
       "2     120000        40000         sharegpt50k   \n",
       "3     120000        40000         sharegpt50k   \n",
       "4      90000        30000         sharegpt50k   \n",
       "..       ...          ...                 ...   \n",
       "114   100000        50000          flan_v250k   \n",
       "115    60000        20000          flan_v250k   \n",
       "116    30000        10000  stanford_alpaca50k   \n",
       "117    30000        10000          flan_v250k   \n",
       "118    30000        10000          flan_v250k   \n",
       "\n",
       "                        model_name_or_path  \\\n",
       "0                                 llama-7b   \n",
       "1    results/baselines/huggyllama/llama-7b   \n",
       "2    results/baselines/huggyllama/llama-7b   \n",
       "3    results/baselines/huggyllama/llama-7b   \n",
       "4    results/baselines/huggyllama/llama-7b   \n",
       "..                                     ...   \n",
       "114  results/baselines/huggyllama/llama-7b   \n",
       "115  results/baselines/huggyllama/llama-7b   \n",
       "116  results/baselines/huggyllama/llama-7b   \n",
       "117  results/baselines/huggyllama/llama-7b   \n",
       "118  results/baselines/huggyllama/llama-7b   \n",
       "\n",
       "     AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*  \\\n",
       "0                                     0.000000   \n",
       "1                                    55.962733   \n",
       "2                                    55.776398   \n",
       "3                                    55.403727   \n",
       "4                                    56.770186   \n",
       "..                                         ...   \n",
       "114                                   4.223602   \n",
       "115                                   5.279503   \n",
       "116                                   8.881988   \n",
       "117                                   5.093168   \n",
       "118                                   4.285714   \n",
       "\n",
       "     AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR  \\\n",
       "0                                    0.124224   \n",
       "1                                   56.211180   \n",
       "2                                   55.900621   \n",
       "3                                   55.527950   \n",
       "4                                   56.894410   \n",
       "..                                        ...   \n",
       "114                                  4.223602   \n",
       "115                                  5.279503   \n",
       "116                                  8.881988   \n",
       "117                                  5.093168   \n",
       "118                                  4.285714   \n",
       "\n",
       "     AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed  \\\n",
       "0                                          2011.0   \n",
       "1                                           232.0   \n",
       "2                                           232.0   \n",
       "3                                           228.0   \n",
       "4                                           225.0   \n",
       "..                                            ...   \n",
       "114                                          11.0   \n",
       "115                                          21.0   \n",
       "116                                          24.0   \n",
       "117                                          12.0   \n",
       "118                                          12.0   \n",
       "\n",
       "     AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2  MMLU/0-shot  MMLU/5-shot  \\\n",
       "0                                    -95.652174    31.818829    34.475146   \n",
       "1                                     -2.111801    40.585387    40.920097   \n",
       "2                                     -2.732919    38.505911    40.820396   \n",
       "3                                     -2.360248    40.086882    40.592508   \n",
       "4                                     -2.360248    40.051275    40.321891   \n",
       "..                                          ...          ...          ...   \n",
       "114                                   -3.726708    44.324170    45.719983   \n",
       "115                                   -4.223602    40.620994    41.140863   \n",
       "116                                   -1.118012    41.240564    41.439966   \n",
       "117                                   -2.857143    42.023928    42.159237   \n",
       "118                                   -3.229814    41.646489    39.965817   \n",
       "\n",
       "     GSM/Direct  GSM/CoT  BBH/Direct    BBH/CoT  TydiQA/CB  TydiQA/GP  \\\n",
       "0           5.4     11.8   30.648148  32.685185   9.618017  38.449168   \n",
       "1           6.6     15.0   31.018519  34.722222   7.404910  33.076438   \n",
       "2           7.0     14.6   31.388889  33.981481   7.374776  30.609401   \n",
       "3           5.8     16.8   31.388889  35.833333   7.516569  32.287148   \n",
       "4           5.4     14.6   32.222222  36.111111   8.114699  33.072397   \n",
       "..          ...      ...         ...        ...        ...        ...   \n",
       "114         3.0     11.8   36.759259  34.444444   8.399034  43.318997   \n",
       "115         4.0     12.4   33.703704  35.555556   7.891699  40.396945   \n",
       "116         4.8      5.8   32.777778  19.907407   8.730517  41.305526   \n",
       "117         5.6     12.0   33.888889  33.333333   8.141089  38.614081   \n",
       "118         3.4     10.8   36.203704  32.407407   7.411876  37.258603   \n",
       "\n",
       "     Codex-Eval/Pass@1     Average    ranking  \n",
       "0            10.162602  163.117627 -65.500000  \n",
       "1            10.772358   43.243234 -29.714286  \n",
       "2            14.634146   43.066085 -33.500000  \n",
       "3            12.804878   43.052434 -29.250000  \n",
       "4            13.211382   43.031487 -24.928571  \n",
       "..                 ...         ...        ...  \n",
       "114           8.536585   19.386382 -61.357143  \n",
       "115           8.739837   19.368077 -64.357143  \n",
       "116           8.536585   18.860331 -67.964286  \n",
       "117           9.146341   18.787392 -58.821429  \n",
       "118           8.943089   18.106046 -72.678571  \n",
       "\n",
       "[119 rows x 20 columns]"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_eval_results_with_useful_cols(save_dirs, chat_fmt=chat_fmt, cols=cols)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "faee9084",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot diversity vs. alpacaeval score\n",
    "\n",
    "\n",
    "dataset_list = [\n",
    "    'flan_v250k',\n",
    "    'oasst2',\n",
    "    'wizardlm50k', \n",
    "    'lima',\n",
    "    'gpt4_alpaca',\n",
    "    'dolly',\n",
    "    'stanford_alpaca50k', \n",
    "    'sharegpt50k',\n",
    "    'ultrachat50k',\n",
    "]\n",
    "save_dirs = []\n",
    "for dataset in dataset_list:\n",
    "    save_dirs += [(f'llama-7b_{dataset}_ep=3', f'../results/oi2/llama-7b_{dataset}_ep=3'),]\n",
    "save_dirs = [x for x in save_dirs if os.path.isdir(x[1])]\n",
    "\n",
    "chat_fmt = 'mix'\n",
    "alpacafarm_judge = 'alpaca:eval:gpt4:turbo:fn' # 'alpaca:eval:gpt4'\n",
    "cols = []\n",
    "cols += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/WR']\n",
    "\n",
    "df = get_eval_results_with_useful_cols(save_dirs, chat_fmt=chat_fmt, cols=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "62f664f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 9 artists>"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "d = df.set_index(['dataset']).to_dict()['AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*']\n",
    "d = dict(sorted(d.items(), key=lambda kv: kv[1]))\n",
    "\n",
    "\n",
    "xs = d.keys()\n",
    "ys = d.values()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(20,2))\n",
    "\n",
    "plt.bar(xs, ys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "deeba0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'mpnet', 'kemb': 'text+embedding'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['run_name',\n",
       " 'nonchat',\n",
       " 'sort_by',\n",
       " 'compute',\n",
       " 'model_name_or_path',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Rep2',\n",
       " 'MMLU/0-shot',\n",
       " 'MMLU/5-shot',\n",
       " 'GSM/Direct',\n",
       " 'GSM/CoT',\n",
       " 'BBH/Direct',\n",
       " 'BBH/CoT',\n",
       " 'TydiQA/CB',\n",
       " 'TydiQA/GP',\n",
       " 'Codex-Eval/Pass@1',\n",
       " 'Average',\n",
       " 'ranking']"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from rosemary import parse_kv_from_string\n",
    "from functools import partial\n",
    "\n",
    "def get_dataset_size(dataset):\n",
    "    if dataset == 'dolly':\n",
    "        return 14956\n",
    "    else:\n",
    "        return 50_000\n",
    "    \n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', ]\n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', ]\n",
    "\n",
    "N = 50_000\n",
    "full_sft_run_name_substr = ('_ep=3', '_ep=10')\n",
    "# full_sft_run_name_substr = '_ep=2'\n",
    "full_sft_short = '100% Data'\n",
    "# label_dpp_vmf_grad = r\"$\\text{DPP-}k_{\\text{norm. gradient}}$\"\n",
    "label_dpp_vmf_text = r\"$\\text{DPP-}k_{\\text{norm. embedding}}$\"\n",
    "label_dpp_rbf_grad = r\"$\\text{DPP-}k_{\\text{gradient}}$\"\n",
    "label_dpp_rbf_text = r\"$\\text{DPP-}k_{\\text{embedding}}$\"\n",
    "\n",
    "label_dpp_vmf_grad = \"DPP-Gaussian-grad(normalized)\"\n",
    "label_dpp_vmf_text = \"DPP-Gaussian-embedding(normalized)\"\n",
    "label_dpp_rbf_grad = \"DPP-Gaussian-grad\"\n",
    "label_dpp_rbf_text = \"DPP-Gaussian-embedding\"\n",
    "\n",
    "# label_dpp_acos0_text = r\"$\\text{DPP-}\\text$\"\n",
    "label_dpp_acos0_text = 'DPP-acos0-text'\n",
    "label_dpp_acos0_grad = 'DPP-acos0-grad'\n",
    "label_dpp_acos1_text = 'DPP-acos1-text'\n",
    "label_dpp_acos1_grad = 'DPP-acos1-grad'\n",
    "\n",
    "\n",
    "def compute_nonchateval_average_performance(row):\n",
    "    L = [row[k] for k in non_chateval_task_names if k in row]\n",
    "    return np.average(L)\n",
    "\n",
    "\n",
    "def parse_sort_by_from_run_name(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'score=([^_]+)', run_name)\n",
    "    if match:\n",
    "        sort_by = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(sort_by)\n",
    "    else:\n",
    "        if run_name.endswith(full_sft_run_name_substr):\n",
    "            kvs = {0: full_sft_short}\n",
    "        else:\n",
    "            kvs = {}\n",
    "    return kvs\n",
    "\n",
    "\n",
    "def parse_sort_by_type(row):\n",
    "    d = row['sort_by']\n",
    "    if not d:\n",
    "        return None\n",
    "    if d[0] == 'dppmap':\n",
    "        if d['k']=='vmf' and d['kmd']=='mpnet': #and (d['gamma']==1 or d['gamma'] == 'auto1000'):\n",
    "            sort_by_type = 'vmf+text'\n",
    "        elif d['kemb']=='text+embedding' and d['kmd'] == 'llama7br512p4096':\n",
    "            if d['k']=='rbf': return label_dpp_rbf_text\n",
    "            elif d['k'] == 'vmf': return label_dpp_vmf_text\n",
    "            elif d['k'] == 'acos0': return label_dpp_acos0_text\n",
    "            elif d['k'] == 'acos1': return label_dpp_acos1_text\n",
    "        elif d['kemb']=='grad+rp+loraB' and d['kmd'] == 'llama7br512p4096':\n",
    "            if d['k']=='rbf': return label_dpp_rbf_grad\n",
    "            elif d['k']=='vmf': return label_dpp_vmf_grad\n",
    "            elif d['k'] == 'acos0': return label_dpp_acos0_grad\n",
    "            elif d['k'] == 'acos1': return label_dpp_acos1_grad\n",
    "        else:\n",
    "            print(d)\n",
    "            return None\n",
    "        print(d)\n",
    "        sort_by_type = f'DPP({sort_by_type})'\n",
    "        return sort_by_type\n",
    "    elif d[0] == 'random':\n",
    "        return 'Random'\n",
    "    elif d[0] == full_sft_short:\n",
    "        return d[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "base_model_perf = df[df['run_name'] == 'llama-7b'].to_dict(orient='records')[0]\n",
    "base_model_perf['nonchat'] = compute_nonchateval_average_performance(base_model_perf)\n",
    "\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "dfc.insert(1, 'sort_by' if chat_fmt!='both' else ('sort_by', ''), dfc.apply(parse_sort_by_from_run_name, axis=1))\n",
    "dfc.insert(1, 'sort_by_type' if chat_fmt!='both' else ('sort_by_type', ''), dfc.apply(parse_sort_by_type, axis=1))\n",
    "dfc.insert(1, 'nonchat' if chat_fmt!='both' else ('nonchat', ''), dfc.apply(compute_nonchateval_average_performance, axis=1))\n",
    "\n",
    "\n",
    "dfc = dfc[dfc['sort_by_type'].notnull()]\n",
    "startswithstrs = ('rbf+text', 'random')\n",
    "startswithstrs = (\n",
    "    full_sft_short,\n",
    "    'Random', \n",
    "    label_dpp_vmf_grad, \n",
    "#     label_dpp_vmf_text,\n",
    "#     label_dpp_rbf_grad,\n",
    "#     label_dpp_rbf_text,\n",
    "    ## dont worry about this.\n",
    "#     label_dpp_acos0_text,\n",
    "#     label_dpp_acos0_grad,\n",
    "#     label_dpp_acos1_text,\n",
    "#     label_dpp_acos1_grad,\n",
    ")\n",
    "dfc = dfc[dfc.apply(lambda x: any(y in x['sort_by_type'] for y in startswithstrs), axis=1)]\n",
    "dfc['subset_size'] = dfc['subset_size'].apply(lambda x: int(x) if x else x)\n",
    "dfc['compute'] = dfc['compute'].apply(lambda x: int(x) if x else x)\n",
    "# dfc = dfc[dfc['subset_size'].apply(lambda x: x>1000)]\n",
    "\n",
    "\n",
    "D = dfc.set_index(['sort_by_type', 'dataset', 'subset_size']).to_dict()\n",
    "from dataclasses import dataclass\n",
    "@dataclass(unsafe_hash=True)\n",
    "class DKey:\n",
    "    sort_by_type: str\n",
    "    dataset: str\n",
    "    subset_size: int\n",
    "def convert_key_to_dataclass(d):\n",
    "    return {DKey(*k): v for k, v in d.items()}\n",
    "D = {k: convert_key_to_dataclass(v) for k, v in D.items()}\n",
    "\n",
    "list(D.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "41b95aee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABsoAAAIqCAYAAACNCx9AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3gUxRsH8O9eS++QQkvooZfQQelNuj+6KEWKUlQEkaKCAoKCUqQJKCBIld5774SSAKEmISEhvZfr8/vjuOU2d5dcegLv53nuyd3t7OwkubndnXcKxxhjIIQQQgghhBBCCCGEEEIIIeQdIyruAhBCCCGEEEIIIYQQQgghhBBSHChQRgghhBBCCCGEEEIIIYQQQt5JFCgjhBBCCCGEEEIIIYQQQggh7yQKlBFCCCGEEEIIIYQQQgghhJB3EgXKCCGEEEIIIYQQQgghhBBCyDuJAmWEEEIIIYQQQgghhBBCCCHknUSBMkIIIYQQQgghhBBCCCGEEPJOokAZIYQQQgghhBBCCCGEEEIIeSdRoIwQQgghhBBCCCGEEEIIIYS8kyTFXQBC3jaPHj1CdHQ02rZtW9xFIYSYoFarcejQIaxduxbHjx+HRqMxmS45ORn//vsv1q5dC2dnZ5w7d65oC0pIIVq7di3Gjh2bp31jYmKwYcMGrF+/Hq1bt8bGjRsLtnCEvAXS09Nx6dIlhIWFIS4uDo6OjvDy8kKrVq3g6elZoMdav349Ro4cCbFYnO+84uPjce7cOYSGhkKr1aJcuXLw8/ODr68vn+bgwYNo27YtHB0ds81LLpfj0qVLePjwITIyMuDh4QFfX180a9aML2tgYCAYY6hfv36+y55bycnJOH36NJ4/fw6O41ClShW0b98eLi4uRV4WQgghBUulUmHw4ME4duwYPvjgA2zbtg0SydvdBBodHY3169fjzz//xKhRozBnzpziLhIhhJQujJAS4NSpU2zo0KHM19eXAcjTo0GDBowxxpycnCxKP3fu3EL5XT766CO+LJYaNGiQyTJ6eXmxiIgIi/IYPnx4tr/vunXr8vDbEJKz48ePsyFDhrBatWpl+xmUSCTM3t6eeXp6skaNGrE+ffqwOXPmsNOnTzO1Wl3o5YyMjGQzZ85kXl5egnJldfv2bTZy5Ehma2vLp2nbtm2hl4+QonLy5EkGgN2+fTtX+507d47179+fSaVSvm4MHz68cApJSCl15coV1qNHDyaTyZibmxtr164d69evH3vvvfeYg4MDE4lErFWrVuzgwYMFcrwnT54wjuPYnj178pVPamoqGz9+PJPJZMzJyYl16dKF9ejRg9WoUYMBYD4+PuzLL79kixYtYq6uriw8PNxsXlqtli1btoyVKVOGSaVS1qZNG9anTx/WqFEjJhaLmYuLC/voo4/YsmXLWIMGDdjmzZsF+ycmJub5fiDrw8nJyWT55s+fz+zt7Y3SW1tbs6lTpzK5XJ6vvyd5u4WEhLDvvvuOlStXjs2ePbu4i1MgwsLC2J49e9jSpUvZvHnz2LJly9jRo0dZUlKSIF1oaCjbtm2b0f6hoaHsu+++Y15eXm/N34Tk3axZs3L8flapVIwxxiZMmJBjWlNtGQcPHjSbfsKECczf31/wXm6ve0uTK1eusMGDBzOZTMb/vob1cO/evRafN7M7vxsKCQkxm0d+7w8uXrxoNu9Zs2blK2+Se8+fP2cbN25kCxYsYMuWLWO7d+9mUVFRgjRbtmwx2k+tVrN9+/axbt26MZFIVFTFLbEeP37Mdu7cyZYsWcLmzp3LFi1axHbs2MFCQkIE6cLDw9nly5eLp5CEUaCMlDiTJ08WnAi3bdvGzp49K3icPHmS/ffff+z7779n5cqVEwTKnjx5ws6dO2cycNSqVSu2Y8cO5u/vz2JjYwu87JGRkXwD4vnz5y3eLzw8nJ05c4Z99dVXzM7OTlDmJk2asIyMDIuOffPmTbZo0SJmY2PDADAPDw+2ceNGdvfuXaObHEIKmlarZePGjRN8ftu3b89mzZrF/vrrL7Znzx62YcMGNnfuXNauXTsmkUj4dB4eHuz3339nCoWi0MoXFhbGzp49y5YsWZJtoOzWrVvsypUr7JNPPqFAGXkr9ejRgwFgI0eOzNV+Fy9eZFeuXGFdu3alQBkhWaSkpPAdn7y9vdnu3bv5RkA9hULBtm7dyipUqMAAsG7durG4uLh8HVffwNi+ffs855GQkMDq1avHNy6mpaUJtt+4cYN16NDBooY0rVbLhg0bxgCw9957j4WFhQm2h4WFsfHjxwvyMhcos7KyYjNmzGDnzp1jAQEBLCgoiAUFBbFNmzYJ9te/HxQUxO7du8cOHDjABgwYYDZQllPnMgCsTZs2Fl1/k5KjZs2aFjUCv3r1yuT+Wa8Psz769OnD9u3bx7p27cpEIpHJxujSRqlUsnXr1rHGjRszAMzOzo61bt2affjhh6xbt26sSpUqTCqVsl69erHjx48zuVzOhgwZwvr06cPncfDgQdajR4+35m9CCkZUVBQ7dOgQa968uaAeiUQi9vvvv7OAgAA+bWRkJNu1axerXr26Ub2bPHkyu337tsm2jNTUVHbt2jU2c+ZMxnEcA8DKlSvHtm3bxl6+fMlUKhXr378/s7W1Zf379zc6J79NTp48yc6cOcPatWtnsh6mpqaywMBAtmvXLqPvSrFYzL744gt28uRJFhAQYPHfSalUslu3brF//vmH71Sjf0ilUvbixYs8/z49e/YU5Ofg4MBWrFjBbt26VSjteMS0Z8+esW7dujEArGLFiqx3796sY8eOzNPTk3Ecx/z8/NiPP/7Ivv32W1atWjV+v8jISPbDDz+w8uXLZ9vu8i5ITU1lCxcuZNWqVeM/y35+fqxXr16se/furF69ekwkErFatWqx2bNnszt37rBff/2VzZw5U5BPYGBgjtc3IpGI2drasooVK7J27dqx6dOns4cPH5os1507dywOnuf0yO1AkZLu3fykkhIta8+frNH1rBITE1nDhg1NVk7DEWo+Pj6F3jvUsOfU//73vzzl8ejRI74BRf8YPHhwrvL48ssvGYB89y4mJLcuXbpkcf198eIF+/jjjwXpmzdvzl6+fFmoZdRqtXwwObsLtmvXrlGgjLx19KNPAN3IibzcbG7fvp0CZYQYePHiBd/w1KBBgxyDX9HR0axu3boMAKtevTp7+vRpno6bmJgoGBUVGBiYp3z0DVIDBgwwm0aj0bCJEyfmGChbvHgxA8AqV67MUlNTzea3fft2/rvIXKBs165dJvc9e/asRQ0vs2fPNgqUbdiwgQ/CjRw5ki1dupStX7+ejRkzhllbWwvyHT16tNm8SckTHBzMrly5wr766iujRpz333+fHT58mD18+NDsLAYJCQns3r17bOPGjXxHTABsypQpzN/fn718+ZKdPHmSXbx4kQ8sleag0NWrV/nGbW9vb7Zp0yaWmZlplC4oKIi/XtfXWcNA2d69e9mJEyf477TS/DchBS8hIYG5uLjwn40mTZqYTRsRESE4p8lkMqbRaCw6TpMmTZhIJGK3bt0qqKKXSv/++2+O9dDwHhcAmz59er6PGxQUZPS9O2nSpDzldf/+ff67Rv9YsmRJvstIcufmzZvMycmJyWQytm7dOkFdVKvVbO/evaxy5cr8/6hq1ar89kePHrFjx46x+fPnv9OBsmPHjvHBwtq1a7Pt27ebPM/GxcWx+fPnM0dHR7PXoAqFgj18+JAdOXKEtW7d2qi+6WdsMOy0on9/zJgxRsfVB8qcnJzYggUL2KVLl1hgYCDf8eznn3/m8yhXrpygU9rt27fZzp07WadOnShQRkhReP78ea4CZYwxdv36ddawYUOj9//3v//x+fTr168QSvtGZmYmK1OmjOALKWsvWktlvXgBcjdV5KpVqxig62FLSFF68uRJruvvxo0bBVO51axZk8XExBRqOT09PXO8YHv06BEFyshbJ+v0Nj///HOu8zh27BgFygh5LTExkdWuXZsBYLa2tuz58+cW7ffkyRNmZWXFB5Xi4+NzfexFixYJ6vPYsWNznYfhNeelS5eyTatWq1nLli3NBsrkcjk/Bfq8efNyPPa0adPMBsqaNm1qdj9LA2VqtZr5+vryr7VaLatUqRJr1qyZyU45T548YVWqVOHz5TjOousYUvK89957/P/R3t6epaen52p/fYeQQYMGmdy+cOFCi4NC8+fPZ2fPns3V8Qvbli1b+Gvvzp07WzTzyPbt2/nZIAwDZXqGjWrFHSgbM2YM1d0S5IsvvuA/G66urtkGv77//nvBd3BycrJFx6hQoYLJz+W75ujRoznWw9TUVME5dP/+/QVybGdnZ0G+NjY2ebqnN5zVRf84evRogZSRWCYlJYXvMLJy5Uqz6RITE1mrVq2MAmV6Go1G0AnpXbJ06VI+4Dtq1CiTAbKsnj17xne86927t9l0cXFxgmDyzz//zM/MpFQq2bFjx4xG83bp0kVQhjt37jCxWMyuXr1q8hj6jmX6zjSmaLVaNmLEiLcuUCYCISWMSJT7j2WzZs3QqFEjo/ft7Oz45/b29vkqV07+/fdfxMXFQSaTAQA0Gg1Wr16dp7w8PDyM3vvhhx+wd+9ei/a3sbEBAFhbW+fp+ITklVQqzfU+w4cPx9q1a/nXjx8/xsiRIwuyWEb09TS/aQgpTZKTk7Fp0ybBZ3v16tXQaDS5yofqBiFvDB06FA8fPgQAzJgxA1WqVLFov+rVq2PKlCkAgJCQEAwdOjRXx9VoNFixYoWgPm7ZsgWJiYm5yufo0aP8cwcHh2zTisVizJo1y+z2q1evIjk52aK8AGDatGlmr1Xff//9HPfPiVgsRps2bfjXly9fhkwmw/Hjx1G+fHmj9NWrV8eBAwcgkUgAAIwxnDp1Kt/lIEXPz8+Pf16zZk3Y2trmav86deoAAFq3bm1yu7Ozs0X5KBQKrFy5MlfHLmwHDx7EJ598ApVKhdq1a2Pv3r1wcnLKcb9BgwZh+fLlZre7uroWZDHzLDY2Flu2bCnuYhADn3zyCf88ISEBV69eNZt2zJgx4DgOgO47+OzZsznm/+jRI7x8+RIff/xx/gtbyllyjW7YRgYUXDuZo6MjmjVrxv//MjMzsXTp0lzlER4ejm3btqFFixaC96ldq2itWrUKkZGRsLW1xejRo82mc3Z2xs6dO+Hi4mJyu0gksvh8+TZZvXo1vvrqKzDG0KtXL6xbt86iz3DVqlVx7NgxODo6IiYmxmw6Nzc3lClThn/t5eXF132pVIquXbviwoUL6NSpE5/mxIkT+OGHHwT5fPjhh0Z1LTc4jsNvv/0GKyurPOdRElGgjLw1/v77b6P39CdpIG8BuNxYtmwZfH19MXXqVP69devWQS6X5znP7t27888ZY/j4449x7969fJWTkJJoxIgRGDJkCP/68OHDFgeG88LwuyE/aQgpTdavX4+0tDSsW7eO/3yHh4fnuq5R3SBE58iRI3ygSSKRYOzYsbnaf+zYsXx9On78OA4cOGDxvvv27cOLFy+wbNkyvtErIyMDf/31V67K8OrVK/75oUOHckzfvXt3lC1btkDycnNzwwcffGD0vpOTE+bPn5/j/pb4448/+OeXL1/G7Nmzs220qVOnDvr27cu/jouLK5BykKLl6OjIP89LI7C+TpkL+FraYeTXX39FZGRkro9fWCIiIjBs2DBotVoAwNq1a40azbPz+eefmw1il5RONNOnT0dmZmZxF4MY8PPzg6+vL/96586dZtNWrFhR0MFh9+7dOea/a9cu2NnZmTyfvGssafPKeh1fUO1kHMehVq1a6NOnD//eypUrkZKSYnEev/32G1QqFaZPn14gZSJ5o7+2tbKyyvG7vXz58vj000/Nbi8p54aicu3aNXz55ZcAgLJly2Lz5s25qmM+Pj6YO3cuYmNjs02XUwcgmUyG9evXC469cuVKpKam8q8LolOaq6sr6tevn+98ShIKlBFSAE6fPo3AwEBMmjQJn3/+Od8TNS4uDtu2bctzvgMHDsScOXP41+np6ejdu3e2vQsIKa3mzJkjOJHPmzevGEtDyNtFP/qkadOm+OSTT9ClSxd+m2FDMiHEct9//z3/vGPHjnB3d8/V/t7e3oIRK4bXfDlZunQpypUrh9GjR2PYsGH8+6tWreIbwS1hGPSaP38+zpw5k216kUgkGK1jLq+TJ09i4cKFOR6/WbNmRu9xHFdgvVMNe/B++umnFo3ca9WqFf/c09OzQMpBilZ+O3TktL8l+Z85cwY//fRTvspR0KZMmcI3Wrdr187siLnszJ492+T7JaETzT///GOy8ywpfh999BH/fOfOndnOZmDYeXLfvn05djzevn07evfuzc+qQ4qXYZArOTnZ4lmWEhISsH79etSuXRu9e/curOIRC+g7PiUmJuLKlSs5pjccNZpVSTg3FBWNRoNx48ZBpVIBAGbNmmXRiO2sxo0bB8ZYvsvj7e2Ntm3b8q8zMjJw/fp1AEC9evUwbty4fB8DePvaEihQRkq1knICXbp0KZydnTF8+HBUqFBB0Ismv18as2fPFtzUh4WF4cMPP4RSqcxXvoSUNDVq1ECHDh3417dv30ZQUJDJtAEBAfj8889Rp04d2NnZwc3NDU2bNsVPP/2UY++bgtCkSRNwHGfysXjxYqP0Pj4+Runu3r1b6OUkRG/fvn0IDQ3le7hNnDiR33bhwoUCH6389OlTzJgxA+XKlcPGjRsBANHR0fj6669RuXJl2NjYwNfXF3PmzEFGRka2eZ0+fRoDBgxAxYoVYWVlBScnJ/j6+mLSpEl4/PhxjmXRarX4559/0L17d3h6ekImk8HDwwN9+/bF6dOns9139+7d6NmzJz+lhb7X3PTp0xEREWHx34O8fUJCQnD79m3+dfPmzfOUj2Gg6M6dO3j27FmO+9y+fRuXLl3C+PHjIZFIBPU5JCQEBw8etPj47du3559nZGSga9eu+OWXX7JtxPzyyy8FI3b0mjdvLujhOmPGDHz00UdISkoym1efPn2KrCdqmTJlLOrVa9jY2rhx48IsEnlLHTlyBL1794ZarS7uovAeP36MXbt28a/zOk1dhw4dULVq1YIqVoH566+/MGrUqOIuBjHDsD0jKioq2ykVq1evzj9PTU3N9pwWEBCAhw8fYvDgwUbbMjMz8c8//+D9999H5cqVTe5v7n7O3MPGxsbouvXJkycYP348fH19YWtrC1tbW1SuXBmDBw/Odvre5ORkrFmzBs2aNePPxfHx8Rg5ciRcXV1Rs2ZNnDt3zmg/xhi2bduG7t27w8vLC1ZWVqhRowZ+/PHHfM1mVFCaN2+Odu3a8a+XLFliUblWrFiB9PR0TJs27Z0KrpREhh2fhg8fjvDw8GzT16lTp9CXuikNtmzZgoCAAAC60XgjRozIUz5WVlZYsmRJgQTL6tatK3itH3QhFovztGyKKW/b1KgUKCOlllwux6VLl4q7GHj27BkOHz6MUaNG8VNXGDZY3LlzJ9/l/PvvvwW9Wy9fvozPPvssX3kSUhIZ9ngBYHRzoVKpMHbsWDRo0AARERH47bffcOnSJfz666+Ii4vD7NmzUbNmTezZs6dQy7lixQp069ZN8J6Pjw9OnTpl8ib92LFj/IWSu7s7du7cKZiChJDCtnTpUnh6emLgwIEAgA8++ECwllJB9ATTaDTYtGkT3n//fdSoUQMLFy7keyQGBQWhUaNGWLJkCUJDQyGXy/H48WP8+OOPaNGihdmR0l9//TU6deqE69evY9GiRbhy5QqWLl2K5ORkrFixAn5+frh586bZMr148QJNmjTBt99+ix49euDo0aM4deoUmjdvjv3796NTp06CKZP11Go1Bg4ciP79+yM0NBR//vknLl++jDlz5iA0NBS//PILGjVqhBcvXuT770ZKp8OHDwteN2zYME/5ZA0SHT9+PMd9lixZAisrK36qx7p16wrOn7mpzx06dEDLli3512q1GtOnT0fz5s1x48YNk/t069bNZKDMwcEBkyZNEry3detW1KpVy+wMC76+viVuypaXL18C0DX8lLSykZJv9OjR6NmzJ9LT0/n32rdvzze0G079qVarsW/fPvTp04dvsNJoNPj5559RoUIFlC1b1mhdMLlcjiVLlqBNmzZwcXGBVCqFp6cn2rRpgyVLlkChUJgs14YNGwSjTbt27Zrn33Hy5MkWpdNqtVizZg38/Pz44MGcOXOyDSBqNBr8/fff6NixI8qWLQupVIqyZcuiSZMmmDt3rlHgXS6Xo0+fPhg9erQgwF+5cmX+b57X72dScKpUqSI412zdutVs2v/++0/wOru027dvh7Ozs+C+7OnTp5gwYQK8vLwwfPhwXLx4MdsG5969e+PcuXO4f/8+goKCBI+DBw/yswUBuvOvYYeQnTt3on79+vj7778xZswYXLx4Edu3b0fZsmWxY8cOdO7cGatWrRIc7/bt2xg2bBi8vLzw+eef4+bNm2CMITExEe3bt8fGjRuRmJiIJ0+eGE3pnJiYiI4dO2Lo0KGws7PDli1bcPnyZXz00UdYuHBhoa/zbakZM2bwz6Ojo7Fhw4Zs02dkZOCPP/5ApUqVcr1mKyl4hp2onj17Bj8/P6PrXkMikQgzZ860OP8nT55g+PDh8PDwgKOjIzp37gx/f/8c9ynKgHRSUhLmzp2Lpk2bwsXFBTY2NqhZsyYmT55sdkrlZcuW8c87duyYp9Fker179y6QgHHW6ZXzU6Z3BiOkhAkJCWEA+EdISIhgu1qtZk+ePGEDBw5kOX2Ehw8fzuczfPjwQinvxIkTmUgkYsHBwYL369atyx97wIABucpT/zfYsGED/15MTAyrXLmy4G/z22+/mdx/w4YNJv92hBS2nOpvTo4ePSrYf/To0YLtAwYMYADY2LFjjfaNj49ntWrVYgCYWCxm//33n9njeHt788ew5Hdp27at0XalUsmaNWvGpxk1alS2v9vGjRsZALZ///5s0xFS0Pz9/RkA9uOPPwreX7RoEf/5tbGxYXFxcRbld/bsWZPnVq1Wy44cOcLOnDnDypcvz6dZunQpq169Ops8eTK7cuUKu3LlCpswYQLjOI5P07VrV6bVagXH+ffff/ntJ0+eFGy7efMmv61Dhw4myxkeHs68vLyYm5sbCw0NFWyTy+XMycmJz2Pz5s2C7fPnz+e3PX36VLDtv//+s7jek7fX+PHjBeerK1eu5Cmfc+fOCfL57LPPsk0fGRnJZDIZGzlypOD9Xbt2CfJ58OCBxWUIDg5mFSpUEOwPgHEcx4YNG8bCw8MtzkuhULAOHToY5QWAtWzZkl29etXivMwx/A4qjNvZ1q1bG12Hk9Jl9uzZ2V7D5cTUvZgh/b0WADZ79mzBtsePH7OgoCA2YcIEPs2mTZtYUFAQCwoKYk+ePGGvXr1iU6ZMYe7u7oLPslarZcOGDTOqOy9fvmSMMRYREcHq1KnDALA+ffqwCxcusIsXL7KvvvqKP6e2bNmSqVQqozLXrl2bz8/T0zPXf5OcZP2bpKSksC5dupj8Lhg3bpzJPFJSUtj777/PALA2bdqwEydOsGvXrrGffvqJyWQyBoBVq1aNJScn8/uo1Wr+b9u3b1/+GKdOneLfp3vikmHlypX8/8fJyYnJ5XKjNCqVirm5uQnaPWQyGUtMTDSZZ5UqVYyuxR4/fswuX77Mpk2bxufh7e1tcn9HR0eWnp5ucptSqWRNmjTh8/jf//4n2P78+XNmZWXFALBZs2YJtqWlpTEPDw8GgNnZ2bGMjAx+24MHD9jVq1fZt99+K/ie6t+/P1uxYgXbsGEDc3NzYwDYBx98wO+Xnp7O33t+/fXXRuW9cOECk0gkZr+bDBnWx7Nnz5pNlxve3t6C+4LGjRvzx6hcubLJ7yW9P/74g79nKMwyEstERkYyFxcXo+/uwYMH8+cjS2Vtd9mzZw+ztbU1ytvR0ZE9fvzYZB47duxgVlZWzMrKii1evJjdunWL7d+/nzVt2pTff+XKlYJ9/P392UcffcRsbGwE9SwhIYHVq1dPcOzq1asL9j19+jQrU6YMGzVqFDt79iy7efMmW7RoEX/v6OzszM6cOSPY59mzZ4I858yZk6u/U24Z/l2zu17Vt5/pH5Ze0xue0819f76tKFBGSpysDe1isVjwMGxYy+nmuLADZUlJScze3p716dPHaNvq1av5Y0skklydUMzdnD18+FDQsCcWi9nRo0eN9qdAGSku+Q2UGTZ+A2C9evXit/39998MAHNwcGBJSUkm97927RoTiUT8DZi5elcQgTLGGLt//z5/vCpVqhg19BsaOnQoq1atWrZpCCkMH3/8MZPJZCwqKkrwfkJCguDmYeHChRblZy5QZmjy5Ml8mnLlyrG9e/capfn9998F9f3QoUOC7b169eK3ZQ10McZYxYoVGQDm6upqsgwtW7ZkANjatWtNbu/atSuf/9ChQwXbDG+gslIoFHxDROPGjU3mTd5+/fv3F3x+79+/n6d89IFscw1xWX3//fcMALtz547gfZVKJQh25RRwyyo0NJT5+fmZbNS2sbFhP/zwg6ChLzuZmZkmG/v1jyFDhuQq+JZVYQbKgoODmUgkYg0bNmRqtbpA8yZFpzgDZabKkLWRNzo6mp09e5Zt27aNicViPt3y5cvZqFGj2IkTJ/jzkLu7O0tNTWWMMda5c2e+0Spro/PEiRP5fP755x/BtrS0NP56FQBr1apVrv8mOTH8m3z99desVatWbOLEiezevXssJiaG/fXXX3xQQSQSsWfPnhnlMWbMGAaAWVtbs5SUFMG2xYsX8/n/9NNPJstgeO9P98ElT2xsrCCQs2fPHqM0R44cYYCug5SDgwOfdt26dUZpb9y4wQCwEydOmDxeZGRkjg293bt3N1verIG2rMG63377jd++ceNGo/0//vhjfntAQIDR9ri4OH67ra0t+/777/ltCQkJ7Pjx44Lz7pdffskAMF9fX7NBJ8Nzb3EHynbu3Ck4TtZOaXpqtZr5+PgwNzc3QdCyMMpILHfo0CG+g4Lhw87Ojs2ZM8dsgDkrw3aXrVu3slq1arEdO3awV69escDAQNaxY8ds7yuLOiB96dIlJpVK2a+//mpUloCAAL4sTk5OgsES+rYqw9+1MFkSKEtMTGSOjo58utatW1uc/7scKKOpF0mJd+TIEdy9e5d/+Pv7Y+fOnahdu3ZxFw1//fUX0tLS+DVfDH388cf8sFa1Wm005D4vatWqhV27dvHD/zUaDQYPHoxHjx7lO29CSoKsQ8H185mrVCr88MMPAIBOnTqZHTLevHlzdOnSBYBumP2vv/5aiKXVTcs0YMAAAEBwcLDZOfTj4uKwe/dujB8/nuZcJ0UqKioKO3bswODBg+Hh4SHY5uLiIpjeZNWqVdmuS5QbDg4O/POJEyeib9++Rmm++uortGjRgn+9bt06wfYyZcoA0K0XpH9uqEKFCgCAlJQUo20HDx7E1atXIZVKBQvIG5oxYwaqVKmCsmXLYtCgQSaPXalSJaP9ZDIZP3e/qWOTd0NycrLgdV7n5886hWFqaqrZtAqFAmvWrMH7779vNJWYRCIRLMq9efPmbNcGy8rb2xtXr17Fjz/+CCsrK8G2zMxM/PTTT6hdu3a209voWVtbY/Pmzdi1axc8PT2Ntm/btg2+vr5Yvnx5gay/UJAWLlwIsViMv/76C2KxuLiLQ95S7u7uaNeuHQYPHoxatWrx7x8/fhxr165F586dcfv2bZw6dQr37t2Dvb09EhIScPLkSQC6aQUNp4MDgH79+vHPs66DGxISIph2Mev1QEH7+++/MXv2bPzxxx+oX78+ypYti1GjRmHMmDEAdFMyHjlyxGi/7du3AwA8PT0F1xFA9r8fKR3KlCkjmPLT1JS827Ztg4+PDzp27IgPP/yQf9/U9Ivbt2+Hu7u7YI1rQy4uLjmWadq0aSbfP3XqFBYtWgRAd37dunWrYNpU/e+jZ+p6UX+dCpi+XjQ8/5cpUwazZs0SlL1Lly78mplPnz7lp1UeO3asUf3X69Gjh8n3i8P//vc/wXpzCxcuNHnO3759O0JDQzFp0iTBtJakeOmnrHd3dxe8n56ejjlz5qBGjRr4999/c5Xnf//9B39/fwwcOBCenp6oW7cu/v33X/56y1Rbyr59+/gphQ0/T4BuWkF92096erpgnd/atWujRYsW+Oabb/j3bt68iVq1amHChAkYMWIEnj59iuPHj/PTvSqVSgwdOhR16tQxOTV/vXr1+HNRcnIy5s2bx2/L2iab9fvCnMePH0MikWT76NOnj0V5GdJqtfjss8/47x6ZTIbffvst1/m8iyhQRkq8GjVqoG7duvyjUaNGGDBgAI4dOwaZTFZs5dJqtVixYgXq1asnmMNXz87OTrB447p168zOGZ8bnTt3xooVK/jXycnJ6NWrFxITE/OdNyHFLWsDoaurKwDdGl/6NUPq1auXbR6GjeJbt24t9EY4wznYDS+WDG3YsAFisbjEzBtP3h2rVq2CUqnEF198YXK74ZqaYWFh2L9/f4Ec1zAg7OXlZTbN+PHj+dcXL14UbF+0aBF+/fVXHD9+3Gh+9djYWP77wtRaJ/rGtpo1a5q96W7bti2eP3+OmJgY9O7dW7Btw4YNWLBggckbtrCwMP6Y2a2zQt5uWTtsZBfgyo5SqRS81p/3TPn3338RGxtrtj6PHTuWvzZOT0/H33//nauySKVS/PDDD7h//77JxrbQ0FB06dIFCxcutCi//v374/Hjx5g8ebLRguHp6en48ssv0a9fvwK5Pi4I/v7++Ouvv/DLL7+gcePGxV0c8o4wbCxftGgR32AokUjQsWNHPthsY2PDnwtz2yif9XVhN0ZPmDCBb7w0ZLjmtqk1PrPrpJJT0IGUDsOGDeOfHzp0SHDulMvl2L9/PwYPHgyO4wT3dOfPnxesC8QYw86dOzFgwACznRosaStq166d0XtxcXH45JNP+HvIH3/8UfDZ1fvoo4/w559/YsuWLUbtQXK5XFBeU9eLhsGuypUrG3VSMbRixQo+2P3++++bTWeqc0pxEYlEgiDFgwcPTF5X//rrr7CzszNa45QUvw4dOuD+/fsYMmSI0baIiAgMGzYM7dq1w/Pnzy3Kb8eOHXzwV8/DwwNVq1YFACQkJCAtLU2wvSgD0tu3b0dYWBg++OADs52bvb29+ecHDhzgvyeytsdmve41x8fHB1euXMG6detQtmxZaDQa/uHl5YWtW7di6dKl2eYRFBSE4OBgKJVKqFQqXL16FV27dsWOHTsA6M75//77L5o3b25Rmd51FCgjpVbFihWLtaLv27cPISEhZhsrAN1Ngv4LNjY2lm+4y69x48YJFlF+9uwZBgwYQA12pNRLSEgQvNb3eDXswe7m5pZtHobfC3FxcRZfuOVVgwYN0LNnTwC6XkrHjx8XbGeMYe3atRg6dKjFPYsIKQj60SetW7eGn5+fyTQNGzZE69at+df63qpFxbBhISEhQdBg4ubmhm+++QbvvfceAN0o6kOHDqFPnz5o0KCB2YWUAeDq1asA8r5gsbe3N6ZPn4769esD0P0tt23bho4dO+K9995Deno6AJS40TCk6OhHFerlteE2a4Ata76Gli1bhkqVKpkcoQnoRqnoRzkDwMqVKwWjSCxVrVo1HDp0CMeOHTOawYExhhkzZuCvv/6yKC9HR0f8/vvvCAwMNBl8279/P0aPHp3rMhY0uVyOTz/9FIMHDxZcYxNS2Awbyw1Hl2VlY2OD48eP45dffjHZKzw4OJh/nvWeMGuDnUqlymtxLWJutIthRwBTnQsOHDiABQsWYNOmTUbbDK/n6Z639Orduzfs7e0B6EYr79u3j992+PBhpKSk8LMddOjQgQ/8aLVaQVvKpUuX8PLlSwwePNjssUSivDV3jhw5Eq9evQIAdOzYEdOnTzeZTiwWY+zYsYKA3u3btzFu3Dh4e3vj3Llz/PumrhdzM8uI4QhMU8GCkmr48OEoV64c/3rBggWC7UePHkVAQADGjBmTbUchUnzKli2LrVu34tSpU6hTp47R9vPnz6Nhw4Y4ffp0jnnl5dxQlAFpfSB34cKFZkd3Gc5YFBcXxwfIsuZraQc6KysrNGvWDCNHjsSyZcsE25YtW4aBAweicuXK2eZx+PBhdOjQAVZWVpDJZGjVqhVOnToFLy8vjB07FgEBAejfv79F5SEUKCOlnOFJt6jpo/qfffaZ2S/RWrVqCS6KCrIBcvHixejVqxf/+vTp0yangCSkNLlz547gtX5aNsNh9Dk1+lWrVk1wYxQbG1uAJTTNsGfS3LlzBdtOnjyJZ8+eYcKECYVeDkIM6UefXLlyJdvpHK5cucLvc+7cOQQGBhZZGStUqCAYLWbqpkKhUGDFihWoXr06Fi5ciKFDhyI0NDTb0aVRUVFm88uNlJQUzJs3Dz4+PtiyZQumTp2KkJCQbIMZ5N2Q9fMXEhKSp3zi4uIEr5s0aWIy3ZkzZxAQEIDw8HBYWVmZrc+GU1kFBwfj8OHDeSoXAHTt2hX37t3DkiVL+IZNvSlTpuQqOFizZk0cOnQIhw8fNrrh37JlCy5cuJDnchaECRMmwNXVNdej8EjJlNcG8qyKYrrs3ByjdevWmDZtGt/DPj4+Hr///jvq1KkjuA/M2iiftZNZTExMPkqcd4YjfEwF6+rWrYvp06fDx8cHAJCWloZ169ahefPmgqkXqZNK6WVrayv4Xxqes7Zv34569erx51exWCwIhBlOv7h9+3ZUrFhR0NmrIPzxxx84dOgQAF2AYPPmzRZ9nxw8eBCtW7fGgAED4Ovri6CgIMHsQvkhl8sF98KlaXpCmUwm6Hxy7do1nD17ln/9yy+/QCqVYsqUKcVRPJILHTt2xN27d/HHH38YnVPS0tLQs2dPPHjwIE95Z3duKMqA9K1btwAA3333nWD5H8NHQEAAAgMD+Yd+muCs94Z5uS/Iem+RXecZQ1OnTkVoaCjS09MRGhqKx48fIyYmBpGRkfjzzz/5EXvEMhQoI6VaQY3Qyq07d+7g4sWLmDJlitkvUP1j7dq1/H7+/v6CBsn8EIlE2LZtm2CNilWrVmHNmjUFkj8hxcGwoYzjOH7OecN1k+Lj47PNg+M4wboGRdE7rUWLFnwPp8uXLwtuANasWYNWrVoZrSdDSGFbvnw5qlWrhoCAgGzPU/fu3ROsV1LUo8oMR31lHQF2/vx51K5dG/PmzcOSJUtw6dIlDBo0KMfpdPQ3Sk+ePMlzz/ndu3ejevXq2LRpE3bu3InDhw+je/fuBdYAS0q3jh07Cl5n7ehhqfv37wted+7c2WS6ZcuWwcnJCf7+/jnWZ8PzTU71+datW4IGuKwkEgm++uor3L17F9WqVePfT05Oxp49ewRp4+LiclzD7IMPPkBgYCA/EluvOANUy5cvR0BAAPbv31+s07qTgmM4FVtegir684alUycVtZCQEIwbNw7Vq1fH48eP8e+//xrNaGCoUqVKgk4pxRUoM2ywzK7jW0xMDL755ht4e3vjzJkzWLx4Ma3J/RYxbPA+efIk4uLikJqaisOHDwvWzs2a1t/fH0+ePIFGo8F///2HQYMGFWgwOyAggJ8qkOM4bNq0yez04XovXrxAhw4d8OGHH6JXr178dMMFef+ZdcaV/HYCK2rjxo0TrBenH1V2/fp1nD9/Hh999JFg+jxSckkkEkycOBFPnjzBZ599Jqh/crk8z9NnWnpuKMyANPCmg7WNjY1g+Z/sHvrrhAYNGgjyystamlnXO846TWVObG1t4e3tjRo1alCnznygO31C8mDp0qWwsbHB9OnTc/zi/PTTTwWLTi5fvrzAymFnZ4dDhw4JRtZ98cUXgkZ6QkqLly9fCm7yP/zwQ77x3nC+9YcPH+aYl76BRCQSCeaRLkyGo8r0a5VFRETg4MGDNJqMFLmzZ8/i3r17mDx5co7nqXr16gk+o//++2+RrnupX6PJ1dVV0JC3e/dudOzYEVFRUTh//nyuFjLW93SUy+U5NtwDuoYaw3WSli5div79+0MikeDSpUv89I+E6NWoUUPQ8/PSpUt5ysff359/3qFDB5ONcs+fP8ehQ4cwduxYNGrUKMc6/fXXX/P7njp1CkFBQWaPf+vWLYtGnVWtWhXHjh0T1NGAgABBmri4OKxcuTLHvOzs7LB7925Bo0LWvIrKjh07sHbtWhw9elTQyYaUboYjLjIyMnK9f2ZmplE+JYFGo8GcOXPg6+uL0NBQ3L17F3/++WeOnbEkEolgavJnz54ZrQNTUqxatQpVq1bFuXPncP78eWzbto3OwW+ZTp068fd4arUau3btwv79+yGXy43WQmrSpAlq1KjBv966dSvOnDmDmJiYbKddzK3MzEwMGTKEvxb8+uuv0b1792z3efLkCZo1a4azZ89iw4YNmD59utmp5fIj6zq9T58+LfBjFCYHBwfBfcbJkyfh7++PhQsXguM4fPvtt8VYOmLK7t27s53i1tXVFatXr8ahQ4cEn8+zZ8/meYaF7BRFQBp4c0+al85vbdu2FXTSOXXqVK476hTFKHaSMwqUEWKGQqHA559/bvR+dHQ0tm/fjhEjRggWljRHJBIJpsLYs2dPtuuq5Fb58uVx4MAB/kZOpVLhn3/+KbD8CSkqCxcu5HvwikQiQeDJcAHl8+fPC0aYZaXVavnpoDp27GjUM6ewdOzYkW+EOHPmDL8oq6urK80JTYrc0qVL4ebmhpEjR1qU/vPPP+d7rWVkZGD9+vUFVpbsbhIUCgUflGvbti3/fkpKCkaNGgWNRoNBgwahZs2auTqmYaPh4sWLs02bnp6OH374gZ9b/vnz55g6dSoAXS9Yw9F2hBgyPE/5+/tnG5AyJT09XbDuyJw5c0ymW758OcRiscVTbA8ePJjvRMUYw4oVK7JNb2kHq6pVq+KTTz7hX+sbFAxduHAh23O0nkwmw8yZM7PNq7AdO3YMc+bMwYkTJyy6pielh2HjWXR0dK7310+JathRq7hptVoMHDgQP/74I9q3b4/Dhw/naq0iw6CCUqm0qBNJUfvqq68wYcIEPlBWt27d4i4SKQSmplTctm0bWrVqZbKDo+Gosq1bt2L79u2oXr262fV382Ly5Ml8Z8wmTZoYraVlyrhx4xATE4PKlStj2LBhBVaWrJycnATnqDNnzli0X2FNUbp3715+LSdLffHFF4LRMePHj8f+/fvRp08f+Pr6FnQRST7t2rXLomkUP/jgA6M1awt6Cv+iCkgDb64dTpw4YVFnkhcvXvAj4JydnQVtPq9evSqR51mSMwqUkRKnpMw5/ueffwp63un98ccfUKlUgt66ORk5ciQcHR0B6AJZlvS2zQ0/Pz9s2bKFpoMipdaRI0ewatUq/vX333+PRo0a8a8HDBjAB4Pj4+Nx7Ngxs3kFBwfzPaAMG/SKgmGj6Zw5c7B+/XqMGTOGpnIiRerJkyc4dOiQIPiVkzJlygimu1mxYkW2PQlzQy6Xm91269YtvlHdsCHk/PnzfMA763SMpmS9dujRowf//MyZM4Lvl6z7jR8/Hi1btuTfO3LkCF+mnI5dUq5ZSPEYMGCA4LOT21kDNm7ciPT0dADAkCFDTI6aSExMxIYNGzBo0CCUL1/eonylUqmgs9emTZuyHSV64sQJJCcnW5R3/fr1+eemAtgJCQkWLehuSV6F6dixY5g0aRKOHDmS7ZrHCoXCogZTUrIYNrZHRkYKRgxb4smTJwCK/nOZnc2bN/PTnc6cOTPXDYVDhw4VBBD37t2b57KEhYVlO2VrXpw/fx7Lli0DoBvNk3UUDXm7GF7zXb58GSdOnDCadlHP8P2nT59iy5YtGDRoUIGVZe/evfjzzz8B6EY/bd++3ey0q/rzQWpqKr82Ul6uU3OrU6dO/PP169dbNFK2MDqgMMawZMkSo+mnc1K2bFmMHj2af33jxg0wxjB9+vSCLiIpIJZ2oho0aJBgLa2C/twVVUAaeLNGWFJSEhYtWpRtWsYYhgwZIpji/9tvvxW0yeaUBymZqFWdlDhZT/rZNbDlxHB+29w0+EVERODnn39G3759Be8nJCRg5cqVaNeunWCdhpzY2toKehesWrUq2wYL/e+cm9+9X79+WLhwocXpCSkMeWlYP3PmDIYOHcrfQPTv3x8//PCDII2Liws/wgMAfvrpJ7PzV+unkGrSpInR9B16hhc05spsSZqsevbsyV9gnTx5ElFRUfjss88s2peQgjJv3jxotVrBDaklhg8fzj8PCwvDli1bTKbLbd3IbrpU/bpE9evXFyzubngtcPToUaN1xh49eiSY2kN/vnzx4gUAXZDccG72SZMmYdasWYI1Du/fv4+ePXti165dgpE6hsc+cOCAUZmvX7/OrxdheJ7WH5u8O0QiEXbt2gV3d3cAwNq1a3Hz5k2L9o2MjOQ7V9SrVw/r1q0zmW7JkiVITU3FmDFjclU2w/qcnp7ON0CbkpmZyU8ZnBP951wmkxldJ+vNmTPHou8GwzozcOBAi44PGN8r6KfJs9TRo0cxceJEHDlyBJUrVzab7tGjR+jVq1eugyyk+Pn5+fEN3RqNRjDFqSX0o5kM19XJLcMplAqiU4Xh+SgvnTjs7Ozw66+/8q+3bduWpynclEolxo4dm+u1U3KS398PKPi/OSk8TZs25adU1P+vzJ0HqlWrJujArFQqzd7jGTK8djS3Xu3Lly8F18tr1qxB1apVTaZNS0vj64zheejBgwd4/vy5IG1SUhKuXr3Kv856nQoIP6M5Bb4Mr1NfvnyJ8ePHm/yMJyUl8c+zrm2ml/UeOjf376tXr4aHh4fJaWnlcnm27VdTp04VBPjbtWtnsmO6Pq/sXpPCt3PnTovTFlbHp6IOSH/wwQf88/nz5xutxWto2bJlcHd352ckAYBGjRoJ2qxOnjyJ/fv356tMpOhRoIyUOFmnrcnPwr2GC51aOu1GREQEunXrBj8/Pzg7Owu2TZs2DUlJSYKRLpYynAYqKSkp27mY9b+zvjejpb755ptcN4wSUpD0C6BaIiMjA3PnzkW3bt34nuzffPMNdu7caXJ05KxZs/D+++8D0PVC++6774zSREZGYsGCBXB0dMSGDRsE80TrKRQKfkodQFfnTTF839LpUjmOE0wl1adPH1qcmBSpCxcu4N9//4Wrq2uu1+fLusbJzJkzBYElPcO6Ya7+GNq0aZPJKenOnj2LjRs3wtbWFtu2bRPUe8OyPH78GH369MGFCxdw9uxZfPbZZ+jcubMg/bZt27Bs2TL8/PPPAHQNghs3buTTaLVa/Pzzz/Dw8IC3tzc8PDxQr149HDlyBIsWLRL8rQyPfebMGQwfPhzXrl3DsWPHMGTIEAwbNowfJRobG4sjR47g+++/p2mP31Hly5fHsWPH4OXlxU+NFhYWlu0+UVFR6NSpE5KTk9GwYUOjtb/0njx5gt9++w0Acn3tWbFiRcHokcWLF2fbKL548eIcp1yNjo7m03zzzTeoWLGiyXRXr17FuHHjzDZMArrghb6DV5s2bXIVKMsafM/NvcLOnTvRp08fpKamolevXvD19TV6VKtWDWXKlEGtWrVw8uTJAl0HhxQNBwcHwYiVbdu2Wbzvo0ePsGfPHnz66adm01jSYcSwIdnwujM4OFjwHWFpY3lOnTiOHj3KP9c3Kmu1Wrx8+ZJ/f9SoUejZsyf/OwwbNixXgWbGGEaPHo1Ro0YZjXA1/JtY0liZ9fshp9/PcJpac51UzP3NAwICzAYNSPExrKNdunTJdgpcw7T16tVD7dq1c8zf8Bo1Pj7eqNODVqvFxx9/zH82Ro4caXZUGwDs37+fDzK5u7vza4qqVCp0794d+/fvx82bNzF37lzUrl1bcF984MABHDhwQJC/4Wc0KCgo2/rfokULfPXVV/zrTZs24cMPP0RwcDAA3ffQ5s2bMXbsWMExjx49im3btgnqpGEbGWB5O9nOnTsxefJkk+frhIQExMbGZtt+ValSJcHvn91osqzn9dxObU3y7+rVqxatYQu8+R6uVauWYP1eIH/nhqIOSH/66ad8BxmNRoOBAwdi8uTJCA8P59PExMTgm2++wdSpU01+hufOnSuYIWL06NFG5S4IhufuwujQZfi3ym2HtFKPvYUUCgXbs2cPGzduHPPz82Nubm5MJpMxJycnVrlyZdarVy82f/589uTJk+IuKnktMTGR3b17l23cuJF5enoyAPzDy8uLrV27lt27d4/FxcVZnGdGRgarUKECn49MJmMrV65k/v7+7OHDhywoKIgFBQWxBw8esBs3brD9+/ezb775hjk6OjIAbMOGDYwxxjQaDbt69SobN24cn5ebmxv766+/2IMHD5hKpcq2HMHBwezAgQOsdu3agt8LABsyZAg7ceIES0xMZElJSezevXts06ZN/N/Azs6OLV68mN28eZNFRkZa9HsrlUrWoUMHBoCFhIRY/PciJL+0Wi379NNPBZ/xMWPGsL///pudP3+eBQQEsCtXrrBdu3axzz//nHl4ePDpunfvzq5du5bjMZKTk1m3bt34/fr27cuOHj3K7t69y/766y9WsWJFVrVqVfbw4UOjfRUKBbt16xb7/PPPBWXs2LEju3DhAouOjmaMMZaQkMAuXrzI3nvvPUG6L774gt28eZOlpaVlW0a1Ws2qV6/OALDTp0/n7Y9JSC6FhYWx1atXMzc3N/4zO3HiRHblyhWWmJiY7b7Jycns8uXLbPTo0UbnqZo1a7J//vmHPX78mEVFRbHTp0+zWrVq8ds5jmPz589nt2/fZkqlks9z9uzZfJpq1aoxV1dXtnDhQnb58mV248YN9tNPPzFbW1vm6urKLly4YLJcgwcPNioPANa+fXsWERHBRo0aJXi/RYsWRvVz+/btzMbGxmQ+YrGY/frrr0bH1Wg0rFWrVib3GThwIEtKSuLPs/pHnz59mFqtzv0/jrw1wsLC+M+Nh4cH27JlC1MoFII0GRkZbP369axMmTIMABs0aBBLTU01yis6Oppt3ryZ+fj48J+xQYMGsXPnzrGYmJhsy5GRkcGuX7/OZs6cafT5LVeuHFu1ahW7d+8en3716tWCNIMGDRJs17t16xZf94cOHco0Go1RmqCgIEFefn5+7OjRo0ZpIyMjWd++fRkAVrdu3Rx/J8YYi42NZf7+/mz58uXMzs5OcJx69eqxvXv3svv377OMjAyzeaxZs4aJRCKTddvco0GDBjmWjZRMUVFR/LWmlZUVu3TpUo77PHv2jFWtWpU1b95ccE7LyvAcN2LECJNptm3bJrjWTE5OZs+ePWMdOnRgKSkpfDrDe8Tz58+bPeb06dP5dFKplP3888/s1q1b7N9//2UtW7ZkzZo147f7+Piwy5cvsz59+rCzZ88K8klJSRGc49q1a2dRHVQoFGz48OEmz5uMMfbjjz/yeU6YMMFkmiNHjgiOa2jNmjWCa4spU6awGzdusD179rDu3bszPz8/JhaLGQDm4ODAzp8/z8aMGcM2btzI57FgwQI+j48//phlZmayO3fusM6dO5v8ziLF69mzZ/z/a8uWLdmmjY6O5v//8+fPzzZtamoqu3btGvvwww8F3+eDBw9m165d48+78+bN47d5enqyu3fvsqdPnwoeT548Ybdv32arV69mzs7ObPjw4fxxDD+zhg8fHx925coV9s8//wjed3d3Zw8ePGBxcXHs9OnTrEePHoLtXbp0YSdOnDBbH9VqNRs7dqxgH47jmJeXF7O3t2e1atViGzduFGx/77332Pbt2wWf/4MHDwrS1K1bl504cYIFBATwbWRBQUEsICCAXbx4kW3atIn17NmTAWC2trYsPT2dMaZrd3rw4AE7dOgQa968OZ/f+PHj2YULF9izZ8+MfocHDx4wjuNYo0aNjLalp6ezwMBA9t9//7GaNWsKyujq6srWrFnDbt++zWJjY7P9/5P8GzRoEAPAnJ2d2c2bN7NNe+rUKf6zeOzYMcE2hULBrKys+P+juf+d4fnr3Llz/PtarZZ5eXnx26pXr8727dvH30t6eXmxRo0a8ds/++wztn//ftaqVSs+j5iYGH67vb09//k1Z+/evYzjOJP1zLCteurUqWbzSEpKYu3atePTVqhQIce/I2OMhYSECI5rrj03Li5OUMavvvoqx7xza8KECYLfPz4+vsCPUVK9VYEyuVzOFi9ezMqWLctEIhETiUSM4ziTD/329u3bs4sXLxZ30d95f/zxh0U3q3Pnzs0xr/3797OlS5eyxo0b5+pG2PAhlUr5hsXY2Nhs0wYGBmZbnq5du+Z4vM2bN7MNGzZkm8bwoiwniYmJrGbNmhQoI0Xi9OnTbMSIEaxevXo5ftZtbW1ZhQoVWIMGDdjgwYPZmjVr2NOnT3N9zD179rA+ffqwcuXKMalUypydndn777/Pli9fbvbiJ2sDXtbHrFmzGGPGjYZZHydPnsyxfF9//TWrVatWrn8vQvIq68224WPKlCnZ7mvYmGfu0bFjR/btt99mm8awLhs2Im7YsIH99ddfrEmTJszW1pbZ2tqyOnXqsBkzZmTbAUahULBp06YxLy8vZmVlxRo0aMBWr17NtFotY4yx+/fvs2rVqjE3Nzc2efJksw3kISEh7PPPP2fe3t5MJpMxDw8PNmTIEHb79m2zx05KSmJjxoxhbm5uzMbGhrVo0YLt2LGD33727Fnm5eXFvLy82Lx58yhIRng7duxgzZs3ZxzHMWdnZ9auXTvWr18/1qZNG2ZnZ8ekUinr2rWr2QAxY8Kb06yP//3vf9ke/+rVqznW56pVq/LpV69ezd5//322evVqNnbsWFalShUG6ALcXbt2ZX379mV16tRhwJtAmzlBQUGsUqVKbMWKFWzatGnMz8+PiUQi5uHhwdq2bcs+/PBD1qJFCyaVSpmNjQ2bPHlyjg0WeobfKdk9zN3X3bx5M0/3BAsWLLCofKRkunv3LitXrhwDdB0QlyxZYjI4/ezZMzZz5kxmZ2fH2rRpY7ZBKCwsjB06dEjQWCaTydiaNWvY3bt3BWnj4+OZi4sLn07fBrFr1y4ml8vZ1atX2TfffCP4vFWrVo3t3LmTPX/+3OjYL1++FHSG0T8kEgmbN28ek8vlggZJAGzRokUmf4/09HQ2cuRIPl2ZMmXY4sWLTTbQZ2Zm8sE4fUdSQ0+fPmVbt24VdIBzcnJiGzdu5IPu4eHh7MyZM4LGUJFIxH7//Xf+XjotLY1VrVrVZD2cNGkSk8vl/PeT/jFx4kRBWR49esSkUqngb25jY2NRkJQUjxYtWjBbW9scOyIyxvjOkqbqh6GsgaCsj4MHD7Lo6GgmkUhyfU7I2ibz999/M19fXyaVSpmPjw+bNm0aHwhPT09n7dq1Y/b29qxv374sNDSUMcbYkiVLsj1GTm1eR48eZR988AFzdXVl1tbWrF69emzhwoVMLpezs2fPMnt7e/bZZ58J2qkiIiLYtm3b2KxZs4w6m+TmMWDAAD7PrI36WR/ly5c3Wf4+ffqw7du3G71/8uRJi8qgv2cnhUcfKAN0baPfffedUcd9rVbLtm/fzpycnJhIJGIrVqzgt6Wnp7NLly6xESNGGF3DXrhwgcXGxjK5XM7u3r3LfvvtN0HQp1mzZuzcuXP8PWJRB6QZY+zff/8129ESABs1alSO935KpZL98MMP/HlZKpWyCRMmmBywo1Kp2OHDh1n79u35Y7Ru3VrQ2VWhULCHDx+ygwcPsiZNmgjKY2tryxYtWsRu3rzJXr58acm/2KTIyEh2/fp1NnfuXKPvx/fff58dPXqUPXz4MMfBIqXdWxMou3jxIqtQoQIfCPPx8WEdOnRgo0aNYl9++SWbMWMGmzVrFvviiy/Y8OHDWatWrZirqyt/wfrpp59adHImhBBCsqNSqViFChXYH3/8UdxFIaTYZA2UEfKuiYqKYnv27GErV65k8+fPZ2vWrGGHDh1iSUlJxV00gZs3b7LHjx8L3gsODmbbt29nS5cuZfPmzWMrV65kFy9ezHaEDWO6zmXHjx8XvBcfH88OHjzIVq5cyebNm8eWLFnCDh06JBhRQ0hhio2NZZMmTeJnDbGxsWGtWrViffv2ZR06dGDVqlVjHMcxb29vtmzZsmwbgAwbD009su577do11qxZM2Zra8uaN2/O1487d+5km0/Hjh1NHv/hw4ese/fuzNbWljk5ObHevXszf39/fvvixYuZg4MDq1OnDtu9e3eOf5tLly6xXr168Q1iYrGY1a1bl/Xq1Yv16dOH+fn5sQoVKrCxY8fyjfxZtW3b1uzvYWVlxRjTNYybS+Pk5MTn9fLlSzZw4EDm6OjI7O3tWceOHdmpU6f47du2bWOurq6scuXKbM2aNSbLc+jQIVanTh1mZ2fHOnToYFEvflJ8/vjjDzZ48GCL0m7evJk1a9askEtECBk0aBAbPXo0W7ZsGRswYABzc3NjEomENWjQgPXq1Yv16NGDlS9fngFgjRs3ZmfOnBHsf/bs2WzPcQsWLMjxPLhkyRI+v+IISL948YJ98cUXrFq1aszKyoo5Ozuzzp07s7179+bqb/ny5Uv27bffMm9vb/7YNWrUYD179mT9+vVjrVu3Zg4ODgzQzVz26aefssuXLxvlExgYaFEguU+fPrkqn6Hhw4dbdIzw8PA8H6M04Bgr/aucrlmzBl999RW6d++OYcOGoV27dnBzc7No3wcPHuDQoUP4+++/YWVlhVOnTvELchNCCCG5tXv3bowYMQIRERFwdHQs7uIQUizmzJmDH3/8EQCwYcMGjBgxongLRAgh5J2mUqng7++PoKAgxMXFQS6Xw9bWFp6enqhfv77RuirvktTUVFy9ehVPnz5FUlISRCIR3NzcULt2bTRt2hRWVlbFXUTylpLL5cjMzOTXBcqOUqlEYmIiPDw8iqBkhLy7du/ejV69evFrMmu1WgQEBODevXuIi4uDUqmEu7s7WrRogTp16hRzaUuPkJAQBAQEICwsDKmpqeA4Dg4ODvDw8EDdunVRo0YNiMXi4i7mO6/UB8o2b96MhQsXYvPmzWjcuHGe89FoNFi/fj3WrVuHc+fOwd7evkDKp1KpsGXLFvzyyy84duwYfHx8CiRfQgghJVPLli3h5+eHFStWFHdRCCk2FCgjhBBCCCGEEEJIaSEp7gLkx8OHD7F582Zcv34934EtsViMcePGoUGDBpg2bRpWrVqV7/Ldv38fW7duxapVq5CcnJzv/AghhJRsW7duxZ07d7Bt27biLgohxUqj0fDPtVptMZaEEEIIIYQQQgghJHui4i5AfqxYsQL//fdfgY3+AoAWLVqgffv2uHz5cr7zqlu3Ln7++WcMHz68AEpGCCGkJJk6dSrs7OxQqVIlfPrpp/jiiy8wcuRI/PTTTzR6mLzzoqOj+eexsbHFWBJCCCGEEEIIIYSQ7BX71Ivh4eG4ceMGKlasiGbNmuVq35SUlEJb/6Ug8/7hhx8wd+5chISEUOMpIYS8JVxdXZGYmCh478svv8TSpUuLp0CEFDO5XI7Hjx/j6tWrmDx5MuRyOQDAy8sLS5Ysga+vLxo0aFDMpSSEEEIIIYQQQggRKpKpF3/66Sf+uVgsxqxZswDo1qwYP348lEolAKBfv37YuXMnRCLLBrrlFMhKT0/HiRMnEBkZiQkTJgAArl27Brlcjnbt2uUr79yw9PchhBBSeqxbtw7Tpk1DREQE/Pz8MGPGDPTs2bO4i0VIsbl//z6aNm1q9P6rV68wePBgAEApXxqXEEIIIYQQQgghb6EiGVEmEolga2uLWbNmYfTo0ShbtiwCAwPRuHFjaDQa+Pn5oW3btti9eze++eYbjB8/Pt/H3LNnD8aOHYvExES4ubkhJiYGgC54NmfOHFy6dAnbt2+Ht7d3vo+VE/2C9paMKFMoFFAoFCa3abVaJCQkwM3NDRzHFUJJCSldGGNITU1FuXLlijwgTXWVEMtRXSWkdCjOumooa72lukqIEJ1XCSkdqK4SUjpQXSWkdCj0usqKAMdxbNeuXYL3evbsyTiOY23btmVqtZoxxlhISAhr3Lhxvo934cIFJpFIGMdxjOM4VrZsWaM0Y8eOZeXLl2eRkZH5Pl5OZs+ezQCwkJAQi9PSgx70sPwRHh5e6PWY6io96JH/B9VVetCjdDyKo65SvaUHPXL/oPMqPehROh5UV+lBj9LxoLpKD3qUjkdh1dUiGVHm6OiIlJQU/vX9+/dRv359iMViBAYGwtfXl99WtWpVPH/+PF/H69y5M27evInp06ejYcOGmDRpEp4+fSpIc+fOHfj5+WH06NFYu3Ztvo6Xk4IaUZacnIxKlSohJCQEDg4OhVBSQkqX1NRUVK5cGUlJSXBycirSY1NdJcRyVFcJKR2Ks64aylpv9XU1PDy80NYnJqQ0SUlJQcWKFem8SkgJR9fAhJQOVFcJKR0Ku64WyRplFSpUELz+6aefwHEcBg0aJAiSpaenIywsLN/Hu3HjBvbs2YOOHTsCAKRSqVEaDw8PAMDBgwfzfbyCZGVlBSsrq2zTuLq6UiMBIXhTt4tjCDrVVUIsR3WVkNKhOOuqIXP11tHRkeoqIQbovEpIyUbXwISUDlRXCSkdCruuFsnEq1WrVsW+ffsAAJs3b8Z///0HqVSKOXPmCNItXrwYWq0238crW7YsHyQz5+HDhwCApKSkfB+PEEIIIYQQQgghhBBCCCGElD5FMqLsl19+wfvvv48xY8YgISEBgG46wmrVqgHQTR3x22+/Yd68eQVyPHd3d6SlpcHe3t5sml9//RUAULly5QI5JiGEEEIIIYQQQgghhBBCCCldiiRQVrt2bdy7dw8bNmxATEwMOnXqhN69e/Pb582bh8zMTIwfP75Ajjds2DB8/vnn2LhxI8RisWCbSqXCxIkTcerUKXAch2HDhhXIMbOjHyVXBMvBEUIIIYQQQgghhBBCCCGEEAsVSaAMAMqXL4/vvvvO5Db96C4AuHTpUr6PNW7cOPz333+oX78++vXrh+TkZKxZswaPHz/Gf//9h8jISABA06ZNMWXKlHwfLyf64718+ZJGsBFCCCGEEEIIIaTEUqq1uPwsDteC45GcqYKTjRQtqrihdbUykEmKZAUPQgghhJAiVSSBsvHjx2PVqlUWpf3www8RExOTr+OJxWIcOXIEU6ZMwaJFi6BSqTBhwgR+RJdIJMJHH32ElStX5rhgYn74+/tj7NixuHPnDgCgZ8+e6NSpE3bv3l1oxySEEEIIIYQQQgjJi+vB8fjl2CNEJGZCwxg4cGBg2HcnAuVdbPBtN180r+JW3MUkhBBCCClQRRIo27RpE5YvXw6JJPvD/fXXX4iPjy+QY1pbW2PlypX48ccfce7cOYSGhkKtVqN8+fJo164dKlasWCDHyY6fnx/8/f0L/TiEEEIIIYQQQggh+XE9OB4z9gQiVa6Gq51MMHpMqdYiPCETM/YEYsGH9ShYRgghhJC3SpEEyjIzM7Fr1y4MGTLEbJqdO3cW2Bplly5dwrp16/DFF1/Az88P/fv3L5B8CSGEEEIIIYQQQt42SrUWvxx7hFS5Gh6OVuA4TrBdJhHBw9EK0SkK/HLsEbaPbUnTMBJCCCHkrVFkVzVfffUVIiIiTG779ddfMXToUKhUqgI51qBBg7BlyxYsXry4QPIjhBBCCCGEEEIIeVtdfhaHiMRMuNrJXgfJGNRaLb+EBQBwHAdXOxkiEjNx+Vlc8RWWEEIIIaSAFUmgjOM4tG/fHj169EBqair/vlqtxqhRozBjxgxotVp06tQJIlH+i2RjYwMAGDduXI5p09PT8308QgghhBBCCCGEkNLqWnA8NIxBJhEhQ6lGeGImQuMyEBKXjqhkOVLkKmi0WsgkImgYw7Xgglk2gxBCCCGkJCiSQNmaNWuwfft2jBgxAv369YNarUZ8fDw6deqETZs2wdraGjt37sSJEyewevXqfB9v5cqVKFu2LJo3b55j2qpVq+b7eIQQQgghhBBCCCGlVXKmChotQ0RSJiKT5FCotAAALQPSFGrEpCgQEpeB8IQMyFUahCVkQKtlOeRKCCGEkBJFrQSenABOfA8c+EL388kJ3fvvuCJZo2zMmDEAdNMvvnjxAgMHDkRgYCCeP3+OcuXKYf/+/fDz8wMAdOrUKd/H69q1Kw4cOICJEyfim2++ga+vr1EauVyOv//+G7Gxsfk+HiGEEEIIIYQQQkhpFJ6QgaBXKUiRqyET6/pTO9lI4WInhVrDkK5UI0OhgUKthUKthVKjxc3QBHz893X4VXKBn48rGldyhoO1tJh/E0IIIYSYFXoZODUHSA4DtNo37wfuBJwqAZ3mAD6ti6t0xa5IAmWGfv/9d3z44Yd4/vw5mjZtin379sHLy4vf/t577yE8PDxfx3BwcEBGRgYAYOPGjfnKixBCCCGEEEIIIeRtE5Mqx7br4TjzKBpJmSpwAGxlYpR1sIL0dcBMIgKspWK42QFqrRYpmSokZqjgaidDSqYaZx/H4uzjWIg4oKanA5p4u6KJjwsql7F7vdYZIYQQQopd6GXg4BeAIhWwdQPEsjfbNEog6YVue6/l72ywrEADZRcuXLAo3dixY5GYmIgZM2bg6dOnePr0KdRqNa5cuYLIyMh8l2PYsGH4888/LUpLF26EEEIIIYQQQgh5VyRnqLDLPxyHA19BrdFNn9jR1x3XQxIQk6KARGS6nUTMcVCqGXw9HbDl0+YIjkvHrdAE3HqRiBfxGQh6lYqgV6nYfO0FXOxkaOLtgibeLmhYyRm2siLvp00IIYQQQDet4qk5uiCZvSeQNR4iluneT4vSpRtxGJDITOX0VivQK5X+/fsjPt7yBV0vXrxYkIfnTZo0CRs3bsSePXtQvXp1SKXGw/+1Wi0uXLiAUaNGFUoZCCGEEEIIIYQQQkqKDKUa++5EYt+dCGSqNACAehWc8ElLb/h6OuJ6cDxm7AlEdIoCrnYyyCRvlrVXqrVISFfCwVqCb7v5wtZKgrrlnVC3vBNGtK6MmFQ5br9IxM3QRNwLT0JiuhInH0bj5MNoiEQc6pRzfB04c0VFVxuLOy0r1VpcfhaHa8HxSM5UwclGihZV3NC6WhlB+QghhBBiRvA53XSLtm7GQTI9jgNs3IDkcF36Gl2KsoQlQoEGyj766CMsW7YM9vb2cHJygkRiefZKpRJRUVEFUo7atWujX79+6N69e7bpKleujO+++65AjkkIIYQQQgghhBBS0ijVWhy9/wo7b4UjJVMNAKjmbo9PWnqjYUVnPmjVvIobFnxYD78ce4SIxExoGAMHDgwMYo5DRVcbfNvNF82ruBkdw93BGt3qeqFbXS8o1Vo8iEyG/4tE3AxNQGSSHIEvkxH4MhkbLofCw9EKfq+naKxX3gnWUrHJcl8PjjdZln13IlDexXxZCCGEEGIg9KJuTTKxDADTjTBTZwKqTOE0jBIZoFXr0lOgLH8+/fRTvHjxAnv27MnT/g8ePEDDhg0LpCybNm2yKF1+10MjhBBCCCGEEEIIKWk0WobTQdHYdiMMcWlKAEB5Zxt83NIbraq6mRzV1byKG7aPbflmFJdcBSfr3I3ikklEaFTJBY0quWD0e1UQmZQJ/xeJ8H+RiICXSYhOUeBI4CscCXwFqZhD/QrO8PN2QRMfF3g52QAAP7otVa42ObotPCETM/YEYsGH9ShYRgghhJiTHg/EPgJUGbrRYio5AO2b7VJb4Xpl4AB5clGXskQo0EBZ3bp10bdvX5PbQkJCULly5Wz3r1OnDtq1a1cgZZFKpVAqldiwYQP279+P0NBQODs7o0GDBvj444/RqlWrAjkOIYQQQgghhBBCSEnBGMOV5/HYfPUFIpIyAQBu9jIMbVYJHWt5QGxmDTI9mUSE9r7uaO/rXiDlKedsg3LONujVoBzkKg0CXibj1osE+IcmIiZVwQfR1l4Ayjlbo3ElF+y5/RKpchU8HK2NAnoyiQgejlaITlHgl2OPsH1sS5qGkRBCCFErgbgnQEwQEPMAiH4IpEUDKZG6ABnTTbsMTgxIrAGpDSC1zpIJA6ydirzoJUGBr6b6ySefGL03dOhQ7NixA9OmTcOCBQuy3f/kyZMFUo7nz5+jd+/eePToEQDdhSIAXLt2DWvXrkXfvn2xdu1auLlRzyNCCCGEEEIIIYSUbowx3A1PwuarL/A0Jg0A4GAtwcAmFfFBPa8SEUyylorRrLIrmlV2BWMM4QmZuPUiAbdeJOJBZAoik+R4FBWGiMRMSMQcWIoctjIJ7GRiSMRvys9xHFztZIhIzMTlZ3EFFtQjhBBCCpxaqVv3K/SibrSWtRPg8x5QpZ1uusO8YAxIjQJiHuoe0Q+B+KeARiVMx4mAMtWAVwGAjQtg5ZBlBFmWcookurK9gwo8UGbK4cOHAcDixVrzKyUlBR07dkRYWBjEYjGaN2+OunXrwsXFBWq1Gi9evMCZM2fQq1cvnDt3DjJZHj+QhBBCCCGEEEIIKV0Ko8GqmD2OSsWmq6EIfKmbLslGKkbfRuXRt1E52MqKpOkn1ziOQyU3W1Rys8WHjSsgQ6nG3bAk/H7yCSKTMsGBQ7pCg3SFBrHQjSRzs5PBzkr3+8gkImgYw7XgeAqUEUIIKZlCLwOn5gDJYbp1wvQCdwJOlYBOcwCf1jnno8oEYh+/Doo90P3MSDBOZ+MMuNcB3GsBHnWAsr664NfGHkDSC0AkNZ0/Y0BmPODsrbseegcVydVSnz59cPDgQcyaNSvHtPPmzcN3332Xr+P98ssvCA8Px/jx4/Hdd9/B09PTKE16ejoGDx6MP//8E5MmTcrX8QghhBBCCCGEEFIKFFSDVUHKR+AuLD4Dm6+F4lqwrrFMIubQo54XBvhVhJOtmcawEspWJkGramVw4F4kXsSnw8VOhnSFBhlKNeQqLZRqLbL2v+bAIVmuMp0hIYQQUpxCLwMHvwAUqYCtm3Akl0apC1wd/ALotVx47cEYkPzyTVAs+gGQEAwwrTB/kRhwq/46KFYX8KgNOHjB6GQJ6K5vDn4BpEUZl0Wt1AXJrBx06Uppp6H8KpJA2Z9//on09HQcOXIEAwYMMJsuISEB8+fPz3egbO/evVi0aBG+/vprs2ns7OywceNG9OjRgwJlhBBCCCGEEELI2y6vDVaFXaY8BO6iU+TYej0M5x7HQMsAEQd08PXAkGYV4e6Ydb2R0sXJRgoGwEoihp1YiwbSB6irDICVJhUKlQPuoz7uSRtCzUnBwOBkXboCgoQQQt4BaqXu/K5IBew9jYNXYpnu/bQo4OT3QJf5QNxj3RSKMQ91+2VlVwZwr/0mKFamBiCxsqw8Pq111zen5gDJ4YBWDYADwHQjzpy9i6ezUAlSJIGyRYsWoUGDBpg3bx7+++8/1KlTxyhNRkYGDh48CKVSme/jxcfH48svv8wxnZubG1JSUvJ9PEIIKbXewmlnCCGEEEIIMZKbBqtTc4ARhwv/ejgPgbukDCV23grHkcAoaLS6tdhbVXXDsBbeqOhqW7jlLSItqrhh350I1JAHYLRiE9w1MRBBCwYOnIahveIcYsTuWG81HDFcDbSoQmvPE0IIKWGCz+k6wdi6GV9zaBSASq6bTlGVqVs/bN94wNrxTRqxTBcI86ijC4q51wHsy+avTD6tddc31A5oUpEEyg4cOIA7d+4AAAIDA/Hff/+ZTMcYK5B1zLy8vCAWi3NMFxoaiqioqHwfjxBCSqWSOO0MIYQQQgghhSG7Bis9jgNs3HQ9rYPPATW6FF55DAJ3WntPpCk0SE+TQ8MYxBwHOysJ7O09IXoduEsfuh97A2Kx/24E5CrdtXuDik74pKUPang4FF45i0HramXQ2e4ZRif9AUcuE8mcI9Tcm1FjEqaChyYak9L/gI3zl2hdrUMxlpYQQggxIfSirq1N3wlGmQZkJgHqTOMpFJmu4wuqdXoTFHOrCogLYcS0RKa7vinMa5xSqkgCZRMnTsSoUaPQtGlTVK9eHVKp8T9Zq9Xizp07ePDgQb6P5+3tjXPnzqFdu3Zm08TGxmLw4MEmR7cRQshbryROO0MIIYQQQkhhydpgBQBpMboGK04EgNMFyjiR7hr50hIg/qkuvcQKEFvpGpcEP60MtptIJ5YBIpHp8rwO3KVLnPAqLh0qDQNjDPppkJIyVZCKOXjaOUEcF4oV69fjEtcYAFDd3R6ftPJBw4rOhfs3KyYyqPGtdAeUyEQUc4FEJIJhaFPFSRGldYEHEvGtdAdkGAXg3e4FTwghpISRJ+t+qjLA0uOgVWZAw6ALinEiQGoNqZUtOKkNkJkMVH4P6Ph9sRb5XVckgbKhQ4fi999/x/Xr17NNl5aWBnd393wfb9KkSRg4cCAWLFiA//3vf3B2dgagG7F2//597N69GytXrkRCQgL++eeffB+PEEJKlZI47QwhhBBCCCGFSd9gpafKBOSJptNqVEDsI0CVkf/jiqWmg2zR96HJSIJCmwlnxoHjODCRCCpIIedsoIIICrUWoUlalOOUqIa7eFGxNYY190bLqm4FMhtPiRV8Dg7ySKQ7l4UsTcsHEaXQQA0xwHGQSUSwti8LO/mrwh/9RwghhOSWVgMoUqCRp0ClYdACSIE90mALFZMCSg5SDQdPJ2vYc6+nQCTFqkgCZTKZDD/++GO2aV68eAFvb28sWrQo38fr1KkTxowZgzFjxmDcuHFwcnKCTCZDUlISvwYaYwwfffQRPvroo3wfjxBCShVT084w7euetK8V5bQzhBBCCCGEFLasDVD6wJnMHrByBMB0vbyZFshIALwaADW66dYRUStf/1ToZl8Q/DTc/vqnVvPmOBqV7pFlOXaWGgWmUcEGTDdair1+AAASoYAEGcwa6cwaWo6hqacIfYc0hlj0FgfI9F6P/rOzs0YVUQaUmWmAMh0irQrJVuVgZWMLe2sJRACQkqhLT/crhBBCSoKEEODW38CLK9Bq1FAxEZJhjzSRE7ScbqkoCXSnfKWaITohBTJrEWQ+7xVrsUkRBcoAoF+/ftluj46Oxtdff42tW7cWyPHmz5+PevXqYdq0aXj58qVgm4ODA2bOnIlp06YVyLEIIaRUMTXtTNKL1yPJPADR61ODRAZo1XTjSQghhBBCSj+f93Rr8WqUgEgMKFJ079u6ARLrN+nUSsBKCbQYn/drYK3GfBDtdZAt5uQy2ISfR5rIARwADlpwTAsZU8CKKSGDCjKo4CxKgwRqSFMeQ/z0GFCxOWDrmu8/R4mk1QJxj4GXN3X/H2UaRGCwBgARAJEYZW0AWBs2ZXHGowUJIYSQopbyCvDfCDw9ATAttFYOSOCcIWJKpIhcjGZz4gBIRYCjNgXBKi9U8X6fJhEuZkUWKNNoNAgKCkJSUhK0WuGCdVqtFnFxcTh9+jTGjRuHjRs3FsgxBw8ejEGDBuH8+fN48OAB0tPTUa1aNXTu3BkODm/XYreEEGKxrDeSihRdg4FWIxxVBoBuPAkhhBBCyFuhSjvAqZKug5jEGgB7PRWiQZCMMSAzHnD21qXPK5EYkNkCsDWb5LzNA7TDVWQyGZSQQqNlb3aHFg4iBWwhhy3TTf+oSU8Azi3UJShbE6jUAqjYAijra34dtNIgLUYXGHt5E3h5Szc9fEokoFEDEqmuM5/UTvf3lNqauF9hNF0VIYSQ4pORANz+Bwg6qOtsDgCV38N1177YePQyvhP9CTeWgGQ4QgEJRBwHDoCEqeDEUpAussMSNgSDQ1LQ3tc620ORwlUkgbKwsDB06tQJz58/zzYdYwz79u0r0GNzHId27dqhXbt2BZovIYSUWllvJDPidT9tXOnGkxBCCCGEvJ0kMqDTHODgF0DySwAMsDG4zlUrdUEyKwddukJaozchXYkbIfHY8MobVbVlUJGLRQxcoOtbDohFHCQiCeSQQM5swQGIZU546NYP/cq80q2dFvtY9/DfpLtWr9hcFzir0BSwdiyUchcYlRx4de91YOwGkPhCuF1mr/tdQi4A9mV1QTJz1ErdbBg0XRUhhJCiJk8BAnYAgf8BarnuvfJ+QLOxgLsvzh0Jgj9XGyvtvsDH6RtQRhMNe6YFwEHEMTBOjGixBzbZjoR/RlX4BMejva97sf5K77oiCZTNmTMHz549g0wmg7u7O+Li4uDh4SFI8+rVK/j6+uLTTz8tkGMqFAocO3YMzZo1g5eXF//+unXr4OjoiP79+0MsFhfIsQghpFQxnHZGLdf95MSAjbMwHd14EkIIIYSQt4lPa+C9KcDhKbp1wxTpgDITANNd9zp764JkPq0L7JCMMYQnZOJacDyuhcTjaXQaACA2k2GRZggWSNfBE4lI5pygFUn5/fQ9zTM4WywWjUKVCl2AD2rpeq6HXwfCrumCTfJk3TRPT0/oOr151Hkz2sytqtFUT0WOMSD++ZtRY1EBur+9HicC3GsBFZoAFZrpnms1wMYer0f/2Zr+HQpq9B8hhBCSG6pMXXDs3nZAqTunw7020Gy0LlD2WnKmChw4+KMWjqm/R3NtIJqLHsCeZSCV2eIGq4ObrD7s1bYA1EiWq0wfjxSZIgmUnTp1CrNnz8bMmTMhlUoxZswY/PDDD6hYsSKfZtq0aahVqxZGjhyZ7+Olp6ejbdu2uHPnDnr37o29e/fy2z799FMsWbIE9evXx44dO1C3bt18Hy8769evx9q1a2FtbQ17e3ssXboUNWrUKNRjElKaqVQqXL9+Hf7+/khNTYWDgwP8/PzQvHlzSKXSnDMgOTOcdkaVqXvPxkU4miyXN570fyOEkJKJvp8JISSL5AjArRpQpjrgWF4XaLJ20nUOq9KuQEaSabQMQa9ScC04HtdDEhCVLBdsr+HhgCY+Ljh4F1hhPQmjFZvhromGSKsFg25smRYiRIs9sd7qEwQoa2BoFTfdzrauQM3uuodGDUTf1wXNwq4CiaFAVKDucWMdYFcWqNRcFzQr7/d6OkgLqJVA8DndWsV5+ftkJOimUdQHxzIThdvtPYCKTXUj4Mo1Nh4FJxK/Gf2XFqVbR85wfeUiGv1nCp1XCSkdqK6SAqdWAo8OArc3vzmvuVYGmo4BvFsZdepwspFCodYgIkkNxiS4LvFDmHNrMKYLoiVnqsA0QGaqAmqtFi8TMpGQroSr3bu1UllJqqtFEijLzMzE7Nmz+deffPIJNm3ahO+++45/b+rUqahatSoaNGiAxo0b5+t4ixcvxu3btwEA3t7egm0ikQhTpkxBTEwM2rdvj7t376J8+fL5Op458+bNw59//gl/f3+4u7tjy5YtaNOmDa5du4YqVaoUyjEJKc1u376NFStW4NWrV9BoNOA4DowxHDt2DF5eXpg4cWK+vx8I3kw7s3s0oMrQ3XTauLzZnssbT/q/EUJIyUTfz4QQkoUyA3h+WtdBrNUXQLmGBZZ1plKDO2GJuBaSgFuhCUiVq/ltUjGH+hWc0aKKK5pVdoOrnQxKtRb3wpNwIaEmnjv8jIbqe6inCoQdS0c6Z4dAaT3clTRARKoWFV1t0LpaGeODiiW636FcQ6DFZ0Bq1OvRZteBCH8gPRYIOqR7iKWAZ32gUkvdiDOnCqZHaoVeBk7NAZLDAMP15QN36jrbmRpxp1YC0YG64Fj4DSD+mXC7xBoo10g3aqxiM8CpYs4j3XxaA72Wvy5L+Ot1XzgU5ui/nNB5lZDSgeoqKVBaLfD0OOC/UXeeBQDHckCTUUDVjibXCWWMQanRIkOpgVjEwcFaAg9Ha4hen/vK2FvB1U6GlEwVEjKUYBogPDEDozbexPs1yqJvw3KoUta+CH/J4lHS6irHGGM5J8ufhg0b4u7du4L3OnXqhEOHDsHa+s0idT4+PvD29sb58+fzdbzatWujdevWGDFiBFq2bAmRiQ9sWFgYfHx8MGrUKKxfvz5fxzMlMDAQjRo1wurVqzFmzBj+/Tp16sDT0xOnT5/OdZ4pKSlwcnJCcnIyHB1L+LzjhOTS7du3MX/+fKSlpcHFxUXQa0ClUiExMRH29vaYNWsW/yVZUutESS2XgFYLbOoBRN7V3TSLZRDceDpVtOjGMy//N/LuKal1oqSWi5CCQOdVQt5eJbVOlNRyCTw8AFz8DXCuCAzcnO9pCfXrjV0LTkDAyySoNG+aV+ytJGha2RUtKruiUSUX2MiMl364HhyPGXsCkSpXw9VOBpnkTduFUq1FQroSDtYSLPiwHprrR5RZSq0EXt3VjTQLuwakRAq3O5bXBcwqtQC8Guo6x4Ve1o3iUqQaj+LSKHVrG1s5AL2W6e4X9CPGIu++WZ9Fr0x13VSKFZoAHnXzPuorv6PbCgidVwkpHaiukgLDmG69zFt/vVlP09YN8BsO1Oyh66xiglqjxapzz3H8QRRC4tIh4gBvN1uIONMBtegUBZxtpahfwQlPXk/PDAB1yzuhb8NyaOrjCpGomKdRLgQlsa4WSaCsS5cu6NChA4YMGQIvLy/IZDKsW7cO9+7dw4oVKwAAN2/eRMuWLWFlZYX09PR8Ha9ChQoIDw8Hl81Fr1qt5tdMi4qKytfxTPnkk0+wefNmhIWFCaaY/PLLL7F8+XLcvn0bjRo1ylWe+g9DaGhonj4MNjY2gsCkoaSkJOT1o2BtbQ0bGxuT25KTk6E17IWWCzKZDHZ2phfuTU1NhVqtNrnNFJVGi2uhyfAPS0aaSosyDrZoUcUNrauVEdyMpKWlQaXK25ywEokEDg4OJrelp6dDqVTmKV+RSAQnJyeT2zIzMyGXy01uywnHcXB2dja5TS6XIzMzM0/5AoCLi4vJ95VKpcn6rVKpMHXqVLx69Qpubm4m6y5jDImJiShfvjz+/PNPSKXSEnvRUCrq6rNTwOm5gMwOaP4ZFM8vAfJkMGsnqMq3gLpSa+GNsQn6/1tUVBTc3d1N/t/UajXi4uLg5eWFxYsX52rYtFQqhb296R40VFd1irquWsrJyUnQSYXqau6UhvOqIaqrOiWprr6t59WSVi5CiktJrROl4ry6ZxwQ+wjqZp/hok1HnA+KRLJcBUcrCfwqOaGFjxOkYuOGLD3GGCKSFfAPS8adiDQExwvPGZ5O1mhe2RX1PKxR1c0aYgsatvzDk7H8/Au8SlZAo9XF7jiOg5jjUN7FBt928+WDZHk+rzIGaWYM7OMDdYGzV/dej9DS0YikULnVhjTsIjhFMrT2XsZBRKYBp8yAKCMWTCSG1rEiP3W7RCzWTQlZ4fV0iuX9AFtXOq9SXc0VugbWoWvgN6iuUl3VK9K6yhjEUXdgFbAZ4gTdCGkms4eydn8oq/fQjZKG6bqaplBj4dEg3HmRAABoU8UZx4LikK7QwNlWIrjGUGm0SMpQw85KjO+7VYVfRSc8j83A0aA43ApPhfb1v8fLyRq9G5ZDR18PQKOkulqIdbVIpl6cPHkyevTogVmzZqFSpUoICQnByJEj4efnh6ZNm6JSpUo4fvw4GGPw8fHJ9/FsbW2zDZIBwK1btwDoKlpB02q1OHLkCBwdHQVBMgB8cOzo0aO5DpTp9e3bF2KxcW+0nEybNg0DBw40ua1///5ISkrKU3nGjBmDcePGmd0WHBycp3wHDBiAb7/91uS2KVOm8NNr5kTl7I30ap2gtXYG4zhYyWSwd3DAvjsRRjcec+fOzdNoPwBo3Lgx1q5da3LbihUrsGvXrjzlW6VKFezcudPktn/++Qfr1q3LU77Ozs44deqUyW0HDhzAr7/+mqd8gTf1K6sLFy5g+vTp2e6bmJhodpuPjw9evXqF69evo02bNnkuX1EpsXVVqwVu/6N7s/4goHZvfDxni0FdPZOrfJ2cnMx+50ZERCAjIwOJiYn44IMPcpVvx44d8csvv5jcRnVVpzjranZOnjxp9kKpJCqxddXMtuI+r2ZFdVWnpNbVt+m8SggpHSw5rzJODJVrFahcfKCVWEOklmNwxyaYMbKfoCOjXoGcV+OeAbGPkKYCPr/sgifJAYhPTIJGo2t428wYRPIk2D07BWnSizdlBQeNgydULj5QOXtD+3o9LRcXV3h6eqK6hz1aVHZDiypuqOhqA47jMHbs2FydVw3/Hl7eVdG5bWuTHTsL5Lxaf4BuCsoIfyD8GhB2HTHPA6F6fAdetmpotIAyOREZGhHkGg5WIgYbiRZWIl2LHQcGsQgIj3sC/3hbREsrYuLCvwHXKkbBNTqvlmx0DUzXwHpUV0s2qqtFV1erOSgw0CcJvk4KAIBCw+FYhAOORDgiU7MGwBo+bda6Gp0ix08HHyIsIQPxsdHIvLodu5PD+HbpBGtnME4EvF6NlGNaiORJUD07hek731x3VKlSBev/2oxDAZE4/iAKr5Ll+PN8MLZcewH7pGDc3rcWImXuOzZTXc1ZkQTKunfvjl9//RXz58+Hl5eX7sASCbZt24aOHTvC398fgC5yvHDhwnwfr0mTJti5c6fZL4OUlBRMnDgRHMehTp06+T5eVi9fvkR8fDxq165ttE3fcBgYGGhyX4VCAYVCYXJbSkpKvsql0Wjy3KMlO1qt1my++RmwmF15Lc1X5eyN1Fq9wSRWECnTIWIa2Mgc4eloDaVai/CEDEzfHYB5fWujmY9rnns96MtkrrwajaZQ8s1PeQEUSnmzyzevvT/0JBIJNBoNbt68iebNmxfK59lSpbmucsFnIUoIBazsofHtDahU+aqr+jmETclPvtl9t1Bd1SmpdVWlUgnyprqaOyX5vGoK1dU3SltdLUnnVUNZ621+6yohpOAUxHk1a0dGvf9eyHD3zyuY2qU6mvm4Fkh5gTfnKdGD/chUqLE/tSYeMTFcbKVIjU2HUqn7fRgnhsbGBam1esP+8RGAaaFy8YHauRKYxMogQw0kKZFo6KHC3I+7w83uzSwM+u/l3J5XOaaBLP4pZPFP4VdRjamdh+s2MA1UqjfnkAI7r3JSoEIL3aMFw/5FM1Ev/V+4W2vAAEhFDE4iDZyyTAah0nLI1IhhLdbiSowdlgaVReXK5TDOsRJg4pxE51W6Bs4NugbWoWvgnPOlumoZqqs6ltTVinZKDPBORkNX3agqlZbDmVf2OPjSESkq00FKwzr1NCYN8488RnKmCq52UtSyCseZ5DAAgDTpBZz8Nxp1EJImhkKaEAyOaYzydbYWYVizCvhfQy+cfRyLQ4G6gFlomg1SGgyFNCEYVlEBkKTH5upvQXU1h+MVau4Gpk6diqlTpwreq127NgICAvgeDV26dEH16tXzfaxp06ahbdu2iIyMxMiRI/mhxcnJydi9ezfmzp2LsDDdh/XLL7/M9/Gyio3VfUhNDZXWv5eQkGBy3wULFuDHH38s8DIBwIMHD2Bra2tyW16HbgPA06dPceTIEZPb8jNiLywszGy+5v5+hhgnRnq1TrogmSIF+lswlUqF5ORkAIAVA+JSFJi14wYm1dHmaxrOhIQEs+XVf97yIjU11Wy+T58+zXO+SqXSbL4PHjzIc74AzOb78OHDfOWbmpoKhUKBhw8f4siRI8jIyMhXfvlRauvq4UNoEroKdopkhJZpjBenLgDIX11VKpV8ncoqPyfbqKgos58lqqs6JbWunjp1SjBlAtXV3Cmp51VzqK7qlMa6WpLOq4YKs94SQvInv/XTVEdGPZGVCM+iOEz+9yYGVdWgmsGMOvk9rx47tA8tnu1AQroShzQNYCVVIDNdAa3W8FqVARoltFaOSKk/COKMOP4eklMrIEkK0zVqJb8Ep1VB7NgE18+b7pld2s6rd8PT4K6QIE0tQpxCDBsxg+3rUWRKLYdMjQiZag5qpvuLuFvrtgN0XjVUks6rdA38Bl0D61BdfYPq6ttfVyUcQ/OyGfBzy0RFzTGErnuJOPtaiHWoAyZ6Ew5RxQVjfM04NC+bAQ66sV4XouyxN8wRCcrswyb6uvo0mcPhcBHUWqCsNUOXclpcuimsU4YdYnJiqq5+4AQEi4BD4bEAx0HlVhUqt6oQp0XD6lUApImh4JB9MJHqas6KLFBmTtmyZTFhwgT+9fbt2zF48OB85dmwYUP8/vvv+Oyzz/DNN9/A3d0dWq0WsbGxYIzxUejx48fjo48+ytexTNH3BJBIjP+8+kiqlZWV0TYAmDFjBr7++muT21JSUoymcsyNOnXqmJ367I8//sjzh6169epm892yZQvi4uLylG+lSpXM5nvo0CG8ePHC5DY9lWsVaK2dIVKm8192TGIDiVQqmJfZVq1FUqYKjjVqw9PzEoKCgvJUXldXV7PlffDggdlhqDlxcHAwm29kZCQuXLiQp3xlMpnZfDMyMnDs2LE85QvAbL5WVlbYvXt3nvN1cHCASqVC7dq18cEHHxRrD/PSWld71HaAKEoBOJZDnYE/oI6VLnifn7oqk8nMznWe16H8AODp6Wn273DpEtVVoOTW1U6dOgmmXqS6mjsl9bxqDtVVndJYV0vSedVQ1nqb37pKCCk4+TmvmuvIqGdvYw1nZ0fEpCpwKcUGn/Vvyk87mJ/zarVq1dG5mhXkoWJEc26IcawLW7EEWsYASTK0nAxMbAUmNrh/5yTgmBZW0Q8gTQyFODXKqAHqbTuvpgXpesxrGYd0NYd0tfm12jgAaWpdejqvvlGSzqt0DfzG21ZX6RqY6qql3tW62sg1ExN94+Blq4IIgEwmh0P6TVTLuA2mqAhth+/B3KpDdHcLGlW4h7RU3d/hepwtdr9wQlSmNPsDvObi6gpVuYY4HxYGOwegcSVnTO1cHTYyMcKeFE5dtU1bj7Xb9kHuWR8qt6rQ2Hsgo3pncIo0WEUHwir2MTiN6SAo1dWccSw/YxcLWFpaGsqVK1dgv/T58+cxc+ZMXLt2TTBEs1atWpgxYwaGDRtWIMfJ6vHjx/D19UXt2rWNIrK7d+9G//79MXLkSPz999+5ypcWcXzDkkUcl54NxaH7sXB31E2FkabQIDZVCamYg7ebnWBNpVfJmfhf4wqY9H5FWnAVRb+I4/Xr17FkyRI4ODhAKjV/QtJqtUhJScGsWbPQpk0bWnA1l6ytZLA5PAFICAH8RgBNRvLb8lJX9f83Jycns8F/jUYDpVKJ1NRUTJ48Gc2bN7c4f1ocWack1VVLOTk5QSR607hCdTV3Sup51Ryqqzolqa6+refVklYuQopLSa0TOZ1XLz5PxNxjz+Bk83oxewZoGQNjgBYABw7gOCjUGqTK1fi0TRXULucAhUqLxJQ0KNQaKNVaKDUMCrUWKo3uue49LZRq3fu652+2qRnwZfpylFc8x0Z1ZxzkOvBlynqutpKIYCsTI1OlQe967pjc3sfs7/u2nVe1j4/D7vR0aK2dAbHMZDoAgEYJkTwJ6R0XQl25PZ1XDZS28ypdA5fOukrXwFRXLfUu1lVJxHXYnpoBTpkKrY0rIJaB4ziIRSJAowTSYwHGALsygMQaGq0WKq/GUNT/GFqXqhaXVaNl2HzrFc480a2v9UE9L4x9vwrEIl1bc1HU1cQMFU4+jsfpx/FIVej+NtYSMdpVd0G3WmXg7iBsp9PXVaVai8vP4nAtOB7JmSo42UjRuIIDGpWz0V2f5cHbUleLbETZy5cvsW3bNrx48QKZmZlGlVGlUuHmzZv5apjLqm3btrh8+TLi4uIQEhICxhgqVqzIr5NWWKpWrQobGxuTEfTo6GgAQN26dfOcv4uLS4F/GMyd1PLLXMXOL3MXDYYULBwikQgSsQQaxpCYoQDHcXCylQmCZIDupixZrjJ7kZNfdnZ2Zr/s88PGxsbsySk/rK2tzZ5M80Mmk0EmM77p6tixI3bu3ImIiAiULVvW6P8D6G5iExISUL58+VwFW4pTiaurwed0QTKZHVD3f4JNeamrlvzfRCIRUlNTUb58eXTs2DHbE2BuUF3VKeq6+rYqcXU1G8V5Xs0Lqqs6dF4lhLxLzJ1XH8REgYGDzevvrQylGpFJptdlUWq02HglBF5O+f1OFsFT+wo+6hAowOGstjE4CSDiOHCcrtFIKhLBzkoCOysxJK87+kQly6GE2GzDT05K43kV9XsCt1dDlPQCsPcETJw7wBiQkQS4eMOhfk9Akv31Ip1XSza6Bi6ddZWugamuFoS3sq6qlcC13wB1OuBYDiLD/z/TAopUQJmuC5ipMoDafSFu8RnEXg2Qm09pplKDX449gv+LRHAc8GmbyujdoJzg81YUddXFBRhX3h0j3tfg7KNYHLgXgfCETJx6koQzT5PQooobejcsh9pejnzZrgfH45djjxCRmAkNY+DAgYFh3x0O5V1s8G03XzSv4lZg5S1tdbVIAmVnzpxBr169IJfLc4xWm/rD5FeZMmVQpkyZAs/XHIlEgm7dumHv3r0ICwtDpUqV+G36odc9evQosvK8q5xspGCvp8dISFNCo2WQijk42xg31DMwOFkXTAM+yT2pVIqJEydi/vz5iI2NhYuLiyCgolKpkJiYCHt7e0ycOLHAgi3vFK0W8N+ke173f4B1/i+y6P9GCCElE30/E0JKouRMlW7U2GuGDVii10ErjtO9r2VM18O5kjOspGLIxCLIJCJYSfQ/xbCSiGAlFRlsE/NprPRppCI43F4Dq0d2uMlqg8W7oaoFwbd38v5QIgM6zQEOfgGkRQG2bsKRZWolkBkPWDno0uUQJHub0HmVkNKB6uo7LvgckBymO3/x1xgMyEwCMuIB/bqoUltALAXq9AW8GuTqEHFpCvx48CFC49Ihk4gwtUtNtKxacIGlvLCSiNGtrie61vHA7bBEHLgbidthSbjyPB5Xnsejurs9ejcsB5lYhO/23UeqXA1XOxk/vTUAKNVahCdkYsaeQCz4sF6BBstMKal1tUgCZVOmTEFmZibKlSuHPn36oEyZMoIpmQBdlPDSpUs4e/ZsoZRBoVDgwIEDCAkJQdWqVdGzZ0+zU4UVhK+//hp79+7F8ePHMWbMGP79EydOoFevXqhZs2ahHZvotKjihn13IpCmUCE5UzfkvayDlVEwVqnWQsxxaFHIXwIke40bN8asWbOwYsUKvHr1ChqNBhzHgTEGsViM8uXLY+LEiWjcuHFxF7V0Cr0IJATrLgjqDSiwbOn/RgghJRN9PxNCShrDjowAYCUVoaq7nSB4pvcqOROdanlgxge18ndQtRIIPQVwHGR1+kB8gYNSrRU0DmX1Tt8f+rQGei0HTs0BksMBrRrQr/gtkgDO3rogmU/r4i1nMaDzKiGlA9XVd1joRV0ncX0nD60KSArX/QR079uW0XX4SIkAQi8BNbpanP3z2DT8dPAhEtKVcLaV4oeetVHdo3BGpeYFx3Hw83aFn7crwuIzsP9uBM4+jsHTmDQsOv4Y4QkZYAAqONtAkmWKRZlEBA9HK0SnKPDLsUfYPrZlttdKBaEk1tUiCZQ9fvwYYrEYV69ezXYRQpVKhbJly+Yq761bt5p8f+jQofzzO3fuoF+/fggPD+ffq1y5Mg4cOIDatWvn6niWatOmDSZNmoTff/8dgwYNgqOjI5YvX460tDQsW7asUI5JhFpXK4PyLjZ4EKlbKNrBRgpbmfAjzxhDQroSFV1t0Lpa0Y06JKY1btwYf/75J65fvw5/f3+kpaXB3t4efn5+aN68OfX2ySutFrj9j+553Q8LZDSZIfq/EUJIyUTfz4SQkkTfkVEfqDIVIAMKOFAVckE31ZK9O+q26IzygdcRnpAJD0fjDpQA3R8C0AXBRhzW9cwPvQjIkwFrJ8DnPaBKu3dqJFlWdF4lpHSguvqOkicbvGBAcqQuSCaS6AJk1obTQnJZ0mfvRkgCFh1/BLlKi0qutpjdqzbcHQt+WtGCUsnNFpM6VscnLX1w9P4rbL72AhlKDcQiDi8SMuBgLYGzrQwyg4AZx3FwtZMhIjETl5/Fob2ve6GXs6TV1SIJlPn6+iIxMTHbIBmgG3a3Zs2aXOUdHR2NqVOnAgDq16+PUaNGoUWLFvz2V69eoVu3boiNjQWgm9O0Ro0aePDgAbp27YqAgIA8zzuek2XLlmHBggVo164dbG1tUaFCBVy+fBk+Pj6FcjwiJJOI0L5mWdyPSIGGMTjZCD/uSrUWCelKOFhL8G0330KPlBPLSKVStGnTBm3atCnuorw9XlwG4p/pRpPVH1goh6D/GyGElEz0/UwIKSn0HRmLNFD16KDuZ80PIJPq7vtm7AlEdIrC5LRDdH/4mkQG1OiiexABOq8SUjpQXX0HGQbCUqMBjRzgxLrR0KKsIRCWJXBm3sF7kVh/MRhaBjSs6Izp3X1hZ1UkIZV8c7KVYnCzSngWk4bwhAxwnG5kfUqmGimZatjKxHC1k8FaKgaga0vXMIZrwfFFEigDSlZdLZIrv2+//RavXr1CcnLOkVq1Wp2rvOvVqwfGGObNm4c7d+5g0qRJaNq0Kb/966+/RmxsLDiOQ/fu3REWFoabN2/i6dOncHFxwZIlS3L9+1iK4zjMnDkTt2/fxqVLl7B9+3YKkhWh5EwVrjxPQAUXG1RwsUFqphqvkjMRlSzHq+RMJGXobsCKYu5VQooNY8Bt/dpkH1p8IUAIIYQQQkhBkklE+LabLxysJYhOUUCp1gq2K9VaRKcoCi5QlRQORN4FOBHgq1sjvHkVNyz4sB4qutogKUNJ94eEEELI28LnPUAk0q1HpkgGwAGO5YyDZGql7j2f97LNTqtlWHvhOdZe0AXJutT2wOxetUtNkMxQmkINK4kYlVxtUN7ZGrYyXWAsQ6mBIsv1GAcOyXJVcRSz2BXJf3bQoEF4/PgxfvzxR/z+++9m02k0GkycOBHDhg2zOO9Dhw7hk08+wYwZM4y23bp1Czt27ADHcahYsSJ27doFW1tbAED58uWxevVqfP755/jpp59y/0uREm/TlVCkKdSoW94Jv/yvPq4Fx+NacDyS5So4WUvRooobWlcr8273FCRvvxdXgLinhTqajBBCCCGEEEvoA1W/HHuEiMRMaBgDBw4MDGKOQ0VXG3zbzbdgAlWPDut+VmwG2L/pFd28ihu2j22Jy8/i6P6QEEIIeVtUaQfYlgVig3SBMLuyurYwQ4wBmfG6UWZV2pnNKlOpweITj3EjJAEAMKKVDz5sXN7kaPjS4M06sRxsZBLYyCRQarRIyVTBwTrLMkVgcLJ+N6cnLbIQ6NSpU/Hxxx9jypQpcHIyHtGg0Whw48YNpKam5irfs2fPYvfu3Sa3fffdd/zzn3/+mQ+S6bVu3RpRUVG5Oh4pHYJepeDkw2gAwOftqsJGJkZ7X/ciGzZKSInAGOC/Ufe8Tj8aTUYIIYQQQopdkQSqNCrgyVHdc9+eRptlEhHdHxJCCCFvE1UGILXSTbfIiQAre+F2tVIXJLNyADrNMbvmZnyaAnMPPcTz2HRIxRy+7lwTbaqX7nVLs64TCwAysQhl7K0E6Qp0ndhSqEgCZffv38cHH3yAiIiIbNMxxnIdmU1NTUW1atWM3r906RJOnDgBjuNQt25dDB061OT+poJ2pHTTaBlWn3sOAOhUywO1vByLuUSEFJMXV4C4J4DUhkaTEUIIIYSQEqPQA1UvLgOZSYCtG1CpZeEcgxBCCCElg1YLnJkLaNRA+caARgmkRAJaNQAOANONMnP21gXJfFqbzCYkLh0/HXyAuDQlnGykmNWj1lvRrlws68SWQkUSKBs/fjxevnwJiUSCtm3boly5chCJhL3EtFotbty4gSdPnuQqb5XK9JyZ33zzDf/8559/NplGLpdDq9Wa3EZKr0MBkQiJS4e9lQQjWvkUd3EIKR6Ga5PV7gvYOBdnaQghhBBCCCk6QYd0P2t2B8Slby0RQgghhOSC/9/Ay1uAxArosxJwqggEnwNCLwLyZN0MSz7v6aZbNDOSzP9FIn45+giZKg0quNhgdq868HSyLtJfo7Do14mdsScQ0SkKuNrJBCP4lWotEtKVBbdObClVJFeM/v7+4DgOZ86cQZs2bcymS01NhaenZ67ydnd3x40bN9CsWTP+vTVr1uD69evgOA7t27dHjx49TO67Z88ewX6k9EtIV+Lfa2EAgOGtvOFk+27OqUoIwq4BsY8BiTXQYFBxl4YQQgghhJCikfIKeHlT99zXdFsAIYQQQt4SoZeB25t1z9//BnCrqnteo4vuYYFj919h9bnn0DKgXgUnzOjuC4e3bJ2uIl0ntpQqkkBZ1apVkZiYmG2QDAAcHBwwe/bsXOU9ePBgjBgxAgcPHkTVqlVx6NAhfP311+A4DjKZDH/88YfJ/ZKSkjBz5kzMnDkzV8cjJdtfl4KRqdKguoc9utTOXdCVkLeGYG2yvoCNS3GWhhBCCCGEkKLz6PVosvJ+gGO54i0LIYQQQgpPcgRw9vVMcnX6AdU752p3rZZh45VQ7L2jWy6qg687JnaoBqn47RxRVSTrxJZiRRIo++GHHzB8+HBkZGTA1tY227StWrXKVd5ffvklduzYgRo1asDFxQWJiYlgjAEAli5dilq1ahntc+XKFYwbNw7h4eHw8/PL1fFIyXUvPAkXnsRBxAHj21WFSJS79e4IeWuE3wBiH+mGnNen0WSEEEIIIeQdodUAT47pntfqVbxlIYQQQkjhUcmBkz8AyjTAoy7QckKudperNFhy8gmuPI8HAAxrUQkDm1Q0uX7X26TQ14ktxYokTNi/f398//33WL58eY5p//e//+Uqb5lMhlOnTmHIkCFITU0FYwzlypXDxo0bMW7cOEHaL7/8Eo0aNULXrl0RGhoKW1tbLFiwIFfHIyWTSqPFmvPPAQDd63mhmrtDMZeIkGJiOJqsdl/A1rU4S0MIeUsp1VqcfRSDBUeCMH13ABYcCcLZRzFQqmntV0IIIcUo7BqQHqdbn9cn+xltCCGEEFJKMQZc+h2If6abRanTHEBs+VSJSRlKzNwbiCvP4yERc5jSpQYGNa301gfJSPaKZETZP//8g3LlymHbtm2wt7eHo6OjURq1Wo0rV64gLi4u1/k7Oztjy5YtWL9+PVJSUuDubjoiumzZslznTUqHfXci8DIxE862Ugxr4V3cxSGk+Ly8CcQ81I0mazC4uEtDCHkLXQ+ONzmv+b47ESjvQvOaE0IIKUb6aRdrdMtVgxkhhBBCSpGgA8CT4wAnAjr+ANiXFWxWqrVvphfMVMHJ5s30glHJcvx06AGiUxSwt5JgVo9aqFveqZh+EVKSFEmg7Ndff0VQUBAA4MSJE4V2HGtra1hbWxda/qRkikmRY8fNcADAqNaVYW9VJB9rQkoexgD/TbrntXrTaDJCSIG7HhyPGXsCkSpXw9VOJpjDXKnWIjwhEzP2BGLBh/UoWEYIIaRopcXqRpQBgG+P4i0LIYQQQgpH9EPg8utZ65qNBco3FmzOrmOns50MIgASsQheTtaY3bsOyjvbFP3vQEqkIokozJgxAx9//DG8vLzg7e0NKysrozQqlQpBQUFISkoqiiKRt8i6i8FQqLWoW94R7WqWzXkHQt5WL28B0fcBsQxoOLS4S0PI20WtBILPAaEXAXkyYO0E+LwHVGkHSGTFXboioVRr8cuxR0iVq+HhaGU0LYVMIoKHoxWiUxT45dgjbB/b8p1fDJgQQkgRenwYYFrAqwHgXKm4S0MIIYSQgpaZqFuXTKsGKr9vNJNSdh07E9IVeB6TBhHHoXU1Nywa0ABONjT6nLxRJIGyIUOGYMWKFbh06RLEYrHZdFFRUahatWpRFIm8JW6FJuBacAJEIg6fta1Kc8mSd5dgbTIaTUZIgQq9DJyaAySHAVqDNbgCdwJOlXTzofu0Lq7SFZnLz+IQkZgJVzsZOI6DljFEp8jhZCOFrUwMgAPHcXC1kyEiMROXn8XRAsGEEEKKhlYLPDqie16rV/GWhRBCCCEFT6sFTs8F0mMBpwpAu+mAQTuwuY6dDAwJaUokZqggEXEQiTgkZahgIzUfoyDvpiLp5isSiTBjxgxoNJps03l6euK7774riiKRt4BCrcGa88EAgD4NysHbza6YS0RIMYq4/WY0WQMaTUZIgQm9DBz8Akh6Adi4Ao7l3jxsXHXvH/xCl+4tdy04HhrG+F55KXIV0hUaxKQqwAzSySQiaBjDteD44ikoIYSQd8/Lm0BaNGDlAFRuW9ylIYQQQkhBu/UXEOEPSKyBLvMAmbAdOGvHTgBgjCE6WYHEDBUAwNVehoouNohM0nXsJMRQkc2H07t3b8hkOU9NdOjQoSIoDXkb/Of/EtEpcrjZyzCkGU2tQd5hjAH+G3TPa/UC7GhdIEIKhFqpG0mmSAXsPXWBaENime59RaounVpZHKUsMsmZKnB4c8ORlK672XCxlfHv63HgkCxXFXkZCSGEvKMevW5HqN7lnZkSmRBCCHlnhF4C7mzRPW87DXCtbJQka8dOLWOISMpEmkINAHB3tIKbnRVkEjF17CQmFcnUi4aSkpKQnp4OrVYLxt70P1YqlTh37hyuXbtW1EUipVBEUiZ2+78EAIx5rwpsZDRclrzDIm8DUYG0NhkhBS34nG66RVu3N1M6qOUAGCB5veAvxwE2bkByuC59jS7FVNjC52QjBXs9dixVoYZayyAWcXC0Nr6cZGBwsqb53gkhhBSBjATgxeuR3bV6Fm9ZCCGEEFKwksKBsz/rntf9H1Cto8lkgo6d0C0TIFdpIeIALydr2Mje3LdSx05iSpEEylQqFWbOnIm///4bSUlJRXFI8hZjjGHt+edQaRgaVXJGq6o0eoa84/w36X769gDsyhRvWQh5m4Re1M2Drh9JJk8G0qJ0QTJng5HMEpluMeHQi291oKxFFTfsuxMBhVqDxHTd6DlnW6nR+qBKtRZijkOLKnR+JoQQUgQeHwW0GsCjDuBapbhLQwghhJCCosoETv4AKNMBz7pAi8/NJjXs2JmYrlsmABxQztkG1lnWI6OOncSUIpl6ccKECfj999+RmJgIxli2D0JycvV5PG6HJUEi5jCubVWjBjpC3imRd4BX9wCxFGj4UXGXhpC3izxZ+FpmD4AD1JmAKiNLYs44/VumdbUyKO9ig+gUOZRqXc88JxvhzQVjDAnpSpR3sUHrahS4J4QQUsi0WuDRYd1zXxpNRgghhLw1GAMu/g4kBAM2LkCnH3VtX2b8n737jo+qSv84/rnT0hNIQicQQkeq6AIiAgosimXFhrq76uryW/uqa1t3FVzrWpdV117W3pAVQUVRUFEsdJRqDL0lIb1Mu78/LgRCAglkZu4k+b5fL16Zue08ITmZmfuc85yhWWk4DYPCci/5ewZ2tkqMqZEk08BOOZiIJMrefvttAP7617+ydetWvF4vwWCwxr/vv/8elyt0k9xef/11zjjjDE444YSqbZ988gmXXXYZK1euDFk7Ejnl3gBPf5kNwFlHd6RDizibIxKx2Q971ibrNQESW9kbi0hTE5tS/bnDuW9bWf4BB5s1j29iPC4HN43vRSBo4g+aJMS6cOw3WMXrD7KjqJKkWBc3j+9VVRteREQkbLYtgaIt4EmArqPtjkZERERC5acZsG4OGA4YM6XOCkrDu6XTOjmGbYUVmKZJcpxLAzvlsESk9GJsbCxxcXHcddddhzxu8ODBDBgwoMHtBQIBzjvvPN577z0A0tL2ZYjHjh1Leno6Y8eOZcqUKfzf//1fg9uTyHnj+43klXhpkxzDOcd0tDscEXttXWrNJnO4NJtMJBwyR8CKtyDg3Vd+MT7VmjnmK7XWK3PFgt9r9cPMEfbGGwFup4PWSbHsKKrANGFbYTkGBiYmTsMgIzWOm8f3YohG54mISCSs+sD62u0kcGsQpYiISJOw40f4+jHr8ZA/QfuBdZ4SNE0SY1xV65QdWFrR6w+SX+rVwE45qIgkyn73u9/xwgsv1OvYzz//vMHtPfTQQ0yfPh3DMGjdunWN/YMGDeLOO+/k8ssvJysri7Fjxza4TQm/jXllzFi6FYD/G9mVGJezjjNEmrhFL1pfe02AxJp/60SkgbJGQUonKNgAiW3BMMDhhpgkqCyyZpUltYPyPGjR2Tq+iXtn0SYSYlxcc1J3erRJYmF2HoUVPlJi3QzNSmN4t3R94BARkcgoL7DWBwXodZqtoYiIiEiIlOXDJ3dY64BnjYT+59Z5immaTJu7jpLKAL3aJQGwo7CCQJlXAzul3iKSKLvzzjv59ttvee+99zjzzDMPeWzPnj3ZvHlzg9p78cUXGTVqFK+99hpt27ald+/eNY456aSTCAaD3HPPPUqUNQKmafKf+esJBk2GdEnl2MxUu0MSsde2Zdb6ZJpNJhI+Lo9V4mHmNVCyHeLTrJll8alWoqyyEMwgxLWwjnN5bA44vFZtK2LlliKcDoOzBnckPTGG0b2UpBcREZusmwMBH7TqCa162B2NiIiINFQwAHPvhNJd0KITjLzFGrBahxlLt/DlulwcDoN7zuxL99ZJLFifq4GdclhCmijbuHHjQff95z//4YYbbqBTp060alVzHZ1AIMD8+fPZtm1bg+PYtGkT8+fPr2rHqKVD7d32ww8/NLg9Cb95a3axcksRHpeDySdk2R2OiP0WvWR97XkyJLWxNxaRpixzOJw2DT6dAoWbrFFte0o5EAyAK8banznczigj4u0frIFMJ/ZqTXpijM3RiIhIs2aasGqm9bjXqfbGIiIiIqHx/bPWoHB3HIz7B3ji6zxl6aYCXlyQA8DkEVkc1d5aO3x0r9Ya2CmHJaSJsv79+1NcXHzIY+bMmRPKJmvVuXPnWpNxtcXhcCiLHO1KKv08v+AXAM47NoPWybE2RyRis+0rYMsiazbZoN/aHY1I05c5HC6eBdnzrBJPFYXWCPaNC63ZZOlNfxR79q4Svs/Jx2HAWYO1RqiIiNhs+woo2GitFdrtJLujERERkYb65UtY+pr1eORN0DKzzlN2FFXwz49WEzThpN6tOaVf2/DGKE1aSLNE559/PqZpNuhfKPTo0YMlS5YcdP/WrVuZOnUqhmFw7LHHhqRNCZ9XFm6goMxHx5ZxnDmog93hiNhv79pkPcdDkt4EiESEywM9xlmj2k6fBmf+B7ocb5VeXPGW3dGF3TuLrNlkx3VLp0OLOJujERGRZm/vbLKuJ4Inwd5YREREpGEKNsG8e63H/c6xXt/rUOkPcM/sVRRX+OneOpErRnWrtaqcSH2FNFE2efJkjj76aLZu3YrP5yMYDNb7n9fr5YMPPghJHDfddBPnnnsuCxYsqLFv9uzZDB8+nO3bt1cdK9Fr/c4SPlxhleP808iuuJ2aASjN3PaVsPkHcDhhoGaTidhqbx9cNRMqiuyNJYy2FpSzYH0uAOfsnU3m98LaOTDn7/D+NdbXtXOs7SIiIuFUUWTN8gborbKLIiIijZqvHD75O3hLoW0/GPKnOk8xTZPHP1tP9q5SkuNc3HJKL609Jg0W0tKLgwYN4owzzqBt28Of4eByuTjllFMYP358g+MYOnQo119/PaNGjaJt27bs3r2boUOHsm7dOgoKCjBNE8MwuPvuuxk3blyD2zsUn8/HK6+8wv33389HH31EZmZmWNtrSoJBk//M+5mgCSO6pzMgo4XdIYnYb+9ssh7jIbmdraGINHsZv4K0bpC3Hn6cDoMvtjuisJi+eDNBEwZ3bklWq0TIWbBnzbaNEAzuO3DFW5DSCcZMaRZrtomIiE3WfwoBL6RmQes+dkcjImIfv7d6efjYFMgcAVmjrIoYItHONOGLByH/F4hPhTFTwVl3uuKD5dv4fM0uHAbcPL4XrZO0TI80XEgTZQB///vfG3T+rFmzQhLH5ZdfzqBBg7j//vv57LPP+O677wDweDyMGDGCW265hZNOCm8t85UrV/Laa6/xxBNPUFhYGNa2mqI5P+1g7Y5i4txOLj2+i93hiNhvx4+w+XtrNpnWJhOxn2HAwAtg7p2w8l3of5616HATkltSydzVOwE455iOVpJs5jVQWQzxaeDc7wN4wAsFG6z9p01TskxERELPNGH1nko0vU+1XotFRJojDV6TpuDH96wBMIbD+p1NSKvzlJVbCnn2y2wA/nB8F/p3bBHeGKXZiNicxLVr13Ldddcxf/78atuffPJJrr76atatWxfyNocOHcp7771HQUEBO3fuZOvWrZSUlPDJJ5+EPUkG0LdvX+655x4uuuiisLfV1BSW+3jp6xwALhzaibTEGHsDEokGi16yvnb/NSS3tzcWEbFkjbL6Y0URrA7NYJ9oMmPJFvwBk6PaJ3NU6zjrw3hlMSS2rZ4kA+t5Yltr/6dTVIZRRERCb9dqyPvZes3pNtbuaESkuYmW8uN7B68VbIC4VOvzyN5/can7Bq/l1FySRiRqbF8J3zxmPR56BbQbUOcpuSWV3P/RaoImjOzRitMH6N6YhE7IZ5TVZsOGDQwbNoyCggJWr17NyJEjq/b96U9/YuHChYwePZp7772X3/3udyFp89NPP2XMmDEAGIZBenr6QY9ds2YNlZWV9O/fPyRtHyglJSUs123KXvo6h5JKP5npCZzaX3/0RNi5CjZ9a42yOTo0fycBvP4gC9bnsjA7j8JyHylxboZmpTG8W7rqO4vUh8MJA86HLx+CZW9AnzPA6bY7qpAoqvDx8Y/Wmq7nHNPRKutSuNGaSbZ3BL+vFNwJ+04yDIhLg8JN1vE9wlviWkREmplVM62vWaMgNtnWUESkmYmWGVx+b/XBawfOrN07eK1ku3XcxbNUhlGiT1k+fHoHBAPQdTT0O7vOU7z+IPfMXkVBmY8u6QlcdWI3DM0slxCKyF3QqVOnsnv3bmJiYjjzzDNr7B86dCh33HEHl156Kd9++21I2vzzn/9c5zGFhYWMGDGCwYMHc+mll9KjRw8+/fTTkLS/P4dDN5sPx6ptRXzy0w4ArhjVFadDf/RE9q1NFrrZZN9m5zHp6W+45d3lvLt4M3NX7eTdxZu55d3lTHr6G77NzgtJOyJNXo/xVj310l1W2Ygm4oNl26jwBemSnsDRnVpaax8Eg/tmkvnKoHCzNWIVc9+JLg8E/dbxIiIioeItg58/sx73PtXeWESkeYmmGVw1Bq+ZYAbA3C95d+DgNZFoEgzA3KlQmgstO8MJN9VZStk0TZ6c/zPrdpSQGOPitgm9iXU7IxSwNBcRmVH2+eef89JLL3HBBRfgdNb+Szxx4kT+7//+jzvvvDMk65QFAgF++uknpk+fztatW2nbti3nnXcePXv2rDrmb3/7G19//TVvv/02EydOZNmyZZx88sm8+OKLjBtnzwjoyspKKisra91XVFQEgM/nw+fzRTKsiAkETR7/bB2maXJir1Z0S49rst+rNJydvxsR7au71uDc8A0YDgL9JkEIrvldTj5/m/ETJZV+WsZ7qs0e8/qDbMov45Z3l3PXb/rwq8zUBrcnzVvT76sGRp+zcHz/NCx5lUCXE63Zn41YuTfA+0s3Y5omZw5sh9/vx1G2GwfWhxTMIEbxdis/5ozBNGH/ZJmBQbBsN0G9hjcq0fKe68B+u7evioj97Py8aqz5GIe3DFp0IpDWOyTviUXCqem/B24mAl6cn9yBUVGEuXcGl7nfIDGHGxLaYJRsx/zkDgK/+1/NEuVgneOvsP75yq1BZ/4KDF85+MvBV1H11fCV7dtWtb8cw1+OsWWRNRunssRKju2NJa4lZkKrfe053RhBP8Hs+QS7jA7v/1Ejp74aWY7vn8bYsgTccQRG3wGGu87X9I9/3MGcH7fjMOD6MV1JjXM2qf8TqZ9w/8wjkigzDKPOkooJCVbZnq+++iokbebn59OvX79q2/7xj3/wwAMPVM0225uQGzVqFAADBgzgvvvu44ILLuDnn3+2pWTivffey9SpUw95zJw5c4iPj49QRJG1ONdg2VYHsU6TdsX5zJ69xu6QJIqVlZXZ1nYk+2rfza+SVlLI9pSBrPlqGbCsQdfzB+HfPzrIqzRIcUN5aSXlBxwTY0JuUSW3vfkdVx8VRFUYpSGaQ191BjwMKfHiLlzBj289TG5SnwZdz27f7zLYstNByxiTgjXfMnst9NmaR0ZlBRXBQmL8Rbj9FZiGk9JADBQWVjs/1lfBpq15/DR7tk3fgRwJO/vq/urTb0XEHnZ+Xj065xmSKgr5OaY9mz/8MOTXFwm15vAeuDloXbiMgTvX4XUkYhYVYZgBnKYXwwxisGcAGSZGMIBz23JynzgFrzsFZ7ASZ9CHM1iJI+jbc45Zd4N1iPPm4g74q1V/BPBVlFPpP/A9uZft61ayrFLvyQ9FfTVy0ot/4qgtbwDwY4fx5H69Elh5yHO2lMKb2U6CJpzQLsjWFV+zdUUEgpWoE+6+aphmCP5K16FPnz4sW7YMt/vga3a8/fbbnHfeeSQnJ1NQUNCg9r766quq5NfAgQPp3LkzpmmybNkycnJy+Oijjxg7dizx8fFUVlbi9/urapqWl5eTnJzMnXfeya233tqgOPaaMmUKU6dO5ZdffiEzM/OQx9Y1kiAjI4Pc3FySk5tePfb8Ui9Xvr6UCl+QP53QhV8f1cbukCTKFRUVkZ6eTmFhYcT7RMT6au5anP+73JpNdtYLkNKxYdcD5q3dxW0zfqJFnLtqJlnQNHEcMNXd6w9SUO7j7t/0YVSPVrVdSqRemkVfBRw/PI+x7FVo1ZPAaY/XWT4iWnn9Qf706hJ2l/m4clQWY3q3BsBY/wnOWddhuuMwSvbMJkvpiOk+4ENbwItRvpvAhEcwu42N/DcgR8zOvrq/2maUZWRk2B6XSLQoKioiJSWlyb+uVpO3DueMP4HDRWDSmxDXIrTXFwmD5vIeuKlzfHQzjpXvgDvOmgUWOMSMhoAP4ltiJh1iuQTDAFesdT1XHLhjwRVnvafe89j6Go/pjttvWxy4YjGWvoxj/Sd7Zrc59vwzgJqfPYzirQT7nUfwpCkN/n9oytRXI6Rwk3V/y1eO2e8cgr/6U52n5Jd6ueGdFRSU+Tiuayp/Gdtd65I1Y+HuqxGZUTZ+/Hhuv/127r333lr3//DDD1x11VUYhsFxxx3X4PamTJnCqFGjeOKJJ+jRo0fVdtM0mTJlCtOmTWPs2LFUVFRgGEa1DhYXF0f79u2ZOXNmnYmyLVu2cNJJJ9XYPnfuXDp06HBEscfExBATE3PIY9xu9yGTjo3Vy99mU+k36dE2iVP6d8ChtcmkDnb2g4j11WWvWm96u4/Fkd6lYdfa44cNhQRNk5g99ZxNTDbll+NxOmidHINrz7qKMW4nwTIvP2woZOxRoVkXTZqnZtFXAQacAz++A7lrcexcAR0HN/yaNpi7ZhsF5X7Sk2IYc1Q73M49U0q7j4EWHTG2rbD+LsW2AE9C9Y/kpgnl+dCiM67uY8DV9N6vNGXR8v6yPv1WROxh2+fVdR9Zrz1ZJ+BI1gAuaRyazXvgpqYsH7Yu2fdvw9fgK4Wg19q/N9HldO9LUu1NWFUUQtv+GMOvBXe8ldxy70ty4Y4HV0zDBtQFKiDnC+tepvMQPz+/FxwunFkjcernfEjqqxHgLYPPplqlR9sPhGFX4HQceo0xXyDIg5+sp7DcT+e0BK4b2wuPR+uSNWfh7gcRSZTdcsst9O/fn1WrVnHppZfSq1cvgsEga9as4Z133uGNN97A7/fjcrmYMmVKg9tbsmQJGzZsIDExsdp2wzD4+9//Tp8++8ohuVw1/wtiYmJYu3Ztne34fD7WrKlZGlA1Ug/fsk0FzF+7C8OAK0Z1VZJMBGDXWtiwwHrDffTvQ3bZwnIfxn63tksrA/gDJqYZxHnAG3YDg8IK/U0TqZf4VOg1AX58D5a+2igTZYGgyTuLtgBw5qAO+5JkAC4PtD8atq2w1kM4cDS/3wvleRCTBGOmWMeLiIg0lK8c1n9qPe51mr2xiEjTU5YP25bC1qVWYqxgY/X9DhcYTohL3Zf8Oth6xL5yaHMUZI0MX7xZoyClExRsgL1rph3INK335S06W8eL2Mk04YsHYHcOxKdZnxXrSJIBPPNlNqu3FxPvcXLbhN7EKUkmYRaRRFnr1q354IMPOP3005k5c2aN/aZpEhsby7PPPsuvfvWrBrcXHx9fI0m2V25uLqZpEggEAGsG2YEKCwspLi6us53MzEwiULmyyfMFgjw5/2cATunXjm6tk2yOSCRKLH7J+trtJGiREbLLpsS5Mdn3t6ugzBoZlxznqjGF3cQkJbaRj1wSiaQBk+Cn/8GWRbBzNbTuZXdEh+Wr9bnsKKogKdbFr49qW33njp9g8w+QkmGNXq0ogGAeVpkX07qJ0KKz9cEnc3jkgxcRkaYpex54SyG5PbQfZHc0ItLYlRfAtmX7Zoztzqm+3zAgrZv196b9ICjZCR/dDLEp4DzEQLA9M7jIHBHO6K3BaGOmwMxroGS7lXjYPy4NXpNos/Jd+PkzKzk2dqo1wLQOn/y0gw9XbMcw4C+/7kn7FjXv34uEWkQSZQDHHHMMK1as4OGHH+b9998nOzsb0zTp1KkTJ510En/+85/p3r17SNrq3LkzDzzwADfeeGO17WvXruXSSy9lwIABeL3WjeEWLVpUO2bnzp3s2rWLVq1CV84huGeFTSXVajdjyRY27y6nRbyb3w7tbHc4ItEhdz3kfGW9SR/0u5BeemhWGjOWbMHrD2JiUuGz/kalxFVPiHn91gyzoVlpIW1fpElLagvdxsC6OdassnH/sDuiegsGTd76YRMAZwxsT6x7vxF7fi/Mv8+aSdZ3Ipxwo3XjMudLq8RMbIp1UyBrlD6Mi4hIaK36wPraawI4DjKLQ0SaJr+34e85K4qqJ8bys2sek9bNKgfXfhC07Q+x+6194/fCN49H1wyuzOFw2jT4dAoUboKgHw1ek6i0fQUsfMJ6PPQKaNuvzlPW7SjmiXnrAbhwSCeOzaw7sSYSChFLlAGkpaVx9913c/fddx/0mIqKCmJjYxvUzlVXXcUFF1zAc889R9++fTFNkw0bNrB06VJOOukk5s6dy/333191fElJSdUMtNdeew2AwYNDVy5p69atAGzevJkuXUKzxlBTsbO4gje/t27KXTI8k8SYiP5KikSvxS9aX7ueCC1Dm0Ae3i2dDi3j2JRfDntmliXGuqrWJgMrsZ9f6iUjNY7h3dJD2r5IkzfwAitRlvMl7N4Q8j4cLt/n5LMxr4w4t5NT+rWrvnPxS9b3Ep8Kx11t3ZjoMc76JyIiEi75v8COlVaZsx4n2x2NiERSzoI9iaCNsGcAOgAr3rJKDx4sEVRZDNuW75cY+9lKZO0vtYuVFGs30EqQxaYcPI5oncGVORwunqXBaxIdaktqtxsIS16GYMC6t9X3rDovU1Dm5e7Zq/AHTIZ0SeWcwaGrriRSl6jLSnTt2pUtW7Y06BqTJk3iu+++49FHH6221tiYMWOYOXMmzz77LNdccw2GYXDGGWdw6qmnMmnSJDweD7fffjuGYXDBBRc09Fth0aJFTJ48mSVLlgBw6qmnMmbMGN59990GX7upePbLX6j0BzmqfTKje7a2OxyR6JD3M/zypTVSLYRrk+3lcTm4eXwvbnp3OVt2l+N0GLTYbzaZ1x8kv9RLUqyLm8f3wuPSyF2Rw5LaBToPt9YYXPYGjLrZ7ojqZJomby/aDMDJ/dqStH/J1V1rYKk1kIjjr68+wlZERCScVu+ZTdb5OEhQlQORZiNngZWYqiyumZgKeK3ZXTOvsWZVtR+4LzG2bSnkrrOqIOyvZed9pRTbDYC4locXT7TO4NLgNYkGtSa1Tfj+GcCw1rk+4cbaZ2Puxx8Icv9Hq8kr8dKhRRzXj+uBw3Hoc0RCKaKJstzcXDZs2EBZWVmNMoRer5fPPvuM7du3h6Sthx9+mDPPPJP//e9/+Hw+RowYwcSJE3E4HFxxxRUMGTKE9evXc95557Fjxw4uuOACPv/8cwCOO+44LrzwwgbHMHjwYBYtWtTg6zRVP+Tk883PeTgMuHxU1xprI4k0W4tetL5mjYaWmWFpYkhWGuOPasvLCzcQNE12l3kxMDAxcRoGGalx3Dy+F0NUdlHkyAy60EqUrfsYjrkEEqN7MMjKLUWs2V6M22nwm4Ed9u0I+GDenpKLXU+ELmFec0FERGQvvxfWfmw97n26vbGISOT4vdZN98ri2ksdOlzgSYLi7fDW76z1cw/UImPPbLE9ybF6rIlUJ83gEqnpYEnt0l3WZ8hgEIo2W4nsOhLJLyzIYeWWIuLcTm6b0Jt4T9TN75EmLiK/cXl5eVx00UV8+OGHkWiuyogRIxgxovYbOoMHD64qr9imTRvmzp3LW2+9RXZ2NpdffrmSNmFW6Q/w5HyrLvQZAzvQOS3B5ohEokTez/DLF2GbTbaXLxBk1fZiuqQnMLZPG8q9AQorfKTEuhmalcbwbumaSSbSEG2Oska3bl0Ky9+C466yO6JDenuRVQZ5TJ82tEzY70P+kpetdRziWsDwa+wJTkREGpXHHnuszuUU2rVrx/nnn19t2+uvv862bduqnmf613NcxXrKHInMePsrMBYAMGzYMIYNG1Z1XGVlJY8//ni9Yps0aRLt27ever527Vo++OCDOs/zeDxcdVX11/I5c+awcuXKOs/t3r07p512WrVtTz/9NCUlJXWeO3bsWPr127eeS25uLv/973/rPA/gj3/8I0lJSVXPFy1axPz58+s8Ly0tjYsuuqjatunTp5OTk1PnuUcffTSjRo2qtu3hhx+uV7wTJ04kMzOz6nlOTg7Tp0+v17nXX399tefz5s1j8eLFdZ6XmZnJxIkTq2176aWXyMvLq/PckSNHVluyo7i4mGeeeabaMRUVFXVeR2qRPc+amRKfti9JFvBaa435ysBfAZjWTfiKCohJgTZ9rPfe7QZZXxPCtHyAZnCJ7HOwpLa3GMrzrbLJLTqCt8Q67uJZB00of756J+8vs5Yuun5cDzJS4yPzPYjsJyKJsssuu4zZs2cD1hvM9PR03G53jeN27dpFeXl5JEJi1qxZ9O7dm6ysrKpt5557bkTaFnhn0WZ2FFWQlujh/F91sjscEfscWMd5x0rrA0DvU63ybWHy9c957C71kprg4crR3XA7lRQTCbmBF1qJslUzYdBvrWRTFFq/s5glGwtwGHDW0R337chdD0tesR4Pv/bwS9SIiEizVFxcjM/nO+QxKSk11wMqKyujuLi46nlnczlBgvwY7EzxfkmlysrKWtusj0AgUO25z+er17keT80bexUVFfU6t7ZkSUlJSb3OPfD/MRgM1vt7ra2KT33OrS3JeeDP5mAa8rPx+/01ntf33NriqM+5ZWVlNbaVlpbW61yv11vtuWmaNc5TouwI5XxpzULZOzMlGLBKLe5fTtHhBnc8+Muh20kw4UF7YhVpzg6W1C7eUy0uLtVau88ZY5UszZ5Xa5L5510l/PuzdQCcd2wGQ1XZSGwSkUTZp59+imEYPPXUU1x88cW4XLU3u2HDBnr16hWJkBg1ahT9+/fnnXfeYdCgQRFpUyxbC8p5d886KJcdn0Wcx2lzRCI2ObCOsxmA8kKr1Hn2PGt/mGqcv7/UGqlzSr92SpKJhEvHYyG9u7VOwo/vWSUYo9DbP1ivySN7tKJN8p6bYwE/zLvXujHR5QSrFKyIiEg9JCUl1TmjLD6+5kjx+Pj4qhlQScFCOpTlAk62xA8gyZFYdVxMTEytbdaH01n9s6fb7a7XubUlymJjY+t1bm3/F4mJibUcWdOBA4wdDke9v9cDq+R4PJ56nZuQULPay/4/m0NpyM/mwPtELper3ufWFkd9zq3t9zAhIaFeCa4DfycMw6jRZm0DxKUeKgqrPy/fbSXJnB7rhrw7zkqUARRttW7Mi0jkHZjUxrT6pBm0EtkJrazNLo+1rl/OlzUSZYXlPu6ZtQpfwGRw55ZcoMkUYiPDPHCYURh069aNiooKNm/eXOex5557Lm+99VaD25w3bx4ffPABBQUFBIPVF/EMBoPk5uby4Ycf0r9/f5YsWdLg9iKhqKiIlJQUCgsLSU5OtjucI2KaJlPe/5HFGwsY1KkFU08/SmUu5YhFa5/YG9fdd9990JsEHfwbGFsxkzjDR1xaR+uNRfFWqCymIuDEb4LXiOGT2NPY4upc6zWOtOxMnt/DIlcf4mJjeOHiY2kR71HZmVqo7Exoy87cdtttUdtXwxrXz59bCfGYJLjgLfBEVwmJTfllXPnaYkwTHr/gaDql7Ylv8X/h++esuM/9b2jWdZCoF+2vq9EWl4hdorVPhDSuhU/Csteh0zA4+b7QBCgSYc2ir4bDnL/Dsjcgub11wz0/2xpUmtwBPAckmYu2wIDzYdw/7IlVmoRo7RPRGleV96+BNR9afRWgLBfK8qx1BFtkgmO/wSlFW6HnyXD6tKpNgaDJHe+vZNmmQtqlxPLweQNJjNG6ZHJw4e4TEfntu+aaa/jb3/6G3+8/6Gyyve69994GtzdjxgzOOusswErMGIZRo+zA3m31uQkoofPNz3ks3liAy2nwfyO7KkkmTdrBys44zADH8TFuyilxtSTO6bFGwVVapTrKHIlU+IMkmSUMK/uYlziXoFFz5uWRljZZ4WuP2RJGdG9Fi3hr5I/KztSksjMqOxMSXUZCSkco3AyrP4D+0VXm+Z1FmzFNGNIldV+SLD8bFr1kPR5+rZJkIiISWQEfrN2zvnnvU+2NRUQiL3MErHjL+ozsLbWSZE5PzSSZ32vdkM8cYU+cIs1d7H5llANeKMu3Hie2qZ4kA8Csfjzw329yWLapkFi3g9sm9FaSTGwXsUTZ119/zfPPP8/kyZMPeewJJ5zAli1bGtTetGnTSE5O5swzz6Rjx4688cYbXHDBBdWSMi+99BKXXnopF1xwQYPakvor9wZ4+stswFoDpUOLOJsjEgmvg5Wd6eJbR8uKYspI3Ff+pWxP0t6ThOn34Aj6KDcTSKWEvrG7+MXdvcZ1jqS0SVnQyY6ClrQ04PQB7aq2q+xMTSo703zKzjz22GN1lohq164d559/frVtr7/+Otu2bavz+qdkHU2vws2w/E3o8xsqA2a9Zn8CTJo0ifbt21c9D+Xsz9KAkw8KO2BiUF6+lIfXfoRhBjnb/TkZMX7oPBy6jQE0+7M2TXX2p4iI7TYsgPICq8Rap2F1Hi4iTUzWKEjpBAU54C23tsUdMHDLNKE8D1p0to4XkcjbP6ldvB0wrYR2PZLaX67bxfTF1v3/a0/qQee0mvdfRCItIomyL774gsmTJ3PXXXeRlpZGq1atahzj9/v58ssv2b59e4PbW7FiBZ9//jkDBw4EIC4ujuOOO46RI0dWHdOzZ0/eeustbrvttga3J/XzxvcbySvx0iY5hnOO6Wh3OCJhd9VVV9U+FXjO32FZPIl7p6cHvFBZZD1OSCPNuV+SpWgLZw5Ih3HX17zOAWJiYmrcfD3QKws30Pr7TfRul0S31vtuSPfo0aPOcw9m3LhxjBtXc0HW+qhr8MTBpKenH3G8gwcPrnaz+HAceIP6cBxpvJmZmUd87qhRo2okAerrwMRDfSUlJdWIt6ioKKpfbw82+3N/KSkpNbbVd4bhjuTj6FXyNZTmwvpPoMuYes8SDAQC1Z6HcvbnCl9b/IEg6Y5SPOV5FAMDzB9JiN0EyZ1gxPVVizJr9mdNmv0pIhImq2ZaX3ueXMuIdBFp8lweGDMF3r0M/OXgjIHY/T5X+71WkiwmyTrOVfN9r4hEwN6kdu4a8Fdar9mJbaofU0tSOye3lH99ug6As47uwPHd0yMbt8hBRCRR9rvf/a5qfbL6jAxuqKSkpKokGVg3+2677bZqibJzzjmHyy+/nH/9619ce+21YY+pufH6gyxYn8vC7DwKy30YwMJf8on3OJl8QldiXPrAI83YgYsT+ysAwxp14zxwJpJR8/gj5PUH+WilNRjh9AEdQnJNkabgYLM/91fbrLv6zjD0xCVCv3Nh4ROw9DXIPLHeswSrZp3uEarZnxVBB5sL0nA6DQYklZPkTiI5WMCvyn/E4XDDsCshYd8HFs3+rEmzP0VEwqBoG2z+wXrca4K9sYiIfTofB+ndoaIAnC5rfSMMwNyz/lFnK0mWOdzeOEWaM5cHhv8Z3v0DBP3W50fHfp+RaklqF1f4uHv2Kir9QQZmtOD3wzJtCl6kJsM8cPhuGPzrX//iuuuuw+PxkJaWhtvtrnEzpKKigp07dwI1R08frgEDBvDVV19V+/B/3nnnceedd9KzZ8+qba1btyYhIYFffvmlQe1FStQv4rjHt9l53P/RarbsLidgmhhAcYUff9AkNcHDv88fxJCsNLvDlCYgWvtEnXHtvzjxXsEAEATHATcpQ7g48dxVO3j003WkJXp49vfH4HI6GnxNkfpotH01lLxl8Nq51lqEY6faXiLmv9/k8PYPm+neJpGHzhmAYZrw/tWwYyVkDIGT76+aTSbNh/qqSOMQrX0iJHF99wwseQU6HgMTHgptgCIR1qT7arhtXgSzrrfWJht2BWxZbA0gjU2xyrdljdJMMgmZaO0T0RpXFdOEOX+DNR9ZSW2Hy1pTcP+kdkpGVVI7GDS584OfWLRhN22SY3j4vIEkx2qgntRfuPtERGaUTZ48mSeeeILFixfXOup3r9WrVzNgwIAGt3fccccxZswYTjnlFI455hgmTJjA9ddfz9lnn82bb75JRkYGd911F7m5ubWW3JEj9212HrdOX0FxhZ/UBA8el4PiCh8llQFcTggETW6dvoJ7J/ZTskyar/3rODv3vLl3OIEDZlqGcHFi0zR5f9lWACb0a6ckmUikeeLhqDNh8X9hyavQZaRtiajSSj8fLLfWVjtncIY1eGnFO1aSzB0PJ/xFSTIREYm8YADWfmQ97nWqvbGIiL2WvW597X2a9R76qDPtjUdEavrlC8j5CuJawPmvwe4NkPPlQZPar367gUUbduNxOfjrKb2VJJOoE5FEWVxcHNdff32t5W3216tXLy677LIGt3frrbcyaNAgpk6disvlorKykiFDhnD88cdXW2AeOOK1W6Qmrz/I/R+tprjCT5vkGAzDIGCa5JZYa2KkJcbQMs7NjqJK7v9oNW9MHobHpZv10gxVLU68ARLb1n5DOsSLE/+0rYjsXaW4nQa/7tu2wdcTkSPQ9yxY/hbkroUti6zR8jaYtWIb5d4AnVLjGdIlFQo3w/fPWDuHXQGJrW2JS0REmrmNC631PONaQObxdkcjInbJXQ+bvwfDAf3OsTsaEalNZTEs+Jf1eOD50Kqn9a9H7evXf/1zLm/9YC3LdPWJ3chqVb/S/iKRFLEsxf/93//hcrnIz89n6dKlVdt37dpFaWlp1fPHH3+8wW116tSJhQsX8uc//5l///vfVWUep02bxkUXXYRhGJimyciRI/nPf/7T4PbEsmB9Llt2l5Oa4Kn6P88v8RIImridBi3jrJKbqQketuwuZ8H6XJsjFrHJ3sWJY5KgZLs1s2x/fq+1PYSLE89cZs0eGd2ztUbtiNglrgX03jNCfskrtoRQ4Qvw/lJrdunZgzviwIT5/7QWX+4wWCP4RUTEPqtmWl97jAen3q+KNFvL37C+Zo2C5Ha2hiIiB/HtU1CWBykdYdDvD3nopvwyHv1kHQBnDGzPqJ4amCnRKSIzygB+/vlnrrjiCubOnUtaWho7duwAYPv27Vx//fUMHjyYf/zjHyFbRDwrK4uHH3642ja3283zzz/Pv/71LwzDqPfC9FI/C7PzCJhm1SyxSn+AwnIfAK2SYqqSZx6Xg4BpsjA7j9G99MdRmqnM4XDaNPh0ChRushY+DdPixLuKK/nmZysxfdqA9nUcLSJh1e9c+PE92LoEdvwEbfpEtPlPV+2gsNxHm+QYRnRPh59mwLZl4I6DE25UyUUREbFHyS7Y9K31WIM2RJqv4h2wfq71eMD59sZSC68/yIL1uSzMzqOw3EdKnJuhWWkM75ZuS8WkaItHmolty/YNbjnhxkMO7i6t9HP3rFWU+wL07ZDCJcO7RChIkcMXkUTZhg0bOO6448jNzcU0TUzTrNrXr18/Zs2axa9//Wt+/etf8/HHHzc4WXbjjTfyyCOP8MADD3DdddfV2J+UlNSg60vtCst9GOy7weZ0GCTFujBNiPdU/1UzMCis8EU6RJHokjkcLp4F2fMOWce5oWav2EbQhH4dU8hMP/g6kSISAUltoPs4WPMhLH0Vfn13xJr2B4JMX7wFgDMHdcRVugO+e9ra+avJGrErIiL2WTMLzCC0GwAtMuyORkTssuJt629Bh8HQqofd0VTzbXYe93+0mi27ywmYJgYGJiYzlmyhQ8s4bh7fiyFZac02Hmkm/F744kHrca9Tof1AoPak7a+6pPLluly2FJSTnujh5vE9cTo0MFOiV0QSZX//+9/ZtWsX48aNY9CgQbz++uvV9ns8Hv72t78xduxY7rvvPv7+9783qL2nnnoK0zTJzs5u0HXk8KTEuTHZlwR1ORy0SY6ttm0vE5MUlX8TsZJhPcYdtI5zQ1X4Any0cjsAp/XXbDKRqDBgEqz9yFr4OP8XSI3MqLr5a3exq7iSFvFuxvRuBR/fCL5y66Zkn99EJAYREZEagkFYPdt63Ps0e2MREftUFMHqD6zHAybZG8sBvs3O49bpKyiu8JOa4Kk2W8vrD7Ipv5xbp6/g3on9IpKcirZ4pBlZ+ioUbIS4ljDk/4CDJ21f+24jgaBJhxZx/PWU3rSID81gcJFwicg83I8//piHHnqIjz76iHvvvZf4+Pgax/Tu3RuAl19+ucHtjRw5koSEBO644446j33xxRcb3J5Yhmal4TQMvP5gte37zzID60XbaRgM1Yu1SNjNX7uLkko/bZJjGNIl1e5wRASgZSZkHm89XvZGRJoMBk3eWWQtnnzGwA7ErJsNWxaDKwZG3gQOlWYREZEI8nth7RyY83d44wKrJHHAB52G2R2ZiNhl1fvWIK60rtDxWLujqeL1B7n/o9UUV1ifqw8saehxOWiTHENxhZ/7P1pd455YU49HmpH8X/attT38GohNrkrabsovp0W8h3YpcbRNiSU51o3XH8TrD1JU4SO/1Gtv7CL1EJEZZQ6Hgz//+c+HPGbbtm0AbNy4scHtvfDCC5xxxhmsXbuW9PT0gx5XXl7OVVddxcUXX9zgNgWGd0unQ8s4NuWX0yZ535pk+zNNk/xSLxmpcQzvdvCfjYg0nGmavL9sKwAT+rfDoSnuItFj4IXwy5ew/hM45g9WScYwWpidx+bd5cR7nJzSxYAZ/7F2HPtHawFmERGRSMlZsGed3o3WbDJviZU485fDy2eGbJ1eEWlE/F5Y+a71uP+kqFo3d8H6XLbsLic1wVN1n6vCF8AfrF49Kcbt4JfcUp75MpujO7Ws2n7gt3Kw7+zAe2j7P91/z+KNu/klt5SkWBflvkDVdpfDUZU0MwyD1AQPW3aXs2B9LqN7ta7fNytyMMEgfPkgBP3Q+TjIGl0jabv3d9gbCLKjqAKHYdAiwU0wCPd/tJo3Jg/T2nkS1SKSKGvXru41L55//nmAQya26mv27NlccsklXHvttZx44okcddRRNY4pKyvjrbfeory8vMHticXjcnDz+F7cOn0FO4oqa53+nV/qJSnWxc3je+mPo0iYrdhSyMa8MmJcDsb2aWt3OCKyv9a9ocPR1qyu5W/A8GvD1pRpmry9ZzbZqf3bEf/NI+ArgzZ9oe9ZYWtXRESkhpwFMPMaqCyG+DQwnJBfAi43JLaBgg3W/tOmKVkm0pysmwNl+ZDYGrqeaHc01SzMziNgmlX3sEoq/WwvrKj1WG8gyAsLfqla/iActhWWU1Thp8JXfaZYSpybVkkxVc89LgcB02Rhdp4SZdJwq2fC9pXgjofjrwPDYMH6XTWSyEHTZHthBUETYt0OWiXF4AuYStpKoxCRRNm4ceOYNm0a115b+02gV199lSeffBLDMDjttIbXJL/nnntYt24dAIsXLz7ocaZp1jrrSY7ckKw07p3Yr9batE7DICPVpgVF/V7Ingc5X0JFIcSmQOYIyBplrREl0gS9v9SaTXZi79YkxkTkz72IHI6Bv7USZatnwdG/t+q8h8HSTQWs31mCx+VgYvxyWP49OD0w6maVXBQRkcjxe62ZZJXFkNjWmi5Rlg+Y4IoDTyK4E6Bku3XcxbP0WU2kOQgGrYFjAP3OAWd0fXYtLPdVLSkSNE12FVcCViLqwKItpmmSFOumV9ukfduq7d/vMdVnpB34tPbzTYrKfRRX+IlxOartczlr3t80MCis8B3kOxOpp5Jd8O1T1uNjL7US2tRMIoPJjqIKa8kdh0HblFgMw8DjMpS0lUYhIq8+N910E4MHD2blypWcd955+Hw+1qxZw+rVq3n11Vd59913MU2T1q1bc/vttze4vSuvvJJrr72W9u3bk5mZidvtrnFMMBhkzZo17Nq1q8HtSXVDstJ4Y/IwFqzPZWF2HoUVPlJi3QzNSmN4t/TIzyQ7sLTHXivegpROKu0hTdKOogq+y8kH4LT+7W2ORkRq1eFoaNULdq22Ss0ce1lYmnnrB2s22W+6e0hYvOcDzjF/gBadwtKeiIhIrbLnWZ/J4tP21RSrKLS+xqZYXw0D4tKgcJN1fI9xdkQqIpG08Rso2GQly3udanc0NaTEuauSWnklXgJBE7fTIKNlXI3B99sKyxnXpw23ntI7bPHcO3sV7y7eTLuUuDqPNTFJia15T1TksHw9Dbyl0LoPHDWxavP+SWSA3WU+SiutcqDtUmJx7TcoU0lbaQwikihLTU1lzpw5nH322Tz//POYpkmfPn0AazQEQNeuXZk+fXq9yjTW5ZJLLuHRRx9l7dq1OJ3Ogx63c+dOMjIyGtye1ORxORjdq7X9IwUOLO3h3G9EYsCr0h7SZM1cthXThEGdWpCRGm93OCJSG8OAgRfAJ7fDjzNgwPngSQhpE6u2FbFySyFOA84qe9NaB6Z1b+h/XkjbERERqVPOl9bAxb2fyXxlEPSC4YCYfbMvcHmsNVByvlSiTKQ5WPa69bXPGeCJvs+uQ7PSmLFkC8UVPgrLrRv9rZJiaiTJvP4gTsNgaJgrKO2Nx+sPHnIgeqTikSbuly/hly/A4YQT/lKtIsn+SeQyr5+8Ei9g9Y9Yd/X78UraSmMQsfnM3bt3Z8mSJcycOZNPPvmEnJwc/H4/HTp04MQTT+Tcc8+tdebXkUhMTOTmm28+ZJIMoHXr1vz5z38OSZsShWor7bE/p8fartIe0sSUewN88tMOAE4foNlkIlEtcwS0yLBG0a6aCQMmhfTy7+xZm+yS1uuI3/YdON0wUiUXRUTEBntnj+3lcEJMsvXVOPB1yah5vIg0PdtXwvYV1nvUKF07d3i3dNq3iOOnbUUYQHKcm3hP9duppmmSX+olIzWO4d3Swx5Ph5ZxbMovp01yzYRdpOORJqyyBBY8aj0ecD6kda22e2/SttznZ0eRVZI0KdZFSlz1/qGkrTQWES3863A4OOOMMzjjjDPC3tbkyZMBWLJkCZs3b65a+2zNmjV4PB66dOkCwP333x/2WMQmtZX28JVZC0/updIe0gR9tnonZd4A7VvEcnSn8Kx5JCIh4nDAgAtg/v2w/C2rlEWIBm3k5Jby3S/5JJuF/LrobWvj0RdBapeQXF9EROSw7C2vuJczBpIOVlHGrHm8iDQ9e9cm6zYWEqLzJrrH5WBIVio/bi0iiElKXPVB/l5/kPxSL0mxLm4e3yvsy414XA5uHt+LW6evYEdRJakJnmptRjoeacK+fwZKcyGlo7Wm9gH2JpFXbSsCIMbtpFVSDOxXjlFJW2lMmuxfy2+++YbevXtzzDHHcOmll1ZtT0hI4JZbbuG8886joKDAvgAl/Gor7VG4CQo2Um051P1Le4g0csGgyQfLtwJwav/2OA5cXVhEok/3sZDQCsryYN3HIbvsO4s2g2lyjecDYgOlkN7DGgkoIiJih8wR1gCRgPfQx/m94HBZx4tI01WwCXK+sh4PiN6y4FsLyvnul3w6toyjc2o8ReU+thWWs72wgm2F5RSUWUmAeyf2Y0iEZswMyUrj3on9yEiNo6DMa3s80gRtXwk//c96POIGcMXUOMTjctC7XTJBEwKmSXqiB8d+Mxy9/iA7iiqVtJVGI6Izyvb39ddf8+yzz7Jr1y769+/P1VdfTdu2bUNy7RUrVjBu3DhKS0tr7OvYsSNvvvkmZ511FiNGjGDBggUkJyeHpF2JMtVKdZhQYpWiwxXL/qMbLCrtIU3Dkk0FbN5dTpzbyUm9bV4jUETqx+m21gz75jFY9gb0nNDg0ojbCsv5ct0uBvmWMMC5EjweGHULOG176yciIs1d1ihI6WStE11baXwA04TyPGjR2TpeRJqu5W9afb7zcGiZaXc0tTJNkyfmrccXMDmuWxp/n9CHr3/OY2F2HoUVPlJi3QzNSmN4t/SIJwGGZKXxxuRhLFifGxXxSBPi98IXD1j9s+cp0OHoWg/7bPUOVmwppGNqHG6HQUGZtY6fgYGJidMwyEiN4+bxvZS0lUYhbHdL5s6dy8MPP0xOTg7dunXjhhtu4IQTTgDgxRdf5LLLLsM0rVk9s2fP5rHHHmPmzJlVxzTE7bffjtfrZfLkyQwaNIh//vOfNY654YYbOP7447nzzjt58MEHG9zmgb788ktuvfVWfvjhBxISEhg/fjz33XcfGRkZIW9LDmL/Uh3lu62Ri4YLEmqb6qvSHtI0zFxmzSYb26dNjbrpIhLFep8Ki1+Cws2Q/Tl0O6lBl5u+eAtxgWIu5n/Euhww6Lc1asqLiIhElMsDY6bAzGusdaLj0/ZV/wDrxlx5HsQkWcdp/WiRpqssH9buqaQQxbPJ5q3ZxbJNhbidBleM6kaM28noXq0Z3Ss6BqV6XI6oikeaiGWvwe4ciGsJQy+v9ZDsXSU89tl6AC47PouzB3dU0lYavbDcRX355Ze5+OKLq56vXr2aWbNm8dprr3HCCSdwzTXXYJpmVaIMoLi4mDPPPJP169fTsmXD1tSZP38+L774Iuefb5UX+te//lXjmL1rlL399tshT5StWLGCMWPG4PF4aNmyJdu3b+e1115j3rx5/PDDD7Rrd7A67BJSmSNgxVtWycXSPGtbYquaC0WrtIc0EVsKylm0YTeGARP66++MSKPijrMWMF/0Iix9DbqeWPtI+3rIK6nk01U7uKD8XdolVkJaDytRJiIiYrfM4XDaNPh0ilUWP+jHqvZhWp/JWnS2kmSZw+2NU0TC68fp1mDm1n2gbX+7o6lVYbmPZ7/KBmDSrzrRvkWczRGJRMDuDbDkFevxcVdDbM0qbMUVPu6ZvQpfwGRw55ZMOjYDh8NQ0lYavZCndLds2cKf/vQnTNPE4XDQpk0bnE4nwWCQK664ghdffJGSkhKSkpL429/+xqxZs3juuefo06cPBQUFPPbYYw2OITExsSpJdjC//PILADt27Ghwewe66aabePTRR9m9ezfbtm3ju+++IyMjg61bt9Y6u03CZG9pj8LNYAbAFQcxB/yB31vaIyVDpT2k0ftgz2yyYzqn6k28SGPUd6KVMMtbD5u+O+LLzFi6lT4VSxnGcuI8bhh5i1XeUUREJBpkDoeLZ1kJswHnQ8+Tra+nTbO2K0km0rR5y+DHGdbjAZOOeHBYuD3/1S8UlfvplBbPxEEd7A5HJPyCQfjyQQj4IGOINXizxiEmD81Zy46iStokx3LDuB44HNHZh0UOV8gTZa+88grl5eVcfPHFbNu2ja1bt7J7927+8Y9/UFhYyJ133kliYiJfffUVd955JyeffDKXXHIJ33zzDX379mXu3LkNjqFNmzb4fL5DHvPvf/8bgA4dQvtiV1ZWxgknnMDll1+Oy2VN2Dv22GN5/PHHAVi1alVI25NDcHmsNV+CAWukYnxq9f1+r1XyQ6U9pAkorfQzd9VOAE4boNlkIo1SbAr0OtV6vPTVI7pEcYWPL5av5+zyt2mZ4IGBF0CrHiEMUkREJARcHugxDsb9A06fZn3tMU6fyUSagzWzobIYUjpGbWWfZZsK+Gz1TgwDrhrdDZdTpeOkGVj9AWxbbg3eHHF9rUnsN3/YxKINu3E7Df56Si+SYjUgU5qOkJde/Pjjj/nNb37D888/X7UtISGB2267jdLSUu677z5uu+02+vbtW+28pKQk7rvvPiZPntzgGM4880xuu+22g87euvvuu3nzzTcxDIOzzz67we3tLy4ujltuuaXG9lGjRgHQuXPnQ55fWVlJZWVlrfuKiooA8Pl8dSYCBQh4ca6fCykdMQJeqCyBikKqSnsYTsyUTgRP/Dtmh1+B/k8bHTv7QbT11Y9XbqPM66djyziOapugvxESVdRXD0OfiThXToetSwlsXgptjjqs02cs3szJRW+T5igltlUvfP0v0Oub1Fu09IMD++3evioi9mt0r6siNtJ74FoEAziXvwWmSfCoszADAQgEIhtDHbz+II99tg7TNPl1nzZ0S4/T37QmTn0VKMvDufA/Vt8cdBFmbFqNz5GLNxbw2rcbME340wlZZLSIUd+QiAr371vIE2Vr165l5syZte77wx/+wH333XfQ5NSYMWMoLi5ucAzXXXcdw4YNY+nSpZx77rmUlZXx8ccfs3r1al599VUWLVoEQNeuXfnrX//a4Pb2Zxxkyvje7+uCCy445Pn33nsvU6dOPeQxc+bMIT4+/sgCbEY65c2ny66f8LoS+b7zX0gtW096ySrcgTJ8znhyE3uzK+kozJUFsHK23eHKESgrK7Ot7Wjqq0ETXljjoNBrcGzibj78cEvY2xQ5HOqrh6eH2Zl2hYvJ/d89/Njxwnqf5w3Akp/WMtn/HS6PwXyGUvzxp2GMVJoaO/vq/urTb0XEHo3xdVXELnoPXFOrohX02boGryuBb9cHCWZH372Yr7YbrN7pIMFl0rown9mzVRmqqVNfhT5b3qRV8VaKYzuweEMsbKzeNwsq4ZX1DioCBgPSgpT//D2zfw5rSCI1hLuvGqZpmqG8YNu2bdm+fftB93s8HioqKnA4ap+2nJmZSU5OToPjyM3N5aKLLuLDDz8E9iWw9n67xx9/PK+//nrISy8ezFNPPcWcOXN49913D3lcXSMJMjIyyM3NJTm55mKKsp/ibTinXwr+SoKj/orZ9SS7I5IwKCoqIj09ncLCwoj3iWjqq9/n7OaeD9eQEOPk2d8dTazbGfY2RQ6H+uphKtyE891LwDQJTHwWWnap12mzflhHxmdXkmaU0PGEizCH/F+YA5Wmxs6+ur/aZpRlZGTYHpdItCgqKiIlJUWvqyJRTu+BD2CaON+/HHLXETz6YsxBv4tc2/W0Mb+M695eTjAIN/26O8Oy0uwOSSKgufdVY+PXOD75OxgOAmf8B9K6VY/RH+SW6SvJySuje5tE7jq9Dx6XypFK5IW7r4Z8RllCQsIh93fo0OGgSbJQSk9PZ9asWSxfvpw5c+aQk5OD3++nQ4cOnHjiiQwfHrkFgsvLy3n11Vd588036zw2JiaGmJiYQx7jdrtxu1UD9pC+fwoCXugwCEfPX0ft4rDSMHb2g2jqq7N/3IFhGPz6qHYkxceGvT2Rw6W+epjSsyBrJGTPx7HybTjxtjpP8fqDmAv/Q3KwiLi2XXAN/SO4ouh7kkYhWvpBffqtiNijUb6uithE74EPsHkR5K0HdxyO/mdBlP2dCAZNnvwiB9M0GJKVyogebQ5aNUqalmbdV72l8M2/rfumA8/H0bZ3td2mafLYvHVsyC+nRbyH2yb0ISFO79PFHuHuqyFPlJWXlx9yf11Jst27dzc4htLS0qqEXf/+/enfv3+Dr3mgLVu2cNJJNWcpzZ07t8Ystdtvv51//etftGvXLuRxSC02fAM5X4HDCcP/rCSZNGkb88pYtqkQhwET+utvjEiTMfBCyJ4P6z+FY/4AyYfu34u/+oi+JV/jdDpIPeV2cOnDi4iIiIhEkeVvWF97ngyxKfbGUos5P21n9fZi4txO/jSyq5Jk0jx89wyU7oLkDjD44hq7P/5xO5+t3onDgJvG9yQ9UZ8zpekKeaJs586dlJeXExcXV2NfWVkZu3btOui527Zto6SkpMExtG/fnp07d4Z1JKrP52PNmjW1bt/fCy+8wLhx4xg0aFDYYpH9+Cvh62nW437nQGr9ylWJNFYzl28FYEhWGm2SNZtMpMlo1RM6HgObf4Dlb8Lxfz7ooYGKYhK+fQSAsh6/wd0h9AOERERERESOWN7PsOk7MBzQ/zy7o6khv9TLCwtyALhwaCdaJSkZIM3A9pXw0wzr8Ygbagy2XLO9mCfnZwPw+2GZ9O/YIrLxiURYyGsgBoNBEhMTcTqdNf4lJSVRWlpa6z6n00nHjh1DEkNxcTEjRozgs88+C8n1apOZmYlpmjX+ZWZmVh0zffp0WrduzdixY8MWhxxg6WtQtBUSWsHRF9kdjUhYFVf4+Hz1TgBOH9De5mhEJOQGXmh9XT0LyvIPetjG2Q8T682n0N2Krqf8OTKxiYiIiIjU17I9s8myRtVZKcEOT3+RTZk3QPfWiZzWX5+tpRkI+ODLB8E0ocd46Di42u6CMi/3friKQNDkuK5pTDy6w0EuJNJ0hGWxsNoSSPX9FwoOh4Px48dz7733MnDgQJ577rmDLowYLm+99RZOp5MJEyZU2/7555/z0ksvRTSWZqNoq5UoAxh2BXji7Y1HJMw++WkHlf4gmekJHNVeC6aLNDntB0HrPtaamyvfrfUQc/MPONd8AEDu4D8TF3/otWJFRERERCKqZCf8PNd6PGCSvbHU4rtf8lmwPheHAVed2A2HQyUXpRlY9gbk/2KVQR12RbVdgaDJPz9eQ16Jl44t47h2THeVIpVmIeSlFwEmTpxIr169DmuBtcrKStasWcOMGTMa3P7pp5/OnXfeCcDq1at57LHHuPvuuzn//PO58sorad8+vKNDnnjiCW699VbatWvHzTffDFjJw6KiIrZv384vv/wS1vabJdOEBdOsm4kdBkPWaLsjEgmrQNBk1vJtgDWbTG9aRJogw4CBF8Ccv8GPM6zHnv0SYd4yCj+6m0p/kG/jRnLGiJprp4qIiIiI2GrF2xAMWIPAWvW0O5pqyr0Bnpz/MwBnDOxAVqtEmyMSiYCCTbD4v9bj466usWbgy9/ksGJzIXFuJ389pTfxnrCkD0SiTsh/03/zm9/wzjvvHPH5F198cYNjmD59etXjXr168dhjj1FUVMQLL7zA2LFjGTBgANdeey1DhgxpcFsHeuaZZ7jyyisBKCoqqrH/2GOPrVaeUUJkw9ew8RtwuGD4tdbNRZEm7Ntf8thZXElSrIsTeqTbHY6IhEvn4dCyszXa77O7weGEikKITcEszaV412Z2O1IJ/uoykmLrP0BJRERERCTsKothlVX9gAHn2xtLLV79dgO7iitpkxzDBUM62R2OSPgFg/DFA9ZEg4xfQbcx1XZ/vT6XdxdvAeCak7qTkapqXdJ8hLz04qBBgxp0/tFHHx2iSKpLTk7m2muvZfny5SQlJXHccccxbNgwXn/99ZC288c//vGQpSW/++67kLYngK8Cvp5mPe5/nnVDUaSJm7lsKwAn921LjMtpczQiEjYOB7QbCHnr4ftnYNnrsOZDWPIy5oq3SK/cwKKYX3Hq4G52RyoiIiIiUt1P74OvDFK7WDflo8j6ncVVn6svH9WVWLc+V0szsPZD2LYMXLFw/PXVJhps3l3Go5+uA+A3gzpwfHcNypbmJeSJsttuu61B51911VUhiqS68vJyHn/8cXr37s2zzz6LaZosXbqUzz77LCztSQQtfQWKt0Niazj6d3ZHIxJ22btKWLmlCIcBJ/eLvoWQRSSEchbAklch6Lc+xHgSIKktBAP4gw5MDCYFZpK663u7IxURERER2cfvhZV7Kk4NOD+qKv8Egib//mw9QRNGdE9ncOdUu0MSCb+yfFj4H+vxMX+A5H33k8q9Ae6dvZpyX4C+HZK5+LhMe2IUsVHIE2UOR8Mu2dDzAY455piqx1u3buWWW26hY8eOXHPNNaxfv55WrVoxZcoUNm7cyDPPPNPg9sRGBZusBSgBhl0F7jh74xGJgJnLrLXJhndLJz0xxuZoRCRs/F74dAp4i63kmOGwPtyU5hIM+PAZLrY52pFslFvH+b12RywiIiIiYln/qfXeNaEVdD3R7miqmblsK9m7SkmIcTL5hCy7wxGJjK+nWeVQW/WEfmdXbTZNk2mfrWNjfhmpCR5uHt8LpyN6EtsikdIkV+NbvHgxl19+Obt27WLmzJn4/X5M06Rv375cd911XHjhhXg8HrvDlIYyTeuPfMBnTeHvcoLdEYmEXWG5j/lrdwJw2oD2NkcjImGVPQ8KN0J8GkGHi2BJHkGfF7x5BE3INdJJiIvBGR8HhZus43uMsztqEREREWnugkGrZDhYN+Sd0bOW7o6iCl5ZuAGAS4Z3oUW87g9KM7Dha/j5c2vw5Qk3Wmtf7/H+sq18tS4Xp8PglpN7qU9Is9UkE2UATz/9NKZpYhgG48eP5/rrr+ekk06yOywJpV++gE3fWW+4jrsmqqbxi4TLxyu34wuYdG+dSK+2SXaHIyLhlPMlBIOUBBxszy8j3h9PSwoBKDLjKQp6iK3wkxgbS2LQbx2vRJmIiIiI2G3jN1Cw0Sob3vs0u6OpYpom/5n3M5X+IEe1T2Zs7zZ2hyQSft4y+OoR63H/8yC9e9WulVsKef6rXwC4bEQXerdLtiNCkajQZBNlLpeLiy++mOuvv56ePXvaHY6Emq8cvnnMejxgErTIsDcekQjwB4LMXmmVXTxtQHsMJYdFmraKQrzBIFt2lxMIAo4kUsxSgibk0QKnw8AXMNmyu5wuHhNPRaHdEYuIiIiIwPI9S2T0Pt1KlkWJr9bnsmjDbpwOgytHd8Oh8nLSHHz/LJTshKR2MPjiqs15JZXc/9FqgiaM7tmKCf3aHfwaIs1Ak02UvfPOO5x2Wt2jVk4++WQ+/PDDCEQkIbXklT1/5NvCwN/aHY1IRHz9cx55JV5axLsZ3i3d7nBEJMwCMcmUVvgJmOB2GpgYbDXa4vWbmBh4HA4MA3wBk9JKP86YZJx1X1ZEREREJHx2/AjbloPDVW0dJLsVV/h4+otsAM49JoOM1HibIxKJgJ2r4Mfp1uMT/gLuWAB8gSD3fbiagjIfmekJXDG6mwZjS7PnsDuAcLjsssvqlST76aef+OSTTyIQkYTU7g2wbM/opOOurvojL9LUzVy2FYCT+7bD42qSf75FZD8r3f3xmwaxDn/VNn/QSpg5jH0Vh2Mdfnymg5Xu/jZFKiIiIiKyx977Nd3HQUL0DPD87zcbKCjz0aFFHGcP7mh3OCLhF/DD/H+CaVr9seMxVbue/+oXVm8vJt7j5NaTexHr1pBLkbDdaX3++efp378/CQkJ9OjRg7vvvhu/31/3iSHw9NNP13nMnDlzmDBhAqZpRiAiCRnThAX/gqAfOg2DzsPtjkgkItbtKGb19mKcDoOT+7a1OxwRiYCPynqxlVa0MIus1z8gELS+OveWiTFNWphFbCOdj8p62RWqiIiIiAgUbLLWzQXof669seznx62FfLRyOwBXndhNA0+leVj+BuRnQ2wyDLuiavPna3bywXJrWY8bxvWkfYs4uyIUiSphKb1488038+CDDwLWQpk///wzt99+O99//z0zZswIR5P1Ypom06dP56GHHuLbb7/FNE1NK21ssufBlkXg9FizyfTzk2Zi72yyE7qn0zLBY3M0IhIJuyvhcedvud18ijQzn91mEuDCMMBhGLhMHylmEWVGPI87fkuq1+6IRURERKRZW/GWNcCr0zBI7WJ3NIBVYu6Jz38GYGyfNvTtkGJzRCJh4Pda90xzvoSKQjAckLPAqsI17GqIawnAL7mlPPbZegDOOzaDX3VJtTFokegS8kTZokWLeOCBBzAMo2q21t6vM2fO5K233uLccyM7qqSsrIznnnuORx99lJycHM0ia6y8ZfDN49bjgRdASgd74xGJkN2lXr5YlwvAaQPa2xyNiERKSpybT40+PJZwDReVvUi6fwfJBDAwcAYhiIMdzra8FH8xi8u6clas2+6QRURERKS5KsuHNR9ZjwdMsjeW/UxfvJmN+WW0iHdzyfBMu8MRCb2cBfDpFCjcCMGgta2yyKrGFZcKHms9vpJKP/fOXoXXH+ToTi244Fed7ItZJAqFPFH2zDPPANC9e3ceeughRo4cSX5+Pi+++CJ33XUXr7/+esQSZVu3bmXatGk8/fTTFBYWViXIjj32WCZNmkRxcTFTp06NSCwSAov/C6W7ILm9lSgTaSY+XLmdQNCkV9skurdJsjscEYmQoVlpzFiyhSVGH9Yk30vH3d8yMLiS1u4KvK5kVrj7scw9kLKAE6fhZWhWmt0hi4iIiEhz9eN7EPBC697QboDd0QCwpaCcN7/fBMClx3chSQPLpKnJWQAzr4HKYohPsypwVRSCtxgcbjCDMPNagqf+i0d+TGVbYQWtk2K44dc9cThUpUtkfyFPlH377bekpaXx5Zdf0qpVKwASExO5/fbbcbvdPP/886FusoalS5fy0EMP8fbbb+Pz+TBNE6fTyYUXXshVV13FMcfsW7zw8ccfD3s8EgL5v1hT+AGOuwZcMfbGIxIhXn+QD1dataM1m0ykeRneLZ0OLePYlF+OM8nDp/6BfMpAOifG43Za6yqYpkl+aSUZqXEM7xY9i6WLiIiISDPiK7cSZWDNJouCZTJM0+Txz9fjC5gc3akFI3u0sjskkdDye62ZZJXFkNjW6nfBgDXJACCxFcS2hJLt5P/vNhY7puB2ebj1lF4kK2ksUkPIV6/cvHkzkyZNqkqS7e/KK6+krKzskOdv27btiNueNWsWJ510EoMHD+a1117D6/WSmprK7bffTmZmJi+++GK1JBnAmjVrjrg9iRDThAWPWn/sOw+HzsPsjkgkYhasz6WgzEdaoofjumq2iEhz4nE5uHl8L5JiXWwtrCBomricRlWSzOsPsqOokqRYFzeP76VFyUVERETEHms+tG7WJ3eAzBPsjgaAuat2smJzIR6XgytGd8OIguSdSEhlz7PKLcan7UtOl+4EMwDOWKvsomFQ5mqBUbSRAb6lXD6qG91aq1KRSG1CfkeluLiYHj161LovOTmZjIyMQ54/fPjww2qvsrKSZ555hj59+nD66afz+eefY5omnTp1Ytq0aWzcuJEpU6bgdteeKW/RosVhtSc2+HkubF1qTR8+7mq7oxGJGNM0mblsKwCn9G2Hy6mb4CLNzZCsNO6d2I+kGBeBoEkgYLK9sIJtheUUlHnJSI3j3on9GKKyiyIiIiJih2AAlu+pANT/HHDY/7m1sMzHc1/9AsAFv+pEm+RYmyMSCYOcL601yZwe67m31FqbDAOS2gDgC5psLw3iMIOcnvIzY/u0sS9ekSgX8tKLXq+X0tLSWvf5fD7atDl4h9y4cSObN28+rPYGDx7MqlWrqtYfGzhwIDfeeCPnnnsuTqfzsK4lUchbCt88YT0++neQ3M7eeEQiaPX2YtbtLMHtNPh137Z2hyMiNhmSlcavuqTyw4bd9GyTRGqih5RYN0Oz0hjeLV0zyURERETEPtnzoHgbxKZAj5PtjgaA577KpqTST5f0BM4YqCUMpImqKKx6GATK/E4MMxaf4aK8FOJjfBSW+QgETZwOBwNaaValyKGEPFEG8PLLL7N27doa28vKyli7di1/+MMfauwrKSnhq6++IhAIHFZbixYt4vnnn+eRRx5h586dXHHFFZxzzjlKkjUVP7wAZXmQ0hH6T7I7GpGI2jubbGSP1qTEqX60SHNV4Qvw865SkmPdTD3jKNqlxNkdkoiIiIiItVTG8jetx0edCW77Z24t2bibz9fswjDgqhO7qTKLNF2xKQCUeP1sL6zAFzAxzZYYgOnzkrdnHkuMy0FCjBNnXAvbQhVpDMKSKFu9ejWrV68+6P7akmhglRk73JrBMTExXH755fzpT3/i3Xff5cEHH2Tq1KnccMMNTJ48mfj4+MO6nkSRvJ9h5bvW4+OuAZfH3nhEIii3pJIF63MBOG2AZlKKNGdrthcTCJqkJXpoq7IxIiIiIhItti6BXWvAFWMlymxW4Qvw+Oc/AzChXzt6tNFaTNKEZY7Au+QNduQX4TXduJwGBtZ99YBpEgyYVgW2gJeA6cCZOcLmgEWiW1gSZaZp0qpVq8NKUpWXl7Nz584jbtMwDM4++2zOPvts5s+fz4MPPsjdd9/NVVddxdVXa12rRsc0YcGjYAahywnQaYjdEYlE1IcrthE0oW+HZLJaJdodjojYaMUWq6RG3/YpWoRcRERERKLHsjesrz1PhiiYrfLm95vYUVRBWqKH3w/LtDsckbDydj6BbF8aaeY2Chz71qw2TfAHrCWKXA6DFhSR7WtHVucT0BQEkYMLS6Lsiy++4Pjjjz/s8z799FN+/etfN7j9kSNHMnLkSH788UceeughunXrhsPhYOPGjXTq1Knaseeffz6vv/56g9uUEFv3CWxbDq5YGHaV3dGIRFSlP8CHK7cDcNoA1VMXae5+3LonUdYh2eZIRERERET2yPsZNn0LhgP6nWt3NPySW8r0JVsA+NPIrsR5tCSLNG0LfiniDfN8/uZ4ijQzn0KS8RtufMEgADGGjzSjhFIjgUfM85n0SxGje6lCicjBhLxQb7t27Y4oSQYwZswY2rRpE7JYjjrqKJ5//nlWrFjBH/7wBwYNGsQ555zD119/DUBubi7Tp08PWXsSIpXFsPAJ6/HRv4ek0P1OiDQGX6zNpbjCT+ukGIZ2Sav7BBFpsrz+IGu2FwPQt0OKzdGIiIiIiOyxd22yLidASgdbQwkGTR77bD3BoMmwrmkMzdLnaGn6Fmbnscjow+OJ17DD2ZZks5jUwC5am/m0NfJoaZSyw9mWxxOvYZHRh4XZeXaHLBLVQj6j7LHHHmvQ+Y8//niIItmnQ4cO/POf/+Tvf/87Tz75JOeeey5utxvTNPH7/SFvTxrohxegfDe0yID+9o9KEokk0zSZuWwrABP6t8PhUJk1keZs7Y5ifAGTFvFuOrSIszscEREREREo2QnrP7UeDzjf3liA2Su3sXZHMXFuJ5NPyLI7HJGIKCz3YWDwo7svf02+l+6lP9CzfBlJRhl4kvkpZgDL3APxG24MKiis8NkdskhUC/mMsjPPPLzFO5cuXcprr71GaWnpEZ1/OJKSkrjxxhvJzs7muuuuY/fu3WFrS45Q7nr48T3r8fDrwOm2Nx6RCPtxaxG/5JYS43Iwto9mU4o0d3vXJ+vXQeuTiYiIiEiUWPEOBAPQfiC07mVrKLkllfz36w0A/P64zqQnxtgaj0ikpMS5MbHWIvMbbn5KHMpzcZfwROLVvJx0GYs8x+I3rPuqJiYpsbrHKnIoIU+UHa6BAwfSuXNnRo0axdlnn80777wT9jY9Hg/XXHMNc+bMCXtbchiCQfjqETCD0HU0dBxsd0QiEbd3NtnoXq1J0psYkWZvb6JMZRdFREREJCpUlsCqmdbjKJhN9vQX2ZT7AvRok8QpfdvZHY5IxAzNSsNpGHj91ppkBgZpiTE17iV5/UGchqGSpCJ1CHnpxSMxfPhw5s+fz+jRoznvvPMIBAIRaXfIkCFccMEFEWlL6mHdx7BjJbjjYOiVdkcjEhFef5AF63NZmJ3H9qIKvl6fS3yMi/FHtbU7NBGxmdcfZPW2IgD6tleiTERERESiwKqZ4CuDlpmQMcTWUBZm5/HNz3k4HAZXndhNSxdIszK8WzodWsaxKb+cNskxtVYgMU2T/FIvGalxDO+WbkOUIo2H7TPK9oqPj2/w+mZH4uWXXw7LdX/44QfGjh1LSkoKLVu25He/+x35+flhaatJqCiCb5+0Hh99ESS2sjcekQj4NjuPSU9/wy3vLufdxZv5dNUO8st87Cyq5MZ3lvGtFloVadbW7bTWJ0uJc5ORqvXJRERERMRmfi+seNt6PGAS2FgavNwb4Mn5PwMwcVAHuqQn2BaLiB08Lgc3j+9FUqyLHUWVVTPL9vL6g+woqiQp1sXN43vhcUVNGkAkKkVVDzn22GOJi2v8N4KWLFnCQw89xG233cbs2bMZPXo0r7zyCueee67doUWvH56D8gJrRFK/c+yORiTsvs3O49bpK9iUX06LeA9tkmPBBI/TQatED5vyy7l1+goly0SasR+3WLPJjuqQrPXJRERERMR+6z+FsjxISIduY2wN5eWFOeSVeGmTHMukX2XYGouIXYZkpXHvxH5kpMZRUOZlW2E52wsr2FZYTkGZNZPs3on9GKKyiyJ1iorSi/tLT2/800CXLFnCa6+9VnVTa8iQIfTu3Zu5c+eye/duWrZsaXOEUWbXGvjpf9bj4deCM+p+LUVCyusPcv9Hqymu8FdNjy8s9xE0weU0SI53k2zCjqJK7v9oNW9MHqaRPyLN0N71yfppfTIRERERsYPfC9nzIOdLa3Dzxq+t9eWPvQyc9q2pvXZHMR8s3wbAlaO7EuNy2haLiN2GZKXxxuRhVct6FFb4SIl1MzQrjeHd0nU/SaSeoi4j4fF47A6hwf7whz9Ue+5yuTj66KMpKCggOTnZpqiiVDAIXz0KpgndToIOR9sdkUjYLVify5bd5aQmePYk1E0Ky30AtIhzY2CAAakJHrbsLmfB+lxG92ptb9AiElH+QJBVWp9MREREROySswA+nQKFG617N0EfVBSDw4BFL0BqFmQOj3hY/kCQxz5bj2nC6J6tGNRJg9FFPC4Ho3u11r0jkQYIeaLsvvvu45Zbbgn1ZRu9VatW8cgjj+B0apRLNWtmw86fwB0PQ6+wOxqRiFiYnUfANKtG9ZR5A3j9QQwDkuP2jcrzuBwETJOF2Xl6syPSzKzbWUKlP0hSrItOqfF2hyMiIiIizUnOAph5DVQWQ3waOD1QuAlcbohJhsLN1v7TpoU1Web1B/fNkin3kRLnJhA0+XlXCcmxbi49PitsbYuISPMS8kTZgw8+2KBEWTAYrPugRubhhx/m1FNP5be//W2dx1ZWVlJZWVnrvqIia2S5z+fD5/OFNEZbVBTh/PZJME2Cg36P6UmBpvB9ScTY2Q8a0ld3l1rnmaZZtS3G5SDG7cA4YPve45tEn5dmq7H2VTst25iPaZr0bptIIOAnELA7ImkOoqUfHNhv9/ZVEbFfY31dFbFDo30PHPDi/OQOjIoizMS2YBjgK8fwloFhYMang+HEKNmO+ckdBH73PyuRFmLf5eTz4Jx1bCmoILjnM3IgaFJS6cflMLhiZBbx7uh5/yKNV6PtqyLNTLj7QcgTZfn5+fzwww8cc8wxh32u1+slNzc31CHZZsaMGfznP/9hzpw5OJ1O4uPj+dvf/nbIc+69916mTp16yGPmzJlDfHzjH13effv7tC/YRGlMaxZtiMHcONvukKSRKSsrs63thvTV3G0OKisNCgv3vRlKcoAZgMLCimrHVnohd9smZs/eEJrARWzQWPuqnWb/4qCw2MC3czezZ/9sdzjSTNjZV/dXn34rIvZorK+rInZorO+BWxcuY+DOdXgdiZh7btTH+nbjCgTwOeOpLC4FwAh68Oxcx9K3HmJnyoCQxr++CN782Ul5ABJdELNniaXdXjCD4A/Cf79ah3fbarpphRNpoMbaV0Wam3D3VcM8cOpCAzkcDlq2bMno0aMPaz0uv9/P8uXLWbFiBYEmMmza6/Wyfv16nn32WaZNm0YgEGDWrFmccsopBz2nrpEEGRkZ5ObmNv61znatxjnzKjBNAhMegbb97Y5IGqGioiLS09MpLCyMeJ9oSF+dt3YXt834iRZx7kMuqur1Byko93H3b/owqkerkMUuEmmNta/aJRA0+e3z31PhC/LwOf3okp5gd0jSTNjZV/dX24yyjIwM2+MSiRZFRUWkpKTodVUkyjXW98COuVNwrHgTM6m9tSHow9j9C5hgtsysNnvMKN5KsN95BE+aErLYvf4gv33+ezbvLqd1Usyedb2huNLPjqIKDAwyWsayu8xHx5ZxvPKHYw/5uVqkLo21r4o0N+HuqyGfUQZQUFDAe++9d9jnmaZZ9QIY7bZs2cJJJ51UY/vcuXPp0KEDAB6Phz59+vDwww/Tp08f/vjHP/L6668fMlEWExNDTEzMIdt2u9243e5DHhPVgkFY+Jj1uMevcWQMtjceabTs7AcN6asje7alY8tf2JRfTpvkmFr/7pmmye4yHxmpcYzs2Ra33vhLI9ZY+6pdftlRTKXfJCnWTbc2KTgcjeO9kTR+0dIP6tNvRcQejfF1VcQujfY9sLcYMPZ9Tg34wHCCOxbDdeA1DZzeYpwh/F6/+nknWwsqSE2IweGwPgcHgiZ5JV4MDFITPMS4XaQmONhaUMF3Gwq1prc0SKPtqyLNTLj7QVgSZaZpkpaWRmJiYr3PCQaD5OXlUV5eHo6QajVjxgymTp3KkiVLDvtcn8/HmjVrat1em0suuYS//vWv7Nq167DbanJWz4Rdq8GTAEMvtzsakYjzuBzcPL4Xt05fwY6iSlITPNVGwHn9QfJLvSTFurh5fC+NjhNpZlZsLgSgT/tkJclEREREJLJiU6o/9yRAWlcI1lb9yax5fAMtzM4jYJrVPgfnlVQSCFrbWsZbN0o9LgcB02Rhdp4SZSIi0mBhSZTNnTuX0aNHH/Z5gUCA3/72t2GIqLpZs2YxZcoUFi9efMTXyMzM5HCqVjqdTrp06ULPnj2PuM0moXw3fPeM9fiYP0B8qr3xiNhkSFYa907sx/0frWbL7nICpomBgYmJ0zDISI3j5vG9GJKVZneoIhJhK7daibJ+HUJ700FEREREpE6ZI2DFWxDw7ldm0QDHAbcQ/V5rW+aIkDZfWO7DYN9gseIKH0UVfgBaJVWvyGJgUFhR+4B1ERGRwxHyRFm7du2OKEkGVjLp4osvDm1A+/n444+54447+P7774HIlnosKysjOzub5557LiLtRa3vnoHKYkjrBkedaXc0IrYakpXGG5OHsWB9Lguz8yis8JES62ZoVhrDu6VrJplIMxQMmvy41Vo0vW8H1aEXERERkQjLGgUpnaBgAyS2hdrum5kmlOdBi87W8SGUEufGxBqYXuELsLPYWr+pZbybOLezehiYpMSqJJ2IiDRcyBNlsbGxDTp/0KBBIYpkn7lz53LHHXfwzTffAOFNkPn9fq666io6d+7MlVdeSXJyMhUVFVxxxRXcd9999O3bNyztNgrbV8LqWdbj4/8MDuchDxdpDjwuB6N7tVapCBEBIDu3hHJvgDiPk6z0+pewFhEREREJCZcHxkyBmddAyXaIT9tvZhnWTLLyPIhJso5zeQ52pSMyNCuNGUu2UO7zs72wEtOEeI+T1MTq7Xj9QZyGwVBVYRERkRAIeaKsoWtwtW4dupvF8+bN44477uCrr74CqCqVGM5ZZKZpsn37dl577TUeeOABRo0aRceOHbn66qsZPHhw2NqNOn4vZM+DnC+hohBikmHrYjCD0GsCtO1nd4QiIiJRZ+UWazbZUVqfTERERETskjkcTpsGn06Bwk0Q9AMGYFrlFlt0tpJkmcND3vTwbum0bxHHqm3W+2KPy0HblNhq5RhN0yS/1EtGahzDu6WHPAYREWl+Qp4oKykp4Q9/+APnnHMOCQkJR3SNE044oUExfPXVV9xxxx3MmzcPqJkgC+eMMrfbzYwZM8Jy7UYjZ8GeN1MbIRi0tvkrwFcG7jhoN8DW8ERERKLVii3W+mR922t9MhERERGxUeZwuHhW9UHQsSnWmmRZo0I+k2wvt9Oge5tEftxaRBCT9kkxOPa7h+f1B8kv9ZIU6+Lm8b20ZIE0eY899lidFdzatWvH+eefX23b66+/zrZt2+q8/rBhwxg2bFjV88rKSh5//PF6xTZp0iTat29f9Xzt2rV88MEHdZ7n8Xi46qqrqm2bM2cOK1eurPPc7t27c9ppp1Xb9vTTT1NSUlLnuWPHjqVfv32TN3Jzc/nvf/9b53kAf/zjH0lKSqp6vmjRIubPn1/neWlpaVx00UXVtk2fPp2cnJw6zz366KMZNWpUtW0PP/xwveKdOHEimZmZVc9zcnKYPn16vc69/vrrqz2fN28eixcvrvO8zMxMJk6cWG3bSy+9RF5eXp3njhw5stoko+LiYp555plqx1RUVNR5nYYIeaIM4MUXX2T27NnExcXVeWxhYSGFhYVVz3/7298ecaJs4cKF3H777cydOxeoPUEmYZazwJqeX1m8b3p+MAC7f7FKLRoOmPM3a4ZZGEYeiYiINFbBoMlPe9Yn69dRiTIRERERCZ/DuvneY1zVttdff51tHzxW5/WP9Ob72ookcmK7kpEah8thUFDmI7+4Am+ltVaZYZgkOXwMcuWyYMZiFux3rm6+6+b7gaLh5ntDFRcX4/P5DnlMSkrNz49lZWUUFxfXef3KPX3rwDbrIxAIVHvu8/nqda7HUzPRXlFRUa9za/t5lZSU1OvcA/8fg8Fgvb/XA/MKXq+3XufW9nc2Ej8bv99f43l9z60tjvqcW1ZWVmNbaWlpvc71er3VnpumWeO8Rpko+/LLLxk+vO4kyPz585k4cWLVL9pf//pX7rrrrsNu74cffuD222/n448/BpQgs43fa80kqyyuvuBr6S4wA+COtxaELdluHXfxrLCNQBIREWlscvJKKan0E+d20rWV1icTERERkfCJxpvvucF4fvCmkBYDV47uxqn927NgfS4ffLeGFWu24zECtHUU095RhLPSpPiAJnTzXTffDxQNN98bKikpqc6kdnx8fK3b9k/CHkxMTEytbdaH0+ms9tztdtfr3Nr6amxsbL3Ore3/IjGxfp+f3W53tecOh6Pe3+uB1ek8Hk+9zq2t4l4kfjYul6vG8/qeW1sc9Tm3tt/DhISEevWxA38nDMOo0eaBP79QC3mirF27dvVKkv33v/9l8uTJ+Hw+nE4nTz75JJdeeulhtbV48WKmTJnCrFmzACXIbJc9zyq3GJ+2L0nmK4fKPTMGE9tY2+PSrBrX2fOqjUoSERFpzvaWXezTPhmn1icTERERkTCKtpvvJQEnS4ra4XA6GZaZzJmDOmAYBqN7taaDo4APcr/f7+jab4rr5rtuvh8oGm6+N9RVV11FcnLyYZ93YCnG+oqJiakx+6++evToccTnjhs3jnHjjuw+8eTJk4/ovPT09COOd/DgwdVmKx6OA2dIHo4jjTczM/OIzx01alSNWaj1deDM1/pKSkqqEW9RURG33XbbEV2vPgwzxNmk999/n9NPP/2Qx9x2223cd999mKZJYmIib731FuPHjz/stt577z3uuOMOVq5cWe2FpT7fkmEYVWuVHThNNFoVFRWRkpJCYWHhEf2BDLs5f4dlb0Dyvtq07M6BQCXEtrASZXsVbYEB58O4f0Q6SmlCorVPRGtcInaJ1j4RbXHdM3sV3/ycx++HdeacYzLsDkeaoWjrE3tFa1widonWPhGtcYnYJVr7RDTGVeELcOM7y8nJLaVb60TuO6sfMS5n3SeKhEA09gmI3rhE7BLuPhHyFS8PlSTzer1MmjSpKknWtm1b5s+ff0RJMoAzzzyT5cuX8/rrr9OrV69qM8oOHJEhEVBRWP25r8xKkhlOSEg/4GCj5vEiIiLNVDBosnLPjLK+HbQ+mYiIiIg0D6Zp8sina8nJLaVFvJvbJvRWkkxERCIu5Imyg8nNzWXUqFG8/fbbmKZJ7969WbhwIYMGDWrwtc877zxWrlzJyy+/TPfu3ZUws0vsATf23PHQohMktbWSZdWYNY8XERFppjbtLqO4wk+My0H31lqfTERERESah7d/2MzX6/NwOgxuPbk36Yk1ywKKiIiEW0QSZatWrWLIkCF8++23mKbJyJEj+frrr+nUqVPI2jAMgwsvvJCffvqJF154gaysLCXMIi1zBDgcENhvoUxXHHgOuOHn94LDZR0vIiIiVeuT9W6XjMsZsXFMIiIiIiK2+TY7j5cXbgDgTyO70qe9ysuJiIg9wn4n5tNPP2X48OHk5ORgmiYXXHABH3/8MSkp4ZlN5HA4uOiii1i9ejXPPPMMnTt3VsIsUrJGQUonKMuDg60TZ5pQngcpGdbxIiIiUpUo66eyiyIiIiLSDGzMK+OhOWsBmNC/HeP7trU5IhERac7Cmih7+umnmTBhAgUFBZimyS233MIrr7yCx+MJZ7MAOJ1OLr30UtauXcuTTz5JRkZGtYSZhIHLA2OmQEwSlGyvPrMMrJlkJdut/WOmWMeLiIg0c6Zp8tPWIgCO6qBRtCIiIiLStBVX+Lhr1k+U+wL07ZDMZcd3sTskERFp5sKWKLvxxhu5/PLL8fl8OJ1OnnjiCe655546z7vkkktCGofL5WLy5MmsW7eOxx57jPbt21clzCQMMofDadOgRWco3w1FW6Boq/W1Yre1/bRp1nEiIiLC5t3lFJT5cDsNurdOsjscEREREZGwCQRNHvh4DdsKK2idFMMt43ur9LiIiNjOFeoLlpeXc+GFF/K///0P0zRJSEjgjTfeYMKECXWea5omM2bM4IUXXgh1WLjdbq644gouu+wynnzySe6//362bdsW8nbCaW+Cr6ioyOZI6pDaDya+DjlfwoZvoLIIYpKh8zBrXTKXB6L9e5BGYW9fiLbkd6PpqyIRor56aN+t2Y6vvJQeHZKpKCuhwtZopDlTXxVpHNRXRRoH9dXavfxNDt+t2UaMy8E1J2Rh+MspKiq3JRYRUF8VaSzC3VdDnigbMWIES5YswTRNXC4XU6dOJSkpiS+++OKQ51VUVPC///0v7J3f4/FwzTXXMHnyZJ544gkeeOCBsLYXSsXFxQBkZGTYHIlIdCkuLg7buodHQn1VpHbqq4f2MfCw3UGIoL4q0lior4o0DuqrB/f+DXZHILKP+qpI4xCuvmqYIU7BORwODMMgJSXlsAIuKSkhLy8PwzAIBAKhDOmQysvLiYuLi1h7DREMBtm6dStJSUmNZp21oqIiMjIy2LRpE8nJ9q+7Em3xyMHV52dlmibFxcW0b98ehyN6SjUcSV+1+3czVO3b/X1IdFJfDR2724/2eOTgmtvrqt2irW9EWzzSsJ9JU+qrdv9u2t2+4mmcsdQ3HvXV0LG7fcXTeKmvRpbd7SuexhlLfeMJd18N+YwygF69ejFv3jxatWp1WOd98sknjB8/PhwhHVRjSZKBlYTs2LGj3WEckeTk5KjodHtFWzxycHX9rKJptM9eDemrdv9uhqp9u78PiT7qq6Fld/sHirZ45OCa2+uq3aKtb0RbPHLkP5Om1lft/t20u/0DKZ6Di6ZYoPm9rtr9/293+wdSPI2H+mpk2d3+gRTPwUVTLGBvXw1Lmvy555477CQZwNixY2nTpk0YIhIRERERERERERERERGpLuSJsrS0NIYOHXrE5z/77LMhjEZERERERERERERERESkdiFPlL3++usNOv+UU06p13GmabJhw4YGtXUomzdvDtu1RURERESk6YqJieGOO+4gJibG7lCA6ItH9DMREREREYkmIU+UjRkzJtSXrJVhGDzwwAMUFBSE/NqPPPIIZWVlIb+uiIiIiIg0fTExMUyZMiVqkiDRFo/oZyIiIiIiEk3CskZZpFx33XVcdNFFFBcXh+yazzzzDPn5+fTo0SNk1xQREREREREREREREZHo06gTZV27duX3v/89w4cP57PPPmvQtfLz87nsssuYMWMGd955Z4gilGgrKRJt8cjBNbefld3fb6jat/v7EAk3u3/H7W7/QNEWjxycflYiEo3s/ttkd/sHUjyNIxaIvnjCze7v1+72D6R4Go/m9n9j9/drd/sHUjyNIxaIjngM0zRN21oPkTfffJOLndNZOgAA+xRJREFULrqIwYMHc/bZZ3PyySfTs2dPDMM45Hl5eXksWLCAmTNn8vbbbzN+/HheeOEF4uLiIhS5iIiIiIiIiIiIiIiI2KVJJMoAli5dyoUXXsiqVaswDIOYmBh69OhB+/btSUpKIi4ujvLycsrKyti5cyfZ2dnk5+cDVsby9ttv55ZbbrH5uxAREREREREREREREZFIaTKJMoBAIMBzzz3HP//5T7Kzs6u27z+zbP9vNyYmhosuuojbb7+d9u3bRzRWERERERERERERERERsVeTSpTt77vvvmPOnDksWrSIzZs3U1RURGJiIm3btiUrK4tx48Zx0kknER8fb3eoIiIiIiIiIiIiIiIiYoMmmygTERERERERERERERERORSH3QGIiIiIiIiIiIiIiIiI2EGJMhEREREREREREREREWmWlCgTERERERERERERERGRZkmJMhEREREREREREREREWmWlCgTERERERERERERERGRZkmJMhEREREREREREREREWmWlCgTERERERERERERERGRZkmJMhEREREREREREREREWmWXHYHIPUXDAbZunUrSUlJGIZhdzgitjNNk+LiYtq3b4/DET15f/VVkerUV0UaB/VVkcZBfVWkcVBfFWkc1FdFGodw91UlyhqRrVu3kpGRYXcYIlFn06ZNdOzY0e4wqqivitROfVWkcVBfFWkc1FdFGgf1VZHGQX1VpHEIV19VoqwRSUpKAqxfhuTkZJujEbFfUVERGRkZVX0jWqivilSnvirSOKivijQO6qsijYP6qkjjoL4q0jiEu68qUdaI7J1mm5ycrD+QIvuJtino6qsitVNfFWkc1FdFGgf1VZHGQX1VpHFQXxVpHMLVV6On8KqIiIiIiIiIiIiIiIhIBClRJiIiIiIiIiIiIiIiIs2SEmUiIiIiIiIiIiIiIiLSLClRJiIiIiIiIiIiIiIiIs2SEmUiIiIiIiIiIiIiIiLSLLnsDkBEpFnzeyF7HuR8CRWFEJsCmSMgaxS4PHZHJyIiIiIiIiIiItKkKVEWRhs2bOCvf/0rOTk5uFwuvF4vl19+Ob///e/tDk1EokHOAvh0ChRuhGBw3/YVb0FKJxgzBTKH2xWdiIiIiIiIiIiISJOnRFmYbN68mcGDB3P11VfzyiuvYBgGP/30E8OGDSMnJ4fbb7/d7hBFxE45C2DmNVBZDPFp4Nxv9ljACwUbrP2nTVOyTERERERERERERCRMtEZZmDz11FP4fD5uv/12DMMAoE+fPkyaNIlHH33U3uBExF5+rzWTrLIYEttWT5KB9TyxrbX/0ynW8SIiIiIiIiIiIiISckqUhcnu3bvx+XxUVlZW256SkkJKSopNUYlIVMieZ5VbjE8DwwBMKN4OvrJ9xxgGxKVB4SbreBEREREREREREREJOSXKwmTs2LGUl5fzt7/9rWqbaZp8/vnn/OMf/7AxMhGxXc6X1ppke2eSle+GykIo2gL+/ZLrLg8E/dbxIiIiIiIiIiIiIhJyWqMsTM444wx++9vf8tBDD5GQkMDUqVN57LHHuOGGG5g0adJBz6usrKwxC22voqIiAHw+Hz6fLyxxizQmdvaDhvRVR9luHFjJcwBiW2BUllozygo3YbboBA43AAYGwbLdBNXnpRFrrH1VpLmJln5wYL/d21dFxH56XRWpP70HFmkc1FdFGodw9wMlysLoxRdfJCkpif/85z/Mnj2bM888k6uvvvqQ59x7771MnTr1kMfMmTOH+Pj4UIYq0iiVlZXVfVCYNKSv9tmaR0ZlBRXBwv22JhJvVuDweQnm5VDuScfEQayvgk1b8/hp9uwQfwcikdNY+6pIc2NnX91fffqtiNhDr6si9af3wCKNg/qqSOMQ7r5qmFVTGiTUysrKmDFjBmeeeSaXXXYZr732GjfccAMPPvjgQc+payRBRkYGubm5JCcnhytskUajqKiI9PR0CgsLI94nGtJXjfWf4Jx1HWZcy33lFwGCfozCTRDwgTsWM6E1RkUhgQmPYHYbG65vRSTsGmtfFWlu7Oyr+6ttRllGRobtcYlEi6KiIlJSUvS6KhLl9B5YpHFQXxVpHMLdVxvljLJAIMCqVavIycmhuLiYuLg4UlNT6du3L6mpqXaHB4DX6+W0007jueeeIy4ujldeeYX4+Hgeeugh0tLSuPXWW2s9LyYmhpiYmENe2+1243a7wxG2SKNiZz9oUF/tPgZadMIo2ACJbcEwrO1ON6R0hIKN4CvHKNgIbfvh6j4GXOrz0ng12r4q0sxESz+oT78VEXvodVWk/vQeWKRxUF8VaRzC3Q8aVaJs+vTpvPTSS3z++eeUlpbWekzXrl0599xzueSSS+jatWuEI9zn8ccfZ/v27WRmZgJgGAZPPvkkq1ev5q677uKqq64iKSnJtvhExEYuD4yZAjOvgZLtEJ+2b2aZ0wOJra1kmeGE9B5WAk1EREREREREREREQs5hdwD1MXPmTAYOHMg555zDzJkzKSkpwTTNWv+tX7+ee+65h969e3PZZZeRm5trS8yfffZZjfqxTqeTq6++mrKyMlavXm1LXCISJTKHw2nToEVnKN8NRVugaKv11VcOad2hRSfYsRJ+eN7uaEVERERERERERESapKieUeb3+7n66qt56qmnaNmyJRMmTGDw4MFkZWWRmZlJUlIS8fHxOBwOiouLKSwsZN26daxatYovv/ySF154gVmzZvHyyy8zZsyYiMbeuXNn5s+fT0lJCYmJiVXbg8EgDoeDjh07RjQeEYlCmcPh4lmQPQ9yvoSKQohNgcwRkDUK1n0MXzwIi/8LCenQ5wy7IxYRERERERERERFpUqI2UVZWVsb48eMpLS3lvffeY8KECbhcdYc7atSoqsc7duzgqaee4vzzz+c///kPZ599dhgjru6mm27ilVde4ZprruGpp57C7XazY8cO7rnnHq699lratWsXsVhEJIq5PNBjnPXvQL1Pg9JcWPQifPUoxKVClxGRjlBERERERERERESkyYra0osXXXQRI0eO5Pvvv+eMM86oV5LsQG3atOH222/nxx9/5PHHH+f7778PQ6S169SpE19//TX5+fkcddRRjB49mnPPPZe//OUvPPTQQxGLQ0QaucEXQ+9TwQzC3Dth+wq7IxIRERERERERERFpMqJyRtnLL7/Mcccdx3XXXReS67Vu3ZoPP/yQP/7xjzz//PO43e6QXLcuffr0YcaMGRFpS0SaKMOA46+Hst2wYQF8dCuc/m9I7WJ3ZCIiIiIiIiIiIiKNXlTOKMvLywtZkmyv2NhY7rrrLubPnx/S64qIhJ3DCSfdDm36QmUxfHgTlOyyOyoRERERERERERGRRi8qE2V//vOfw3Ldzp07M2bMmLBcW0QkrNyxMP4eaJEBJTvhwxutpJmIiIiIiIiIiIiIHLGoTJTV5fXXX+eMM87ghBNOqNr2ySefcNlll7Fy5UobIxMRCaPYFDj5AYhPhfxf4OPbwO+1OyoRERERERERERGRRqtRJcoCgQBnn302v/3tb/nggw9YvXp11b6xY8dy5ZVXMnbsWJ566ikboxQRCaPkdlayzB0P25bB53dDMGh3VCIiIiIiIiIiIiKNUqNKlD300ENMnz4dgNatW+N0OqvtHzRoEHfeeSdXXnkln3zyiR0hioiEX3o3+PVd4HBB9jz45t9gmnZHJSIiIiIiIiIiItLoNKpE2YsvvsioUaPYsmUL27Zto0WLFjWOOemkkwgGg9xzzz2RD1BEJFI6DIbRf7Uer5wOy163Nx4RERERERERERGRRihiibJrr722wdfYtGkTb775Jm3btgXAMIwax+zd9sMPPzS4PRGRqNbtJBh2lfX426dg7Rx74xERERERERERERFpZCKSKNu2bRvPPPNMg6/TuXNnWrVqdchj5syxbhQ7HI1qspyIyJHpfw70P896PP8+2PSdvfGIiIiIiIiIiIiINCKu+hw0ZswYgsHgETXg8/lYtWoVlZWVR3T+/nr06MGSJUsYNGhQrfu3bt3K1KlTMQyDY489tsHtiYg0CkP+BGV5sP5T+OR2OPVRaN3L7qhEREREREREREREol69EmWGYTBv3rwGNVRbmcTDddNNN3Huuefy4osvMnz48Gr7Zs+ezZVXXsn27dsxDIObbrqpwe2JiDQKDgeMugXKd8OWRfDRLXDG45DSwe7IRERERERERERERKJavRJll112GcuXL+eGG24gLS0Nl6tepwHg9Xr5/PPPefPNN484yL2GDh3K9ddfz6hRo2jbti27d+9m6NChrFu3joKCAkzTxDAM7r77bsaNG9fg9kREGg2nG8b9A96/BvLWw+wb4YzHID7V7shEREREREREREREola9Ml4TJ07k008/PeJZWn/84x/57LPPjujcA11++eUMGjSI+++/n88++4zvvrPW4/F4PIwYMYJbbrmFk046KSRtiYg0Kp4EOOUBmHEFFG2Bj26FUx8BT7zdkYmIiIiIiIiIiIhEpXolytxuN3fccUeDGlq2bFmDzt/f0KFDee+99zBNk7y8PPx+P+np6Yc1001EpEmKT7WSZf+7Anathk+nwK/vAaf+PoqIiIiIiIiIiIgcyFHfAzt27HhEDbz55pu88847tGnT5ojO399jjz1W7blhGKSnp9O2bdtqSbJp06YRDAYb3J6ISKPUIgPG3w+uGNj0LXzxTzBNu6MSERERERERERERiTr1TpQdqbPOOosrr7yS1157rcHXmjZtWr2OmzRpEvfff3+D2xMRabTa9IExU8BwwNqP4ftn7Y5IREREREREREREJOo0KFEWCASYOnUqxxxzDN26dSMrK6vav8zMTNLT09m1axd/+ctfQhVznVwuFy+99FLE2quvyy+/nMzMTLvDiAy/F9bOgTl/h/evsb6unWNtF5HI6HwcnHCj9XjJK7Byur3xiIiIiIiIiIiIiESZBi1a88gjjzB16tR6Hdu1a9fDvv68efO4++67CQQCAGzZsoUTTzzxkOdUVFTw008/Rd16Za+88gpPPvkknTt3tjuU8MtZYK2LVLgR9i+BueItSOlkzXLJHG5XdCLNS69ToHQX/PA8fD0N4tMga6TdUYmIiIiIiIiIiIhEhQZlk1599VUGDx7M1VdfTYcOHZg6dSp//etfiYuLA8A0Te644w6uuuoqzjrrrMO+/qhRo+jYsSO///3vWbhwIWAlz+rjoYceOuz2wmXlypU899xzDB06lG3bttkdTnjlLICZ10BlsXVD3unZty/ghYIN1v7TpilZJhIpR//eSpatmgmf3QWxKdB+oN1RiYiIiIiIiIiIiNiuQYmyDRs2sGbNGlq1agXAxo0bKSwsZPz48VXH3HfffVx22WVMmDCB+Pj4w26jW7duzJ07l4kTJ7J06VLuu+++gx5rGAZxcXH079+fnj17Hv43FAbFxcVcfvnlvPbaa/zud7+zO5zw8nutmWSVxZDYFgyj+n6nx9pest067uJZ4PLUdiURCSXDgOOvh/LdkPMVfHwbnPFvSM2yOzIRERERERERERERWzUoUda2bduqJBnAueeey/nnn895551XtW3YsGHs3r2bG2+8kccff/yI2omLi+Ott97ijDPO4KKLLmpIyBE3efJkpk6dSkZGht2hhF/2PKvcYnzaviSZtxTcsWA4reeGAXFpULjJOr7HOLuiFWleHA446Xb44HrYsRJm3wS/eQJiW1h9MedLqCi0ZptljoCsUUpki4iIiIiIiIiISJPXoERZbGwsa9asqZq9lZCQQJcuXZg1axYTJkwAoKSkhOLiYt58880jTpQBJCUl8corr9R53Oeff87AgQNp2bLlEbcVKo8++iiDBg2qc121/VVWVlJZWVnrvqKiIgB8Ph8+ny8kMYaSI3s+jmAA0+EG04SgH6NoC2BAXEvMuJZgOMDpxgj6CWbPJ9hltN1hSyNmZz9onH3VAWP+gfODa60yqG9fDL5yjKKtYAYAAzBh+VuYKRkET/w7ZqfjbI5ZmgL1VZHGIVr6wYH9dm9fFRH76XVVpP70HlikcVBfFWkcwt0PGpQoO+eccxg6dCgDBw5k6NCh3HvvvfzlL3/5f/buOz6KOn3g+Ge2ZtM2nUAIhNAiRSlCQEBRUMHee8V2Z8GznIrnKZyVOz39eXinngXL2buiKKII0kR6byEQQiCkb7J9Z35/DAmEJJBkk+yGPO/XK69sZmdnnk3yZCbzzPP9kp2dzSOPPEJ6ejovvPACVVVVzRp28XBdunQ56jr9+/fnlFNO4auvviIjIyPofTbXokWL+O2333jvvfea9Lqnn36aadOmHXGdH374oUW+ny3thF1rSfV4cavlABg0HxGqgkH1gaMQrbIIrykGnzGSCJ+XvVvXsdrzbYijFu2Z0+kM2b7bc65aTeMZXv4Cdvd6NBSqLClohoia5xXVj2XfFvwf3crqbpMojs4KYbTiWCC5KkT7EMpcPVRj8lYIERpyXBWi8eQcWIj2QXJViPahtXNV0TRNa+6Lq6qqOOWUU1ixYgU2m43KykoUReGVV17hj3/8I4qiUL35u+++m+effz7ogLdu3cr3339PWVkZqqrWek5VVYqKivjvf/9LdnY28+fPD3p/zbF//36uuuoqPv/8c6Kjo2uWjx07ltzcXHJzcxt87dHuJEhPT6eoqIjY2NiWDjtohrlTMaz9EC2mdkFT8TqgqggCB6q+RhOgoA66FnW8XAQRzVdRUUFSUhLl5eVtnhPtOVcJeDG+eSbK/k36sKgRMXXyFk1DqdyLFtedwLVf6nMMCtFMx0SuBrwoO35B2bmwZphSrfsotB6nSH6IY0Yoc/VQ9XWUpaenhzwuIcJFRUUFdru9fR9XhegAjolzYCE6AMlVIdqH1s7VoDrKoqKiWLRoEbNnz6Z79+4oB+aluu2227DZbPzrX/8C4JxzzmHKlClBBzt//nzOPPNMvF7vEdfTNI2NGzcGvb/mmjZtGmvWrOHEE0+stXzXrl34fD6ysrIYPnw4b7/9dp3XWq1WrFbrEbdvNpsxm80tGnOLyDwF1n+CovpqXzS0xoI1BtwV4CyCgBfUAMY9yzHmLYIeJx+c00yIJghlHrTrXN3xMzj3g70rVO4DbyVKVSFEdzq4jqJAZBJKxW4MuxbKfIIiKO0+V3MXwo9T9Xk4D71JZ/0nYO8G46dCxqgWiVeIUAqXY1Zj8lYIERrt+hxYiDbW7s+BheggJFeFaB9aOw+CKpQBWCwWzjvvvDrLr7vuOq677rpgN1/L3//+dwKBAKeccgpdu3Zl7ty5nHFG7Yu33377LZdeeinXXntti+67KSorKyksLKSwsLDe5zdv3kxqamobR9UGMsfqFwzLdkJ06mHFLwUi7HrBrDQXjBr4nDDnUUjOguG3QtehIQpciA4md4F+sT/Crs8b6NgD7jIwmCAy8eB6Jguofn19KZSJjip3IXw9GTwOPT8OvREk4NWPeV9PhnNflGKZEEIIIYQQQgghRDsUVKHstNNO46effmqpWI5q2bJlzJo1i9NPPx2Av/zlL1x00UUMHXqwwPLKK6+wevVqsrOz2yyuw82cOZOZM2fWWd6YoRfbNZNFv6v+68lQubfuBUW/F1zFEJ0CE6ZDWS6s/QT2b4JZ90LaUBh+C6QcF6p3IETH4C4/+NgaA2oKVBXqHZ/WaDAeejeTUnt9IToSv1fvJPM46rkBBP0YF52qH/N+nAo3zNKPhUIIIYQQQgghhBCi3TAE8+J58+YxefJkysvb5iKq1WqtKZIB3HDDDbzxxhu11rnhhht45513eO+999okJnGYjFH6XfVx3cFVChX5ULFH/+wu1Zef+yL0Hg/DboYr3oMBF+mdLPnL4fM/wA+PQMmOUL8TIY5dEfbaX9viwZYIMZ0PK5IBaHXXF6KjyJmnD7cYmXhIkeywqV0VRc+f8jx9fSGEEEIIIYQQQgjRrgRVKANYtWoVAwYMYPLkyWzdurUlYmpQXFxcrfnJevfuze7du8nPz69ZZrVaiY2N5cknn2zVWMQRZIzS76o/90U44UroO1H/fO6L+vJDh6aKTIBRd8Pl70KfCfowcDsWwCeTYN4z4NgbuvchxLEqYwwYDPqwcdWikvT5BA/l9+pF7IwxbRufEOGiepjS6u5oLQDF2/UOTDVwcL1DhykVQgghhBBCCCGEEO1KUIWyzp07M3/+fDZv3kz//v25+OKLOeecc5gzZ05LxVfL8ccfz6WXXspbb73FqlWrALj99tu56qqrKCsrA+Cll16ioKCAXbt2tUoMopFMFn1OozMeh/Ne1D/3OaPhIaliO8OpU+CSN6DHGNBU2PwdfHgNLHwRnCVtG78Qx7Lq+QSdxaBp9a+jafpQqfZ0fX0hOqLDhx31OPRimasUSnKgar/+NSDDlAohhBBCCCGEEEK0T0EVyqrn2oqMjOS2225jzZo13Hvvvfz73//mhBNO4NVXX8XtdrdEnAA8/PDD/PDDD0yaNIlRo0ahaRpnnnkmSUlJdO7cmcTERCZPnoyiKJx44okttt+WMm/evGN3frKWktADzngCLvgPpA2BgA/WfQofXAXLXgdPZagjFKL9q55P0Bqjz610aGcZ6J1klXv158dPlTmXRMd1+LCjEXF68dhkA1RwlegFM2exfoOHDFMqhBBCCCGEEEII0e4EVSgzm811lp122ml8/vnnfPXVVyxatIiuXbsyZcoU8vLygtkVAP369WPOnDmcf/753H333SgH5gt54403OOmkkygtLUXTNHr27Mm///3voPcnQqhTPzjneTj7n5CcBT4XrHgb3r8CVn8Afk+oIxSifWvsfIKHDpUqREdT3zCl5kiI6waxXcEYoRfIqgrBUwGqD7zO0MUrhBBCCCGEEEIIIZrM1BobXb9+Pc8//zwfffQRbreb6dOn89VXX7F+/fqgtz169GhGjx5da5ndbmfu3Lk12+/bty8mU6u8NdHWug6FtJdhx3xY9hqU7YIl/4G1n8DQ66HvWWAwhjpKIdqn6vkEc+bpcyu5y/WOmIwx+nCL0kkmOrrqYUrLdkJ0Khy4QQcAS5T+4anQC8wGE+QuhA+uhEHXQL/zwGQNWehCCCGEEEIIIYQQonGC6ii79957a309e/ZszjzzTI4//njeeOMN3G43Y8eO5csvv2TdunVBBdoY/fv3p3///phMJuLi4lp9f6KNKApkngKXzoRTHoToFH1emPnPwkfXwba5oKqhjlKI9qmp8wkK0ZE0ZphSb5U+HOMpD+mfXWWweIY+ZPD6L/QhhIUQQgghhBBCCCFE2Aqq7er//u//yM7OZv/+/fznP/9h06ZNaJqG2Wzmiiuu4J577mHQoEEtFGrjLV++HIfD0eb7Fa3MYISss6DXeNjwJax8B8p3w9y/wer3YdgtkD689h3/QgghRDCqhyn9cSqU54HqBxRA07vI4rrrxbSMURDww9bvYflbULkPfn1ePz4NuR76nCkd0EIIIYQQQgghhBBhKKhCmaZpXHXVVTWPExMT+cMf/sAdd9xBampqiwTYHE888UTI9i3agMkCx18KWWfD2o9g9YdQtBW+ewA6nwDDb4XUAbVf4/fK8HJCCCGap7HDlBpN+rGp1+mw6Rv9hg7HXvhlOqz6H5x4I2Seps97JoQQQgghhBBCCCHCQtATeWmaRlZWFn/605+47rrriIiIaIm4atmzZw+7d++mb9++2O32I677pz/9iS+//BJFuopCyutXWbitiCU5xZS7fNhtZkZkJjKqVxIWUwtdILREwtAboN8FsOo9WP85FKyGL++A7ifBsJshsac+Z8yPU6F8V+0hGtd+pM89U90JIEQItEmuCCGCVz1MaZ8zGrfugIv0eTQ3fKkXycp3w9zHYeW7cOIkvcgm5ypCCCGEEEIIIYQQIRd0oWzKlCk88cQTrVKY2rNnDzfccANz584FwGw2c/fdd/PMM8/U2V95eTnXXnsts2bNAiApKanF4xGNszSnmOmzN5Ff6iKgaSgoaGh8sTKftHgbD07IIjszseV2aIuDkbfDwEv04a42fws7F8GuxZDUF/KWgM8FkYlgPKR7LOCFsp3w9WR9WC0plok21ua5IoRoW+YIOOFyOO5cWPcprP4ASnbAD3+FpD4w7CZIz5aCmRBCCCGEEEIIIUQIBdWu0KtXr1YrkrlcLiZMmMDcuXPRNA1N0/B6vTz77LM88sgjtdZdsWIFQ4YMYdasWWiaxsknn8zKlStbPCZxdEtzipny2VrySlzERVrobLeRao+gs91GXKSFvBIXUz5by9Kc4pbfeXQKnPJnuOwtfSgsNQAbv4Ly3WgoOLwqBeVudpe5KCh3U+EzoEangsehd5z5vS0fkxANCGmuCCHaliUShlwLV76vfzZHQtEW+O5B+PJOyF8e6gibzu+FLT/oRb+vJuuft/wgx1IhhBBCCCGEEEK0O0EVyrZs2dJgkayqqopAINDsbc+cOZN169YBMHr0aK688kqOP/54NE3jueeeo7CwEIB///vfjBo1ih07dqAoCo8++ig//fQTXbp0afa+RfN4/SrTZ2/C4fbTKdZaZ9g4i8lAp1grDref6bM34fWrDWwpSHHd4PRpMPRGAAIY8VSWYizbgeIsosrlpdTpJb/MRU5RFVUmO5Tn6XPPCNEGwiZXhBBtKyJWHxb4yvfghCv0Lud96+Cbe+HrP8HedaGOsHFyF8LMs+Hru/Quuc3f6Z+/vktfnrsw1BEKIYQQQgghhBDhQW40bReCHnqxIWVlZdx9990kJydz9dVXM3r06Ca9/vPPPyc2NpZZs2YxatTBIfFee+01/vCHPzBz5kxWrlzJRx99hKZpdO7cmf/973+MHTu2hd+JaKyF24rIL3WREGVpsICqKAoJURbyS10s3FbEqVkprRdQ6Q68xkgK/BHYKScCL3E4iFac7DV0QQW8fo3dFQF6WHxYchc0bu4ZIYJUX674VRWT4WDBrE1zRQjRtmzxMOKPMPAyWPkObPwa9qzU59hMz9aHZEzuW/s1fq9+Q0fuAnCXQ4Rdn+csc6w+J1pbyV2oD1nscciQxkIIIYQQQoRSuPyPIIRoWO5CfSSz8l2gHnIj/NqPwN4Nxk+V/53DRKMLZUOGDAEgLS2N22+/nYkTJx5x/bS0ND755BNefPFFTjvtNLp06UJubm6jA9uyZQvTpk2rVSQDuPnmm/n999+ZMmUKAJqmMWHCBN5++22ZlyzEluQUE9C0mu6YgKqxs7gKg0HBoCgYDQoGBQyKQpXHz8xFO6jy+omymog+8BFlMREdYSLKasRqMgYVT8BVRqUnQJVmxWvshE1zYdfKcSqRaIACmI0KvoBGlceP0VVGcHsUonEOzxVfQCWvxEl0hInkaGtN8cxiMhDQNJbkFEuhTIhjUVQijP6T3l224h19js28pfpHjzF6Z3Riz/A5sfZ79Tg8DohOrTu3mtGiL6/cq693wyz5B10IIYQQQojWEC7/IwghGiY3mrYrjS6UrVq1irvuuot//vOfGI16OWH+/Pn1rnvyySfXPJ48eTJ+v58///nPTQqsuLiYSy65pN7nbr31Vl599VVMJhNPPfUU999/f511ysvLsdvtTdqnCE65y4fCwYtmqqahaqAGNECrta4voLJmdzklVb4Gt2c2KjVFtIOfjURbzURbjUQeKKodfF5/LspqJMpiIt9lIUpTMRn1mFyKDZdiQzksFpNRQQ1o5LssdGu5b4cQDTo8V1y+AKoGFS4/Xr9Kqj2iprtMQaHc3XCeCCGOATGp+hybg66E5W/BtjmwYwHk/gpJffTCmc8VmhNrVQVfFXgqYctsKNkOlmjwVICmghYAgwki4vT1FQVsiQeHNJZObSGEEEIIIVqWXHwXIvzJjabtTpOGXvzb3/5WUyQDKCws5KWXXmL+/Pl07dqVu+66i4EDB9Z53R133FHTAdZYfr+ftLS0ep87/vjjiYqKYu7cuQwfPrzedYYMGcL27dubtE8RHLvNjHZIEcpkUOiWGImqaqiaRkDVC2cBVaPM6aVncjRDM+Kp8vip8gRwuP1Uefw4vX5UDXwBjTKnjzJn84oEvco78ZBmgIAX34FfdUXRyxPGQ6aEMms+AhhYovaTQploE4fnSmyEGZNBYW+5G7dPJa/ERWd7BBFmIxoa9ghzCKMVQrQZe1c47S8w6CpYPhO2/6QPyxjw6sWn5p5Y+73grdSLW57KA48PfO2t0k/cvZW1P1ev560E7cDfq4o94CoHn7P29k22g4Uy0GNQ/foQMFIoE0IIIYQQouXIxXch2oeceXrHZ2Q9/8tXkxtNw0qjC2URERF1OrQuueQSTj75ZFJTU/nmm2/qLZIBWK1WUlKaNmyYx+OhsrKS6OjoukGbTHTp0qXBIllBQQG7d+9u0v5E8EZkJvLFyny8fhWLyYCiKFiMCoePZ+j1q/gDKnec2qve4eRUVcPtD1Dp9lN5oIhW6dEfO73+moJalcdPpSdApcdXs06Vx4/Hr7ec/xroz24tiXT2U0g8oICmYVDAWN3No2nYtQrySGG1ZRCXtfL3SAiomysAkRYT6QmRFJS78fpVdpe6iI80Y1QURmQmhjhiIUSbSugBp0+D+B7w/RQwGMFbASUOfd4Ba4zezaUG9M8oULgRPr8NolMOFLkcBwtegRaYINho0TvHDEa9MGYwgmIAxQim+or5ij5PghBCCCGEEKLl1HvxvXqCkQPk4rsQoZe7QB+hpbrj01up36hqNOujtFQvlxtNw0ajC2UmU/2rpqSk0KlTpwaLZNVsNlvTIgMeeOCBBucdKy4uZtKkSXWWO51OFi1ahN/vb/L+WsNrr73Gq6++SkREBNHR0bzwwgv06dMn1GG1ilG9kkiLt5FX4qJT7MF5lg6laRolVV7SE2yM6lX/z9ZgUIi0mIi0mGjOrExev4rT6+fvszfx0tprmMordNbKKFVi8GOuOY8waT7sWgVOJZIZhqvJjIxsxt5ES/P5fCxdupTly5fjcDiIiYlh6NChZGdnYzYfG51VDeWK2Wiga7yNfRVuKt1+Ch0eUmKsDO+REOKIj64j/NyEaHPVwxxGJkBVkT4EortM/zic36cP1Rjbpf5tKYq+LUu0XmizHvo45sDjaLBUfx1V+zmTBX74K6z+oOF91KLpRT0RcvL3WQghhGg5clwVIXf4xXefExwFENMZzIdc1+rgF98lV0XIVd846i4DV2ntG1ir9oPBrP/fbYmqvX4HE0652qShFxsSHx/fEpup45VXXjni82+99Va9yzVNq7dI09aeeOIJXnnlFZYvX05KSgrvvvsuo0ePZsmSJWRmZoY6vBZnMRl4cEIWUz5by74KDwlRlppuGdALWCVVXmIiTDw4IavWcy0dh8Vk4fR+qTy0cQD/Z7mLmz1vkxLYhwEVTQNFAxUD+4ypvGa9jjXePlwlXTsht2LFCmbMmEFBQQGBQABFUdA0jdmzZ9O5c2fuvPNOhgwZEuowg3akXDEoColRFjx+FdWvEmE2MvWr9Uw56zgSosJzuISO8nMTos1VnyibIvRhGX0ucBbr//AqhtpdXV4HJPeFEbcfUgSLPVjwMkeCIcjjbsYYfXLwgLf2PAiH83v17rOMMcHtTwRN/j4LIYRo9/xevSMmd4F+bhRh188xMse2+XByclwVYaH6fwRN1S+2V99E5ywB++E3gHfMUR4kV0XIOUugbJdeIPM69GWKUf8fPeDVC9yq7+CNsAEf7P4dVv4P0rMhsWfDwzUeQ8ItV1ukUNZajEYjnTp1arCbrT5Op5P9+/e3YlSNs3btWqZOncp//vOfmmEnr7nmGp5++mluueUW5s6dG+IIW0d2ZiJPXzSQ6bM3kV/qIqBpKChoaBgVhfQEGw9OyCK7DYpS1V0780v6sD3mKQb5VzPQt5YorYoqJYq15oGsMp1AvkM9YoebaBsrVqzgySefpLKykvj4+Fp3Dfh8PvLz83nyySf5y1/+ckyc0BwtV3qnRHPBoDRmrS1g014H93y4iilnZZGVGhvq0GvpaD83IdrU4R1ZZpteMKtPhQ+6DIass1ovnsyxYO+mTw5e33wIoM9n5iqGuO76+iJk5O+zEEKIdi93oT7HUvkuvYOm2tqP9HOS8VMhY1SbhCLHVRE2Iuz6BfbSnaAe6FCJiIeo5HpW7nijPEiuipAq3akfo7b8oI8Kg6YXyCIT9VxUqm9e1cDr1Idi9Dr0QpnPBb+9qn9EJuoFs/ThkDYUIsLrWmBLCMdcbbNCWVOHQuzfvz+LFi0iJiamyfv67rvvOOecc5r8upb0j3/8g0AgwIQJE2otHz9+PC+++CIrV65k8ODBzdp2aWkpgUCgya+z2WxERETU+1xZWRmapjUrnoiIiFpDa2ZnJvLBrSNZuK2IXzbuocLtI8ZqYmg3OyMy7JiNBkpLS4+6XYvFQlRUVL3PORyORv1O3T46jcdnb2d3hZ/KyBNYGjEYRVEwGox6h5ujdodbZWUlPp+v8W/+ECaTqcHf16qqKrze5s0RYzAY6swPWM3lcuF2u5u1XUVRiIuLq/c5t9uNy+Vq1nah4S5Tr9dLVVVVneU+n48XXniBiooKEhMTURSl1s9XURTi4+MpLS1lxowZvPLKK+2iVf5oudon3sDLl2WxJLec5bvKcXj8xFhNnNQrmVP7dcFiMjCuXyeemrWRXSVOpny2lutOTGVs7+YNxXh4rh6qvLwc9dB/Phuh+ufmcDhISUmp08lrNptJSEigqKiIF154gWeffbZJPzez2VzvPJWA5OoBbZ2rjWW32zEE273UhsL2uFpPB5e/vjgDXgwYqEoajP8Ix9eWOK6aRtxH5I9TUCr2oNoSwGg5cFw16Hd8u4r1DrbxU8FkkVw9QI6rQoiOJGyPq/VozjlwtZY4rtZHzoF1pvzfiPn5YX3O1cjEWt3sqt8DJTvQvrgT5/in8adlN2nbclzVSa62w1ytKMVYUYTV4wDFiGa0oEWloJkjaxeToc7/CHIOLLl6KMlVXYvkqqZBwWpY8yHsXARAQFXxdzoeo2LE4C5DNceAqgGH/ByNERBhxRDwodozcA+5GdPe1ZgK12ByFsPmb/UPxQCd+kF6Nu7kE3BFdT2k4NZ4kqtH1+hCmd/vZ8GCBfUmkdPpbPA5VVXZsmULeXl5TQrsvPPOa1aRDGDixIk1XVyhoKoq3377LbGxsaSnp9d6rro49t133zW7UHbBBRdgNBqb/LoHHniAyy67rN7nLrnkEsrKypoVzy233MJtt91Wa5nFZODUrBT+8+id5OTkADCridu99NJLefDBB+t97r777mPFihWN2o4vrjtVvcZTEhGHphiwWsxEx8TU2+H2+OOPN7vbb8iQIbz66qv1Pjdjxgw+/vjjZm03MzOTjz76qN7n3n77bf773/82a7txcXH8+OOP9T731Vdf8fe//71Z2wX4/fff610+f/58HnrooSO+9khF1IyMDAoKCli6dCmjR49udnxtpbm52v+BB7Acr+dqWpyNZy89ged/3MLi7cU89M4vGPeswbZrEYrWtJOP+nL10Oeqc7Wp7HZ7g8Pd5ufn43Q6KS0t5ayzmtbpMm7cOKZPn17vc5KrulDm6pHMmTOn1YZlbg1he1ytp4Nr586deDyeQ9bWSI4IsMdp5rbbnsSvPdXgdlvquDo4wcudWQ4620owKmC2WoiNjtaHW4zrXuvubslVnRxXhRAdSdgeVxt4rrnnwC11XD2cnAODSdF4fUwB/btE19vFXuZwsndvOckRJex59XpuW9wVv9b4IarkuKqTXG1nubp/C3kvX4tanENGdABNC5Dn1FALd9ezlbr/I8g58EGSq5Kr1YLJ1ROHDOLlB66ANR/B/s36QkWB7qN4e4WLl17/hcEJbv5yfBlRphJKPcZaxyqzohFnDVDlN/Dkj1ZWvjEDgN6ZGbz/zymQtwTyfoPSXNi7Dvauw1G0n+17SllbGsHq0gjWlUZQ6W/c74bk6tE1ulDmdrsZO3Zsg88f6bnmaCiRG+tf//pXC0XSdLt376a4uJh+/frVea76wuHatWvrfa3H4znsAthBFRUVQcUVCASaXSU/ElVVG9xuc+9OgCPH25Ttmst2Yl8+E19CJr74DFK7ZTJuUF+ye8RzUmYiFpOhZj/NveuhOqaG4m3OnR+N2W4w8QKtEu+Rttvcuz+qmUwmAoEAy5YtIzs7u1V+nxurLXPVpMB943ryaUIE07ZsxtupH4HIBKK2zcHga/wdH62Vq9VjCLf0do8Ur+SqLlxz1efz1dp2R8nVlnLwd19BOfURjLPuAUcBWmTtYYsPPbGesSnpqBeIWuq4urLExm2Lu5Kd7GRooos+3ToxbOB4tO6j0Hqcot/xLcfVWsI1V8PpuHqow/M22FwVQrSc9n1crSsc/l89nJwDQ3ayk05Wr969ru8ENBXFV4VmiT7w/VUo8xjpbPORnexkYWH9XQj16QjHVcnVg9p9rqp+lNXvYVj1Lna1jJ0+EzM22bkso4xEa+CIF98P/R9BzoEPklwNTkfP1QijytjUSi5L+BX1xy36QqMFrc8E1P4Xg70rBcv/ASisLLHx5JpO3JlVRGebD6MC+hEMAhrscZqZsSmJlSUHO/T8moKv0/HQ6Xg48VZw7EXJ/x1l92/4ir4l1hxgVEoVo1Kq0IAch4U1pTbWlEaQ47Cg0fB1AZ/Ph9fjZsuSb3BtXYDRU07AasfrTcRoMBBo5t+CYyVXmzT0YrAXUpvihBNOaPa+QK+Mh0r1HGn1dcRVLyspKan3tU8//TTTpk1rlbjWr19PZOThE3vqmjvMAsDWrVv59ttv633O4XA0e7u7du1qcLsNff8aomgBLMVbsRRvpav5OAYGUnBugx+31V5v7969zQ2XkpKSBuPdtWtXs7frcDga3O7WrVubvV2v19vgdtevX9/s7QINbnfDhg1BbdfhcODxeNiwYQPffvstTqczqO0FIxS5GgXYc+ZS0nUUgZhUHP0vImrrD5iqGjcvY2vlqtfrpby8/gmCgzkx3rt3b4PxSq7qwjVXf/zxx1pDJnS0XIWWPa4mJl7OcXs+IrKsgASji0CEesQT64a05HHVryksLIxiYWEUx9GHSzzDYYsPttS+Q01yVReuuRpOx9VDtWbeCiGCcywcVw8VLv+vHkrOgWFoogsFDYejEpPqxqS6Maoe0MBlScTt1v/H8GkKRkVfvymFso5wXJVcPag952qkZz9ZBZ8R484HYI0jnqeXR1LpN7K1wtqki+9yDnyQ5Krk6qHPNVaCxc8ZaQ5OTa3CZlSxqBaKqhLJjxvOnrhh+MuiYOEaYE2t4+rhN5pGmwJU+o0sL7axdH9knRte689VAzCCBcUu9q79kRPi3Rwf7yI9ykfPGC89Y7xc2K2cSr+BdaURrC61sbY0ggrfwW4zr9fLp2/+kwF7PiZNK8KAWvN3o6emcNz4WGZsSmbtrqYXaI+VXG10ocxut/Pss8+SkZGBydT4+prf72fXrl0Ntk4ei6rvBKjv+1RdSbVarfW+dsqUKdx77731PldRUVFnKMem6N+/f4NDn/3rX/9q9i9b7969G9zuu+++S1FRUbO2261btwa3+80337Bz585mbTc1NbXB7f76669s3LixWdtNSEhocLvr169vsA31aGJiYhrc7p49e5g/f36ztmuxWBrcrtPpZPbs2c3aLtDgdq1WK59++mmztxsTE4PP56Nfv36cddZZIb3DPJS56lv/GVW9z0S1xVF53HnYcn/FWrT5qNttrVy1WCwNjnXe3FZ+kFyt1h5zdfz48bWGXuyoudpyx9WzIHAnyo5f+OGlKQSqSo54Yt0QOa7qJFcPCqfj6qEOz9tgc1UI0XKOjePqQfL/qi58jqsa6VE+BsTpFxIt/kN+NgYjmCxER0bixVdzo54GRJuadnNeRziuSq4e1C5zdeIElPWfYfj9A7B6ITYNdeRkln+6nEr/50DTL77LOfBBkquSq9Uak6vdo7xMTHMwIrkKw4G0KnCZ2RQ4nlvv+Jh4o4UBh73m8OPqoTeaHs3RcnXe/F/ZVB7Bh7lxxFv8DIx3c0K8mwHxbqJNKiOSnYxI1n+2uZUW1pRGsLrERmKXFE4qmIkNJw6DnYDhkDm//B7STWU80t/NE6Q3uVh2rOSqojWyTeyuu+4KajjDadOm8dhjjzX79e3J5s2bycrKol+/fnXunvj000+55JJLuPHGG3njjTeatN2Kigrsdju5ubnExsY2OS6ZxFEnkyPrwmkSx6VLl/L8888TExNzxMkZVVWloqKCv/zlL4wePbomJ8rLy5uVE62lLXLV5Q3w7193sTxPP0ickZXENcO6YDI0fMG8pXO1+udmt9sbLP4HAgG8Xi8Oh4N77rmH7OzGT7QtuaoLp1xtLLvdjsFwcHLZjpyrzSHHVZ3k6kFyXA3PuIQIlXDNCTmuHiTHVV2jjqtqAOP+9Zjyl2LavRRD1T4MlQUorlIUkwVMNrBGgyVaH94ZUDWt5udmqCzAe9zFuEZPaXTMclyVXK0WjrlqdhcRvexfULBaX5CeDSf/GaKT5Rz4AMnVxpFc1TUrVzUNY8EKrJs+w7hvTc3iQMpAPFkXEugyFJPZEl7HVTWAsXgTpj0rMBYsx1i6/eDbUQN4i3JRCFCmxOM22AhQe24zTVOJV0soMqWSeMsXmC31/+7U51jJ1Ua3hjXl4mZ9hg0bFtTr25OePXtis9nqraDv27cPgAEDDq81N158fHyL/zI0dFALVkOJHayG/hAFq6E/nMGKiopq8I99MGw2W4MHp2BEREQ0eDANhsViwWKx1Fk+btw4PvroI/Lz80lOTq53qFZN0ygpKSEtLS3ov0dtpTVzNR7424WJfLAsj/d/28VPW8sodKo8OCGLuMi63+OjaU6uNubnZjAYcDgcpKWlMW7cuCMeAJtCclXX1rl6rJLjqhxXqx0ruXqsHleFEO2DHFfluFqtweOq1wm7l0Hur7BrMXgOGarLYtMLAzsXQXQKqtlGpdtPVaWfgObCqChEWU1ER5gw+L1gNBPRdzwRDVyka4qOdlyVXA2zXNU02PQNLP43+JxgtsGI2+G4c+HA75ycA+skV4Mnuaqrk6t+L2z7EdZ8CKW5+jKTGXqeBsdfjim5D/XfJl5byHI1cTT0Ga0/dpbox9pdS3CsnUUEHgIYSdBKIVCKTzHjViKoUqLwYUZRDDgMdhL9hRSsX8AJp10WdLztLVcNR19Fd8011zRrB59++imLFy9usAXvWGQymZgwYQKFhYV1xvqubuc8++yzQxGaEGHJbDZz5513Eh0dzf79++vczeHz+di/fz/R0dHceeedLVZsae8MBoWrsrvxyNnHYTMbWZdfwZ8+XMXWfc0fE7op5OcmhBDhSf4+CyGECDvOEtj4NXz3ILx9Psx5FLb+oBfJImKh70Q44wm4/iu4dCYk9cZbWUJOoYP8MhelTi8VLj+lTi/5ZS5yCh14HfvBng6ZY1s1dDmuilZXVQSzH4L5z+pFss7HwyVvQL/zaopk4ugkV0UNvxe2/AA//BW+mqx/3vKDvrw+7nJY8Q68dxn8Ml0vkpkj4fjL4coPYNxfIblPm76FoEUmQJ8zYfxjrLedSBU2Kgx2vIpeuDJrPqLVCiyap+YlAcWMkQCuLfNaNbRwzdVGD73YXH6/n+7du/PWW28xfvz41txVWPn1118ZM2YMr776KrfcckvN8r59+9K3b1+++uqrJm8zXFuBhWgpK1asYMaMGRQUFBAIBFAUBU3TMBqNdO7cmTvvvJMhQ4bUrB+uORGKuPJKnDw5ayP5ZS7MRoU7Tu3FuOM6tcm+m/pzEx2P5KoQoSHHVSGOTeGaE+Eal2g6r19l4bYiluQUU+7yYbeZGZGZyKheSVhMjbzfWtOgbCfkLoSdC6Fwg76sWmwaZIyC7qMgdaA+B9khNiz+jugf7sWmHZhLRTl4kcyo+YhRy3EpkVSe8U/6jZzYEm/7qOS4KlrFtrnw6/N60dhogWE3w8BLwdDo3gZxGMnVDi53Ifw4Fcp3waHDQBoMYO8G46fqxx+A8t2w9mPY/B34DxSMopL1HMw6Wx/69xiw9P+upmfpr5QakwioGprqx4aHSNyUG+xwyHxl8YEitieMIXvyu60eV7jlatCFsrfeeouvv/6asrKyOmOQqqpKUVERGzZsoGfPnmzdujWoYJvi3XffbXYXXEuZPHkyc+bMYenSpcTGxvLiiy8yffp0fv31V3r06NHk7ckfSNER+Hw+li5dyvLly6msrCQ6OpqhQ4eSnZ1d5w6CcM2JUMVV5fHz3A9bWJZbAsC5J3Rm0qgemIytf4LdlJ+b6HgkV4UIHTmuCnHsCdecCNe4RNMszSnmue/WklaylMHqemKowkEUKw39yU/I5r6JA8nOTKz/xaoKhev1IRVzf9UvQB4qOQsyRusf8RkNdsp4/SpXvLqYpOLf+RPv0UktxICKBiiAioF9hhRe4CqKEk/kg1tHNr6AFyQ5rooW4y7XC2Tbf9a/TuoDpz4MCU2/XijqklztoHIXwteT9cJzZGLN3JYABLzgLAZrDIy6B4o26ceq6tJIUm84/gq9S9nY6Nmq2oUF//4jx+2bxV4OHr8VwGhQMBpqH4sTAvvZmnoOI/7w7zaJLZxyNahC2euvv86tt97aqMn/jjvuONavX9/cXTVJVVUVXbp0oby8vE321xBN03j66af55JNPiIyMpGvXrjzzzDNkZGQ0a3vyB1KI2sI1J0IZl6pqvL9sFx/8lgfAgLRYHppwHPZIKVaJ0JFcFaJ9CNecCNe4hAiVcM2JcI1LNN7SnGLe//gDbnTNJE0pwoiKhoKCRgAD+VoSb9pu4MpLrzhYLPN7YPfvB+YbWwSusoMbNJqhy5CDnWNRSY2K4+dNhTz06RriIi1EGgOc4FvFQN9aorQqqpQo1poHsto8CGfASJnTyzMXH8+pWSkt/w0JUrjmRLjG1aHsXAzz/64PSaoYYMh1MPjaJl+cb5HuTxG2ORGucYUtvxdmnq13M0en1n8zhscBFfl63iX20j93G6EPsdhl8DE31Om2wko+X7mb4hVfc4/7JcqIwa+Y9AJZPe/VqPmIVh0UnDy9ReYoa2mtnRNBlUdfe+01unXrxo033kjXrl3517/+xZ133onJdHCz//znP7njjju4/PLLgw4WYPfu3Xz44Yfk5ubidDrrFOm8Xi+//fYblZWVLbK/YCiKwsMPP8zDDz8c6lCEEB2EwaBwdXZ3MpOieX7OlgPzlq3kL2cfR6+U1pn8VIiOQP4JFUIIIUSr8XshZx7kLtC7TCLskDFGv6vdZDnaq1uE16/y9Vcf8yfXDGIVF+VKLP5Dhjs0aT7S2c+fXDN450svQ87sgzlvkV4k87sPbsgao1907D4K0oeDJarWfjRNw+1TqfT4qfL4a33WHwf4anU+DrefgKZRqGrkaP35RO2Hqmmk2iOIsujXnCwmCGgaS3KKw7JQJkQd3ipYNAM2f6t/HZ+hd5El923yppbmFDN99ibyS10EtOqStsYXK/NJi7fx4ISshrs/hTgW5czTh1uMTKxd8NJU8FTohWnVB2gQ8EFKPxj70DHXxamqGst3lfLZinzW5etNRIbIoez1JNOFQsoMifUXBDWNGLWcYlNnjht1XhtHHR6CKpRt2bKF33//vWYYwaqqKlJTUzn77LNr1unUqRNPPvkkkyZNCi5S4Pvvv+eiiy7C7dZPwo7UyaYcYxVgIYRoipE9E0mLO4Env93AnjI3D3yyhrtO6y3/QArRDPJPqBBCCCFaTUNzqaz9qO5cKq1o0eY9XFb+OjGKi2Iloe5FNEXBq5lJpYj7yp+m6vtMIq1mVA08EUkUJw5jX8JQ8iP6UOmDql0BKrfmUek+pCDm9VPpCaCqRx6VaHepE29ARfPUfe7w1yoolLt9wb59IVpf/gr4ZTo49ur5NfAyfT6yZhTDl+YUM+WztTjcfhKiLLVu3PP6VfJKXEz5bC1PX3SEoVKFONbkLtCPo4cOt+gsBlcpaAH9a8WoF9J8bohOOaaKZF6/ys+bC/liZT67S12AfjP9yb2TuGBwGp5tf8P1w73EqcVHnPtTHfcYFmtEqN5GSAVVKEtMTKw119bVV1/NH//4x1qFsgkTJnDdddcxbdo0Hn/88WB2x3333YfL5SI5OZlzzjmHzp071zv3ze+//863334b1L6EEKK965YYyXOXDeK5Hzbze24p/5yzhe37K7lxVI86YxALIeoXLv+EhltHW7jFI4QQQrRLR5tLpWyn/vy5L7Z6saxw9ff00/bjMMRiUDTQAiiqHxtuInFhwQcagIaZABvKFZZEncxa8/HsCXQBpwJ5APmN2p/BoBBjNRFlNRJlNRF94CPKamLRtiJW7y4nIcqC0QAGRdE/DAqmw/6P0dCwR8gw8yKM+T3w26uw9hP965jOehdLl0HN2pzXrzJ99iYcbj+dYq11GgUsJgOdYq3sq/AwffamNp3DT4iQch82BVPlPnCX6Y+NFrDFg9WuF6or9tRdv50qd/n4bm0Bs9YWUObUbxyxWYxM6J/KuSd0ITnGqq+YPJENgHPuNBL8+zASOGR4ZSPFps6o4x6j38iJoXszIRZUoSwyMpK9e/eSmpoKQEJCAlFRUSxdupTs7GwA/H4/Pp+P119/PehCWW5uLhaLhVWrVtG5c+cG19M0jeTk5KD2JYQQx4Joq4m/nt2P//22i4+W5fHlqj3kFFXx4JlZ2CPNcrFbiCMIl39Cw62jLdziEUIIIdolv1fvJPM46p9LxWjRl1fu1de7YVb9nSeaphfVvFXgc+kf3soDj50HPlwHnj/wtffAMl9VzePxO5YTQwUxqhPQDhTFDtkNCi4sOLERiYt19GJ+zDlEWY1kRJiJthqJsuiFrpgIE5EWE9ERpjrLq4tiVpOhwZGA+nWO5aFP12AzG494buX1qxgVhRFy3iHC1b4NMO8pKNPnEOe4c2HE7WCJbPYmF24rIr/URUKUpSaHNE0DRe+wBH2UrYQoC/mlLhZuK5KRZUTHEGE/+NhVerBIFp1a+zkAtHqWtS/5ZS6+XJXP3I2FeP16R3pyjJXzB3Xh9H6diLTULfv0GzkR75BT2bjwK1xb5qF4K9Assdj6jOW4Ued12E6yakEVyiZMmMBJJ53EKaecQnZ2Nn/4wx/485//zMSJE/n3v/9Neno606dPp7y8HIMh+AtHw4cPJycn54hFMtAPCP/5z3+C3p8QQhwLDAaFa0d0p2dSFC/8uJW1u8u556NVnHtCZ95ZvFMudgvRgMP/CQ2oGk6vX5/49pCP1vwnNFw62sI1HiGEEKLdqm8uFZ8TVL8+n4qq6p81DQo3wKc36cNE1RS9DhTCvFX6ekEIaBqmgFPf14EKmYaCqhjwYMWl2HApEWgYQQFbwMvxSQo3/GFkcN+DBozqlURavI28Ele9NyuBXhgoqfKSnmBjVK+kVolDiGYL+GD5TFj1np6fUUlw8gPQLTvoTS/JKSagaVhMBjRNo8Ltp9TpJSnaSrT14GVei8kgc/iJjiVjjD5ssasUqgr1ZVEpdQtifi8YTPr67YymaWwoqOCLlfks3VFC9axUvVKiuWBwGqN6JmIyHrkGY7FGcMJpl8Fpl7VBxO1LUIWyP//5z3zwwQe89dZbvPfee9x2220cd9xx3HDDDZxzzjm1TmbOOeecoIOdPn06Y8eOpaCg4KjFspycnKD3J4QQx5KTeiXRNT6SJ2ZtYFthJQ99upYIs4HUWJtc7BaiHof+Ewrg9QfYV1F3sgyDAXwHus+W7ighLtKM3WYmzqZ/tkeaiYu0YLeZibIYGz2Parh0tIVrPEIIIUS7Vj2XimLQ51Bxl+lFsvr4fbBrCcR2OfI2zZFgtukflqgDj6P07pXqx2abvp4lilKfkfm5VSzIdXKK4XNOCiylkEQUgwFjPTc7K+hlNAWNpKTWG8XHYjLw4IQspny2ln0Vnnpvzimp8hITYeLBCVlyviHCS/F2+PkpKN6mf937dDhpMkTEtsjmy1360GplLi9lVT78B+btK3f5ahXKQObwEx1M5liISobCTWAw6kMt2uJrr6Np4CqGuO76+u1EQNVYvL2Yz1fms2Wfo2b5sIwELhqSRv8usY2+ziAaFvQcZStWrODdd9+lV69eNT+QqVOnYjAY+Ne//gXoRbIXXngh6GCHDRvGO++8w8MPP8ybb77Z4Houl4unnnqKBx98MOh9CiHEsaRbYiTPXDSQM19YQEDV8PhUKtw+EqMtNcM0yMVuIXTlLl9NXoDesW6zGAmoWs0H6Ne4VA32VbhZuK3oiNs0GpR6CmmWmsfVz9kjzazaVVZnWJXDteWwKvUN8xLKeIQQQoh2Sw3A/i3gdUBJJTXjHCpGMEXoxbNDPzwVkHIcjLzzQBEs8rCiVySYbPrdO42wea+Dz1fms3h7EaoWBUBG8mmM3LsCo6aiGBq+VKQEvGAw0nnQ6cF+F44oOzORpy8aWO9wz0ZFIT1BRsAQIeD36t2guQv0+Y0i7HpXSuZYvUNlzQfw+xt6R1lELIy5r0Uvxrt9AQodHspdPqo8AUD//yI+0kysre5cfTKHn+hQ3OX6sMWKAb39Oa72836vXiSzxsD4qfUPZxxmXN4Aczbu46tV+TU37ZqNCqdlpXD+oDTSE5o/jKuoK6hCGejzkk2ePLnO8kcffZRHH3002M3XctNNN6FpGitXruTcc8+tdx4yv9/PihUrqKysbNF9CyHEsWL17nIUBRKiLDjcfsqcPjx+ldTYCIwGGdNciGp2mxntkAk6IsxG0uJsNV9raKiqfnfXvgo3I3smMnFAZ8pcPipcPsqcXsqcPspdPspcPlzeAAFVo7jSS3Gl96j7Lyh3Ueb04fQFMB0y1KOhniJVpcfPq/O3s31/653/zN24j0qPH4Oh9v5NRoU428F/MmSYFyGEEKIBjn2weRZs+hYKVuudYiazXuyKiANrNFDPzSgBD3Q+Afqc0exdq6rGb7klfL4inw0FFTXLB6XHceGQNAZ3GUblK5+QuH8H+wLxmIyGWpFogD+g0gkHlsQemHud1uxYGis7M5EPbh15cE5ltw97hMypLEIkd6E+X2D5Lv1OuWprP9LnQIpKhqr9+rLuo+Dk+yEyoUV27fIG+HZtAV+symdXiRNNA4MCCdEW7BHmem9ikzn8RIfidcL3U/QbUboOA78LKvYc6NQ+0A9tMOmdZOOnQsaoEAd8ZMWVHr5ZU8B36wpqiuKxNhNnDezM2QM7ExcZ/kW+9ijoQllDNE1r8Za/3bt38+OPPwKwZs2aI64r7YZCCFG/JTnFqJpGZ7uNKKuffRVuXN4AeaVO0uJsmA+MZywXu0VHNyIzkS9W5uP1q/VeiFFQMBr0QpnVZODSoelHzBWvX6Xc5aPc5dWLZ05frUJaTXHNpS+r7ljzBzT8Aa3B7QL4Aiqb9jqoPHAS3Rp2lzrx+FXKnLWHb4kwG2oVykCGeRFCCCFqqAF92MSNX0HeUmomFIlO0S/kRafqwyQ2JMi5VNy+AD9vKuSLVfnsKXMDegfKyX2SuWBQFzKTo2vWjTn7CVyf3UGqo5TiQAw+TFRfYDTjJ1VxYIuJw3b2E212J77FZODUrBT5f0SEVu5C+HoyeBz6vILGQ37/nUWwb73exZLUG057BPpMODj3YBCcXj/frNYLZA63PjRrz+QojIqC40DhWObwEx2eqsJPT0DRVn2oxQv+o+dpQ92fIegk8/rVgzd9uHzYbfXf9LGjqIovVubzy5b9NdcDusRFcMGgNE7NSiHCbGzz2DuSoAtlCxYs4J///CdXXXUVl156ac3y1157jblz53LHHXcwZkzLTI734IMPMmfOHK644gp69OiB2Vz3gOB2u1m4cCELFy5skX0KIcSx5tDh5KKtJizxNvaUuzEqSk1HWTW52C06spaeSN5iMpAcYyU5xnrUfWuaxt++2cAXK/NJjLbWGu5R0+oWzcpdPvp1juWM/qmNf4NN9MP6vazaXVZn+Jb6JguWYV6EEEJ0eI69sGkWbP4Wqg4ZmjltCGSdA+nZ8M6FULZT7yir76J6EHOplDm9zFpbwKw1BTUX2KOsRiYO6MzZx3cmKbqe85GMUdguegnrj1OJKs7F5/OjAgbAbDZhTuyNoR3ciS9Ei/J79U4yj0MvbFfnqurX89xXpc+HhAIGM/QcF3SRzOH28fXqAr5anV/TTdIlLoJLh6Yztm8yy3eWyhx+QlRb8m/YuVAvYJ/5JMR21pf3OSOoTuyWsjSnuN5hhL9YmU9avI0HDuTp5yvyWZVXVvO6/l1iuWBwGsMzEuqM6iJaR1CFsnXr1nHmmWfi8Xhwu921CmW33HILp512GuPGjePWW2/l4YcfDjrY0047jfPOO4/33nvviOv5/X5SUuRuIyGEqM/hw8lZTEbS4yPR0OoM6SYXu0VHFsqJ5BVF4eTeyXy7pgCjomCzNnznmNevElA1bh6T2ap3W3dLiOShT9cQE2E+4nuVYV6EEEJ0WGoAdi2GDV/B7t8Odo/Z4qDPRMg6G+LSD64/fqrepVK5t26XSjPnUskrcfLlqnx+2lSI70BHeqdYK+cNSuP04zphsxzlbvSMURhumIU1Zx7WMLkTX4iQypmnD7cYmagXwFSfPsxb1X7QAoABYpLBFKnncs68Zl+cL3f5+GpVPl+vLsDl0wtk6Qk2LjsxnTG9k2tubJU5/IQ4YP0XsPZj/fGpU6BT/5CGc7ilOcVM+WwtDre/zvUEjy/A9sJKbpq5jE6xEURZTRgUOKlXEhcOTqNPp5gQRt4xBVUomzZtGm63m549e3LbbbfVeb5nz5784x//4IorrmDw4MFMnDgxmN0BMHXqVPx+PyZTw6GbTCY+++yzoPclhBDHovqGk9NPuGsXyeRitxCh/Se0pTvajrV4hBBCiLDh2AubvoHN39XtHjvuXOg+uv4CU8YoOPfFA/Me5TV7LhVN01iXX8FnK3fze25pzfLenaK5aHBXRvZMrDNyxBGZLGFzJ74QIaGqULkPSnfAb6+CuwL8Hr2AzSHzk5lsEJN6sMit+vWh3pqYO2VOL5+vzOfbtQW4ffr2uydGcsWwbpzUM7HebhKZw090eLuWwsL/0x8Puxl6tv7cmU3h9atMn70Jh9tf6//ngKpR4danYfAHVPyqxj6Hm7tO7M2FQ9LoFBsR4sg7rqAKZUuXLuWXX3454tCKEyZMQNM0pk+f3iKFskGDBjVqvQ8++ICxY8cGvT8hhDjWyMVuIZomVP+EhrKjrT3EI4QQQoRUwK93j238unHdYw3JGAU3zGrWXCr+gMrC7cV8vmI32/dXAXrDy/CMBC4ckka/zrEyf7to3/ze1p1nqKYglnvgYweU7tQf+/U5/SjbBQEv1IzKooDRChExYEs4bIOKHmcjFVd6+HxlPt+t24vXrxfIeiZHcfmwbmT3OPpwazKHn+iwSnL0m0w0FfpOhMHXhDqiOhZuKyK/1EVClAVFUfCrKqVVPircvppTBpPRQFykkYAGfVNjpEgWYkEVyiwWS6PnH1u2bFmTtl1SUkJCwuEHnMbZuHEjM2fO5OWXX27W64UQ4lgmF7uFaLpQ/RMabsOqhFs8QgghRJurKDjYPeYsPrg8bajePZYxGoxNHLq8iR1cTq+fH9bv48tV+RRVegEwGxXG9+vE+YPSSIuzNW3/QoSj3IUHui136QWtams/Anu3RnVb1tC0AwWxnQeKYblQskOfI9Dnqv81RjPEdQOjCfZvhuhOeueY8UgFOk0v5h1FocPNp8vzmbNhb80QqX06xXDF8HRO7B4vBW7R7nj96sEbS10+7LZWvLHUWQLfPQQ+J3Q+AcbcF/S8gK1hSU4xAU3DZFQoqfJS6vTWFMgsJgNxkWZirCYURaGg3MWSnGIpeodYUIWyyMhIqqqqiIqKanCd999/HwCbrfEnaueddx6zZs3igQce4Omnn65Z3qdPH/x+/xFf6/P52Lt3L+qhB1EhhBC1yMVuIdqPcBtWJdziEUIIIZqsqV0qAT/sWgQbvzmseyxev5M962ywd212OI29wLjf4eHr1XuYvX4vLq8+f5HdZuac4zszcWBn7DaZW1gcI3IX6vP3eRx15+8LePUC19eT9aFLDy2WaZo+d1jJjrpdYj5n/fsymsGeDvEZBz8SekBsGhiMsOUH+PquoxfJ/F59yNSMhhsK9lW4+fj3PH7cWEhA1f+O9OscyxXD0xmUHicFMtEuLc0prvfa0hcr80mLb+FrSz43fP+wXvi2d4Uznmj6zSltpNzlwxdQ2VXsxH8g3yPMBhKiLERajBw6/YmCQrnbF6JIRbWgCmUXXXQRt99+OzNnzqz3j/kXX3zBfffdh6IojBs3rtHbXbZsGZqm1elC69+/P19++WWjtiEHFyGEODK52C1E+xFuw6qEWzxCCCFEozWlS6U1uscO05gLjEkxVr5Ymc/8rUWoBy62dY23ccHgNE7tmyLn7eLY4vfqOepxQHRq3U4Ro0Vf7tgD394PJ90FZXkHC2MNFcQMJv3CekKPAwWxA5/tXfWCWEMyx+p/G8p21h8P6AU6V7E+r2Dm2DpP55e5+Pj3PH7eVMiBFOb4rnauGNaNAWkyRKpov5bmFDPls7U43P56RyvKK3Ex5bO1PH3RwOCLZaoK856Cwo1gjYGJ0yEiNsh30Do27a1gxa5SKj0BLEYDJoNCYrSFmAgThxbIqmlo2CPCs+DXkQRVKLvvvvsYOnQoQ4cOZdKkSfTt2xdVVdm8eTOffPIJCxcuRNM0oqOj+dvf/tbo7c6ZM4fvv/+eK6+8stbym2++mWXLljF9+nQ6deqE2Vz3F8jr9fLTTz/x97//PZi31uL++Mc/8t1335GbmxvqUIQQooZc7BZCCCGEEB1GY7pUvpoMwybpF9x3L2vx7rFDHekCo8cfIGd/FTe//TvJ0VairPrlm4Fd7Vw4OI2h3eKPOn+REO1Szjy9kB2ZeLAoFfCCt0r/7Pfon1UfuErhl3/UvlhuMNbuEKsujMV21YdRbCqTRS+gfz0ZKvfW/dvh9+pFMmuMvt4hXam7ip189HseC7burymQDekWx+XDutGvS3he4Beisbx+lemzN+Fw++kUa61T8LWYDHSKtbKvwsP02Zv44NaRwd3Ysew1yPlFL3qf+WSLHYtbUqHDzVuLcpm/pQiPX8WgQKzNRFK0FUMDBXGvX8WoKIyQEZ1CLqhCWUxMDLNnz+bcc89l8uTJtRJCO3AymZSUxIcffkjfvn0bvd0BAwYwYMCAOssnTpzIOeecw9VXX33E159++um8/fbbjd5fa3v33Xd5+eWX6d69e6hDEUIIIYQQQgghOp6jdakoCigm/QL9T09AYi9QDHr3WL/zoPuoFh3eqaELjJqm4XD7KXP58PgC+FWNvRVurh+ZwcVDu9IrJbrFYhAiLOUu0DtHqotRWkAvYmuHTbGiGEHRIDIeBl8L8d31LjF715Yfii1jFJz7IuqPU/EV5+Lz+VEBA2A2mzAnZmA4pBt1R1EVHy7LY9H2oppa+7CMBK4Ynk6fTjEtG5sQIbJwWxH5pS4SoiwNdkUqikJClIX8UhcLtxU1/ybtTd/Cqv/pj095UJ+bLIy4vAE+WZ7H5yvz8QU0FAXOPyGNeVsKKShz19NDptM0jZIqL+kJNkb1SmrTmEVdQRXKADIzM1m1ahUzZ87kq6++IicnB03T6NatG+PGjePmm28mPj6+ydvNzs5m6dKltZYZDAaeeuqpRr1+8+bNTd5na1i3bh2vv/46I0aMoKCgINThCCGEEEIIIYQQHU99XSpoepeKqwx8VfoiRQHVD2knwsn3gz2tVcI59AKjBrh9AZxePxUuf83cRQaDQrzNjKZpDO+RIEUy0TG4yw/7ukIvkhnMeueY0ap3bRkt+vConQbAiTe2elhL1Sye8/yFNO9SBqvriaaKSqJYqfUn35PNfWoWiYWVfLhsF0tySmped1LPRC4blk7PZMlfcWxZklNMQNMwmxTcvgCVHj/OA/NnxkaYiIkwYzQoWEwGAprGkpzi5hXK8lfAgmf1x0Ovhz5ntOC7CI6qaszdVMjbi3Mpc+pzjA1Ii+XmMZn0TI5mVK9Epny2ln0VnnqHpiyp8hITYeLBCVkyjHIYCLpQBmA2m7nlllu45ZZb6jy3c+fOZhXKli1bxjfffMM555xTa3lCQkKjXh8dHfoDkMPh4I9//CPvvfce1157bajDEUIIIYQQQgghOqY6XSoqlO2CgOfgOuYosNn1C/PW6FYpkqmqxp5yFx8u24XD48ftV/H6a3fKGA0KcZFm7DYzBkWhoNzV/AuMQrQ3EfbaX7vL9M+RiXWfQ6tnWcs7dJjU8uiRbDONqnnO61cpLHZzy9u/k3RgmFRFgdG9krjsxHQykqJaPT4h2povoLJ9fyVOb4DcImfNDR7Viiq9FFd5ibaaiIs0o6BQ7vY1fUelO2HOo6AGoNc4GNr6RfHGWpdfzn8X5JCzX7/RJtUewY2jMhiZmVjTYZedmcjTFw2sdy5So6KQnqDPRRr0/G2iRbRIoexI9u3bx7333st7772H1Wpt0msvvPBCLr30Um655RZOPfXUVoqw9dx6661MmzaN9PT0UIcihBBCCCGEEEJ0XId3qTiL9SKZYoSIOP1ie/VwbW5H3fWbyeH2sWVfJZv3Otiyz8HmvQ4qPX52lzrx+tWaYdlMBgWr2UC01US01VRrGKtmX2AUoj3KGANrPzowD5lf/6wY9DnADuX36nMVZYxp1XCONA+TyxegpMqLy3twmNQbT8rgiuHdSE+IbNW4hGhrLm+AFbtKWby9mGW5JWzfX4nHr2IxGlAUiLKYiLIaUTUod/nw+lUcbj8Otx9V0yit8uLxB7CajI3cYRnMfkgfMrnTADjlobrDJofAnjIXMxflsnh7MQCRFiNXDE/n7IFd6u0Ky85M5INbR7JwWxFLcoopd/uwR5gZkZnIqF5J0kkWRoIulAUCATZu3EhZWRmqWvsuKFVVKSoqYu7cudx2223MnDmzSdu+8sorSU5O5rbbbsPr9XLttddy/fXX06tXr2DDbnUvvPACgwcP5rTTTmvS6zweDx6Pp97nKioqAPD5fPh8cpIsRCjzQHJViMaTXBWifQiXPDg8b6tzVQgReu35uGqwxGBAQ9M0NL8HraoEVdMoM8Xj90cR7YMog4YCKGiolhjUJr4PVdXYVepk895KthRWsmVfJbtLXXXWMxsVUmKseP0qyTFWIswGTIbaF8qq532vfhxtMYbl91U0TM6Bm6nbKIyx6SjV85JpQEQsGgo1lWVNQ3EWocV1J9BtFLTi+/hly352l7qIj9QL6aqm4vIGKHX6cPn0YeYUBew2MwowKD2W1BhzeH5vRb0kVxtW7vLxe24pS3aUsHp3Ob7AwWNTcrQVlzdAYpSZmAhzrSJybIQRl0+lwuWjwq0PKbypoILrX1/KaVkpnNkvhS5xtoZ3HPBinP0wlOdDTCqB06aCprRqrh9NpcfPx8vzmbV2LwFVw6DAGf06ccWwrthtZtAC+A78TTicAozuGc/onoeNuneE14i6WjsPgiqU7dq1i/Hjx7N9+/YjrqdpGl988UWTtm2323n77bcBeO6551i6dClvvfUW2dnZZGVlcf3113PFFVcQGxvb3PBbzaJFi/jtt9947733mvzap59+mmnTph1xnR9++IHISLkzRQin0xmyfUuuCtF4kqtCtA+hzNVDNSZvhRCh0Z6PqynlVgZ5fTiKi7H6yrBoAaqwsT9gAo+H0iowKRBv8RGj+VhVaKXw22+PuM0qHxS4oMCpsMepsNep4FPrrhdn0egSCZ0jNTpHaiTbYFOZwgclBjxOP4Ej3EzuV8HrB0PRdr79dluQ3wXRluQcuPkSI09n0P7XiPSWomLA6TOilutdnorqxxJw4DfaWB15OsXf/9iqsXy504DTpaB63XhU8AagOs0VwGaEKDMYCVDmhffnLse5rZ4/BCJsSa7WVu6FreUK2yoU8qsUDh1U0W7R6G3X6B2rkRwBL1UaKK70o3pc9TZ7WTUwAzFmiFSryC908k5hCe/M30RGtMYJiRo9Y/WiUw1NI6vgUzpVrMFvjGBlwhk4f17Uyu+6YaoGq0sUFu1TcPn1QDNiNMZ2VkmqLGHhzxtDFltH09q5qmiH3qbURJMmTWLmzJlYLBZSUlIoKiqiU6dOtdYpKCggKyuLm266ibvuuqvR2/7yyy85//zz6yz3er189dVXzJw5k/nz53P22Wdz/fXXc+aZZ9aqXIfK/v37ueqqq/j8889rzZM2duxYcnNzyc3NPeLrj3YnQXp6OkVFRWFZIBSirVVUVJCUlER5eXmb54TkqhCNJ7kqRPsQylw9VH0dZenp6SGPS4hwUVFRgd1ul+NqUwW8uF47G6VoCya8aBjZa+xMAH0IKE0DvxqgE2WYkzKw3Tzr4Hxm6POx5BY52bzPoQ+luK+SQkfd70WE2UCfTtH0SYmmT6cY+nSK1u80P4zXr3LNG8vYXeoiJcZa7/UMTdModHjoGm/j3UnDZHimdkbOgYNj+PGvGFa8pSenNRq9LKWBYkSzp6Oe9le0bie1yr59AZXNeytZvquUtxbvYk+5C7PxYP4ZFYXoCBPxkeZa3aB7K9yc1jeZJy/o3ypxidZxLOSq16+yKKeYpTtKqXD5iLWZye4Rz0mZiUc9dmiaxs4SJ0t3lLIkp4Tc4trFiB5JkWT3SGBEjwS6JdhqHa9+yy3hkS82UOnxEx9pqbUvr1+l1KnPU/bEBf04sVs8K/LK+G7dPlbmldU0iCZGWTijXwrjj0shIcqCsuItDCvfBoMR9Yxn0NKGHDH+1rRyVxlvLtpJ3oHu8K7xNm48qTtDusWFLKaOrLVzNaiOsh9//JHHHnuMhx9+GLPZzC233MKjjz5aa06uBx54gOOOO44bb2zaZHv1FckALBYLl1xyCZdccgl79+7lf//7Hw8++CA33XQT11xzDddddx39+7f+ASk/P59x48bVWT5y5EjWrFnDiSeeWGv5rl278Pl8ZGVlMXz48JpuucNZrdajzuVmNpsxm+ueaAvR0YQyDyRXhWg8yVUh2odwyYPG5K0QIjTa83HVqxj5l+887uVpTKiUKvaaIhmAGR9JSgUVmo3X/Fdwu9tAzv5yNu2tYPNeB9v3V9YacgrAYFBIj4+kb2oMfVNjyEqNIT0+EoPh6Dfxms3w0MTjmPLZWgodXhKi6l5gLKnyEhNh5qGJxxFlk7+L7Y2cAwch4IeiLZDYC447V5+jyF2uzyWYMQYlcywGk+Xo22mCQoebFTtLWb6zlNV55TXDKuqfFSLMRqIsJiItRqxmAwr153l8lDV8v6+iXu09V5fmFDN99ibyS10ENA0FBQ2Nr1cXkBZv48EJWWRnJtZ6japqbNrrYHFOMYu3F7Ovwl3znNGg0K9LLCMyExmRmUin2IgG9z2qdyeeudhU7/6NikJ6QmSt/Y/slcLIXinsq3Dz3doC5mzcR4nTxwe/5/PRij1cnbCZc4pnYjMbUcbchyEjuzHfxhaXV+Lk9V93sHxnKQCxNjNXZXdjQv9UTEa5aSVUWjtXgyqUuVwuHnvssZqvr7vuOt566y0eeeSRmmX3338/PXv25IQTTmDIkJatAKempnLfffdx7rnnMnnyZJ599lmeffZZBg8ezPXXX9+kDram8vl8bN68uc7yESNGUFhYSGFhYb2v27x5M6mpqa0WlxBCCCGEEEIIIWpbuK2ITo4NFBmSidUcGFFJUovQ0PtUAhjIJ4UXlKtYsL87C/67hNiI2hdkoq0m+qbGcFznGPqmxtI7JZooa/Mvq2RnJvL0RQOPcIGx/gucQhzzdi4EZzFEJsLoe8DY8hdHvX6VDQUV/J5bwspdZewqqd1FExdpZnB6HCajgXcW76xTzK5ve0ZFYYTkq2hDS3OKmfLZWhxuf703XOSVuJjy2Vqevmggg7vFs2Z3GUtyilm6o4Qy58H5nsxGhcHd4hmRmcjwjATskY3PuezMRD64dSQLtxWxJKeYcrcPe4SZEZmJjOqVVG/edIqN4IZRPbgquzsLtxfx7ZoCPLtXcfz2V8jX/KxMmIDNO4TTPP6gjrNNVe7y8f5vu/hubQGqphcNzzm+M5cPSycmQgrgx7qgftPS0tJqfT1mzBimTZvG/fffT0SEXm1OSUkhMTGRe+65h19++SWY3dVSWVnJhx9+yJtvvsnixYuBg5PdOp1OvF5vi+2rPhkZGTQ0auXMmTPrLGvs0ItCCCGEEEIIIYRoWblrfuUkdTluYyT/iH6AeLWE3q7VRAQclKuR/Kb1ZzED8WEioKk4PX4Gp8fRNzWWrNQY+qTG0MUe0eJTPjTnAqMQx7wNX+ifs85u0SLZ3nI3v+8sYcXOMtbsLsPjPziXmEGBvqkxnNg9gSHd48hMisZgUPD6VeZtLiSvxEWn2IaHSS2p8pKeYGNUr6QWi1eII/H6VabP3oTD7a/3d9NiMpAcYyG/zMXdH6yka3xkrd/5SIuR4T0SGJGZyJBu8dgsxsN30WgWk4FTs1I4NSul6a/rm8KpqT5cH32II6CwWBvEu4Ez0ebn8NaiXMb2TeasgZ3JTI4++gabyRdQmbWmgA+W7aLKo3eTZvdI4MbRPUiLs7XafkV4CapQlpKSwjPPPMOVV15J586dsVgsXH755dx///3MmDEDgGXLlrF7927279/fpG0/8sgjPPHEE3WW//LLL7z55pt8+umnOJ3OmmJVdHQ0l112GTfddBMjR44M5m0JIYQQQgghhBDiWOH3Mmz3TEBhofUkVge6U1zZmYDar2YVo0Ehwmwg1myk0uNnbN8U/nHpCW0SXnMvMApxTCrbBfkrQDHg7XMOCzcV6kVklw+7rWlFZI8/wLr8cpYfGFJxT5m71vPxURaGdotnaPd4Tki319sxYjEZeHBCFlM+W8u+Cs8Rhkk18eCELCluizazcFsR+aUufV6vQ4pkAVWl0hOgyuPH6QugqhpVngBWs5HuiVGMyExgZGYiA9LstebeCxl3Bcx+EJtahS3zBE6f8BzGbRV8t3Yvu0qcfL9+H9+v30ff1BjOHti5RW8i0TSNpTtKeOPXHRSU638feiRFcfOYHhzfNa5F9iHaj6AKZffccw9nn302f/nLX+jWrRs7duzgxhtvZOjQoQwbNoxu3brx/fffo2kaGRkZTdr2v/71L/76179itVrJycnhf//7H2+99RY7duwADnaPjRo1ikmTJnHZZZcRFRUVzNsRQgghhBBCCCHEsWbNByT695FLFP91jaPE7wH0oaYSoixEmI2YjQocmHPI7QuQENWy8x8JIRppw1cAFNgHccd7OXWGJf1iZX6D8y5pmsaecnfNcIprdpfVmlvQYFDo1zmGod0TGNItjh5JUY3qEpVhUkU4WpJTTEDTaopGbl+AokoPbp9aaz2ryUBA1RiekcD0i49v1DyabSbggzmPQlkeRKfAmU8RGRnNOcdHc/bAzqzfU8G3awtYuL2YzXsdbN7r4L8Lcji9XycmDEils73+bi+vXz3Yqd1AkT1nfyWv/bqDtbvLAX241WtHdGf8cZ3C63sk2kxQhbKJEyfy97//nSeffJLOnTvrGzSZeP/99xk3bhzLly8HwGKx8MwzzzRp2w6Hg379+mE2m9m6dWvNck3TSE1N5brrrmPSpEn06dMnmLcghBBCCCGEEEKIY1X5bvy/v41PVfmvbyJFigWjARKiLMTZzHUukss8Q0KEkM8NW2ZT6fXzVG4f8nyuo867dEJ6HGt2H+wa21dRu2ssMdrCid3jGdI9nkHpcURamncpVIZJFeGm3OVD4eAxzKBQUySzmgxEWU1EW01YTAp7yz0YjUp4FYA0DRb8E/asBHMkTHgGog4eexVFYUCanQFpdkqrvMzZsI/v1hVQVOnlsxX5fL4ynyHd4pk4IJVhGQk1721pTnG9Re3qIvvtY3uxoaCCHzfuQ9P0m2YuHJzGJUPTgxp+UrR/Qc+Gd//993P//ffXWtavXz/WrFnDRx99BMAZZ5xB7969m7zt3Nzcms4xs9mMzWZDVVWmTJnCddddh91uDzb8NjNv3rxQhyCEEEIIIYQQQnQYfn+AXV88iba/jE2G3iwxDsaIQrcEG2Zj3YthMs+QECG2/SdUj4ONjiiWBnrSyV7fvEsK8ZFmCirc3PHeCtLibaiHNNAYDQoD0mIZ2j2eod0SSE+wtdjcgjJMqggndpsZjYMdkxaTgZRYK5FmI6bDhlTU0LDXM7RoSK1+HzZ/C4oBxk+FxJ4NrhofZeGyYelcPLQrv+eW8O3aAlbsKqspkCfHWJnQP5XEaAtPztqIw+2vU2R3+wJsLazkzvdW0CXORpTVxJjeSVx/UgadYiPa4A2LcBd0oawhycnJ3HHHHUFtQ9M0evXqxe23384111xDTEwMn3/+OTNnzuThhx/m3HPPZdKkSYwfP76FohZCCCGEEEIIIUR7tyqvjAXffciEfb/hV0ws63o9j2X155VftlNc6SMhSpF5hoQINxu+pNLt59vAaOKjI2oKXKqm4fQGcHr9OL0B/AENVdNweQNEWU30TolmSPd4hnaL5/iucdIVIjqEEZmJfLEyH69fPXDMUoitpxgWlp3SOfNg6Sv645Pugm7ZjXqZ0aCQnZlIdmYie8pczF63lzkb9rHf4eGtxbnsKKoCDTrHRWAxVRfINRxuP8VVXnx+Fb+qUeby8cIVg2QeMlFLixTKvF4v33zzDcuWLaO0tJSYmBgGDBjAxIkTSUlp/l0W999/P0899RQm08Ewr7jiCq644gry8/N55513uOuuu3C5XFx//fXceOONTZ4LTQghhBBCCCGEEMeGfRVu3vh1Byu27WaK4wOMBgXPwCt59JwzMRgUMhIjZZ4hIcJR4SbYvwmHF+ZxItEHitWqppFX4qw115iiQLTFhNevMqpnIk9eOLDFusaEaC9G9UoiLd5GXomLTrF1uy8hTDulCzfCT0/qjwdcDAMuatZmusTZmDS6B1eP6MbCbUW8tmCHXhQ0KOwpc2MxGYiJMFHl8dcMSWkyGkiKNuELaBRXelvqHYljRNCFslmzZnHLLbewb9++Os9ZLBbuvPNOnnrqKczmprV3JiQk8Mwzz2Aw1H8XV1paGg899BAPPfQQixcvZtq0aTz55JOccsopTJo0iYsvvpiICGmbFEIIIYQQQgghjnUef4BPl+fzyfI8fAGNi92zSI9wEde5D+azbtcnb0HmGRIibG34EoBNkUOp9MQQfWBxhcuHL6BhUCAmwkyU1UiE2YhBUdhb7kYFKZKJDsliMvDghCymfLaWfRWeeufzC7tOacdemD0FAl7oNhJG3hn0Jq0mI6dldWJpTgkbCyqwGA04PH68frWmGKYoEB9pIS7SjEFRKCh3sSSnWIZRFbUEVSibO3cuF1xwAaqqomkaSUlJDB06lMTERNxuN+vWreO5555j1apVfPfdd7U6w47ml19+abBIVs3tdvPJJ5/w5ptv8ssvv6CqKj///DM///wzzz//PL///nswb08IIYQQQgghhBBhTNM0Fm8v5vVfd1Do8ABwWmIJV5atwGq0wsn3gclS6zUyz5AQYcZdAdvnApDbaTxaqd49pmkapU4fAInRVuy22jfhh+W8S0K0oezMRJ6+aGD76JT2VsHsh8BVCom9YNyjcJRr/01R7vJhMhhIiY0gUdNwuH1Uuf2YTQYSoiyYDtmXgkK529di+xbHhqAKZX/9618JBAIkJCTw4osvcsUVV9Qpbv36669ce+21/N///R/33Xdfo7fdv3//Bp9bvHgxb775Jh999BEOhwPQD542m42LL76Ym266iVNOOaV5b0oIIYQQQgghhBBhb1exk1cXbGd1XjkASdEWbhqVwai1f0ExKtD7dOg6NMRRCiGOausP4PdAQiaZ/bMxbl6L16/i8gUIqBpGg0JsRO1LmGE575IQIdAuOqXVAPw4DUp2QGQiTHgGLJEtugu7zYyGXmQ3KgpxNgtxNku960qRXdQnqELZqlWrUBSFjz/+mFNPPbXedUaPHs1HH33EpEmTmlQo69OnD1u2bKn5uqCggLfffpuZM2fWLNc0/Zd/2LBhTJo0iSuvvJLY2Ngg3pEQQgghhBBCCCHCWaXHz/tLd/HNmj2oGpiNChcN6colQ7sSselzKNoClmgYcXuoQxVCHI2m1Qy7SL/zGdU7+cC8S05cvgAA8VHmWsMrhuW8S0KEUFh3SmsaLPw/yFsKpgiY8DREJ7f4bkZkJvLFyny8fvWIxUEpsouGBFUo69y5M06ns8EiWbVhw4ZRXl7epG1v27aNV155BbPZzCeffMKcOXNqhngESExM5JprruGmm25iwIABzX4PQgghhBBCCCGECH+qqvHjxn28vXgn5S59yKQRmQncPCaTTrERULkflr2ur5x9K0QmhDBaIUSj7FkJZbvAHAm9z6iZd2nyBytx+/QL3rGHdH6E5bxLQoiGrftUL4YrCpz2CCT3bZXdjOqVdKDI7qJTrLXeuQulyC6OJKhC2d13381f//pXvF4vFkv9rYwAgUCgwfnG/v3vf3P77fXf5XXock3TMBgMnHnmmUyaNInzzz8fs1laJIUQQgghhBBCiGPdpr0VvPpLDlsLKwHoGm/jlpMzGdIt/uBKi2eAzwmd+kPWuSGKVAjRJBu+0D/3Pr1mKLZhGQmkx0ficPsxGRT2VbjDd94lIQT4vZAzD3IXgLscIuyQMQaMFv3YDJD9R+gxptVCqC6yT/lsLfsqPCREWWoV0qXILo4mqELZ5MmTycvLY8qUKTz33HMNrjdjxgzOOOOMOsu9Xi8PPfRQg4Uy0AtkPXr04MYbb+SGG26ga9euwYQshBBCCCGEEEKIdqK0ysvMRbn8tKkQAJvZyFXZ3Tjn+M6YjIdc5Nq1VL9Ipxhg9L3QwM26QogwUlUMub/qj/udX7N4wbYiPH6VgWl2bhzVg5W7SsNz3iUhBOQuhB+nQvkuUNWDy1e/Dz4XRKfCoCvh+MtaPZTszESevmgg02dvIr/URUDTpMguGi2oQtnjjz9OTEwMc+bM4frrr6dnz561nvd6vWzYsIFvvvmGyZMn87e//a3mOY/Hw7x586iqqmpw+4MHD2b69OmMGzcumDCFEEIIIYQQQggRJrx+lYXbiliSU0y5y4fdVvfity+g8vXqPXzwW17NPEXjj+vEdSO7Ex912Ig2Pjf8+rz+eOAlkNSrLd+OEKK5Nn0DagBSB0Cifk1RVTU+WpYHwEVD0pgwIJUJA1JDGaUQoiG5C+HryeBxQGSi3kEGoPqhdAf4PVC1H7oO14debAPZmYl8cOvIg+cZUmQXjRRUoWz27NksWbIEgIULFzY49ifA888/X+9z9b0GwGq1MmfOHOLj4+t9XgghhBBCCCGEEO3L0pzieu/0/mJlPmnx+p3eJqOB/87PIb/MBUDvlGhuO6UnfVNj6t/oynfAUQBRyTD0xjZ8N0KIZlMDsPFr/XG/C2oWL9lRzK4SJzaLkbOP7xKa2IQQR+f36p1kHofeNVZ9jV9ToSJf/2yOApMFfnocus3SH7cBi8nAqVkpnJqV0ib7E8eGoOcoW7x4MdnZ2fTu3Ruj0djo13q9XpYvX87WrVvrff6ZZ56RIpkQQgghhBBCCHGMWJpTzJTP1uJw++udO2RnsZNb3vmdpCgrUVYTcZFmrhuZwbisFAyGBu5EL9kBqz/QH4+6u2aOIyFEmNu1WO80ibBDj1MA/Yb6Dw90k517QheirUFdthRCtKacefpwi5GJtbvFHAXgd4NigriuoGpQnqev36fu1ExChIugjjgXX3wxQ4YMYfHixc16vcPhIDW1/vbpu+++O5jQhBBCCCGEEEIIESa8fpXpszfhcPvpFGutNbqMqmk43D6cXj++gMbegJu7x/XmmhHdiTrShXJN04dcVP3QfRRkjG6DdyKEaBEbvtQ/9z2rpstk+c5ScvZXEWE2cN4J0k0mRFjLXaDPSWY8pEusaj94KwEF7GlgMIMB/Tidu0AKZSKsBVUoMxqNPP74481+fUxMDDfeKMMiCCGEEEIIIYQQx7KF24rIL3WREGU5pEim4XD7Kar0ElA1QCHKasRsVOjTKebIRTKALbOhYDWYImDU5Dab/0QIEaTy3ZD3m56z/c4D9G6yDw50k00c0Bm7zRzKCIUQR+Mur/21zwmuEv1xTGf92FxDqbu+EGEm6NnrJk6c2Kj1LrroonqXz5gxI9gQhBBCCCGEEEIIEcaW5BQT0LSa4Ra9/gD5pS72VXgIqBomo0KqPYJuCbaa9Y/IXQ5L/q0/HnoDxNQ/Wo0QIgxVz03WdTjE6p1ja3aXs3mvA7NR4cLBaSEMTgjRKBH2g481FRx7DyyPB+vhc4pqtdcXIgwFXShrjA0bNjBr1qy22FXY2LlzJ1dffTWjRo3ilFNOYeTIkbz99tuhDksIIYQQQgghhGhz5S4fCgc7vvyqhsunoiiQEGWhW0LkgfmIFBQUyt2+I29w6SvgroCEHjDw0tYNXgjRcvxe2Pyt/rjf+TWLP/xd7yY7o38q8VGW+l4phAgnGWPAYICAF5xFoPr0oRajkmqv5/eCwaSvL0QYa9TQi3369MHv9zdrBz6fj71796KqarNe3x7t3r2boUOHctddd/Huu++iKAobNmxg5MiR5Obm8uijj4Y6RCGEEEIIIYQQos3YbWY0tJqvIy0mEqMtRFtNmI217+HV0LBHHGHYtYI1sOnAzbhj7gNjULNKCCHaUs48vcgd3Qm6jQRgw54K1u4ux2hQuHhI19DGJ4RonMyxYO8GxdvBV6UPpRrTCZRDjumaBq5iiOuury9EGGvU2WT//v358ssvg9qR0oHGCn/llVfw+Xw8+uijNe+7X79+XHHFFbzwwgtSKBNCCCGEEEII0aGMyEzki5X5eP1qzfCL8ZF1u0a8fhWjojAiM7H+DQX8sOA5/XHWOZA6sLVCFkK0hg0Hri8ed67ejQJ8dKCbbPxxKSTHWEMVmRCiKUwWOO0R+OAqUP36kIvmqIPP+716kcwaA+On6usLEcYaVSi7+eabWbVqFdOnTycxMRGTqfF3a3m9Xn7++WemT5/e7CDbm9LSUnw+Hx6Ph4iIgxMX2u127HYZj1UIIYQQQgghRMcyqlcSafE28kpcdIq11nszraZplFR5SU+wMapXUj1bAdZ+BKW5+lwn2be2btBCiJZVtA32rdOHYcs6G4Ct+xws31mKQYFLhqaHOEAhRJOU5EB0KlQV6oXvinxAATQ9z+O660WyjFEhDlSIo2tUxWvixIlMnDiRyy67rFk7Of300/nf//7XrNe2R6effjovvfQSjzzyCM8++yygn/D//PPPPP744yGOTgghhBBCCCGEaFsWk4EHJ2Qx5bO17KvwkBBlqeksA72TrKTKS0yEiQcnZNV6rkZFASyfqT8ecbteLBNCtB8bvtA/9zgZIhOAg91kp/RJJtUe0cALhRBhp2QHrHwXrNEw4SlAgdwF4C7Xj88ZY/ThFqWTTLQTjSqUGQwG/vGPfwS1o4kTJwb1+vbk/PPP55prruG5554jKiqKadOmMWPGDO677z6uuOKKI77W4/Hg8Xjqfa6iogLQ533z+Y4ysbEQHUAo80ByVYjGk1wVon0Ilzw4PG+rc1UIEXrBHleHpMfy+PnH8ewPW8kvc6Oq2sEbzw0KXeMjuP+M3gxJj627DU3DsOB5FJ8bUo8n0OM0CJO/W0LUR86BD+Otwrh1DmgagT5ng8/HzmIni7cXoyhwwaDUsDkXER2L5GozaCrGec9AwIfWbSRqxqn6HGU9Tj1sPeRYLVpMa+dBo8dQjIqKOvpKDcjLy+P111/n5ZdfbvY22puZM2cSExPDf/7zH7799lsuvPBC7rrrrqO+7umnn2batGlHXOeHH34gMjKypUIVot1yOp0h27fkqhCNJ7kqRPsQylw9VGPyVggRGi11XL2mC2yOUthWoeDyg80EvWI1+tqrKNpQzLcb6r4mybGB/vnfoypGlicMwvndd8G8FSFanZwD19aldCm9i/ZSZU3h9xW7Qcnn610GyssV+tg11i6ex9o2i0aIgyRXmy6tZBG9CpfgN1pZ5hyAV47Jog20dq4qmqZprbmDjRs3cu2117Jy5UoCgUBr7qrGF198wbRp01i5cmWb7K8+TqeTL774ggsvvJCbb76Z9957j/vuu69mKMaGHO1OgvT0dIqKioiNjW2NsIVoVyoqKkhKSqK8vLzNc0JyVYjGk1wVon0IZa4eqr6OsvT09JDHJUS4qKiowG63d6zjqs+J8dNJULUf7YSrUU+c1LLbF6IVyDnwITQN4+c3Q2ku6sg70fpdSH6Zi7s+WI2mwT8vHUiPpObfoC9EMCRXm8hRgPGzm8HvRh11D1rWOaGOSHQQrZ2rje4oa6rly5fz3HPP8cknn+D3++udqLelzZo1i6lTp7JixYpW31d+fj7jxo2rs3zu3LkkJydz7rnn8vrrr2Oz2Xj33XeJjIzkueeeIzExkSlTpjS4XavVitVqPeK+zWYzZrM56PcgRHsXyjyQXBWi8SRXhWgfwiUPGpO3QojQCNlxddk74CwCexoMuwGjKTz+XglxJHIOfIiC1VC2E8w2DFlngdnM56t2AArZmQn06RzXNnEIUQ/J1SbQNFj0AgQ8kDYYQ//zwVDPnKJCtILWzoMWL5R9/fXXPPfccyxYsACAVm5YA+D777/nscceY9myZTX7bO3CnM/nY/PmzfUuf+mll9i7dy8ZGRkAKIrCyy+/zKZNm3jiiSe48847iYmJadX4hBBCCCGEEEKIdq9oK6z7VH886k9gkkK6EO3O+i/0z73HgzWafRVu5m0uBODyYemhi0sI0TSbv4P85WC0wMl/liKZOKa0yG+z2+3m5ZdfJisriwsuuID58+ejaRqpqancdddd3HjjjS2xmzrmzp3L6NGjOeuss1i2bFmbFOWqZWRkoGlanY+MjAx++umnOmPHGo1G7rrrLpxOJ5s2bWqzOIUQQgghhBBCiHZJVWHBc6Cp0PNU6JYd6oiEEE3lLIEd8/XH/S4A4JPlu1E1GNwtjj6d5EZyIdoFZwks+bf++MRJYO8a2niEaGFBdZTt27ePGTNm8PLLL1NSUlJTqDr55JO58847ufDCCzEajWiaxhdffNES8QIwb948HnvsMX799VfgYNdaWwzv2Bjdu3fnl19+obKykujo6JrlqqpiMBjo2lX+kAghhBBCCCGEEEe08Sso3AjmSBh5Z6ijEUI0x+ZvQfVDSj9I6k1RpYcfN+4D4LITpZtMiHbj1+fB44DkvnD8ZaGORogW16yOsvXr13PTTTeRkZHBU089RXFxMSaTieuuu44ePXowb948LrnkEoxGI6AXsH755Zegg/31118ZN24c48aN49dff63p4lIUBUVR2rSj7EgeeOABDAYDkydPxufzAXpR8amnnuLuu++mc+fOIY5QCCGEEEIIIYQIY84S+O2/+uPhN0NUUmjjEUI0narCxq/1x/3OB+DzFfn4AxoD0mIZkGYPYXBCiEbL+UXvDDUY4eQH9M9CHGOa1FE2Z84cnnvuOebMmQPonVzR0dHceuut3HPPPaSlpdGvX796XztgwIBmB7lkyRIeffRR5s6dW7NfONhBFi4FsmrdunVj0aJFPPzww/Tv35+0tDRUVeX+++/n2muvDXV4QgghhBBCCCFEeFv8Engr9TvX+10Y6miEEM2RtxQce8EaAz1PpczpZfb6vYB0kwnRbrgrYOEL+uMTroSkXiENR4jW0uhC2YknnsjKlSsBvTDVqVMnJk+ezO23347d3jp3gPz+++88+uijfP/99zX7hfAtkB2qX79+LTrcpBBCCCGEEEII0SHsXg7bfgTFAGPuA0OLTK8uhGhrG77UP/edCCYrny/dgdev0qdTDIPS40IamhCikZa+rHd5x6XDkOtDHY0QrabRZ5vffPMN999/P7Gxsdjtdl577TWmTJnSKkWyFStWcN5555Gdnc33339f7xCL4VwkE0IIIYQQQgghRDP4vfDrP/XH/S/QO8qEEO1PRQHkLdEfH3ceFW4f363Vu8kuH5ZecxO8ECKM7V4Om2aBosApD4LJEuqIhGg1jS6UpaamMn36dPLy8vjLX/7CH//4R4YPH94qXVM7d+4kNze3VgeZFMiEEEIIIYQQQohj3Kr/QfluiEyEE28KdTRCiOba+DVoGnQ9EeLS+Xr1Hly+AD2SohiWER/q6IQQR+NzwYJn9cf9LoDUgSENR4jW1uTxC6Kjo7n//vvJycnhjjvu4NFHH6Vfv3689dZb+P3+FgnqwgsvZM2aNbz//vtkZWXVKZgJIYQQQgghhBDiGFOWpxfKAE66C6zRoY1HCNE8fi9snqU/7nc+VR4/X6/eA0g3mRDtxu9vQMUeiE6B4beGOhohWl2zB/o2mUxcf/31rFmzhmeffZa33nqLzMxMSktLcTqdddZ/4IEHmryPyy+/nHXr1vHOO+/Qu3dvKZgJIYQQQgghhBDHIk2DX5+HgA/SsyFzbKgjEkI0V+58cJVBVDJ0H8WstQVUeQKkJ9gYmZkY6uiEEEdTuBHWfqI/HnM/WCJDG48QbaBFZsQ966yz+Omnn/jss88YM2YM3bp1489//jN5eXkAVFVVMWPGjGZtW1EUrr76ajZs2MCbb75JZmamFMyEEEIIIYQQQohjyba5kL8cjBYYdbc+H4oQon3a8KX+Oets3AH4clU+AJcOTcdgkNwWIqwFfPDLdNBU6H0GdMsOdURCtAlTS27sxBNP5KOPPmL79u08//zz9O/fn6FDh+J0OvF4PEFt22AwcP3113PNNdcwc+ZMnnzySXJzc2sVy2T+MiGEEEIIIYQQIsz5vZAzD3IXgLsczDbYuUh/bsh1YE8LaXhCiCCU5EDBGlAMkHUOs9ftpcLlJ9Uewcl9kkMdnRDiaFb9D0p2QIQdRt4R6miEaDMt0lF2uJ49ezJjxgy2b9/O4MGDWbFiRYtt22g0ctNNN7FlyxZefvll0tPTa3WYCSGEEEIIIYQQIkzlLoSZZ8PXd8HqD2Dzd7DiHSjcAOV5YE8PdYRCiGBUd5NljMYbkcinK3YDcOnQrhilm0yI8FayQz8mg97dbYsLaThCtKVWKZRVS05O5p///Ceffvppi2/bZDJx6623snXrVmbMmEGXLl2ko0wIIYQQQgghhAhXuQvh68lQthNsCRDbBSITABUMRkCBb+/T1xNCtD9eJ2z5QX/c7wLmbNhHmdNHUrSFU7NSQhubEOLIVBXm/wNUP3QfBT1PC3VEQrSpVi2UVTvvvPM46aSTWmXbZrOZ22+/ne3bt/PCCy+QmpraKvsRQgghhBBCCCFEM/m98ONU8DggOlWfiwzAsU//HBGvd5N5HPp6fm+oIhVCNNe2H8HnBHtXfKmDarrJLh7aFbOxTS5BCiGaa/1nsG89mCNh9D0yV6jocNrsKLVgwYJW3b7FYmHy5Mls376dZ599lpQUuVNFCCGEEEIIIYQICznzoHwXRCYevPjmKoWAGxQjRCfry22J+hCMOfNCGa0Qoqk07eCwi/0uYN6WIvY7PMRFmjm9X6fQxiaEOLKKAvjtv/rjEX/Uj8lCdDDH3O0cERER3HvvveTk5IQ6FCGEEEIIIYQQQgDkLtCHdaruJFP94CzSH0cl68UyAJNFfy63dW+2FUK0sH3roXgbGC0Eep/Bx7/nAXDRkDSsJmOIgxNCNEjTYMFz4HdD5xMg65xQRyRESBxzhbJqNpst1CEIIYQQQgghhBACwF1e+2ufS784Z7JBhP2wlZW66wshwlt1N1mv8czf5aGg3E1MhImJAzqHNi4hxJFt+R52L9NvZDn5z2A4ZssFQhyRKdQBCCGEEEIIIYQQ4hh3eDHMGgMmawMra/UUz4QQYctVBjk/A6Aedx4f/6h3k10wKI0Is3STCRG2nCWweIb++MQbIS49tPEIEUJSIhZCCCGEEEIIIUTryhij36Ue8B5cZrQcHIqxmt8LBpO+vhCifdj8HQR8kNyXJY5k8kpcRFqMnH28dJMJEdYW/h94HJDUB46/PNTRCBFSYVco0zSNnTt3ttr2d+/eHfQ2fD4fb775JllZWeTm5ta7TmlpKTfffDNJSUlERESQnZ3N119/HfS+hRBCCCGEEEKIdidzLNi7gbNYH3KxPpoGrmKwp+vrCyHCn6rCRv16l3bceXywTO8mO/eELkRZZSArIcLWjgWQMw8UA5zyIBik+1N0bGFXKFMUhX/84x+UlZW1+Laff/55nE5nUNtYt24djz32GPfccw+bN2+udx1VVTn33HOZOXMmNpuNQCDAb7/9xnnnncdbb70V1P6FEEIIIYQQQoh2x2SB8VP1IRcr99buLAO9k6xyr/78+Kn6+kKI8Jf/O1TkgyWa5eYh7CiqIsJs4LxBXUIdmRCiIR4H/Pq8/njQVZDUK7TxCBEGwq5QBnDPPfdw/fXX43A4Wmyb//3vfykpKaFPnz5BbWfAgAE89dRTXH/99Q2u895775GcnMzu3bvJy8ujuLiYyy67DID777+fQCAQVAxCCCGEEEIIIUS7kzEKzn0R4rqDq1S/uF6xR//sLtWXn/uivp4Qon3Y8CUAWp8zeX/FfgDOGtiZ2AhzKKMSQhzJkpf1Dm97VxjS8DVuITqSsOyB7tmzJ9dddx2jRo3ihRde4LTTTmv2tkpKSnjggQcoKCjgm2++abEY7faGJxbevn07H3/8MSaT/u2NjY3lrbfeYuHCheTn57N//35SU1NbLBYhhBBCCCGEEKJdyBgFN8zSh3vKXQDucoiw63OSZY6VTjIh2pPKQti5CICN8aeyZUU5ZqPChYPTQhyYEKJB+cth04Fr5Kc8IMddIQ4Iy0IZwMUXX4zf7+ess85i6NChXHLJJUycOJG+ffuiKMoRX1tcXMzChQv5+uuv+fjjj5kwYQKffPLJUV/XFAZDw814jzzyCEZj7XFdq+cpmz17NklJSS0WhxBCCCGEEEII0a6YLNDnDP1DCNF+bfwKNBW6DOadTfrcgxMGpBIXKRfehQhLPjfMf1Z/3P8C6HxCSMMRIpyEbaEM4PLLL6dv375cffXV3Hfffdx///1YrVb69OlDly5diImJwWaz4XK5cDqdFBYWkpOTQ0lJCQBWq5VHH32Uhx56qE3jPrxIVs3hcHDZZZfVdJrVx+Px4PF46n2uoqICAJ/Ph8/nCz5QIdq5UOaB5KoQjSe5KkT7EC55cHjeVueqECL05LgqROMd8+fAqh/jxm9A08hJOpW1y8oxGhTOG9hJ/gaIduWYz9VDGH57DaU8H6KSCQy+ESRXRTvS2rka1oUygEGDBrFmzRpef/11/v73v5OTk8OaNWtYs2ZNrQ4xTdNqHlutVq6//noeffRRunQJj8lDS0tLWb16NTNnzjziek8//TTTpk074jo//PADkZGRLRidEO2T0+kM2b4lV4VoPMlVIdqHUObqoRqTt0KI0JDjqhCNd6yfAydXrKNfwQ68pmgeX6JRXlnO8QkqS+fPbfY2hQiFYz1Xq8W48hm863UUTWVtzDmU/PhL0NsUoi21dq4q2qEVpnbgt99+44cffmD58uXs3r2biooKoqOjSU1NJTMzkzPOOINx48a1+on51KlTmTZtGjt27CAjI+Oo6z/00EP079+fa6+99ojrHe1OgvT0dIqKioiNjW1O2EIcUyoqKkhKSqK8vLzNc0JyVYjGk1wVon0IZa4eqr6OsvT09JDHJUS4qKiowG63y3FViDB3rJ8DG769D6VgFft6XsItGwdjUOClqwaRGhvR7G0KEQrHeq4CEPBh/OqPULIDrec41LEPB7c9IUKgtXM17DvKDjd8+HCGDx/eatvPz89n3LhxdZbPnTuXtLTmTUa6aNEiLBbLUYtkoHfDWa3WI65jNpsxm83NikWIY0ko80ByVYjGk1wVon0IlzxoTN4KIUJDjqtCNN4xfQ5cuhP2rgaDkQ8qh6AoMDYrhfTEmOZtT4gQOqZztdra96E0F2xxMHoyRjlOi3aotXO13RXKWpvP52Pz5s31Lm+O3NxcZs2axRNPPBFsaEIIIYQQQgghhBBChNbGrwAoTxnGT3mgKHDZiV1DHJQQol6lubDibf3xSZPBFh/ScIQIV1IoO0xGRgYtNRplQUEBb7zxBo8//nit+dSEEEIIIYQQQgghhGh3fC7YPBuAr3zDABjdK4mu8TI3oRBhR1Xhl39AwAfdRkKvuqOoCSF0hlAH0F6pqgrQYFEtLy+Pl156iUcffRSD4eC3uaioiPvvv79NYhRCCCGEEEIIIYQQosVs/wm8lThtnfhkbycALj0xPcRBCSHqteFz2LcOzJEw5l69/VMIUS8plDXTnj17ANi9e3ed5zZv3syYMWP48MMPGTBgAFlZWWRlZZGZmUmXLl2IiZExm4UQQgghhBBCCCFEO7PhSwB+MY5ExUB2jwR6JEWFOCghRB2OvfDbf/XH2bdBdEpo4xEizMnQi020fPlybr31VlauXAnAOeecw/jx4/n0008BfbjF0aNHU1RU1OA2Lr300jaJVQghhBBCCCGEEEKIFlG4CfZvxouJd4qPAwUuHybdZEKEnN8LOfMgdwG4yyHCDkVbwFsFXQbBceeFOkIhwp4Uyppo6NChLF++vMHnO3fuzP79+9swIiGEEEIIIYQQQgghWtmBbrLV5kE4vNEM6RZH704yapIQIZW7EH6cCuW79DnJAAIevUhmioDR94JBBpUT4mikUCaEEEIIIYQQQgghhKjt0C6Vqv2w/Wf8JhvvuwaCES4f1i3UEQrRseUuhK8ng8cBkYlgtIAagNIdYDCCYoCfn9CHXcwYFepohQhrUigTQgghhBBCCCGEEEIcdHiXit8NXicoRm5R/sP87nfSr8voUEcpRMfl9+o56nFAdCooir68qhC0AJgiIS4dKvfp690wC0yWUEYsRFiTvkshhBBCCCGEEEIIIYSuukulbCfYEiC2CygKmtFMsRZLJ3Uf1xf9U19PCBEaOfP0QnZk4sEimbcSPBWAAjGpekeZLRHK8/T1hRANkkKZEEIIIYQQQgghhBCiVpeKGp1Khc9AUWkpXo8bd0CjXImhypKMVa3S1/N7Qx2xEB1T7gK929N4oEtMU/XuMQBbPJis+mOTBVS/vr4QokFSKBNCCCGEEEIIIYQQQtR0qVSZ7OQUVZFf5gJ3GQFNo1yNxOPXcPlVnCa7dKkIEUru8tpfe6v0gpjRAlFJh62s1F1fCFGLzFHWjmiaBkBFRUWIIxEiPFTnQnVuhAvJVSFqk1wVon2QXBWifZBcFaJ9aLe5uv5HvA4vO71eAhpYFBVVc1IB7NEi8KHi8mk4XNDd4sGy/kdIHdF2b0CIFtZuczUQAW4VzP4DC2xgSQMFcAVqr+sO6OvLMVq0Y62dq1Ioa0ccDgcA6enpIY5EiPDicDiw2+2hDqOG5KoQ9ZNcFaJ9kFwVon2QXBWifTi2crW4nmX/OPAhRPvWfnM1p5FblFwVx4bWylVFC7dyuWiQqqrs2bOHmJgYlOpJGsNcRUUF6enp5OXlERsbG+pwwi4e0bDG/Kw0TcPhcNClSxcMhvAZSbY5uRrq382W2n+o34cIT5KrLSfU+w/3eETDOtpxNdTCLTfCLR4R3M/kWMrVUP9uhnr/Ek/7jKWx8UiutpxQ71/iab8kV9tWqPcv8bTPWBobT2vnqnSUtSMGg4GuXbuGOoxmiY2NDYukqxZu8YiGHe1nFU53+1QLJldD/bvZUvsP9fsQ4UdytWWFev+HC7d4RMM62nE11MItN8ItHtH8n8mxlquh/t0M9f4PJ/E0LJxigY53XA319z/U+z+cxNN+SK62rVDv/3AST8PCKRYIba6GT5lcCCGEEEIIIYQQQgghhBBCiDYkhTIhhBBCCCGEEEIIIYQQQgjRIUmhTAghhBBCCCFakNVq5bHHHsNqtYY6FCD84hHyMxFCCCGEECKcyBxlQgghhBBCCNGCrFYrU6dODXUYNcItHiE/EyGEEEIIIcKJdJQJIYQQQgghhBBCCCGEEEKIDkkKZaJVhduQIuEWj2hYR/tZhfr9ttT+Q/0+hGhtof4dD/X+Dxdu8YiGyc9KCBGOQv23KdT7P5zE0z5igfCLp7WF+v2Gev+Hk3jaj472vQn1+w31/g8n8bSPWCA84lE0TdNCtnchhBBCCCGEEEIIIYQQQgghQkQ6yoQQQgghhBBCCCGEEEIIIUSHJIUyIYQQQgghhBBCCCGEEEII0SFJoUwIIYQQQgghhBBCCCGEEEJ0SFIoE0IIIYQQQog2INNDCyGEEEIIIUT4kUKZEEIIIYQQQrSi3NxcABRFCW0gBxQVFYU6BFEP+bkIIYQQQggRGlIoE0IIIYQQQohWUlBQwGuvvRbqMGps2rSJV155JdRhiMPIz0UIIYQQQojQkUKZCAkZdkaIhoVbfoRbPEKEi3DKjXCKRQhRm9VqZf369ezdu5dAIBDqcIiJiWHjxo04HA78fn+owxEHyM8lvI5l4RRLOJLvT8cWTj//cIolHMn3p2MLp59/OMUSjuT7Ex5CVij75Zdf+POf/0y3bt1QFKXWh8FgIDIykoSEBPr168f555/P008/zdatW0MVrmghMuyMEA2r/hsXLvkRbvkqRLgIp1wNtzyV46oQtWmaRkJCAj179sRisWA0Gv+/vfsOi+Jq2wB+Lx0V7AJW5LVgQ7EjohhbjCXG3kWxa+yKMcaosZuoUYxGY+y9x9gi9og9FoxdUQErihTpu8/3B99OWKnqUmTv33V5CbOzM8/OmWcOO2fOOSk2lmXGF2QRQeHChWFlZQVTU1OYmJhAo9FkWTyUwNDLhfVqyrJbvXr9+nUA2ef4UOZirqaMuUrZCXM1ZcxVSk2WNZQ1bNgQ8+bNw4EDB5Rl3bt3x/379xEbG4vw8HD4+fnh22+/xfPnzzFx4kSUL18evXv3RmhoqF5iuHz5Mt68eaOXbVHaOOwM6Vt2eCpbX8LCwuDt7Q21Wp0tboBkVL7mpDIjw5SdcpX1Kukbr9H6p/3Sa21tDT8/PwCAsbExRAQbNmzAunXrsH37dp11MzoeMzMzFChQAIGBgRARGBkZQURw8OBB7N27F76+vsq6WX2dMxSGXC6sV1OW3erVyMhI/P7774iOjs7qUAAA165dw71797I6jFTlpHqVuZoy5uqnj7maMZirqctuucp6NRsMvViuXDnl5zJlysDBwQEmJiYwNjZGsWLF0L17d5w9exY//fQTVCoV1q5dCzc3N7x+/fqj9z1q1Cg2lGUiDjtD+nT16lUcP34cQM54slaj0eDevXsICQnJ6lAAZEy+5rQyI8OUnXKV9SrpE6/RGSMuLg4AkCdPHty4cQNAwvHt3LkzTp06hSVLlsDT0xPdunVT3pORx18bT3R0NC5duqQ0urRr1w7bt2/HkCFD0K1bN4wcORJAzmuUya4MuVxYr6Ysu9WrKpUKDx48UBpzs1JkZCR27NiRLcopJTmtXmWupoy5+mljrmYc5mrqslOusl5NkOUNZaampulab/To0Zg9ezYAwM/PD3379v2o/S5cuBAnTpz4qG1Q+nHYGdK3EydO4OzZswByRhflfPnywdnZGcbGxlCpVFlaOWVUvua0MiPDlF1ylfUq6Ruv0fpx48YNnD59Gg8fPoSIKN91mjZtioiICADAs2fPEB0djWXLluHPP//ErFmzsGvXLgwYMACAfo//w4cPcf36dURGRgL477vX559/jtjYWADAvXv3YGxsjN9++w2HDx9G586d8csvv2Dy5Ml6j4cSsFz+w3o15XiyW71qaWmJGjVqwMTEJMu/r+TKlQt58+bFzZs3k309O/ytkdPqVeZqyvEwVz9tzNWMwVxNW3bKVdarCbK8oex9jBs3DjVq1AAA7NmzB0ePHv2g7axYsQKjR4/WZ2iUBg47Q/rWrFkznYb25MroUys3jUaD48ePQ0SU/Fi9ejV+//13bNmyJdPiyKh8zYllRoYpO+Qq61XSN16jP96GDRvg6emJHj16oHnz5pg0aZLyhdfY2BgnTpxAbGwsXr9+jXPnzmHPnj0oVKgQunbtiu+//x779u3D1atX9RbPxo0b0a1bNzRv3hwNGjTAihUrlDLMlSsXDh06BAB4/vw5Dh8+jGvXrsHR0RGDBg2Cp6cn/vjjDwQEBOgtHkrAckmK9Wry8WTHejV37tw4deoUgITjo9Fo4O3tjYULF2LRokWZEoNWnjx5EBgYCCDpUEza31O6CZoZcmK9ylxNPh7m6qeNuZoxmKvpk51ylfXqJ9ZQBgAjRoxQfk48rmhERARmzZoFZ2dnVKhQAfnz50e1atUwb948ne6UEyZMwJw5c5QD5+7ujjJlysDd3V1ZJzY2FkuXLkXt2rVRuXJl5MuXDxUqVMC3336rPPVH74fDzpC+WVpa4syZM4iLi0NMTIxSsb58+RIhISFQq9VZ/kRGemmfHK5QoQJevXqlfJYePXrg9OnT2Lx5M3r27InevXvrZdjZtGRUvuakMiPDlJ1ylfUq6Ruv0R/nwYMHWLZsGXbt2oV//vkHVatWxebNm7F3716ICCpWrAh7e3uYmZmhUqVKcHNzw8CBA3Hx4kXkz58fAwcOhI2NDYyNjfUSz/Xr1+Ht7Y0tW7Yoo2jMnTsXV65cAZBwHcuTJw8AoH79+nBycsJXX32Fly9fonTp0hgxYgRiY2Oz9MtwTsRy0cV6Ne14sku9qo3H3t4eT58+BZDw+T08PHDr1i34+vri22+/RdOmTZWG3Iyu511dXZWftTcXv/32W/Tr1w8DBgyAr68vjIyy7pZXTqpXmatpx8Nc/XQxVzMGczV98WSnXGW9+gk2lDVp0kT5WdujLCYmBu7u7pg9ezY2bNiAmzdv4tatWzAxMcH48ePxww8/KO+ZPXu2zsR0x48fx71795QxLgGgffv2GDZsGH788Udcv34dAQEBKF26NGbOnInBgwdn/IfMATjsDGUEbaUQHx8PW1tb5M+fH0DCuMcajQa9e/dGz5494ebmhl69eiEiIkK5uGcnV69eha+vr/JUjZmZGQCgevXqePDgAQAgMDAQISEhyk235cuXY9u2bcr5qE8Zma85pczIMGWnXGW9ShmB12j9UavV8Pf3R0BAAPLnz48lS5ZArVbj5MmTyrmu0Whw/fp1AMCkSZNQunRpNG/eHN7e3tixYwesrKxQsGBBvcQTFxeHkJAQxMXFoUyZMvjzzz8RGBiIgwcPAgAKFCgAlUqF169fQ0Qwfvx4iAiqV6+OAwcO4MKFC7Czs0OuXLn0Eg8liI6ONuhyYb2asuxWr168eBH79+/HmTNnoFarlXjq1q2Lly9fAgDevHmD169fY+rUqdi0aRO2bNmCq1evYvjw4XqPJzlxcXE4e/YsIiMjoVarMWzYMKjValSpUgX37t1Dw4YNsWPHDgCZ9wR8TqlXmaspY67mDMxV5irAXH0X69WEHWY5AAJAvv/++3Stnzt3buU9r1+/lt27dwsAadCggc56q1evFgDi7Oyc4j79/f11ll+5ckUASMmSJXWWHz9+XABI/vz53+uzGaL169dL3bp1xd7eXsqVKycTJ06U+Ph4ERH5999/pWXLlhITEyPXr1+XIkWKyO7du0VE5PXr1zJr1iwpWrSoXLlyRW/xbNiwQVxcXKRo0aJSo0YNWb58uWg0GhER+fvvv6V79+4iInLq1CmxtraWq1eviojIgwcPZNCgQVK1alV5/Pix3uKh9xcZGZns8gkTJsitW7dERGTZsmXi6ekpb9++lW+//VZKliwp1apVk7dv32ZmqGnasGGD1KtXT/73v/9J2bJlZdSoUcprN2/elDZt2khcXJzcvXtXypYtKxs2bBCNRiOxsbGycOFCsba2losXL+otnozK15xUZmSYslOusl4lfeM1Wv+ePXsmrq6u4u7uLhcuXBARkZ9++knmzp0rcXFxIiIyceJE+euvv5T33L9/X4YMGSJffvmltGvXTv7991+9xePn5yeOjo7Sp08fuXHjhoiIfPPNN7Jq1SqJj4+X+Ph48fDwkDNnzoiISHx8vBw/flzatWsn7u7u0qJFC/Hz89NbPIbu+vXrEhkZKbdv35by5csbZLmwXk1ZdqtXtfFUqVJFSpYsKd27d1euYwEBAdK0aVMJCwuTgIAAcXR0lAULFkh8fLyo1WrZtGmTWFtby5EjR/QWz7Fjx2TGjBmycuVKneMeHR0t48ePV3739PSUP//8U0QSroEdOnQQS0tLuXbtmt5iSUlOqleZqyljrn76mKvMVeYq69XUfJINZUWLFlXeExQUJJcvXxYLCwsZN26czno+Pj4CQEqXLp3iPt9tKHvy5Inkz59fOnbsqLP83r17AkBUKtV7fTZDc//+falfv748ffpUXr9+LR07dhQHBwfZtWuXclEaOnSosn779u3FxsZGuaHw+vVrcXZ21tsXQD8/P3FxcZHHjx/L3bt3pUaNGlKmTBn5559/RETk1atXMnDgQGX9+vXri4ODg7x48UJEEiqXChUqyMOHD/USD72/bdu2Se/evaVhw4ayatUqefLkiYiIaDQaGT9+vOzatUtERGbOnCl9+vQREZG3b9/KypUrpXTp0vLtt98q515We/Tokbi4uEhQUJA8efJEBg4cKCVKlJA1a9Yo6yS+jn355ZdiZ2cnx48fF41GI+Hh4VKvXj25fv26XuLJqHzNSWVGhunx48fi6uqaLXKV9SrpG6/RGcfb21scHR3F2tpaxo8fL9WqVZNLly4pr+/du1c2bdqU7Hu1X5b1acKECVK0aFFxdHSUmTNnirOzs3IjQERkzZo1cuzYsSTvi4yMlOjoaL3HY6g2b94s9vb2cuLECRER8fLykmLFihlUubBeTVl2q1efPn0qjRo1ksePH0t8fLyMHz9eSpUqJfPnz1eOz7hx4yQqKkpERIYMGSK5c+eWbdu2SWxsrIiINGjQQE6fPq2XeLZt2yZOTk4yaNAgyZMnj9StW1fngYO+ffvKjRs3JD4+Xtzc3KRp06bKzdkLFy5I+fLl5ddff9VLLKnFmFPqVeZqypirnz7mKnNVhLnKejV1n9zQiwAQHh6u/FygQAFUq1YNERERmDt3LoCE+cp+//13TJkyBcD7dQe0s7PDy5cvsXXrVgAJ47tu3bpVmRtNDHzs3rRw2BnSJx8fH8yYMQNdu3aFhYUFRo0ahUWLFiEqKgoqlQqNGjVScrJMmTJYvXo1duzYgVy5cqFr165wcXHB/fv3s8VQAmFhYbC2toa/vz9evXoFOzs7jB8/HlZWVrh69aqy3uvXr3H69GkAwOLFi1GqVCl06NABs2fPxqZNmyAiyJcvn15iio2N1Xu+5qQyI8MVFRUFf39/vH79OstzlfUq6ROv0fpz6tQprFmzBt7e3krODx06FFu3bsW0adNQrlw5rF27FtWrV1e+i6jVamWScEl4YFHZnomJyUfFc+7cOezbtw9bt27FkSNHAACzZs3Cr7/+io4dO8LIyAgrV66Ek5OTEo9Go1GGstdoNEo8lpaWMDc3/6h4KMG2bdvQtWtXPHr0CKtXrwaQMBXA/Pnz0aVLF4MpF9arKctu9aparcbNmzfh5+cHY2NjeHl5oUSJErh27ZpyfOLi4pQ59n744Qc0adIEPXv2hJeXFxYuXIj4+HgUL178o+IQEURERGDr1q345ZdfsHTpUqxZswZv3rzBli1bEB0dDQCwsrLC8+fPYWxsjGnTpuH06dPw8PBAaGgoatasiZo1a2boPPM5rV5lrqaMufppY64yVw09V1mvps8n11AWHBysNJSVLFkSFhYWABImmQsICMDw4cPRpUsXWFpaYuLEiR+0D2NjY7x69QqTJk1Cq1atEBoaihkzZujtM+Rk1tbWsLe3x/jx43Hx4kUULlwYw4cPh52dHeLj4wEA+fPnVyYqrFatGjZs2IAuXbrAx8cHBw4cwNKlS2FnZ6eXeLRjvk6fPh03b96Era0tRo0aBTs7O6jVaqjVakRHR+POnTtQqVT44osvsGrVKtSuXRtz587Fpk2b8PPPP6Nw4cJ6iYfez99//w13d3c0b94cBw8eRLt27bBkyRKEhIQASBij9tSpU9BoNGjYsCHatWuHjh07YvXq1bC0tIS7uzvMzc0RGxubpY3cmzdvRp06dfDw4UOUL18e3bt3x7179+Dg4ABPT0/ky5dPmWyycuXKSqwlSpTAgQMH0L59e/j5+eHAgQP4/fffUaxYsY+K58KFCwgPD0exYsVQqlQpveZrTikzMmylSpVC8eLF0a1btyzNVYD1KukXr9H6sXv3bowePRoPHjzA2rVr0adPH1SsWBFz586Fg4MDRowYgT59+qBKlSoQEWXS65o1a6JQoUIAEuYY0NfNlj179mDYsGHw8fHBuHHj0KpVKzRo0ABbt25Fs2bNMG3aNIwbNw7Ozs4QEWW/1apVU75LGRkZZZubPznFtm3b0LlzZ5iammLOnDn4999/sWnTJgBAp06d8P3338PLy8sgyoX1asqyQ72auOG+cOHCqFu3LgYPHoyTJ0+iQIEC6NOnD2xtbZU5XRwdHfH27VsACTcct23bhm+//RZhYWH4559/sHLlSpQsWfKjjotKpUKePHkQHByMBQsWAADatWsHT09PnDt3Tlmvfv36CA4OBgDUqFEDP/30E/bu3YtGjRrh66+/xoMHD9C6deuPiiU1Oa1eZa6mjLn6aWOuMlcNPVdZr6bTB/VD0zO8x9CLW7duVdbv37+/snzZsmVia2sre/bsUZYdO3ZMAEipUqVS3Oe7Qy+KiOzatUtsbW11xjD19/dX3kOp47Az9LG0ebdgwQIpXbq0/PHHHyIiolarpW7dukr38Fu3bsk333yjvO+ff/4RDw8PUalU0rp1a6lcubLcvHkz8z9AIlu3bhWVSiVWVlaya9cu2bBhg5QrV05MTExk3Lhx4uzsrHQBFxHZvn27rFixQkQkSVdhbbfrj7FlyxaxtraWVatWiYjIokWLpGLFih+drzmpzMgwBQYGyu3bt5Xxtrdv3y6Ojo5ZlquJsV6lj8VrtH5oNBp58uSJuLu7y+XLl0VEJDg4WPbu3Svly5cXlUolHTp0kJCQEBERZZgSrTdv3kjfvn3lxYsXSV77UA8ePJB69eopOfjw4UNZvHixFC1aVHLnzi2jR4+W8PBwEUko78SCg4Nl+PDhEh0dneQ1+jibNm0SlUolRkZGsnTpUhER+fnnn2Xq1Kki8t+5kdywMDmlXFivpl92q1f/+OMPqVOnjqhUKhkwYIA4OzsrQ2SJiJw8eVIWLlwoIknL6mPPWe321Gq1xMfHy/Tp06VkyZIycuRIERE5ePCg9O7dWyIiIkREZPfu3TJ48GDl/XFxcXLnzh2ZNm2aeHt7y+3btz8qnrTizAn1KnM1/Zirnx7mKnPV0HOV9er7+bgxPrKAt7c3gISWUO1wiGvXrsWgQYOwaNEitGnT5qO2f+zYMXTo0AEjRoxA//79PzrenO7UqVN48OABwsPDUbBgQXTp0gVDhw5FgwYNcPToUeTJkwc9evRAlSpVoNFoYGRkpAw706VLF6V1V/ukpD6GnQkODsbbt29RsGBBNG7cGLNmzYKrqyvOnz+fZHgTIyMjZXgTd3d3aDQa5QlfS0vLjz4+9GG050PNmjUhIpg7dy4CAgJQrlw5mJmZKU9jlypVCqGhoXj9+jUKFCgAZ2dnrFq1CiNHjgSQ8ORG0aJFs+pjKE8Sq1Qq1KlTB97e3jh8+DDc3Nywc+dOFCpUCD179lTyQ6VSwcTEBHfu3AGQcBwk0RPGH5sf27ZtQ5cuXQAA+/btg4eHB77++mtUr14dV65cgYWFxQfna04pMzJMmzZtwsyZM/H48WNERkaiadOmWLVqFQ4fPoytW7fCxsYm03KV9SplBF6j9UOlUsHMzAxAwpO5AFCwYEG0atUKNWvWRMuWLbFjxw6ICFatWgUrKyvl2qDRaJA7d26Ym5tDo9HA2NhYbzFZWVnByckJQEIZDhw4EDVr1oSHhwcWLFgAjUaDGTNmIFeuXDrxqFQqhIaG4u3btyhQoIBe4iHgzp076NmzJwBg6dKlGDBgAACgatWq6NOnD1q0aIFatWoBQJLeYjmlXFivpiy71atHjhzBP//8g/DwcOTLlw9dunRB69at0aBBA+zbtw958uTByJEjUaFCBZ3hQf38/JQySlxWH9sDUnt91Gg0MDExgaenJx48eIANGzbgzJkzMDMzw8yZM5E7d24AQIMGDXD27Fnl/cbGxihbtiy+++67j4ojLTmlXmWupoy5mjMwV5mrhp6rrFff0wc3sekR0tmj7LffflPWHT16tLK8Ro0aAkB2796ts762R1mJEiVS3Oe7Pcrat28vAJSWXK3EPcoM5cmLtOzatUtq1qwpkydPllq1aom5ubk4OjrKnDlzlJZo7bFK3CIeGBioPE2pT7t375aaNWvKyJEjpWTJkmJhYSFubm6yZcsWiYmJSRKPNqbLly/LjBkz9B4Pvb9Xr15JUFCQhIWFKcsOHTok7dq1k+rVq0uXLl3k1KlTIpLwJG5kZKT06tUr2Z6hWW3btm3Kk8Ta3lvt27dP9lxLnB8vXrzIkPNR27PNxMREFi9eLDVq1EhynUsunrTyNSeVGRmmbdu2Sa5cuaRz584yadIkadGihahUKnFxcUmybkbnKutV0jdeo/Xv5cuXYm1tLcuXL1eWaZ+EDQ8Plxo1aohKpZIxY8Yk+0Sqt7e3PHr0SG/x3L9/X/LkyaNMap2Yn5+fODo6ioWFhSxcuDBJLzaNRiPz58+Xp0+f6i0eSnjS1c7OTsaOHass0x77mTNnSq9evSQ0NDTF93/q5cJ6NWXZrV7duXOn1KxZU3788Uf56quvJE+ePFKgQAEZPHiw0jM2uePz9u3bdI0G9L527NghI0aMkKZNm0q3bt1kw4YN8urVKxERefTokZw/f14CAwN14omJiZH27dtLSEhIptynyUn1KnM1ZczVTx9zlbnKXGW9+iGyvKEsLi4uXQ1lmzZtEnNzcwEgHTp00OmaqW0oc3d3Vw6sr6+vuLm5CQCxsrKS2NhYnW6elpaWAiBJdzxtQ1mFChXk+fPnIiJy/fp1+fLLL5U4nz9/Lhs3btTjUfi0cNgZygjbtm2TJk2aSIUKFcTR0VFq164tu3btksjISBERiY6Oljdv3oiIboXy448/yt27d7Mk5pScPn1aVCqVqFQqnRtp69evl0GDBul0fX7Xs2fPpGPHjvL06VO9nY8bN25UGu1++eUXEUmowIcOHSpv3rxJdT+p5WtOKjMyPBqNRiIjI6V///7y22+/KXkQEREhixcvFjs7O/n1119FJONzlfUqZQReozNGaGioNGjQQJycnOT8+fPKcu0QNs+fP5eKFSuKra2tXLlyRUSSH17vYyRugHv27JmUKVNGWrVqJffu3Uuy7rlz56RUqVLi5OQkL168SBKPvofeoQS//PKLrFmzRkR0hxQ6c+aMtGvXTvlyn9I1+1MsF9arqctO9apGo5FXr15JixYt5OLFiyKScGPs+vXrUqtWLVGpVFKzZk15+fKliCQ9PhEREdK9e3e5e/eu3ur5vXv3iqurq/j6+srUqVOlVatWShxbtmxJ9j1xcXGi0Wikb9++8vjxY73EkZqcUq8yV1PHXP30MVcTMFcNO1dZr34Yow/vi6Yf2m6gABAcHIyoqCjld7Vajb///hsdOnRA165dkStXLsydOxdbt27V6ZrZqlUrAMDx48dhZ2cHOzs79O3bF0OHDgUAhIeHo2jRospE2kDC0BcAcPLkSYgIZs2ahYiICGVbN2/eRMmSJVGiRAk0a9YMgwYNUt5boUIFBAYGZsDR+DSkNuzM8ePH4ezsjB07dqBfv34IDw+HsbGx0rU2s4ed2bFjB4oXL44FCxbgu+++Q2RkJIyMjHTiSTy8SeJzhDKPj48PFi1ahF9++QVHjhzB0KFDERUVhU6dOqF///64du0azM3NdYYw0nr79i2OHj0KANliUlUAMDMzQ+7cuTFv3jydIVybNWuGo0ePYsmSJQCQ5HwTEdjY2KBEiRLIkyePXs7HwMBAeHp6AgB++eUXDB48GADg4OCAs2fP4sKFCynuJ7V8zWllRoZHpVLB3NwcIgJnZ2dlCIbcuXOjd+/eqF69Oi5cuAAg43OV9SrpG6/R+hMUFIQ7d+7g2rVrABImLO/Rowf8/PywdOlS+Pv7A0iYODw+Ph5FihTBb7/9hujoaKxcuRKAfoc32rNnD3r37q18F7GxsUHv3r2xb98+rF+/HqGhoTrr16pVC7NmzcKdO3ewfPnyJPFoJzynj/Pvv//C19cXO3fuxJMnT1C3bl1lSoDE1+W6devC1NQUY8eOTfJaYp9iubBeTTum7FKvqlQq5MqVCxEREcpxMjIyQqVKlfD333+jVatWuHTpEpo3b46QkBBlyCYgoaxy586NYsWKwcTE5KPj0X7O3bt34+uvv4aLiwsmT56M1atX48cff8SlS5fQs2dP5fsTACUWExMTqFQqVK5cGQ8fPvyoONKSk+pV5mraMTFXP13M1QTMVcPNVdarHylDmt/SwdfXV77//nuxt7dXemoBECMjI7GxsZHSpUtL8eLFxdHRUbp16yYrVqzQ6YaXWHR0tAwfPlwKFSok+fPnl4EDB0pYWJjEx8eLq6ur2NjYyNq1a3Xec/nyZalSpYpYWVlJz549lZZIjUYj06ZNEzs7O8mTJ4907txZnj17JiIinTp1kvz588ucOXMy9uB8AjjsDOnT2rVrZdasWcrv8fHxcuPGDWnfvr2oVCpp2LChMmGplvZpgsOHDyu9pLKLkJAQ+fLLL+Xvv/8WkYSnV7RPhezbt0/atm0rDx48SPH906dP10t+REVFKU++jxgxQlmuzYElS5ZIw4YN0zz3k8vXnFZmZJjCw8Pl66+/1uldrs3V06dPi5ubm7x9+zbF3iD6ylUR1qukX7xG68fGjRulcuXKYm1tLebm5tKgQQN58uSJiIi0a9dOTExM5JtvvknyxGV0dLR4eXlJixYt9N4z6LfffhOVSiXDhg1Thkrx9/cXV1dXsbS0lGXLlilD32gFBwdLly5dpHfv3nqNhRJs2bJFnJycpFq1alK4cGEpUKCA9OnTR3x9fUVEkowkEBAQIF9++aWcOHEiy2LOKKxXU5Zd6tWoqCgREYmMjBRbW1v54YcflNe0w1RFR0fLl19+KSqVSjp27Chv375Nsp0VK1ak+n0mvbRDYbm7uyvD1Sc+PzZv3qwMH//uPR3terNnz5affvrpo2NJTU6rV5mrKWOuftqYq7qYq4aXq6xXP06WD71InyYOO0P6NH78eKlVq1aS5W/evJFevXqJSqWS9u3bJ1tpnD9/Xvr37y/R0dF6P8c+xr///itBQUFJlt+/f1+++uorOXLkiIgk30VeH86fP69UeuvXr5eZM2eKiO7wPwEBAdKnTx/lRs37dIHPiWVGhunu3btJztP4+Hi5c+eO1K5dWxkeQSThy8H9+/czJA7Wq6RPvEZ/vOTmgzAxMZHatWuLSMJDd/Xr1xczMzMZMWKE3LhxQ+f9u3fvlsaNG+tteBmtffv2SalSpcTExER69OihDBW/c+dOcXBwkDx58sj8+fOVB/20li9fLl988YVeY6GEYW3q168vt2/flqioKLl9+7b06NFDVCqVlC9fXud6rhUeHi59+/aVKVOmZEHEGY/16n+yW72q/X4QFRUlGo1GunfvLoULF5aDBw8m2U90dLS4uLiIsbGx7Nu3L0k8H+vdbXXt2lVq1KghwcHBIqL7HWnLli2iUqmkbNmycvbs2STb8vf31+vN1+TkxHqVufof5mrOwVxlrmoZWq6yXtUPNpRRugQGBsrt27eVsV9FEr5wq1Qq6dOnj86Jq70R7+vrK/ny5ZOvv/5a7/Hs3r1bOnfuLAEBAcqyH374QVQqlUyZMkUZw1RLo9HIxo0bxcLCQqZPn673eOjjbN++XQoXLqwzj6D2YhcWFiadOnUSlUolP//8s4joXuDDwsKSlHd2EBcXp9MoldicOXOkUqVK8vr16wzZ94kTJ6Rv377K/BcREREpji88atQoadSo0XvvIyeWGRmmuLg45Umvd3l4eMjDhw+V3//66y+ZNm2aXvbLepUyEq/RHy6t+SBsbW2VpzP3798vjRs3FiMjI2ndurUcOHBA2c62bdtkwIABem8oO3funPTv319mz56tNJa9evVK4uPjZdOmTVKpUiUxNTWVIUOG6NzEWL16tYwZM0avsVDCE7faPEtc1t99952oVCqpXbu23LlzJ8n7Ll26JCVKlJDjx49nWqyZhfVqguxWr2q/HyS+8bVnzx5RqVTy2WefKXOqiPz3BPyTJ0+kaNGi0qlTJ73H86558+aJSqWSGTNmKL1iE+fUkiVLlGMnkvkNATmxXmWuJmCu5izMVeaqlqHnKuvVD8OGMkoTh52hjPbw4UMpUKCAuLm5KU+eiPx3kXzw4IG4urqKvb19knL9lGg/T2xsrPTt21fWr18vIvrrVabd/tKlS5UnVLTe7dqdeBigpk2byrp1695rX4ZSZmTYunfvLqdPnxaRhFzp1KmT1KtXL8VG8PRivUoZjdfoj6NWq6Vfv35y6dIl5XeRhC9lLVu2lL59+yrrXr9+XcaPHy9mZmZiaWkpX375pYwfP14+++wz+ffff/UeW2hoqEyePFmCgoLk22+/FRMTE+nWrZuIJJT7xIkTZdiwYaJSqcTe3l48PT1l3rx58tlnn+kM20P60alTJ+nYsaPye+IbWU2bNhUjIyNZsGCBiPx3Hmn/HzlypMyaNUvvjanZGevVzK9Xk/t+kPicGzVqlKhUKunWrZtOfaE9HkuXLpXatWvL69ev9XYTbf/+/TJixAhp2bKlfPfdd0pMlSpVkqJFi8qmTZuUXgPafImJiZF+/fpJkSJFlJ60mcnQ6lXmKnP1U8VcZa4mZii5ynpVf9hQRqnisDOkby9evJCAgIAkYwHPmzdPjI2NpXfv3kqlp6VWq2X37t1StGhR2b9/f2aGmyE0Go1MnTpVOnTokCHbb9KkiezYsUNEUm+E086dNmPGDBk7dmyK67HMyNBo66wxY8bI5cuXlZ9z586d7DBa74P1Kukbr9H6l575IMLDw3Xec/HiRdmyZYuMGTNGFi9enGwvIn14+fKldOnSRd68eSNPnjyR7777TkxMTKRt27aSK1cu6dmzp4gk5PT8+fOlZ8+eMn36dDaSZZCZM2dKhQoVZPfu3coybWPZ4sWLpWTJklK1atVkbxbt27dP56nonIz1atbXq4m/HyS+MRcYGCjdunUTlUolbdq0UeZY1jp9+rQ0atQoxd4M72v37t3SoEED+fXXX8XLy0vMzMxk1KhRIpLwdLmNjY1UqFBBdu7cqcz7oo33yJEjUrx4cWV++YxiyPUqc5W5+ilhrjJXRZirrFf1iw1llCwOO0MZYfPmzdK8eXOpWLGiVKhQQerVqydr166V4OBgefnypbRr105UKpUMGDAgyRjDERERUq5cuWw3ueqHUqvVYm9vL0uXLtX7tp2dneXw4cPK74GBgXLhwgU5efKkMhyjyH+V440bN8TW1lap5BNjmZEh0ubGxIkT5ezZszJx4kSxtLRUepd86DZZr5K+8Rqdcd53PojEw95ktKlTp0poaKjy+4gRI8TIyEjKli2bYfNSUPKuXbsmuXPnFkdHR1m0aJFSf+zdu1emTZsmPXv2FEtLS7l161YWR5q1WK9mfb367veDgIAA+eeff+TUqVOya9cu8fLyEpVKJVWqVFHmORYR+eOPP6R79+7KzbWPcf78ealdu7ZOb9udO3dKmzZtJCoqSkJCQmTevHmSN29e+d///ifLli2TkJAQnW188cUXGdrAbOj1KnOVufqpYK4yV5mrrFczAhvKKEUcdob06ejRo9KgQQMJCAiQR48eybp166Ry5cqiUqnkyy+/lCdPnsi9e/ekUaNGyqSNJ06c0NnGN998Iz4+Pln0CfRH2w1+y5YtKc4d9iHi4+Pl9evXUrBgQdm6dauIJIxRXa9ePSlUqJCoVCrJnTu3bNmyRUQSclr7x8vs2bNl6NChOk+1sMzI0I0fP17KlCkj5ubmOmOMfyjWq6RPvEZnrPeZD+LQoUN6mw8iPcaOHSu7du0SkYQv5QULFpRq1aqJiYmJ9O7dWxkahzLHunXrxMLCQlQqlZQoUULc3d2lUaNGEhUVJRcvXhQTExM5duxYVoeZLbBezfx6NbXvBwUKFBCVSiV58uSR9evXy8aNG6Vw4cKiUqmkfv360q9fP2nQoIFcv35dL7EcOHBAhgwZIiIJ19j4+Hi5dOmSjBo1Sul1GRYWJosXLxZ7e3sxMzOT3r17Kw8A7NmzRxo0aJDkJp++sF79D3PVsHM1u2Ou/oe5ati5ynpV/9hQRinisDOkT2vXrpUJEyYov2s0Gnn69Km0bt1aVCqV1KxZU54+fSoPHjwQT09PMTU1FQcHBxk9erQEBgbKhg0bxM3NTadH1KdOX3OTaWk0GlGr1eLg4CAeHh5y/vx5adWqlWzbtk327NkjY8aMEUtLS1GpVPLXX3/pvPfChQtJbqyxzMhQaZ/Q69q1q5iZmYmfn59etst6lfSJ1+isk1HzQaQl8ZwIJ0+elJCQEClUqJD06dNHHj58KFOmTBFLS0v56quvkgw7Qxnr3Llz0qtXL/Hw8JCZM2cqQ8ucP39ejI2Nk3zpNzSsV7OuXk3r+8Ho0aOV7wdXr16VV69eyfHjx2Xu3Lmyfv16vfZS3bFjh5QuXVqnx4NGo5HNmzfL+fPnxcfHRy5duiRBQUFy48YN6dKli9jY2IixsbF06tRJ6tevn2SIL31ivcpcZa5+GpirzFXmagLWq/rHhjJKFYedIX2ZMGGCuLi4KL8nbiTq2LGjqFQqadGihQQHB0t8fLwcOXJEWrVqJQ4ODuLu7i6NGzfmDdl0atu2rRQtWlTWrFmT5EmVLVu2SNmyZeXzzz+X6OjoVBvrWGZkyOLi4uSHH36Qq1ev6nW7rFdJX3iNznwZOR/E+7hy5Yp4enqKtbW19OjRQ5mc+/nz5zJu3DgpVKiQBAUFZVo8lEDbUJp4noqQkBApWbKk/PPPP1kVVrbBejVr69W0vh84ODgo3w8yyvPnz6VevXri6OgoPXv2lKFDh0rXrl2lSJEiYmtrKyqVSlQqlbi4uMiGDRtEROTVq1dy7NgxuXnzZpL5S/SN9WoC5ipzNbtjriZgrjJXWa/qHxvKKFUcdob05cCBA5I7d25ZvXq1sizxxOZffvmlqFQq+eGHH5QbDWq1WtRqtbx9+1bevn2b6TF/arQ3ZlavXi0qlUrc3d3l0aNHIiI6lfP8+fPFzs5OIiIiUt0ey4wMnb7HVRdhvUr6w2t05suI+SA+xMuXL6V8+fIybNiwJPMbvHjxQucGBmUe7fmh0WiU+sPHx0dcXV0zvLfhp4L1aubXq/r+fvCxbty4IX379pXy5ctLuXLlxNXVVVauXCknT56Uw4cPy44dO6RBgwbi4uIiL168yNBY3sV69T/MVeZqdsZc/Q9zlbnKelW/2FBGH4zDzlBaEj9Re/fuXcmXL5/Url1bOW9E/rtIvnnzRurVqycODg4SGRkpIvofmtBQBAUFSdmyZUWlUom3t7eyXHtcg4KCUnyyhWVGlHVYr1JaeI3OHvQ9H8SHCAwM1GkkS3xuUPbh7e0tgwYNkri4OJZRFmC9+p+P+X6gbxqNRrn5tW3btiQ3ZJ8+fSoFChSQvXv3ZkosWqxXsw5z9T/ZKVezE+Zq9sBc/U92ylXWq/rDhjJ6bxx2htJy+vRppXus9mkAEZHFixeLsbGxdOnSRWccXO05dezYMSlcuLBs374984POYS5cuCBWVlZSpEgRWbhwoc5r69atk1atWuk8ncEyI8o6rFcpLbxGZw8ZNR8E5Uw7d+6UsmXLyq1bt7I6FIPDejV57/v9ICNpr6ceHh5KHaVWq5Wbe8OHD5e7d+9m2P5Zr2YPzNXkZadczWrM1eyBuZq87JSrrFf1gw1l9N447Ayl5tmzZ+Lu7i6NGjWSe/fuich/F8DHjx+Lh4eHqFQq8fDwUCpYrTdv3kjlypXl119/zeywc6Tjx49LkSJFxNTUVNzd3eWHH36QWbNmSZ06dXTG+WWZEWUt1quUGl6js5eMmg+Cch5/f3+5fft2VodhkFivpiy93w8yy4wZM6RRo0Y69dfevXulRYsWGTaEFuvV7IO5mrLslqtZgbmafTBXU5bdcpX16sdhQxl9MA47Q8m5f/++ODk5iUqlks8//1zu3Lmj8/qFCxfkq6++EiMjI2nZsqUcPHhQ5/UJEybIgQMHMjPkHM3f319mz54tn3/+uXz55ZcyZMiQJE82s8yIsgfWq5QcXqOzn4yYD4KI9I/1avLS8/0gs9y8eVNsbGykUqVKMmrUKJk4caLUrFkzQ+NhvZr9MFeTl51yNSswV7Mf5mryslOusl79OGwoo/fGYWcoNQcPHpQDBw7IqFGjxMTERJo3b57kInn16lUZOXKkqFQqsbW1lREjRsjdu3dl7dq1UrduXfH398+a4A1Acn9EsMyIshbrVUoNr9FERO+H9er7yeqbjFeuXBEPDw9p0KCBDBw4UP79998M3R/r1eyDufp+sjpXMxtzNftgrr6frM5V1qsfTiUiAqL3FB8fj9mzZ6NNmzZwcnLK6nAoG4mKioKlpSUAYNSoUViyZAk+++wzLF68GGXLltVZ9+jRo1i5ciVOnTqFihUrQqPRYPHixShfvnxWhJ5jiQhUKlWSn7VYZkRZj/UqpYTXaCKi98d6NXVpfT/IChqNBgBgZGSUofthvZq9MFdTlx1zNbMwV7MX5mrqsmOusl59f2woow+mVqthbGyc1WFQNpS4UkjuIikJvVl1Ltbx8fGIjY1Frly5sipsg8YyI8p6rFcpJbxGExG9P9arlBLWq9kLc5VSwlzNXpirlJKckqtsKCOiDKHRaJQLYHIXyeQq2Ozy1IWhYpkREWVfvEYTERHpD+tVok8Dc5Xo05ATcjVj+94RkcEyMjJSuvkuWLAAQ4cOxdGjRzF8+HDcvXsXxsbGePbsmbIOgGx1cTRELDMiouyL12giIiL9Yb1K9GlgrhJ9GnJCrrJHGRFlqOSeKHBzc0O9evXw6tUr/Pjjj9mqmy2xzIiIsjNeo4mIiPSH9SrRp4G5SvRp+JRzlQ1lRJThEl8kvby8MG/ePOTNmxcnTpzgJKDZFMuMiCj74jWaiIhIf1ivEn0amKtEn4ZPNVdNsjoAIsr5tN1vjYyM4OTkhPz58+Pvv/9GhQoVsjo0SgHLjIgo++I1moiISH9YrxJ9GpirRJ+GTzVX2VBGRJnCyMgIkZGRuHv3Lk6cOJHtL47EMjMEcXFxUKvVWR0GEX2gqKgoPH36FMeOHUPp0qURHR2d1SERERF9shLXq2XKlMnqcIgoGbxPQfRp+BRzlUMvElGmio+Ph4kJ2+g/JSyznCcsLAzBwcGIiYnJ6lCI6COJSLabBJmIiOhTlbheNTc3R6FChWBtbZ3FURHRu3ifgujT8CnlKhvKiIiIDEhYWBiCgoKQJ08e5M2bF6amprzJTkRERET0/0QEcXFxCA0NRUREBIoVK8bGMiIiohyODWVEREQG5MGDBzA1NUXx4sXZQEZERERElAIRQWBgIOLi4uDg4JDV4RAREVEGMsrqAIiIiChzxMXFISYmBnnz5mUjGRERERFRKlQqFfLmzYuYmBjExcVldThERESUgdhQRkREZCDUajUAwNTUNIsjISIiIiLK/rR/N2v/jiYiIqKciQ1lREREBoa9yYiIiIiI0sa/m4mIiAwDG8qIiIiIiIiIiIiIiIjIILGhjIiIiIiIiIiIiIiIiAwSG8qIiIiIiIiIiDKQiGR1CERERESUAjaUEREREdF7u3btGgYMGIBKlSq91/uio6OxZs0a1K1bF1OnTs2g6CinEhEcOHAALVu2RN++fbM6HCIC8Pz5cxQvXhyenp5ZHUqWePDgAcaOHYsCBQqkuM6FCxcwY8aMTIwqc4kIDh8+jHbt2qFp06Y6r/n5+aFQoUKYNm1apsXzbpmo1WpMnDgRd+/ezbQYiIiI6NPChjIiIiIyOCdPnsSECRNgamoKlUoFGxsbuLi44LPPPkOlSpVQuXJljB49Gv7+/lkdqo7u3bsjd+7cUKlUUKlU+PPPP9N8z4MHD2BiYgKVSgVra2s0adLko+MICAjA4cOHsW7dOrx9+/a93nv48GHs378f586dM9in62PjNTh26wVm7b+JCTuuYdb+mzh26wVi4zVZHZri1KlTmDhxIszNzaFSqWBlZYVKlSrB3t4exYoVQ4sWLXDgwIFMj8vX1xdHjhzB/v37odFkn+OVY8XHAnf+Av76DvhjeML/d/5KWJ5NnDp1ChMmTICZmZlybSxRogScnJxQunRpODo6omPHjli7di3UarXyvnXr1qFChQrKe1QqFYyMjGBtbY0KFSpg6NChePjwobL+mDFjULRoUZ31TUxMUKBAAdSuXRvTp09HRETEB32GAwcOoEOHDqhVqxYaNGiAzz//HC1atIC3tzeuXr2KWbNmfexhylBRUVEIDg5GUFBQVoeS6cLCwvDHH39g/fr1CAkJSXadnTt3Yvv27Zg0aVImR5d5Ll26hFOnTmHXrl2Ii4vTeS0sLAwhISF48uRJpsSSXJkYGxvj+++/x4QJE/D3339nShxERET0aVGJod6hICIiMjDR0dHw9/dH6dKlYWFhkdXhZAvNmzfHX3/9hcOHD+s0IB06dAi9e/dGdHQ0Dhw4ABcXlyyMUtfjx4/h4OAAtVoNV1fXNG/4DBkyBEuXLgWQ0AusSpUqeouldu3aePHihc7N5PQ4ePAgWrRoge+//x5TpkzRWzyfgnMPXmHOwVsIComCWgQqqCAQGKtUKJbfEl6fO6KOQ8GsDlPxxRdf4MCBAzo5cubMGXTo0AFPnjyBt7c3hg4dmqkxRUZGInfu3OjduzdWr16dqfs2KA9PAz5TgNDHQOJGSSMjIG9JoMkUwN41q6JLokWLFjh48CD+/PNPtGzZUll+4cIFTJo0CX/99Rdq1qyJTZs2oUyZMsrrbdu2xZ49e9C/f3/06NEDL1++xJIlS3Ds2DHky5cPR44cQfXq1QEk1KP29vZ4/vw5Fi9eDCcnJ9y5cwezZs3CgwcP4OTkhBMnTiBfvnzpijk8PByenp44ceIEFi9ejHbt2sHExARAQuOTt7c3vv32W/Tv3x9LlizR38HKAMHBwbC2toaZmVlWh5IlOnXqhG3btiV5AOTs2bMYP348jh07BmNj4yyKLnNER0fD0tISDRs2xPHjx3Vee/78OQoVKpSpxyC5MgkODkaDBg1w8OBBlCxZMl3b4d/PREREhoE9yoiIiMhg2djYJLu8efPm+P333xEaGor+/ftnclSpK1myJGxtbZE3b16cPn0ap06dSnHdFy9eYP369cidOzcAoGLFinqN5UNvGJmbm+s1jk/FuQev8M1OPwS8jkK+XGawy2sJ27wWsMtriXy5zBDwOgrf7PTDuQevsjpUReHChZMsc3Fxwfz58wEAXl5eOr10MgNvVGaCh6eBvcOBN48AywKAddH//lkWSFi+d3jCetmE9lx99/pSq1YtHDx4EIMGDcLFixfRsmVLhIaGKq9rh4+tXbs2GjRogPbt28PHxweurq548+YNBg0apKxrYWGB//3vfwCAzz//HA0aNEC/fv3g6+uL/Pnz49q1a5g5c2a64o2Pj8fnn3+O/fv3w8fHB506dVIayQDA0tIS48aNg7e3N54/f/5hByUTFSpUyGAbyYDkr0vR0dHo1asXvLy8cnwjGZB63W5jY5PpxyC5MilUqBAGDhyI7t27Z2osRERElP2xoYyIiIgMlpFRyn8KNWjQAADw77//pjicUlYxMTHB4MGDASDVIbkWLVqEtm3bKr0b9H2TKrXjlxqVSqXXOD4FsfEazDl4C+HR8bCxNoeZie6xMzMxgo21OcKj4zHn4K1sMwxjSmXl5OQEAHj79i3CwsIyM6QPPu8oneJjE3qSxYQDeWwB43caP4zNEpbHhCesl02GYUztvFCpVFi0aBEqVqyIO3fu6MyPaGpqmuy2Bg4cCCChR1riczy59W1sbPDVV18BAHx8fNIV75QpU+Dr6wsvL69Ue/oOGDAAtra26domZZ3kzr8VK1YgODgYn3/+eRZElPmyW92e0jWhR48e8PX1xaFDhzI5IiIiIsrO+C2TiIiIKBmXL18GkPCEdJ48eZTl8fHxmDFjBurWrQtXV1fY29tj/PjxiI+PV9bRaDSYNGkS3Nzc4OzsDCMjIxQqVEhn+zExMZg8eTJat26NMmXKoHLlyti+fXu64xs5ciQsLCxw4MABXL16NcnrERERWLp0Kby8vFLdzrp169C0aVPUq1cPpUqVwtChQ/HqVdIeTcHBwRgwYACqV6+OevXqwdPTM9n5yT72c2VHIoLoOPVH/Tt2+wUCQ6KQL5cpBIBGJMk/AZAvlykCQ6Jw7PaLj9pfRo+ufuTIEQCAs7Mz8ufPryx/+/Ytxo4di3r16qF27dooU6YM5syZo7x+9epVTJ06FWXLlsXUqVNx8uRJDBs2DGXLloWTk1Oy5/K1a9fwxRdfoE6dOqhTpw7mzZuXbEwxMTGYMmUKPvvsMzg5OaFChQr48ccfldyMjIzE0qVL0bx5c+TOnRsxMTFYuHAhOnfujPz586N58+Z48uQJbt++jZEjR6JGjRooVqwYNm/erM9Dl7FEgLioj/t399D/9yTLD0AA0ST9B0l4/c3jhPU/Zn+ZNBOAqakphg8fDgBYvXo1oqKiUl0/8Xmdnl6T2vXTs25oaCjmz58PlUqVrl7LP/30k87vL1++RL9+/eDm5oZq1aqhUqVKWLVqlfK6u7u7MjeldnjSK1euwMHBASqVCvb29jrb27p1K1xdXeHi4qLMg3n9+nXl9aNHj6Jhw4aoX78+8uXLpzNHZlxcHLZv346mTZuib9++Ott98OABOnbsiEaNGqFChQqoWbOmztyax44dQ9++fVGkSBEcO3YMa9asgYeHB2xsbNCyZUu8efMmzWOjpVarMXPmTNSoUQN16tSBi4sLLl68qLPOqVOnMGzYMNjY2ODu3bsYOHAg8uTJo5wXaR1Xrbdv32L8+PGoVq0a6tevj3bt2uHFixdJ1lu0aBE+++wznYdUHj9+jJUrV6JWrVpo0qQJHj58iAkTJsDFxQVFixbFxo0bk2wnKCgInp6eaNasGRwcHODi4oI9e/Yor4eHh2Pt2rVo2bIlmjVrhhs3bqBGjRooWLAgVq1ahZkzZ6JOnTpo0qQJnjx5gsmTJ6Np06bIly8fhgwZgri4OBw8eBD9+/eHvb09qlatimvXrunEkFZZpiQqKgqrVq1C3bp1dRqop0yZgrx588LV1RXu7u5wd3eHm5ubMv/fyZMnlXX379+Pr776Cq6urrC1tcWIESMQHR39QWUCAAULFkSlSpWS5BUREREZNpO0VyEiIiJDcebMGZw5cybN9ezs7NC1a1edZZs2bcLTp0/TfK+Li4vOnF8xMTHpnnulS5cuKFq0aLrW/VAajQa+vr7o06cPAGDcuHE6PQgmT56MRYsWwd/fH4ULF8aqVavQt29flClTBgMGDAAALFmyBH5+fjh58iRUKhX+/vtvdOnSRWcf7dq1w9dff41p06ZBo9Ggf//+6NixI/bs2YM2bdqkGaeNjQ08PDywbNkyzJ49G5s2bdJ5ffny5ahXr54yrFhyJk2ahMOHD8PHxwdWVla4du0amjRpgqNHj+L06dMoUKAAACAkJARubm5o1KgRLl68CCMjI8ycORO///47SpUqpdfPlR3FxGvQcVnaeZGap6FRCImMQ3h0fJrrxqo1+HaXH+zyWn7w/rYNcoGFqf6HuXr58iVWrFiBadOmoVy5ctiwYYPO6/3794evry9u3rwJS0tLfP/995gwYQKcnZ3RrFkzVK1aFdHR0ZgyZQoOHDgANzc3eHt7IyIiAmXKlIGHh4fSSA0AFy9eRKNGjfDrr7+iW7duiI2NRfv27ZPEpVar0bx5c1SqVAlHjhyBSqXCxo0b0aNHD1y4cAFbtmxBrly5MHjwYGzZsgWRkZH45Zdf0LdvX4wcORJHjhxBkyZN8NVXX6F///5YsGABVCoVvvrqK/Tp0weNGjVKcajWbCU+Gvj9I3uvhD0BIl8DMenoKRgfB/w5OmFIxg/V9yBg+uHn+vto1KgRgIRrmrYxISXa+R+rVq2q02iWktOnT+vsIzU7d+5EVFQU/ve//6Wrt9i7Q9p9+eWXEBGcPn0aRkZG6N27Nzw9PeHi4gJHR0ccP34cU6dO1ZkDslq1arh//z7Kli2r82DHlStXMG7cOFy7dg158+bFs2fPUL9+feX1p0+fokuXLvjnn39QvHhxhIeHo3nz5srrZ8+ehY+PD3x8fNC7d29leXR0NJo0aYJatWrh2LFjUKvVaNasGTp16oQnT54gX758aNSoEc6fP49Vq1bh119/xcyZM9G7d29cvHgRtWrVwtSpU7FgwYI0jw8ADB06FPv27cOVK1dQsGBBbN68GW5ubihTpgwKFSqEadOmwdTUFP/++y9evHiBBQsWoEOHDggICEBMTEy6jiuQ0DDYokULFChQAGfPnoWFhQU2btyYZCi/a9eu4d69e0n+VipZsiQ8PDwwYsQI5MuXDz4+Ppg5cyaMjIzQunVreHp6onHjxsr1JiAgAHXq1MGCBQvQuXNnaDQaDBs2DG3btsWSJUswZMgQhIeHo2jRojh8+DAqVKiAzZs3Y9SoUZgzZw6KFi2Krl27Ytq0abC1tcWRI0cwZcoUGBkZ4bvvvsP06dPx4sULDB06FCtWrEB4eDgqVaqE3r17K9fi9JRlSo4fP459+/bh3LlzOj3rtH8bJe5N+cMPP+Dvv//G4MGDlV7969atw/Hjx7F161aYmpriyJEjaNasGQIDA7Fjx473KpPEtA/xRERE6DwMRURERIaLPcqIiIhIERMTg/Dw8DT/RUZGJnlvZGRkut6rvSGVWHreFx4enmFzIXXv3h2urq6oWbMm8uXLBzc3N7x8+RLe3t744YcfdNY9ePAg7OzslPlw2rZtCyDhZqPWX3/9hbx58yrDENWvXx89evRQXt+4cSMsLS2Vm0ZGRkYYOXIkAGDGjBnpjnvcuHEwNjbGtm3bcP/+fWV5XFwcFixYgAkTJqT43kuXLmHWrFmYNm0arKysACQMpzdr1izcunUL3333nbKul5cX3rx5g4ULFypDGXl5eaFIkSI629TX58qJ1BpBegelUv3/+tnJyJEjUb58eRQpUgRz5szBli1bcO3aNVSoUEFnvYMHD6Js2bKwtExo+EguP7S9K5s2bYrPPvsMAJAnTx64uLjgypUryvxRarUaPXv2RLNmzdCtWzcAgJmZWbJzQC1evBhnzpzBrFmzlLzr1q0bunfvjq1bt2Lbtm3KusWLF1c+U968eQEAjRs3Rv78+WFhYYF+/fop22jSpAmio6Nx9uzZDz94nxpNPN7rZNWk3fibXWjLHgAePXqk85q28UhEsGXLFixcuBAWFhZYvHhxstvSrh8TEwMvLy+cPXsWpUuXxsSJE9OM4+bNmwBSnicTSJgDrXTp0rC3t4e9vT3KlSuHXbt2ISwsDGfOnEHlypWV63Hbtm0hIjq9gBI/xKClUql0jgGQ0DvUyMhIaSywtbXVaWDz9fXF27dvlVyxsrLC3Llzldfd3NyUHlmJ3blzB/7+/sowrcbGxmjVqhWioqJw584dZT3t9aB///5wcHAAAKUuPn78eIrHJ7GgoCAsX74cX331FQoWLAgg4cEaBwcHREVF4dixY3Bzc1N6ggNAixYt0LRpU+zfvx+//vpruo/rvHnzcP78eaxYsUKZA6tbt26oXr26Tkzah460c9olZmxsjPz586N06dLo16+fsr/krjdff/01SpUqhc6dOwNIqFd//vlnlC5dGqNHj0ZAQACKFi2KJk2aoEiRInj16hW++eYb9OjRA35+fmjevDksLCxQqFAhlCpVCj179lT217FjRwAJ8/RpG3itrKxQp04dnWtxessyOS1atEjS0xBIaIBO3Eh26dIl/PDDD3B0dFR6ekVERGDUqFH46aeflAeWGjdujGrVqmHnzp1KHqW3TBJzcHBAXFxcqvO8EhERkWFhjzIiIiJSmJubK40mqcmVK1eyy9Lz3uQme0/P+wD9z7GltWHDBjRp0gRAwjBB+/fvh5eXFxYsWAA7Ozu0a9dOWXfGjBnQaP6bP0p7szXxMF4lS5bE0qVLYWtri0mTJsHa2hqzZ89WXt++fTsuX74Md3d3ZVl8fDxKlSql3JhKDwcHB3Ts2BGbN2/G3Llz8euvvyqfp1SpUsoNweQsX74cGo0GtWrV0lnetWtXDB48GOvWrcOiRYsQGhqK1atXo3PnzjAz+2+uImNjYzg6OurcbNbX58puzE2MsG2QS9orpmLeodvYfSUIttYWaa77LDQabZ2LYVzz8h+8P3MT/T4PN2HCBHTq1AnVq1dXemQkl8ve3t46N+iTyw9tHr+bz9ob8aGhocibNy8OHDiAW7duYezYsTrrVa5cOcl+ly5divLly8Pa2lpnea9evbB+/XqsXr1auSlsYpLwFejd+XSsra2TLMudO7cS0yfBxCKhh9bHODIN8NsGWNmlvW74U6BKR6Dx5A/fn0naOaEvicv33eFJN27ciMOHD+PRo0eIi4tDjx49MHr0aFSsWDHZbU2aNAlxcXG4d+8e8uTJg2+++QZjxoxRGmpSoz2fwsPDU1zn4MGDSo9lExMT3L9/HyVLlgSQ0Gu5YcOGABIalAMDAwEgzeEkk1OyZEk8fPgQbdq0weLFi+Hg4KDzYEfJkiURGRmJZs2aYdmyZahatapOjzMASsN4YpUqVcLcuXOVHlWxsbFKr/P0Xg/Sm3cBAQEQkSTzx1WsWBHbt29HcHCw0iCnzf9354WztrZO87hqNBosXLgQtWrVUh6W0apcuTL++ecf5fe7d+8qnyM5xsbGqV4DgYQGwL1792Lo0KE665mamqJr166YOXMmNm/ejHHjximfzd7ePtny0A7F+e5nBpJeCxNf9/LmzZvuskxJcvFoH6LQbkN7zm3YsEFZ38fHB+Hh4TrrAgnDLJYqVQr3799H+fLl010miWnz9PHjx2nGT0RERIaBDWVERESkeHdYxPfx7vBC6WVubo7Ro0d/0HszgqWlJdq3b4+6deuiUqVKaN++PbZt24YOHToASHg6Oj4+HmvWrMHevXuVhqbEN10nT56MCxcuYN68eVixYgVGjRqFcePGKTd/7ty5g06dOqU419L78PLywubNm7FmzRpMmTIFtra2+PHHH3Ua5pJz4cIFANBp/AISGjzLli2LGzdu4OnTp7h27Rri4uKSHfLy3Ztr+vxc2YlKpfroYQzrlymEP68+QbxaYJZKI1ZsvAYmRirUL1MoQ4ZO/BhmZmb4/fffUa9ePYwZMwZNmzZNMtdRt27dEBUVhUWLFuHEiRNKI8P7zJmmbYjWzlHz7rn37nkXFhaGO3fuJDuMXrVq1QAAt2/fTvf+U4sp21OpPn4YQ4dGwL87E3qKGZulvF58LGBkkrB+Jg2d+LGCgoKUn9/tcdWrVy/069cv3duaPXs2ypQpk+Lr3t7e8Pb21llWu3ZtrF27FiVKlACQcJNeo9EoPXzepR1+zsbGRmkkA4AhQ4YgJCQE06dPx9WrV1GsWDEA75dnWu3atYOHhwdWr16Nv/76Cz169MD06dOVbdaqVQvffvstZs2aBWdnZ7Rp0wazZ89WhiIEkuYkkNAQNG7cODx58gReXl4ICAhQevukN87EederVy+cP39e5/Vhw4Zh2LBhKFeuHMzNzZPMcagdVk87jHBa0jqut27dwsuXL5MdXvPdY6Bt7EruwaK0aD/3pUuXoNFoktTTgP6ubemJ42PLMrnzIzEvLy/cunULs2fP1ukFdufOHVhbW6fas/DGjRvpLpPEtI2BL1++TCN6IiIiMhQcepGIiIgoGcWKFVPmQko8R8qNGzfg7OyMoKAgbN68GV5eXknea2NjgzNnzuC3335D7ty58f3336NOnToICQkBkPCk+rs39D5UtWrV0Lx5c8TExGDBggX4888/oVKp0LJly1Tfpx0+M7l55bTz8VhbWysxp+fJfn1+rpzGtUwhFMtviddvY1O8sSgieP02FsXyW8K1TKFMjjB9ateujdGjRyM8PBx9+vRJ8lm0c87kyZMH27dvh6en5wfvK73nXnrPZUonB3cgb0kg8hWQ0k1wESDqFZC3RML6n4gTJ04AAAoUKABnZ+cM3VdwcDBu376t80/be6VZs2YAEs7t1IZ+0/Y40vaC0tq1axdq1KiBatWqYdu2bUl63LwPY2NjrFq1CkePHoWzszNWr16NypUr49KlS8o606dPx8WLF9G0aVPs2bMHVatWxf79+9Pc9rJly9CoUSO0bdsWGzduVBr+PsTjx4+THM/g4GAACeU5ffp0HD16FLt27QKQ8DDI0aNH8f3336fYEPmutI7r+9SH2oaY5IabTq/sdG3TZ1km5uPjA29vbzRs2FDpGaelVqsRHBys08D9rvcpk8S0jWjv5hYREREZLjaUEREREaVAO2dLREQEACjDT1WuXBkTJ05M9QaLsbExPD09cffuXXh4eMDPzw+//PILAMDe3h5HjhzRmfdE6+eff37vOLVzkS1btgxTp07F+PHj03yCu1KlSgCAixcvJnktKioKjo6OsLa2hp1dwvBriedAS4m+P1dOYmZiBK/PHWFlYYLnYTGIjdftoRQbr8HzsBhYWZjA63PHVHudZbVp06ahXLlyOH78OBYtWqQsDwwMxBdffIGOHTuib9++aZ6DaUnvuWdjY4OCBQvi2bNnSW6oaocFq1OnzkfFYlBMzIAmUwBzKyDiGaCO1X09PjZhublVwnomqfQ6y0bUarVyvg4fPjzDhvLVmjJlCkRE55+2Z0zt2rWVIWrf99p46dIldOrUCV5eXmjVqlWK62k/X3p7QzZq1Ajnzp3DkiVLEBoammSOS2dnZxw6dAg7duyAkZERRowYker29uzZg8GDB2PRokUf3FM9sePHjyc5nonnUhs2bBhat26NFStWoH79+pgyZQo2bdqUZOjWlKTnuL5Pfaidw1P798OH0NbTiRsttTLz2qbvstQKCQmBh4cH8ubNi7Vr1yoNmhqNBhqNRumxvHDhwiTvvXz5Mk6dOvVeZZKYdtjTd+daJSIiIsOVfb+BExEREWWw1IYMiomJwV9//QUAaNq0KQDAz88PQUFBOjdWtNtIvK2xY8cqv1taWmLFihU6vbPatm0LjUaD1q1bw9fXV3n/+vXr0zVfhlqtRnx8vPK7u7s76tSpg/DwcLx8+TLJMJjadRO/p2/fvgCAVatW6awbGxuLO3fuYODAgQAShuMsUKAAjh07luyNqMTbTO/nSu6YGYI6DgUxq10VlChgiTeRsXgaGoVnodF4GhqFN5GxKFHAErPaVUEdh7TnOMos2vJVq9XKMgsLC/z+++8wMjKCl5eXMgfM6dOnER4enmZ+aLeVWs86AMrN6lWrVuns/93YVCoV+vTpA41GgzVr1uis4+fnByMjI50h9bQNB8ntP62YDIa9K9B6EZCvFBAVAoQFAWFPEv6PDklY3npRwnrZRFoNQuPHj8e1a9dQvXp1nUag5K6PqXnf9VOyatUq2NraYteuXVi7dm263+fj44P4+Pg080w739WzZ8+UZbGxsQgODkZs7H+NnwsXLkRAQACAhFwaMmQIWrRoodRX27dvx5kzZ5T127Vrh759+yqvp7T/gwcT5sr7mOvB++Rdz5490alTJ+zfvx9///039u3bpzO/6Lvevaak57g6ODigQoUKuHfvXorDAWrPi6pVqwKAMs9ZcvtP63pTpUoV1KxZE7dv31bqVC0/Pz/Y2dmhdevWqX4uLY1G897XN+3y9JZlSnV7SsuHDBmCoKAgLF26VGdoUV9fXzx+/BjNmjWDpaUlfvrpJ8yZM0c5b+/fv49Ro0ahdu3a71UmiWmHXHx3rjoiIiIyXGwoIyIiIoP14sULAElv3gQGBqJr1664desWKlasiIkTJwIASpcuDVNTU6xduxZ79+7F3r170bVrVxgZGeHWrVtYv349/P39cevWLYwcORLR0dEAgIcPHyI2Nla5aefp6Yk6derg8ePHcHV1RbFixVC4cGFMmDABkyZNSjXm4OBgvHjxAjdu3NBZrr3xO2bMGJ2ebs+ePcOrV68AQOc9LVu2RK9evXD48GH89ttvyvIpU6bA2dkZw4YNA5DQ0LdgwQKo1Wqdm6M3b95Uhr568eIFIiMj0/25/P39leNiaOo4FMTmAS6Y3d4J7asXR+OKRdC+enHMbu+EzQNcsl0j2b///gsg4aZsYq6urhg2bBhiYmLQokULnDhxAuXKlQOQcOP96NGj2LJlC4YOHaq8/5dffkFYWBju3bsHIGn5a4cXe/ToEYCEXjd9+/bF/fv3MXbsWOUGsHZotbt37+Lt27dQq9WYPHkyKlWqhDlz5igNd5GRkfj+++/h5eWlM3+ZtsE38f7fvHmD169f48mTJzo3mg35XIW9K+CxL6FBrGpXoHyLhP9bL0pYno0ayYCU5xq6f/8+OnXqhPnz56N58+Y4cuQIzM3Nlde15/j169fT3EdkZKRyTqRn/dTY29vj1KlTcHJygoeHByZNmoTXr18rr8fHx+PYsWMA/htmD4CSZ9OmTYOvry9WrlyJyZMnA0joeTR//nwACXOLmZqaYvny5Th69CgOHTqEESNGQKVS4fnz5zh8+DACAwMRHx+P7t27Kw1qUVFR8Pf3R6dOnZR9enp6KnmjVqtx+/ZtndeTyxNtnF5eXjh37hwWLFigzNl25swZ5efkrgeRkZEIDQ1FcHAw3r59m+axfPv2LXbu3AlPT0+ULVsWFSpUQOXKlVG7dm3069cPDx48UNbV7ufs2bM620jvcfX29oapqSmGDBmiNII9efJEmT/t5s2biIiIgLu7O8zMzJJ9wCQ8PBwvXrxAUFCQTiPOu9dAAPjtt99gZWWFIUOGKENN+vv747fffsPy5cuVOdDCw8Px+vVr3Lp1C2/evNHZX1hYGF6+fKmUt5Y2tncf0Hm3PNNbltr3vbuf5M6PTZs2YfPmzejRowe6dOmis/8///wTAFCwYEHMnj0bIoIJEyagYMGCKFWqFMqVK4chQ4YoeZzeMknszp07KFiwYIYPwUpERESfECEiIiKDEBUVJTdu3JCoqKisDiXLnThxQsaOHSvGxsYCQExNTaVixYpSr149KVeunBQuXFhq1KghU6ZMkbCwMJ33rly5UmxsbMTOzk6GDRsmoaGh0rhxY7Gzs5OtW7eKiEjLli0FgOTPn19cXV2lfv36snfvXp3thIWFybBhw6Rw4cJiYWEhzZs3lzt37qQad69evaRgwYICQKysrKRRo0bKaxqNRurXry9v375VlnXs2FEKFCggAJT3NGnSRHk9Pj5e5syZI2XKlBFnZ2dp3LixfPfdd8meI1u3bpWKFSuKjY2NdO/eXWbPni2urq7i4uIiP/zwgzx+/Dhdn2v69OmSO3duJaaaNWtKfHx8WkVGmWzu3LlSsmRJpZwASPXq1eXcuXPKOhEREeLg4KC8bm9vL1OnTpX8+fNLqVKlZPLkyRIeHi6Ojo7yv//9T44fPy7e3t6SN29enfJ/9OiRVKtWTVmWP39+8fb2FpGEc3TKlClStGhRcXR0FA8PD9m0aZPkypVLWrVqJb/88otERkaKiMirV69k0KBBUrRoUXFzc5OmTZvKmjVrlHgjIyPFyclJ2U+RIkVk/vz5smnTJilWrJiyvEyZMnL58mXp1KmTco0wMTGRvn37Zm4hULocP35cRo0apZSVmZmZVKpUSerXry81a9aUChUqiKenp/j4+Oi8b+3atVK+fHmdc7xq1aqyc+fOZPczevRosbW1VdY1MzOTunXryoMHDz4qfrVaLRs3bpQOHTpIuXLlpE6dOlK3bl2pVKmStGrVSlatWiXR0dHK+hqNRoYMGSLW1tZSrlw5+fnnn+XZs2diZ2cnVatWFT8/P2XddevWiZ2dneTNm1cGDRokYWFh0qRJE2nZsqVs3rxZoqKiZN68eQJALCwspGbNmlK3bl2ZM2eOaDQaERHZtm2bkgPVqlUTFxcXGT9+vBLTmjVrlHoJgFSuXFlevHghkZGR0rFjR8mTJ484OTnJhg0b5Pr165IvXz5p0KCBPH78WHr37q2Um6WlpfTv318OHDggpUuXVrZXqlQp8fX1TfM4Tp06Vezs7KRgwYJiamqqU64lS5aU6OhoqV27trLM1NRUJ6ff57gePXpUatWqJfny5ZPOnTvLt99+K+3atZNq1arJxIkT5caNGyKSUAfXqFFDJ05fX18pUaKEEkfZsmXl3Llz0q5dOzEzM1Ni8/DwUN7j5+cnrVq1kmLFiknjxo2lbdu2cvr0aeV1Hx8fKVq0qLJNGxsb2b17t7K/xNfysmXLyvHjx2Xs2LFiZWUlAESlUkmNGjXk1atXUrlyZWXdvHnzytKlS9NVlgcOHBA7Ozud/Vy8eFFmz54tefLkUZbXrl1bQkNDJX/+/AJAGjRoIC1btpSWLVvKF198ITVr1hQA4u/vr3y+9evXS+XKlcXMzEzKli0ra9euTVL+6S0TrVKlSsmQIUPSPK9E+PczERGRoVCJGNo4IkRERIYpOjoa/v7+KF26NCwsLLI6HCIiIqKPFhUVhTZt2mDz5s0oWPC/XrlxcXFKj8JVq1bp9CzNDNeuXUONGjUQGBgIGxubTN03pezmzZtwcnLC7du34eDgkOb6/PuZiIjIMHDoRSIiIiIiIiL6JE2ZMgXlypXTaSQDAFNTUzg6OqJJkyYoUKBApsfl5OSEIUOG4Jdffsn0fVPKvL298c0336SrkYyIiIgMBxvKiIiIiIiIiOiTtHz5cuTLly/Z19RqNUxNTVG6dOnMDer//fjjj/D19VXmwqOsdfnyZQQEBOC7777L6lCIiIgom2FDGRERERERERF9klq3bo3Fixdj3bp10Gg0yvLQ0FB4e3tjzJgxWRabqakpdu3ahcWLF+PWrVtZFgcBV69exZo1a7Bp0yaYmppmdThERESUzXCOMiIiIgPBORaIiIgop9FoNFi+fDl+//13BAYGwsHBAfb29qhVqxYGDBgAS0vLrA4RALB//3588cUXWR2GQVKr1di3bx/atGnz3u/l389ERESGgQ1lREREBoJf9ImIiIiI0o9/PxMRERkGDr1IREREREREREREREREBokNZURERERERERERERERGSQ2FBGREREREREREREREREBokNZURERERERERERERERGSQ2FBGREREREREREREREREBokNZURERERERERERERERGSQ2FBGREREREREREREREREBokNZURERERERERERERERGSQ2FBGREREREREREREREREBokNZURERERERERERERERGSQ2FBGREREBi0uLg6rVq2Co6MjHj58mOJ6169fR4sWLeDm5gYXFxesXbs22fVEBLNmzULNmjXh6uqKLl264NmzZ0nW+/HHH1GtWjVUrFgRgwcPRnx8fIr77tatGy5cuJDmZzl16hQmTJgAMzMzqFQqqFQqlChRAk5OTihdujQcHR3RsWNHrF27Fmq1Os3tERERERERERHldGwoIyIiIoN1/fp1fP/99xg1ahRu376d4nrXrl1DgwYN0KtXL5w6dQp79uzBN998g8WLFydZt3///ti+fTuOHz+O06dPo3LlynBzc8Pr16+VdTZs2IDvvvsOBw8exJkzZ7BhwwYsXLgw2X2vWLECTk5OqFWrVpqfx83NDbNnz0bjxo0BAH/++ScCAgJw7do1+Pv7Y926dQgLC0Pv3r1Rt25d3Lt3L81tJketVmPKlCkf9F4iIiIiIiIiouyEDWVERERksCpXroyZM2eid+/eKa4jIhgwYAAqVKiArl27AgCKFCmCESNGYNy4cTqNTfv378fKlSsxe/Zs5MmTBwAwduxYvH79GuPGjVPWW7lyJSpVqgRbW1vkzZsXrq6uWLFiRZJ93759G3/88QfGjx//Xp+rcOHCAABzc3Od5bVq1cLBgwcxaNAgXLx4ES1btkRoaOh7bRsAlixZkmrvOyIiIiIiIiKiTwUbyoiIiEgREhLywf+io6NT3O6bN28+eLtRUVEZ/rnz5s2b4mvHjh3DuXPn8Pnnn+ssb9q0KWJiYnR6lc2ePRuWlpZo2LChsszCwgL169fHunXr8Pz5cwBAUFAQcuXKpayTP39+BAQE6Gw/NjYWw4YNw7Jly2Bk9H5/sqW2vkqlwqJFi1CxYkXcuXMHU6dOfa9tHzp0CGPHjn2v9xARERERERERZVcmWR0AERERZR9Nmzb94PeOHz8enTp1Sva1Dh064M2bNx+03f79+2PgwIEfHFd6pNawtHfvXgAJvc8Sc3JygpGREQ4cOICff/4Zr1+/hq+vLypVqgQzMzOddZ2dnfHHH3/gyJEj6NatG0qXLo2goCDl9eDgYJQqVUrnPd988w2GDBmCYsWKfezHS8LU1BTDhw/HoEGDsHr1asyYMQOWlpYAgGXLlmH16tUwMzPDo0eP0KxZM8yfPx9WVlb4+++/MW/ePMTFxeHgwYNwd3dHmTJl8NtvvyE+Ph5z5szB3r17YWxsjKCgIHTq1AkzZ86EiQn/5CQiIiIiIiKi7Il3LYiIiIhScfXqVQBA8eLFdZYbGxvD2toa9+7dQ3R0NK5fvw61Wp1kPSChxxgA+Pn5AQCGDRuGtm3b4p9//kHhwoVx6tQpzJ07V1n/0KFDiIyMxFdffZVRHwuNGjUCkNCL8MaNG6hRowaWL1+OwYMH499//0XFihVx7NgxfPbZZyhcuDBmzpyJ+vXrw8fHByqVCp9//jlWr16tbG/y5MlYtGgR/P39UbhwYaxatQp9+/ZFmTJlMGDAgAz7HEREREREREREH4NDLxIRERGl4uXLlwAAKyurJK9ZWVlBRBASEpLmegDw+vVrAECrVq2wbt06jBgxAj179sTcuXMxbNgwZX+zZ8/GTz/9BAA4e/YsmjZtCjc3N2zYsEFvnytxg96jR48AAAcPHoSJiQkqVqwIIKExzdraGleuXElzewcPHoSdnZ0yP1rbtm0BIF3vJSIiIiIiIiLKKuxRRkRERJSKmJgYAEh2+MD4+HgAgLm5ebrX0+ratSu6du2aZN2BAwdiwYIFyJUrFwIDA9G0aVOsWrUKtWrVgqOjI6ysrNCmTZuP/lwqlUr5WUQAAOPGjUO7du2U5ffu3YOpqWm65ombMWMGNBqN8ru28S0z5pgjIiIiIiIiIvpQbCgjIiIixeHDhz/4vdo5rpKzfft2pTHmfVlYWHxoSHpRsGBB3L17FyEhIUleCw8Ph7GxMfLnz4+CBQsCQIrrAUChQoVS3dfPP/+M+vXro1q1agCAFStWIDY2Fm3btoWJiQnq1KmDBQsW6KWhLPEcadr50VxcXFC3bl3s3r0bmzZtQtmyZWFsbJyusmvRogXi4+OxZs0a7N27F7Vq1QKADy53IiIiIiIiIqLMwIYyIiIiUmjn0tK3fPnyZch2M0OVKlVw9uxZBAcH6yx/+/YtIiIiUKVKFahUKlSpUgUAkqwHAM+fPwcAVK5cOcX9XLt2DUePHsXu3buVZf/88w8KFSqk9FIrVqwY9u7d+7EfCQBw4sQJAECBAgXg7OwMIKHxrEuXLqhWrRpWr14NS0tLrF+/Pl3bu3HjBjp37oyuXbti8+bNMDExwYQJE/QSKxERERERERFRRuEcZURERESpaNWqFQDgwoULOstv3boFAGjZsiUAoGjRonB2doafn58yDKPWzZs3YWZmhqZNmya7j6ioKAwfPhy//vqrzpCIarUaxsbGyu9GRkY6r38otVqNRYsWAQCGDx+u9Bpr3bo14uPjsXjx4lR7CL4rMjISzZo1Q+XKlTFx4sRkh58kIiIiIiIiIsqO2FBGREREBk87t1ZywwS2bNkS5cuXx6FDh3SWHzp0CJaWlhg6dKiybMyYMYiKisLJkyeVZVFRUTh16hQGDhwIKyurZPc/evRojBs3Dra2tjrLK1asiFevXilxPXv2DP/73//S/XlSMn78eFy7dg3Vq1dXen29ePECly9fRpEiRXTWFZEkx8XIyEhnmZ+fH4KCgnTeq32dQy8SERERERERUXbGhjIiIiIyeE+ePAEABAYGJnnN2NgYq1atwqVLl/DXX38BAO7fv4+ff/4ZCxYsQPHixZV1u3fvjjZt2mDmzJmIi4uDiOC7775D8eLFMWXKlGT3vXv3bpiamio90xLz9PREXFwcTpw4gZcvX+Ls2bMYNGhQmp/n5cuXyS6/f/8+OnXqhPnz56N58+Y4cuQIzM3NASTMn1agQAEcOHAA69atg4+PD3r27ImQkBA8fPgQe/bsUXrV2dra4tGjRwASGgzt7e1hamqKtWvXYu/evdi7dy+6du0KIyMj3Lp1C+vXr4e/v3+acRMRERERERERZTY2lBEREZHBunTpEmrUqIHff/8dQMIwi+3bt0+ynouLC3x8fDBt2jQ0bNgQHh4e+PXXXzFw4MAk627duhXVq1dH3bp14erqivDwcBw/fhwFChRIsm5QUBAWLlyIuXPnJhtfhQoVsGPHDowZMwbNmzfHqFGj0K9fvxQ/z4kTJzB69GgcPnwYQEJvuMqVK8PNzQ21atVC69atYW1tDR8fHxw8eFBn7jhjY2OsXbsWxYoVw6hRo7BmzRrMmzcPHTt2RHh4OB4/foxatWoBAGbMmIErV66gY8eOyJ07N2xsbLBs2TKYm5tj4MCB+Ouvv7B8+XI0atQIAQEBMDc3R+nSpVMuCCIiIiIiIiKiLKISjodDRERkEKKjo+Hv74/SpUvDwsIiq8MhIiIiIsrW+PczERGRYWCPMiIiIiIiIiIiIiIiIjJIbCgjIiIiIiIiIiIiIiIig8SGMiIiIiIiIiIiIiIiIjJIbCgjIiIiIiIiIiIiIiIig8SGMiIiIiIiIiIiIiIiIjJIbCgjIiIiIiIiIiIiIiIig8SGMiIiIiIiIiIiIiIiIjJIbCgjIiIiIiIiIiIiIiIig8SGMiIiIgMjIlkdAhERERFRtse/m4mIiAwDG8qIiIgMhLGxMQAgLi4uiyMhIiIiIsr+tH83a/+OJiIiopyJDWVEREQGwtTUFObm5ggNDeXTsUREREREqRARhIaGwtzcHKamplkdDhEREWUglfBOGRERkcEICwtDUFAQ8uTJg7x588LU1BQqlSqrwyIiIiIiyhZEBHFxcQgNDUVERASKFSsGa2vrrA6LiIiIMhAbyoiIiAxMWFgYgoODERMTk9WhEBERERFlS+bm5ihUqBAbyYiIiAwAG8qIiIgMVFxcHNRqdVaHQURERESUrRgbG3O4RSIiIgPChjIiIiIiIiIiIiIiIiIySEZZHQARERERERERERERERFRVmBDGRERERERERERERERERkkNpQRERERERERERERERGRQWJDGRERERERERERERERERkkNpQRERERERERERERERGRQWJDGRERERERERERERERERkkNpQRERERERERERERERGRQfo/oMPuse+Jm1AAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1750x500 with 14 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "font_path = '/dccstor/data-pruning/miniconda3/pkgs/mscorefonts-0.0.1-3/fonts/times.ttf'  # Your font path goes here\n",
    "font_manager.fontManager.addfont(font_path)\n",
    "prop = font_manager.FontProperties(fname=font_path)\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = prop.get_name()\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_task_name_display(task_name):\n",
    "    if task_name == 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*': return 'AlpacaEval\\n(Win Rate)'\n",
    "    elif task_name == 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len*': return 'AlpacaEval\\n(Tok Length*)'\n",
    "    elif task_name == 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len': return 'AlpacaEval\\n(Tok Length)'\n",
    "    elif task_name == 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/LenMed': return 'AlpacaEval\\n(Medium #Tokens)'\n",
    "    elif task_name == 'MTBench(gpt:4)/Turn-1': return 'MT-Bench(GPT-4)/Turn-1'\n",
    "    elif task_name == 'MTBench(gpt:4)/Turn-2': return 'MT-Bench(GPT-4)/Turn-2'\n",
    "    elif task_name == 'MTBench(gpt:4)/Rating': return 'MT-Bench(GPT-4)/Rating'\n",
    "    elif task_name == 'nonchat': return 'NLP Benchmarks\\n(Average Score)'\n",
    "    else: return task_name\n",
    "        \n",
    "def get_dataset_display(dataset):\n",
    "    if 'dolly' in dataset: return 'Dolly'\n",
    "    elif 'stanford_alpaca' in dataset: return 'Alpaca'\n",
    "    elif 'ultrachat' in dataset: return 'UltraChat'\n",
    "    elif 'sharegpt' in dataset: return 'ShareGPT'\n",
    "    elif 'ultrafeedback' in dataset: return 'UltraFeedback'\n",
    "    elif 'flan_v2' in dataset: return \"FLAN\"\n",
    "    elif 'oasst2' in dataset: return \"OASST2\"\n",
    "    elif 'wizardlm' in dataset: return \"WizardLM\"\n",
    "    else: raise ValueError(f'{dataset} not defined display name')\n",
    "\n",
    "\n",
    "data_to_compute_dict = dfc.set_index(['subset_size']).to_dict()['compute']\n",
    "data_to_compute_pct = lambda x: data_to_compute_dict[x]/max(data_to_compute_dict.values())*100\n",
    "\n",
    "\n",
    "plt_base_model = True\n",
    "plt_full_finetune = True\n",
    "xaxis_type = 'data' # 'compute'\n",
    "yaxis_type = 'abs'\n",
    "yaxis_type = 'delta_fullfinetune'; \n",
    "assert(yaxis_type in ['abs', 'delta_fullfinetune'])\n",
    "\n",
    "if finetune_type == 'sft':\n",
    "    datasets = ['dolly', 'stanford_alpaca50k', 'ultrachat50k', 'sharegpt50k']\n",
    "    datasets = ['flan_v250k', 'dolly', 'stanford_alpaca50k', 'oasst2', 'ultrachat50k', 'wizardlm50k', 'sharegpt50k']\n",
    "else:\n",
    "    datasets = ['ultrafeedback']\n",
    "# datasets = list(np.unique(dfc['dataset']))\n",
    "\n",
    "task_names = []\n",
    "task_names += ['nonchat']\n",
    "# task_names += ['nonchat', 'MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR*',]\n",
    "# task_names += ['MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1',]\n",
    "# task_names += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "# task_names += [f'MTBench({mtbench_judge})/Rating']\n",
    "# task_names += [f'MTBench({mtbench_judge})/Turn-1']\n",
    "task_names += [f'AlpacaFarm({alpacafarm_judge})/WR*'] \n",
    "# task_names += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/LenMed'] # , f'AlpacaFarm({alpacafarm_judge})/Rep2'\n",
    "\n",
    "label_baseline = 'Base Model'\n",
    "\n",
    "plt_settings = {\n",
    "    'color': {\n",
    "        full_sft_short: '#333333', #'#FFA500', # orange\n",
    "#         'Random': 'gray',\n",
    "        label_baseline: 'gray',\n",
    "#         label_dpp_vmf_grad: '#3498db', # bright blue\n",
    "#         label_dpp_vmf_text: '#1f618d', # dark blue\n",
    "#         label_dpp_vmf_text,\n",
    "#         label_dpp_rbf_grad,\n",
    "#         label_dpp_rbf_text,\n",
    "    },\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'axes.titlesize': 25,   # ax title\n",
    "    'axes.labelsize': 19,   # labels (x-axis and y-axis)\n",
    "    'xtick.labelsize': 14,  # xtick size\n",
    "    'ytick.labelsize': 15,  # ytick size\n",
    "    'figure.labelsize': 25, # \n",
    "    'legend.fontsize': 15,  # legend font size\n",
    "})\n",
    "\n",
    "markers_list = ['^', 'o', '*', 'x', 's', ]\n",
    "markers_list = ['o']*10\n",
    "lineplot_kwargs = {'marker': '.', \n",
    "#                    'markerfacecolor': 'none', \n",
    "                   'markersize': 8, \n",
    "                   'alpha': .8,\n",
    "#                    'markeredgewidth': 2,\n",
    "#                    'linewidth': 1.5,\n",
    "                  }\n",
    "\n",
    "w = 2.5; h = 2.5\n",
    "# w = 3; h = 3\n",
    "ncols = len(datasets)\n",
    "nrows = len(task_names)\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(w*ncols, h*nrows), sharey='row', sharex='col')\n",
    "\n",
    "xticks_data = defaultdict(list)\n",
    "\n",
    "for axi, task_name in enumerate(task_names):\n",
    "    d = D[task_name]\n",
    "    for axj, dataset in enumerate(datasets):\n",
    "        ax = axs.reshape(nrows, ncols)[axi, axj]\n",
    "        dataset_size = get_dataset_size(dataset)\n",
    "        is_first_subfig = (axi==0 and axj==0)\n",
    "\n",
    "        if plt_base_model and task_name == 'nonchat':\n",
    "            k = DKey(full_sft_short, dataset, dataset_size)\n",
    "            if k in d:\n",
    "                y_fullfinetune = d[k]\n",
    "                y_base = base_model_perf[task_name]\n",
    "                y = y_base-y_fullfinetune if yaxis_type == 'delta_fullfinetune' else y_base\n",
    "                ax.axhline(y=y, linestyle='--', color=plt_settings['color'][label_baseline], label=label_baseline if is_first_subfig else None, linewidth=2)\n",
    "        if plt_full_finetune:\n",
    "            k = DKey(full_sft_short, dataset, dataset_size)\n",
    "            if k in d:\n",
    "                y = 0 if yaxis_type == 'delta_fullfinetune' else d[k]\n",
    "                ax.axhline(y=y, linestyle='--', color=plt_settings['color'][full_sft_short], label=full_sft_short if is_first_subfig else None, linewidth=3)\n",
    "\n",
    "        sort_by_types = sorted(set(x.sort_by_type for x in d.keys()))[::-1]\n",
    "#         sort_by_types = list(set([x.sort_by_type for x in d.keys()]))\n",
    "        for i, sort_by_type in enumerate(sort_by_types):\n",
    "            xs = sorted([x.subset_size for x in d.keys()\n",
    "                         if x.dataset == dataset and x.sort_by_type==sort_by_type])\n",
    "            xticks_data[dataset] += list(set(xs) - set(xticks_data[dataset]))\n",
    "\n",
    "            ys = [d[DKey(sort_by_type, dataset, x)] for x in xs]\n",
    "            if yaxis_type == 'delta_random':\n",
    "                if not all(DKey('random', dataset, x) in d for x in xs): continue\n",
    "                ys = [y-d[DKey('random', dataset, x)] for x, y in zip(xs, ys)] \n",
    "            elif yaxis_type == 'delta_fullfinetune':\n",
    "                if DKey(full_sft_short, dataset, dataset_size) not in d: continue\n",
    "                ys = [y-d[DKey(full_sft_short, dataset, dataset_size)] for y in ys]\n",
    "            kwargs = {}\n",
    "            if sort_by_type in plt_settings['color']:\n",
    "                kwargs['color'] = plt_settings['color'][sort_by_type]\n",
    "            if full_sft_short not in sort_by_type and is_first_subfig:\n",
    "                kwargs['label'] = sort_by_type\n",
    "            kwargs.update(lineplot_kwargs)\n",
    "            kwargs.update({'marker': markers_list[i]})\n",
    "            xs = xs if xaxis_type == 'data' else [data_to_compute_pct(x) for x in xs]\n",
    "            ax.plot(xs, ys, **kwargs)\n",
    "            ax.grid(visible=True, axis='y')\n",
    "            ax.tick_params(axis='both', which='both', length=6) \n",
    "\n",
    "\n",
    "## left most subfigure set ylabel & yticks\n",
    "for axi, task_name in enumerate(task_names):\n",
    "    task_name_shortened = get_task_name_display(task_name)\n",
    "    ax = axs.reshape(nrows, ncols)[axi, 0]\n",
    "    ax.set_ylabel(task_name_shortened.replace('(', '(▲ ') if yaxis_type.startswith('delta') else task_name_shortened, va='bottom')\n",
    "    if yaxis_type == 'delta_fullfinetune':\n",
    "        if task_name == 'nonchat': yticks = [-3,-2,-1,0,1]\n",
    "        elif 'AlpacaFarm' in task_name and 'WR' in task_name: yticks = [-12, -8, -4, 0, 4, 8]\n",
    "        else: yticks = None\n",
    "        if yticks is not None: ax.set_yticks(yticks, yticks)\n",
    "    \n",
    "\n",
    "for axj, dataset in enumerate(datasets):\n",
    "    dataset_size = get_dataset_size(dataset)\n",
    "    xticks = np.array(sorted(xticks_data[dataset]))\n",
    "    ax = axs.reshape(nrows, ncols)[nrows-1, axj]\n",
    "    c = .05; ax.set_xlim((-N*c, N+c*N))\n",
    "    xticklabels = [f'{x*100:.0f}%' for x in xticks/get_dataset_size(dataset)]\n",
    "    ax.set_xticks(xticks, xticklabels, ha='center', rotation=45)\n",
    "\n",
    "    ax = axs.reshape(nrows, ncols)[0, axj]\n",
    "    ax.set_title(get_dataset_display(dataset))\n",
    "\n",
    "    if yaxis_type != 'abs':\n",
    "        axs.reshape(nrows, ncols)[0, axj].set_ylim((-3.5, 1))\n",
    "        axs.reshape(nrows, ncols)[1, axj].set_ylim((-14, 10))\n",
    "        \n",
    "## data xlabel at the side s\n",
    "axs.reshape(nrows, ncols)[nrows-1, 0].annotate('Data', xy=(-0.4, -.15), xycoords=\"axes fraction\", ha='left', va='center', weight='bold', fontsize=plt.rcParams['axes.labelsize'])\n",
    "## legend at bottom\n",
    "fig.legend(loc='lower center', bbox_to_anchor=(0.5, -.12), ncol=3, frameon=True)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "save_path = os.path.join(assets_dir, 'fig_vmf_grad_vs_random_cross_datasets.pdf')\n",
    "fig.savefig(save_path, bbox_inches='tight', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "aba492aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1             sharegpt50k\n",
       "3             sharegpt50k\n",
       "4             sharegpt50k\n",
       "6             sharegpt50k\n",
       "9             sharegpt50k\n",
       "10            sharegpt50k\n",
       "12            sharegpt50k\n",
       "13            sharegpt50k\n",
       "14            sharegpt50k\n",
       "18            sharegpt50k\n",
       "20         gpt4_alpaca50k\n",
       "24            wizardlm50k\n",
       "25           ultrachat50k\n",
       "26            wizardlm50k\n",
       "28           ultrachat50k\n",
       "29           ultrachat50k\n",
       "30            sharegpt50k\n",
       "33           ultrachat50k\n",
       "34            wizardlm50k\n",
       "36           ultrachat50k\n",
       "37            wizardlm50k\n",
       "38           ultrachat50k\n",
       "39           ultrachat50k\n",
       "40           ultrachat50k\n",
       "44           ultrachat50k\n",
       "45           ultrachat50k\n",
       "47            wizardlm50k\n",
       "48            wizardlm50k\n",
       "51                   lima\n",
       "54            wizardlm50k\n",
       "57                 oasst2\n",
       "58                 oasst2\n",
       "60            wizardlm50k\n",
       "62                 oasst2\n",
       "63                 oasst2\n",
       "65           ultrachat50k\n",
       "66                   lima\n",
       "69            wizardlm50k\n",
       "70                  dolly\n",
       "73     stanford_alpaca50k\n",
       "77     stanford_alpaca50k\n",
       "78     stanford_alpaca50k\n",
       "82     stanford_alpaca50k\n",
       "83     stanford_alpaca50k\n",
       "91                  dolly\n",
       "94     stanford_alpaca50k\n",
       "96                  dolly\n",
       "102                 dolly\n",
       "104                 dolly\n",
       "107    stanford_alpaca50k\n",
       "111            flan_v250k\n",
       "112            flan_v250k\n",
       "113            flan_v250k\n",
       "115            flan_v250k\n",
       "117            flan_v250k\n",
       "Name: dataset, dtype: object"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd81658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6878e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
