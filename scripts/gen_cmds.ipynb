{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da1794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/__init__.py:25: UserWarning: Install `torch` for functionalities dependent on torch\n",
      "  warn(f'Install `torch` for functionalities dependent on torch')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'ppc64le', 'cluster': 'dcs'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "import re\n",
    "from llm.submit import (\n",
    "    multiline_to_singleline,\n",
    "    submit_job_ccc,\n",
    "    submit_job_aimos,\n",
    "    submit_job,\n",
    "        get_run_statistics)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import datetime\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import base64\n",
    "string_to_alphanumeric = lambda s: base64.urlsafe_b64encode(s.encode('utf-8')).decode('utf-8')\n",
    "alphanumeric_to_string = lambda a: base64.urlsafe_b64decode(a).decode('utf-8')\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm, shell_scripts_template_lsf, get_host_info\n",
    "\n",
    "info = get_host_info()\n",
    "arch, cluster = info['arch'], info['cluster']\n",
    "print(info)\n",
    "\n",
    "## jobs submitted in notebook inherits env variables.\n",
    "cache_dir = '/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/cache'\n",
    "os.environ['WANDB_DIR'] = cache_dir\n",
    "os.makedirs(os.environ['WANDB_DIR'], exist_ok=True)\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_PROJECT'] = 'mitibm'\n",
    "##\n",
    "##\n",
    "\n",
    "shell_scripts_template = shell_scripts_template_slurm \\\n",
    "    if arch == 'ppc64le' else shell_scripts_template_lsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8323654",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "850a84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_name = 'ft'\n",
    "# test_run = 1\n",
    "# test_run = bool(test_run)\n",
    "\n",
    "# queue = 'x86_12h' # 'x86_12h'\n",
    "# num_cpus = 20\n",
    "# num_gpus = 1\n",
    "# cpu_mem = 32\n",
    "# require = 'a100_80gb'\n",
    "\n",
    "# # model_name_or_path = 'mosaicml/mpt-7b'; max_seq_length = 2048\n",
    "# # model_name_or_path = 'gpt2'; max_seq_length = 1024\n",
    "# # model_name_or_path = 'gpt2-Large'; max_seq_length = 1024\n",
    "# # model_name_or_path = 'gpt2-xl'; max_seq_length = 1024\n",
    "# model_name_or_path = 'huggyllama/llama-7b'; max_seq_length = 2048\n",
    "\n",
    "\n",
    "# train_file = 'data/processed/oasst1/oasst1_data.jsonl'; train_file_short = 'oasst1'\n",
    "# train_file = 'data/processed/flanv2_cot_oasst1_dolly.jsonl'; train_file_short = 'human_mix'\n",
    "# # train_file = 'data/processed/flanv2_cot_oasst1_dolly_shuffled.jsonl'; train_file_short = 'human_mix_shuffled'\n",
    "\n",
    "# output_dir = f\"results/{model_name_or_path.replace('/', ':')}_{train_file_short}\"\n",
    "# if test_run:\n",
    "#     output_dir = 'jpt_' + output_dir\n",
    "\n",
    "# use_deepspeed = False\n",
    "# # deepspeed_config_file = 'ds_configs/stage3_no_offloading_accelerate_setauto.conf'\n",
    "# # deepspeed_config_file = 'ds_configs/stage3_offloading_accelerate.conf'\n",
    "# deepspeed_config_file = 'ds_configs/stage3_offloading_accelerate_setauto.conf'\n",
    "\n",
    "# use_lora = True\n",
    "# lora_rank = 4\n",
    "# lora_alpha = lora_rank\n",
    "# lora_dropout = 0.05\n",
    "\n",
    "# batch_size_per_gpu = 1\n",
    "# total_batch_size = 128\n",
    "# mixed_precision = 'bf16' # 'bf16', 'fp16'\n",
    "# checkpointing_steps = None # every n steps, where n='1' or every 'epoch'\n",
    "\n",
    "# gradient_acc_steps = int(total_batch_size/num_gpus/batch_size_per_gpu)\n",
    "\n",
    "# print(f\"Training {model_name_or_path} \"\n",
    "#       f\"using {num_gpus} GPUs, \"\n",
    "#       f\"{batch_size_per_gpu} batch size per GPU, \"\n",
    "#       f\"{gradient_acc_steps} gradient accumulation steps.\")\n",
    "\n",
    "# # do use fast tokenizer since mpt-7b does not have a fast tokenizer counter-part\n",
    "# #     --use_slow_tokenizer \\\n",
    "# # do not use flash attention, since having problem installing flash-attn with cuda 12.1\n",
    "# #     --use_flash_attn \\\n",
    "\n",
    "# cmd = f\"\"\"\n",
    "# {'!cd .. && ' if test_run else ''}accelerate launch \\\n",
    "#     --mixed_precision {mixed_precision} \\\n",
    "#     --num_machines 1 \\\n",
    "#     --num_processes {num_gpus} \\\n",
    "#     {'--use_deepspeed' if use_deepspeed else ''}\n",
    "#     {'--deepspeed_config_file '+deepspeed_config_file if use_deepspeed else ''}\n",
    "#     open_instruct/finetune.py \\\n",
    "#     --model_name_or_path {model_name_or_path} \\\n",
    "#     --tokenizer_name {model_name_or_path} \\\n",
    "#     --train_file {train_file} \\\n",
    "#     --max_seq_length {max_seq_length} \\\n",
    "#     {'--use_lora' if use_lora else ''}\n",
    "#     --lora_rank {lora_rank} \\\n",
    "#     --lora_alpha {lora_alpha} \\\n",
    "#     --lora_dropout {lora_dropout} \\\n",
    "#     --preprocessing_num_workers 16 \\\n",
    "#     --per_device_train_batch_size {batch_size_per_gpu} \\\n",
    "#     --gradient_accumulation_steps {gradient_acc_steps} \\\n",
    "#     --learning_rate 2e-5 \\\n",
    "#     --lr_scheduler_type linear \\\n",
    "#     --warmup_ratio 0.03 \\\n",
    "#     --weight_decay 0. \\\n",
    "#     --num_train_epochs 2 \\\n",
    "#     --output_dir {output_dir} \\\n",
    "#     --with_tracking \\\n",
    "#     --report_to tensorboard \\\n",
    "#     {'--checkpointing_steps '+str(checkpointing_steps) if checkpointing_steps else ''}\n",
    "#     --logging_steps 1\n",
    "# \"\"\"\n",
    "\n",
    "# # things to test to see its effects on (1) eval perf (2) runtime.\n",
    "# #\n",
    "# # - int8\n",
    "# # - mixed_precision bf16 or no\n",
    "# # - with/without LoRA\n",
    "# # - LoRA's rank/alpha (alpha typically set to 2*rank)\n",
    "# # - batch size\n",
    "# # - micro-batch size (largest without running out of memory)\n",
    "\n",
    "\n",
    "# cmd = multiline_to_singleline(cmd)\n",
    "# if test_run:\n",
    "#     print()\n",
    "#     print(cmd)\n",
    "\n",
    "\n",
    "# shell_scripts = shell_scripts_template.format(\n",
    "#     conda_env='open-instruct',\n",
    "#     cwd=os.path.dirname(os.getcwd()),\n",
    "#     cmd=cmd,\n",
    "#     log_dir=os.getcwd(),\n",
    "#     save_dir=output_dir\n",
    "# )\n",
    "# out = submit_job_ccc(\n",
    "#     shell_scripts, \n",
    "#     job_name=job_name, \n",
    "#     queue=queue,\n",
    "#     num_cpus=num_cpus,\n",
    "#     cpu_mem=cpu_mem,\n",
    "#     require=require,\n",
    "#     num_gpus=num_gpus,\n",
    "#     test_run=test_run,\n",
    "# )\n",
    "# if not test_run:\n",
    "#     print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c8b",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune_trainer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d611cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = '00:33:12'\n",
    "n = 15\n",
    "# total = 1515; nnodes = 1\n",
    "# total = 2083; nnodes = 1\n",
    "total = 1587; nnodes = 1\n",
    "# total = 1041; nnodes = 1\n",
    "# total = 4228; nnodes = 1\n",
    "# total = 4512; nnodes = 4\n",
    "# total = 4296; nnodes = 1\n",
    "# total = 2254; nnodes = 2\n",
    "# total = 1128; nnodes = 4\n",
    "# total = 1074; nnodes = 4\n",
    "# total = 1252; nnodes = 4\n",
    "\n",
    "l = [int(x) for x in t.split(':')]\n",
    "t = l[0]*60*60+l[1]*60+l[2]\n",
    "# t = t/60/60 # in hr\n",
    "\n",
    "print(f'{t/n/nnodes:.0f}s/it, {t/n*total/60/60:.1f}hrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51bf7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# how to sample mixture sample size?\n",
    "# \n",
    "# approaches: \n",
    "# (1) want sufficient coverage for #datapoints/dataset, #datasets used, total sample size.\n",
    "#  Use 5k as a unit of data, sample different #unit/dataset, and vary total units of data.\n",
    "# (2) specify a total sample size and a mixture weight. this answers the question, given a \n",
    "#  fixed compute budget, what is the optimal mixture. this seems to be a simpler approach.\n",
    "#\n",
    "# experiments\n",
    "# (1) first use samples from a single dataset for tuning. \n",
    "# (2)\n",
    "# \n",
    "\n",
    "\n",
    "datasets = ['baize', 'code_alpaca', 'cot', 'dolly', 'flan_v2', 'gpt4_alpaca', 'oasst1', 'self_instruct', 'sharegpt', 'stanford_alpaca', 'super_ni', 'unnatural_instructions']\n",
    "total_data_points = 200000\n",
    "\n",
    "subsample_mixture_list = []\n",
    "subsample_mixture_list += [\n",
    "    {k: 100000} for k in datasets if k != 'flan_v2'\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    {k: int(total_data_points/4) for k in ['cot', 'flan_v2', 'dolly', 'oasst1']}\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': 0.48785105, 'flan_v2': 0.48785105, 'dolly': 0.00732313, 'oasst1': 0.01697478}.items())\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    {k: int(total_data_points/len(datasets)) for k in datasets} \n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': .07678, 'flan_v2': .9137, 'dolly': .004471, 'oasst1': .009072}.items())\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': 0.1127, 'flan_v2': 0.8726, 'dolly': 0.01395, 'oasst1': 0.001391}.items())\n",
    "]\n",
    "subsample_mixture_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d47226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up checkpoints `optimizer.bin` to save disk space. \n",
    "# (e.g., 7b model, ~8*7=56GB for storing gradient/momentum in `optimizer.bin`)\n",
    "\n",
    "import glob, os\n",
    "\n",
    "def cleanup_checkpoints(save_dir, test_run=False):\n",
    "\n",
    "    checkpoints = glob.glob(os.path.join(save_dir, 'checkpoint-*'))\n",
    "    checkpoints = sorted(checkpoints, key=lambda x: int(x.split('-')[-1]))\n",
    "    checkpoints = checkpoints[:-1]\n",
    "    \n",
    "    if not checkpoints: return\n",
    "\n",
    "    for ckpt_path in checkpoints:\n",
    "        optimizer_bin_path = os.path.join(ckpt_path, 'optimizer.bin')\n",
    "        if os.path.isfile(optimizer_bin_path):\n",
    "            print(optimizer_bin_path)\n",
    "            if not test_run:\n",
    "                os.remove(optimizer_bin_path)\n",
    "        \n",
    "        \n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "exp_dirs = [\n",
    "    '../results/ft1',\n",
    "    '../results/ft2',\n",
    "    '../results/oi3',\n",
    "    '../results/oi4',\n",
    "    '../results/oi4_perf_cross_time',\n",
    "    '../results/oi4_tulu_v1_human_mix',\n",
    "    '../results/oi4_flanv2_prune_with_hmv1_model',\n",
    "    '../results/oi4_flan_v2_vary_subsetsize',\n",
    "]\n",
    "\n",
    "print('Remove extra files (e.g., optimizer.bin) for non-latest checkpoints:')\n",
    "\n",
    "for exp_dir in exp_dirs:\n",
    "    for run_name in os.listdir(exp_dir):\n",
    "        save_dir = os.path.join(exp_dir, run_name)\n",
    "        if os.path.islink(save_dir): continue\n",
    "        cleanup_checkpoints(save_dir, test_run=test_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19aebd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results/baselines/huggyllama/llama-7b using 6 GPUs, 2 batch size per GPU, 2 gradient accumulation steps, Effective batch size 120\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm:llama-7b\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 512,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=oi5_wizardlm:llama-7b --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmpf3_5j2ly', 'job_id': 1221517}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm:llama-7b\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 512,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=oi5_wizardlm:llama-7b --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp0uw99os6', 'job_id': 1221518}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm:llama-7b\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 512,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=oi5_wizardlm:llama-7b --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp1y_g7bpg', 'job_id': 1221519}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm:llama-7b\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 512,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=oi5_wizardlm:llama-7b --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp5_36eq9h', 'job_id': 1221520}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm:llama-7b\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 512,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=oi5_wizardlm:llama-7b --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmpu8hx2sen', 'job_id': 1221521}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm:llama-7b\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 512,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=oi5_wizardlm:llama-7b --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmpkbze4fci', 'job_id': 1221522}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm:llama-7b\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 512,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=oi5_wizardlm:llama-7b --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmpcl6wcg32', 'job_id': 1221523}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm:llama-7b\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 512,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=oi5_wizardlm:llama-7b --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp01dwulgq', 'job_id': 1221524}]\n"
     ]
    }
   ],
   "source": [
    "def compute_mixture_num_samples(mixture, max_train_samples):\n",
    "    s = sum(mixture.values())\n",
    "    mixture = {k: int(max_train_samples*v/s) for k, v in mixture.items()}\n",
    "    return mixture\n",
    "\n",
    "add_hardwarespec_to_dirname = False\n",
    "num_cpus = 144 if arch == 'ppc64le' else 32\n",
    "cpu_mem =  512 if arch == 'ppc64le' else 64\n",
    "\n",
    "\n",
    "save_strategy = 'steps'\n",
    "save_steps = 100\n",
    "save_total_limit = 1\n",
    "preprocessing_num_workers = 32\n",
    "evaluation_strategy = 'steps'\n",
    "eval_steps = save_steps\n",
    "\n",
    "\n",
    "dataloader_sampler = None\n",
    "hf_models_dir = 'results/baselines/'\n",
    "# model_name_or_path = 'results/baselines/gpt2-medium'; abbr_model_name = 'gpt2m'; max_seq_length = 1024\n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = 'results/baselines/NousResearch/Llama-2-7b-hf'; abbr_model_name = 'llama2-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = 'mosaicml/mpt-7b'; abbr_model_name = 'mpt-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-1.4b'; abbr_model_name = 'pythia-1.4b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-2.8b'; abbr_model_name = 'pythia-2.8b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-6.9b'; abbr_model_name = 'pythia-6.9b'; max_seq_length = 2048\n",
    "\n",
    "\n",
    "\n",
    "subsample_mixture_list = []\n",
    "# subsample_mixture_list += [\n",
    "#     {k: max_train_samples} for k in datasets\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     {k: int(max_train_samples/4) for k in ['cot', 'flan_v2', 'dolly', 'oasst1']}\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     ('humanmix', dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {'cot': 0.48785105, 'flan_v2': 0.48785105, 'dolly': 0.00732313, 'oasst1': 0.01697478}.items()))\n",
    "# ] # humanmix mixture.\n",
    "# subsample_mixture_list += [\n",
    "#     {k: int(max_train_samples/len(datasets)) for k in datasets} \n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {'cot': .07678, 'flan_v2': .9137, 'dolly': .004471, 'oasst1': .009072}.items())\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {'cot': 0.1127, 'flan_v2': 0.8726, 'dolly': 0.01395, 'oasst1': 0.001391}.items())\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {'cot':  0.13568177819252014, 'flan_v2': 0.3957784175872803, \n",
    "#      'dolly': 0.05964866653084755, 'oasst1': 0.4088916480541229}.items())\n",
    "# ] # gpt2-medium_humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {\"cot\": 0.360595703125, \"dolly\": 0.0021991729736328125, \"flan_v2\": 0.63037109375, \"oasst1\": 0.0016956329345703125}.items())\n",
    "# ] # pythia-1.4b humanmix_uniform:200k_doremiv1.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {\"cot\": 0.2254638671875, \"dolly\": 0.01409149169921875, \"flan_v2\": 0.1739501953125, \"oasst1\": 0.59423828125}.items())\n",
    "# ] # pythia-1.4b humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {\"cot\": 0.08563232421875, \"dolly\": 0.54296875, \"flan_v2\": 0.347900390625, \"oasst1\": 0.0103302001953125}.items())\n",
    "# ] # llama-7b_humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {\"cot\": 0.0316162109375, \"dolly\": 0.204833984375, \"flan_v2\": 0.40966796875, \"oasst1\": 0.40966796875}.items()\n",
    "#         )] # llama-7b_humanmix_uniform:600k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_normalized_list = []\n",
    "# subsample_mixture_normalized_list += [('uniform:1200k_doremiv2', # llama-7b_humanmix_uniform:1200k_doremiv2.json\n",
    "#                                        {\"cot\": 0.11419677734375, \"dolly\": 0.1024169921875, \"flan_v2\": 0.204833984375, \"oasst1\": 0.204833984375})]\n",
    "## 10 for trying out datamodels\n",
    "# mixes = [{'cot': 0.37664033529374275,\n",
    "#   'dolly': 0.0874640765523398,\n",
    "#   'flan_v2': 0.39740799933549775,\n",
    "#   'oasst1': 0.1384875888184196},\n",
    "#  {'cot': 0.23064419241874784,\n",
    "#   'dolly': 0.04693354147889885,\n",
    "#   'flan_v2': 0.72121745986295,\n",
    "#   'oasst1': 0.0012048062394032465},\n",
    "#  {'cot': 0.11244721555034376,\n",
    "#   'dolly': 0.21997027355988638,\n",
    "#   'flan_v2': 0.5826671754210359,\n",
    "#   'oasst1': 0.08491533546873392},\n",
    "#  {'cot': 0.27704626812045546,\n",
    "#   'dolly': 0.5712282144637615,\n",
    "#   'flan_v2': 0.024940119654536592,\n",
    "#   'oasst1': 0.12678539776124645},\n",
    "#  {'cot': 0.0024519793352964607,\n",
    "#   'dolly': 0.13274603201304974,\n",
    "#   'flan_v2': 0.012268378167304219,\n",
    "#   'oasst1': 0.8525336104843496},\n",
    "#  {'cot': 0.08065633865016615,\n",
    "#   'dolly': 0.41886215168938545,\n",
    "#   'flan_v2': 0.21723932820070485,\n",
    "#   'oasst1': 0.2832421814597436},\n",
    "#  {'cot': 0.13878643021160036,\n",
    "#   'dolly': 0.05686171157146557,\n",
    "#   'flan_v2': 0.6701353469446995,\n",
    "#   'oasst1': 0.13421651127223455},\n",
    "#  {'cot': 0.2461125374866837,\n",
    "#   'dolly': 0.09774240280444893,\n",
    "#   'flan_v2': 0.13974091986040005,\n",
    "#   'oasst1': 0.5164041398484672},\n",
    "#  {'cot': 0.4069781049152398,\n",
    "#   'dolly': 0.06318759506033228,\n",
    "#   'flan_v2': 0.09504719644992135,\n",
    "#   'oasst1': 0.4347871035745066},\n",
    "#  {'cot': 0.22379693013848484,\n",
    "#   'dolly': 0.30565901275011814,\n",
    "#   'flan_v2': 0.15457716965000887,\n",
    "#   'oasst1': 0.31596688746138824}]\n",
    "\n",
    "# mixes = [\n",
    "#     {'cot': 0.46638974, 'dolly': 0.01456044, 'flan_v2': 0.50886009, 'oasst1': 0.01018973},\n",
    "#     {'cot': 0.39744481, 'dolly': 0.00472114, 'flan_v2': 0.59104177, 'oasst1': 0.00679229},\n",
    "# ]\n",
    "\n",
    "# subsample_mixture_normalized_list += [('', d) for d in mixes]\n",
    "# subsample_mixture_normalized_list += [('humanmix', # humanmix\n",
    "#                                        {'cot': 0.48785105, 'dolly': 0.00732313, 'flan_v2': 0.48785105, 'oasst1': 0.01697478})]\n",
    "# subsample_mixture_normalized_list = [(x[0],  compute_mixture_num_samples(x[1], max_train_samples)) \n",
    "#                                      for x in subsample_mixture_normalized_list]\n",
    "# subsample_mixture_list += subsample_mixture_normalized_list\n",
    "\n",
    "\n",
    "subsample_mixture_list = [('',None)]\n",
    "subsample_inds_file_list = [None]\n",
    "\n",
    "\n",
    "train_file = 'data/processed/all.jsonl'; abbr_train_file = 'all'\n",
    "\n",
    "\n",
    "\n",
    "max_train_samples_list = [None]\n",
    "num_train_epochs_list = [1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def subsample_inds_file_abbr_fn(x):\n",
    "    s = os.path.basename(x).split('.pkl')[0]\n",
    "    if s.startswith('inds_'):\n",
    "        scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "        pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "        return f'score={scoring_fn}_pace={pacing_fn}'\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "# ft1: reproduce open-instruct table with llama7b\n",
    "# job_name = 'ft1'; num_train_epochs_list = [2]\n",
    "# job_name = 'ft1_ep=1'; num_train_epochs_list = [1] # train for 1 epoch (baseline for comparison.)\n",
    "# job_name = 'ft1_ep=2'; num_train_epochs_list = [2]\n",
    "# job_name = 'oi2'; num_train_epochs_list = [5, 10]\n",
    "\n",
    "# model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# train_file = 'data/processed/lima/lima_data.jsonl'; abbr_train_file = 'lima'\n",
    "# # train_file = 'data/processed/cot/cot_data.jsonl'; abbr_train_file = 'cot'\n",
    "# # train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2'\n",
    "# # # # train_file = 'data/processed/wpq/cot_flanv2_data.jsonl'; abbr_train_file = 'cot:flanv2'\n",
    "# # # # train_file = 'data/processed/tulu/tulu_v1_human_mix.jsonl'; abbr_train_file = 'hmv1'\n",
    "# # train_file = 'data/processed/tulu/tulu_v1_mix.jsonl'; abbr_train_file = 'tuluv1m'\n",
    "# train_file = 'data/processed/sharegpt/sharegpt_data.jsonl'; abbr_train_file = 'sharegpt'\n",
    "\n",
    "\n",
    "\n",
    "# model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048\n",
    "# train_file = 'data/processed/ultrachat/ultrachat200k_train_data.jsonl'; abbr_train_file = 'ultrachat200k'\n",
    "# train_file = 'data/processed/lima/lima_data.jsonl'; abbr_train_file = 'lima'\n",
    "\n",
    "# # max_train_samples_list = [120]; save_steps = 1; save_total_limit = 100\n",
    "\n",
    "\n",
    "\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly'\n",
    "# # train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1'\n",
    "# # train_file = 'data/processed/super_ni/super_ni_data.jsonl'; abbr_train_file = 'super_ni'\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca'\n",
    "# # train_file = 'data/processed/baize/baize_data.jsonl'; abbr_train_file = 'baize'\n",
    "# # train_file = 'data/processed/self_instruct/self_instruct_data.jsonl'; abbr_train_file = 'self_instruct'\n",
    "# # train_file = 'data/processed/code_alpaca/code_alpaca_data.jsonl'; abbr_train_file = 'code_alpaca'\n",
    "# # train_file = 'data/processed/unnatural_instructions/unnatural_instructions_data.jsonl'; abbr_train_file = 'unnatural_instructions'\n",
    "# # train_file = 'data/processed/gpt4_alpaca/gpt4_alpaca_data.jsonl'; abbr_train_file = 'gpt4_alpaca'\n",
    "\n",
    "\n",
    "# # ft2: test mixture weights\n",
    "# # vary mixture weights\n",
    "# job_name = 'ft2'\n",
    "\n",
    "# # oi3: instruction tuning performance w.r.t. steps.\n",
    "# job_name = 'oi3'\n",
    "\n",
    "# # oi4: data pruning \n",
    "# job_name = 'oi4_flan_v2_vary_subsetsize'\n",
    "# train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2'\n",
    "# subsample_mixture_list = [('',None)]\n",
    "# max_train_samples_list = [int(pct*100000) for pct in [.1, .3, .5]]; num_train_epochs_list = [2]\n",
    "# data_inds_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b/flan_v2/'\n",
    "# subsample_inds_file_list = [\n",
    "# #     os.path.join(data_inds_dir, 'random.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'prob_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'prob_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_k=Kcos.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_k=Kcosp.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_k=Kcos1np.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeanscd_nc=3000_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeanscd_nc=3000_decr.pkl'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# # oi4_perf_cross_time: perf cross time on flan_v2\n",
    "# job_name = 'oi4_perf_cross_time'\n",
    "# save_steps = 50; save_total_limit = 200\n",
    "# train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2'\n",
    "# subsample_mixture_list = [('',None)]\n",
    "# max_train_samples_list = [int(pct*100000) for pct in [.3]]; num_train_epochs_list = [3]\n",
    "# data_inds_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b/flan_v2/'\n",
    "# subsample_inds_file_list = [\n",
    "#     os.path.join(data_inds_dir, 'random.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=300_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=300_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=1000_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=1000_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'prob_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'prob_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'dppmap_k=Kcos.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'dppmap_k=Kcosp.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'dppmap_k=Kcos1np.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'el2n_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'el2n_decr.pkl'),\n",
    "# ]\n",
    "\n",
    "# # ## oi4_flanv2_prune_with_hmv1_model\n",
    "# job_name = 'oi4_flanv2_prune_with_hmv1_model'\n",
    "# save_steps = 50; save_total_limit = 200\n",
    "# train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2'\n",
    "# subsample_mixture_list = [('',None)]\n",
    "# max_train_samples_list = [int(pct*100000) for pct in [.3]]; num_train_epochs_list = [3]\n",
    "# data_inds_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b_ft=hmv1/flan_v2/'\n",
    "# subsample_inds_file_list = [\n",
    "# #     os.path.join(data_inds_dir, 'random.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'prob_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'prob_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_k=Kcos.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_k=Kcosp.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'el2n_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'el2n_decr.pkl'),\n",
    "# ]\n",
    "\n",
    "# ## tulu mix v1.\n",
    "# dataset = 'tulu_v1_human_mix'; train_file = 'data/processed/tulu/tulu_v1_human_mix.jsonl'; abbr_train_file = 'tuluv1hm'\n",
    "# job_name = f'oi4_{dataset}'\n",
    "# save_steps = 50; save_total_limit = 200\n",
    "# subsample_mixture_list = [('',None)]\n",
    "# max_train_samples_list = [30000]; num_train_epochs_list = [3]\n",
    "# data_inds_dir = f'/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b/{dataset}/'\n",
    "# subsample_inds_file_list = [\n",
    "#     os.path.join(data_inds_dir, 'random.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'prob_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'prob_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'dppmap_k=Kcos.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'dppmap_k=Kcosp.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'dppmap_k=Kcos1np.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_decr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_incr.pkl'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# ## \n",
    "# dataset = 'flan2022_1m'; train_file = 'data/processed/flan2022/flan2022_1m_data.jsonl'; abbr_train_file = 'flan2022_1m'\n",
    "# job_name = f'oi4_{dataset}'\n",
    "# save_steps = 50; save_total_limit = 200\n",
    "# subsample_mixture_list = [('',None)]\n",
    "# data_inds_dir = f'/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b+lora:r=256:a=256/{dataset}/'\n",
    "# ## full data\n",
    "# # max_train_samples_list = [1000000]; num_train_epochs_list = [1]\n",
    "# # subsample_inds_file_list = ['']\n",
    "# # subset\n",
    "# max_train_samples_list = [200000]; num_train_epochs_list = [1]\n",
    "# subsample_inds_file_list = [\n",
    "# #     os.path.join(data_inds_dir, 'random.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'prob_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_nc=3000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeanscd_nc=3000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeanscd_nc=3000_decr.pkl'),\n",
    "#     # not that helpful\n",
    "# #     os.path.join(data_inds_dir, 'prob_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_decr.pkl'),\n",
    "#     ## gradnorm outputs\n",
    "# #     os.path.join(data_inds_dir, 'el2n_agg=mean_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_agg=l2n_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_agg=l2n_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'logit_margin_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'logit_margin_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'grad_loraB_l2n_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'grad_loraB_l2n_decr.pkl'),  \n",
    "#     ## random baselines.\n",
    "# #     os.path.join(data_inds_dir, 'random_s=0.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'random_s=1.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'random_s=2.pkl'),\n",
    "#     ## kmeans on grads\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=1000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=1000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=3000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=3000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=6000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=6000_incr.pkl'),\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# ## \n",
    "# dataset = 'tulu_v1_mix'; train_file = 'data/processed/tulu/tulu_v1_mix.jsonl'; abbr_train_file = 'tuluv1m'\n",
    "# # job_name = f'oi4_{dataset}_ep=3'\n",
    "# job_name = f'oi5_tulu_v1_mix:llama-7b' # re-run to see if transformers upgrade altered eval performance.\n",
    "# # save_steps = 50; save_total_limit = 200\n",
    "# subsample_mixture_list = [('',None)]\n",
    "# data_inds_dir = f'/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b+lora:r=256:a=256/{dataset}/'\n",
    "# max_train_samples_list = [50000]; num_train_epochs_list = [3]\n",
    "# subsample_inds_file_list = [\n",
    "#     # random baselines\n",
    "# #     os.path.join(data_inds_dir, 'random_s=0.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'random_s=1.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'random_s=2.pkl'),\n",
    "# #     # correlated statistics\n",
    "# #     os.path.join(data_inds_dir, 'log_prob_incr.pkl'),\n",
    "#     os.path.join(data_inds_dir, 'log_prob_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'logit_margin_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'logit_margin_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_agg=mean_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'el2n_agg=mean_decr.pkl'),\n",
    "# #     # grad norm\n",
    "# #     os.path.join(data_inds_dir, 'grad_loraB_l2n_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'grad_loraB_l2n_decr.pkl'),  \n",
    "# #     # kmeans\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=1000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=1000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=text+embedding_nc=1000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=text+embedding_nc=1000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=3000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=grad+rp+loraB_nc=3000_decr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=text+embedding_nc=3000_incr.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'kmeansl2_emb=text+embedding_nc=3000_decr.pkl'),\n",
    "# # #     # kcos only 50k data\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_emb=grad+rp+loraB_k=Kcos.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_emb=text+embedding_k=Kcos.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_emb=grad+rp+loraB_k=Kcos1np.pkl'),\n",
    "# #     os.path.join(data_inds_dir, 'dppmap_emb=text+embedding_k=Kcos1np.pkl'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# oi5: try curriculum learning / pruning\n",
    "\n",
    "scoring_fn_and_pacing_fn = []\n",
    "\n",
    "# ###### 150k(ep=3) baselines on various baselines\n",
    "# model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# M = 150_000; dataset = 'tulu_v1_mix'; train_file = 'data/processed/tulu/tulu_v1_mix.jsonl'; abbr_train_file = 'tuluv1m'\n",
    "# # M = 150_000; dataset = 'wizardlm'; train_file = 'data/processed/wizardlm/wizardlm_data.jsonl'; abbr_train_file = 'wizardlm'\n",
    "# # M = 150_000; dataset = 'sharegpt'; train_file = 'data/processed/sharegpt/sharegpt_data.jsonl'; abbr_train_file = 'sharegpt'\n",
    "# # M = 150_000; dataset = 'ultrachat200k'; train_file = 'data/processed/ultrachat/ultrachat200k_train_data.jsonl'; abbr_train_file = 'ultrachat200k'\n",
    "\n",
    "# # scoring_fn_list = ['log_prob_neg']\n",
    "# # pacing_fn_list = [\n",
    "# # #     f'prune_size={M}_ep=3',\n",
    "# #     f'singlestep_size={M}_startingfrac=0.05',\n",
    "# # #     f'singlestep_size={M}_startingfrac=0.1',\n",
    "# # #     f'singlestep_size={M}_startingfrac=0.2',\n",
    "# #     f'fep_size={M}_nsteps=5_startingfrac=0.05_inc=1.5',\n",
    "# # ]\n",
    "# # scoring_fn_and_pacing_fn += list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "# ######\n",
    "\n",
    "\n",
    "##### \n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# M = 150_000; dataset = 'tulu_v1_mix'; train_file = 'data/processed/tulu/tulu_v1_mix.jsonl'; abbr_train_file = 'tuluv1m'; pacing_fn_list = [f'prune_size={M}_ep=3']\n",
    "# M = 100_000; dataset = 'wizardlm'; train_file = 'data/processed/wizardlm/wizardlm_data.jsonl'; abbr_train_file = 'wizardlm'; pacing_fn_list = [f'prune_size={M}_ep=2'] # 6hr gpu ok.\n",
    "# M = 200_000; dataset = 'wizardlm'; train_file = 'data/processed/wizardlm/wizardlm_data.jsonl'; abbr_train_file = 'wizardlm'; pacing_fn_list = [f'prune_size={M}_ep=2']\n",
    "M = 50_000; dataset = 'wizardlm'; train_file = 'data/processed/wizardlm/wizardlm_data.jsonl'; abbr_train_file = 'wizardlm'; pacing_fn_list = [f'prune_size={M}_ep=5'] # 6hr gpu ok.\n",
    "\n",
    "scoring_fn_list = []\n",
    "scoring_fn_list += ['log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n'] # 'numtoks_input_neg'\n",
    "scoring_fn_list += ['semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=200',\n",
    "#                     'semdedup_cl=kmeansfaisscd_md=bge_dist=cd_emb=text+embedding_nc=200'\n",
    "                   ]\n",
    "# scoring_fn_list = ['semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=200',\n",
    "#                    'semdedup_cl=kmeansfaisscd_md=bge_dist=cd_emb=text+embedding_nc=200',\n",
    "#                    'semdedup_cl=kmeansfaisscd_md=llama7b_dist=cd_emb=text+embedding_nc=200',\n",
    "#                    'semdedup_cl=kmeansfaisscd_md=llama7b_dist=cd_emb=grad+rp+loraB_nc=200',]\n",
    "scoring_fn_list += [\n",
    "    'random_s=0',\n",
    "    'random_s=1',\n",
    "]\n",
    "scoring_fn_list += [\n",
    "    #     wizardlm\n",
    "    'dppmapbd_nc=200_k=vmf_gamma=0.0000015_kmd=mpnet', # for ->10k\n",
    "#     'dppmapbd_nc=200_k=vmf_gamma=0.00005_kmd=mpnet', # for ->50k\n",
    "    'dppmapbd_nc=200_k=lin_kmd=mpnet',\n",
    "#     'dppmapbd_nc=200_k=vmf_gamma=0.3_kmd=mpnet',\n",
    "#     'dppmapbd_nc=200_k=vmf_gamma=1.0_kmd=mpnet',\n",
    "#     'dppmapbd_nc=200_k=vmf_gamma=3.0_kmd=mpnet',\n",
    "#     'dppmapbd_nc=200_k=vmf_gamma=0.00006_kmd=mpnet',\n",
    "]\n",
    "# ifd & quality kernel as ifd\n",
    "# scoring_fn_list = [\n",
    "#     'ifd',\n",
    "#     'ifd_neg',\n",
    "#     'dppmapbd_nc=200_theta=0.3_k=lin_kmd=mpnet_q=ifd_qmd=llama7b+lima',\n",
    "#     'dppmapbd_nc=200_theta=0.6_k=lin_kmd=mpnet_q=ifd_qmd=llama7b+lima',\n",
    "#     'dppmapbd_nc=200_theta=0.3_k=lin_kmd=mpnet_q=prob_qmd=llama7b+lima',\n",
    "#     'dppmapbd_nc=200_theta=0.6_k=lin_kmd=mpnet_q=prob_qmd=llama7b+lima',\n",
    "# ]\n",
    "\n",
    "\n",
    "scoring_fn_and_pacing_fn += list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "####\n",
    "\n",
    "# ### mistral-7b on ultrachat15/200k\n",
    "# model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048\n",
    "# # M =  50_000; dataset = 'ultrachat200k'; train_file = 'data/processed/ultrachat/ultrachat200k_train_data.jsonl'; abbr_train_file = 'ultrachat200k'\n",
    "# M = 100_000; dataset = 'ultrachat15';   train_file = 'data/processed/ultrachat/ultrachat15_data.jsonl'; abbr_train_file = 'ultrachat15'; preprocessing_num_workers = 64\n",
    "# # M = 400_000; dataset = 'ultrachat15';   train_file = 'data/processed/ultrachat/ultrachat15_data.jsonl'; abbr_train_file = 'ultrachat15'; preprocessing_num_workers = 64\n",
    "\n",
    "# # scoring_fn_list = ['log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n', 'el2n_agg=mean']\n",
    "# # scoring_fn_list = ['numtoks_input_neg']\n",
    "# # scoring_fn_list = ['log_prob_neg', 'el2n_agg=mean', 'logit_margin_neg', 'grad_loraB_l2n',] #  'kmeansl2_emb=text+embedding_nc=3000_incr'\n",
    "# # scoring_fn_list = ['rhov1_log_prob', 'rhov1_log_prob_neg']\n",
    "# # scoring_fn_list = ['numtoks_input_neg', 'numtoks_output_neg', 'numtoks_total_neg']\n",
    "# # scoring_fn_list = [\n",
    "# #     'semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=200',\n",
    "# #                    'semdedup_cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=text+embedding_nc=200',\n",
    "# #                    'semdedup_cl=kmeansfaisscd_md=mistral7b_dist=cd_emb=grad+rp+loraB_nc=200',\n",
    "# #                   ]\n",
    "# # scoring_fn_list = ['dppmapbd_nc=200_k=lin_kmd=mpnet']\n",
    "# # scoring_fn_list =[f'dppmapbd_nc=200_k=vmf_gamma={gamma}_kmd=mpnet' for gamma in [.3, 3.]]\n",
    "# # scoring_fn_list = ['dppmapbd_nc=200_k=vmf_gamma=0.000035_kmd=mpnet']\n",
    "# scoring_fn_list = ['dppmapbd_nc=200_k=vmf_gamma=1.0_kmd=mpnet'] \n",
    "# pacing_fn_list = [f'prune_size={M}_ep=2']\n",
    "# scoring_fn_and_pacing_fn += list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "# ##### \n",
    "\n",
    "evaluation_strategy = 'steps' if 'ultrachat' in dataset else 'no'\n",
    "job_name = f'oi5_{dataset}:{abbr_model_name}'\n",
    "num_train_epochs_list = [1] # offload handling of epochs to `generate_curriculum`\n",
    "dataloader_sampler = 'SequentialSampler'\n",
    "\n",
    "## random baselines # 'random_s=0', 'random_s=1'\n",
    "# scoring_fn_list = ['random_s=0']; pacing_fn_list = [f'prune_size={M}_ep=2']\n",
    "# scoring_fn_and_pacing_fn += list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "subsample_inds_file_list = []\n",
    "for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "    if 'semdedup' in scoring_fn or 'dppmap' in scoring_fn:\n",
    "        if 'md=mpnet' in scoring_fn: md = 'all-mpnet-base-v2'\n",
    "        elif 'md=bge' in scoring_fn: md = 'bge-large-en-v1.5'\n",
    "        elif 'md=llama7b' in scoring_fn: md = 'llama-7b+lora:r=256:a=256'\n",
    "        elif 'md=mistral7b' in scoring_fn: md = 'mistral-7b+lora:r=256:a=256'\n",
    "        else: raise ValueError(f'md not found in {scoring_fn}')\n",
    "        data_inds_dir = (f'/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/curriculum/{md}/{dataset}/')\n",
    "    else:\n",
    "        data_inds_dir = (f'/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/curriculum/'\n",
    "                         f'{abbr_model_name}+lora:r=256:a=256/{dataset}/')\n",
    "    p = os.path.join(data_inds_dir, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "    if not os.path.isfile(p):\n",
    "        raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "    subsample_inds_file_list.append(p)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##### code instruction tuning\n",
    "# job_name = 'oi6_starcoder_ep=3'; num_train_epochs_list = [3]\n",
    "# model_name_or_path = hf_models_dir+'codellama/CodeLlama-7b-hf'; abbr_model_name = 'codellama-7b'; max_seq_length = 2048\n",
    "\n",
    "# train_file = 'data/processed/starcoder/starcoder_random_simple.jsonl'; abbr_train_file = 'rsimplev1'\n",
    "# # train_file = 'data/processed/starcoder/starcoder_random_role.jsonl'; abbr_train_file = 'rrolev1'\n",
    "# # train_file = 'data/processed/starcoder/starcoder_simple.jsonl'; abbr_train_file = 'simplev1'\n",
    "# # train_file = 'data/processed/starcoder/starcoder_role.jsonl'; abbr_train_file = 'rolev1'\n",
    "# ##### \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "debug_mode = test_run\n",
    "\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12 # llama-7b on 100k. data\n",
    "nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6 # llama-7b on 100k. data\n",
    "# nodes = 10; num_gpus = 6; gpu_type = 'v100'; job_duration = 36 # llama-7b on 100k. data\n",
    "\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 18 # llama-7b on 400k data\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 30 # llama-7b on 600k data\n",
    "\n",
    "# nodes = 1; num_gpus = 1; gpu_type = 'v100'; job_duration = 6  # gpt2\n",
    "# nodes = 2; num_gpus = 6; gpu_type = 'v100'; job_duration = 6  # pythia-1.4b\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6  # pythia-2.8b|6.9b\n",
    "\n",
    "\n",
    "overwrite_output_dir = True if test_run else False # always continue from ckpt if run from cluster.\n",
    "\n",
    "\n",
    "per_device_train_batch_size = 2; total_batch_size = 128 # 128\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "\n",
    "optimizer = 'adamw_hf' # 'adafactor'\n",
    "\n",
    "deepspeed = ''; fsdp = False if num_gpus == 1 else \"full_shard auto_wrap\"  # full_shard, shard_grad_op\n",
    "if 'gpt2' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPT2Block'\n",
    "elif 'llama' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'LlamaDecoderLayer'\n",
    "elif 'mpt' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MPTBlock'\n",
    "elif 'pythia' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPTNeoXLayer'        \n",
    "elif 'mistral' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MistralDecoderLayer'\n",
    "else: raise ValueError('Not sure how to set `fsdp_transformer_layer_cls_to_wrap`')\n",
    "    \n",
    "# deepspeed = './ds_configs/ds_zero3_cpu_offload.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/ds_zero3.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/stage3_no_offloading.conf'; fsdp = False # error with loading... something wrong with the config.\n",
    "\n",
    "# fsdp = False; deepspeed = False\n",
    "\n",
    "if fsdp and deepspeed:\n",
    "    raise ValueError('either fsdp or deepspeed, not both')\n",
    "\n",
    "use_lora = False\n",
    "lora_rank = 256 # test {8, 16, 32, 128} # just [128, 8] for now.\n",
    "lora_alpha = lora_rank \n",
    "lora_dropout = 0.05\n",
    "if use_lora:\n",
    "    abbr_model_name += f'+lora(r={lora_rank},a={lora_alpha})'\n",
    "\n",
    "mixed_precision = 'bf16' if arch == 'x86_64' else 'fp16' # mixed_precision = ''\n",
    "torch_dtype = 'bfloat16' if arch=='x86_64' else 'float16'; torch_dtype = 'float32'\n",
    "\n",
    "gradient_checkpointing = True\n",
    "load_in_8bit = False\n",
    "\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"Effective batch size {effective_batch_size}\")\n",
    "\n",
    "\n",
    "if nodes == 1:\n",
    "    exe = 'python' if num_gpus==1 else \\\n",
    "        f\"torchrun --nproc_per_node={num_gpus} --master_port=10002\"\n",
    "else:\n",
    "    exe = f\"torchrun --nnodes={nodes} --nproc_per_node={num_gpus} --rdzv-id=$SLURM_JOB_ID --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT\"\n",
    "\n",
    "if test_run:\n",
    "    exe = f\"CUDA_VISIBLE_DEVICES={','.join(map(str, range(num_gpus)))} {exe}\"\n",
    "if test_run and debug_mode:\n",
    "    exe = 'TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO ' + exe\n",
    "    error_file='/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/error_file'\n",
    "    exe = f'TORCHELASTIC_ERROR_FILE={error_file} {exe}'\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    num_train_epochs_list,\n",
    "    subsample_mixture_list,\n",
    "    subsample_inds_file_list,\n",
    "    max_train_samples_list,\n",
    ")\n",
    "\n",
    "output_dirname_list = []\n",
    "for (num_train_epochs,\n",
    "     mix_name_and_subsample_mixture,\n",
    "     subsample_inds_file,\n",
    "     max_train_samples,) in options_list:\n",
    "    mix_name, subsample_mixture = mix_name_and_subsample_mixture\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{abbr_train_file}\"\n",
    "    if max_train_samples:\n",
    "        output_dirname += f\":{int(max_train_samples/1000)}k\"\n",
    "        \n",
    "    if job_name == 'ft2':\n",
    "        if subsample_mixture is not None:\n",
    "            assert(abbr_train_file=='all')\n",
    "            output_dirname += \\\n",
    "                '_mix='+','.join(f'{k}:{v}' for k,v in subsample_mixture.items())\n",
    "            \n",
    "    if job_name == 'oi2':\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "            \n",
    "    if job_name == 'oi3':\n",
    "        output_dirname += '_'+mix_name\n",
    "        \n",
    "#     if job_name.startswith('oi4'):\n",
    "    if subsample_inds_file:\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "\n",
    "            \n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "            \n",
    "    # if not test_run:\n",
    "    #     output_dirname += \\\n",
    "    #         '_ep='+str(num_train_epochs)\n",
    "    if add_hardwarespec_to_dirname:\n",
    "        output_dirname += \\\n",
    "            ('_fsdp='+fsdp.split(' ')[0] if fsdp else '')+\\\n",
    "            ('_deepspeed='+os.path.basename(deepspeed).split('.')[0] if deepspeed else '')+\\\n",
    "            ('_gradckpt='+str(gradient_checkpointing) if gradient_checkpointing else '')+\\\n",
    "            '_mbsz='+str(per_device_train_batch_size)+\\\n",
    "            '_dtype='+torch_dtype+\\\n",
    "            ('_mp='+str(mixed_precision) if mixed_precision else '_mp=none')+\\\n",
    "            '_seqlen='+str(max_seq_length)+\\\n",
    "            '_nodes='+str(nodes)\n",
    "    output_dir = os.path.join('results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join('results', job_name), exist_ok=True)\n",
    "    wandb_run_name = output_dir.replace('results/', '')\n",
    "    \n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {'!cd .. && ' if test_run else ''}{exe}\n",
    "        open_instruct/finetune_trainer.py \\\n",
    "        --model_name_or_path={model_name_or_path} \\\n",
    "        --tokenizer_name={model_name_or_path} \\\n",
    "        {'--load_in_8bit' if load_in_8bit else ''} \\\n",
    "        --use_fast_tokenizer=True \\\n",
    "        --train_file={train_file} \\\n",
    "        --max_seq_length={max_seq_length} \\\n",
    "        {'--max_train_samples='+str(max_train_samples) if max_train_samples else ''} \\\n",
    "        {'--use_lora' if use_lora else ''}\n",
    "        {'--lora_rank='+str(lora_rank) if use_lora else ''}\n",
    "        {'--lora_alpha='+str(lora_alpha) if use_lora else ''}\n",
    "        {'--lora_dropout='+str(lora_dropout) if use_lora else ''}\n",
    "        --do_train \\\n",
    "        --preprocessing_num_workers={preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size={per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
    "        --learning_rate=2e-5 \\\n",
    "        --lr_scheduler_type=linear \\\n",
    "        --warmup_ratio=0.03 \\\n",
    "        --weight_decay=0. \\\n",
    "        --optim={optimizer} \\\n",
    "        --evaluation_strategy={evaluation_strategy} \\\n",
    "        {'--eval_steps='+str(eval_steps) if eval_steps else ''} \\\n",
    "        --report_to tensorboard wandb \\\n",
    "        --run_name {wandb_run_name} \\\n",
    "        --logging_strategy=steps \\\n",
    "        --logging_first_step \\\n",
    "        --logging_steps=1 \\\n",
    "        --save_strategy={save_strategy} \\\n",
    "        --save_steps={save_steps} \\\n",
    "        --save_total_limit={save_total_limit} \\\n",
    "        --num_train_epochs={num_train_epochs} \\\n",
    "        --ddp_timeout=7200 \\\n",
    "        {'--fsdp=\"'+fsdp+'\"' if fsdp else ''}\n",
    "        {'--fsdp_transformer_layer_cls_to_wrap=\"'+fsdp_transformer_layer_cls_to_wrap+'\"' \n",
    "            if fsdp else ''}\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''}\n",
    "        --torch_dtype={torch_dtype} \\\n",
    "        --dataloader_num_workers=8 \\\n",
    "        {f'--{mixed_precision}=True' if mixed_precision else ''} \\\n",
    "        {'--overwrite_output_dir' if overwrite_output_dir else ''} \\\n",
    "        {'--deepspeed='+deepspeed if deepspeed else ''} \\\n",
    "        {'--subsample_mixture=\"'+str(subsample_mixture).replace(': ', ':').replace(', ', ',')+'\"'\n",
    "            if subsample_mixture else ''} \\\n",
    "        {'--subsample_inds_file='+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        {'--dataloader_sampler '+str(dataloader_sampler) if dataloader_sampler else ''} \\\n",
    "        --output_dir=\"{output_dir}\" \\\n",
    "    \"\"\" \n",
    "    #    --overwrite_cache\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    if test_run:\n",
    "        print()\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e2b372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchrun --nnodes=5 --nproc_per_node=6 --rdzv-id=$SLURM_JOB_ID --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/wizardlm/wizardlm_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=32 --per_device_train_batch_size=2 --gradient_accumulation_steps=2 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=100 --report_to tensorboard wandb --run_name oi5_wizardlm:llama-7b/llama-7b_wizardlm_score=dppmapbd:nc=200:k=lin:kmd=mpnet_pace=prune:size=50000:ep=5 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=100 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --gradient_checkpointing --torch_dtype=float32 --dataloader_num_workers=8 --fp16=True --subsample_inds_file=/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/curriculum/all-mpnet-base-v2/wizardlm/dppmapbd_nc=200_k=lin_kmd=mpnet/inds_prune_size=50000_ep=5.pkl --dataloader_sampler SequentialSampler --output_dir=\"results/oi5_wizardlm:llama-7b/llama-7b_wizardlm_score=dppmapbd:nc=200:k=lin:kmd=mpnet_pace=prune:size=50000:ep=5\"\n"
     ]
    }
   ],
   "source": [
    "print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831fe55",
   "metadata": {},
   "source": [
    "# eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41e3fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_all_symlinks(directory, verbose=False):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files + dirs:\n",
    "            path = os.path.join(root, name)\n",
    "            if os.path.islink(path):\n",
    "                os.unlink(path)\n",
    "                if verbose:\n",
    "                    print(f\"Removed symlink: {path}\")\n",
    "                \n",
    "import uuid\n",
    "\n",
    "def create_unique_symlinks(file_paths, verbose=False):\n",
    "    \"\"\"Create symlinks for each `file` in `files` in the same directory, with a unique name. \"\"\"\n",
    "    dirs = [os.path.dirname(x) for x in file_paths]\n",
    "\n",
    "    symlink_path_dict = {}\n",
    "    for directory, path in zip(dirs, file_paths):\n",
    "        if os.path.isdir(path):\n",
    "            symlink_name = f\"symlink_{str(uuid.uuid4())[:8]}\"  # Generate a unique symlink name\n",
    "            symlink_path = os.path.join(directory, symlink_name)\n",
    "            try:\n",
    "                os.symlink(os.path.abspath(path), symlink_path)\n",
    "                if verbose:\n",
    "                    print(f\"Created symlink: {symlink_path} -> {path}\")\n",
    "            except OSError as e:\n",
    "                print(f\"Failed to create symlink: {path}. Error: {e}\")\n",
    "            symlink_path_dict.update({path: symlink_path})\n",
    "    return symlink_path_dict\n",
    "\n",
    "\n",
    "def get_resource_for_task(task_name, model_name_or_path):\n",
    "    model_name_or_path = model_name_or_path.lower()\n",
    "    if any(x in model_name_or_path for x in ['gpt2-medium', 'pythia-160m']):\n",
    "        return 50, 1\n",
    "    if any(x in model_name_or_path for x in ['gpt-xl']):\n",
    "        if any(x in task_name for x in ['bbh_s=3', 'mmlu_s=5', 'tydiqa_s=1_gp']):\n",
    "            return 16, 1\n",
    "        else:\n",
    "            return 32, 1\n",
    "    if any(x in model_name_or_path for x in ['llama', 'mistral', 'zephyr', 'pythia-1.4b', 'pythia-2.8b']):\n",
    "        if any(x in task_name for x in ['bbh_s=3', 'mmlu_s=5', 'tydiqa_s=1_gp', 'alpacafarm']):\n",
    "            return 5, 1\n",
    "        else:\n",
    "            return 10, 1\n",
    "    if any(x in model_name_or_path for x in ['pythia-6.9b', 'dolly-v2-7b']):\n",
    "        if any(x in task_name for x in ['bbh_s=3', 'mmlu_s=5', 'mmlu_s=0', 'tydiqa_s=1_gp', 'alpacafarm']):\n",
    "            return 4, 1\n",
    "        else:\n",
    "            return 10, 1\n",
    "    return 10, 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9b68375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('alpacafarm_ann=chatgpt_chatfmt', 'results/ft1_ep=2/llama-7b_lima')\n",
      "#cmds:  1 \n",
      "\n",
      "python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path \"results/ft1_ep=2/llama-7b_lima\" --save_dir \"results/ft1_ep=2/llama-7b_lima/eval/alpacafarm_ann=chatgpt_chatfmt\" --eval_batch_size 5 --annotators_config chatgpt --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=chatgpt_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "exp_dir = ''\n",
    "create_symlinks = False\n",
    "include_checkpoints = False\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "\n",
    "\n",
    "num_cpus = 10; cpu_mem = 32 # mem usage quite small for llama7b+lora on bbh\n",
    "num_cpus = 24; cpu_mem = 64\n",
    "\n",
    "use_slow_tokenizer = False\n",
    "\n",
    "task_names = [\n",
    "    'mmlu_s=0', # \n",
    "    'mmlu_s=5', # ~1hr\n",
    "    'gsm_s=8',\n",
    "    'gsm_s=8_cot',\n",
    "    'bbh_s=3',\n",
    "    'bbh_s=3_cot', # max_datapoints_per_task=40 -> 40min.\n",
    "    'humaneval',\n",
    "    'tydiqa_s=1_cb', # 3min\n",
    "    'tydiqa_s=1_gp',\n",
    "    # 'toxigen', # ~1.5hr\n",
    "    # 'alpacafarm_ann=chatgpt', # ~$1 per eval.\n",
    "]\n",
    "# task_names = ['alpacafarm_ann=chatgpt']\n",
    "task_names_chatfmt = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # ## baselines eval \n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "# #     'gpt2',\n",
    "# #     'gpt2-medium',\n",
    "# #     'huggyllama/llama-7b', \n",
    "# #     'mistralai/Mistral-7B-v0.1',\n",
    "# #     'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "# #     'NousResearch/Llama-2-7b-hf',\n",
    "#     'HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-beta',\n",
    "#     'HuggingFaceH4/zephyr-7b-alpha',\n",
    "# #     'HuggingFaceH4/zephyr-7b-beta',\n",
    "# #     'EleutherAI/pythia-1.4b',\n",
    "# #     'EleutherAI/pythia-2.8b',\n",
    "# #     'EleutherAI/pythia-6.9b',\n",
    "# #     'databricks/dolly-v2-7b',\n",
    "# ]]\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# # ## baseline re-eval after merge upstream/main\n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "#     'huggyllama/llama-7b',\n",
    "# ]]\n",
    "# subdir_path_list += ['results/ft1/llama-7b_humanmix']\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# ## ft1\n",
    "# exp_dir = 'results/ft1'\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "## ft1_ep=1\n",
    "# exp_dir = 'results/ft1_ep=1'\n",
    "exp_dir = 'results/ft1_ep=2'\n",
    "subdir_filter_fn = lambda x: 'lima' in x\n",
    "# task_names = task_names_chatfmt\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "task_names = ['alpacafarm_ann=chatgpt']; task_names = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "\n",
    "# ## ft2\n",
    "# exp_dir = 'results/ft2/'\n",
    "# create_symlinks = True\n",
    "# subdir_filter_fn = lambda x: any(y in x for y in ['llama-7b'])\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# ## llama-7b time-series 400k, 600k\n",
    "# exp_dir = 'results/oi3/'\n",
    "# include_checkpoints = True\n",
    "# subdir_filter_fn = lambda x: any(y in x for y in ['400k', '600k']) # , '600k'\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# # oi4 include checkpoints!\n",
    "# # exp_dir = 'results/oi4_perf_cross_time/'\n",
    "# # exp_dir = 'results/oi4_tulu_v1_human_mix/'\n",
    "# # exp_dir = 'results/oi4_flanv2_prune_with_hmv1_model/'\n",
    "# # exp_dir = 'results/oi4_flan2022_1m/'\n",
    "# # exp_dir = 'results/oi4_tulu_v1_mix/'\n",
    "# exp_dir = 'results/oi4_tulu_v1_mix_ep=3/'\n",
    "# # include_checkpoints = True\n",
    "# include_checkpoints = False\n",
    "# subdir_filter_fn = lambda x: any(y in x for y in ['random']) #$ ['log_prob_decr', 'el2n_agg=mean_incr', 'logit_margin_decr', 'grad_loraB']\n",
    "# # task_names = task_names+task_names_chatfmt\n",
    "# task_names = ['alpacafarm_ann=chatgpt']; task_names = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "# # oi4 without checkpoint \n",
    "# # exp_dir = 'results/oi4/'\n",
    "# exp_dir = 'results/oi4_flan_v2_vary_subsetsize/'\n",
    "# task_names = task_names_chatfmt\n",
    "\n",
    "# # oi5\n",
    "# # exp_dir = 'results/oi5_tulu_v1_mix:llama-7b/'\n",
    "# # exp_dir = 'results/oi5_ultrachat:mistral-7b'\n",
    "# # exp_dir = 'results/oi5_ultrachat200k:mistral-7b'\n",
    "# # exp_dir = 'results/oi5_ultrachat15:mistral-7b'\n",
    "# exp_dir = 'results/oi5_wizardlm:llama-7b'\n",
    "# # subdir_filter_fn = lambda x: any(y in x for y in ['semdedup', 'dppmap']) and 'mpnet' in x\n",
    "# # subdir_filter_fn = lambda x : 'log:prob:neg' in x\n",
    "# # task_names = ['alpacafarm_ann=chatgpt']; task_names = [x+'_chatfmt' for x in task_names]\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "# # \n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "\n",
    "if len(subdir_path_list)==0:\n",
    "    if create_symlinks:\n",
    "        remove_all_symlinks(exp_dir)\n",
    "    subdir_path_list = []\n",
    "    subdirs = list(os.listdir(exp_dir))\n",
    "    subdirs = filter(subdir_filter_fn, subdirs)\n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(exp_dir, subdir)\n",
    "        if include_checkpoints:\n",
    "            subdir_path_list += glob.glob(os.path.join(subdir_path, 'checkpoint-*'))\n",
    "        if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "            continue\n",
    "        subdir_path_list.append(subdir_path)\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not os.path.islink(subdir_path) and \\\n",
    "                not os.path.isfile(os.path.join(subdir_path, 'eval', task_name, 'metrics.json')):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "                print((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "\n",
    "print('#cmds: ', len(list(task_name_and_model)), '\\n')\n",
    "\n",
    "if create_symlinks:\n",
    "    # create symlink for each directory.\n",
    "    symlink_path_dict = create_unique_symlinks(\n",
    "        list([x[1] for x in task_name_and_model]))\n",
    "    options_list = list(map(lambda x: (x[0], symlink_path_dict[x[1]]), task_name_and_model))\n",
    "else:\n",
    "    options_list = task_name_and_model\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "info = {}  \n",
    "cmds = []\n",
    "for task_name, model_name_or_path in options_list:\n",
    "    \n",
    "    use_chat_format = 'chatfmt' in task_name\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(model_name_or_path, 'ft_args.json'), 'r') as f:\n",
    "            ft_args = json.load(f)\n",
    "        # note `model_name_or_path` could be anything, e.g., soft links with arbitrary names.\n",
    "        # but `ft_args_model_name_or_path` indicates the finetuned model name.\n",
    "        ft_args_model_name_or_path = ft_args['model_args']['model_name_or_path']\n",
    "    except:\n",
    "        ft_args_model_name_or_path = model_name_or_path\n",
    "\n",
    "    if 'gpt2' in ft_args_model_name_or_path:\n",
    "        tydiqa_max_context_length = 400 # max ctx len without exceeding max_seq_len\n",
    "    else:\n",
    "        tydiqa_max_context_length = 512\n",
    "    batch_size, job_duration = get_resource_for_task(\n",
    "        task_name, ft_args_model_name_or_path)\n",
    "    \n",
    "    job_name = f'eval.{task_name}'\n",
    "    run_id = model_name_or_path\n",
    "    save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "    \n",
    "    if task_name.startswith('mmlu'):\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 5)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.mmlu.run_eval \\\n",
    "            --data_dir data/eval/mmlu \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --ntrain {n_shot} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('gsm'):\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 8)\n",
    "        # open-instruct used 200 examples. use higher amount to get a more accurate number\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.gsm.run_eval \\\n",
    "            --data_dir data/eval/gsm/ \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_num_examples 500 \\\n",
    "            --n_shot {n_shot} \\\n",
    "            --max_new_tokens 256 \\\n",
    "            {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('bbh'):\n",
    "        max_num_examples_per_task = 40\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 3)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.bbh.run_eval \\\n",
    "            --data_dir data/eval/bbh/ \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_new_tokens 256 \\\n",
    "            --n_shot {n_shot} \\\n",
    "            {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--max_num_examples_per_task '+str(max_num_examples_per_task) if max_num_examples_per_task else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('humaneval'):\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.codex_humaneval.run_eval \\\n",
    "            --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --eval_pass_at_ks 1 \\\n",
    "            --unbiased_sampling_size_n 1 \\\n",
    "            --temperature 0.1 \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('tydiqa'):\n",
    "        no_context = 'cb' in task_name\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot in [0,1])\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.tydiqa.run_eval \\\n",
    "            --data_dir data/eval/tydiqa \\\n",
    "            --n_shot {n_shot} \\\n",
    "            --max_num_examples_per_lang 100 \\\n",
    "            --max_context_length {tydiqa_max_context_length} \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            {'--no_context' if no_context else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('toxigen'):\n",
    "        # max_prompts_per_group=500 (out of 1000) is open-instruct default.\n",
    "        # eval batch size=1 much faster (llama-7b) not sure why.\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.toxigen.run_eval \\\n",
    "            --data_dir data/eval/toxigen \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size 1 \\\n",
    "            --max_prompts_per_group 200 \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('alpacafarm'):\n",
    "        match = re.search(r'ann=([^_]+)', task_name)\n",
    "        annotators_config = match.group(1)\n",
    "        annotators_config = annotators_config.replace(':', '_')\n",
    "        if not annotators_config in ['chatgpt', 'alpaca_eval_gpt4_0314']:\n",
    "            raise ValueError('Just support 2 annotators_config.')\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.alpaca_farm.run_eval \\\n",
    "            --reference_path alpaca_eval_data \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --annotators_config {annotators_config} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "        \"\"\"\n",
    "    else:\n",
    "        raise ValueError(f'{task_name} not supported.')\n",
    "        \n",
    "        \n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "    print(cmd)\n",
    "    \n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=save_dir,\n",
    "    )\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=1,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "358cd711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "\n",
    "with open('gen_cmds_run_cmds.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'][0]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4392e9ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_fmt=True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ddb5a_row0_col0, #T_ddb5a_row0_col1, #T_ddb5a_row1_col0, #T_ddb5a_row1_col1, #T_ddb5a_row2_col0, #T_ddb5a_row2_col1, #T_ddb5a_row3_col0, #T_ddb5a_row3_col1, #T_ddb5a_row4_col0, #T_ddb5a_row4_col1, #T_ddb5a_row5_col0, #T_ddb5a_row5_col1, #T_ddb5a_row6_col0, #T_ddb5a_row6_col1, #T_ddb5a_row7_col0, #T_ddb5a_row7_col1, #T_ddb5a_row8_col0, #T_ddb5a_row8_col1, #T_ddb5a_row9_col0, #T_ddb5a_row9_col1, #T_ddb5a_row10_col0, #T_ddb5a_row10_col1, #T_ddb5a_row11_col0, #T_ddb5a_row11_col1, #T_ddb5a_row12_col0, #T_ddb5a_row12_col1, #T_ddb5a_row13_col0, #T_ddb5a_row13_col1, #T_ddb5a_row14_col0, #T_ddb5a_row14_col1, #T_ddb5a_row15_col0, #T_ddb5a_row15_col1, #T_ddb5a_row16_col0, #T_ddb5a_row16_col1, #T_ddb5a_row17_col0, #T_ddb5a_row17_col1, #T_ddb5a_row18_col0, #T_ddb5a_row18_col1, #T_ddb5a_row19_col0, #T_ddb5a_row19_col1, #T_ddb5a_row20_col0, #T_ddb5a_row20_col1, #T_ddb5a_row21_col0, #T_ddb5a_row21_col1, #T_ddb5a_row22_col0, #T_ddb5a_row22_col1, #T_ddb5a_row23_col0, #T_ddb5a_row23_col1, #T_ddb5a_row24_col0, #T_ddb5a_row24_col1, #T_ddb5a_row25_col0, #T_ddb5a_row25_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ddb5a_row0_col2, #T_ddb5a_row6_col4, #T_ddb5a_row12_col4, #T_ddb5a_row15_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row0_col3, #T_ddb5a_row13_col6, #T_ddb5a_row16_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row0_col4, #T_ddb5a_row8_col4, #T_ddb5a_row18_col7, #T_ddb5a_row21_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row0_col5, #T_ddb5a_row13_col10, #T_ddb5a_row14_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row0_col6, #T_ddb5a_row8_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row0_col7, #T_ddb5a_row0_col10, #T_ddb5a_row1_col10, #T_ddb5a_row2_col5, #T_ddb5a_row2_col6, #T_ddb5a_row2_col8, #T_ddb5a_row2_col10, #T_ddb5a_row3_col11, #T_ddb5a_row4_col3, #T_ddb5a_row6_col9, #T_ddb5a_row7_col2, #T_ddb5a_row22_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row0_col9, #T_ddb5a_row5_col6, #T_ddb5a_row10_col6, #T_ddb5a_row13_col3, #T_ddb5a_row15_col3, #T_ddb5a_row19_col7, #T_ddb5a_row24_col6, #T_ddb5a_row25_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c83836;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row1_col3, #T_ddb5a_row19_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dc5d4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row1_col4, #T_ddb5a_row2_col4, #T_ddb5a_row12_col5, #T_ddb5a_row19_col4, #T_ddb5a_row22_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row1_col5, #T_ddb5a_row3_col4, #T_ddb5a_row5_col4, #T_ddb5a_row18_col3, #T_ddb5a_row24_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row1_col7, #T_ddb5a_row7_col4, #T_ddb5a_row9_col7, #T_ddb5a_row12_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row1_col8, #T_ddb5a_row20_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row1_col9, #T_ddb5a_row7_col9, #T_ddb5a_row9_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row1_col11, #T_ddb5a_row10_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row2_col3, #T_ddb5a_row11_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row2_col7, #T_ddb5a_row4_col4, #T_ddb5a_row11_col4, #T_ddb5a_row14_col4, #T_ddb5a_row15_col4, #T_ddb5a_row23_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row2_col9, #T_ddb5a_row7_col10, #T_ddb5a_row13_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row3_col2, #T_ddb5a_row11_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row3_col3, #T_ddb5a_row8_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row3_col5, #T_ddb5a_row14_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row3_col6, #T_ddb5a_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row3_col7, #T_ddb5a_row5_col7, #T_ddb5a_row22_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row3_col8, #T_ddb5a_row11_col3, #T_ddb5a_row18_col8, #T_ddb5a_row21_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row4_col7, #T_ddb5a_row10_col7, #T_ddb5a_row25_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row4_col8, #T_ddb5a_row10_col8, #T_ddb5a_row23_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row4_col9, #T_ddb5a_row18_col10, #T_ddb5a_row19_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row5_col2, #T_ddb5a_row22_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row5_col5, #T_ddb5a_row15_col5, #T_ddb5a_row16_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row5_col8, #T_ddb5a_row6_col8, #T_ddb5a_row15_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row5_col9, #T_ddb5a_row10_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row5_col10, #T_ddb5a_row6_col10, #T_ddb5a_row10_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row5_col11, #T_ddb5a_row8_col7, #T_ddb5a_row12_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row6_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row6_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row6_col5, #T_ddb5a_row8_col5, #T_ddb5a_row17_col3, #T_ddb5a_row24_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row6_col6, #T_ddb5a_row18_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row6_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row6_col11, #T_ddb5a_row19_col3, #T_ddb5a_row20_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row7_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row7_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row7_col6, #T_ddb5a_row22_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row7_col7, #T_ddb5a_row9_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row7_col8, #T_ddb5a_row19_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row7_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row8_col2, #T_ddb5a_row17_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row8_col3, #T_ddb5a_row15_col8, #T_ddb5a_row16_col2, #T_ddb5a_row25_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row8_col6, #T_ddb5a_row14_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row8_col10, #T_ddb5a_row9_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row8_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row9_col2, #T_ddb5a_row13_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row9_col3, #T_ddb5a_row14_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row9_col4, #T_ddb5a_row16_col4, #T_ddb5a_row18_col4, #T_ddb5a_row23_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row9_col5, #T_ddb5a_row21_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row9_col8, #T_ddb5a_row11_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row9_col9, #T_ddb5a_row15_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row10_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row10_col4, #T_ddb5a_row20_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row10_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row10_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row11_col2, #T_ddb5a_row23_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row11_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row11_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row11_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row11_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row12_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row12_col6, #T_ddb5a_row21_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row12_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row12_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row12_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row13_col5, #T_ddb5a_row13_col9, #T_ddb5a_row17_col4, #T_ddb5a_row17_col11, #T_ddb5a_row23_col3, #T_ddb5a_row23_col6, #T_ddb5a_row24_col7, #T_ddb5a_row24_col8, #T_ddb5a_row25_col2, #T_ddb5a_row25_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row13_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row13_col8, #T_ddb5a_row16_col8, #T_ddb5a_row17_col6, #T_ddb5a_row17_col7, #T_ddb5a_row22_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row13_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row14_col3, #T_ddb5a_row23_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row14_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row14_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row14_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row15_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row15_col9, #T_ddb5a_row17_col8, #T_ddb5a_row20_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ead5c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row15_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row16_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row16_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row16_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row16_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row16_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row17_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row17_col5, #T_ddb5a_row24_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row17_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row18_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row18_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row18_col9, #T_ddb5a_row18_col11, #T_ddb5a_row19_col9, #T_ddb5a_row19_col11, #T_ddb5a_row20_col9, #T_ddb5a_row20_col11, #T_ddb5a_row21_col9, #T_ddb5a_row21_col11, #T_ddb5a_row22_col9, #T_ddb5a_row22_col11, #T_ddb5a_row23_col9, #T_ddb5a_row23_col11, #T_ddb5a_row24_col9, #T_ddb5a_row24_col11, #T_ddb5a_row25_col3, #T_ddb5a_row25_col7, #T_ddb5a_row25_col9, #T_ddb5a_row25_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row19_col5, #T_ddb5a_row22_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row19_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row20_col3, #T_ddb5a_row21_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row20_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row20_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row20_col10, #T_ddb5a_row21_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row21_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row21_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row22_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row23_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row24_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ddb5a_row24_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ddb5a_row25_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ddb5a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ddb5a_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_ddb5a_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_ddb5a_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_ddb5a_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_ddb5a_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_ddb5a_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_ddb5a_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_ddb5a_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_ddb5a_level0_col8\" class=\"col_heading level0 col8\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_ddb5a_level0_col9\" class=\"col_heading level0 col9\" >AlpacaFarm(v.Davinci-003)/WR</th>\n",
       "      <th id=\"T_ddb5a_level0_col10\" class=\"col_heading level0 col10\" >Average</th>\n",
       "      <th id=\"T_ddb5a_level0_col11\" class=\"col_heading level0 col11\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ddb5a_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:k=vmf:gamma=0.00006:kmd=mpnet_pace=prune:size=200000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row0_col1\" class=\"data row0 col1\" >200000</td>\n",
       "      <td id=\"T_ddb5a_row0_col2\" class=\"data row0 col2\" >36.94</td>\n",
       "      <td id=\"T_ddb5a_row0_col3\" class=\"data row0 col3\" >34.73</td>\n",
       "      <td id=\"T_ddb5a_row0_col4\" class=\"data row0 col4\" >4.20</td>\n",
       "      <td id=\"T_ddb5a_row0_col5\" class=\"data row0 col5\" >14.40</td>\n",
       "      <td id=\"T_ddb5a_row0_col6\" class=\"data row0 col6\" >31.30</td>\n",
       "      <td id=\"T_ddb5a_row0_col7\" class=\"data row0 col7\" >31.02</td>\n",
       "      <td id=\"T_ddb5a_row0_col8\" class=\"data row0 col8\" >14.63</td>\n",
       "      <td id=\"T_ddb5a_row0_col9\" class=\"data row0 col9\" >53.73</td>\n",
       "      <td id=\"T_ddb5a_row0_col10\" class=\"data row0 col10\" >27.62</td>\n",
       "      <td id=\"T_ddb5a_row0_col11\" class=\"data row0 col11\" >-8.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ddb5a_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm_score=random:s=0_pace=prune:size=200000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row1_col1\" class=\"data row1 col1\" >200000</td>\n",
       "      <td id=\"T_ddb5a_row1_col2\" class=\"data row1 col2\" >37.79</td>\n",
       "      <td id=\"T_ddb5a_row1_col3\" class=\"data row1 col3\" >35.03</td>\n",
       "      <td id=\"T_ddb5a_row1_col4\" class=\"data row1 col4\" >4.00</td>\n",
       "      <td id=\"T_ddb5a_row1_col5\" class=\"data row1 col5\" >13.80</td>\n",
       "      <td id=\"T_ddb5a_row1_col6\" class=\"data row1 col6\" >31.94</td>\n",
       "      <td id=\"T_ddb5a_row1_col7\" class=\"data row1 col7\" >29.07</td>\n",
       "      <td id=\"T_ddb5a_row1_col8\" class=\"data row1 col8\" >15.85</td>\n",
       "      <td id=\"T_ddb5a_row1_col9\" class=\"data row1 col9\" >53.43</td>\n",
       "      <td id=\"T_ddb5a_row1_col10\" class=\"data row1 col10\" >27.61</td>\n",
       "      <td id=\"T_ddb5a_row1_col11\" class=\"data row1 col11\" >-8.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ddb5a_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm_score=semdedup:cl=kmeansfaisscd:md=mpnet:dist=cd:emb=text+embedding:nc=200_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row2_col1\" class=\"data row2 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row2_col2\" class=\"data row2 col2\" >32.12</td>\n",
       "      <td id=\"T_ddb5a_row2_col3\" class=\"data row2 col3\" >33.26</td>\n",
       "      <td id=\"T_ddb5a_row2_col4\" class=\"data row2 col4\" >4.00</td>\n",
       "      <td id=\"T_ddb5a_row2_col5\" class=\"data row2 col5\" >15.20</td>\n",
       "      <td id=\"T_ddb5a_row2_col6\" class=\"data row2 col6\" >33.70</td>\n",
       "      <td id=\"T_ddb5a_row2_col7\" class=\"data row2 col7\" >28.80</td>\n",
       "      <td id=\"T_ddb5a_row2_col8\" class=\"data row2 col8\" >19.51</td>\n",
       "      <td id=\"T_ddb5a_row2_col9\" class=\"data row2 col9\" >54.10</td>\n",
       "      <td id=\"T_ddb5a_row2_col10\" class=\"data row2 col10\" >27.59</td>\n",
       "      <td id=\"T_ddb5a_row2_col11\" class=\"data row2 col11\" >-11.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ddb5a_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:k=vmf:gamma=0.00006:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row3_col1\" class=\"data row3 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row3_col2\" class=\"data row3 col2\" >38.38</td>\n",
       "      <td id=\"T_ddb5a_row3_col3\" class=\"data row3 col3\" >34.37</td>\n",
       "      <td id=\"T_ddb5a_row3_col4\" class=\"data row3 col4\" >5.40</td>\n",
       "      <td id=\"T_ddb5a_row3_col5\" class=\"data row3 col5\" >12.80</td>\n",
       "      <td id=\"T_ddb5a_row3_col6\" class=\"data row3 col6\" >33.43</td>\n",
       "      <td id=\"T_ddb5a_row3_col7\" class=\"data row3 col7\" >29.72</td>\n",
       "      <td id=\"T_ddb5a_row3_col8\" class=\"data row3 col8\" >12.80</td>\n",
       "      <td id=\"T_ddb5a_row3_col9\" class=\"data row3 col9\" >51.75</td>\n",
       "      <td id=\"T_ddb5a_row3_col10\" class=\"data row3 col10\" >27.33</td>\n",
       "      <td id=\"T_ddb5a_row3_col11\" class=\"data row3 col11\" >-7.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ddb5a_row4_col0\" class=\"data row4 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:k=lin:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row4_col1\" class=\"data row4 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row4_col2\" class=\"data row4 col2\" >37.16</td>\n",
       "      <td id=\"T_ddb5a_row4_col3\" class=\"data row4 col3\" >35.51</td>\n",
       "      <td id=\"T_ddb5a_row4_col4\" class=\"data row4 col4\" >4.40</td>\n",
       "      <td id=\"T_ddb5a_row4_col5\" class=\"data row4 col5\" >12.00</td>\n",
       "      <td id=\"T_ddb5a_row4_col6\" class=\"data row4 col6\" >33.43</td>\n",
       "      <td id=\"T_ddb5a_row4_col7\" class=\"data row4 col7\" >30.09</td>\n",
       "      <td id=\"T_ddb5a_row4_col8\" class=\"data row4 col8\" >10.37</td>\n",
       "      <td id=\"T_ddb5a_row4_col9\" class=\"data row4 col9\" >52.55</td>\n",
       "      <td id=\"T_ddb5a_row4_col10\" class=\"data row4 col10\" >26.94</td>\n",
       "      <td id=\"T_ddb5a_row4_col11\" class=\"data row4 col11\" >-9.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ddb5a_row5_col0\" class=\"data row5 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:theta=0.6:k=lin:kmd=mpnet:q=prob:qmd=llama7b+lima_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row5_col1\" class=\"data row5 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row5_col2\" class=\"data row5 col2\" >37.64</td>\n",
       "      <td id=\"T_ddb5a_row5_col3\" class=\"data row5 col3\" >33.61</td>\n",
       "      <td id=\"T_ddb5a_row5_col4\" class=\"data row5 col4\" >5.40</td>\n",
       "      <td id=\"T_ddb5a_row5_col5\" class=\"data row5 col5\" >11.20</td>\n",
       "      <td id=\"T_ddb5a_row5_col6\" class=\"data row5 col6\" >32.13</td>\n",
       "      <td id=\"T_ddb5a_row5_col7\" class=\"data row5 col7\" >29.72</td>\n",
       "      <td id=\"T_ddb5a_row5_col8\" class=\"data row5 col8\" >14.02</td>\n",
       "      <td id=\"T_ddb5a_row5_col9\" class=\"data row5 col9\" >51.12</td>\n",
       "      <td id=\"T_ddb5a_row5_col10\" class=\"data row5 col10\" >26.85</td>\n",
       "      <td id=\"T_ddb5a_row5_col11\" class=\"data row5 col11\" >-10.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ddb5a_row6_col0\" class=\"data row6 col0\" >llama-7b_wizardlm_score=random:s=1_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row6_col1\" class=\"data row6 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row6_col2\" class=\"data row6 col2\" >36.08</td>\n",
       "      <td id=\"T_ddb5a_row6_col3\" class=\"data row6 col3\" >33.93</td>\n",
       "      <td id=\"T_ddb5a_row6_col4\" class=\"data row6 col4\" >5.20</td>\n",
       "      <td id=\"T_ddb5a_row6_col5\" class=\"data row6 col5\" >12.20</td>\n",
       "      <td id=\"T_ddb5a_row6_col6\" class=\"data row6 col6\" >31.20</td>\n",
       "      <td id=\"T_ddb5a_row6_col7\" class=\"data row6 col7\" >27.69</td>\n",
       "      <td id=\"T_ddb5a_row6_col8\" class=\"data row6 col8\" >14.02</td>\n",
       "      <td id=\"T_ddb5a_row6_col9\" class=\"data row6 col9\" >54.47</td>\n",
       "      <td id=\"T_ddb5a_row6_col10\" class=\"data row6 col10\" >26.85</td>\n",
       "      <td id=\"T_ddb5a_row6_col11\" class=\"data row6 col11\" >-12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ddb5a_row7_col0\" class=\"data row7 col0\" >llama-7b_wizardlm_score=random:s=0_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row7_col1\" class=\"data row7 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row7_col2\" class=\"data row7 col2\" >39.33</td>\n",
       "      <td id=\"T_ddb5a_row7_col3\" class=\"data row7 col3\" >35.36</td>\n",
       "      <td id=\"T_ddb5a_row7_col4\" class=\"data row7 col4\" >4.60</td>\n",
       "      <td id=\"T_ddb5a_row7_col5\" class=\"data row7 col5\" >9.60</td>\n",
       "      <td id=\"T_ddb5a_row7_col6\" class=\"data row7 col6\" >29.35</td>\n",
       "      <td id=\"T_ddb5a_row7_col7\" class=\"data row7 col7\" >29.54</td>\n",
       "      <td id=\"T_ddb5a_row7_col8\" class=\"data row7 col8\" >13.41</td>\n",
       "      <td id=\"T_ddb5a_row7_col9\" class=\"data row7 col9\" >53.42</td>\n",
       "      <td id=\"T_ddb5a_row7_col10\" class=\"data row7 col10\" >26.83</td>\n",
       "      <td id=\"T_ddb5a_row7_col11\" class=\"data row7 col11\" >-11.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ddb5a_row8_col0\" class=\"data row8 col0\" >llama-7b_wizardlm_score=semdedup:cl=kmeans:md=mpnet:dist=cd:emb=text+embedding:nc=200_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row8_col1\" class=\"data row8 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row8_col2\" class=\"data row8 col2\" >34.21</td>\n",
       "      <td id=\"T_ddb5a_row8_col3\" class=\"data row8 col3\" >32.61</td>\n",
       "      <td id=\"T_ddb5a_row8_col4\" class=\"data row8 col4\" >4.20</td>\n",
       "      <td id=\"T_ddb5a_row8_col5\" class=\"data row8 col5\" >12.20</td>\n",
       "      <td id=\"T_ddb5a_row8_col6\" class=\"data row8 col6\" >30.65</td>\n",
       "      <td id=\"T_ddb5a_row8_col7\" class=\"data row8 col7\" >30.00</td>\n",
       "      <td id=\"T_ddb5a_row8_col8\" class=\"data row8 col8\" >15.24</td>\n",
       "      <td id=\"T_ddb5a_row8_col9\" class=\"data row8 col9\" >53.11</td>\n",
       "      <td id=\"T_ddb5a_row8_col10\" class=\"data row8 col10\" >26.53</td>\n",
       "      <td id=\"T_ddb5a_row8_col11\" class=\"data row8 col11\" >-14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ddb5a_row9_col0\" class=\"data row9 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:theta=0.3:k=lin:kmd=mpnet:q=prob:qmd=llama7b+lima_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row9_col1\" class=\"data row9 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row9_col2\" class=\"data row9 col2\" >38.02</td>\n",
       "      <td id=\"T_ddb5a_row9_col3\" class=\"data row9 col3\" >34.34</td>\n",
       "      <td id=\"T_ddb5a_row9_col4\" class=\"data row9 col4\" >4.80</td>\n",
       "      <td id=\"T_ddb5a_row9_col5\" class=\"data row9 col5\" >11.80</td>\n",
       "      <td id=\"T_ddb5a_row9_col6\" class=\"data row9 col6\" >31.48</td>\n",
       "      <td id=\"T_ddb5a_row9_col7\" class=\"data row9 col7\" >29.07</td>\n",
       "      <td id=\"T_ddb5a_row9_col8\" class=\"data row9 col8\" >10.98</td>\n",
       "      <td id=\"T_ddb5a_row9_col9\" class=\"data row9 col9\" >51.49</td>\n",
       "      <td id=\"T_ddb5a_row9_col10\" class=\"data row9 col10\" >26.50</td>\n",
       "      <td id=\"T_ddb5a_row9_col11\" class=\"data row9 col11\" >-12.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ddb5a_row10_col0\" class=\"data row10 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:k=vmf:gamma=1.0:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row10_col1\" class=\"data row10 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row10_col2\" class=\"data row10 col2\" >37.48</td>\n",
       "      <td id=\"T_ddb5a_row10_col3\" class=\"data row10 col3\" >35.23</td>\n",
       "      <td id=\"T_ddb5a_row10_col4\" class=\"data row10 col4\" >5.00</td>\n",
       "      <td id=\"T_ddb5a_row10_col5\" class=\"data row10 col5\" >10.40</td>\n",
       "      <td id=\"T_ddb5a_row10_col6\" class=\"data row10 col6\" >32.13</td>\n",
       "      <td id=\"T_ddb5a_row10_col7\" class=\"data row10 col7\" >30.09</td>\n",
       "      <td id=\"T_ddb5a_row10_col8\" class=\"data row10 col8\" >10.37</td>\n",
       "      <td id=\"T_ddb5a_row10_col9\" class=\"data row10 col9\" >51.12</td>\n",
       "      <td id=\"T_ddb5a_row10_col10\" class=\"data row10 col10\" >26.48</td>\n",
       "      <td id=\"T_ddb5a_row10_col11\" class=\"data row10 col11\" >-11.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ddb5a_row11_col0\" class=\"data row11 col0\" >llama-7b_wizardlm_score=dppmap:k=lin:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row11_col1\" class=\"data row11 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row11_col2\" class=\"data row11 col2\" >34.73</td>\n",
       "      <td id=\"T_ddb5a_row11_col3\" class=\"data row11 col3\" >33.99</td>\n",
       "      <td id=\"T_ddb5a_row11_col4\" class=\"data row11 col4\" >4.40</td>\n",
       "      <td id=\"T_ddb5a_row11_col5\" class=\"data row11 col5\" >13.40</td>\n",
       "      <td id=\"T_ddb5a_row11_col6\" class=\"data row11 col6\" >32.78</td>\n",
       "      <td id=\"T_ddb5a_row11_col7\" class=\"data row11 col7\" >28.70</td>\n",
       "      <td id=\"T_ddb5a_row11_col8\" class=\"data row11 col8\" >10.98</td>\n",
       "      <td id=\"T_ddb5a_row11_col9\" class=\"data row11 col9\" >51.55</td>\n",
       "      <td id=\"T_ddb5a_row11_col10\" class=\"data row11 col10\" >26.32</td>\n",
       "      <td id=\"T_ddb5a_row11_col11\" class=\"data row11 col11\" >-14.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_ddb5a_row12_col0\" class=\"data row12 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:theta=0.3:k=lin:kmd=mpnet:q=ifd:qmd=llama7b+lima_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row12_col1\" class=\"data row12 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row12_col2\" class=\"data row12 col2\" >37.13</td>\n",
       "      <td id=\"T_ddb5a_row12_col3\" class=\"data row12 col3\" >33.73</td>\n",
       "      <td id=\"T_ddb5a_row12_col4\" class=\"data row12 col4\" >5.20</td>\n",
       "      <td id=\"T_ddb5a_row12_col5\" class=\"data row12 col5\" >10.60</td>\n",
       "      <td id=\"T_ddb5a_row12_col6\" class=\"data row12 col6\" >33.24</td>\n",
       "      <td id=\"T_ddb5a_row12_col7\" class=\"data row12 col7\" >28.43</td>\n",
       "      <td id=\"T_ddb5a_row12_col8\" class=\"data row12 col8\" >7.32</td>\n",
       "      <td id=\"T_ddb5a_row12_col9\" class=\"data row12 col9\" >54.42</td>\n",
       "      <td id=\"T_ddb5a_row12_col10\" class=\"data row12 col10\" >26.26</td>\n",
       "      <td id=\"T_ddb5a_row12_col11\" class=\"data row12 col11\" >-13.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_ddb5a_row13_col0\" class=\"data row13 col0\" >llama-7b_wizardlm_score=ifd_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row13_col1\" class=\"data row13 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row13_col2\" class=\"data row13 col2\" >38.01</td>\n",
       "      <td id=\"T_ddb5a_row13_col3\" class=\"data row13 col3\" >34.90</td>\n",
       "      <td id=\"T_ddb5a_row13_col4\" class=\"data row13 col4\" >5.80</td>\n",
       "      <td id=\"T_ddb5a_row13_col5\" class=\"data row13 col5\" >9.20</td>\n",
       "      <td id=\"T_ddb5a_row13_col6\" class=\"data row13 col6\" >31.76</td>\n",
       "      <td id=\"T_ddb5a_row13_col7\" class=\"data row13 col7\" >30.83</td>\n",
       "      <td id=\"T_ddb5a_row13_col8\" class=\"data row13 col8\" >9.15</td>\n",
       "      <td id=\"T_ddb5a_row13_col9\" class=\"data row13 col9\" >49.75</td>\n",
       "      <td id=\"T_ddb5a_row13_col10\" class=\"data row13 col10\" >26.18</td>\n",
       "      <td id=\"T_ddb5a_row13_col11\" class=\"data row13 col11\" >-12.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_ddb5a_row14_col0\" class=\"data row14 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:k=vmf:gamma=3.0:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row14_col1\" class=\"data row14 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row14_col2\" class=\"data row14 col2\" >37.07</td>\n",
       "      <td id=\"T_ddb5a_row14_col3\" class=\"data row14 col3\" >34.19</td>\n",
       "      <td id=\"T_ddb5a_row14_col4\" class=\"data row14 col4\" >4.40</td>\n",
       "      <td id=\"T_ddb5a_row14_col5\" class=\"data row14 col5\" >12.80</td>\n",
       "      <td id=\"T_ddb5a_row14_col6\" class=\"data row14 col6\" >30.65</td>\n",
       "      <td id=\"T_ddb5a_row14_col7\" class=\"data row14 col7\" >29.44</td>\n",
       "      <td id=\"T_ddb5a_row14_col8\" class=\"data row14 col8\" >7.93</td>\n",
       "      <td id=\"T_ddb5a_row14_col9\" class=\"data row14 col9\" >52.92</td>\n",
       "      <td id=\"T_ddb5a_row14_col10\" class=\"data row14 col10\" >26.17</td>\n",
       "      <td id=\"T_ddb5a_row14_col11\" class=\"data row14 col11\" >-14.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_ddb5a_row15_col0\" class=\"data row15 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:k=vmf:gamma=0.3:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row15_col1\" class=\"data row15 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row15_col2\" class=\"data row15 col2\" >37.32</td>\n",
       "      <td id=\"T_ddb5a_row15_col3\" class=\"data row15 col3\" >34.90</td>\n",
       "      <td id=\"T_ddb5a_row15_col4\" class=\"data row15 col4\" >4.40</td>\n",
       "      <td id=\"T_ddb5a_row15_col5\" class=\"data row15 col5\" >11.20</td>\n",
       "      <td id=\"T_ddb5a_row15_col6\" class=\"data row15 col6\" >30.56</td>\n",
       "      <td id=\"T_ddb5a_row15_col7\" class=\"data row15 col7\" >29.91</td>\n",
       "      <td id=\"T_ddb5a_row15_col8\" class=\"data row15 col8\" >6.71</td>\n",
       "      <td id=\"T_ddb5a_row15_col9\" class=\"data row15 col9\" >52.36</td>\n",
       "      <td id=\"T_ddb5a_row15_col10\" class=\"data row15 col10\" >25.92</td>\n",
       "      <td id=\"T_ddb5a_row15_col11\" class=\"data row15 col11\" >-15.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_ddb5a_row16_col0\" class=\"data row16 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:theta=0.6:k=lin:kmd=mpnet:q=ifd:qmd=llama7b+lima_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row16_col1\" class=\"data row16 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row16_col2\" class=\"data row16 col2\" >33.69</td>\n",
       "      <td id=\"T_ddb5a_row16_col3\" class=\"data row16 col3\" >31.93</td>\n",
       "      <td id=\"T_ddb5a_row16_col4\" class=\"data row16 col4\" >4.80</td>\n",
       "      <td id=\"T_ddb5a_row16_col5\" class=\"data row16 col5\" >11.20</td>\n",
       "      <td id=\"T_ddb5a_row16_col6\" class=\"data row16 col6\" >31.39</td>\n",
       "      <td id=\"T_ddb5a_row16_col7\" class=\"data row16 col7\" >29.17</td>\n",
       "      <td id=\"T_ddb5a_row16_col8\" class=\"data row16 col8\" >9.15</td>\n",
       "      <td id=\"T_ddb5a_row16_col9\" class=\"data row16 col9\" >53.23</td>\n",
       "      <td id=\"T_ddb5a_row16_col10\" class=\"data row16 col10\" >25.57</td>\n",
       "      <td id=\"T_ddb5a_row16_col11\" class=\"data row16 col11\" >-17.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_ddb5a_row17_col0\" class=\"data row17 col0\" >llama-7b_wizardlm_score=ifd:neg_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row17_col1\" class=\"data row17 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row17_col2\" class=\"data row17 col2\" >35.42</td>\n",
       "      <td id=\"T_ddb5a_row17_col3\" class=\"data row17 col3\" >33.51</td>\n",
       "      <td id=\"T_ddb5a_row17_col4\" class=\"data row17 col4\" >3.40</td>\n",
       "      <td id=\"T_ddb5a_row17_col5\" class=\"data row17 col5\" >10.80</td>\n",
       "      <td id=\"T_ddb5a_row17_col6\" class=\"data row17 col6\" >27.78</td>\n",
       "      <td id=\"T_ddb5a_row17_col7\" class=\"data row17 col7\" >28.89</td>\n",
       "      <td id=\"T_ddb5a_row17_col8\" class=\"data row17 col8\" >11.59</td>\n",
       "      <td id=\"T_ddb5a_row17_col9\" class=\"data row17 col9\" >51.36</td>\n",
       "      <td id=\"T_ddb5a_row17_col10\" class=\"data row17 col10\" >25.34</td>\n",
       "      <td id=\"T_ddb5a_row17_col11\" class=\"data row17 col11\" >-19.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_ddb5a_row18_col0\" class=\"data row18 col0\" >llama-7b_wizardlm_score=semdedup:cl=kmeansfaisscd:md=llama7b:dist=cd:emb=text+embedding:nc=200_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row18_col1\" class=\"data row18 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row18_col2\" class=\"data row18 col2\" >36.01</td>\n",
       "      <td id=\"T_ddb5a_row18_col3\" class=\"data row18 col3\" >34.59</td>\n",
       "      <td id=\"T_ddb5a_row18_col4\" class=\"data row18 col4\" >4.80</td>\n",
       "      <td id=\"T_ddb5a_row18_col5\" class=\"data row18 col5\" >15.00</td>\n",
       "      <td id=\"T_ddb5a_row18_col6\" class=\"data row18 col6\" >31.20</td>\n",
       "      <td id=\"T_ddb5a_row18_col7\" class=\"data row18 col7\" >28.52</td>\n",
       "      <td id=\"T_ddb5a_row18_col8\" class=\"data row18 col8\" >12.80</td>\n",
       "      <td id=\"T_ddb5a_row18_col9\" class=\"data row18 col9\" >nan</td>\n",
       "      <td id=\"T_ddb5a_row18_col10\" class=\"data row18 col10\" >23.27</td>\n",
       "      <td id=\"T_ddb5a_row18_col11\" class=\"data row18 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_ddb5a_row19_col0\" class=\"data row19 col0\" >llama-7b_wizardlm_score=semdedup:cl=kmeansfaisscd:md=bge:dist=cd:emb=text+embedding:nc=200_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row19_col1\" class=\"data row19 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row19_col2\" class=\"data row19 col2\" >36.15</td>\n",
       "      <td id=\"T_ddb5a_row19_col3\" class=\"data row19 col3\" >34.01</td>\n",
       "      <td id=\"T_ddb5a_row19_col4\" class=\"data row19 col4\" >4.00</td>\n",
       "      <td id=\"T_ddb5a_row19_col5\" class=\"data row19 col5\" >11.40</td>\n",
       "      <td id=\"T_ddb5a_row19_col6\" class=\"data row19 col6\" >32.50</td>\n",
       "      <td id=\"T_ddb5a_row19_col7\" class=\"data row19 col7\" >30.46</td>\n",
       "      <td id=\"T_ddb5a_row19_col8\" class=\"data row19 col8\" >13.41</td>\n",
       "      <td id=\"T_ddb5a_row19_col9\" class=\"data row19 col9\" >nan</td>\n",
       "      <td id=\"T_ddb5a_row19_col10\" class=\"data row19 col10\" >23.13</td>\n",
       "      <td id=\"T_ddb5a_row19_col11\" class=\"data row19 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_ddb5a_row20_col0\" class=\"data row20 col0\" >llama-7b_wizardlm_score=log:prob:neg_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row20_col1\" class=\"data row20 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row20_col2\" class=\"data row20 col2\" >36.44</td>\n",
       "      <td id=\"T_ddb5a_row20_col3\" class=\"data row20 col3\" >32.77</td>\n",
       "      <td id=\"T_ddb5a_row20_col4\" class=\"data row20 col4\" >5.00</td>\n",
       "      <td id=\"T_ddb5a_row20_col5\" class=\"data row20 col5\" >14.20</td>\n",
       "      <td id=\"T_ddb5a_row20_col6\" class=\"data row20 col6\" >27.41</td>\n",
       "      <td id=\"T_ddb5a_row20_col7\" class=\"data row20 col7\" >30.28</td>\n",
       "      <td id=\"T_ddb5a_row20_col8\" class=\"data row20 col8\" >11.59</td>\n",
       "      <td id=\"T_ddb5a_row20_col9\" class=\"data row20 col9\" >nan</td>\n",
       "      <td id=\"T_ddb5a_row20_col10\" class=\"data row20 col10\" >22.53</td>\n",
       "      <td id=\"T_ddb5a_row20_col11\" class=\"data row20 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_ddb5a_row21_col0\" class=\"data row21 col0\" >llama-7b_wizardlm_score=semdedup:cl=kmeansfaisscd:md=llama7b:dist=cd:emb=grad+rp+loraB:nc=200_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row21_col1\" class=\"data row21 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row21_col2\" class=\"data row21 col2\" >33.49</td>\n",
       "      <td id=\"T_ddb5a_row21_col3\" class=\"data row21 col3\" >32.76</td>\n",
       "      <td id=\"T_ddb5a_row21_col4\" class=\"data row21 col4\" >4.20</td>\n",
       "      <td id=\"T_ddb5a_row21_col5\" class=\"data row21 col5\" >11.80</td>\n",
       "      <td id=\"T_ddb5a_row21_col6\" class=\"data row21 col6\" >33.24</td>\n",
       "      <td id=\"T_ddb5a_row21_col7\" class=\"data row21 col7\" >29.26</td>\n",
       "      <td id=\"T_ddb5a_row21_col8\" class=\"data row21 col8\" >12.80</td>\n",
       "      <td id=\"T_ddb5a_row21_col9\" class=\"data row21 col9\" >nan</td>\n",
       "      <td id=\"T_ddb5a_row21_col10\" class=\"data row21 col10\" >22.51</td>\n",
       "      <td id=\"T_ddb5a_row21_col11\" class=\"data row21 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_ddb5a_row22_col0\" class=\"data row22 col0\" >llama-7b_wizardlm_score=el2n:agg=mean_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row22_col1\" class=\"data row22 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row22_col2\" class=\"data row22 col2\" >37.65</td>\n",
       "      <td id=\"T_ddb5a_row22_col3\" class=\"data row22 col3\" >32.42</td>\n",
       "      <td id=\"T_ddb5a_row22_col4\" class=\"data row22 col4\" >6.00</td>\n",
       "      <td id=\"T_ddb5a_row22_col5\" class=\"data row22 col5\" >11.40</td>\n",
       "      <td id=\"T_ddb5a_row22_col6\" class=\"data row22 col6\" >29.35</td>\n",
       "      <td id=\"T_ddb5a_row22_col7\" class=\"data row22 col7\" >29.72</td>\n",
       "      <td id=\"T_ddb5a_row22_col8\" class=\"data row22 col8\" >9.15</td>\n",
       "      <td id=\"T_ddb5a_row22_col9\" class=\"data row22 col9\" >nan</td>\n",
       "      <td id=\"T_ddb5a_row22_col10\" class=\"data row22 col10\" >22.24</td>\n",
       "      <td id=\"T_ddb5a_row22_col11\" class=\"data row22 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_ddb5a_row23_col0\" class=\"data row23 col0\" >llama-7b_wizardlm_score=grad:loraB:l2n_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_ddb5a_row23_col1\" class=\"data row23 col1\" >100000</td>\n",
       "      <td id=\"T_ddb5a_row23_col2\" class=\"data row23 col2\" >36.78</td>\n",
       "      <td id=\"T_ddb5a_row23_col3\" class=\"data row23 col3\" >31.50</td>\n",
       "      <td id=\"T_ddb5a_row23_col4\" class=\"data row23 col4\" >4.80</td>\n",
       "      <td id=\"T_ddb5a_row23_col5\" class=\"data row23 col5\" >13.20</td>\n",
       "      <td id=\"T_ddb5a_row23_col6\" class=\"data row23 col6\" >23.61</td>\n",
       "      <td id=\"T_ddb5a_row23_col7\" class=\"data row23 col7\" >28.80</td>\n",
       "      <td id=\"T_ddb5a_row23_col8\" class=\"data row23 col8\" >10.37</td>\n",
       "      <td id=\"T_ddb5a_row23_col9\" class=\"data row23 col9\" >nan</td>\n",
       "      <td id=\"T_ddb5a_row23_col10\" class=\"data row23 col10\" >21.29</td>\n",
       "      <td id=\"T_ddb5a_row23_col11\" class=\"data row23 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_ddb5a_row24_col0\" class=\"data row24 col0\" >llama-7b</td>\n",
       "      <td id=\"T_ddb5a_row24_col1\" class=\"data row24 col1\" >None</td>\n",
       "      <td id=\"T_ddb5a_row24_col2\" class=\"data row24 col2\" >32.82</td>\n",
       "      <td id=\"T_ddb5a_row24_col3\" class=\"data row24 col3\" >33.51</td>\n",
       "      <td id=\"T_ddb5a_row24_col4\" class=\"data row24 col4\" >5.40</td>\n",
       "      <td id=\"T_ddb5a_row24_col5\" class=\"data row24 col5\" >10.80</td>\n",
       "      <td id=\"T_ddb5a_row24_col6\" class=\"data row24 col6\" >32.13</td>\n",
       "      <td id=\"T_ddb5a_row24_col7\" class=\"data row24 col7\" >27.41</td>\n",
       "      <td id=\"T_ddb5a_row24_col8\" class=\"data row24 col8\" >1.83</td>\n",
       "      <td id=\"T_ddb5a_row24_col9\" class=\"data row24 col9\" >nan</td>\n",
       "      <td id=\"T_ddb5a_row24_col10\" class=\"data row24 col10\" >20.56</td>\n",
       "      <td id=\"T_ddb5a_row24_col11\" class=\"data row24 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb5a_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_ddb5a_row25_col0\" class=\"data row25 col0\" >llama-7b+lima</td>\n",
       "      <td id=\"T_ddb5a_row25_col1\" class=\"data row25 col1\" >None</td>\n",
       "      <td id=\"T_ddb5a_row25_col2\" class=\"data row25 col2\" >31.55</td>\n",
       "      <td id=\"T_ddb5a_row25_col3\" class=\"data row25 col3\" >nan</td>\n",
       "      <td id=\"T_ddb5a_row25_col4\" class=\"data row25 col4\" >5.60</td>\n",
       "      <td id=\"T_ddb5a_row25_col5\" class=\"data row25 col5\" >9.80</td>\n",
       "      <td id=\"T_ddb5a_row25_col6\" class=\"data row25 col6\" >31.11</td>\n",
       "      <td id=\"T_ddb5a_row25_col7\" class=\"data row25 col7\" >nan</td>\n",
       "      <td id=\"T_ddb5a_row25_col8\" class=\"data row25 col8\" >6.71</td>\n",
       "      <td id=\"T_ddb5a_row25_col9\" class=\"data row25 col9\" >nan</td>\n",
       "      <td id=\"T_ddb5a_row25_col10\" class=\"data row25 col10\" >16.95</td>\n",
       "      <td id=\"T_ddb5a_row25_col11\" class=\"data row25 col11\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffca02bdab0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_03539_row0_col0, #T_03539_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_03539_row0_col2, #T_03539_row0_col3, #T_03539_row0_col4, #T_03539_row0_col5, #T_03539_row0_col6, #T_03539_row0_col7, #T_03539_row0_col8, #T_03539_row0_col9, #T_03539_row0_col10, #T_03539_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_03539\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_03539_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_03539_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_03539_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_03539_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_03539_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_03539_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_03539_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_03539_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_03539_level0_col8\" class=\"col_heading level0 col8\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_03539_level0_col9\" class=\"col_heading level0 col9\" >AlpacaFarm(v.Davinci-003)/WR</th>\n",
       "      <th id=\"T_03539_level0_col10\" class=\"col_heading level0 col10\" >Average</th>\n",
       "      <th id=\"T_03539_level0_col11\" class=\"col_heading level0 col11\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_03539_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_03539_row0_col0\" class=\"data row0 col0\" >mistral-7b+lima</td>\n",
       "      <td id=\"T_03539_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_03539_row0_col2\" class=\"data row0 col2\" >59.63</td>\n",
       "      <td id=\"T_03539_row0_col3\" class=\"data row0 col3\" >30.12</td>\n",
       "      <td id=\"T_03539_row0_col4\" class=\"data row0 col4\" >8.80</td>\n",
       "      <td id=\"T_03539_row0_col5\" class=\"data row0 col5\" >5.00</td>\n",
       "      <td id=\"T_03539_row0_col6\" class=\"data row0 col6\" >21.85</td>\n",
       "      <td id=\"T_03539_row0_col7\" class=\"data row0 col7\" >41.94</td>\n",
       "      <td id=\"T_03539_row0_col8\" class=\"data row0 col8\" >33.54</td>\n",
       "      <td id=\"T_03539_row0_col9\" class=\"data row0 col9\" >41.12</td>\n",
       "      <td id=\"T_03539_row0_col10\" class=\"data row0 col10\" >30.25</td>\n",
       "      <td id=\"T_03539_row0_col11\" class=\"data row0 col11\" >-11.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffca037f040>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_sort_rows_by_avg_ranking\n",
    "from llm.evaluate import EvalResults, get_eval_results\n",
    "\n",
    "\n",
    "\n",
    "exp_dir = ''\n",
    "chat_fmt = None\n",
    "sort_rows = True\n",
    "use_normalized_preferred_metric = False\n",
    "\n",
    "\n",
    "# ## investigate code change / package update effect on eval baselines.\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# use_normalized_preferred_metric = False\n",
    "# save_dirs = [\n",
    "#     # llama\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b_10.30update', '../results/baselines/huggyllama/llama-7b_10.30update/'),\n",
    "#     ('llama-7b_09.23update', '../results/baselines/huggyllama/llama-7b_09.23update/'),\n",
    "#     ('llama-7b_09.23update_before', '../results/baselines/huggyllama/llama-7b_09.23update_before/'),\n",
    "#     # llama2\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('llama2-7b_10.30update', '../results/baselines/NousResearch/Llama-2-7b-hf_10.30update/'),\n",
    "#     ('llama2-7b_original', '../results/baselines/NousResearch/Llama-2-7b-hf_original/'),\n",
    "#     # mistral\n",
    "#     ('mistral-7b_10.16update', '../results/baselines/mistralai/Mistral-7B-v0.1_10.16update/'),\n",
    "#     ('mistral-7b-Instruct_10.16update', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "# ]\n",
    "\n",
    "# baselines\n",
    "save_dirs = []\n",
    "# save_dirs += [\n",
    "# #     ('gpt2', '../results/baselines/gpt2'),\n",
    "# #     ('gpt2m', '../results/baselines/gpt2-medium'),\n",
    "# #     ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'),\n",
    "# #     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "# #     ('llama2-7b+humanmix', '../results/llama2-7b_humanmix'),\n",
    "# #     ('pythia-1.4b', '../results/baselines/EleutherAI/pythia-1.4b'),\n",
    "# #     ('pythia-2.8b', '../results/baselines/EleutherAI/pythia-2.8b'),\n",
    "# #     ('pythia-6.9b', '../results/baselines/EleutherAI/pythia-6.9b'),\n",
    "# #     ('dolly-v2-7b', '../results/baselines/databricks/dolly-v2-7b'),\n",
    "#     ('mistral-7b-v0.1', '../results/baselines/mistralai/Mistral-7B-v0.1')\n",
    "# ]\n",
    "# use_normalized_preferred_metric = False\n",
    "\n",
    "# exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# # exp_dir = '../results/ft2'\n",
    "# # exp_dir = '../results/ft1'\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "#     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1/'),\n",
    "# ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "# # exp_dir = '../results/oi4'\n",
    "# # exp_dir = '../results/oi4_perf_cross_time'\n",
    "# # exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'\n",
    "# exp_dir = '../results/oi4_flan_v2_vary_subsetsize'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi4_flan2022_1m'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #              ('llama-7b_flan_v2_ep=2', '../results/ft1/llama-7b_flan_v2'),\n",
    "# #              ('llama-7b_humanmix_ep=2', '../results/ft1/llama-7b_humanmix'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "# #              ('llama-7b_cot:flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_cot:flanv2'),\n",
    "#             ]\n",
    "# use_normalized_preferred_metric = True\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# # exp_dir = '../results/oi4_tulu_v1_mix'\n",
    "# exp_dir = '../results/oi4_tulu_v1_mix_ep=3'\n",
    "# use_normalized_preferred_metric = False\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# save_dirs = [\n",
    "#     # baselines \n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "# #     ('llama-7b_sharegpt_ep=2', '../results/ft1_ep=2/llama-7b_sharegpt'),\n",
    "#     # oi4_tulu_v1_mix_ep=3 models before transformers update.\n",
    "# #     ('llama-7b_tuluv1m:50k_log_prob_decr_<10.16update', '../results/oi4_tulu_v1_mix_ep=3/llama-7b_tuluv1m:50k_log_prob_decr'),\n",
    "# ]\n",
    "# exp_dir = '../results/oi5_tulu_v1_mix:llama-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "\n",
    "# save_dirs = [\n",
    "#     # baselines \n",
    "#     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "# #     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     ('mistral-7b_ultrachat200k_aftersplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k'),\n",
    "#     ('mistral-7b_ultrachat200k_beforesplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k_beforesplitlongconv'),\n",
    "# #     ('mistral-7b_sft-alpha', '../results/baselines/HuggingFaceH4/mistral-7b-sft-alpha'),\n",
    "# #     ('mistral-7b-sft-beta', '../results/baselines/HuggingFaceH4/mistral-7b-sft-beta'),\n",
    "# #     ('mistral-7b-sft-alpha+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-alpha'),\n",
    "# #     ('mistral-7b-sft-beta+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "# # exp_dir = '../results/oi5_ultrachat:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_ultrachat200k:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# exp_dir = '../results/oi5_ultrachat15:mistral-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "\n",
    "save_dirs = [\n",
    "    ('llama-7b+lima', '../results/ft1_ep=2/llama-7b_lima/'),\n",
    "    ('mistral-7b+lima', '../results/ft1_ep=2/mistral-7b_lima/'), \n",
    "    ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "]\n",
    "exp_dir = '../results/oi5_wizardlm:llama-7b'\n",
    "save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'size=150000' not in x]\n",
    "\n",
    "\n",
    "###### \n",
    "\n",
    "from llm.evaluate import detect_oom_evals\n",
    "oom_eval_paths = detect_oom_evals([x for l in [glob.glob(os.path.join(x[1], 'eval/*/*.out')) for x in save_dirs] for x in l])\n",
    "if oom_eval_paths: print(oom_eval_paths)\n",
    "\n",
    "if any(exp_dir.endswith(x) for x in ['', 'ft2', 'oi4']):\n",
    "    chat_fmt = False\n",
    "    chat_fmt = True\n",
    "#     chat_fmt = 'both'\n",
    "    ft_args_fields = [\n",
    "        'run_name',\n",
    "        'model_args.model_name_or_path',\n",
    "        'data_args.subsample_mixture',\n",
    "        'data_args.max_train_samples',\n",
    "    ]\n",
    "    print(f'chat_fmt={chat_fmt}')\n",
    "    df = get_eval_results(save_dirs, chat_fmt=chat_fmt, ft_args_fields=ft_args_fields, use_normalized_preferred_metric=use_normalized_preferred_metric)\n",
    "#     df = get_eval_results(save_dirs, chat_fmt='both', ft_args_fields=ft_args_fields)\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "#     cols = ['MMLU/0-shot', 'GSM/Direct', 'BBH/Direct', 'TydiQA/CB', 'Codex-Eval/Pass@1']\n",
    "\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'Codex-Eval/Pass@1', 'AlpacaFarm(v.Davinci-003)/WR']\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1'] #  'ToxiGen/Acc'\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT']\n",
    "\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm(v.Davinci-003)/WR']\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'Codex-Eval/Pass@1', 'AlpacaFarm(v.Davinci-003)/WR']\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm(v.Davinci-003)/WR'] #  'ToxiGen/Acc'\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', 'AlpacaFarm(v.Davinci-003)/WR'] #  entire, without tydiqa, which has high variance\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', ] #  entire, without tydiqa, which has high variance\n",
    "\n",
    "    df = df[ft_args_fields + cols]\n",
    "    df['Average'] = df[cols].mean(axis=1)\n",
    "    if sort_rows:\n",
    "        df = pd_sort_rows_by_avg_ranking(df); df['ranking'] = -df['ranking']\n",
    "        sort_value_col, sort_value_col_ascending = 'Average', False\n",
    "    #     sort_value_col, sort_value_col_ascending = 'ranking', False\n",
    "        df = df.sort_values(sort_value_col, ascending=sort_value_col_ascending)\n",
    "    df = df.reset_index(drop=True)\n",
    "else:\n",
    "    ft_args_fields = [\n",
    "        'run_name',\n",
    "        'data_args.subsample_mixture',\n",
    "        'data_args.max_train_samples',\n",
    "    ]\n",
    "    df = get_eval_results(save_dirs, chat_fmt='both', ft_args_fields=ft_args_fields, use_normalized_preferred_metric=use_normalized_preferred_metric)\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "    df = df[ft_args_fields+cols]\n",
    "    \n",
    "\n",
    "def compute_total_train_samples(x):\n",
    "    match = re.search(r'size=(\\d+)', x['run_name' if chat_fmt!='both' else ('run_name', '')])\n",
    "    total_train_samples = match.group(1) if match else None\n",
    "    return total_train_samples\n",
    "df.insert(1, 'total_train_samples' if chat_fmt!='both' else ('total_train_samples', ''), df.apply(compute_total_train_samples, axis=1))\n",
    "\n",
    "if any(exp_dir.endswith(x) for x in ['ft2']):\n",
    "#     for model_name_contain in ['gpt2', 'llama', 'pythia-1.4b']:\n",
    "#         for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "    for model_name_contain in ['llama']:\n",
    "        for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "#         for total_train_samples in [200000, 400000, 600000]:\n",
    "            dfc = df.copy()\n",
    "            dfc.insert(0, 'total_train_samples',  dfc['data_args.subsample_mixture'].apply(\n",
    "                lambda d: sum(list(d.values())) if d else 200000))\n",
    "            dfc = dfc[dfc['total_train_samples'].apply(\n",
    "                lambda x: total_train_samples-20000<x<total_train_samples+20000)]\n",
    "            dfc = dfc[dfc['model_args.model_name_or_path'].apply(\n",
    "                lambda x: model_name_contain in x)]\n",
    "            dfc['total_train_samples'] = dfc['total_train_samples'].astype(str)\n",
    "            dfc = dfc.drop(columns=['model_args.model_name_or_path', 'data_args.subsample_mixture'])\n",
    "            dfc = dfc.reset_index(drop=True)\n",
    "            if len(dfc):\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .format(precision=2))\n",
    "elif any(exp_dir.endswith(x) for x in ['oi4']):\n",
    "    dfc = df.copy()\n",
    "    dfc = dfc.drop(columns=['model_args.model_name_or_path', 'data_args.subsample_mixture', 'data_args.max_train_samples'])\n",
    "    dfc = dfc.reset_index(drop=True)\n",
    "    if len(dfc):\n",
    "        display(dfc\n",
    "                .style\n",
    "                .set_properties(**{'text-align': 'left'})\n",
    "                .background_gradient(cmap ='coolwarm')\n",
    "                .format(precision=1))\n",
    "else:\n",
    "    for model_name_contain in ['llama', 'pythia-1.4b', 'mistral']:\n",
    "        dfc = df.copy()\n",
    "        dfc = dfc[dfc['model_args.model_name_or_path'].apply(\n",
    "            lambda x: model_name_contain in x)]\n",
    "        dfc = dfc.drop(columns=['model_args.model_name_or_path', 'data_args.subsample_mixture', 'data_args.max_train_samples'])\n",
    "        dfc = dfc.reset_index(drop=True)\n",
    "        if len(dfc):\n",
    "            display(dfc\n",
    "                    .style\n",
    "                    .set_properties(**{'text-align': 'left'})\n",
    "                    .background_gradient(cmap ='coolwarm')\n",
    "                    .format(precision=2))\n",
    "\n",
    "# llama-7b_tulu_v1_mix(paper)\n",
    "# MMLU/0-shot, MMLU/5-shot, GSM/Direct, GSM/CoT, BBH/Direct, BBH/CoT, TydiQA/GP, TydiQA/CB, CodexEval/Pass@1, AlpacaEval(vs.Davinci-003)\n",
    "# 44.8       , 47.1       , 7.0       , 25.0   , 38.5      , 38.5   , 43.5,    , 8.0      , 18.6,           , 48.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16806ad9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_eca0c_row0_col0, #T_eca0c_row0_col1, #T_eca0c_row1_col0, #T_eca0c_row1_col1, #T_eca0c_row2_col0, #T_eca0c_row2_col1, #T_eca0c_row3_col0, #T_eca0c_row3_col1, #T_eca0c_row4_col0, #T_eca0c_row4_col1, #T_eca0c_row5_col0, #T_eca0c_row5_col1, #T_eca0c_row6_col0, #T_eca0c_row6_col1, #T_eca0c_row7_col0, #T_eca0c_row7_col1, #T_eca0c_row8_col0, #T_eca0c_row8_col1, #T_eca0c_row9_col0, #T_eca0c_row9_col1, #T_eca0c_row10_col0, #T_eca0c_row10_col1, #T_eca0c_row11_col0, #T_eca0c_row11_col1, #T_eca0c_row12_col0, #T_eca0c_row12_col1, #T_eca0c_row13_col0, #T_eca0c_row13_col1, #T_eca0c_row14_col0, #T_eca0c_row14_col1, #T_eca0c_row15_col0, #T_eca0c_row15_col1, #T_eca0c_row16_col0, #T_eca0c_row16_col1, #T_eca0c_row17_col0, #T_eca0c_row17_col1, #T_eca0c_row18_col0, #T_eca0c_row18_col1, #T_eca0c_row19_col0, #T_eca0c_row19_col1, #T_eca0c_row20_col0, #T_eca0c_row20_col1, #T_eca0c_row21_col0, #T_eca0c_row21_col1, #T_eca0c_row22_col0, #T_eca0c_row22_col1, #T_eca0c_row23_col0, #T_eca0c_row23_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_eca0c_row0_col2, #T_eca0c_row0_col4, #T_eca0c_row0_col7, #T_eca0c_row0_col8, #T_eca0c_row0_col10, #T_eca0c_row1_col5, #T_eca0c_row1_col6, #T_eca0c_row2_col11, #T_eca0c_row3_col3, #T_eca0c_row10_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row0_col3, #T_eca0c_row0_col5, #T_eca0c_row0_col6, #T_eca0c_row0_col9, #T_eca0c_row15_col4, #T_eca0c_row15_col11, #T_eca0c_row22_col7, #T_eca0c_row22_col8, #T_eca0c_row23_col2, #T_eca0c_row23_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row0_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row1_col3, #T_eca0c_row5_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row1_col4, #T_eca0c_row17_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row1_col7, #T_eca0c_row6_col2, #T_eca0c_row21_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row1_col9, #T_eca0c_row2_col6, #T_eca0c_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row1_col10, #T_eca0c_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row1_col11, #T_eca0c_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row2_col4, #T_eca0c_row4_col4, #T_eca0c_row13_col11, #T_eca0c_row22_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row2_col5, #T_eca0c_row12_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row2_col7, #T_eca0c_row4_col7, #T_eca0c_row16_col2, #T_eca0c_row20_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row2_col8, #T_eca0c_row16_col8, #T_eca0c_row19_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row2_col10, #T_eca0c_row7_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row3_col4, #T_eca0c_row3_col7, #T_eca0c_row8_col7, #T_eca0c_row9_col4, #T_eca0c_row12_col4, #T_eca0c_row13_col4, #T_eca0c_row21_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row3_col8, #T_eca0c_row8_col8, #T_eca0c_row21_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e16751;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row3_col10, #T_eca0c_row4_col9, #T_eca0c_row8_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row3_col11, #T_eca0c_row5_col3, #T_eca0c_row11_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row4_col2, #T_eca0c_row20_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row4_col3, #T_eca0c_row5_col11, #T_eca0c_row14_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row4_col5, #T_eca0c_row13_col5, #T_eca0c_row14_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f2c9b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row4_col6, #T_eca0c_row8_col6, #T_eca0c_row22_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row4_col10, #T_eca0c_row5_col10, #T_eca0c_row6_col6, #T_eca0c_row12_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row4_col11, #T_eca0c_row7_col10, #T_eca0c_row8_col10, #T_eca0c_row9_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row5_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row5_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row5_col9, #T_eca0c_row10_col6, #T_eca0c_row19_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row6_col3, #T_eca0c_row10_col11, #T_eca0c_row17_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row6_col4, #T_eca0c_row19_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row6_col5, #T_eca0c_row9_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row6_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row6_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row6_col9, #T_eca0c_row17_col6, #T_eca0c_row18_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row6_col10, #T_eca0c_row17_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row6_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row7_col2, #T_eca0c_row11_col8, #T_eca0c_row14_col8, #T_eca0c_row20_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row7_col3, #T_eca0c_row9_col9, #T_eca0c_row23_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row7_col4, #T_eca0c_row14_col4, #T_eca0c_row16_col4, #T_eca0c_row21_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row7_col5, #T_eca0c_row19_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row7_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row7_col7, #T_eca0c_row9_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row7_col8, #T_eca0c_row9_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row7_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row8_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row8_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row8_col4, #T_eca0c_row18_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row8_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row8_col11, #T_eca0c_row20_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row9_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row9_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row9_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row9_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row10_col2, #T_eca0c_row12_col2, #T_eca0c_row18_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row10_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row10_col4, #T_eca0c_row14_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row10_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row10_col7, #T_eca0c_row19_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row10_col8, #T_eca0c_row13_col7, #T_eca0c_row18_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row10_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row11_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row11_col3, #T_eca0c_row13_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row11_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row11_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row11_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row11_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row11_col10, #T_eca0c_row12_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row11_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row12_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row12_col7, #T_eca0c_row15_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row12_col8, #T_eca0c_row14_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row12_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row12_col11, #T_eca0c_row20_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row13_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row13_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row13_col8, #T_eca0c_row23_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row13_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row13_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row14_col2, #T_eca0c_row16_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row14_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row14_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row14_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row15_col3, #T_eca0c_row17_col5, #T_eca0c_row20_col5, #T_eca0c_row22_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row15_col5, #T_eca0c_row22_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row15_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row15_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row15_col8, #T_eca0c_row18_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row15_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row15_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row16_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row16_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row16_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row16_col9, #T_eca0c_row16_col11, #T_eca0c_row17_col9, #T_eca0c_row17_col11, #T_eca0c_row18_col9, #T_eca0c_row18_col11, #T_eca0c_row19_col9, #T_eca0c_row19_col11, #T_eca0c_row20_col9, #T_eca0c_row20_col11, #T_eca0c_row21_col9, #T_eca0c_row21_col11, #T_eca0c_row22_col9, #T_eca0c_row22_col11, #T_eca0c_row23_col3, #T_eca0c_row23_col7, #T_eca0c_row23_col9, #T_eca0c_row23_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row16_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row17_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row17_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row17_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row18_col3, #T_eca0c_row19_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row18_col6, #T_eca0c_row23_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row18_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row19_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row19_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row20_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row20_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row21_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row21_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row21_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row21_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row22_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_eca0c_row22_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_eca0c_row23_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_eca0c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_eca0c_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_eca0c_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_eca0c_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_eca0c_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_eca0c_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_eca0c_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_eca0c_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_eca0c_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_eca0c_level0_col8\" class=\"col_heading level0 col8\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_eca0c_level0_col9\" class=\"col_heading level0 col9\" >AlpacaFarm(v.Davinci-003)/WR</th>\n",
       "      <th id=\"T_eca0c_level0_col10\" class=\"col_heading level0 col10\" >Average</th>\n",
       "      <th id=\"T_eca0c_level0_col11\" class=\"col_heading level0 col11\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_eca0c_row0_col0\" class=\"data row0 col0\" >mistral-7b+lima</td>\n",
       "      <td id=\"T_eca0c_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_eca0c_row0_col2\" class=\"data row0 col2\" >59.6</td>\n",
       "      <td id=\"T_eca0c_row0_col3\" class=\"data row0 col3\" >30.1</td>\n",
       "      <td id=\"T_eca0c_row0_col4\" class=\"data row0 col4\" >8.8</td>\n",
       "      <td id=\"T_eca0c_row0_col5\" class=\"data row0 col5\" >5.0</td>\n",
       "      <td id=\"T_eca0c_row0_col6\" class=\"data row0 col6\" >21.9</td>\n",
       "      <td id=\"T_eca0c_row0_col7\" class=\"data row0 col7\" >41.9</td>\n",
       "      <td id=\"T_eca0c_row0_col8\" class=\"data row0 col8\" >33.5</td>\n",
       "      <td id=\"T_eca0c_row0_col9\" class=\"data row0 col9\" >41.1</td>\n",
       "      <td id=\"T_eca0c_row0_col10\" class=\"data row0 col10\" >30.3</td>\n",
       "      <td id=\"T_eca0c_row0_col11\" class=\"data row0 col11\" >-11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_eca0c_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm_score=semdedup:cl=kmeansfaisscd:md=mpnet:dist=cd:emb=text+embedding:nc=200_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row1_col1\" class=\"data row1 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row1_col2\" class=\"data row1 col2\" >32.1</td>\n",
       "      <td id=\"T_eca0c_row1_col3\" class=\"data row1 col3\" >33.3</td>\n",
       "      <td id=\"T_eca0c_row1_col4\" class=\"data row1 col4\" >4.0</td>\n",
       "      <td id=\"T_eca0c_row1_col5\" class=\"data row1 col5\" >15.2</td>\n",
       "      <td id=\"T_eca0c_row1_col6\" class=\"data row1 col6\" >33.7</td>\n",
       "      <td id=\"T_eca0c_row1_col7\" class=\"data row1 col7\" >28.8</td>\n",
       "      <td id=\"T_eca0c_row1_col8\" class=\"data row1 col8\" >19.5</td>\n",
       "      <td id=\"T_eca0c_row1_col9\" class=\"data row1 col9\" >54.1</td>\n",
       "      <td id=\"T_eca0c_row1_col10\" class=\"data row1 col10\" >27.6</td>\n",
       "      <td id=\"T_eca0c_row1_col11\" class=\"data row1 col11\" >-11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_eca0c_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:k=vmf:gamma=0.00006:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row2_col1\" class=\"data row2 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row2_col2\" class=\"data row2 col2\" >38.4</td>\n",
       "      <td id=\"T_eca0c_row2_col3\" class=\"data row2 col3\" >34.4</td>\n",
       "      <td id=\"T_eca0c_row2_col4\" class=\"data row2 col4\" >5.4</td>\n",
       "      <td id=\"T_eca0c_row2_col5\" class=\"data row2 col5\" >12.8</td>\n",
       "      <td id=\"T_eca0c_row2_col6\" class=\"data row2 col6\" >33.4</td>\n",
       "      <td id=\"T_eca0c_row2_col7\" class=\"data row2 col7\" >29.7</td>\n",
       "      <td id=\"T_eca0c_row2_col8\" class=\"data row2 col8\" >12.8</td>\n",
       "      <td id=\"T_eca0c_row2_col9\" class=\"data row2 col9\" >51.7</td>\n",
       "      <td id=\"T_eca0c_row2_col10\" class=\"data row2 col10\" >27.3</td>\n",
       "      <td id=\"T_eca0c_row2_col11\" class=\"data row2 col11\" >-7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_eca0c_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:k=lin:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row3_col1\" class=\"data row3 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row3_col2\" class=\"data row3 col2\" >37.2</td>\n",
       "      <td id=\"T_eca0c_row3_col3\" class=\"data row3 col3\" >35.5</td>\n",
       "      <td id=\"T_eca0c_row3_col4\" class=\"data row3 col4\" >4.4</td>\n",
       "      <td id=\"T_eca0c_row3_col5\" class=\"data row3 col5\" >12.0</td>\n",
       "      <td id=\"T_eca0c_row3_col6\" class=\"data row3 col6\" >33.4</td>\n",
       "      <td id=\"T_eca0c_row3_col7\" class=\"data row3 col7\" >30.1</td>\n",
       "      <td id=\"T_eca0c_row3_col8\" class=\"data row3 col8\" >10.4</td>\n",
       "      <td id=\"T_eca0c_row3_col9\" class=\"data row3 col9\" >52.5</td>\n",
       "      <td id=\"T_eca0c_row3_col10\" class=\"data row3 col10\" >26.9</td>\n",
       "      <td id=\"T_eca0c_row3_col11\" class=\"data row3 col11\" >-9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_eca0c_row4_col0\" class=\"data row4 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:theta=0.6:k=lin:kmd=mpnet:q=prob:qmd=llama7b+lima_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row4_col1\" class=\"data row4 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row4_col2\" class=\"data row4 col2\" >37.6</td>\n",
       "      <td id=\"T_eca0c_row4_col3\" class=\"data row4 col3\" >33.6</td>\n",
       "      <td id=\"T_eca0c_row4_col4\" class=\"data row4 col4\" >5.4</td>\n",
       "      <td id=\"T_eca0c_row4_col5\" class=\"data row4 col5\" >11.2</td>\n",
       "      <td id=\"T_eca0c_row4_col6\" class=\"data row4 col6\" >32.1</td>\n",
       "      <td id=\"T_eca0c_row4_col7\" class=\"data row4 col7\" >29.7</td>\n",
       "      <td id=\"T_eca0c_row4_col8\" class=\"data row4 col8\" >14.0</td>\n",
       "      <td id=\"T_eca0c_row4_col9\" class=\"data row4 col9\" >51.1</td>\n",
       "      <td id=\"T_eca0c_row4_col10\" class=\"data row4 col10\" >26.9</td>\n",
       "      <td id=\"T_eca0c_row4_col11\" class=\"data row4 col11\" >-10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_eca0c_row5_col0\" class=\"data row5 col0\" >score=random:s=(\\d)_pace=prune:size=100000_avg (N=2)</td>\n",
       "      <td id=\"T_eca0c_row5_col1\" class=\"data row5 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row5_col2\" class=\"data row5 col2\" >37.7</td>\n",
       "      <td id=\"T_eca0c_row5_col3\" class=\"data row5 col3\" >34.6</td>\n",
       "      <td id=\"T_eca0c_row5_col4\" class=\"data row5 col4\" >4.9</td>\n",
       "      <td id=\"T_eca0c_row5_col5\" class=\"data row5 col5\" >10.9</td>\n",
       "      <td id=\"T_eca0c_row5_col6\" class=\"data row5 col6\" >30.3</td>\n",
       "      <td id=\"T_eca0c_row5_col7\" class=\"data row5 col7\" >28.6</td>\n",
       "      <td id=\"T_eca0c_row5_col8\" class=\"data row5 col8\" >13.7</td>\n",
       "      <td id=\"T_eca0c_row5_col9\" class=\"data row5 col9\" >53.9</td>\n",
       "      <td id=\"T_eca0c_row5_col10\" class=\"data row5 col10\" >26.8</td>\n",
       "      <td id=\"T_eca0c_row5_col11\" class=\"data row5 col11\" >-11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_eca0c_row6_col0\" class=\"data row6 col0\" >llama-7b_wizardlm_score=semdedup:cl=kmeans:md=mpnet:dist=cd:emb=text+embedding:nc=200_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row6_col1\" class=\"data row6 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row6_col2\" class=\"data row6 col2\" >34.2</td>\n",
       "      <td id=\"T_eca0c_row6_col3\" class=\"data row6 col3\" >32.6</td>\n",
       "      <td id=\"T_eca0c_row6_col4\" class=\"data row6 col4\" >4.2</td>\n",
       "      <td id=\"T_eca0c_row6_col5\" class=\"data row6 col5\" >12.2</td>\n",
       "      <td id=\"T_eca0c_row6_col6\" class=\"data row6 col6\" >30.6</td>\n",
       "      <td id=\"T_eca0c_row6_col7\" class=\"data row6 col7\" >30.0</td>\n",
       "      <td id=\"T_eca0c_row6_col8\" class=\"data row6 col8\" >15.2</td>\n",
       "      <td id=\"T_eca0c_row6_col9\" class=\"data row6 col9\" >53.1</td>\n",
       "      <td id=\"T_eca0c_row6_col10\" class=\"data row6 col10\" >26.5</td>\n",
       "      <td id=\"T_eca0c_row6_col11\" class=\"data row6 col11\" >-14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_eca0c_row7_col0\" class=\"data row7 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:theta=0.3:k=lin:kmd=mpnet:q=prob:qmd=llama7b+lima_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row7_col1\" class=\"data row7 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row7_col2\" class=\"data row7 col2\" >38.0</td>\n",
       "      <td id=\"T_eca0c_row7_col3\" class=\"data row7 col3\" >34.3</td>\n",
       "      <td id=\"T_eca0c_row7_col4\" class=\"data row7 col4\" >4.8</td>\n",
       "      <td id=\"T_eca0c_row7_col5\" class=\"data row7 col5\" >11.8</td>\n",
       "      <td id=\"T_eca0c_row7_col6\" class=\"data row7 col6\" >31.5</td>\n",
       "      <td id=\"T_eca0c_row7_col7\" class=\"data row7 col7\" >29.1</td>\n",
       "      <td id=\"T_eca0c_row7_col8\" class=\"data row7 col8\" >11.0</td>\n",
       "      <td id=\"T_eca0c_row7_col9\" class=\"data row7 col9\" >51.5</td>\n",
       "      <td id=\"T_eca0c_row7_col10\" class=\"data row7 col10\" >26.5</td>\n",
       "      <td id=\"T_eca0c_row7_col11\" class=\"data row7 col11\" >-12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_eca0c_row8_col0\" class=\"data row8 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:k=vmf:gamma=1.0:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row8_col1\" class=\"data row8 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row8_col2\" class=\"data row8 col2\" >37.5</td>\n",
       "      <td id=\"T_eca0c_row8_col3\" class=\"data row8 col3\" >35.2</td>\n",
       "      <td id=\"T_eca0c_row8_col4\" class=\"data row8 col4\" >5.0</td>\n",
       "      <td id=\"T_eca0c_row8_col5\" class=\"data row8 col5\" >10.4</td>\n",
       "      <td id=\"T_eca0c_row8_col6\" class=\"data row8 col6\" >32.1</td>\n",
       "      <td id=\"T_eca0c_row8_col7\" class=\"data row8 col7\" >30.1</td>\n",
       "      <td id=\"T_eca0c_row8_col8\" class=\"data row8 col8\" >10.4</td>\n",
       "      <td id=\"T_eca0c_row8_col9\" class=\"data row8 col9\" >51.1</td>\n",
       "      <td id=\"T_eca0c_row8_col10\" class=\"data row8 col10\" >26.5</td>\n",
       "      <td id=\"T_eca0c_row8_col11\" class=\"data row8 col11\" >-11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_eca0c_row9_col0\" class=\"data row9 col0\" >llama-7b_wizardlm_score=dppmap:k=lin:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row9_col1\" class=\"data row9 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row9_col2\" class=\"data row9 col2\" >34.7</td>\n",
       "      <td id=\"T_eca0c_row9_col3\" class=\"data row9 col3\" >34.0</td>\n",
       "      <td id=\"T_eca0c_row9_col4\" class=\"data row9 col4\" >4.4</td>\n",
       "      <td id=\"T_eca0c_row9_col5\" class=\"data row9 col5\" >13.4</td>\n",
       "      <td id=\"T_eca0c_row9_col6\" class=\"data row9 col6\" >32.8</td>\n",
       "      <td id=\"T_eca0c_row9_col7\" class=\"data row9 col7\" >28.7</td>\n",
       "      <td id=\"T_eca0c_row9_col8\" class=\"data row9 col8\" >11.0</td>\n",
       "      <td id=\"T_eca0c_row9_col9\" class=\"data row9 col9\" >51.6</td>\n",
       "      <td id=\"T_eca0c_row9_col10\" class=\"data row9 col10\" >26.3</td>\n",
       "      <td id=\"T_eca0c_row9_col11\" class=\"data row9 col11\" >-14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_eca0c_row10_col0\" class=\"data row10 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:theta=0.3:k=lin:kmd=mpnet:q=ifd:qmd=llama7b+lima_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row10_col1\" class=\"data row10 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row10_col2\" class=\"data row10 col2\" >37.1</td>\n",
       "      <td id=\"T_eca0c_row10_col3\" class=\"data row10 col3\" >33.7</td>\n",
       "      <td id=\"T_eca0c_row10_col4\" class=\"data row10 col4\" >5.2</td>\n",
       "      <td id=\"T_eca0c_row10_col5\" class=\"data row10 col5\" >10.6</td>\n",
       "      <td id=\"T_eca0c_row10_col6\" class=\"data row10 col6\" >33.2</td>\n",
       "      <td id=\"T_eca0c_row10_col7\" class=\"data row10 col7\" >28.4</td>\n",
       "      <td id=\"T_eca0c_row10_col8\" class=\"data row10 col8\" >7.3</td>\n",
       "      <td id=\"T_eca0c_row10_col9\" class=\"data row10 col9\" >54.4</td>\n",
       "      <td id=\"T_eca0c_row10_col10\" class=\"data row10 col10\" >26.3</td>\n",
       "      <td id=\"T_eca0c_row10_col11\" class=\"data row10 col11\" >-13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_eca0c_row11_col0\" class=\"data row11 col0\" >llama-7b_wizardlm_score=ifd_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row11_col1\" class=\"data row11 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row11_col2\" class=\"data row11 col2\" >38.0</td>\n",
       "      <td id=\"T_eca0c_row11_col3\" class=\"data row11 col3\" >34.9</td>\n",
       "      <td id=\"T_eca0c_row11_col4\" class=\"data row11 col4\" >5.8</td>\n",
       "      <td id=\"T_eca0c_row11_col5\" class=\"data row11 col5\" >9.2</td>\n",
       "      <td id=\"T_eca0c_row11_col6\" class=\"data row11 col6\" >31.8</td>\n",
       "      <td id=\"T_eca0c_row11_col7\" class=\"data row11 col7\" >30.8</td>\n",
       "      <td id=\"T_eca0c_row11_col8\" class=\"data row11 col8\" >9.1</td>\n",
       "      <td id=\"T_eca0c_row11_col9\" class=\"data row11 col9\" >49.8</td>\n",
       "      <td id=\"T_eca0c_row11_col10\" class=\"data row11 col10\" >26.2</td>\n",
       "      <td id=\"T_eca0c_row11_col11\" class=\"data row11 col11\" >-12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_eca0c_row12_col0\" class=\"data row12 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:k=vmf:gamma=3.0:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row12_col1\" class=\"data row12 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row12_col2\" class=\"data row12 col2\" >37.1</td>\n",
       "      <td id=\"T_eca0c_row12_col3\" class=\"data row12 col3\" >34.2</td>\n",
       "      <td id=\"T_eca0c_row12_col4\" class=\"data row12 col4\" >4.4</td>\n",
       "      <td id=\"T_eca0c_row12_col5\" class=\"data row12 col5\" >12.8</td>\n",
       "      <td id=\"T_eca0c_row12_col6\" class=\"data row12 col6\" >30.6</td>\n",
       "      <td id=\"T_eca0c_row12_col7\" class=\"data row12 col7\" >29.4</td>\n",
       "      <td id=\"T_eca0c_row12_col8\" class=\"data row12 col8\" >7.9</td>\n",
       "      <td id=\"T_eca0c_row12_col9\" class=\"data row12 col9\" >52.9</td>\n",
       "      <td id=\"T_eca0c_row12_col10\" class=\"data row12 col10\" >26.2</td>\n",
       "      <td id=\"T_eca0c_row12_col11\" class=\"data row12 col11\" >-14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_eca0c_row13_col0\" class=\"data row13 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:k=vmf:gamma=0.3:kmd=mpnet_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row13_col1\" class=\"data row13 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row13_col2\" class=\"data row13 col2\" >37.3</td>\n",
       "      <td id=\"T_eca0c_row13_col3\" class=\"data row13 col3\" >34.9</td>\n",
       "      <td id=\"T_eca0c_row13_col4\" class=\"data row13 col4\" >4.4</td>\n",
       "      <td id=\"T_eca0c_row13_col5\" class=\"data row13 col5\" >11.2</td>\n",
       "      <td id=\"T_eca0c_row13_col6\" class=\"data row13 col6\" >30.6</td>\n",
       "      <td id=\"T_eca0c_row13_col7\" class=\"data row13 col7\" >29.9</td>\n",
       "      <td id=\"T_eca0c_row13_col8\" class=\"data row13 col8\" >6.7</td>\n",
       "      <td id=\"T_eca0c_row13_col9\" class=\"data row13 col9\" >52.4</td>\n",
       "      <td id=\"T_eca0c_row13_col10\" class=\"data row13 col10\" >25.9</td>\n",
       "      <td id=\"T_eca0c_row13_col11\" class=\"data row13 col11\" >-15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_eca0c_row14_col0\" class=\"data row14 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:theta=0.6:k=lin:kmd=mpnet:q=ifd:qmd=llama7b+lima_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row14_col1\" class=\"data row14 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row14_col2\" class=\"data row14 col2\" >33.7</td>\n",
       "      <td id=\"T_eca0c_row14_col3\" class=\"data row14 col3\" >31.9</td>\n",
       "      <td id=\"T_eca0c_row14_col4\" class=\"data row14 col4\" >4.8</td>\n",
       "      <td id=\"T_eca0c_row14_col5\" class=\"data row14 col5\" >11.2</td>\n",
       "      <td id=\"T_eca0c_row14_col6\" class=\"data row14 col6\" >31.4</td>\n",
       "      <td id=\"T_eca0c_row14_col7\" class=\"data row14 col7\" >29.2</td>\n",
       "      <td id=\"T_eca0c_row14_col8\" class=\"data row14 col8\" >9.1</td>\n",
       "      <td id=\"T_eca0c_row14_col9\" class=\"data row14 col9\" >53.2</td>\n",
       "      <td id=\"T_eca0c_row14_col10\" class=\"data row14 col10\" >25.6</td>\n",
       "      <td id=\"T_eca0c_row14_col11\" class=\"data row14 col11\" >-17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_eca0c_row15_col0\" class=\"data row15 col0\" >llama-7b_wizardlm_score=ifd:neg_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row15_col1\" class=\"data row15 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row15_col2\" class=\"data row15 col2\" >35.4</td>\n",
       "      <td id=\"T_eca0c_row15_col3\" class=\"data row15 col3\" >33.5</td>\n",
       "      <td id=\"T_eca0c_row15_col4\" class=\"data row15 col4\" >3.4</td>\n",
       "      <td id=\"T_eca0c_row15_col5\" class=\"data row15 col5\" >10.8</td>\n",
       "      <td id=\"T_eca0c_row15_col6\" class=\"data row15 col6\" >27.8</td>\n",
       "      <td id=\"T_eca0c_row15_col7\" class=\"data row15 col7\" >28.9</td>\n",
       "      <td id=\"T_eca0c_row15_col8\" class=\"data row15 col8\" >11.6</td>\n",
       "      <td id=\"T_eca0c_row15_col9\" class=\"data row15 col9\" >51.4</td>\n",
       "      <td id=\"T_eca0c_row15_col10\" class=\"data row15 col10\" >25.3</td>\n",
       "      <td id=\"T_eca0c_row15_col11\" class=\"data row15 col11\" >-19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_eca0c_row16_col0\" class=\"data row16 col0\" >llama-7b_wizardlm_score=semdedup:cl=kmeansfaisscd:md=llama7b:dist=cd:emb=text+embedding:nc=200_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row16_col1\" class=\"data row16 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row16_col2\" class=\"data row16 col2\" >36.0</td>\n",
       "      <td id=\"T_eca0c_row16_col3\" class=\"data row16 col3\" >34.6</td>\n",
       "      <td id=\"T_eca0c_row16_col4\" class=\"data row16 col4\" >4.8</td>\n",
       "      <td id=\"T_eca0c_row16_col5\" class=\"data row16 col5\" >15.0</td>\n",
       "      <td id=\"T_eca0c_row16_col6\" class=\"data row16 col6\" >31.2</td>\n",
       "      <td id=\"T_eca0c_row16_col7\" class=\"data row16 col7\" >28.5</td>\n",
       "      <td id=\"T_eca0c_row16_col8\" class=\"data row16 col8\" >12.8</td>\n",
       "      <td id=\"T_eca0c_row16_col9\" class=\"data row16 col9\" >nan</td>\n",
       "      <td id=\"T_eca0c_row16_col10\" class=\"data row16 col10\" >23.3</td>\n",
       "      <td id=\"T_eca0c_row16_col11\" class=\"data row16 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_eca0c_row17_col0\" class=\"data row17 col0\" >llama-7b_wizardlm_score=semdedup:cl=kmeansfaisscd:md=bge:dist=cd:emb=text+embedding:nc=200_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row17_col1\" class=\"data row17 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row17_col2\" class=\"data row17 col2\" >36.1</td>\n",
       "      <td id=\"T_eca0c_row17_col3\" class=\"data row17 col3\" >34.0</td>\n",
       "      <td id=\"T_eca0c_row17_col4\" class=\"data row17 col4\" >4.0</td>\n",
       "      <td id=\"T_eca0c_row17_col5\" class=\"data row17 col5\" >11.4</td>\n",
       "      <td id=\"T_eca0c_row17_col6\" class=\"data row17 col6\" >32.5</td>\n",
       "      <td id=\"T_eca0c_row17_col7\" class=\"data row17 col7\" >30.5</td>\n",
       "      <td id=\"T_eca0c_row17_col8\" class=\"data row17 col8\" >13.4</td>\n",
       "      <td id=\"T_eca0c_row17_col9\" class=\"data row17 col9\" >nan</td>\n",
       "      <td id=\"T_eca0c_row17_col10\" class=\"data row17 col10\" >23.1</td>\n",
       "      <td id=\"T_eca0c_row17_col11\" class=\"data row17 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_eca0c_row18_col0\" class=\"data row18 col0\" >llama-7b_wizardlm_score=log:prob:neg_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row18_col1\" class=\"data row18 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row18_col2\" class=\"data row18 col2\" >36.4</td>\n",
       "      <td id=\"T_eca0c_row18_col3\" class=\"data row18 col3\" >32.8</td>\n",
       "      <td id=\"T_eca0c_row18_col4\" class=\"data row18 col4\" >5.0</td>\n",
       "      <td id=\"T_eca0c_row18_col5\" class=\"data row18 col5\" >14.2</td>\n",
       "      <td id=\"T_eca0c_row18_col6\" class=\"data row18 col6\" >27.4</td>\n",
       "      <td id=\"T_eca0c_row18_col7\" class=\"data row18 col7\" >30.3</td>\n",
       "      <td id=\"T_eca0c_row18_col8\" class=\"data row18 col8\" >11.6</td>\n",
       "      <td id=\"T_eca0c_row18_col9\" class=\"data row18 col9\" >nan</td>\n",
       "      <td id=\"T_eca0c_row18_col10\" class=\"data row18 col10\" >22.5</td>\n",
       "      <td id=\"T_eca0c_row18_col11\" class=\"data row18 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_eca0c_row19_col0\" class=\"data row19 col0\" >llama-7b_wizardlm_score=semdedup:cl=kmeansfaisscd:md=llama7b:dist=cd:emb=grad+rp+loraB:nc=200_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row19_col1\" class=\"data row19 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row19_col2\" class=\"data row19 col2\" >33.5</td>\n",
       "      <td id=\"T_eca0c_row19_col3\" class=\"data row19 col3\" >32.8</td>\n",
       "      <td id=\"T_eca0c_row19_col4\" class=\"data row19 col4\" >4.2</td>\n",
       "      <td id=\"T_eca0c_row19_col5\" class=\"data row19 col5\" >11.8</td>\n",
       "      <td id=\"T_eca0c_row19_col6\" class=\"data row19 col6\" >33.2</td>\n",
       "      <td id=\"T_eca0c_row19_col7\" class=\"data row19 col7\" >29.3</td>\n",
       "      <td id=\"T_eca0c_row19_col8\" class=\"data row19 col8\" >12.8</td>\n",
       "      <td id=\"T_eca0c_row19_col9\" class=\"data row19 col9\" >nan</td>\n",
       "      <td id=\"T_eca0c_row19_col10\" class=\"data row19 col10\" >22.5</td>\n",
       "      <td id=\"T_eca0c_row19_col11\" class=\"data row19 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_eca0c_row20_col0\" class=\"data row20 col0\" >llama-7b_wizardlm_score=el2n:agg=mean_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row20_col1\" class=\"data row20 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row20_col2\" class=\"data row20 col2\" >37.7</td>\n",
       "      <td id=\"T_eca0c_row20_col3\" class=\"data row20 col3\" >32.4</td>\n",
       "      <td id=\"T_eca0c_row20_col4\" class=\"data row20 col4\" >6.0</td>\n",
       "      <td id=\"T_eca0c_row20_col5\" class=\"data row20 col5\" >11.4</td>\n",
       "      <td id=\"T_eca0c_row20_col6\" class=\"data row20 col6\" >29.4</td>\n",
       "      <td id=\"T_eca0c_row20_col7\" class=\"data row20 col7\" >29.7</td>\n",
       "      <td id=\"T_eca0c_row20_col8\" class=\"data row20 col8\" >9.1</td>\n",
       "      <td id=\"T_eca0c_row20_col9\" class=\"data row20 col9\" >nan</td>\n",
       "      <td id=\"T_eca0c_row20_col10\" class=\"data row20 col10\" >22.2</td>\n",
       "      <td id=\"T_eca0c_row20_col11\" class=\"data row20 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_eca0c_row21_col0\" class=\"data row21 col0\" >llama-7b_wizardlm_score=grad:loraB:l2n_pace=prune:size=100000:ep=2</td>\n",
       "      <td id=\"T_eca0c_row21_col1\" class=\"data row21 col1\" >100000</td>\n",
       "      <td id=\"T_eca0c_row21_col2\" class=\"data row21 col2\" >36.8</td>\n",
       "      <td id=\"T_eca0c_row21_col3\" class=\"data row21 col3\" >31.5</td>\n",
       "      <td id=\"T_eca0c_row21_col4\" class=\"data row21 col4\" >4.8</td>\n",
       "      <td id=\"T_eca0c_row21_col5\" class=\"data row21 col5\" >13.2</td>\n",
       "      <td id=\"T_eca0c_row21_col6\" class=\"data row21 col6\" >23.6</td>\n",
       "      <td id=\"T_eca0c_row21_col7\" class=\"data row21 col7\" >28.8</td>\n",
       "      <td id=\"T_eca0c_row21_col8\" class=\"data row21 col8\" >10.4</td>\n",
       "      <td id=\"T_eca0c_row21_col9\" class=\"data row21 col9\" >nan</td>\n",
       "      <td id=\"T_eca0c_row21_col10\" class=\"data row21 col10\" >21.3</td>\n",
       "      <td id=\"T_eca0c_row21_col11\" class=\"data row21 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_eca0c_row22_col0\" class=\"data row22 col0\" >llama-7b</td>\n",
       "      <td id=\"T_eca0c_row22_col1\" class=\"data row22 col1\" >None</td>\n",
       "      <td id=\"T_eca0c_row22_col2\" class=\"data row22 col2\" >32.8</td>\n",
       "      <td id=\"T_eca0c_row22_col3\" class=\"data row22 col3\" >33.5</td>\n",
       "      <td id=\"T_eca0c_row22_col4\" class=\"data row22 col4\" >5.4</td>\n",
       "      <td id=\"T_eca0c_row22_col5\" class=\"data row22 col5\" >10.8</td>\n",
       "      <td id=\"T_eca0c_row22_col6\" class=\"data row22 col6\" >32.1</td>\n",
       "      <td id=\"T_eca0c_row22_col7\" class=\"data row22 col7\" >27.4</td>\n",
       "      <td id=\"T_eca0c_row22_col8\" class=\"data row22 col8\" >1.8</td>\n",
       "      <td id=\"T_eca0c_row22_col9\" class=\"data row22 col9\" >nan</td>\n",
       "      <td id=\"T_eca0c_row22_col10\" class=\"data row22 col10\" >20.6</td>\n",
       "      <td id=\"T_eca0c_row22_col11\" class=\"data row22 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eca0c_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_eca0c_row23_col0\" class=\"data row23 col0\" >llama-7b+lima</td>\n",
       "      <td id=\"T_eca0c_row23_col1\" class=\"data row23 col1\" >None</td>\n",
       "      <td id=\"T_eca0c_row23_col2\" class=\"data row23 col2\" >31.5</td>\n",
       "      <td id=\"T_eca0c_row23_col3\" class=\"data row23 col3\" >nan</td>\n",
       "      <td id=\"T_eca0c_row23_col4\" class=\"data row23 col4\" >5.6</td>\n",
       "      <td id=\"T_eca0c_row23_col5\" class=\"data row23 col5\" >9.8</td>\n",
       "      <td id=\"T_eca0c_row23_col6\" class=\"data row23 col6\" >31.1</td>\n",
       "      <td id=\"T_eca0c_row23_col7\" class=\"data row23 col7\" >nan</td>\n",
       "      <td id=\"T_eca0c_row23_col8\" class=\"data row23 col8\" >6.7</td>\n",
       "      <td id=\"T_eca0c_row23_col9\" class=\"data row23 col9\" >nan</td>\n",
       "      <td id=\"T_eca0c_row23_col10\" class=\"data row23 col10\" >17.0</td>\n",
       "      <td id=\"T_eca0c_row23_col11\" class=\"data row23 col11\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc8e958700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f81f9_row0_col0, #T_f81f9_row0_col1, #T_f81f9_row1_col0, #T_f81f9_row1_col1, #T_f81f9_row2_col0, #T_f81f9_row2_col1, #T_f81f9_row3_col0, #T_f81f9_row3_col1, #T_f81f9_row4_col0, #T_f81f9_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f81f9_row0_col2, #T_f81f9_row0_col4, #T_f81f9_row0_col7, #T_f81f9_row0_col8, #T_f81f9_row0_col10, #T_f81f9_row1_col5, #T_f81f9_row1_col9, #T_f81f9_row1_col11, #T_f81f9_row2_col3, #T_f81f9_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row0_col3, #T_f81f9_row0_col5, #T_f81f9_row0_col6, #T_f81f9_row0_col9, #T_f81f9_row0_col11, #T_f81f9_row2_col4, #T_f81f9_row3_col7, #T_f81f9_row3_col8, #T_f81f9_row4_col2, #T_f81f9_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f81f9_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f81f9_row1_col10, #T_f81f9_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ba162b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f81f9_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f81f9_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f81f9_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f81f9_row3_col9, #T_f81f9_row3_col11, #T_f81f9_row4_col3, #T_f81f9_row4_col7, #T_f81f9_row4_col9, #T_f81f9_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f81f9_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f81f9_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f81f9_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f81f9_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f81f9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f81f9_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_f81f9_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_f81f9_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_f81f9_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_f81f9_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_f81f9_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_f81f9_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_f81f9_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_f81f9_level0_col8\" class=\"col_heading level0 col8\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_f81f9_level0_col9\" class=\"col_heading level0 col9\" >AlpacaFarm(v.Davinci-003)/WR</th>\n",
       "      <th id=\"T_f81f9_level0_col10\" class=\"col_heading level0 col10\" >Average</th>\n",
       "      <th id=\"T_f81f9_level0_col11\" class=\"col_heading level0 col11\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f81f9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f81f9_row0_col0\" class=\"data row0 col0\" >mistral-7b+lima</td>\n",
       "      <td id=\"T_f81f9_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_f81f9_row0_col2\" class=\"data row0 col2\" >59.6</td>\n",
       "      <td id=\"T_f81f9_row0_col3\" class=\"data row0 col3\" >30.1</td>\n",
       "      <td id=\"T_f81f9_row0_col4\" class=\"data row0 col4\" >8.8</td>\n",
       "      <td id=\"T_f81f9_row0_col5\" class=\"data row0 col5\" >5.0</td>\n",
       "      <td id=\"T_f81f9_row0_col6\" class=\"data row0 col6\" >21.9</td>\n",
       "      <td id=\"T_f81f9_row0_col7\" class=\"data row0 col7\" >41.9</td>\n",
       "      <td id=\"T_f81f9_row0_col8\" class=\"data row0 col8\" >33.5</td>\n",
       "      <td id=\"T_f81f9_row0_col9\" class=\"data row0 col9\" >41.1</td>\n",
       "      <td id=\"T_f81f9_row0_col10\" class=\"data row0 col10\" >30.3</td>\n",
       "      <td id=\"T_f81f9_row0_col11\" class=\"data row0 col11\" >-11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f81f9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f81f9_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm_score=dppmapbd:nc=200:k=vmf:gamma=0.00006:kmd=mpnet_pace=prune:size=200000:ep=2</td>\n",
       "      <td id=\"T_f81f9_row1_col1\" class=\"data row1 col1\" >200000</td>\n",
       "      <td id=\"T_f81f9_row1_col2\" class=\"data row1 col2\" >36.9</td>\n",
       "      <td id=\"T_f81f9_row1_col3\" class=\"data row1 col3\" >34.7</td>\n",
       "      <td id=\"T_f81f9_row1_col4\" class=\"data row1 col4\" >4.2</td>\n",
       "      <td id=\"T_f81f9_row1_col5\" class=\"data row1 col5\" >14.4</td>\n",
       "      <td id=\"T_f81f9_row1_col6\" class=\"data row1 col6\" >31.3</td>\n",
       "      <td id=\"T_f81f9_row1_col7\" class=\"data row1 col7\" >31.0</td>\n",
       "      <td id=\"T_f81f9_row1_col8\" class=\"data row1 col8\" >14.6</td>\n",
       "      <td id=\"T_f81f9_row1_col9\" class=\"data row1 col9\" >53.7</td>\n",
       "      <td id=\"T_f81f9_row1_col10\" class=\"data row1 col10\" >27.6</td>\n",
       "      <td id=\"T_f81f9_row1_col11\" class=\"data row1 col11\" >-8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f81f9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f81f9_row2_col0\" class=\"data row2 col0\" >score=random:s=(\\d)_pace=prune:size=200000_avg (N=1)</td>\n",
       "      <td id=\"T_f81f9_row2_col1\" class=\"data row2 col1\" >200000</td>\n",
       "      <td id=\"T_f81f9_row2_col2\" class=\"data row2 col2\" >37.8</td>\n",
       "      <td id=\"T_f81f9_row2_col3\" class=\"data row2 col3\" >35.0</td>\n",
       "      <td id=\"T_f81f9_row2_col4\" class=\"data row2 col4\" >4.0</td>\n",
       "      <td id=\"T_f81f9_row2_col5\" class=\"data row2 col5\" >13.8</td>\n",
       "      <td id=\"T_f81f9_row2_col6\" class=\"data row2 col6\" >31.9</td>\n",
       "      <td id=\"T_f81f9_row2_col7\" class=\"data row2 col7\" >29.1</td>\n",
       "      <td id=\"T_f81f9_row2_col8\" class=\"data row2 col8\" >15.9</td>\n",
       "      <td id=\"T_f81f9_row2_col9\" class=\"data row2 col9\" >53.4</td>\n",
       "      <td id=\"T_f81f9_row2_col10\" class=\"data row2 col10\" >27.6</td>\n",
       "      <td id=\"T_f81f9_row2_col11\" class=\"data row2 col11\" >-8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f81f9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f81f9_row3_col0\" class=\"data row3 col0\" >llama-7b</td>\n",
       "      <td id=\"T_f81f9_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_f81f9_row3_col2\" class=\"data row3 col2\" >32.8</td>\n",
       "      <td id=\"T_f81f9_row3_col3\" class=\"data row3 col3\" >33.5</td>\n",
       "      <td id=\"T_f81f9_row3_col4\" class=\"data row3 col4\" >5.4</td>\n",
       "      <td id=\"T_f81f9_row3_col5\" class=\"data row3 col5\" >10.8</td>\n",
       "      <td id=\"T_f81f9_row3_col6\" class=\"data row3 col6\" >32.1</td>\n",
       "      <td id=\"T_f81f9_row3_col7\" class=\"data row3 col7\" >27.4</td>\n",
       "      <td id=\"T_f81f9_row3_col8\" class=\"data row3 col8\" >1.8</td>\n",
       "      <td id=\"T_f81f9_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
       "      <td id=\"T_f81f9_row3_col10\" class=\"data row3 col10\" >20.6</td>\n",
       "      <td id=\"T_f81f9_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f81f9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f81f9_row4_col0\" class=\"data row4 col0\" >llama-7b+lima</td>\n",
       "      <td id=\"T_f81f9_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_f81f9_row4_col2\" class=\"data row4 col2\" >31.5</td>\n",
       "      <td id=\"T_f81f9_row4_col3\" class=\"data row4 col3\" >nan</td>\n",
       "      <td id=\"T_f81f9_row4_col4\" class=\"data row4 col4\" >5.6</td>\n",
       "      <td id=\"T_f81f9_row4_col5\" class=\"data row4 col5\" >9.8</td>\n",
       "      <td id=\"T_f81f9_row4_col6\" class=\"data row4 col6\" >31.1</td>\n",
       "      <td id=\"T_f81f9_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
       "      <td id=\"T_f81f9_row4_col8\" class=\"data row4 col8\" >6.7</td>\n",
       "      <td id=\"T_f81f9_row4_col9\" class=\"data row4 col9\" >nan</td>\n",
       "      <td id=\"T_f81f9_row4_col10\" class=\"data row4 col10\" >17.0</td>\n",
       "      <td id=\"T_f81f9_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffca1456830>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/pd.py:123: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  col_contains_substr = df[col].str.contains(substr, regex=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8db5b_row0_col0, #T_8db5b_row0_col1, #T_8db5b_row1_col0, #T_8db5b_row1_col1, #T_8db5b_row2_col0, #T_8db5b_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8db5b_row0_col2, #T_8db5b_row0_col4, #T_8db5b_row0_col7, #T_8db5b_row0_col8, #T_8db5b_row0_col10, #T_8db5b_row1_col3, #T_8db5b_row1_col5, #T_8db5b_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8db5b_row0_col3, #T_8db5b_row0_col5, #T_8db5b_row0_col6, #T_8db5b_row0_col9, #T_8db5b_row0_col11, #T_8db5b_row1_col4, #T_8db5b_row1_col7, #T_8db5b_row1_col8, #T_8db5b_row1_col9, #T_8db5b_row1_col11, #T_8db5b_row2_col2, #T_8db5b_row2_col9, #T_8db5b_row2_col10, #T_8db5b_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8db5b_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8db5b_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8db5b_row2_col3, #T_8db5b_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8db5b_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8db5b_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8db5b_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8db5b_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8db5b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8db5b_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_8db5b_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_8db5b_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_8db5b_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_8db5b_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_8db5b_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_8db5b_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_8db5b_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_8db5b_level0_col8\" class=\"col_heading level0 col8\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_8db5b_level0_col9\" class=\"col_heading level0 col9\" >AlpacaFarm(v.Davinci-003)/WR</th>\n",
       "      <th id=\"T_8db5b_level0_col10\" class=\"col_heading level0 col10\" >Average</th>\n",
       "      <th id=\"T_8db5b_level0_col11\" class=\"col_heading level0 col11\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8db5b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8db5b_row0_col0\" class=\"data row0 col0\" >mistral-7b+lima</td>\n",
       "      <td id=\"T_8db5b_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_8db5b_row0_col2\" class=\"data row0 col2\" >59.6</td>\n",
       "      <td id=\"T_8db5b_row0_col3\" class=\"data row0 col3\" >30.1</td>\n",
       "      <td id=\"T_8db5b_row0_col4\" class=\"data row0 col4\" >8.8</td>\n",
       "      <td id=\"T_8db5b_row0_col5\" class=\"data row0 col5\" >5.0</td>\n",
       "      <td id=\"T_8db5b_row0_col6\" class=\"data row0 col6\" >21.9</td>\n",
       "      <td id=\"T_8db5b_row0_col7\" class=\"data row0 col7\" >41.9</td>\n",
       "      <td id=\"T_8db5b_row0_col8\" class=\"data row0 col8\" >33.5</td>\n",
       "      <td id=\"T_8db5b_row0_col9\" class=\"data row0 col9\" >41.1</td>\n",
       "      <td id=\"T_8db5b_row0_col10\" class=\"data row0 col10\" >30.3</td>\n",
       "      <td id=\"T_8db5b_row0_col11\" class=\"data row0 col11\" >-11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8db5b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8db5b_row1_col0\" class=\"data row1 col0\" >llama-7b</td>\n",
       "      <td id=\"T_8db5b_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_8db5b_row1_col2\" class=\"data row1 col2\" >32.8</td>\n",
       "      <td id=\"T_8db5b_row1_col3\" class=\"data row1 col3\" >33.5</td>\n",
       "      <td id=\"T_8db5b_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_8db5b_row1_col5\" class=\"data row1 col5\" >10.8</td>\n",
       "      <td id=\"T_8db5b_row1_col6\" class=\"data row1 col6\" >32.1</td>\n",
       "      <td id=\"T_8db5b_row1_col7\" class=\"data row1 col7\" >27.4</td>\n",
       "      <td id=\"T_8db5b_row1_col8\" class=\"data row1 col8\" >1.8</td>\n",
       "      <td id=\"T_8db5b_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_8db5b_row1_col10\" class=\"data row1 col10\" >20.6</td>\n",
       "      <td id=\"T_8db5b_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8db5b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8db5b_row2_col0\" class=\"data row2 col0\" >llama-7b+lima</td>\n",
       "      <td id=\"T_8db5b_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_8db5b_row2_col2\" class=\"data row2 col2\" >31.5</td>\n",
       "      <td id=\"T_8db5b_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_8db5b_row2_col4\" class=\"data row2 col4\" >5.6</td>\n",
       "      <td id=\"T_8db5b_row2_col5\" class=\"data row2 col5\" >9.8</td>\n",
       "      <td id=\"T_8db5b_row2_col6\" class=\"data row2 col6\" >31.1</td>\n",
       "      <td id=\"T_8db5b_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_8db5b_row2_col8\" class=\"data row2 col8\" >6.7</td>\n",
       "      <td id=\"T_8db5b_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_8db5b_row2_col10\" class=\"data row2 col10\" >17.0</td>\n",
       "      <td id=\"T_8db5b_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffca1457f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_average_col_contains_substr\n",
    "\n",
    "Ns = np.unique([x for x in df['total_train_samples'].to_numpy() if x]).tolist()\n",
    "for N in Ns+[None]:\n",
    "    dfc = df.copy()\n",
    "    dfc = dfc[dfc['total_train_samples'].apply(lambda x: x == N if x else True)]\n",
    "#     dfc = pd_average_col_contains_substr(dfc, 'run_name', 'random_', substitute=True)\n",
    "    dfc = pd_average_col_contains_substr(dfc, 'run_name', 'score=random:s=(\\d)_pace=prune:size=150000:ep=3', substitute=True)\n",
    "    dfc = pd_average_col_contains_substr(dfc, 'run_name', 'score=random:s=(\\d)_pace=prune:size=150000:ep=1', substitute=True)\n",
    "    dfc = pd_average_col_contains_substr(dfc, 'run_name', 'score=random:s=(\\d)_pace=prune:size=100000', substitute=True)\n",
    "    dfc = pd_average_col_contains_substr(dfc, 'run_name', 'score=random:s=(\\d)_pace=prune:size=200000', substitute=True)\n",
    "    dfc = pd_average_col_contains_substr(dfc, 'run_name', 'score=random:s=(\\d)_pace=prune:size=400000', substitute=True)\n",
    "    #     dfc = dfc.sort_values(['ranking'], ascending=False)\n",
    "    dfc = dfc.sort_values(['Average'], ascending=False)\n",
    "    dfc = dfc.drop(columns=['model_args.model_name_or_path', 'data_args.subsample_mixture', 'data_args.max_train_samples'])\n",
    "    dfc = dfc.reset_index(drop=True)\n",
    "    if len(dfc):\n",
    "        display(dfc\n",
    "                .style\n",
    "                .set_properties(**{'text-align': 'left'})\n",
    "                .background_gradient(cmap ='coolwarm')\n",
    "                .format(precision=1))\n",
    "\n",
    "# random\n",
    "# log_prob_decr\n",
    "# el2n agg_mean incr\n",
    "# logit_margin_decr\n",
    "# grad l2n incr\n",
    "# kmeansl2_emb=text+embedding_nc=3000_incr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d63fd168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cot': 0.37664033529374275,\n",
       "  'dolly': 0.0874640765523398,\n",
       "  'flan_v2': 0.39740799933549775,\n",
       "  'oasst1': 0.1384875888184196},\n",
       " {'cot': 0.23064419241874784,\n",
       "  'dolly': 0.04693354147889885,\n",
       "  'flan_v2': 0.72121745986295,\n",
       "  'oasst1': 0.0012048062394032465},\n",
       " {'cot': 0.11244721555034376,\n",
       "  'dolly': 0.21997027355988638,\n",
       "  'flan_v2': 0.5826671754210359,\n",
       "  'oasst1': 0.08491533546873392},\n",
       " {'cot': 0.27704626812045546,\n",
       "  'dolly': 0.5712282144637615,\n",
       "  'flan_v2': 0.024940119654536592,\n",
       "  'oasst1': 0.12678539776124645},\n",
       " {'cot': 0.0024519793352964607,\n",
       "  'dolly': 0.13274603201304974,\n",
       "  'flan_v2': 0.012268378167304219,\n",
       "  'oasst1': 0.8525336104843496},\n",
       " {'cot': 0.08065633865016615,\n",
       "  'dolly': 0.41886215168938545,\n",
       "  'flan_v2': 0.21723932820070485,\n",
       "  'oasst1': 0.2832421814597436},\n",
       " {'cot': 0.13878643021160036,\n",
       "  'dolly': 0.05686171157146557,\n",
       "  'flan_v2': 0.6701353469446995,\n",
       "  'oasst1': 0.13421651127223455},\n",
       " {'cot': 0.2461125374866837,\n",
       "  'dolly': 0.09774240280444893,\n",
       "  'flan_v2': 0.13974091986040005,\n",
       "  'oasst1': 0.5164041398484672},\n",
       " {'cot': 0.4069781049152398,\n",
       "  'dolly': 0.06318759506033228,\n",
       "  'flan_v2': 0.09504719644992135,\n",
       "  'oasst1': 0.4347871035745066},\n",
       " {'cot': 0.22379693013848484,\n",
       "  'dolly': 0.30565901275011814,\n",
       "  'flan_v2': 0.15457716965000887,\n",
       "  'oasst1': 0.31596688746138824}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def runif_in_simplex(n):\n",
    "    ''' Return uniformly random vector in the n-simplex '''\n",
    "\n",
    "    k = np.random.exponential(scale=1.0, size=n)\n",
    "    return k / sum(k)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "np.random.seed(4)\n",
    "\n",
    "L = []\n",
    "dataset_name = ['cot', 'dolly', 'flan_v2', 'oasst1']\n",
    "xs = np.arange(4)\n",
    "for _ in range(10):\n",
    "    ys = runif_in_simplex(4)\n",
    "    d = {k: v for k, v in zip(dataset_name, ys)}\n",
    "    L.append(d)\n",
    "    ax.plot(xs, ys)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d8a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dirs = []\n",
    "run_dirs = [\n",
    "#     'pythia-1.4b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "#     'pythia-2.8b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "#     'pythia-6.9b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "    ''\n",
    "]\n",
    "for run_dir in run_dirs:\n",
    "    save_dirs += [(os.path.basename(x), x) \n",
    "                  for x in glob.glob(os.path.join('../results/ft2', run_dir, 'checkpoint-*'))]\n",
    "    break\n",
    "\n",
    "    \n",
    "df = get_eval_results(save_dirs, chat_fmt=None, ft_args_fields=ft_args_fields)\n",
    "# df['model'] = ''\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666b028",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from llm.evaluate import get_eval_results_cross_time\n",
    "\n",
    "\n",
    "\n",
    "eval_name_list = [\n",
    "    'MMLU/0-shot',\n",
    "    'MMLU/5-shot',\n",
    "    'GSM/Direct',\n",
    "    'GSM/CoT',\n",
    "    'BBH/Direct',\n",
    "    'BBH/CoT',\n",
    "    'TydiQA/CB',\n",
    "    'TydiQA/GP',\n",
    "    'Codex-Eval/Pass@1',\n",
    "]\n",
    "eval_name_list += [eval_name_list.copy()]\n",
    "\n",
    "\n",
    "N = len(eval_name_list)\n",
    "w = 5\n",
    "fig, axs = plt.subplots(2, 5, figsize=(5*w, 2*w), sharey='row', sharex='col')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dataset = 'tuluv1hm'; exp_dir = '../results/oi4_tulu_v1_human_mix'\n",
    "dataset = 'flan_v2'; exp_dir = '../results/oi4_perf_cross_time'; keep_size = '30k'\n",
    "dataset = 'flan_v2'; exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'; keep_size = '30k'\n",
    "dataset = 'flan2022_1m'; exp_dir = '../results/oi4_flan2022_1m'; keep_size = '100k'\n",
    "filter_fn = lambda x: '100k' in x\n",
    "\n",
    "\n",
    "runs = [x for x in os.listdir(exp_dir) if os.path.isdir(os.path.join(exp_dir, x))]\n",
    "runs = list(filter(filter_fn, runs))\n",
    "def get_name_and_path(x):\n",
    "    name = x.split(':')[-1]\n",
    "    return name, x\n",
    "runs = list(map(get_name_and_path, runs))\n",
    "\n",
    "# runs = [\n",
    "#     ('random', f'llama-7b_{dataset}:{keep_size}_random'),\n",
    "# #     ('dppmap_k=Kcos', f'llama-7b_{dataset}:{keep_size}_dppmap_k=Kcos'),\n",
    "# #     ('dppmap_k=Kcos1np', f'llama-7b_{dataset}:{keep_size}_dppmap_k=Kcos1np'),\n",
    "# #     ('dppmap_k=Kcosp', f'llama-7b_{dataset}:{keep_size}_dppmap_k=Kcosp'),\n",
    "#     ('kmeansl2_nc=3000_incr', f'llama-7b_{dataset}:{keep_size}_kmeansl2_nc=3000_incr'),\n",
    "#     ('kmeansl2_nc=3000_decr', f'llama-7b_{dataset}:{keep_size}_kmeansl2_nc=3000_decr'),\n",
    "# #     ('kmeansl2_nc=1000_incr', f'llama-7b_{dataset}:{keep_size}_kmeansl2_nc=1000_incr'),\n",
    "# #     ('kmeansl2_nc=1000_decr', f'llama-7b_{dataset}:{keep_size}_kmeansl2_nc=1000_decr'),\n",
    "# #     ('kmeansl2_nc=300_incr', f'llama-7b_{dataset}:{keep_size}_kmeansl2_nc=300_incr'),\n",
    "# #     ('kmeansl2_nc=300_decr', f'llama-7b_{dataset}:{keep_size}_kmeansl2_nc=300_decr'),\n",
    "#     ('prob_incr', f'llama-7b_{dataset}:{keep_size}_prob_incr'),\n",
    "#     ('prob_decr', f'llama-7b_{dataset}:{keep_size}_prob_decr'),\n",
    "#     ('el2n_incr', f'llama-7b_{dataset}:{keep_size}_el2n_incr'),\n",
    "#     ('el2n_decr', f'llama-7b_{dataset}:{keep_size}_el2n_decr'),\n",
    "# ]\n",
    "\n",
    "\n",
    "runs = [(x, os.path.join(exp_dir, y)) for x, y in runs]\n",
    "\n",
    "\n",
    "for run_name, save_dir in runs:\n",
    "    df = get_eval_results_cross_time(save_dir, chat_fmt=True)\n",
    "\n",
    "    for axi, eval_name in enumerate(eval_name_list):\n",
    "        ax = axs.flatten()[axi]\n",
    "\n",
    "        xs = df['steps'].to_numpy()\n",
    "        ys = df[eval_name].to_numpy()\n",
    "        if ys.ndim == 2:\n",
    "            ys = ys.mean(-1)\n",
    "\n",
    "        ax.plot(xs, ys, label=run_name)\n",
    "\n",
    "\n",
    "        ax.grid()\n",
    "        ax.set_ylim(0, 55)\n",
    "        ax.set_xlabel('Steps', fontsize=15)\n",
    "        title = eval_name if isinstance(eval_name, str) else 'Avg'\n",
    "        ax.set_title(title, fontsize=20)\n",
    "        \n",
    "        ax.legend()\n",
    "        \n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb043d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ylabel = 'llama-7b:600k'\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "ylabel = 'llama-7b_flan_v2:30k'\n",
    "exp_dir = '../results/oi4_perf_cross_time'\n",
    "# exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'\n",
    "save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in glob.glob(os.path.join(exp_dir, 'llama-7b_flan_v2:30k_kmeansl2_nc=3000_decr', 'checkpoint-*'))]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in glob.glob(os.path.join(exp_dir, 'llama-7b_flan_v2:30k_kmeansl2_nc=3000_incr', 'checkpoint-*'))]\n",
    "save_dirs += [(os.path.basename(x), x) for x in glob.glob(os.path.join(exp_dir, 'llama-7b_flan_v2:30k_kmeansl2_nc=3000_incr', 'checkpoint-*'))]\n",
    "df = get_eval_results(save_dirs, chat_fmt=None, ft_args_fields=ft_args_fields)\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "# add base model performance\n",
    "dfc.loc[dfc['model_args.model_name_or_path']=='huggyllama/llama-7b', 'model_args.model_name_or_path'] = 'checkpoint-0'\n",
    "# get steps \n",
    "dfc.insert(0, 'steps', dfc['model_args.model_name_or_path'].apply(lambda x: int(x.split('-')[-1])))\n",
    "dfc = dfc.sort_values('steps')\n",
    "\n",
    "\n",
    "y_labels_list = [\n",
    "    ['MMLU/0-shot',\n",
    "     'MMLU/0-shot_chatfmt',\n",
    "     'MMLU/5-shot',\n",
    "     'MMLU/5-shot_chatfmt',\n",
    "    ],\n",
    "    ['GSM/Direct',\n",
    "     'GSM/Direct_chatfmt',\n",
    "     'GSM/CoT', \n",
    "     'GSM/CoT_chatfmt', \n",
    "    ],\n",
    "    ['BBH/Direct',\n",
    "     'BBH/Direct_chatfmt',\n",
    "     'BBH/CoT',\n",
    "     'BBH/CoT_chatfmt',\n",
    "    ],\n",
    "    ['TydiQA/CB',\n",
    "     'TydiQA/CB_chatfmt',\n",
    "     'TydiQA/GP',\n",
    "     'TydiQA/GP_chatfmt',\n",
    "    ],\n",
    "    ['Codex-Eval/Pass@1',\n",
    "     'Codex-Eval/Pass@1_chatfmt'],\n",
    "    ['MMLU/0-shot',\n",
    "     'GSM/CoT',\n",
    "     'BBH/CoT',],\n",
    "]\n",
    "\n",
    "N = len(y_labels_list)\n",
    "\n",
    "fig, axs = plt.subplots(1,N,figsize=(5*N,5))\n",
    "\n",
    "axs[0].set_ylabel(ylabel, fontsize=20)\n",
    "\n",
    "for axi, y_labels in enumerate(y_labels_list):\n",
    "    ax = axs[axi]\n",
    "\n",
    "    x = dfc['steps']\n",
    "    y_list = []\n",
    "    for y_label in y_labels:\n",
    "        if y_label not in dfc.columns: continue\n",
    "        y = dfc[y_label].to_numpy()\n",
    "        y_list.append(y)\n",
    "        ax.plot(x, y, label=y_label)\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    ax.set_ylim(0, 55)\n",
    "    \n",
    "    \n",
    "# for y_label in ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1']:\n",
    "    \n",
    "#     for chat_fmt in ['', 'chatfmt']:\n",
    "#         col = '_'.join([y_label, chat_fmt]) if chat_fmt else y_label\n",
    "#         y = dfc[col].to_numpy()\n",
    "#         print(f'{col}\\t{y.mean():.2f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_labels = [\n",
    "    'Answer:\\n<|assistant|>\\nThe answer is:',\n",
    "    'Answer:\\n<|assistant|>\\n',\n",
    "    '<|assistant|>\\nAnswer:',\n",
    "    '<|assistant|>\\nThe answer is:',\n",
    "]\n",
    "x_labels = [f'v{i+1}:\\n{x}' for i,x in enumerate(x_labels)]\n",
    "\n",
    "dfc = df.copy()\n",
    "dfc = df.filter(regex='_v|run')\n",
    "\n",
    "runs = dfc['run_name'].to_list()[::-1]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for axi, task in enumerate(['MMLU/0-shot', 'MMLU/5-shot']):\n",
    "\n",
    "    ax = axs[axi]\n",
    "    cols = [f'{task}_v{x}' for x in [1, 2, 3, 4]]\n",
    "    x = np.arange(len(x_labels))\n",
    "\n",
    "    width = .25\n",
    "    multiplier = 0\n",
    "\n",
    "    for run in runs:\n",
    "        offset = width*multiplier\n",
    "        y = dfc[dfc['run_name']==run][cols].to_numpy().squeeze()\n",
    "        rects = ax.bar(x+offset, y, width, label=run)\n",
    "        ax.bar_label(rects, padding=3, fmt='{:.2f}')\n",
    "        multiplier += 1\n",
    "\n",
    "    ax.set_title(task)\n",
    "    ax.set_xticks(x+width)\n",
    "    ax.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_ylim(0, 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa6ba4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "total_data_points = 200000 # 10000, 50000, 100000, 200000\n",
    "subsample_mixture_list = []\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': 0.48785105, 'flan_v2': 0.48785105, 'dolly': 0.00732313, 'oasst1': 0.01697478}.items())\n",
    "] # humanmix mixture.\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.360595703125, \"dolly\": 0.0021991729736328125, \"flan_v2\": 0.63037109375, \"oasst1\": 0.0016956329345703125}.items())\n",
    "] # pythia-1.4b humanmix_uniform:200k_doremiv1.json\n",
    "\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.2254638671875, \"dolly\": 0.01409149169921875, \"flan_v2\": 0.1739501953125, \"oasst1\": 0.59423828125}.items())\n",
    "] # pythia-1.4b humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.08563232421875, \"dolly\": 0.54296875, \"flan_v2\": 0.347900390625, \"oasst1\": 0.0103302001953125}.items())\n",
    "] # llama-7b_humanmix_uniform:200k_doremiv2.json\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.0316162109375, \"dolly\": 0.204833984375, \"flan_v2\": 0.40966796875, \"oasst1\": 0.40966796875}.items()\n",
    "        )] # llama-7b_humanmix_uniform:600k_doremiv2.json\n",
    "subsample_mixture_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "6323+40966+81933+81933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_dir = 'results/ft1'\n",
    "\n",
    "# d = {\n",
    "#     'bbh_s=0': 'bbh_s=3',\n",
    "#     'gsm': 'gsm_s=8_cot',\n",
    "#     'mmlu': 'mmlu_s=0',\n",
    "#     'tydiqa_cb': 'tydiqa_s=1_cb',\n",
    "#     'tydiqa_gp': 'tydiqa_s=1_gp',\n",
    "# }\n",
    "\n",
    "# d.update({k+'_chatfmt': v+'_chatfmt' for k,v in d.items()})\n",
    "\n",
    "# for subdir in os.listdir(exp_dir):    \n",
    "#     for task_name_src, task_name_tgt in d.items():\n",
    "#         path_src = os.path.join(exp_dir, subdir, 'eval', task_name_src)\n",
    "#         path_tgt = os.path.join(exp_dir, subdir, 'eval', task_name_tgt)\n",
    "#         if os.path.isdir(path_src):\n",
    "# #             os.rename(path_src, path_tgt)\n",
    "#             print(path_src)\n",
    "#             print(path_tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27138820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfc = df.copy()\n",
    "dfc.insert(0, 'total_train_samples',  dfc['data_args.subsample_mixture'].apply(\n",
    "    lambda d: sum(list(d.values())) if d else 200000))\n",
    "# dfc[dfc['total_train_samples'].apply(\n",
    "#     lambda x: total_train_samples-500<x<total_train_samples+500)]\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad6edc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dfc = df.copy()\n",
    "dfc.columns = [x.split('_')[0] for x in dfc.columns]\n",
    "def get_dataset(x):\n",
    "    x = x.split('+')\n",
    "    if len(x) == 1:\n",
    "        return ''\n",
    "    else:\n",
    "        d = x[1]\n",
    "        d = d.replace('_', '')\n",
    "        return d\n",
    "dfc['Dataset'] = dfc['Model'].apply(get_dataset)\n",
    "order_list = ['',\n",
    " 'superni', 'cot', 'flanv2', 'dolly', 'oasst1',\n",
    " 'selfinstruct', 'unnaturalinstructions', 'stanfordalpaca', 'codealpaca', 'gpt4alpaca',\n",
    " 'baize', 'sharegpt', 'humanmix', 'h+gptmix']\n",
    "dfc['order'] = dfc['Dataset'].map({v: i for i, v in enumerate(order_list)})\n",
    "dfc = dfc.sort_values('order')\n",
    "dfc = dfc.drop(columns=['order', 'Dataset'])\n",
    "dfc = dfc.reset_index(drop=True)\n",
    "\n",
    "display(dfc[dfc['Model'].apply(lambda x: 'llama-7b' in x and ':' not in x)]\n",
    "        .style\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=1))\n",
    "\n",
    "\n",
    "display(dfc[dfc['Model'].apply(\n",
    "            lambda x: 'llama-7b' in x and (\n",
    "                ':' in x or any(c in x for c in ['dolly', 'oasst1', 'cot', 'flan'])\n",
    "                or 'humanmix' in x\n",
    "            )\n",
    "        )]\n",
    "        .style\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=1))\n",
    "\n",
    "display(dfc[dfc['Model'].apply(lambda x: 'llama2-7b' in x or 'llama-7b'==x)]\n",
    "        .style\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba1a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0588857",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"dataset\": \"flan_v2\", \"id\": \"flan_v2_2\", \"messages\": [{\"role\": \"user\", \"content\": \"Tratatul de la Lisabona nu face inutil referire, pentru prima dat n istoria Uniunii Europene, la drepturile persoanelor care aparin acestor minoriti i la valorile proprii acestora.\\n\\nWhich language is this?\\n\"}, {\"role\": \"assistant\", \"content\": \"Romanian\"}]}\n",
    "{\"dataset\": \"flan_v2\", \"id\": \"flan_v2_2\", \"messages\": [{\"role\": \"user\", \"content\": \"Tratatul de la Lisabona nu face inutil referire, pentru prima dat\\u0103 \\u00een istoria Uniunii Europene, la drepturile persoanelor care apar\\u0163in acestor minorit\\u0103\\u0163i \\u015fi la valorile proprii acestora.\\n\\nWhich language is this?\\n\"}, {\"role\": \"assistant\", \"content\": \"Romanian\"}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7702c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.1f}'.format):\n",
    "    display(df[['Model']+[x for x in df.columns if 'chatfmt' in x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82eac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.3f}'.format):\n",
    "    display(df[[x for x in df.columns if 'chatfmt' not in x]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "models = []\n",
    "models += ['t5-small', 't5-base', 't5-large', 't5-3b', 't5-11b']\n",
    "models += ['huggyllama/llama-7b']\n",
    "save_dirs = [f'../results/baselines/{x}/eval/gsm/' for x in models]\n",
    "\n",
    "data = []\n",
    "for model, save_dir in zip(models, save_dirs):\n",
    "    logfile_path = glob.glob(os.path.join(save_dir, '*.out'))[0]\n",
    "    out = get_run_statistics(logfile_path)\n",
    "    with open(os.path.join(save_dir, 'metrics.json'), 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    data.append((model, out['cpu_time']/60/60, out['avg_mem'], out['max_mem'], metrics['exact_match']))\n",
    "    \n",
    "\n",
    "import pandas as pd\n",
    "columns = ['name', 'cpu_time (hr)', 'avg_mem', 'max_mem', 'exact_match']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
