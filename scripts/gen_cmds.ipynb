{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da1794b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('ppc64le', 'dcs')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "import re\n",
    "from llm.submit import (\n",
    "    multiline_to_singleline,\n",
    "    submit_job_ccc,\n",
    "    submit_job_aimos,\n",
    "    submit_job,\n",
    "    get_run_statistics)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import json\n",
    "import platform\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import datetime\n",
    "import itertools\n",
    "import socket\n",
    "import glob\n",
    "\n",
    "import base64\n",
    "string_to_alphanumeric = lambda s: base64.urlsafe_b64encode(s.encode('utf-8')).decode('utf-8')\n",
    "alphanumeric_to_string = lambda a: base64.urlsafe_b64decode(a).decode('utf-8')\n",
    "\n",
    "arch = platform.uname().processor\n",
    "hostname = socket.gethostname()\n",
    "cluster = 'ccc' if hostname.startswith('ccc') else ('dcs' if hostname.startswith('dcs') else 'npl')\n",
    "arch, cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8323654",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850a84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_name = 'ft'\n",
    "# test_run = 1\n",
    "# test_run = bool(test_run)\n",
    "\n",
    "# queue = 'x86_12h' # 'x86_12h'\n",
    "# num_cpus = 20\n",
    "# num_gpus = 1\n",
    "# cpu_mem = 32\n",
    "# require = 'a100_80gb'\n",
    "\n",
    "# # model_name_or_path = 'mosaicml/mpt-7b'; max_seq_length = 2048\n",
    "# # model_name_or_path = 'gpt2'; max_seq_length = 1024\n",
    "# # model_name_or_path = 'gpt2-Large'; max_seq_length = 1024\n",
    "# # model_name_or_path = 'gpt2-xl'; max_seq_length = 1024\n",
    "# model_name_or_path = 'huggyllama/llama-7b'; max_seq_length = 2048\n",
    "\n",
    "\n",
    "# train_file = 'data/processed/oasst1/oasst1_data.jsonl'; train_file_short = 'oasst1'\n",
    "# train_file = 'data/processed/flanv2_cot_oasst1_dolly.jsonl'; train_file_short = 'human_mix'\n",
    "# # train_file = 'data/processed/flanv2_cot_oasst1_dolly_shuffled.jsonl'; train_file_short = 'human_mix_shuffled'\n",
    "\n",
    "# output_dir = f\"results/{model_name_or_path.replace('/', ':')}_{train_file_short}\"\n",
    "# if test_run:\n",
    "#     output_dir = 'jpt_' + output_dir\n",
    "\n",
    "# use_deepspeed = False\n",
    "# # deepspeed_config_file = 'ds_configs/stage3_no_offloading_accelerate_setauto.conf'\n",
    "# # deepspeed_config_file = 'ds_configs/stage3_offloading_accelerate.conf'\n",
    "# deepspeed_config_file = 'ds_configs/stage3_offloading_accelerate_setauto.conf'\n",
    "\n",
    "# use_lora = True\n",
    "# lora_rank = 4\n",
    "# lora_alpha = lora_rank\n",
    "# lora_dropout = 0.05\n",
    "\n",
    "# batch_size_per_gpu = 1\n",
    "# total_batch_size = 128\n",
    "# mixed_precision = 'bf16' # 'bf16', 'fp16'\n",
    "# checkpointing_steps = None # every n steps, where n='1' or every 'epoch'\n",
    "\n",
    "# gradient_acc_steps = int(total_batch_size/num_gpus/batch_size_per_gpu)\n",
    "\n",
    "# print(f\"Training {model_name_or_path} \"\n",
    "#       f\"using {num_gpus} GPUs, \"\n",
    "#       f\"{batch_size_per_gpu} batch size per GPU, \"\n",
    "#       f\"{gradient_acc_steps} gradient accumulation steps.\")\n",
    "\n",
    "# # do use fast tokenizer since mpt-7b does not have a fast tokenizer counter-part\n",
    "# #     --use_slow_tokenizer \\\n",
    "# # do not use flash attention, since having problem installing flash-attn with cuda 12.1\n",
    "# #     --use_flash_attn \\\n",
    "\n",
    "# cmd = f\"\"\"\n",
    "# {'!cd .. && ' if test_run else ''}accelerate launch \\\n",
    "#     --mixed_precision {mixed_precision} \\\n",
    "#     --num_machines 1 \\\n",
    "#     --num_processes {num_gpus} \\\n",
    "#     {'--use_deepspeed' if use_deepspeed else ''}\n",
    "#     {'--deepspeed_config_file '+deepspeed_config_file if use_deepspeed else ''}\n",
    "#     open_instruct/finetune.py \\\n",
    "#     --model_name_or_path {model_name_or_path} \\\n",
    "#     --tokenizer_name {model_name_or_path} \\\n",
    "#     --train_file {train_file} \\\n",
    "#     --max_seq_length {max_seq_length} \\\n",
    "#     {'--use_lora' if use_lora else ''}\n",
    "#     --lora_rank {lora_rank} \\\n",
    "#     --lora_alpha {lora_alpha} \\\n",
    "#     --lora_dropout {lora_dropout} \\\n",
    "#     --preprocessing_num_workers 16 \\\n",
    "#     --per_device_train_batch_size {batch_size_per_gpu} \\\n",
    "#     --gradient_accumulation_steps {gradient_acc_steps} \\\n",
    "#     --learning_rate 2e-5 \\\n",
    "#     --lr_scheduler_type linear \\\n",
    "#     --warmup_ratio 0.03 \\\n",
    "#     --weight_decay 0. \\\n",
    "#     --num_train_epochs 2 \\\n",
    "#     --output_dir {output_dir} \\\n",
    "#     --with_tracking \\\n",
    "#     --report_to tensorboard \\\n",
    "#     {'--checkpointing_steps '+str(checkpointing_steps) if checkpointing_steps else ''}\n",
    "#     --logging_steps 1\n",
    "# \"\"\"\n",
    "\n",
    "# # things to test to see its effects on (1) eval perf (2) runtime.\n",
    "# #\n",
    "# # - int8\n",
    "# # - mixed_precision bf16 or no\n",
    "# # - with/without LoRA\n",
    "# # - LoRA's rank/alpha (alpha typically set to 2*rank)\n",
    "# # - batch size\n",
    "# # - micro-batch size (largest without running out of memory)\n",
    "\n",
    "\n",
    "# cmd = multiline_to_singleline(cmd)\n",
    "# if test_run:\n",
    "#     print()\n",
    "#     print(cmd)\n",
    "\n",
    "# shell_scripts = shell_scripts_template.format(\n",
    "#     cmd=cmd,\n",
    "#     log_dir=os.getcwd(),\n",
    "#     save_dir=output_dir)\n",
    "# out = submit_job_ccc(\n",
    "#     shell_scripts, \n",
    "#     job_name=job_name, \n",
    "#     queue=queue,\n",
    "#     num_cpus=num_cpus,\n",
    "#     cpu_mem=cpu_mem,\n",
    "#     require=require,\n",
    "#     num_gpus=num_gpus,\n",
    "#     test_run=test_run,\n",
    "# )\n",
    "# if not test_run:\n",
    "#     print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c8b",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune_trainer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c2170c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "echo \"Running on $SLURM_JOB_NODELIST\"\n",
      "echo \"======\"\n",
      "\n",
      "master_addr=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\" | head -n 1)\n",
      "master_port=10002\n",
      "RDZV_ENDPOINT=$master_addr:$master_port\n",
      "\n",
      "source ~/.profile\n",
      "conda activate open-instruct\n",
      "cd /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/\n",
      "\n",
      "set -e\n",
      "set -x\n",
      "echo \"======\"\n",
      "srun {cmd}\n",
      "\n",
      "[ ! -f \"{log_dir}/$SLURM_JOB_ID*.out\" ] && mv {log_dir}/$SLURM_JOB_ID*.out {save_dir}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shell_scripts_template_slurm = \"\"\"\n",
    "echo \"Running on $SLURM_JOB_NODELIST\"\n",
    "echo \"======\"\n",
    "\n",
    "master_addr=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\" | head -n 1)\n",
    "master_port=10002\n",
    "RDZV_ENDPOINT=$master_addr:$master_port\n",
    "\n",
    "source ~/.profile\n",
    "conda activate open-instruct\n",
    "cd /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/\n",
    "\n",
    "set -e\n",
    "set -x\n",
    "echo \"======\"\n",
    "srun {cmd}\n",
    "\n",
    "[ ! -f \"{log_dir}/$SLURM_JOB_ID*.out\" ] && mv {log_dir}/$SLURM_JOB_ID*.out {save_dir}\n",
    "\"\"\"\n",
    "\n",
    "shell_scripts_template_lsf = \"\"\"\n",
    "echo \"Running on $LSB_DJOB_HOSTFILE\"\n",
    "echo \"======\"\n",
    "\n",
    "master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\")\n",
    "master_port=10002\n",
    "RDZV_ENDPOINT=$master_addr:$master_port\n",
    "\n",
    "source ~/.profile\n",
    "conda activate open-instruct\n",
    "cd /dccstor/mit_fm/wpq/github/mitibm2023/external/open-instruct/\n",
    "\n",
    "set -e\n",
    "set -x\n",
    "echo \"======\"\n",
    "srun {cmd}\n",
    "\n",
    "[ ! -f \"{log_dir}/$LSB_JOBID*.out\" ] && mv {log_dir}/$LSB_JOBID*.out {save_dir}\n",
    "\"\"\"\n",
    "\n",
    "shell_scripts_template = shell_scripts_template_slurm \\\n",
    "    if arch == 'ppc64le' else shell_scripts_template_lsf\n",
    "\n",
    "print(shell_scripts_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d611cbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133s/it, 58.5hrs\n"
     ]
    }
   ],
   "source": [
    "t = '00:33:12'\n",
    "n = 15\n",
    "# total = 1515; nnodes = 1\n",
    "# total = 2083; nnodes = 1\n",
    "total = 1587; nnodes = 1\n",
    "# total = 1041; nnodes = 1\n",
    "# total = 4228; nnodes = 1\n",
    "# total = 4512; nnodes = 4\n",
    "# total = 4296; nnodes = 1\n",
    "# total = 2254; nnodes = 2\n",
    "# total = 1128; nnodes = 4\n",
    "# total = 1074; nnodes = 4\n",
    "# total = 1252; nnodes = 4\n",
    "\n",
    "l = [int(x) for x in t.split(':')]\n",
    "t = l[0]*60*60+l[1]*60+l[2]\n",
    "# t = t/60/60 # in hr\n",
    "\n",
    "print(f'{t/n/nnodes:.0f}s/it, {t/n*total/60/60:.1f}hrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a669464",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "p = '../data/processed/'\n",
    "for x in os.listdir(p):\n",
    "    y = os.path.join(p, x)\n",
    "    if os.path.isdir(y):\n",
    "        d = os.path.join(y, os.listdir(y)[0])\n",
    "    else:\n",
    "        continue\n",
    "    d = d[3:]\n",
    "    if 'shuffled' in d:\n",
    "        continue\n",
    "#     print(f\"train_file = '{d}'; abbr_train_file = '{x}'\")\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51bf7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# how to sample mixture sample size?\n",
    "# \n",
    "# approaches: \n",
    "# (1) want sufficient coverage for #datapoints/dataset, #datasets used, total sample size.\n",
    "#  Use 5k as a unit of data, sample different #unit/dataset, and vary total units of data.\n",
    "# (2) specify a total sample size and a mixture weight. this answers the question, given a \n",
    "#  fixed compute budget, what is the optimal mixture. this seems to be a simpler approach.\n",
    "#\n",
    "# experiments\n",
    "# (1) first use samples from a single dataset for tuning. \n",
    "# (2)\n",
    "# \n",
    "\n",
    "\n",
    "datasets = ['baize', 'code_alpaca', 'cot', 'dolly', 'flan_v2', 'gpt4_alpaca', 'oasst1', 'self_instruct', 'sharegpt', 'stanford_alpaca', 'super_ni', 'unnatural_instructions']\n",
    "total_data_points = 200000\n",
    "\n",
    "subsample_mixture_list = []\n",
    "subsample_mixture_list += [\n",
    "    {k: 100000} for k in datasets if k != 'flan_v2'\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    {k: int(total_data_points/4) for k in ['cot', 'flan_v2', 'dolly', 'oasst1']}\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': 0.48785105, 'flan_v2': 0.48785105, 'dolly': 0.00732313, 'oasst1': 0.01697478}.items())\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    {k: int(total_data_points/len(datasets)) for k in datasets} \n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': .07678, 'flan_v2': .9137, 'dolly': .004471, 'oasst1': .009072}.items())\n",
    "]\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': 0.1127, 'flan_v2': 0.8726, 'dolly': 0.01395, 'oasst1': 0.001391}.items())\n",
    "]\n",
    "subsample_mixture_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d47226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove extra files (e.g., optimizer.bin) for non-latest checkpoints:\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-50/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-850/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-900/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-950/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1000/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1050/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1850/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1900/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-1950/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2000/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2050/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2850/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2900/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-2950/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-3000/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-3050/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-3100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-3150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-3200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:400k_humanmix/checkpoint-3250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-50/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-850/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-900/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-950/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1000/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1050/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1850/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1900/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-1950/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2000/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2050/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2850/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2900/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-2950/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3000/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3050/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3850/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3900/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-3950/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4000/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4050/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4100/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4150/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4200/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4250/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4300/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4350/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4400/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4450/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4500/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4550/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4600/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4650/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4700/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4750/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4800/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4850/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4900/optimizer.bin\n",
      "../results/oi3/llama-7b_all:600k_humanmix/checkpoint-4950/optimizer.bin\n"
     ]
    }
   ],
   "source": [
    "## Clean up checkpoints `optimizer.bin` to save disk space. \n",
    "# (e.g., 7b model, ~8*7=56GB for storing gradient/momentum in `optimizer.bin`)\n",
    "\n",
    "import glob, os\n",
    "\n",
    "def cleanup_checkpoints(save_dir, test_run=False):\n",
    "\n",
    "    checkpoints = glob.glob(os.path.join(save_dir, 'checkpoint-*'))\n",
    "    checkpoints = sorted(checkpoints, key=lambda x: int(x.split('-')[-1]))\n",
    "    checkpoints = checkpoints[:-1]\n",
    "    \n",
    "    if not checkpoints: return\n",
    "\n",
    "    for ckpt_path in checkpoints:\n",
    "        optimizer_bin_path = os.path.join(ckpt_path, 'optimizer.bin')\n",
    "        if os.path.isfile(optimizer_bin_path):\n",
    "            print(optimizer_bin_path)\n",
    "            if not test_run:\n",
    "                os.remove(optimizer_bin_path)\n",
    "        \n",
    "        \n",
    "test_run = False\n",
    "exp_dirs = ['../results/ft2',\n",
    "            '../results/oi3']\n",
    "\n",
    "print('Remove extra files (e.g., optimizer.bin) for non-latest checkpoints:')\n",
    "\n",
    "for exp_dir in exp_dirs:\n",
    "    for run_name in os.listdir(exp_dir):\n",
    "        save_dir = os.path.join(exp_dir, run_name)\n",
    "        if os.path.islink(save_dir): continue\n",
    "        cleanup_checkpoints(save_dir, test_run=test_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51c8d72e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results/baselines/huggyllama/llama-7b using 6 GPUs, 2 batch size per GPU, 2 gradient accumulation steps, Effective batch size 120\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi4\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 512,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 2\n",
      "}\n",
      "[{'args': 'sbatch --job-name=oi4 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J_1:2.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmpa93765f8', 'job_id': 944342}, {'args': 'sbatch --job-name=oi4 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J_2:2.out --time=6:00:00 --dependency=afterany:944342 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp_u5k18ep', 'job_id': 944343}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi4\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 512,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 2\n",
      "}\n",
      "[{'args': 'sbatch --job-name=oi4 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J_1:2.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp0sq9p8rd', 'job_id': 944344}, {'args': 'sbatch --job-name=oi4 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J_2:2.out --time=6:00:00 --dependency=afterany:944344 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmpi0ua0bdb', 'job_id': 944345}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi4\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 512,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 2\n",
      "}\n",
      "[{'args': 'sbatch --job-name=oi4 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J_1:2.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp8sy475q4', 'job_id': 944346}, {'args': 'sbatch --job-name=oi4 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=512GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J_2:2.out --time=6:00:00 --dependency=afterany:944346 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2tcm1_xk', 'job_id': 944347}]\n"
     ]
    }
   ],
   "source": [
    "def compute_mixture_num_samples(mixture, max_train_samples):\n",
    "    s = sum(mixture.values())\n",
    "    mixture = {k: int(max_train_samples*v/s) for k, v in mixture.items()}\n",
    "    return mixture\n",
    "\n",
    "num_cpus = 144 if arch == 'ppc64le' else 32\n",
    "cpu_mem =  512 if arch == 'ppc64le' else 64\n",
    "\n",
    "max_train_samples = 200000 # 10000, 50000, 100000, 200000\n",
    "# max_train_samples = 600000\n",
    "\n",
    "\n",
    "subsample_mixture_list = []\n",
    "# subsample_mixture_list += [\n",
    "#     {k: max_train_samples} for k in datasets\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     {k: int(max_train_samples/4) for k in ['cot', 'flan_v2', 'dolly', 'oasst1']}\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     ('humanmix', dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {'cot': 0.48785105, 'flan_v2': 0.48785105, 'dolly': 0.00732313, 'oasst1': 0.01697478}.items()))\n",
    "# ] # humanmix mixture.\n",
    "# subsample_mixture_list += [\n",
    "#     {k: int(max_train_samples/len(datasets)) for k in datasets} \n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {'cot': .07678, 'flan_v2': .9137, 'dolly': .004471, 'oasst1': .009072}.items())\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {'cot': 0.1127, 'flan_v2': 0.8726, 'dolly': 0.01395, 'oasst1': 0.001391}.items())\n",
    "# ]\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {'cot':  0.13568177819252014, 'flan_v2': 0.3957784175872803, \n",
    "#      'dolly': 0.05964866653084755, 'oasst1': 0.4088916480541229}.items())\n",
    "# ] # gpt2-medium_humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {\"cot\": 0.360595703125, \"dolly\": 0.0021991729736328125, \"flan_v2\": 0.63037109375, \"oasst1\": 0.0016956329345703125}.items())\n",
    "# ] # pythia-1.4b humanmix_uniform:200k_doremiv1.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {\"cot\": 0.2254638671875, \"dolly\": 0.01409149169921875, \"flan_v2\": 0.1739501953125, \"oasst1\": 0.59423828125}.items())\n",
    "# ] # pythia-1.4b humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {\"cot\": 0.08563232421875, \"dolly\": 0.54296875, \"flan_v2\": 0.347900390625, \"oasst1\": 0.0103302001953125}.items())\n",
    "# ] # llama-7b_humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "# subsample_mixture_list += [\n",
    "#     dict((k, int(v*max_train_samples)) for k, v in\n",
    "#     {\"cot\": 0.0316162109375, \"dolly\": 0.204833984375, \"flan_v2\": 0.40966796875, \"oasst1\": 0.40966796875}.items()\n",
    "#         )] # llama-7b_humanmix_uniform:600k_doremiv2.json\n",
    "\n",
    "subsample_mixture_normalized_list = []\n",
    "# subsample_mixture_normalized_list += [('uniform:1200k_doremiv2', # llama-7b_humanmix_uniform:1200k_doremiv2.json\n",
    "#                                        {\"cot\": 0.11419677734375, \"dolly\": 0.1024169921875, \"flan_v2\": 0.204833984375, \"oasst1\": 0.204833984375})]\n",
    "## 10 for trying out datamodels\n",
    "# mixes = [{'cot': 0.37664033529374275,\n",
    "#   'dolly': 0.0874640765523398,\n",
    "#   'flan_v2': 0.39740799933549775,\n",
    "#   'oasst1': 0.1384875888184196},\n",
    "#  {'cot': 0.23064419241874784,\n",
    "#   'dolly': 0.04693354147889885,\n",
    "#   'flan_v2': 0.72121745986295,\n",
    "#   'oasst1': 0.0012048062394032465},\n",
    "#  {'cot': 0.11244721555034376,\n",
    "#   'dolly': 0.21997027355988638,\n",
    "#   'flan_v2': 0.5826671754210359,\n",
    "#   'oasst1': 0.08491533546873392},\n",
    "#  {'cot': 0.27704626812045546,\n",
    "#   'dolly': 0.5712282144637615,\n",
    "#   'flan_v2': 0.024940119654536592,\n",
    "#   'oasst1': 0.12678539776124645},\n",
    "#  {'cot': 0.0024519793352964607,\n",
    "#   'dolly': 0.13274603201304974,\n",
    "#   'flan_v2': 0.012268378167304219,\n",
    "#   'oasst1': 0.8525336104843496},\n",
    "#  {'cot': 0.08065633865016615,\n",
    "#   'dolly': 0.41886215168938545,\n",
    "#   'flan_v2': 0.21723932820070485,\n",
    "#   'oasst1': 0.2832421814597436},\n",
    "#  {'cot': 0.13878643021160036,\n",
    "#   'dolly': 0.05686171157146557,\n",
    "#   'flan_v2': 0.6701353469446995,\n",
    "#   'oasst1': 0.13421651127223455},\n",
    "#  {'cot': 0.2461125374866837,\n",
    "#   'dolly': 0.09774240280444893,\n",
    "#   'flan_v2': 0.13974091986040005,\n",
    "#   'oasst1': 0.5164041398484672},\n",
    "#  {'cot': 0.4069781049152398,\n",
    "#   'dolly': 0.06318759506033228,\n",
    "#   'flan_v2': 0.09504719644992135,\n",
    "#   'oasst1': 0.4347871035745066},\n",
    "#  {'cot': 0.22379693013848484,\n",
    "#   'dolly': 0.30565901275011814,\n",
    "#   'flan_v2': 0.15457716965000887,\n",
    "#   'oasst1': 0.31596688746138824}]\n",
    "\n",
    "# mixes = [\n",
    "#     {'cot': 0.46638974, 'dolly': 0.01456044, 'flan_v2': 0.50886009, 'oasst1': 0.01018973},\n",
    "#     {'cot': 0.39744481, 'dolly': 0.00472114, 'flan_v2': 0.59104177, 'oasst1': 0.00679229},\n",
    "# ]\n",
    "\n",
    "# subsample_mixture_normalized_list += [('', d) for d in mixes]\n",
    "# subsample_mixture_normalized_list += [('humanmix', # humanmix\n",
    "#                                        {'cot': 0.48785105, 'dolly': 0.00732313, 'flan_v2': 0.48785105, 'oasst1': 0.01697478})]\n",
    "subsample_mixture_normalized_list = [(x[0],  compute_mixture_num_samples(x[1], max_train_samples)) \n",
    "                                     for x in subsample_mixture_normalized_list]\n",
    "subsample_mixture_list += subsample_mixture_normalized_list\n",
    "\n",
    "subsample_inds_file_list = []\n",
    "\n",
    "\n",
    "train_file = 'data/processed/all.jsonl'; abbr_train_file = 'all'\n",
    "# train_file = 'data/processed/flanv2_cot_oasst1_dolly.jsonl'; abbr_train_file = 'humanmix'\n",
    "# train_file = 'data/processed/dolly_oasst1.jsonl'; abbr_train_file = 'dolly:oasst1'\n",
    "# train_file = 'data/processed/cot_flanv2.jsonl'; abbr_train_file = 'cot:flanv2'\n",
    "\n",
    "# train_file = 'data/processed/super_ni/super_ni_data.jsonl'; abbr_train_file = 'super_ni'\n",
    "# train_file = 'data/processed/cot/cot_data.jsonl'; abbr_train_file = 'cot'\n",
    "# train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2'\n",
    "# train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly'\n",
    "# train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1'\n",
    "\n",
    "# train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca'\n",
    "# train_file = 'data/processed/baize/baize_data.jsonl'; abbr_train_file = 'baize'\n",
    "# train_file = 'data/processed/self_instruct/self_instruct_data.jsonl'; abbr_train_file = 'self_instruct'\n",
    "\n",
    "# train_file = 'data/processed/code_alpaca/code_alpaca_data.jsonl'; abbr_train_file = 'code_alpaca'\n",
    "# train_file = 'data/processed/unnatural_instructions/unnatural_instructions_data.jsonl'; abbr_train_file = 'unnatural_instructions'\n",
    "# train_file = 'data/processed/sharegpt/sharegpt_data.jsonl'; abbr_train_file = 'sharegpt'\n",
    "# train_file = 'data/processed/gpt4_alpaca/gpt4_alpaca_data.jsonl'; abbr_train_file = 'gpt4_alpaca'\n",
    "\n",
    "def subsample_inds_file_abbr_fn(x):\n",
    "    if x.endswith('K_cos.pkl'):\n",
    "        return 'Kcos'\n",
    "    if x.endswith('prob_incr.pkl'):\n",
    "        return 'probincr'\n",
    "    if x.endswith('prob_decr.pkl'):\n",
    "        return 'probdecr'\n",
    "    if x.endswith('K_cos_oneminusprob.pkl'):\n",
    "        return 'Kcos1np'\n",
    "    return ''\n",
    "\n",
    "max_train_samples_list = [200000]\n",
    "num_train_epochs_list = [1]\n",
    "\n",
    "\n",
    "\n",
    "# ft1: reproduce open-instruct table with llama7b\n",
    "job_name = 'ft1'\n",
    "\n",
    "# ft2: test mixture weights\n",
    "# vary mixture weights\n",
    "job_name = 'ft2'\n",
    "\n",
    "# oi3: instruction tuning performance w.r.t. steps.\n",
    "job_name = 'oi3'\n",
    "\n",
    "# oi4: dpp idea.\n",
    "job_name = 'oi4'\n",
    "train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2'\n",
    "subsample_mixture_list = [('',None)]\n",
    "max_train_samples_list = [int(pct*100000) for pct in [.1, .3, .5]]; num_train_epochs_list = [2] # note pct=1 just need to run once, it means using all data.\n",
    "\n",
    "script_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/'\n",
    "subsample_inds_file_list = [\n",
    "    # baseline, random (first N) subset \n",
    "    '',\n",
    "    # dpp's data subset\n",
    "    os.path.join(script_dir, 'note_explore_dpp_llama-7b_flan_v2_subsets_K_cos.pkl'),\n",
    "    # select subset based on llama's prob (increasing/decreasing)\n",
    "    os.path.join(script_dir, 'note_explore_dpp_llama-7b_flan_v2_subsets_prob_incr.pkl'),\n",
    "    os.path.join(script_dir, 'note_explore_dpp_llama-7b_flan_v2_subsets_prob_decr.pkl'),\n",
    "]\n",
    "subsample_inds_file_list = [\n",
    "    os.path.join(script_dir, 'note_explore_dpp_llama-7b_flan_v2_subsets_K_cos_oneminusprob.pkl'),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "debug_mode = test_run\n",
    "\n",
    "nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12 # llama-7b on 100k. data\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12 # llama-7b on 400k data\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 30 # llama-7b on 600k data\n",
    "\n",
    "# nodes = 1; num_gpus = 1; gpu_type = 'v100'; job_duration = 6  # gpt2\n",
    "# nodes = 2; num_gpus = 6; gpu_type = 'v100'; job_duration = 6  # pythia-1.4b\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6  # pythia-2.8b|6.9b\n",
    "\n",
    "\n",
    "overwrite_output_dir = True if test_run else False # always continue from ckpt if run from cluster.\n",
    "save_strategy = 'steps'\n",
    "# save_steps = 50; save_total_limit = 200 # keep track of ckpts during training.\n",
    "save_steps = 100; save_total_limit = 1\n",
    "\n",
    "\n",
    "hf_models_dir = 'results/baselines/'\n",
    "# model_name_or_path = 'results/baselines/gpt2-medium'; abbr_model_name = 'gpt2m'; max_seq_length = 1024\n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = 'results/baselines/NousResearch/Llama-2-7b-hf'; abbr_model_name = 'llama2-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = 'mosaicml/mpt-7b'; abbr_model_name = 'mpt-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-1.4b'; abbr_model_name = 'pythia-1.4b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-2.8b'; abbr_model_name = 'pythia-2.8b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-6.9b'; abbr_model_name = 'pythia-6.9b'; max_seq_length = 2048\n",
    "\n",
    "\n",
    "\n",
    "per_device_train_batch_size = 2\n",
    "total_batch_size = 128 # 128\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "\n",
    "optimizer = 'adamw_hf' # 'adafactor'\n",
    "\n",
    "deepspeed = ''; fsdp = False if num_gpus == 1 else \"full_shard auto_wrap\"  # full_shard, shard_grad_op\n",
    "if 'gpt2' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPT2Block'\n",
    "elif 'llama' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'LlamaDecoderLayer'\n",
    "elif 'mpt' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MPTBlock'\n",
    "elif 'pythia' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPTNeoXLayer'        \n",
    "else: raise ValueError('Not sure how to set `fsdp_transformer_layer_cls_to_wrap`')\n",
    "    \n",
    "# deepspeed = './ds_configs/ds_zero3_cpu_offload.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/ds_zero3.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/stage3_no_offloading.conf'; fsdp = False # error with loading... something wrong with the config.\n",
    "\n",
    "# fsdp = False; deepspeed = False\n",
    "\n",
    "if fsdp and deepspeed:\n",
    "    raise ValueError('either fsdp or deepspeed, not both')\n",
    "\n",
    "use_lora = False\n",
    "lora_rank = 256 # test {8, 16, 32, 128} # just [128, 8] for now.\n",
    "lora_alpha = lora_rank \n",
    "lora_dropout = 0.05\n",
    "if use_lora:\n",
    "    abbr_model_name += f'+lora(r={lora_rank},a={lora_alpha})'\n",
    "\n",
    "mixed_precision = 'bf16' if arch == 'x86_64' else 'fp16' # mixed_precision = ''\n",
    "torch_dtype = 'bfloat16' if arch=='x86_64' else 'float16'; torch_dtype = 'float32'\n",
    "\n",
    "gradient_checkpointing = True\n",
    "load_in_8bit = False\n",
    "\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"Effective batch size {effective_batch_size}\")\n",
    "\n",
    "\n",
    "if nodes == 1:\n",
    "    exe = 'python' if num_gpus==1 else \\\n",
    "        f\"torchrun --nproc_per_node={num_gpus} --master_port=10002\"\n",
    "else:\n",
    "    exe = f\"torchrun --nnodes={nodes} --nproc_per_node={num_gpus} --rdzv-id=$SLURM_JOB_ID --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT\"\n",
    "\n",
    "if test_run:\n",
    "    exe = f\"CUDA_VISIBLE_DEVICES={','.join(map(str, range(num_gpus)))} {exe}\"\n",
    "if test_run and debug_mode:\n",
    "    exe = 'TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO ' + exe\n",
    "    error_file='/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/error_file'\n",
    "    exe = f'TORCHELASTIC_ERROR_FILE={error_file} {exe}'\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    num_train_epochs_list,\n",
    "    subsample_mixture_list,\n",
    "    subsample_inds_file_list,\n",
    "    max_train_samples_list,\n",
    ")\n",
    "\n",
    "output_dirname_list = []\n",
    "for (num_train_epochs,\n",
    "     mix_name_and_subsample_mixture,\n",
    "     subsample_inds_file,\n",
    "     max_train_samples,) in options_list:\n",
    "    mix_name, subsample_mixture = mix_name_and_subsample_mixture\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{abbr_train_file}:{int(max_train_samples/1000)}k\"\n",
    "        \n",
    "    if job_name == 'ft2':\n",
    "        if subsample_mixture is not None:\n",
    "            assert(abbr_train_file=='all')\n",
    "            output_dirname += \\\n",
    "                '_mix='+','.join(f'{k}:{v}' for k,v in subsample_mixture.items())\n",
    "            \n",
    "    if job_name == 'oi3':\n",
    "        output_dirname += '_'+mix_name\n",
    "        \n",
    "    if job_name == 'oi4':\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "            \n",
    "            \n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "            \n",
    "    # if not test_run:\n",
    "    #     output_dirname += \\\n",
    "    #         '_ep='+str(num_train_epochs)\n",
    "    # if not test_run:\n",
    "    #     output_dirname += \\\n",
    "    #         ('_fsdp='+fsdp.split(' ')[0] if fsdp else '')+\\\n",
    "    #         ('_deepspeed='+os.path.basename(deepspeed).split('.')[0] if deepspeed else '')+\\\n",
    "    #         ('_gradckpt='+str(gradient_checkpointing) if gradient_checkpointing else '')+\\\n",
    "    #         '_mbsz='+str(batch_size_per_gpu)+\\\n",
    "    #         '_dtype='+torch_dtype+\\\n",
    "    #         ('_mp='+str(mixed_precision) if mixed_precision else '_mp=none')+\\\n",
    "    #         '_seqlen='+str(max_seq_length)+\\\n",
    "    #         '_nodes='+str(nodes)\n",
    "    output_dir = os.path.join('results', job_name, output_dirname)\n",
    "    \n",
    "    cmd = f\"\"\"\n",
    "    {'!cd .. && ' if test_run else ''}{exe}\n",
    "        open_instruct/finetune_trainer.py \\\n",
    "        --model_name_or_path={model_name_or_path} \\\n",
    "        --tokenizer_name={model_name_or_path} \\\n",
    "        {'--load_in_8bit' if load_in_8bit else ''} \\\n",
    "        --use_fast_tokenizer=True \\\n",
    "        --train_file={train_file} \\\n",
    "        --max_seq_length={max_seq_length} \\\n",
    "        {'--max_train_samples='+str(max_train_samples) if max_train_samples else ''} \\\n",
    "        {'--use_lora' if use_lora else ''}\n",
    "        {'--lora_rank='+str(lora_rank) if use_lora else ''}\n",
    "        {'--lora_alpha='+str(lora_alpha) if use_lora else ''}\n",
    "        {'--lora_dropout='+str(lora_dropout) if use_lora else ''}\n",
    "        --do_train \\\n",
    "        --preprocessing_num_workers=16 \\\n",
    "        --per_device_train_batch_size={per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
    "        --learning_rate=2e-5 \\\n",
    "        --lr_scheduler_type=linear \\\n",
    "        --warmup_ratio=0.03 \\\n",
    "        --weight_decay=0. \\\n",
    "        --optim={optimizer} \\\n",
    "        --evaluation_strategy=\"no\" \\\n",
    "        --logging_steps=1 \\\n",
    "        --save_strategy={save_strategy} \\\n",
    "        --save_steps={save_steps} \\\n",
    "        --save_total_limit={save_total_limit} \\\n",
    "        --num_train_epochs={num_train_epochs} \\\n",
    "        {'--fsdp=\"'+fsdp+'\"' if fsdp else ''}\n",
    "        {'--fsdp_transformer_layer_cls_to_wrap=\"'+fsdp_transformer_layer_cls_to_wrap+'\"' \n",
    "            if fsdp else ''}\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''}\n",
    "        --report_to=tensorboard \\\n",
    "        --torch_dtype={torch_dtype} \\\n",
    "        --dataloader_num_workers=8 \\\n",
    "        {f'--{mixed_precision}=True' if mixed_precision else ''} \\\n",
    "        {'--overwrite_output_dir' if overwrite_output_dir else ''} \\\n",
    "        {'--deepspeed='+deepspeed if deepspeed else ''} \\\n",
    "        {'--subsample_mixture=\"'+str(subsample_mixture).replace(': ', ':').replace(', ', ',')+'\"'\n",
    "            if subsample_mixture else ''} \\\n",
    "        {'--subsample_inds_file='+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        --output_dir=\"{output_dir}\" \\\n",
    "    \"\"\" \n",
    "    #    --overwrite_cache\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    if test_run:\n",
    "        print()\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70c2e4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_train_samples = 200000\n",
    "subsample_mixture_normalized_list = []\n",
    "\n",
    "mixes = [\n",
    "    {'cot': 0.46638974, 'dolly': 0.01456044, 'flan_v2': 0.50886009, 'oasst1': 0.01018973},\n",
    "    {'cot': 0.39744481, 'dolly': 0.00472114, 'flan_v2': 0.59104177, 'oasst1': 0.00679229},\n",
    "]\n",
    "\n",
    "subsample_mixture_normalized_list += [('', d) for d in mixes]\n",
    "subsample_mixture_normalized_list += [('humanmix', # humanmix\n",
    "                                       {'cot': 0.48785105, 'dolly': 0.00732313, 'flan_v2': 0.48785105, 'oasst1': 0.01697478})]\n",
    "\n",
    "subsample_mixture_normalized_list = [(x[0],  compute_mixture_num_samples(x[1], max_train_samples)) \n",
    "                                     for x in subsample_mixture_normalized_list]\n",
    "\n",
    "subsample_mixture_normalized_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831fe55",
   "metadata": {},
   "source": [
    "# eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41e3fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_all_symlinks(directory, verbose=False):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files + dirs:\n",
    "            path = os.path.join(root, name)\n",
    "            if os.path.islink(path):\n",
    "                os.unlink(path)\n",
    "                if verbose:\n",
    "                    print(f\"Removed symlink: {path}\")\n",
    "                \n",
    "import uuid\n",
    "\n",
    "def create_unique_symlinks(file_paths, verbose=False):\n",
    "    \"\"\"Create symlinks for each `file` in `files` in the same directory, with a unique name. \"\"\"\n",
    "    dirs = [os.path.dirname(x) for x in file_paths]\n",
    "\n",
    "    symlink_path_dict = {}\n",
    "    for directory, path in zip(dirs, file_paths):\n",
    "        if os.path.isdir(path):\n",
    "            symlink_name = f\"symlink_{str(uuid.uuid4())[:8]}\"  # Generate a unique symlink name\n",
    "            symlink_path = os.path.join(directory, symlink_name)\n",
    "            try:\n",
    "                os.symlink(os.path.abspath(path), symlink_path)\n",
    "                if verbose:\n",
    "                    print(f\"Created symlink: {symlink_path} -> {path}\")\n",
    "            except OSError as e:\n",
    "                print(f\"Failed to create symlink: {path}. Error: {e}\")\n",
    "            symlink_path_dict.update({path: symlink_path})\n",
    "    return symlink_path_dict\n",
    "\n",
    "\n",
    "def get_resource_for_task(task_name, model_name_or_path):\n",
    "    model_name_or_path = model_name_or_path.lower()\n",
    "    if any(x in model_name_or_path for x in ['gpt2-medium', 'pythia-160m']):\n",
    "        return 50, 1\n",
    "    if any(x in model_name_or_path for x in ['gpt-xl']):\n",
    "        if any(x in task_name for x in ['bbh_s=3', 'tydiqa_s=1_gp', 'mmlu_s=5']):\n",
    "            return 16, 1\n",
    "        else:\n",
    "            return 32, 1\n",
    "    if any(x in model_name_or_path for x in ['llama', 'pythia-1.4b', 'pythia-2.8b']):\n",
    "        if any(x in task_name for x in ['bbh_s=3', 'mmlu_s=5']):\n",
    "            return 5, 1\n",
    "        else:\n",
    "            return 10, 1\n",
    "    if any(x in model_name_or_path for x in ['pythia-6.9b', 'dolly-v2-7b']):\n",
    "        if any(x in task_name for x in ['bbh_s=3', 'mmlu_s=5', 'mmlu_s=0']):\n",
    "            return 4, 1\n",
    "        else:\n",
    "            return 10, 1\n",
    "    return 10, 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9b68375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('toxigen', 'results/baselines/huggyllama/llama-7b')\n",
      "('toxigen_chatfmt', 'results/baselines/huggyllama/llama-7b')\n",
      "('mmlu_s=0', 'results/ft1/llama-7b_humanmix')\n",
      "('mmlu_s=5', 'results/ft1/llama-7b_humanmix')\n",
      "('gsm_s=8', 'results/ft1/llama-7b_humanmix')\n",
      "('gsm_s=8_cot', 'results/ft1/llama-7b_humanmix')\n",
      "('bbh_s=3', 'results/ft1/llama-7b_humanmix')\n",
      "('bbh_s=3_cot', 'results/ft1/llama-7b_humanmix')\n",
      "('humaneval', 'results/ft1/llama-7b_humanmix')\n",
      "('tydiqa_s=1_cb', 'results/ft1/llama-7b_humanmix')\n",
      "('tydiqa_s=1_gp', 'results/ft1/llama-7b_humanmix')\n",
      "('toxigen', 'results/ft1/llama-7b_humanmix')\n",
      "('mmlu_s=0_chatfmt', 'results/ft1/llama-7b_humanmix')\n",
      "('mmlu_s=5_chatfmt', 'results/ft1/llama-7b_humanmix')\n",
      "('gsm_s=8_chatfmt', 'results/ft1/llama-7b_humanmix')\n",
      "('gsm_s=8_cot_chatfmt', 'results/ft1/llama-7b_humanmix')\n",
      "('bbh_s=3_chatfmt', 'results/ft1/llama-7b_humanmix')\n",
      "('bbh_s=3_cot_chatfmt', 'results/ft1/llama-7b_humanmix')\n",
      "('humaneval_chatfmt', 'results/ft1/llama-7b_humanmix')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/ft1/llama-7b_humanmix')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/ft1/llama-7b_humanmix')\n",
      "('toxigen_chatfmt', 'results/ft1/llama-7b_humanmix')\n",
      "#cmds:  22 \n",
      "\n",
      "python -m eval.toxigen.run_eval --data_dir data/eval/toxigen --model_name_or_path \"results/baselines/huggyllama/llama-7b\" --save_dir \"results/baselines/huggyllama/llama-7b/eval/toxigen\" --eval_batch_size 1 --max_prompts_per_group 200\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.toxigen\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.toxigen.run_eval --data_dir data/eval/toxigen --model_name_or_path \"results/baselines/huggyllama/llama-7b\" --save_dir \"results/baselines/huggyllama/llama-7b/eval/toxigen_chatfmt\" --eval_batch_size 1 --max_prompts_per_group 200 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.toxigen_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/mmlu_s=0\" --eval_batch_size 10 --ntrain 0\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/mmlu_s=5\" --eval_batch_size 5 --ntrain 5\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/gsm_s=8\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/gsm_s=8_cot\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/bbh_s=3\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/bbh_s=3_cot\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/humaneval\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/tydiqa_s=1_cb\" --eval_batch_size 10 --no_context\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/tydiqa_s=1_gp\" --eval_batch_size 10\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.toxigen.run_eval --data_dir data/eval/toxigen --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/toxigen\" --eval_batch_size 1 --max_prompts_per_group 200\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.toxigen\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/mmlu_s=0_chatfmt\" --eval_batch_size 10 --ntrain 0 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.mmlu.run_eval --data_dir data/eval/mmlu --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/mmlu_s=5_chatfmt\" --eval_batch_size 5 --ntrain 5 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/gsm_s=8_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --no_cot --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.gsm.run_eval --data_dir data/eval/gsm/ --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/gsm_s=8_cot_chatfmt\" --eval_batch_size 10 --max_num_examples 200 --n_shot 8 --max_new_tokens 256 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/bbh_s=3_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --no_cot --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.bbh.run_eval --data_dir data/eval/bbh/ --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/bbh_s=3_cot_chatfmt\" --eval_batch_size 5 --max_new_tokens 256 --n_shot 3 --use_chat_format --max_num_examples_per_task 40\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/humaneval_chatfmt\" --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/tydiqa_s=1_cb_chatfmt\" --eval_batch_size 10 --no_context --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.tydiqa.run_eval --data_dir data/eval/tydiqa --n_shot 1 --max_num_examples_per_lang 100 --max_context_length 512 --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/tydiqa_s=1_gp_chatfmt\" --eval_batch_size 10 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.toxigen.run_eval --data_dir data/eval/toxigen --model_name_or_path \"results/ft1/llama-7b_humanmix\" --save_dir \"results/ft1/llama-7b_humanmix/eval/toxigen_chatfmt\" --eval_batch_size 1 --max_prompts_per_group 200 --use_chat_format\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.toxigen_chatfmt\",\n",
      "    \"num_cpus\": 24,\n",
      "    \"cpu_mem\": 64,\n",
      "    \"num_gpus\": 1,\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "exp_dir = ''\n",
    "create_symlinks = False\n",
    "include_checkpoints = False\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "chat_formatting_function = 'eval.templates.create_prompt_with_llama2_chat_format'\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "num_cpus = 10; cpu_mem = 32 # mem usage quite small for llama7b+lora on bbh\n",
    "num_cpus = 24; cpu_mem = 64\n",
    "\n",
    "\n",
    "task_names = [\n",
    "    'mmlu_s=0',\n",
    "    'mmlu_s=5', # ~1hr\n",
    "    'gsm_s=8',\n",
    "    'gsm_s=8_cot',\n",
    "    'bbh_s=3',\n",
    "    'bbh_s=3_cot', # max_datapoints_per_task=40 -> 40min.\n",
    "    'humaneval',\n",
    "    'tydiqa_s=1_cb',\n",
    "    'tydiqa_s=1_gp',\n",
    "    'toxigen',\n",
    "]\n",
    "\n",
    "task_names_chatfmt = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "\n",
    "\n",
    "# # ## baselines eval \n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "# #     'gpt2',\n",
    "# #     'gpt2-medium',\n",
    "#     'huggyllama/llama-7b', \n",
    "#     'NousResearch/Llama-2-7b-hf',\n",
    "#     'EleutherAI/pythia-1.4b',\n",
    "#     'EleutherAI/pythia-2.8b',\n",
    "#     'EleutherAI/pythia-6.9b',\n",
    "#     'databricks/dolly-v2-7b',\n",
    "# ]]\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# ## baseline re-eval after merge upstream/main\n",
    "subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "    'huggyllama/llama-7b',\n",
    "]]\n",
    "subdir_path_list += ['results/ft1/llama-7b_humanmix']\n",
    "task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# ## ft1\n",
    "# exp_dir = 'results/ft1'\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# ## ft2\n",
    "# exp_dir = 'results/ft2/'\n",
    "# create_symlinks = True\n",
    "# subdir_filter_fn = lambda x: any(y in x for y in ['llama-7b'])\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "# ## llama-7b time-series 400k, 600k\n",
    "# exp_dir = 'results/oi3/'\n",
    "# include_checkpoints = True\n",
    "# subdir_filter_fn = lambda x: any(y in x for y in ['400k', '600k']) # , '600k'\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "\n",
    "# ## oi4\n",
    "# exp_dir = 'results/oi4/'\n",
    "# task_names = task_names+task_names_chatfmt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if len(subdir_path_list)==0:\n",
    "    if create_symlinks:\n",
    "        remove_all_symlinks(exp_dir)\n",
    "    subdir_path_list = []\n",
    "    subdirs = list(os.listdir(exp_dir))\n",
    "    subdirs = filter(subdir_filter_fn, subdirs)\n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(exp_dir, subdir)\n",
    "        if include_checkpoints:\n",
    "            subdir_path_list += glob.glob(os.path.join(subdir_path, 'checkpoint-*'))\n",
    "        if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "            continue\n",
    "        subdir_path_list.append(subdir_path)\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not os.path.islink(subdir_path) and \\\n",
    "                not os.path.isfile(os.path.join(subdir_path, 'eval', task_name, 'metrics.json')):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "                print((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "\n",
    "print('#cmds: ', len(list(task_name_and_model)), '\\n')\n",
    "\n",
    "if create_symlinks:\n",
    "    # create symlink for each directory.\n",
    "    symlink_path_dict = create_unique_symlinks(\n",
    "        list([x[1] for x in task_name_and_model]))\n",
    "    options_list = list(map(lambda x: (x[0], symlink_path_dict[x[1]]), task_name_and_model))\n",
    "else:\n",
    "    options_list = task_name_and_model\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "info = {}  \n",
    "cmds = []\n",
    "for task_name, model_name_or_path in options_list:\n",
    "    \n",
    "    use_chat_format = 'chatfmt' in task_name\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(model_name_or_path, 'ft_args.json'), 'r') as f:\n",
    "            ft_args = json.load(f)\n",
    "        # note `model_name_or_path` could be anything, e.g., soft links with arbitrary names.\n",
    "        # but `ft_args_model_name_or_path` indicates the finetuned model name.\n",
    "        ft_args_model_name_or_path = ft_args['model_args']['model_name_or_path']\n",
    "    except:\n",
    "        ft_args_model_name_or_path = model_name_or_path\n",
    "\n",
    "    if 'gpt2' in ft_args_model_name_or_path:\n",
    "        tydiqa_max_context_length = 400 # max ctx len without exceeding max_seq_len\n",
    "    else:\n",
    "        tydiqa_max_context_length = 512\n",
    "    batch_size, job_duration = get_resource_for_task(\n",
    "        task_name, ft_args_model_name_or_path)\n",
    "    \n",
    "    job_name = f'eval.{task_name}'\n",
    "    run_id = model_name_or_path\n",
    "    save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "    \n",
    "    if task_name.startswith('mmlu'):\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 5)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.mmlu.run_eval \\\n",
    "            --data_dir data/eval/mmlu \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --ntrain {n_shot} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('gsm'):\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 8)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.gsm.run_eval \\\n",
    "            --data_dir data/eval/gsm/ \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_num_examples 200 \\\n",
    "            --n_shot {n_shot} \\\n",
    "            --max_new_tokens 256 \\\n",
    "            {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''}\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('bbh'):\n",
    "        max_num_examples_per_task = 40\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 3)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.bbh.run_eval \\\n",
    "            --data_dir data/eval/bbh/ \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_new_tokens 256 \\\n",
    "            --n_shot {n_shot} \\\n",
    "            {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            {'--max_num_examples_per_task '+str(max_num_examples_per_task) if max_num_examples_per_task else ''} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('humaneval'):\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.codex_humaneval.run_eval \\\n",
    "            --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --eval_pass_at_ks 1 \\\n",
    "            --unbiased_sampling_size_n 1 \\\n",
    "            --temperature 0.1 \\\n",
    "            {'--use_chat_format' if use_chat_format else ''}\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('tydiqa'):\n",
    "        no_context = 'cb' in task_name\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot in [0,1])\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.tydiqa.run_eval \\\n",
    "            --data_dir data/eval/tydiqa \\\n",
    "            --n_shot {n_shot} \\\n",
    "            --max_num_examples_per_lang 100 \\\n",
    "            --max_context_length {tydiqa_max_context_length} \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            {'--no_context' if no_context else ''}\n",
    "            {'--use_chat_format' if use_chat_format else ''}\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('toxigen'):\n",
    "        # max_prompts_per_group=500 (out of 1000) is open-instruct default.\n",
    "        # eval batch size=1 much faster (llama-7b) not sure why.\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.toxigen.run_eval \\\n",
    "            --data_dir data/eval/toxigen \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size 1 \\\n",
    "            --max_prompts_per_group 200 \\\n",
    "            {'--use_chat_format' if use_chat_format else ''}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        raise ValueError(f'{task_name} not supported.')\n",
    "        \n",
    "        \n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "    print(cmd)\n",
    "    \n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=save_dir)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=1,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aef11ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_fmt=True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e1917_row0_col0, #T_e1917_row0_col1, #T_e1917_row0_col2, #T_e1917_row0_col3, #T_e1917_row1_col0, #T_e1917_row1_col1, #T_e1917_row1_col2, #T_e1917_row1_col3, #T_e1917_row2_col0, #T_e1917_row2_col1, #T_e1917_row2_col2, #T_e1917_row2_col3, #T_e1917_row3_col0, #T_e1917_row3_col1, #T_e1917_row3_col2, #T_e1917_row3_col3, #T_e1917_row4_col0, #T_e1917_row4_col1, #T_e1917_row4_col2, #T_e1917_row4_col3, #T_e1917_row5_col0, #T_e1917_row5_col1, #T_e1917_row5_col2, #T_e1917_row5_col3, #T_e1917_row6_col0, #T_e1917_row6_col1, #T_e1917_row6_col2, #T_e1917_row6_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e1917_row0_col4, #T_e1917_row0_col5, #T_e1917_row0_col7, #T_e1917_row0_col8, #T_e1917_row0_col9, #T_e1917_row0_col10, #T_e1917_row0_col11, #T_e1917_row0_col12, #T_e1917_row0_col13, #T_e1917_row0_col14, #T_e1917_row2_col6, #T_e1917_row3_col6, #T_e1917_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row1_col4, #T_e1917_row1_col5, #T_e1917_row1_col12, #T_e1917_row2_col10, #T_e1917_row2_col12, #T_e1917_row2_col14, #T_e1917_row3_col12, #T_e1917_row5_col6, #T_e1917_row5_col7, #T_e1917_row5_col8, #T_e1917_row5_col9, #T_e1917_row5_col11, #T_e1917_row5_col12, #T_e1917_row5_col13, #T_e1917_row6_col6, #T_e1917_row6_col7, #T_e1917_row6_col8, #T_e1917_row6_col9, #T_e1917_row6_col11, #T_e1917_row6_col12, #T_e1917_row6_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row1_col7, #T_e1917_row5_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e1917_row1_col8, #T_e1917_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e1917_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row2_col4, #T_e1917_row2_col5, #T_e1917_row3_col4, #T_e1917_row3_col5, #T_e1917_row4_col4, #T_e1917_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row2_col7, #T_e1917_row3_col7, #T_e1917_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e1917_row2_col8, #T_e1917_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e1917_row2_col9, #T_e1917_row3_col9, #T_e1917_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row2_col13, #T_e1917_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e1917_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e1917_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e1917_row4_col10, #T_e1917_row4_col11, #T_e1917_row4_col14, #T_e1917_row5_col4, #T_e1917_row5_col5, #T_e1917_row5_col14, #T_e1917_row6_col4, #T_e1917_row6_col5, #T_e1917_row6_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e1917_row4_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e1917_row6_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e1917\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e1917_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_e1917_level0_col1\" class=\"col_heading level0 col1\" >model_args.model_name_or_path</th>\n",
       "      <th id=\"T_e1917_level0_col2\" class=\"col_heading level0 col2\" >data_args.subsample_mixture</th>\n",
       "      <th id=\"T_e1917_level0_col3\" class=\"col_heading level0 col3\" >data_args.max_train_samples</th>\n",
       "      <th id=\"T_e1917_level0_col4\" class=\"col_heading level0 col4\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_e1917_level0_col5\" class=\"col_heading level0 col5\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_e1917_level0_col6\" class=\"col_heading level0 col6\" >GSM/Direct</th>\n",
       "      <th id=\"T_e1917_level0_col7\" class=\"col_heading level0 col7\" >GSM/CoT</th>\n",
       "      <th id=\"T_e1917_level0_col8\" class=\"col_heading level0 col8\" >BBH/Direct</th>\n",
       "      <th id=\"T_e1917_level0_col9\" class=\"col_heading level0 col9\" >BBH/CoT</th>\n",
       "      <th id=\"T_e1917_level0_col10\" class=\"col_heading level0 col10\" >TydiQA/CB</th>\n",
       "      <th id=\"T_e1917_level0_col11\" class=\"col_heading level0 col11\" >TydiQA/GP</th>\n",
       "      <th id=\"T_e1917_level0_col12\" class=\"col_heading level0 col12\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_e1917_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_e1917_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e1917_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e1917_row0_col0\" class=\"data row0 col0\" >llama-7b_humanmix_prev</td>\n",
       "      <td id=\"T_e1917_row0_col1\" class=\"data row0 col1\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_e1917_row0_col2\" class=\"data row0 col2\" >{}</td>\n",
       "      <td id=\"T_e1917_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_e1917_row0_col4\" class=\"data row0 col4\" >43.55</td>\n",
       "      <td id=\"T_e1917_row0_col5\" class=\"data row0 col5\" >46.46</td>\n",
       "      <td id=\"T_e1917_row0_col6\" class=\"data row0 col6\" >6.00</td>\n",
       "      <td id=\"T_e1917_row0_col7\" class=\"data row0 col7\" >29.00</td>\n",
       "      <td id=\"T_e1917_row0_col8\" class=\"data row0 col8\" >36.11</td>\n",
       "      <td id=\"T_e1917_row0_col9\" class=\"data row0 col9\" >34.35</td>\n",
       "      <td id=\"T_e1917_row0_col10\" class=\"data row0 col10\" >10.37</td>\n",
       "      <td id=\"T_e1917_row0_col11\" class=\"data row0 col11\" >43.48</td>\n",
       "      <td id=\"T_e1917_row0_col12\" class=\"data row0 col12\" >10.37</td>\n",
       "      <td id=\"T_e1917_row0_col13\" class=\"data row0 col13\" >28.85</td>\n",
       "      <td id=\"T_e1917_row0_col14\" class=\"data row0 col14\" >-1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1917_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e1917_row1_col0\" class=\"data row1 col0\" >llama-7b_prev</td>\n",
       "      <td id=\"T_e1917_row1_col1\" class=\"data row1 col1\" >huggyllama/llama-7b_prev</td>\n",
       "      <td id=\"T_e1917_row1_col2\" class=\"data row1 col2\" >{}</td>\n",
       "      <td id=\"T_e1917_row1_col3\" class=\"data row1 col3\" >None</td>\n",
       "      <td id=\"T_e1917_row1_col4\" class=\"data row1 col4\" >32.46</td>\n",
       "      <td id=\"T_e1917_row1_col5\" class=\"data row1 col5\" >33.06</td>\n",
       "      <td id=\"T_e1917_row1_col6\" class=\"data row1 col6\" >5.50</td>\n",
       "      <td id=\"T_e1917_row1_col7\" class=\"data row1 col7\" >11.00</td>\n",
       "      <td id=\"T_e1917_row1_col8\" class=\"data row1 col8\" >32.97</td>\n",
       "      <td id=\"T_e1917_row1_col9\" class=\"data row1 col9\" >28.43</td>\n",
       "      <td id=\"T_e1917_row1_col10\" class=\"data row1 col10\" >10.35</td>\n",
       "      <td id=\"T_e1917_row1_col11\" class=\"data row1 col11\" >38.56</td>\n",
       "      <td id=\"T_e1917_row1_col12\" class=\"data row1 col12\" >0.00</td>\n",
       "      <td id=\"T_e1917_row1_col13\" class=\"data row1 col13\" >21.37</td>\n",
       "      <td id=\"T_e1917_row1_col14\" class=\"data row1 col14\" >-3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1917_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e1917_row2_col0\" class=\"data row2 col0\" >llama-7b_r=1</td>\n",
       "      <td id=\"T_e1917_row2_col1\" class=\"data row2 col1\" >huggyllama/llama-7b_r=1</td>\n",
       "      <td id=\"T_e1917_row2_col2\" class=\"data row2 col2\" >{}</td>\n",
       "      <td id=\"T_e1917_row2_col3\" class=\"data row2 col3\" >None</td>\n",
       "      <td id=\"T_e1917_row2_col4\" class=\"data row2 col4\" >32.82</td>\n",
       "      <td id=\"T_e1917_row2_col5\" class=\"data row2 col5\" >33.51</td>\n",
       "      <td id=\"T_e1917_row2_col6\" class=\"data row2 col6\" >6.50</td>\n",
       "      <td id=\"T_e1917_row2_col7\" class=\"data row2 col7\" >12.50</td>\n",
       "      <td id=\"T_e1917_row2_col8\" class=\"data row2 col8\" >32.13</td>\n",
       "      <td id=\"T_e1917_row2_col9\" class=\"data row2 col9\" >27.41</td>\n",
       "      <td id=\"T_e1917_row2_col10\" class=\"data row2 col10\" >7.84</td>\n",
       "      <td id=\"T_e1917_row2_col11\" class=\"data row2 col11\" >35.32</td>\n",
       "      <td id=\"T_e1917_row2_col12\" class=\"data row2 col12\" >0.00</td>\n",
       "      <td id=\"T_e1917_row2_col13\" class=\"data row2 col13\" >20.89</td>\n",
       "      <td id=\"T_e1917_row2_col14\" class=\"data row2 col14\" >-3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1917_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e1917_row3_col0\" class=\"data row3 col0\" >llama-7b_r=2</td>\n",
       "      <td id=\"T_e1917_row3_col1\" class=\"data row3 col1\" >huggyllama/llama-7b</td>\n",
       "      <td id=\"T_e1917_row3_col2\" class=\"data row3 col2\" >{}</td>\n",
       "      <td id=\"T_e1917_row3_col3\" class=\"data row3 col3\" >None</td>\n",
       "      <td id=\"T_e1917_row3_col4\" class=\"data row3 col4\" >32.82</td>\n",
       "      <td id=\"T_e1917_row3_col5\" class=\"data row3 col5\" >33.51</td>\n",
       "      <td id=\"T_e1917_row3_col6\" class=\"data row3 col6\" >6.50</td>\n",
       "      <td id=\"T_e1917_row3_col7\" class=\"data row3 col7\" >12.50</td>\n",
       "      <td id=\"T_e1917_row3_col8\" class=\"data row3 col8\" >32.13</td>\n",
       "      <td id=\"T_e1917_row3_col9\" class=\"data row3 col9\" >27.41</td>\n",
       "      <td id=\"T_e1917_row3_col10\" class=\"data row3 col10\" >8.98</td>\n",
       "      <td id=\"T_e1917_row3_col11\" class=\"data row3 col11\" >33.88</td>\n",
       "      <td id=\"T_e1917_row3_col12\" class=\"data row3 col12\" >0.00</td>\n",
       "      <td id=\"T_e1917_row3_col13\" class=\"data row3 col13\" >20.86</td>\n",
       "      <td id=\"T_e1917_row3_col14\" class=\"data row3 col14\" >-3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1917_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e1917_row4_col0\" class=\"data row4 col0\" >llama-7b_r=0</td>\n",
       "      <td id=\"T_e1917_row4_col1\" class=\"data row4 col1\" >huggyllama/llama-7b_r=0</td>\n",
       "      <td id=\"T_e1917_row4_col2\" class=\"data row4 col2\" >{}</td>\n",
       "      <td id=\"T_e1917_row4_col3\" class=\"data row4 col3\" >None</td>\n",
       "      <td id=\"T_e1917_row4_col4\" class=\"data row4 col4\" >32.82</td>\n",
       "      <td id=\"T_e1917_row4_col5\" class=\"data row4 col5\" >33.51</td>\n",
       "      <td id=\"T_e1917_row4_col6\" class=\"data row4 col6\" >6.50</td>\n",
       "      <td id=\"T_e1917_row4_col7\" class=\"data row4 col7\" >12.50</td>\n",
       "      <td id=\"T_e1917_row4_col8\" class=\"data row4 col8\" >31.73</td>\n",
       "      <td id=\"T_e1917_row4_col9\" class=\"data row4 col9\" >27.41</td>\n",
       "      <td id=\"T_e1917_row4_col10\" class=\"data row4 col10\" >nan</td>\n",
       "      <td id=\"T_e1917_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_e1917_row4_col12\" class=\"data row4 col12\" >0.61</td>\n",
       "      <td id=\"T_e1917_row4_col13\" class=\"data row4 col13\" >20.72</td>\n",
       "      <td id=\"T_e1917_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1917_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e1917_row5_col0\" class=\"data row5 col0\" >llama-7b_humanmix_r=1</td>\n",
       "      <td id=\"T_e1917_row5_col1\" class=\"data row5 col1\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_e1917_row5_col2\" class=\"data row5 col2\" >{}</td>\n",
       "      <td id=\"T_e1917_row5_col3\" class=\"data row5 col3\" >None</td>\n",
       "      <td id=\"T_e1917_row5_col4\" class=\"data row5 col4\" >nan</td>\n",
       "      <td id=\"T_e1917_row5_col5\" class=\"data row5 col5\" >nan</td>\n",
       "      <td id=\"T_e1917_row5_col6\" class=\"data row5 col6\" >0.00</td>\n",
       "      <td id=\"T_e1917_row5_col7\" class=\"data row5 col7\" >0.00</td>\n",
       "      <td id=\"T_e1917_row5_col8\" class=\"data row5 col8\" >21.94</td>\n",
       "      <td id=\"T_e1917_row5_col9\" class=\"data row5 col9\" >4.54</td>\n",
       "      <td id=\"T_e1917_row5_col10\" class=\"data row5 col10\" >8.81</td>\n",
       "      <td id=\"T_e1917_row5_col11\" class=\"data row5 col11\" >0.00</td>\n",
       "      <td id=\"T_e1917_row5_col12\" class=\"data row5 col12\" >0.00</td>\n",
       "      <td id=\"T_e1917_row5_col13\" class=\"data row5 col13\" >5.04</td>\n",
       "      <td id=\"T_e1917_row5_col14\" class=\"data row5 col14\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1917_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e1917_row6_col0\" class=\"data row6 col0\" >llama-7b_humanmix_r=0</td>\n",
       "      <td id=\"T_e1917_row6_col1\" class=\"data row6 col1\" >results/baselines/huggyllama/llama-7b_r=0</td>\n",
       "      <td id=\"T_e1917_row6_col2\" class=\"data row6 col2\" >{}</td>\n",
       "      <td id=\"T_e1917_row6_col3\" class=\"data row6 col3\" >None</td>\n",
       "      <td id=\"T_e1917_row6_col4\" class=\"data row6 col4\" >nan</td>\n",
       "      <td id=\"T_e1917_row6_col5\" class=\"data row6 col5\" >nan</td>\n",
       "      <td id=\"T_e1917_row6_col6\" class=\"data row6 col6\" >0.00</td>\n",
       "      <td id=\"T_e1917_row6_col7\" class=\"data row6 col7\" >0.00</td>\n",
       "      <td id=\"T_e1917_row6_col8\" class=\"data row6 col8\" >21.94</td>\n",
       "      <td id=\"T_e1917_row6_col9\" class=\"data row6 col9\" >4.54</td>\n",
       "      <td id=\"T_e1917_row6_col10\" class=\"data row6 col10\" >8.62</td>\n",
       "      <td id=\"T_e1917_row6_col11\" class=\"data row6 col11\" >0.00</td>\n",
       "      <td id=\"T_e1917_row6_col12\" class=\"data row6 col12\" >0.00</td>\n",
       "      <td id=\"T_e1917_row6_col13\" class=\"data row6 col13\" >5.01</td>\n",
       "      <td id=\"T_e1917_row6_col14\" class=\"data row6 col14\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffdf69df7c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_sort_rows_by_avg_ranking\n",
    "from llm.evaluate import EvalResults, get_eval_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "exp_dir = ''\n",
    "chat_fmt = None\n",
    "sort_rows = True\n",
    "\n",
    "# baselines\n",
    "save_dirs = []\n",
    "save_dirs += [\n",
    "#     ('gpt2', '../results/baselines/gpt2'),\n",
    "#     ('gpt2m', '../results/baselines/gpt2-medium'),\n",
    "    ('llama-7b_r=2', '../results/baselines/huggyllama/llama-7b'),\n",
    "    ('llama-7b_r=1', '../results/baselines/huggyllama/llama-7b_r=1/'),\n",
    "    ('llama-7b_r=0', '../results/baselines/huggyllama/llama-7b_r=0/'),\n",
    "    ('llama-7b_prev', '../results/baselines/huggyllama/llama-7b_prev/'),\n",
    "    ('llama-7b_humanmix_r=1', '../results/ft1/llama-7b_humanmix'),\n",
    "    ('llama-7b_humanmix_r=0', '../results/ft1/llama-7b_humanmix_r=0'),\n",
    "    ('llama-7b_humanmix_prev', '../results/ft1/llama-7b_humanmix_prev'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('llama2-7b+humanmix', '../results/llama2-7b_humanmix'),\n",
    "#     ('pythia-1.4b', '../results/baselines/EleutherAI/pythia-1.4b'),\n",
    "#     ('pythia-2.8b', '../results/baselines/EleutherAI/pythia-2.8b'),\n",
    "#     ('pythia-6.9b', '../results/baselines/EleutherAI/pythia-6.9b'),\n",
    "#     ('dolly-v2-7b', '../results/baselines/databricks/dolly-v2-7b'),\n",
    "]\n",
    "\n",
    "\n",
    "# exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/ft2'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'), # 2 epochs\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:200k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "# exp_dir = '../results/oi4'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_flan_v2_epochs=2', '../results/ft1/llama-7b_flan_v2'),]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# exp_dir = '../results/ft2'\n",
    "# save_dirs = []\n",
    "\n",
    "# run_dirs = [\n",
    "#     'pythia-1.4b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "#     'pythia-2.8b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "#     'pythia-6.9b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "# ]\n",
    "# for run_dir in run_dirs:\n",
    "#     save_dirs += [(os.path.basename(x), x) \n",
    "#                   for x in glob.glob(os.path.join(exp_dir, run_dir, 'checkpoint-*'))]\n",
    "\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:200k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "\n",
    "# # check mmlu chat_format_version\n",
    "# exp_dir = ''\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b-huamnmix', '../results/ft1/llama-7b_humanmix'),\n",
    "# ]\n",
    "\n",
    "# save_dirs = [x for x in save_dirs if 'replace' not in x[1]]\n",
    "\n",
    "ft_args_fields = [\n",
    "    'run_name',\n",
    "    'model_args.model_name_or_path',\n",
    "    'data_args.subsample_mixture',\n",
    "    'data_args.max_train_samples',\n",
    "]\n",
    "\n",
    "\n",
    "if any(exp_dir.endswith(x) for x in ['', 'ft2', 'oi4']):\n",
    "    print('chat_fmt=True')\n",
    "    df = get_eval_results(save_dirs, chat_fmt=True, ft_args_fields=ft_args_fields)\n",
    "#     df = get_eval_results(save_dirs, chat_fmt='both', ft_args_fields=ft_args_fields)\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP']\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "    df = df[ft_args_fields + cols]\n",
    "    df['Average'] = df[cols].mean(axis=1)\n",
    "    if sort_rows:\n",
    "        df = pd_sort_rows_by_avg_ranking(df); df['ranking'] = -df['ranking']\n",
    "        sort_value_col, sort_value_col_ascending = 'Average', False\n",
    "    #     sort_value_col, sort_value_col_ascending = 'ranking', False\n",
    "        df = df.sort_values(sort_value_col, ascending=sort_value_col_ascending)\n",
    "    df = df.reset_index(drop=True)\n",
    "else:\n",
    "    df = get_eval_results(save_dirs, chat_fmt='both', ft_args_fields=ft_args_fields)\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "    df = df[ft_args_fields+cols]\n",
    "    \n",
    "\n",
    "if any(exp_dir.endswith(x) for x in ['ft2']):\n",
    "#     for model_name_contain in ['gpt2', 'llama', 'pythia-1.4b']:\n",
    "#         for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "    for model_name_contain in ['llama']:\n",
    "        for total_train_samples in [200000, 400000, 600000]:\n",
    "            dfc = df.copy()\n",
    "            dfc.insert(0, 'total_train_samples',  dfc['data_args.subsample_mixture'].apply(\n",
    "                lambda d: sum(list(d.values())) if d else 200000))\n",
    "            dfc = dfc[dfc['total_train_samples'].apply(\n",
    "                lambda x: total_train_samples-20000<x<total_train_samples+20000)]\n",
    "            dfc = dfc[dfc['model_args.model_name_or_path'].apply(\n",
    "                lambda x: model_name_contain in x)]\n",
    "            dfc['total_train_samples'] = dfc['total_train_samples'].astype(str)\n",
    "            dfc = dfc.reset_index(drop=True)\n",
    "            if len(dfc):\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .format(precision=2))\n",
    "elif any(exp_dir.endswith(x) for x in ['oi4']):\n",
    "    dfc = df.copy()\n",
    "    dfc = dfc.reset_index(drop=True)\n",
    "    if len(dfc):\n",
    "        display(dfc\n",
    "                .style\n",
    "                .set_properties(**{'text-align': 'left'})\n",
    "                .background_gradient(cmap ='coolwarm')\n",
    "                .format(precision=2))\n",
    "else:\n",
    "    for model_name_contain in ['llama', 'pythia-1.4b']:\n",
    "        dfc = df.copy()\n",
    "        dfc = dfc[dfc['model_args.model_name_or_path'].apply(\n",
    "            lambda x: model_name_contain in x)]\n",
    "        dfc = dfc.reset_index(drop=True)\n",
    "        if len(dfc):\n",
    "            display(dfc\n",
    "                    .style\n",
    "                    .set_properties(**{'text-align': 'left'})\n",
    "                    .background_gradient(cmap ='coolwarm')\n",
    "                    .format(precision=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b583a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0c55c_row0_col0, #T_0c55c_row0_col1, #T_0c55c_row0_col2, #T_0c55c_row0_col3, #T_0c55c_row1_col0, #T_0c55c_row1_col1, #T_0c55c_row1_col2, #T_0c55c_row1_col3, #T_0c55c_row2_col0, #T_0c55c_row2_col1, #T_0c55c_row2_col2, #T_0c55c_row2_col3, #T_0c55c_row3_col0, #T_0c55c_row3_col1, #T_0c55c_row3_col2, #T_0c55c_row3_col3, #T_0c55c_row4_col0, #T_0c55c_row4_col1, #T_0c55c_row4_col2, #T_0c55c_row4_col3, #T_0c55c_row5_col0, #T_0c55c_row5_col1, #T_0c55c_row5_col2, #T_0c55c_row5_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0c55c_row0_col4, #T_0c55c_row0_col5, #T_0c55c_row0_col6, #T_0c55c_row0_col7, #T_0c55c_row0_col8, #T_0c55c_row0_col9, #T_0c55c_row0_col11, #T_0c55c_row0_col13, #T_0c55c_row0_col14, #T_0c55c_row2_col12, #T_0c55c_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row0_col10, #T_0c55c_row1_col4, #T_0c55c_row2_col5, #T_0c55c_row3_col5, #T_0c55c_row3_col14, #T_0c55c_row5_col6, #T_0c55c_row5_col7, #T_0c55c_row5_col8, #T_0c55c_row5_col9, #T_0c55c_row5_col11, #T_0c55c_row5_col12, #T_0c55c_row5_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row0_col12, #T_0c55c_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c55c_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c55c_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c83836;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c55c_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c55c_row2_col4, #T_0c55c_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row2_col6, #T_0c55c_row3_col6, #T_0c55c_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row2_col7, #T_0c55c_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c55c_row2_col8, #T_0c55c_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c55c_row2_col9, #T_0c55c_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c55c_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row2_col13, #T_0c55c_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c55c_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c55c_row4_col4, #T_0c55c_row4_col5, #T_0c55c_row4_col7, #T_0c55c_row4_col9, #T_0c55c_row4_col11, #T_0c55c_row4_col12, #T_0c55c_row4_col14, #T_0c55c_row5_col4, #T_0c55c_row5_col5, #T_0c55c_row5_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c55c_row4_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c55c_row5_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0c55c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0c55c_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_0c55c_level0_col1\" class=\"col_heading level0 col1\" >model_args.model_name_or_path</th>\n",
       "      <th id=\"T_0c55c_level0_col2\" class=\"col_heading level0 col2\" >data_args.subsample_mixture</th>\n",
       "      <th id=\"T_0c55c_level0_col3\" class=\"col_heading level0 col3\" >data_args.max_train_samples</th>\n",
       "      <th id=\"T_0c55c_level0_col4\" class=\"col_heading level0 col4\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_0c55c_level0_col5\" class=\"col_heading level0 col5\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_0c55c_level0_col6\" class=\"col_heading level0 col6\" >GSM/Direct</th>\n",
       "      <th id=\"T_0c55c_level0_col7\" class=\"col_heading level0 col7\" >GSM/CoT</th>\n",
       "      <th id=\"T_0c55c_level0_col8\" class=\"col_heading level0 col8\" >BBH/Direct</th>\n",
       "      <th id=\"T_0c55c_level0_col9\" class=\"col_heading level0 col9\" >BBH/CoT</th>\n",
       "      <th id=\"T_0c55c_level0_col10\" class=\"col_heading level0 col10\" >TydiQA/CB</th>\n",
       "      <th id=\"T_0c55c_level0_col11\" class=\"col_heading level0 col11\" >TydiQA/GP</th>\n",
       "      <th id=\"T_0c55c_level0_col12\" class=\"col_heading level0 col12\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_0c55c_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_0c55c_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0c55c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0c55c_row0_col0\" class=\"data row0 col0\" >llama-7b_humanmix_prev</td>\n",
       "      <td id=\"T_0c55c_row0_col1\" class=\"data row0 col1\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_0c55c_row0_col2\" class=\"data row0 col2\" >{}</td>\n",
       "      <td id=\"T_0c55c_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_0c55c_row0_col4\" class=\"data row0 col4\" >43.03</td>\n",
       "      <td id=\"T_0c55c_row0_col5\" class=\"data row0 col5\" >46.15</td>\n",
       "      <td id=\"T_0c55c_row0_col6\" class=\"data row0 col6\" >6.50</td>\n",
       "      <td id=\"T_0c55c_row0_col7\" class=\"data row0 col7\" >28.00</td>\n",
       "      <td id=\"T_0c55c_row0_col8\" class=\"data row0 col8\" >35.18</td>\n",
       "      <td id=\"T_0c55c_row0_col9\" class=\"data row0 col9\" >34.35</td>\n",
       "      <td id=\"T_0c55c_row0_col10\" class=\"data row0 col10\" >9.30</td>\n",
       "      <td id=\"T_0c55c_row0_col11\" class=\"data row0 col11\" >42.81</td>\n",
       "      <td id=\"T_0c55c_row0_col12\" class=\"data row0 col12\" >11.59</td>\n",
       "      <td id=\"T_0c55c_row0_col13\" class=\"data row0 col13\" >28.55</td>\n",
       "      <td id=\"T_0c55c_row0_col14\" class=\"data row0 col14\" >-1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c55c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0c55c_row1_col0\" class=\"data row1 col0\" >llama-7b_prev</td>\n",
       "      <td id=\"T_0c55c_row1_col1\" class=\"data row1 col1\" >huggyllama/llama-7b_prev</td>\n",
       "      <td id=\"T_0c55c_row1_col2\" class=\"data row1 col2\" >{}</td>\n",
       "      <td id=\"T_0c55c_row1_col3\" class=\"data row1 col3\" >None</td>\n",
       "      <td id=\"T_0c55c_row1_col4\" class=\"data row1 col4\" >31.86</td>\n",
       "      <td id=\"T_0c55c_row1_col5\" class=\"data row1 col5\" >35.22</td>\n",
       "      <td id=\"T_0c55c_row1_col6\" class=\"data row1 col6\" >6.00</td>\n",
       "      <td id=\"T_0c55c_row1_col7\" class=\"data row1 col7\" >10.50</td>\n",
       "      <td id=\"T_0c55c_row1_col8\" class=\"data row1 col8\" >31.65</td>\n",
       "      <td id=\"T_0c55c_row1_col9\" class=\"data row1 col9\" >29.24</td>\n",
       "      <td id=\"T_0c55c_row1_col10\" class=\"data row1 col10\" >9.51</td>\n",
       "      <td id=\"T_0c55c_row1_col11\" class=\"data row1 col11\" >40.40</td>\n",
       "      <td id=\"T_0c55c_row1_col12\" class=\"data row1 col12\" >11.59</td>\n",
       "      <td id=\"T_0c55c_row1_col13\" class=\"data row1 col13\" >22.89</td>\n",
       "      <td id=\"T_0c55c_row1_col14\" class=\"data row1 col14\" >-2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c55c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0c55c_row2_col0\" class=\"data row2 col0\" >llama-7b_r=1</td>\n",
       "      <td id=\"T_0c55c_row2_col1\" class=\"data row2 col1\" >huggyllama/llama-7b_r=1</td>\n",
       "      <td id=\"T_0c55c_row2_col2\" class=\"data row2 col2\" >{}</td>\n",
       "      <td id=\"T_0c55c_row2_col3\" class=\"data row2 col3\" >None</td>\n",
       "      <td id=\"T_0c55c_row2_col4\" class=\"data row2 col4\" >32.38</td>\n",
       "      <td id=\"T_0c55c_row2_col5\" class=\"data row2 col5\" >35.03</td>\n",
       "      <td id=\"T_0c55c_row2_col6\" class=\"data row2 col6\" >5.00</td>\n",
       "      <td id=\"T_0c55c_row2_col7\" class=\"data row2 col7\" >11.00</td>\n",
       "      <td id=\"T_0c55c_row2_col8\" class=\"data row2 col8\" >31.11</td>\n",
       "      <td id=\"T_0c55c_row2_col9\" class=\"data row2 col9\" >27.50</td>\n",
       "      <td id=\"T_0c55c_row2_col10\" class=\"data row2 col10\" >10.03</td>\n",
       "      <td id=\"T_0c55c_row2_col11\" class=\"data row2 col11\" >38.06</td>\n",
       "      <td id=\"T_0c55c_row2_col12\" class=\"data row2 col12\" >12.20</td>\n",
       "      <td id=\"T_0c55c_row2_col13\" class=\"data row2 col13\" >22.48</td>\n",
       "      <td id=\"T_0c55c_row2_col14\" class=\"data row2 col14\" >-2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c55c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0c55c_row3_col0\" class=\"data row3 col0\" >llama-7b_r=0</td>\n",
       "      <td id=\"T_0c55c_row3_col1\" class=\"data row3 col1\" >huggyllama/llama-7b_r=0</td>\n",
       "      <td id=\"T_0c55c_row3_col2\" class=\"data row3 col2\" >{}</td>\n",
       "      <td id=\"T_0c55c_row3_col3\" class=\"data row3 col3\" >None</td>\n",
       "      <td id=\"T_0c55c_row3_col4\" class=\"data row3 col4\" >32.38</td>\n",
       "      <td id=\"T_0c55c_row3_col5\" class=\"data row3 col5\" >35.03</td>\n",
       "      <td id=\"T_0c55c_row3_col6\" class=\"data row3 col6\" >5.00</td>\n",
       "      <td id=\"T_0c55c_row3_col7\" class=\"data row3 col7\" >11.00</td>\n",
       "      <td id=\"T_0c55c_row3_col8\" class=\"data row3 col8\" >31.96</td>\n",
       "      <td id=\"T_0c55c_row3_col9\" class=\"data row3 col9\" >27.50</td>\n",
       "      <td id=\"T_0c55c_row3_col10\" class=\"data row3 col10\" >10.81</td>\n",
       "      <td id=\"T_0c55c_row3_col11\" class=\"data row3 col11\" >36.40</td>\n",
       "      <td id=\"T_0c55c_row3_col12\" class=\"data row3 col12\" >10.98</td>\n",
       "      <td id=\"T_0c55c_row3_col13\" class=\"data row3 col13\" >22.34</td>\n",
       "      <td id=\"T_0c55c_row3_col14\" class=\"data row3 col14\" >-3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c55c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0c55c_row4_col0\" class=\"data row4 col0\" >llama-7b_r=3</td>\n",
       "      <td id=\"T_0c55c_row4_col1\" class=\"data row4 col1\" >huggyllama/llama-7b</td>\n",
       "      <td id=\"T_0c55c_row4_col2\" class=\"data row4 col2\" >{}</td>\n",
       "      <td id=\"T_0c55c_row4_col3\" class=\"data row4 col3\" >None</td>\n",
       "      <td id=\"T_0c55c_row4_col4\" class=\"data row4 col4\" >nan</td>\n",
       "      <td id=\"T_0c55c_row4_col5\" class=\"data row4 col5\" >nan</td>\n",
       "      <td id=\"T_0c55c_row4_col6\" class=\"data row4 col6\" >5.00</td>\n",
       "      <td id=\"T_0c55c_row4_col7\" class=\"data row4 col7\" >nan</td>\n",
       "      <td id=\"T_0c55c_row4_col8\" class=\"data row4 col8\" >31.11</td>\n",
       "      <td id=\"T_0c55c_row4_col9\" class=\"data row4 col9\" >nan</td>\n",
       "      <td id=\"T_0c55c_row4_col10\" class=\"data row4 col10\" >9.47</td>\n",
       "      <td id=\"T_0c55c_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_0c55c_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_0c55c_row4_col13\" class=\"data row4 col13\" >15.19</td>\n",
       "      <td id=\"T_0c55c_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c55c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_0c55c_row5_col0\" class=\"data row5 col0\" >llama-7b_humanmix_r=0</td>\n",
       "      <td id=\"T_0c55c_row5_col1\" class=\"data row5 col1\" >results/baselines/huggyllama/llama-7b</td>\n",
       "      <td id=\"T_0c55c_row5_col2\" class=\"data row5 col2\" >{}</td>\n",
       "      <td id=\"T_0c55c_row5_col3\" class=\"data row5 col3\" >None</td>\n",
       "      <td id=\"T_0c55c_row5_col4\" class=\"data row5 col4\" >nan</td>\n",
       "      <td id=\"T_0c55c_row5_col5\" class=\"data row5 col5\" >nan</td>\n",
       "      <td id=\"T_0c55c_row5_col6\" class=\"data row5 col6\" >0.00</td>\n",
       "      <td id=\"T_0c55c_row5_col7\" class=\"data row5 col7\" >0.00</td>\n",
       "      <td id=\"T_0c55c_row5_col8\" class=\"data row5 col8\" >22.78</td>\n",
       "      <td id=\"T_0c55c_row5_col9\" class=\"data row5 col9\" >4.35</td>\n",
       "      <td id=\"T_0c55c_row5_col10\" class=\"data row5 col10\" >9.54</td>\n",
       "      <td id=\"T_0c55c_row5_col11\" class=\"data row5 col11\" >0.00</td>\n",
       "      <td id=\"T_0c55c_row5_col12\" class=\"data row5 col12\" >0.00</td>\n",
       "      <td id=\"T_0c55c_row5_col13\" class=\"data row5 col13\" >5.24</td>\n",
       "      <td id=\"T_0c55c_row5_col14\" class=\"data row5 col14\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffde5fff8b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(df\n",
    "        .style\n",
    "        .set_properties(**{'text-align': 'left'})\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c65992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfc = df.copy()\n",
    "dfc.insert(0, 'total_train_samples',  dfc['data_args.subsample_mixture'].apply(\n",
    "    lambda d: sum(list(d.values())) if d else 200000))\n",
    "dfc = dfc[dfc['model_args.model_name_or_path'].apply(\n",
    "    lambda x: 'llama-7b' in x)]\n",
    "display(dfc\n",
    "        .style\n",
    "        .set_properties(**{'text-align': 'left'})\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ce47f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfc = df.copy()\n",
    "\n",
    "total_train_samples = 200000\n",
    "dfc.insert(0, 'total_train_samples',  dfc['data_args.subsample_mixture'].apply(\n",
    "    lambda d: sum(list(d.values())) if d else 200000))\n",
    "dfc = dfc[dfc['total_train_samples'].apply(\n",
    "    lambda x: total_train_samples-20000<x<total_train_samples+20000)]\n",
    "\n",
    "mixtures = [dict(x) for x in dfc['data_args.subsample_mixture']]\n",
    "mixtures = [{k: v/sum(list(d.values())) for k, v in d.items()} for d in mixtures]\n",
    "mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0741ca82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def runif_in_simplex(n):\n",
    "    ''' Return uniformly random vector in the n-simplex '''\n",
    "\n",
    "    k = np.random.exponential(scale=1.0, size=n)\n",
    "    return k / sum(k)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "np.random.seed(4)\n",
    "\n",
    "L = []\n",
    "dataset_name = ['cot', 'dolly', 'flan_v2', 'oasst1']\n",
    "xs = np.arange(4)\n",
    "for _ in range(10):\n",
    "    ys = runif_in_simplex(4)\n",
    "    d = {k: v for k, v in zip(dataset_name, ys)}\n",
    "    L.append(d)\n",
    "    ax.plot(xs, ys)\n",
    "L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ea7782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dirs = []\n",
    "run_dirs = [\n",
    "#     'pythia-1.4b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "#     'pythia-2.8b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "#     'pythia-6.9b_all:200k_mix=cot:97570,dolly:1464,flan_v2:97570,oasst1:3394',\n",
    "    ''\n",
    "]\n",
    "for run_dir in run_dirs:\n",
    "    save_dirs += [(os.path.basename(x), x) \n",
    "                  for x in glob.glob(os.path.join('../results/ft2', run_dir, 'checkpoint-*'))]\n",
    "    break\n",
    "\n",
    "    \n",
    "df = get_eval_results(save_dirs, chat_fmt=None, ft_args_fields=ft_args_fields)\n",
    "# df['model'] = ''\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcb043d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ylabel = 'llama-7b:600k'\n",
    "\n",
    "\n",
    "exp_dir = '../results/oi3'\n",
    "save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "save_dirs += [(os.path.basename(x), x) for x in \n",
    "             glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "df = get_eval_results(save_dirs, chat_fmt=None, ft_args_fields=ft_args_fields)\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "# add base model performance\n",
    "dfc.loc[dfc['model_args.model_name_or_path']=='huggyllama/llama-7b', 'model_args.model_name_or_path'] = 'checkpoint-0'\n",
    "# get steps \n",
    "dfc.insert(0, 'steps', dfc['model_args.model_name_or_path'].apply(lambda x: int(x.split('-')[-1])))\n",
    "dfc = dfc.sort_values('steps')\n",
    "\n",
    "\n",
    "y_labels_list = [\n",
    "    ['MMLU/0-shot',\n",
    "     'MMLU/0-shot_chatfmt',\n",
    "     'MMLU/5-shot',\n",
    "     'MMLU/5-shot_chatfmt',\n",
    "    ],\n",
    "    ['GSM/Direct',\n",
    "     'GSM/Direct_chatfmt',\n",
    "     'GSM/CoT', \n",
    "     'GSM/CoT_chatfmt', \n",
    "    ],\n",
    "    ['BBH/Direct',\n",
    "     'BBH/Direct_chatfmt',\n",
    "     'BBH/CoT',\n",
    "     'BBH/CoT_chatfmt',\n",
    "    ],\n",
    "    ['TydiQA/CB',\n",
    "     'TydiQA/CB_chatfmt',\n",
    "     'TydiQA/GP',\n",
    "     'TydiQA/GP_chatfmt',\n",
    "    ],\n",
    "    ['Codex-Eval/Pass@1',\n",
    "     'Codex-Eval/Pass@1_chatfmt'],\n",
    "    ['MMLU/0-shot',\n",
    "     'GSM/CoT',\n",
    "     'BBH/CoT',],\n",
    "]\n",
    "\n",
    "N = len(y_labels_list)\n",
    "\n",
    "fig, axs = plt.subplots(1,N,figsize=(5*N,5))\n",
    "\n",
    "axs[0].set_ylabel(ylabel, fontsize=20)\n",
    "\n",
    "for axi, y_labels in enumerate(y_labels_list):\n",
    "    ax = axs[axi]\n",
    "\n",
    "    x = dfc['steps']\n",
    "    y_list = []\n",
    "    for y_label in y_labels:\n",
    "        if y_label not in dfc.columns: continue\n",
    "        y = dfc[y_label].to_numpy()\n",
    "        y_list.append(y)\n",
    "        ax.plot(x, y, label=y_label)\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    ax.set_ylim(0, 55)\n",
    "    \n",
    "    \n",
    "# for y_label in ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1']:\n",
    "    \n",
    "#     for chat_fmt in ['', 'chatfmt']:\n",
    "#         col = '_'.join([y_label, chat_fmt]) if chat_fmt else y_label\n",
    "#         y = dfc[col].to_numpy()\n",
    "#         print(f'{col}\\t{y.mean():.2f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3099f05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>model_args.model_name_or_path</th>\n",
       "      <th>data_args.subsample_mixture</th>\n",
       "      <th>MMLU/0-shot</th>\n",
       "      <th>MMLU/0-shot_chatfmt</th>\n",
       "      <th>MMLU/5-shot</th>\n",
       "      <th>MMLU/5-shot_chatfmt</th>\n",
       "      <th>GSM/Direct</th>\n",
       "      <th>GSM/Direct_chatfmt</th>\n",
       "      <th>GSM/CoT</th>\n",
       "      <th>...</th>\n",
       "      <th>BBH/Direct</th>\n",
       "      <th>BBH/Direct_chatfmt</th>\n",
       "      <th>BBH/CoT</th>\n",
       "      <th>BBH/CoT_chatfmt</th>\n",
       "      <th>Codex-Eval/Pass@1</th>\n",
       "      <th>Codex-Eval/Pass@1_chatfmt</th>\n",
       "      <th>TydiQA/CB</th>\n",
       "      <th>TydiQA/CB_chatfmt</th>\n",
       "      <th>TydiQA/GP</th>\n",
       "      <th>TydiQA/GP_chatfmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama-7b</td>\n",
       "      <td>huggyllama/llama-7b</td>\n",
       "      <td>{}</td>\n",
       "      <td>31.861558</td>\n",
       "      <td>32.459764</td>\n",
       "      <td>35.222903</td>\n",
       "      <td>33.057969</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>...</td>\n",
       "      <td>31.652294</td>\n",
       "      <td>32.970313</td>\n",
       "      <td>29.243182</td>\n",
       "      <td>28.425926</td>\n",
       "      <td>11.585366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.50548</td>\n",
       "      <td>10.349886</td>\n",
       "      <td>40.403106</td>\n",
       "      <td>38.564264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_name model_args.model_name_or_path data_args.subsample_mixture  \\\n",
       "0  llama-7b           huggyllama/llama-7b                          {}   \n",
       "\n",
       "   MMLU/0-shot  MMLU/0-shot_chatfmt  MMLU/5-shot  MMLU/5-shot_chatfmt  \\\n",
       "0    31.861558            32.459764    35.222903            33.057969   \n",
       "\n",
       "   GSM/Direct  GSM/Direct_chatfmt  GSM/CoT  ...  BBH/Direct  \\\n",
       "0         6.0                 5.5     10.5  ...   31.652294   \n",
       "\n",
       "   BBH/Direct_chatfmt    BBH/CoT  BBH/CoT_chatfmt  Codex-Eval/Pass@1  \\\n",
       "0           32.970313  29.243182        28.425926          11.585366   \n",
       "\n",
       "   Codex-Eval/Pass@1_chatfmt  TydiQA/CB  TydiQA/CB_chatfmt  TydiQA/GP  \\\n",
       "0                        0.0    9.50548          10.349886  40.403106   \n",
       "\n",
       "   TydiQA/GP_chatfmt  \n",
       "0          38.564264  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_labels = [\n",
    "    'Answer:\\n<|assistant|>\\nThe answer is:',\n",
    "    'Answer:\\n<|assistant|>\\n',\n",
    "    '<|assistant|>\\nAnswer:',\n",
    "    '<|assistant|>\\nThe answer is:',\n",
    "]\n",
    "x_labels = [f'v{i+1}:\\n{x}' for i,x in enumerate(x_labels)]\n",
    "\n",
    "dfc = df.copy()\n",
    "dfc = df.filter(regex='_v|run')\n",
    "\n",
    "runs = dfc['run_name'].to_list()[::-1]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for axi, task in enumerate(['MMLU/0-shot', 'MMLU/5-shot']):\n",
    "\n",
    "    ax = axs[axi]\n",
    "    cols = [f'{task}_v{x}' for x in [1, 2, 3, 4]]\n",
    "    x = np.arange(len(x_labels))\n",
    "\n",
    "    width = .25\n",
    "    multiplier = 0\n",
    "\n",
    "    for run in runs:\n",
    "        offset = width*multiplier\n",
    "        y = dfc[dfc['run_name']==run][cols].to_numpy().squeeze()\n",
    "        rects = ax.bar(x+offset, y, width, label=run)\n",
    "        ax.bar_label(rects, padding=3, fmt='{:.2f}')\n",
    "        multiplier += 1\n",
    "\n",
    "    ax.set_title(task)\n",
    "    ax.set_xticks(x+width)\n",
    "    ax.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_ylim(0, 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa6ba4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "total_data_points = 200000 # 10000, 50000, 100000, 200000\n",
    "subsample_mixture_list = []\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {'cot': 0.48785105, 'flan_v2': 0.48785105, 'dolly': 0.00732313, 'oasst1': 0.01697478}.items())\n",
    "] # humanmix mixture.\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.360595703125, \"dolly\": 0.0021991729736328125, \"flan_v2\": 0.63037109375, \"oasst1\": 0.0016956329345703125}.items())\n",
    "] # pythia-1.4b humanmix_uniform:200k_doremiv1.json\n",
    "\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.2254638671875, \"dolly\": 0.01409149169921875, \"flan_v2\": 0.1739501953125, \"oasst1\": 0.59423828125}.items())\n",
    "] # pythia-1.4b humanmix_uniform:200k_doremiv2.json\n",
    "\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.08563232421875, \"dolly\": 0.54296875, \"flan_v2\": 0.347900390625, \"oasst1\": 0.0103302001953125}.items())\n",
    "] # llama-7b_humanmix_uniform:200k_doremiv2.json\n",
    "subsample_mixture_list += [\n",
    "    dict((k, int(v*total_data_points)) for k, v in\n",
    "    {\"cot\": 0.0316162109375, \"dolly\": 0.204833984375, \"flan_v2\": 0.40966796875, \"oasst1\": 0.40966796875}.items()\n",
    "        )] # llama-7b_humanmix_uniform:600k_doremiv2.json\n",
    "subsample_mixture_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "6323+40966+81933+81933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_dir = 'results/ft1'\n",
    "\n",
    "# d = {\n",
    "#     'bbh_s=0': 'bbh_s=3',\n",
    "#     'gsm': 'gsm_s=8_cot',\n",
    "#     'mmlu': 'mmlu_s=0',\n",
    "#     'tydiqa_cb': 'tydiqa_s=1_cb',\n",
    "#     'tydiqa_gp': 'tydiqa_s=1_gp',\n",
    "# }\n",
    "\n",
    "# d.update({k+'_chatfmt': v+'_chatfmt' for k,v in d.items()})\n",
    "\n",
    "# for subdir in os.listdir(exp_dir):    \n",
    "#     for task_name_src, task_name_tgt in d.items():\n",
    "#         path_src = os.path.join(exp_dir, subdir, 'eval', task_name_src)\n",
    "#         path_tgt = os.path.join(exp_dir, subdir, 'eval', task_name_tgt)\n",
    "#         if os.path.isdir(path_src):\n",
    "# #             os.rename(path_src, path_tgt)\n",
    "#             print(path_src)\n",
    "#             print(path_tgt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27138820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfc = df.copy()\n",
    "dfc.insert(0, 'total_train_samples',  dfc['data_args.subsample_mixture'].apply(\n",
    "    lambda d: sum(list(d.values())) if d else 200000))\n",
    "# dfc[dfc['total_train_samples'].apply(\n",
    "#     lambda x: total_train_samples-500<x<total_train_samples+500)]\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad6edc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dfc = df.copy()\n",
    "dfc.columns = [x.split('_')[0] for x in dfc.columns]\n",
    "def get_dataset(x):\n",
    "    x = x.split('+')\n",
    "    if len(x) == 1:\n",
    "        return ''\n",
    "    else:\n",
    "        d = x[1]\n",
    "        d = d.replace('_', '')\n",
    "        return d\n",
    "dfc['Dataset'] = dfc['Model'].apply(get_dataset)\n",
    "order_list = ['',\n",
    " 'superni', 'cot', 'flanv2', 'dolly', 'oasst1',\n",
    " 'selfinstruct', 'unnaturalinstructions', 'stanfordalpaca', 'codealpaca', 'gpt4alpaca',\n",
    " 'baize', 'sharegpt', 'humanmix', 'h+gptmix']\n",
    "dfc['order'] = dfc['Dataset'].map({v: i for i, v in enumerate(order_list)})\n",
    "dfc = dfc.sort_values('order')\n",
    "dfc = dfc.drop(columns=['order', 'Dataset'])\n",
    "dfc = dfc.reset_index(drop=True)\n",
    "\n",
    "display(dfc[dfc['Model'].apply(lambda x: 'llama-7b' in x and ':' not in x)]\n",
    "        .style\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=1))\n",
    "\n",
    "\n",
    "display(dfc[dfc['Model'].apply(\n",
    "            lambda x: 'llama-7b' in x and (\n",
    "                ':' in x or any(c in x for c in ['dolly', 'oasst1', 'cot', 'flan'])\n",
    "                or 'humanmix' in x\n",
    "            )\n",
    "        )]\n",
    "        .style\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=1))\n",
    "\n",
    "display(dfc[dfc['Model'].apply(lambda x: 'llama2-7b' in x or 'llama-7b'==x)]\n",
    "        .style\n",
    "        .background_gradient(cmap ='coolwarm')\n",
    "        .format(precision=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba1a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0588857",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"dataset\": \"flan_v2\", \"id\": \"flan_v2_2\", \"messages\": [{\"role\": \"user\", \"content\": \"Tratatul de la Lisabona nu face inutil referire, pentru prima dat n istoria Uniunii Europene, la drepturile persoanelor care aparin acestor minoriti i la valorile proprii acestora.\\n\\nWhich language is this?\\n\"}, {\"role\": \"assistant\", \"content\": \"Romanian\"}]}\n",
    "{\"dataset\": \"flan_v2\", \"id\": \"flan_v2_2\", \"messages\": [{\"role\": \"user\", \"content\": \"Tratatul de la Lisabona nu face inutil referire, pentru prima dat\\u0103 \\u00een istoria Uniunii Europene, la drepturile persoanelor care apar\\u0163in acestor minorit\\u0103\\u0163i \\u015fi la valorile proprii acestora.\\n\\nWhich language is this?\\n\"}, {\"role\": \"assistant\", \"content\": \"Romanian\"}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7702c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.1f}'.format):\n",
    "    display(df[['Model']+[x for x in df.columns if 'chatfmt' in x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82eac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.float_format', '{:0.3f}'.format):\n",
    "    display(df[[x for x in df.columns if 'chatfmt' not in x]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "models = []\n",
    "models += ['t5-small', 't5-base', 't5-large', 't5-3b', 't5-11b']\n",
    "models += ['huggyllama/llama-7b']\n",
    "save_dirs = [f'../results/baselines/{x}/eval/gsm/' for x in models]\n",
    "\n",
    "data = []\n",
    "for model, save_dir in zip(models, save_dirs):\n",
    "    logfile_path = glob.glob(os.path.join(save_dir, '*.out'))[0]\n",
    "    out = get_run_statistics(logfile_path)\n",
    "    with open(os.path.join(save_dir, 'metrics.json'), 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    data.append((model, out['cpu_time']/60/60, out['avg_mem'], out['max_mem'], metrics['exact_match']))\n",
    "    \n",
    "\n",
    "import pandas as pd\n",
    "columns = ['name', 'cpu_time (hr)', 'avg_mem', 'max_mem', 'exact_match']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
