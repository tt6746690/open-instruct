{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da1794b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dccstor/data-pruning/wpq/github/mitibm2023/external/rosemary/src/rosemary/__init__.py:25: UserWarning: Install `torch` for functionalities dependent on torch\n",
      "  warn(f'Install `torch` for functionalities dependent on torch')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'x86_64', 'cluster': 'ccc', 'queue': 'alt_7d'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "import re\n",
    "from llm.submit import (\n",
    "    multiline_to_singleline,\n",
    "    submit_job_ccc,\n",
    "    submit_job_aimos,\n",
    "    submit_job,\n",
    "        get_run_statistics)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import datetime\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import base64\n",
    "string_to_alphanumeric = lambda s: base64.urlsafe_b64encode(s.encode('utf-8')).decode('utf-8')\n",
    "alphanumeric_to_string = lambda a: base64.urlsafe_b64decode(a).decode('utf-8')\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm, shell_scripts_template_lsf, get_host_info, move_lsf_job_summary_to_save_dir\n",
    "from note_pruning_analysis import open_instruct_dir\n",
    "import getpass\n",
    "\n",
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "info = get_host_info()\n",
    "info.update({'queue': queue})\n",
    "arch, cluster = info['arch'], info['cluster']\n",
    "print(info)\n",
    "\n",
    "os.environ['TORCHELASTIC_ERROR_FILE'] = os.path.join(os.getcwd(), 'torchelastic_error_file') \n",
    "\n",
    "## jobs submitted in notebook inherits env variables.\n",
    "cache_dir = os.path.normpath(os.path.join(os.getcwd(), '../../../../mitibm2023/cache')) \\\n",
    "    if arch == 'ppc64le' else '/dccstor/data-pruning/cache'\n",
    "os.environ['WANDB_DIR'] = cache_dir\n",
    "os.makedirs(os.environ['WANDB_DIR'], exist_ok=True, mode=0o777)\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_PROJECT'] = 'mitibm'\n",
    "##\n",
    "##\n",
    "\n",
    "shell_scripts_template = shell_scripts_template_slurm \\\n",
    "    if arch == 'ppc64le' else shell_scripts_template_lsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c421d1",
   "metadata": {},
   "source": [
    "# DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c09b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/oi2/llama-7b_sharegptv2_ep=2 using 6 GPUs, 1 batch size per GPU, 1 gradient accumulation steps, 30 effective batch size.\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp7pssto1b', 'job_id': 1354503}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2p8zx1bt', 'job_id': 1354504}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2_mpillk', 'job_id': 1354505}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm\n",
    "debug = False\n",
    "if debug:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'INFO'\n",
    "    os.environ['NCCL_DEBUG'] = 'INFO'\n",
    "else:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'WARNING'\n",
    "    os.environ['NCCL_DEBUG'] = ''\n",
    "num_cpus = 144 if arch == 'ppc64le' else 32\n",
    "cpu_mem =  650 if arch == 'ppc64le' else 64\n",
    "\n",
    "preprocessing_num_workers = 32\n",
    "report_to = 'wandb'\n",
    "mixed_precision = 'bf16' if arch == 'x86_64' else 'fp16'\n",
    "torch_dtype = 'bfloat16' if arch=='x86_64' else 'float32'\n",
    "gradient_checkpointing = True\n",
    "use_fast_tokenizer = True\n",
    "hf_models_dir = 'results/baselines/'\n",
    "resume_from_checkpoint = True # resume from latest checkpoint if exists, otherwise train from scratch\n",
    "num_train_epochs = 2\n",
    "checkpointing_steps = 300 # (50_000 / 32) * 2 / 6 ~= 500 (data size of 50k, bsz=32, ep=2, total save 6 times at most)\n",
    "max_train_steps = None\n",
    "subsample_inds_file_list = [None]\n",
    "dataloader_sampler = 'RandomSampler'\n",
    "overwrite_cache = True\n",
    "\n",
    "\n",
    "# #####\n",
    "# job_name = 'dpo1'\n",
    "\n",
    "# # model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-410m-deduped'; max_seq_length = 2048; abbr_model_name = 'pythia-410m'\n",
    "# # model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "\n",
    "# train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "\n",
    "\n",
    "# M = 60_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 20_000\n",
    "# M = 50_000; pacing_fn_list = [f'prune_size={M}_ep=5']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "    (10_000, 10),\n",
    "#     (30_000, 3),\n",
    "]]\n",
    "\n",
    "gen_output_md = 'llama7br512p4096'\n",
    "# gen_output_md = 'llama7b+sharegptv2ep2+r512p4096'\n",
    "# gen_output_model_name = 'all-mpnet-base-v2'\n",
    "\n",
    "scoring_fn_list = []\n",
    "scoring_fn_list += ['random_s=0']\n",
    "# scoring_fn_list += ['random_s=1']\n",
    "scoring_fn_list += [ \n",
    "    f'dppmap_k=vmf_gamma=1_kmd={gen_output_md}_kemb=grad+rp+loraB',\n",
    "    f'dppmap_k=rbf_gamma=1e-3_kmd={gen_output_md}_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1_kmd=mpnet_kemb=text+embedding',\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'dpo2_{dataset}:{abbr_model_name}'\n",
    "    \n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12\n",
    "# nodes = 2; num_gpus = 1; gpu_type = 'v100'; job_duration = 6; cpu_mem = 100; num_cpus = 32; max_train_steps = 5; checkpointing_steps = 2; report_to = 'tensorboard'\n",
    "    \n",
    "#####\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs = 1 # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "use_deepspeed = True\n",
    "deepspeed_config_file = 'ds_configs/stage3_no_offloading_accelerate.conf'\n",
    "\n",
    "per_device_train_batch_size = 1; total_batch_size = 32\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"{effective_batch_size} effective batch size.\")\n",
    "\n",
    "# reference: https://gist.github.com/pacman100/1cb1f17b2f1b3139a63b764263e70b25\n",
    "launcher = f\"\"\"accelerate launch \\\n",
    "    --mixed_precision {mixed_precision} \\\n",
    "    --num_machines {nodes} \\\n",
    "    --num_processes {num_gpus*nodes} \\\n",
    "    {'--use_deepspeed' if use_deepspeed else ''} \\\n",
    "    {'--deepspeed_config_file '+deepspeed_config_file if use_deepspeed else ''} \\\n",
    "    {'--main_process_ip $master_addr' if use_deepspeed else ''} \\\n",
    "    {'--main_process_port $master_port' if use_deepspeed else ''} \\\n",
    "    {'--machine_rank $SLURM_PROCID' if use_deepspeed else ''} \\\n",
    "    {'--rdzv_backend c10d' if use_deepspeed and nodes>1 else ''} \\\n",
    "    {'--deepspeed_multinode_launcher standard' if use_deepspeed and nodes>1 else ''} \\\n",
    "\"\"\"\n",
    "\n",
    "cmds = []\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    subsample_inds_file_list,\n",
    ")\n",
    "\n",
    "output_dirname_list = []\n",
    "for (subsample_inds_file,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{dataset}\"\n",
    "    if any(job_name == y for y in ['dpo1']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "\n",
    "    if subsample_inds_file:\n",
    "        assert(num_train_epochs==1)\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                s = f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "\n",
    "    if subsample_inds_file is not None:\n",
    "        assert(dataloader_sampler=='SequentialSampler')\n",
    "        assert(num_train_epochs==1)\n",
    "    else:\n",
    "        assert(dataloader_sampler=='RandomSampler')\n",
    "\n",
    "    output_dir = os.path.join('results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join('results', job_name), exist_ok=True)\n",
    "    wandb_run_name = output_dir.replace('results/', '')\n",
    "\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {f'cd .. && CUDA_VISIBLE_DEVICES={os.environ[\"CUDA_VISIBLE_DEVICES\"]} ' if test_run else ''}{launcher}\n",
    "        open_instruct/dpo_tune.py \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --tokenizer_name {model_name_or_path} \\\n",
    "        {'--use_slow_tokenizer' if not  use_fast_tokenizer else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        --train_file {train_file} \\\n",
    "        --max_seq_length {max_seq_length} \\\n",
    "        {'--subsample_inds_file '+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        --dataloader_sampler {dataloader_sampler} \\\n",
    "        --preprocessing_num_workers {preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size {per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
    "        --learning_rate 5e-7 \\\n",
    "        --lr_scheduler_type linear \\\n",
    "        --warmup_ratio 0.1 \\\n",
    "        --weight_decay 0. \\\n",
    "        --num_train_epochs {num_train_epochs} \\\n",
    "        --with_tracking \\\n",
    "        {'--report_to \"'+str(report_to)+'\"' if report_to else ''} \\\n",
    "        --checkpointing_steps {checkpointing_steps} \\\n",
    "        {'--max_train_steps '+str(max_train_steps) if max_train_steps else ''} \\\n",
    "        {'--resume_from_checkpoint' if resume_from_checkpoint else ''} \\\n",
    "        {'--low_cpu_mem_usage' if not use_deepspeed else ''} \\\n",
    "        {'--overwrite_cache' if overwrite_cache else ''} \\\n",
    "        --logging_steps 1 \\\n",
    "        --output_dir {output_dir}\n",
    "    \"\"\"\n",
    "    # if test_run:\n",
    "    #     print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    if test_run:\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64': # ccc\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "        queue=queue,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda1f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prune: {1k@10, 10k@3}, datasets={dolly, stanford_alpaca}, scoring={random, dppmapx2}\n",
    "# need to gen curriculum for 50k sft datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b79b9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_dpo.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce604bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=5\n",
      "+ cd ..\n",
      "+ CUDA_VISIBLE_DEVICES=2,5\n",
      "+ accelerate launch --mixed_precision fp16 --num_machines 1 --num_processes 2 --use_deepspeed --deepspeed_config_file ds_configs/stage3_no_offloading_accelerate.conf open_instruct/dpo_tune.py --model_name_or_path results/baselines/huggyllama/llama-7b --tokenizer_name results/baselines/huggyllama/llama-7b --gradient_checkpointing --train_file data/processed/ultrafeedback/ultrafeedback_data.jsonl --max_seq_length 2048 --preprocessing_num_workers 32 --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --learning_rate 5e-7 --lr_scheduler_type linear --warmup_ratio 0.1 --weight_decay 0. --num_train_epochs 2 --with_tracking --report_to tensorboard --checkpointing_steps 500 --logging_steps 1 --output_dir results/dpo1/jpt_llama-7b_ultrafeedback\n",
      "[2024-01-08 20:41:08,547] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "[2024-01-08 20:41:17,396] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-08 20:41:17,400] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:662:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,611] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 1\n",
      "Local process index: 1\n",
      "Device: cuda:1\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 251.17it/s]\n",
      "01/08/2024 20:41:25 - WARNING - datasets.builder - Found cached dataset json (/gpfs/u/scratch/PTFM/PTFMqngp/huggingface_cache/datasets/json/default-201ebfceee303348/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 252.78it/s]\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:26,493] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 6.74B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.74s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:16<00:00,  8.11s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:43,556] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 13.48B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.60s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "01/08/2024 20:42:20 - INFO - accelerate.accelerator - Updating DeepSpeed's gradient accumulation steps to 16 from 1.\n",
      "[2024-01-08 20:42:20,382] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.1+23a11a39, git-hash=23a11a39, git-branch=master\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 1\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "[2024-01-08 20:42:20,751] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n",
      "[2024-01-08 20:42:20,779] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\n",
      "[2024-01-08 20:42:20,891] [INFO] [utils.py:786:see_memory_usage] Stage 3 initialize beginning\n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 14.16 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.9 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:118:__init__] Reduce bucket size 16777216\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:119:__init__] Prefetch bucket size 15099494\n",
      "[2024-01-08 20:42:20,995] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 13.64 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n",
      "[2024-01-08 20:42:21,139] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.76 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:21,240] [INFO] [utils.py:786:see_memory_usage] Before creating fp16 partitions\n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.4 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:23,090] [INFO] [utils.py:786:see_memory_usage] After creating fp16 partitions: 4\n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.4 GB         CA 14.6 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.99 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,190] [INFO] [utils.py:786:see_memory_usage] Before creating fp32 partitions\n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.39 GB         CA 14.6 GB         Max_CA 15 GB \n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.81 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,742] [INFO] [utils.py:786:see_memory_usage] After creating fp32 partitions\n",
      "[2024-01-08 20:42:23,743] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 26.61 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,744] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 116.15 GB, percent = 16.7%\n",
      "[2024-01-08 20:42:23,836] [INFO] [utils.py:786:see_memory_usage] Before initializing optimizer states\n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 25.94 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 117.28 GB, percent = 16.8%\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 1; 31.75 GiB total capacity; 25.93 GiB already allocated; 3.34 GiB free; 27.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 0; 31.75 GiB total capacity; 25.94 GiB already allocated; 3.21 GiB free; 27.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 409110) of binary: /gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/python3.10\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 964, in launch_command\r\n",
      "    deepspeed_launcher(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 687, in deepspeed_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "open_instruct/dpo_tune.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 409111)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 409110)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_dpo.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c8b",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune_trainer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "19aebd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/baselines/huggyllama/llama-7b using 8 GPUs, 1 batch size per GPU, 16 gradient accumulation steps, Effective batch size 128\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 128,\n",
      "    \"cpu_mem\": 768,\n",
      "    \"num_gpus\": 8,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_wizardlm50k:llama-7b -mem 768g -cores 1x128+8 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=8 --rdzv_backend=c10d --master_port=0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/wizardlm/wizardlm50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=16 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/wizardlm50k/random_s=0/inds_prune_size=60000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1395067}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 128,\n",
      "    \"cpu_mem\": 768,\n",
      "    \"num_gpus\": 8,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_wizardlm50k:llama-7b -mem 768g -cores 1x128+8 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=8 --rdzv_backend=c10d --master_port=0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/wizardlm/wizardlm50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=16 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/wizardlm50k/dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding/inds_prune_size=60000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1395068}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 128,\n",
      "    \"cpu_mem\": 768,\n",
      "    \"num_gpus\": 8,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_wizardlm50k:llama-7b -mem 768g -cores 1x128+8 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=8 --rdzv_backend=c10d --master_port=0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/wizardlm/wizardlm50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=16 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/wizardlm50k/dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB/inds_prune_size=60000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1395069}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "add_hardwarespec_to_dirname = False\n",
    "save_strategy = 'steps'\n",
    "save_steps = 200 if getpass.getuser() in ('PTFMqngp', 'wpq') else 1_000_000\n",
    "save_total_limit = 1\n",
    "preprocessing_num_workers = 32\n",
    "evaluation_strategy = 'no' # set do_eval=False\n",
    "eval_steps = save_steps\n",
    "report_to = 'tensorboard wandb'\n",
    "suffix = None\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0.03\n",
    "dataloader_sampler = None\n",
    "hf_models_dir = 'results/baselines/'\n",
    "subsample_inds_file_list = [None]\n",
    "max_train_samples_list = [None]\n",
    "num_train_epochs_list = [1]\n",
    "scoring_fn_and_pacing_fn = None\n",
    "\n",
    "\n",
    "# ########### sft baselines\n",
    "\n",
    "\n",
    "# job_name = 'oi2'; num_train_epochs_list = [2] \n",
    "# # model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "\n",
    "# # train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca'; \n",
    "# # train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# # train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2'; max_train_samples_list=[100_000]\n",
    "\n",
    "# ## 50k sft datasets\n",
    "# # train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# # train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# # train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "# # train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "\n",
    "# # train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2'; max_train_samples_list=[100_000]\n",
    "# ###########\n",
    "\n",
    "\n",
    "############ pruning runs\n",
    "\n",
    "# model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048; gen_output_md = 'mistral7br512p4096'\n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048; gen_output_md = 'llama7br512p4096'\n",
    "\n",
    "\n",
    "# # 50k sft datasets\n",
    "# dataset = 'flan_v250k'; train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca50k'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "dataset = 'wizardlm50k'; train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "# dataset = 'sharegpt50k'; train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "# dataset = 'ultrachat50k'; train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "\n",
    "# dataset = 'flan_v2'; train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca';\n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# dataset = 'wizardlmv2'; train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2';\n",
    "# dataset = 'sharegptv2'; train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2';\n",
    "# dataset = 'ultrachat200kv2'; train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2';\n",
    "\n",
    "\n",
    "# dataset = 'oasst1'; train_file = 'data/processed/oasst/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# dataset = 'open_orca_slim'; train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; \n",
    "# dataset = 'tulu_v2'; train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2';\n",
    "        \n",
    "# M = 80_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 40_000\n",
    "# M = 40_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 20_000\n",
    "# M = 30_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [\n",
    "    f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "#         (10_000, 10), # 1k\n",
    "#         (30_000, 3),  # 10k\n",
    "        (60_000, 3),  # 20k\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "scoring_fn_list = [\n",
    "    'random_s=0',\n",
    "#     'random_s=1',\n",
    "#     'log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n',\n",
    "#     'ifd_neg', 'log_pmi_neg',\n",
    "#     'numtoks_input_neg', 'numtoks_output_neg', 'numtoks_total_neg',\n",
    "#     f'dppmap_k=vmf_gamma=1_kmd=mpnet', #_kemb=text+embedding',\n",
    "    f'dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding',\n",
    "    f'dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB',\n",
    "]\n",
    "\n",
    "scoring_fn_list += [ # vary kernel embedding model \n",
    "#     f'dppmap_k=vmf_gamma=auto{subset_size}_kmd={kmd}_kemb=grad+rp+loraB'\n",
    "#     for kmd in ['llama7br256p4096', 'llama7br512p4096', 'pythia1br512p4096']\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'oi5_{dataset}:{abbr_model_name}'\n",
    "############ \n",
    "\n",
    "    \n",
    "# add_hardwarespec_to_dirname = True\n",
    "# job_name += '_debug' # wpq debug\n",
    "# max_train_samples_list=[128*2]\n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "debug_mode = test_run\n",
    "\n",
    "if arch == 'x86_64':\n",
    "    nodes = 1; num_gpus = 8; gpu_type = 'a100_80gb'; job_duration = 6\n",
    "    num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus); preprocessing_num_workers = 128 # tok takes quite a bit.\n",
    "    per_device_train_batch_size = 1\n",
    "    gradient_checkpointing = False\n",
    "    mixed_precision = 'bf16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = True \n",
    "    save_model_torch_dtype = 'bfloat16' # typically save fp32 weights, but for disk space sake, convert to bf16.\n",
    "else:\n",
    "    nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_checkpointing = True\n",
    "    mixed_precision = 'fp16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = False\n",
    "    save_model_torch_dtype = None\n",
    "\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs_list = [1] # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "overwrite_output_dir = True if test_run else False # always continue from ckpt if run from cluster.\n",
    "\n",
    "total_batch_size = 128\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "optimizer = 'adamw_hf'\n",
    "\n",
    "deepspeed = ''; fsdp = False if num_gpus == 1 else \"full_shard auto_wrap\" \n",
    "if 'gpt2' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPT2Block'\n",
    "elif 'llama' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'LlamaDecoderLayer'\n",
    "elif 'mpt' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MPTBlock'\n",
    "elif 'pythia' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPTNeoXLayer'        \n",
    "elif 'mistral' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MistralDecoderLayer'\n",
    "else: raise ValueError('Not sure how to set `fsdp_transformer_layer_cls_to_wrap`')\n",
    "    \n",
    "# deepspeed = './ds_configs/ds_zero3_cpu_offload.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/ds_zero3.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/stage3_no_offloading.conf'; fsdp = False # error with loading... something wrong with the config.\n",
    "# fsdp = False; deepspeed = False\n",
    "\n",
    "if fsdp and deepspeed:\n",
    "    raise ValueError('either fsdp or deepspeed, not both')\n",
    "\n",
    "use_lora = False\n",
    "lora_rank = 256 \n",
    "lora_alpha = lora_rank \n",
    "lora_dropout = 0.05\n",
    "if use_lora:\n",
    "    abbr_model_name += f'+lora(r={lora_rank},a={lora_alpha})'\n",
    "load_in_8bit = False\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"Effective batch size {effective_batch_size}\")\n",
    "\n",
    "\n",
    "if nodes == 1:\n",
    "    exe = 'python' if num_gpus==1 else \\\n",
    "        f\"torchrun --nnodes 1 --nproc_per_node={num_gpus} --rdzv_backend=c10d --master_port=0\" # assigns random port. https://github.com/pytorch/pytorch/issues/73320\n",
    "else:\n",
    "    exe = f\"torchrun --nnodes={nodes} --nproc_per_node={num_gpus} --rdzv-id=${'SLURM_JOB_ID' if arch == 'ppcle64' else 'LSB_JOBID'} --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT\"\n",
    "\n",
    "if test_run:\n",
    "    exe = f\"CUDA_VISIBLE_DEVICES={','.join(map(str, range(num_gpus)))} {exe}\"\n",
    "if test_run and debug_mode:\n",
    "    exe = 'TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO ' + exe\n",
    "    error_file = os.path.join(open_instruct_dir, 'scripts', 'error_file')\n",
    "    exe = f'TORCHELASTIC_ERROR_FILE={error_file} {exe}'\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "options_list = itertools.product(\n",
    "    num_train_epochs_list,\n",
    "    subsample_inds_file_list,\n",
    "    max_train_samples_list,\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "output_dirname_list = []\n",
    "for (num_train_epochs,\n",
    "     subsample_inds_file,\n",
    "     max_train_samples,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{abbr_train_file}\"\n",
    "    if max_train_samples:\n",
    "        output_dirname += f\":{int(max_train_samples/1000)}k\"\n",
    "            \n",
    "    if any(job_name == y for y in ['oi2']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "        \n",
    "    if subsample_inds_file:\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                return f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            else:\n",
    "                return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "            \n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "            \n",
    "    if add_hardwarespec_to_dirname:\n",
    "        output_dirname += \\\n",
    "            ('_fsdp='+fsdp.split(' ')[0] if fsdp else '')+\\\n",
    "            ('_deepspeed='+os.path.basename(deepspeed).split('.')[0] if deepspeed else '')+\\\n",
    "            ('_gradckpt='+str(gradient_checkpointing) if gradient_checkpointing else '')+\\\n",
    "            '_mbsz='+str(per_device_train_batch_size)+\\\n",
    "            ('_dtype='+torch_dtype if torch_dtype is not None else '')+\\\n",
    "            ('_mp='+str(mixed_precision) if mixed_precision else '_mp=none')+\\\n",
    "            '_seqlen='+str(max_seq_length)+\\\n",
    "            '_nodes='+str(nodes)+\\\n",
    "            '_ngpus='+str(num_gpus)+\\\n",
    "            ('_fa2' if use_flash_attn else '')\n",
    "    if suffix:\n",
    "        output_dirname += suffix\n",
    "    output_dir = os.path.join(open_instruct_dir, 'results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join(open_instruct_dir, 'results', job_name), exist_ok=True)\n",
    "    if arch == 'x86_64':\n",
    "        wandb_run_name = 'ccc'+output_dir[output_dir.find('results'):][7:] # e.g., ccc/oi2/run_name\n",
    "    else:\n",
    "        wandb_run_name = output_dir.replace('results/', '') # e.g., oi2/run_name\n",
    "    \n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {'cd .. && ' if test_run else ''}{exe}\n",
    "        open_instruct/finetune_trainer.py \\\n",
    "        --model_name_or_path={model_name_or_path} \\\n",
    "        --tokenizer_name={model_name_or_path} \\\n",
    "        {'--load_in_8bit' if load_in_8bit else ''} \\\n",
    "        --use_fast_tokenizer=True \\\n",
    "        --train_file={train_file} \\\n",
    "        --max_seq_length={max_seq_length} \\\n",
    "        {'--max_train_samples='+str(max_train_samples) if max_train_samples else ''} \\\n",
    "        {'--use_lora' if use_lora else ''} \\\n",
    "        {'--lora_rank='+str(lora_rank) if use_lora else ''} \\\n",
    "        {'--lora_alpha='+str(lora_alpha) if use_lora else ''} \\\n",
    "        {'--lora_dropout='+str(lora_dropout) if use_lora else ''} \\\n",
    "        --do_train \\\n",
    "        --preprocessing_num_workers={preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size={per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
    "        --learning_rate=2e-5 \\\n",
    "        --lr_scheduler_type={lr_scheduler_type} \\\n",
    "        --warmup_ratio={warmup_ratio} \\\n",
    "        --weight_decay=0. \\\n",
    "        --optim={optimizer} \\\n",
    "        --evaluation_strategy={evaluation_strategy} \\\n",
    "        {'--eval_steps='+str(eval_steps) if eval_steps else ''} \\\n",
    "        {'--report_to '+str(report_to) if report_to else ''} \\\n",
    "        --run_name {wandb_run_name} \\\n",
    "        --logging_strategy=steps \\\n",
    "        --logging_first_step \\\n",
    "        --logging_steps=1 \\\n",
    "        --save_strategy={save_strategy} \\\n",
    "        --save_steps={save_steps} \\\n",
    "        --save_total_limit={save_total_limit} \\\n",
    "        --num_train_epochs={num_train_epochs} \\\n",
    "        --ddp_timeout=7200 \\\n",
    "        {'--fsdp=\"'+fsdp+'\"' if fsdp else ''} \\\n",
    "        {'--fsdp_transformer_layer_cls_to_wrap=\"'+fsdp_transformer_layer_cls_to_wrap+'\"' \n",
    "            if fsdp else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        {'--torch_dtype='+str(torch_dtype) if torch_dtype else ''} \\\n",
    "        {'--save_model_torch_dtype='+str(save_model_torch_dtype) if save_model_torch_dtype else ''} \\\n",
    "        --dataloader_num_workers=8 \\\n",
    "        {f'--{mixed_precision}=True' if mixed_precision else ''} \\\n",
    "        {f'--tf32=True' if use_tf32 else ''} \\\n",
    "        {'--overwrite_output_dir' if overwrite_output_dir else ''} \\\n",
    "        {'--deepspeed='+deepspeed if deepspeed else ''} \\\n",
    "        {'--subsample_inds_file='+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        {'--dataloader_sampler '+str(dataloader_sampler) if dataloader_sampler else ''} \\\n",
    "        --use_flash_attn {'True' if use_flash_attn else 'False'} \\\n",
    "        --low_cpu_mem_usage \\\n",
    "        --overwrite_cache \\\n",
    "        --output_dir=\"{output_dir}\" \\\n",
    "    \"\"\" \n",
    "    #  --overwrite_cache   # if delete a dataset and need to refresh cache\n",
    "\n",
    "    if test_run:\n",
    "        print()\n",
    "        print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64':\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        queue=queue,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12fc2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_sft.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed0c2894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ cd ..\n",
      "+ TORCHELASTIC_ERROR_FILE=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/error_file\n",
      "+ TORCH_CPP_LOG_LEVEL=INFO\n",
      "+ NCCL_DEBUG=INFO\n",
      "+ LOGLEVEL=INFO\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/oasst1/oasst1_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=32 --per_device_train_batch_size=1 --gradient_accumulation_steps=128 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=200 --report_to tensorboard wandb --run_name /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=200 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --overwrite_output_dir --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl --dataloader_sampler SequentialSampler --use_flash_attn True --low_cpu_mem_usage --overwrite_cache --output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10\n",
      "[2024-01-19 02:04:37,834] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Saving args dict to /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10.args.json\n",
      "01/19/2024 02:04:39 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "01/19/2024 02:04:39 - INFO - __main__ - Training parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=8,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_sampler=SequentialSampler,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=7200,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=200.0,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=128,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10/runs/Jan19_02-04-39_cccxc552,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1.0,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard', 'wandb'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=True,\n",
      "save_steps=200,\n",
      "save_strategy=steps,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=True,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "Using custom data configuration default-b03eccd42e843020\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Using custom data configuration default-b03eccd42e843020\n",
      "Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "[INFO|configuration_utils.py:715] 2024-01-19 02:04:39,135 >> loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "[INFO|configuration_utils.py:777] 2024-01-19 02:04:39,136 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3118] 2024-01-19 02:04:39,229 >> loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1222] 2024-01-19 02:04:39,229 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[WARNING|modeling_utils.py:1304] 2024-01-19 02:04:39,230 >> You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:39,230 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.07it/s]\n",
      "[INFO|modeling_utils.py:3950] 2024-01-19 02:04:41,778 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:3958] 2024-01-19 02:04:41,778 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:749] 2024-01-19 02:04:41,781 >> loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:41,781 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "01/19/2024 02:04:41 - INFO - __main__ - [wpq] model.dtype=torch.bfloat16\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1648] 2024-01-19 02:04:41,845 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spawning 32 processes\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Spawning 32 processes\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 0/33717 [00:Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 22/33717 [00Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   1%| | 361/33717 [0Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):   3%| | 1001/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   5%| | 1719/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   7%| | 2251/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):  12%| | 4021/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  14%|▏| 4841/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  18%|▏| 5957/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32): 100%|█| 33717/33717 \n",
      "Concatenating 32 shards\n",
      "01/19/2024 02:04:55 - INFO - datasets.arrow_dataset - Concatenating 32 shards\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - __main__ - Subsample dataset according to indices: /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl\n",
      "01/19/2024 02:04:56 - INFO - __main__ - subsample_inds_file has 10000 indices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[wpq] Example 0 of train_dataset: \r\n",
      "{'dataset': 'oasst1', 'id': 'oasst1_20480', 'messages': [{'role': 'user', 'content': 'Cómo manejar un carro manual'}, {'role': 'assistant', 'content': 'Lo primero que tienes que hacer, si nunca has conducido un coche manual, es familiarizarte con el embrague y palanca de cambios. Si conduces habitualmente un coche automático, estarás acostumbrado a no utilizar para nada el pie izquierdo ni la palanca del cambio. Encontrarás tres pedales, siendo el embrague el que está situado a la izquierda y el que tendrás que pisar cada vez que cambies de marcha. Por otro lado, la palanca del cambio se ubica siempre en la consola central.\\n\\nPara arrancar un coche manual, es necesario seguir una serie de pasos que, al principio, pueden parecer muchos, pero que, con el tiempo, acabarás haciéndolos sin darte cuenta:\\n\\n1) Comprueba que la palanca del cambio está en punto muerto\\n2) Coloca el pie derecho en el pedal del freno\\n3) Arranca el motor\\n4) Pisa el embrague con el pie izquierdo\\n5) Coloca la palanca del cambio en la primera marcha, sin levantar el pedal del freno\\n6) Suelta el freno de mano\\n7) Suelta el pedal del freno\\nYa estás listo para iniciar la marcha, soltando suavemente el embrague, a medida que aceleras.\\n\\nUna vez que ya estás en marcha, debes hacer un uso correcto del cambio manual para cambiar las marchas de forma correcta. Un uso incorrecto de la caja de cambios manual puede repercutir negativamente en tu seguridad y también afectar gravemente al embrague y a la transmisión, lo que se traduce en serias averías de coste muy elevado. Para evitarlo, te explicamos cómo debes proceder:\\n\\nUna vez que hayas arrancado, pisa el acelerador muy lentamente. Notarás que el régimen del motor aumenta. En ese momento, comienza a soltar suavemente el pedal del embrague. Verás que el motor vuelve a bajar de vueltas. En ese momento, puedes presionar un poco más el acelerador y el coche comenzará a avanzar.\\n\\nAhora llega el momento de meter la segunda marcha. Dependiendo del tipo de coche y combustible, podrás circular a un régimen de giro más bajo o alto. El régimen de giro en coche de gasolina, por lo general, oscila entre loas 2.500 y 3.000 vueltas. Si el motor está sobrealimentado por turbo, te permitirá circular por debajo de ese rango, ya que algunos coches turbos modernos entregan la totalidad de su par motor, incluso por debajo de las 2.000 vueltas.\\n\\nUn coche con motor turbodiésel te permite circular a un régimen muy bajo, por debajo de las 2.000 vueltas, ya que la entrega de par se produce antes que en un motor de gasolina.\\n\\nCuando el coche alcance un régimen de vueltas apropiado, suelta el pedal del acelerador y vuelve a pisar el embrague. Coge la palanca del cambio y baja para meter segunda. Suelta el embrague y presiona nuevamente el acelerador. A partir de aquí, cada vez que quieras cambiar de marcha, deberás repetir el mismo proceso: soltar el acelerador, pisar embrague, meter la marcha, soltar embrague y volver a acelerar.\\n\\n¡Buen viaje!'}], 'input_ids': tensor([    1,   529, 29989,  1792, 29989, 29958,    13, 29907, 29980,  4346,\r\n",
      "          767, 29872,  4758,   443,  1559,   307, 12219,    13, 29966, 29989,\r\n",
      "          465, 22137, 29989, 29958,    13,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'labels': tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:593] 2024-01-19 02:04:57,333 >> Using auto half precision backend\n",
      "[INFO|trainer.py:738] 2024-01-19 02:04:57,494 >> The following columns in the training set don't have a corresponding argument in `LlamaForCausalLM.forward` and have been ignored: messages, id, dataset. If messages, id, dataset are not expected by `LlamaForCausalLM.forward`,  you can safely ignore this message.\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1723] 2024-01-19 02:04:57,514 >> ***** Running training *****\n",
      "[INFO|trainer.py:1724] 2024-01-19 02:04:57,514 >>   Num examples = 10,000\n",
      "[INFO|trainer.py:1725] 2024-01-19 02:04:57,514 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1726] 2024-01-19 02:04:57,514 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:1729] 2024-01-19 02:04:57,514 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1730] 2024-01-19 02:04:57,514 >>   Gradient Accumulation steps = 128\n",
      "[INFO|trainer.py:1731] 2024-01-19 02:04:57,514 >>   Total optimization steps = 78\n",
      "[INFO|trainer.py:1732] 2024-01-19 02:04:57,515 >>   Number of trainable parameters = 6,738,423,808\n",
      "[INFO|integration_utils.py:718] 2024-01-19 02:04:57,519 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "  0%|                                                    | 0/78 [00:00<?, ?it/s][WARNING|logging.py:314] 2024-01-19 02:05:01,563 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,569 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,572 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,576 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,577 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 1.6425, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}         \n",
      "{'loss': 1.7168, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.03}        \n",
      "  3%|█▏                                          | 2/78 [00:42<26:54, 21.24s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash gen_cmds_sft.sh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:177\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:646\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGCONT)\n\u001b[0;32m--> 646\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_sft.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831fe55",
   "metadata": {},
   "source": [
    "# eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "499d6f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('humaneval', 'results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=0', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('humaneval', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('humaneval', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('humaneval', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('humaneval', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=0', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('humaneval', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('humaneval', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('humaneval', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('humaneval', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "#cmds:  284 \n",
      "\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from gen_cmds_utils import remove_all_symlinks, create_unique_symlinks, get_chat_formatting_function, get_resource_for_task, OPENAI_MODEL_LIST\n",
    "\n",
    "\n",
    "create_symlinks = False\n",
    "include_checkpoints = False\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "use_slow_tokenizer = True\n",
    "definitely_run_mtbench_on_non_alt7b_queue = False\n",
    "launch_one_job_per_model = True\n",
    "\n",
    "task_names = [\n",
    "    'mmlu_s=0',\n",
    "    'mmlu_s=5', \n",
    "    'gsm_s=8',\n",
    "    'gsm_s=8_cot',\n",
    "    'bbh_s=3',\n",
    "    'bbh_s=3_cot', # max_datapoints_per_task=40 -> 40min.\n",
    "    'humaneval',\n",
    "    'tydiqa_s=1_cb', # 3min\n",
    "    'tydiqa_s=1_gp',\n",
    "    # 'toxigen', # ~1.5hr\n",
    "#     'alpacafarm_ann=gpt35:turbo:1106',\n",
    "    # 'alpacafarm_ann=chatgpt', # ~$1 per eval.\n",
    "]\n",
    "task_names_chatfmt = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "\n",
    "task_names_mtbench = ['mtbench_ann=gpt:4:1106:preview_chatfmt'] # ann=gpt:4, ann=gpt:3.5:turbo:1106, gpt:4:1106:preview (gpt4-turbo)\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:3.5:turbo:1106_chatfmt'] # for debug sake, prefer gpt4\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:4_chatfmt']\n",
    "# task_names_alpacafarm = ['alpacafarm_ann=chatgpt_chatfmt']\n",
    "task_names_alpacafarm = ['alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt']\n",
    "task_names_chateval = task_names_mtbench + task_names_alpacafarm\n",
    "\n",
    "\n",
    "# # ## baselines eval \n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "# #     'huggyllama/llama-7b', \n",
    "# #     'mistralai/Mistral-7B-v0.1',\n",
    "# #     'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "# #     'NousResearch/Llama-2-7b-hf',\n",
    "# #     'NousResearch/Llama-2-7b-chat-hf',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-beta',\n",
    "# #     'HuggingFaceH4/zephyr-7b-alpha',\n",
    "#     'HuggingFaceH4/zephyr-7b-beta',\n",
    "# #     'codellama/CodeLlama-7b-hf',\n",
    "# #     'codellama/CodeLlama-7b-Python-hf',\n",
    "# #     'codellama/CodeLlama-7b-Instruct-hf',\n",
    "# ]]\n",
    "# # task_names = task_names + task_names_chatfmt\n",
    "# task_names = task_names_mtbench; definitely_run_mtbench_on_non_alt7b_queue = True\n",
    "\n",
    "# # oi5\n",
    "# exp_dir = 'results/oi2'\n",
    "# exp_dir = 'results/oi5_flan_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_dolly:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlm50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegpt50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b_debug'\n",
    "# exp_dir = 'results/oi5_stanford_alpaca:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlmv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegptv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_ultrachat200kv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_tulu_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_open_orca_slim:llama-7b'\n",
    "# exp_dir = 'results/dpo1'\n",
    "# exp_dir = 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2'\n",
    "exp_dirs = [\n",
    "    'results/oi5_dolly:llama-7b',\n",
    "    'results/oi5_flan_v250k:llama-7b',\n",
    "    'results/oi5_stanford_alpaca50k:llama-7b',\n",
    "    'results/oi5_oasst2:llama-7b',\n",
    "    'results/oi5_wizardlm50k:llama-7b',\n",
    "    'results/oi5_sharegpt50k:llama-7b',\n",
    "    'results/oi5_ultrachat50k:llama-7b',\n",
    "]\n",
    "\n",
    "# subdir_filter_fn = lambda x: '=prune:size=30000:ep=3' in x\n",
    "task_names = task_names + task_names_chatfmt;\n",
    "# task_names = task_names_alpacafarm; \n",
    "# task_names = task_names_mtbench; definitely_run_mtbench_on_non_alt7b_queue = False\n",
    "# task_names = task_names + task_names_chatfmt + task_names_mtbench\n",
    "# task_names = task_names\n",
    "# task_names = ['alpacafarm_ann=gpt35:turbo:1106_chatfmt']\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "num_gpus = 1\n",
    "if arch == 'x86_64': # ccc\n",
    "\n",
    "    if definitely_run_mtbench_on_non_alt7b_queue:\n",
    "        gpu_type = 'v100'; num_cpus = int(32/8*num_gpus); cpu_mem = int(240/8*num_gpus)\n",
    "    else:\n",
    "        gpu_type = 'a100_80gb'; num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus)\n",
    "    use_vllm = True; torch_dtype = 'bfloat16'\n",
    "else:\n",
    "    gpu_type = 'v100'\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    use_vllm = False; torch_dtype = 'float16'\n",
    "    \n",
    "    \n",
    "if len(subdir_path_list)==0:\n",
    "    subdir_path_list = []\n",
    "    for exp_dir in exp_dirs:\n",
    "        if create_symlinks:\n",
    "            remove_all_symlinks(exp_dir)\n",
    "        subdirs = list(os.listdir(exp_dir))\n",
    "        subdirs = filter(subdir_filter_fn, subdirs)\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(exp_dir, subdir)\n",
    "            if include_checkpoints:\n",
    "                subdir_path_list += glob.glob(os.path.join(subdir_path, 'checkpoint-*'))\n",
    "            if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "                continue\n",
    "            subdir_path_list.append(subdir_path)\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not os.path.islink(subdir_path) and \\\n",
    "                not os.path.isfile(os.path.join(subdir_path, 'eval', task_name, 'metrics.json')):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "                print((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "\n",
    "print('#cmds: ', len(list(task_name_and_model)), '\\n')\n",
    "\n",
    "if create_symlinks:\n",
    "    # create symlink for each directory.\n",
    "    symlink_path_dict = create_unique_symlinks(\n",
    "        list([x[1] for x in task_name_and_model]))\n",
    "    options_list = list(map(lambda x: (x[0], symlink_path_dict[x[1]]), task_name_and_model))\n",
    "else:\n",
    "    options_list = task_name_and_model\n",
    "    \n",
    "    \n",
    "dfo = pd.DataFrame(options_list, columns=['task_name', 'model_name_or_path'])\n",
    "model_and_task_list = dfo.groupby('model_name_or_path')['task_name'].agg(list).to_dict()\n",
    "\n",
    "\n",
    "info = {}  \n",
    "cmds = []\n",
    "for model_name_or_path, task_name_list in model_and_task_list.items():\n",
    "    num_tasks = len(task_name_list)\n",
    "    cmds_per_model = []\n",
    "    for i, task_name in enumerate(task_name_list):\n",
    "        queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else \\\n",
    "            ('alt_7d' if task_name.startswith('mtbench') else 'alt_1h')\n",
    "\n",
    "        use_chat_format = 'chatfmt' in task_name\n",
    "        chat_formatting_function = get_chat_formatting_function(model_name_or_path)\n",
    "\n",
    "        try:\n",
    "            with open(os.path.join(model_name_or_path, 'ft_args.json'), 'r') as f:\n",
    "                ft_args = json.load(f)\n",
    "            # note `model_name_or_path` could be anything, e.g., soft links with arbitrary names.\n",
    "            # but `ft_args_model_name_or_path` indicates the finetuned model name.\n",
    "            if 'model_args' in ft_args:\n",
    "                ft_args_model_name_or_path = ft_args['model_args']['model_name_or_path']\n",
    "            else:\n",
    "                ft_args_model_name_or_path = ft_args['model_name_or_path']\n",
    "        except:\n",
    "            ft_args_model_name_or_path = model_name_or_path\n",
    "\n",
    "        batch_size, job_duration = get_resource_for_task(\n",
    "            task_name, ft_args_model_name_or_path)\n",
    "\n",
    "        job_name = f'eval.{task_name}'\n",
    "        save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "\n",
    "        if task_name.startswith('mmlu'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 5)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.mmlu.run_eval \\\n",
    "                --data_dir data/eval/mmlu \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --ntrain {n_shot} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('gsm'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 8)\n",
    "            # open-instruct used 200 examples. use higher amount to get a more accurate number\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.gsm.run_eval \\\n",
    "                --data_dir data/eval/gsm/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_num_examples 500 \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('bbh'):\n",
    "            max_num_examples_per_task = 40\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 3)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.bbh.run_eval \\\n",
    "                --data_dir data/eval/bbh/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                --n_shot {n_shot} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--max_num_examples_per_task '+str(max_num_examples_per_task) if max_num_examples_per_task else ''} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('humaneval'):\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.codex_humaneval.run_eval \\\n",
    "                --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens 512 \\\n",
    "                --eval_pass_at_ks 1 \\\n",
    "                --unbiased_sampling_size_n 3 \\\n",
    "                --temperature 0.1 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('tydiqa'):\n",
    "            no_context = 'cb' in task_name\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot in [0,1])\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.tydiqa.run_eval \\\n",
    "                --data_dir data/eval/tydiqa \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_num_examples_per_lang 100 \\\n",
    "                --max_context_length 512 \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_context' if no_context else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('toxigen'):\n",
    "            # max_prompts_per_group=500 (out of 1000) is open-instruct default.\n",
    "            # eval batch size=1 much faster (llama-7b) not sure why.\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.toxigen.run_eval \\\n",
    "                --data_dir data/eval/toxigen \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size 1 \\\n",
    "                --max_prompts_per_group 200 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('alpacafarm'):\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            annotators_config = match.group(1)\n",
    "            annotators_config = annotators_config.replace(':', '_')\n",
    "            if not annotators_config in ['chatgpt', 'alpaca_eval_gpt4_0314', 'gpt35_turbo_1106', 'alpaca_eval_gpt4_turbo_fn']:\n",
    "                raise ValueError('Just support 2 annotators_config.')\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.alpaca_farm.run_eval \\\n",
    "                --reference_path alpaca_eval_data \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --max_new_tokens 2048 \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --annotators_config {annotators_config} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('mtbench'):\n",
    "            assert('chatfmt' in task_name)\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            judge_model = match.group(1).replace(':', '-')\n",
    "            if not judge_model in OPENAI_MODEL_LIST:\n",
    "                raise ValueError('fastchat does not support the judge model.')\n",
    "            os.makedirs(save_dir, exist_ok=True) # since not using python file, make the directory now.\n",
    "            fastchat_mtbench_data_dir = os.path.normpath(os.path.join(open_instruct_dir, '../FastChat/fastchat/llm_judge/data'))\n",
    "            question_file = os.path.join(fastchat_mtbench_data_dir, 'mt_bench/question.jsonl')\n",
    "            rating_file = os.path.join(save_dir, f'{judge_model}_single.jsonl')\n",
    "            question_begin, question_end = (0, 1) if False else (None, None)\n",
    "            model_id = os.path.basename(model_name_or_path) if 'results/baselines' in save_dir else 'tulu'\n",
    "            cmd = \"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_model_answer \\\n",
    "                    --model-path {model_name_or_path} \\\n",
    "                    --model-id {model_id} \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --question-file {question_file} \\\n",
    "                    {'--question-begin '+str(question_begin) if question_begin else ''} \\\n",
    "                    {'--question-end '+str(question_end) if question_end else ''} \\\n",
    "                    --max-new-token 2048 \\\n",
    "                    --answer-file {os.path.join(save_dir, 'model_answer.jsonl')} \\\n",
    "                    --dtype {torch_dtype} \\\n",
    "                && \\\n",
    "            \"\"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_judgment \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --judge-file {os.path.join(fastchat_mtbench_data_dir, 'judge_prompts.jsonl')} \\\n",
    "                    --judge-model {judge_model} \\\n",
    "                    --mode single \\\n",
    "                    --question-file {question_file} \\\n",
    "                    --answer-dir {save_dir} \\\n",
    "                    --ref-answer-dir {os.path.join(fastchat_mtbench_data_dir, 'mt_bench/reference_answer')} \\\n",
    "                    --output-file {rating_file} \\\n",
    "                && \\\n",
    "                python -m fastchat.llm_judge.show_result \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --input-file {rating_file} \\\n",
    "                    --mode single \\\n",
    "                    --save-to-json\n",
    "            \"\"\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'{task_name} not supported.')\n",
    "            \n",
    "        if task_name.startswith('alpacafarm') and (getpass.getuser() not in ('PTFMqngp', 'wpq')):\n",
    "            queue = 'alt_6h'\n",
    "\n",
    "        if test_run:\n",
    "            print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd.strip())]))\n",
    "\n",
    "        cmd = multiline_to_singleline(cmd)\n",
    "        cmds.append(cmd)\n",
    "        cmds_per_model.append(cmd)\n",
    "        \n",
    "        if launch_one_job_per_model:\n",
    "            shell_scripts = shell_scripts_template.format(\n",
    "                conda_env='open-instruct',\n",
    "                cwd=os.path.dirname(os.getcwd()),\n",
    "                cmd=cmd,\n",
    "                log_dir=os.getcwd(),\n",
    "                save_dir=save_dir,\n",
    "            )\n",
    "            if arch == 'x86_64': # ccc\n",
    "                shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "            out = submit_job(\n",
    "                shell_scripts, \n",
    "                job_name=job_name,\n",
    "                num_cpus=num_cpus,\n",
    "                cpu_mem=cpu_mem,\n",
    "                num_gpus=num_gpus,\n",
    "                gpu_type=gpu_type,\n",
    "                test_run=test_run,\n",
    "                job_duration=job_duration,\n",
    "                queue=queue,\n",
    "            )\n",
    "        else:\n",
    "            if i + 1 == num_tasks:\n",
    "                assert(len(cmds_per_model) == num_tasks)\n",
    "                cmd = ' && '.join(cmds_per_model)\n",
    "                if test_run:\n",
    "                    print(cmd)\n",
    "                shell_scripts = shell_scripts_template.format(\n",
    "                    conda_env='open-instruct',\n",
    "                    cwd=os.path.dirname(os.getcwd()),\n",
    "                    cmd=cmd,\n",
    "                    log_dir=os.getcwd(),\n",
    "                    save_dir=os.getcwd(), # just delete afterwards.\n",
    "                )\n",
    "                if arch == 'x86_64': # ccc\n",
    "                    shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "                out = submit_job(\n",
    "                    shell_scripts, \n",
    "                    job_name=f'eval.{os.path.basename(model_name_or_path)}',\n",
    "                    num_cpus=num_cpus,\n",
    "                    cpu_mem=cpu_mem,\n",
    "                    num_gpus=num_gpus,\n",
    "                    gpu_type=gpu_type,\n",
    "                    test_run=test_run,\n",
    "                    job_duration=6,\n",
    "                    queue=None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_6b',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ea7ac978",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_eval.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b3939309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10 --max_new_tokens 2048 --save_dir results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt --eval_batch_size 10 --annotators_config alpaca_eval_gpt4_turbo_fn --use_vllm --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype bfloat16\n",
      "[2024-01-21 21:11:36,716] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:loading data and model...\n",
      "INFO 01-21 21:11:39 llm_engine.py:73] Initializing an LLM engine with config: model='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10', tokenizer='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO 01-21 21:11:39 tokenizer.py:32] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "MegaBlocks not found. Please install it by `pip install megablocks`. Note that MegaBlocks depends on mosaicml-turbo, which only supports Python 3.10 for now.\n",
      "STK not found: please see https://github.com/stanford-futuredata/stk\n",
      "INFO 01-21 21:11:53 llm_engine.py:222] # GPU blocks: 7451, # CPU blocks: 512\n",
      "Processed prompts: 100%|██████████████████████| 805/805 [01:01<00:00, 13.00it/s]\n",
      "INFO:root:Evaluating the llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10-greedy-long outputs.\n",
      "INFO:root:Creating the annotator from `alpaca_eval_gpt4_turbo_fn`.\n",
      "WARNING:root:Saving_path is given but not 'auto', make sure that it's different for different seeds.\n",
      "Annotation chunk:   0%|                                   | 0/7 [00:00<?, ?it/s]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:02<06:07,  2.90s/it]\u001b[A\n",
      "prompt_batches:   2%|▋                          | 3/128 [00:03<01:52,  1.11it/s]\u001b[A\n",
      "prompt_batches:   3%|▊                          | 4/128 [00:06<03:40,  1.78s/it]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/128 [00:11<02:02,  1.04s/it]\u001b[A\n",
      "prompt_batches:   9%|██▍                       | 12/128 [00:14<02:13,  1.15s/it]\u001b[A\n",
      "prompt_batches:  14%|███▋                      | 18/128 [00:14<01:00,  1.81it/s]\u001b[A\n",
      "prompt_batches:  16%|████                      | 20/128 [00:15<01:02,  1.73it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:18<01:16,  1.38it/s]\u001b[A\n",
      "prompt_batches:  18%|████▋                     | 23/128 [00:18<01:08,  1.52it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:21<01:29,  1.16it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/128 [00:21<01:17,  1.31it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:23<01:36,  1.05it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:25<01:27,  1.12it/s]\u001b[A\n",
      "prompt_batches:  25%|██████▌                   | 32/128 [00:29<01:47,  1.12s/it]\u001b[A\n",
      "prompt_batches:  30%|███████▋                  | 38/128 [00:34<01:27,  1.03it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/128 [00:36<01:25,  1.03it/s]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:38<01:15,  1.12it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▎                | 46/128 [00:46<01:56,  1.42s/it]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:47<01:01,  1.21it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▌              | 57/128 [00:49<00:49,  1.43it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▊              | 58/128 [00:50<00:54,  1.29it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 59/128 [00:53<01:04,  1.08it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:54<00:48,  1.36it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▊             | 63/128 [00:55<00:52,  1.23it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 64/128 [00:56<00:56,  1.13it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 65/128 [00:56<00:47,  1.32it/s]\u001b[A\n",
      "prompt_batches:  53%|█████████████▊            | 68/128 [00:58<00:39,  1.53it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [01:11<02:16,  2.36s/it]\u001b[A\n",
      "prompt_batches:  66%|█████████████████▎        | 85/128 [01:11<00:25,  1.69it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:13<00:21,  1.79it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:19<00:37,  1.02it/s]\u001b[A\n",
      "prompt_batches:  78%|███████████████████▌     | 100/128 [01:21<00:16,  1.71it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:25<00:17,  1.45it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:28<00:12,  1.55it/s]\u001b[A\n",
      "prompt_batches:  86%|█████████████████████▍   | 110/128 [01:28<00:10,  1.76it/s]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▎  | 114/128 [01:29<00:06,  2.21it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:30<00:07,  1.70it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_batches:  91%|██████████████████████▊  | 117/128 [01:32<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 119/128 [01:33<00:05,  1.66it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▋ | 121/128 [01:35<00:04,  1.46it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▍| 125/128 [01:36<00:01,  2.04it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 126/128 [01:36<00:01,  1.92it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:37<00:00,  1.31it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 97.8 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  14%|███▊                       | 1/7 [01:37<09:47, 97.89s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:05<12:20,  5.83s/it]\u001b[A\n",
      "prompt_batches:   5%|█▍                         | 7/128 [00:15<03:59,  1.98s/it]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:19<02:12,  1.16s/it]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:19<01:50,  1.02it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:20<01:07,  1.59it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:22<01:22,  1.28it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:23<01:03,  1.63it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/128 [00:24<01:05,  1.56it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:24<00:58,  1.73it/s]\u001b[A\n",
      "prompt_batches:  22%|█████▋                    | 28/128 [00:25<01:02,  1.59it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/128 [00:26<01:06,  1.48it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:26<01:08,  1.42it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▎                   | 31/128 [00:29<01:45,  1.09s/it]\u001b[A\n",
      "prompt_batches:  27%|██████▉                   | 34/128 [00:29<00:52,  1.78it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 36/128 [00:29<00:42,  2.14it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/128 [00:30<00:38,  2.34it/s]\u001b[A\n",
      "prompt_batches:  30%|███████▋                  | 38/128 [00:38<03:11,  2.12s/it]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:40<01:28,  1.04s/it]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:41<00:43,  1.79it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:42<00:36,  2.06it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▏              | 55/128 [00:43<00:40,  1.81it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▌              | 57/128 [00:46<00:54,  1.31it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:47<00:33,  1.97it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 64/128 [00:55<01:15,  1.18s/it]\u001b[A\n",
      "prompt_batches:  56%|██████████████▋           | 72/128 [00:55<00:32,  1.71it/s]\u001b[A\n",
      "prompt_batches:  57%|██████████████▊           | 73/128 [00:56<00:32,  1.71it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 74/128 [01:05<01:23,  1.54s/it]\u001b[A\n",
      "prompt_batches:  67%|█████████████████▍        | 86/128 [01:06<00:24,  1.71it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▋        | 87/128 [01:07<00:23,  1.74it/s]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▉        | 88/128 [01:07<00:21,  1.82it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:08<00:22,  1.76it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:12<00:43,  1.13s/it]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 95/128 [01:13<00:19,  1.67it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:13<00:20,  1.57it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:15<00:25,  1.23it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:17<00:18,  1.44it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:19<00:19,  1.31it/s]\u001b[A\n",
      "prompt_batches:  84%|████████████████████▉    | 107/128 [01:20<00:10,  2.09it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:20<00:10,  1.95it/s]\u001b[A\n",
      "prompt_batches:  86%|█████████████████████▍   | 110/128 [01:22<00:10,  1.67it/s]\u001b[A\n",
      "prompt_batches:  88%|█████████████████████▉   | 112/128 [01:24<00:12,  1.33it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:25<00:07,  1.82it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▋  | 116/128 [01:27<00:08,  1.43it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 117/128 [01:27<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 119/128 [01:28<00:05,  1.71it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▍ | 120/128 [01:30<00:06,  1.17it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:32<00:05,  1.03it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:33<00:00,  1.37it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 93.5 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  29%|███████▋                   | 2/7 [03:11<07:56, 95.40s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:03<07:34,  3.58s/it]\u001b[A\n",
      "prompt_batches:   2%|▍                          | 2/128 [00:06<06:45,  3.22s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/128 [00:07<01:14,  1.60it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/128 [00:08<01:16,  1.54it/s]\u001b[A\n",
      "prompt_batches:   9%|██▏                       | 11/128 [00:09<01:20,  1.45it/s]\u001b[A\n",
      "prompt_batches:   9%|██▍                       | 12/128 [00:10<01:29,  1.30it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:10<01:00,  1.89it/s]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:12<01:07,  1.65it/s]\u001b[A\n",
      "prompt_batches:  13%|███▍                      | 17/128 [00:13<01:10,  1.57it/s]\u001b[A\n",
      "prompt_batches:  14%|███▋                      | 18/128 [00:14<01:21,  1.35it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:15<01:08,  1.57it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:16<01:17,  1.36it/s]\u001b[A\n",
      "prompt_batches:  18%|████▋                     | 23/128 [00:17<01:23,  1.26it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:18<01:07,  1.53it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:20<01:06,  1.51it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:23<01:22,  1.18it/s]\u001b[A\n",
      "prompt_batches:  26%|██████▋                   | 33/128 [00:23<00:54,  1.75it/s]\u001b[A\n",
      "prompt_batches:  27%|███████                   | 35/128 [00:24<00:48,  1.93it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 36/128 [00:25<00:53,  1.73it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/128 [00:25<00:50,  1.82it/s]\u001b[A\n",
      "prompt_batches:  30%|███████▉                  | 39/128 [00:27<00:51,  1.74it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/128 [00:29<01:28,  1.01s/it]\u001b[A\n",
      "prompt_batches:  34%|████████▉                 | 44/128 [00:30<00:42,  1.97it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████▏                | 45/128 [00:32<01:06,  1.24it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▎                | 46/128 [00:32<00:55,  1.47it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▊                | 48/128 [00:32<00:37,  2.12it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▉                | 49/128 [00:34<01:00,  1.30it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:34<00:39,  1.95it/s]\u001b[A\n",
      "prompt_batches:  42%|██████████▉               | 54/128 [00:38<01:00,  1.22it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▏              | 55/128 [00:39<00:57,  1.28it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▍              | 56/128 [00:40<01:05,  1.09it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 59/128 [00:43<01:06,  1.05it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:43<00:40,  1.65it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▊             | 63/128 [00:44<00:40,  1.59it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 65/128 [00:46<00:46,  1.37it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 66/128 [00:46<00:38,  1.61it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▌            | 67/128 [00:46<00:34,  1.78it/s]\u001b[A\n",
      "prompt_batches:  54%|██████████████            | 69/128 [00:47<00:27,  2.11it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [00:49<00:48,  1.18it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▍           | 71/128 [00:50<00:50,  1.13it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▏          | 75/128 [00:51<00:25,  2.05it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▍          | 76/128 [00:54<00:45,  1.14it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████          | 79/128 [00:54<00:28,  1.72it/s]\u001b[A\n",
      "prompt_batches:  63%|████████████████▍         | 81/128 [00:55<00:25,  1.81it/s]\u001b[A\n",
      "prompt_batches:  64%|████████████████▋         | 82/128 [00:57<00:32,  1.42it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 83/128 [01:00<00:55,  1.24s/it]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▉        | 88/128 [01:01<00:22,  1.76it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:02<00:24,  1.60it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 91/128 [01:05<00:33,  1.10it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▋       | 92/128 [01:06<00:35,  1.03it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:07<00:19,  1.63it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:07<00:16,  1.85it/s]\u001b[A\n",
      "prompt_batches:  77%|███████████████████▉      | 98/128 [01:08<00:18,  1.62it/s]\u001b[A\n",
      "prompt_batches:  77%|████████████████████      | 99/128 [01:10<00:25,  1.13it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:11<00:20,  1.29it/s]\u001b[A\n",
      "prompt_batches:  80%|███████████████████▉     | 102/128 [01:12<00:16,  1.55it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 104/128 [01:12<00:14,  1.70it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▌    | 105/128 [01:15<00:22,  1.02it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:16<00:13,  1.53it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▎   | 109/128 [01:17<00:14,  1.33it/s]\u001b[A\n",
      "prompt_batches:  87%|█████████████████████▋   | 111/128 [01:19<00:15,  1.10it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:23<00:11,  1.16it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▋  | 116/128 [01:28<00:18,  1.51s/it]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:29<00:04,  1.36it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:32<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 92.2 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation chunk:  43%|███████████▌               | 3/7 [04:43<06:15, 93.97s/it]INFO:root:Annotating 127 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 127 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/127 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/127 [00:03<07:05,  3.38s/it]\u001b[A\n",
      "prompt_batches:   2%|▍                          | 2/127 [00:04<03:43,  1.79s/it]\u001b[A\n",
      "prompt_batches:   5%|█▎                         | 6/127 [00:04<01:06,  1.81it/s]\u001b[A\n",
      "prompt_batches:   6%|█▍                         | 7/127 [00:06<01:38,  1.22it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/127 [00:06<00:56,  2.05it/s]\u001b[A\n",
      "prompt_batches:   9%|██▎                       | 11/127 [00:10<01:59,  1.03s/it]\u001b[A\n",
      "prompt_batches:  10%|██▋                       | 13/127 [00:11<01:41,  1.12it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/127 [00:12<01:31,  1.24it/s]\u001b[A\n",
      "prompt_batches:  13%|███▍                      | 17/127 [00:14<01:24,  1.30it/s]\u001b[A\n",
      "prompt_batches:  15%|███▉                      | 19/127 [00:15<01:13,  1.48it/s]\u001b[A\n",
      "prompt_batches:  17%|████▎                     | 21/127 [00:15<00:59,  1.77it/s]\u001b[A\n",
      "prompt_batches:  19%|████▉                     | 24/127 [00:18<01:04,  1.59it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/127 [00:19<01:00,  1.66it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/127 [00:23<01:36,  1.02it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/127 [00:24<00:41,  2.16it/s]\u001b[A\n",
      "prompt_batches:  31%|███████▉                  | 39/127 [00:26<00:49,  1.79it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/127 [00:26<00:44,  1.94it/s]\u001b[A\n",
      "prompt_batches:  33%|████████▌                 | 42/127 [00:27<00:39,  2.17it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████                 | 44/127 [00:27<00:32,  2.56it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████▏                | 45/127 [00:28<00:28,  2.84it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▍                | 46/127 [00:28<00:36,  2.23it/s]\u001b[A\n",
      "prompt_batches:  37%|█████████▌                | 47/127 [00:29<00:42,  1.86it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▊                | 48/127 [00:31<01:08,  1.15it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▋               | 52/127 [00:32<00:40,  1.87it/s]\u001b[A\n",
      "prompt_batches:  42%|██████████▊               | 53/127 [00:34<00:47,  1.56it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████               | 54/127 [00:35<00:52,  1.40it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▎              | 55/127 [00:35<00:53,  1.35it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▊              | 58/127 [00:37<00:41,  1.65it/s]\u001b[A\n",
      "prompt_batches:  46%|████████████              | 59/127 [00:37<00:40,  1.68it/s]\u001b[A\n",
      "prompt_batches:  47%|████████████▎             | 60/127 [00:38<00:36,  1.85it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▋             | 62/127 [00:39<00:43,  1.49it/s]\u001b[A\n",
      "prompt_batches:  50%|████████████▉             | 63/127 [00:42<01:10,  1.10s/it]\u001b[A\n",
      "prompt_batches:  54%|█████████████▉            | 68/127 [00:43<00:28,  2.08it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▎           | 70/127 [00:45<00:41,  1.36it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▌           | 71/127 [00:51<01:21,  1.45s/it]\u001b[A\n",
      "prompt_batches:  59%|███████████████▎          | 75/127 [00:52<00:45,  1.15it/s]\u001b[A\n",
      "prompt_batches:  61%|███████████████▊          | 77/127 [00:53<00:37,  1.32it/s]\u001b[A\n",
      "prompt_batches:  63%|████████████████▍         | 80/127 [00:53<00:24,  1.93it/s]\u001b[A\n",
      "prompt_batches:  64%|████████████████▌         | 81/127 [00:55<00:32,  1.43it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 82/127 [00:56<00:34,  1.32it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▉         | 83/127 [00:56<00:29,  1.50it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▌        | 86/127 [00:56<00:17,  2.41it/s]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▊        | 87/127 [00:58<00:25,  1.54it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 90/127 [01:00<00:22,  1.64it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▊       | 92/127 [01:00<00:18,  1.90it/s]\u001b[A\n",
      "prompt_batches:  73%|███████████████████       | 93/127 [01:01<00:17,  1.94it/s]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▏      | 94/127 [01:01<00:17,  1.93it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▍      | 95/127 [01:02<00:15,  2.08it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 96/127 [01:03<00:23,  1.33it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▊      | 97/127 [01:03<00:18,  1.59it/s]\u001b[A\n",
      "prompt_batches:  78%|████████████████████▎     | 99/127 [01:04<00:15,  1.78it/s]\u001b[A\n",
      "prompt_batches:  80%|███████████████████▉     | 101/127 [01:06<00:16,  1.61it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 102/127 [01:08<00:21,  1.16it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▍    | 104/127 [01:10<00:20,  1.10it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 107/127 [01:10<00:11,  1.69it/s]\u001b[A\n",
      "prompt_batches:  87%|█████████████████████▋   | 110/127 [01:16<00:19,  1.13s/it]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 116/127 [01:18<00:07,  1.39it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 121/127 [01:19<00:03,  1.93it/s]\u001b[A\n",
      "prompt_batches:  96%|████████████████████████ | 122/127 [01:21<00:03,  1.47it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 123/127 [01:24<00:03,  1.10it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 127/127 [01:27<00:00,  1.45it/s]\u001b[A\n",
      "INFO:root:Completed 127 examples in 87.5 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation chunk:  57%|███████████████▍           | 4/7 [06:11<04:34, 91.46s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:04<10:20,  4.88s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/128 [00:07<01:36,  1.25it/s]\u001b[A\n",
      "prompt_batches:   7%|█▉                         | 9/128 [00:07<01:24,  1.41it/s]\u001b[A\n",
      "prompt_batches:  10%|██▋                       | 13/128 [00:08<00:53,  2.16it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:10<01:12,  1.57it/s]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:10<01:02,  1.80it/s]\u001b[A\n",
      "prompt_batches:  15%|███▊                      | 19/128 [00:12<01:00,  1.79it/s]\u001b[A\n",
      "prompt_batches:  16%|████                      | 20/128 [00:13<01:08,  1.58it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:13<00:59,  1.79it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:14<00:59,  1.78it/s]\u001b[A\n",
      "prompt_batches:  19%|████▉                     | 24/128 [00:16<01:22,  1.25it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:17<00:54,  1.86it/s]\u001b[A\n",
      "prompt_batches:  22%|█████▋                    | 28/128 [00:18<00:55,  1.79it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/128 [00:18<00:57,  1.72it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:21<01:35,  1.02it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▎                   | 31/128 [00:26<03:17,  2.04s/it]\u001b[A\n",
      "prompt_batches:  32%|████████▎                 | 41/128 [00:29<01:00,  1.44it/s]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:30<00:55,  1.52it/s]\u001b[A\n",
      "prompt_batches:  37%|█████████▌                | 47/128 [00:32<00:51,  1.59it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:33<00:38,  1.99it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▌               | 52/128 [00:36<00:51,  1.48it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:36<00:52,  1.43it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▍              | 56/128 [00:37<00:38,  1.85it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▊              | 58/128 [00:38<00:31,  2.20it/s]\u001b[A\n",
      "prompt_batches:  47%|████████████▏             | 60/128 [00:45<01:26,  1.26s/it]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 66/128 [00:46<00:42,  1.47it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▌            | 67/128 [00:47<00:47,  1.27it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [00:49<00:39,  1.49it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▋           | 72/128 [00:49<00:32,  1.72it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 74/128 [00:52<00:40,  1.35it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▍          | 76/128 [00:52<00:33,  1.55it/s]\u001b[A\n",
      "prompt_batches:  60%|███████████████▋          | 77/128 [00:55<00:46,  1.10it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████          | 79/128 [00:57<00:45,  1.09it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████▎         | 80/128 [00:57<00:42,  1.14it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 83/128 [00:59<00:34,  1.31it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▋        | 87/128 [01:01<00:24,  1.65it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:02<00:21,  1.80it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:02<00:19,  1.98it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 91/128 [01:05<00:39,  1.07s/it]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 95/128 [01:07<00:22,  1.45it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:08<00:24,  1.31it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:09<00:24,  1.27it/s]\u001b[A\n",
      "prompt_batches:  77%|████████████████████      | 99/128 [01:10<00:19,  1.47it/s]\u001b[A\n",
      "prompt_batches:  78%|███████████████████▌     | 100/128 [01:11<00:20,  1.38it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:11<00:18,  1.43it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:12<00:16,  1.54it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 104/128 [01:13<00:17,  1.41it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▌    | 105/128 [01:15<00:22,  1.01it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:18<00:18,  1.07it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▎   | 109/128 [01:20<00:21,  1.12s/it]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▎  | 114/128 [01:22<00:10,  1.35it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:26<00:15,  1.21s/it]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:26<00:03,  1.94it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 124/128 [01:28<00:02,  1.81it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 126/128 [01:29<00:01,  1.73it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:32<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 92.2 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  71%|███████████████████▎       | 5/7 [07:43<03:03, 91.78s/it]INFO:root:Annotating 124 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 124 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/124 [00:04<08:16,  4.04s/it]\u001b[A\n",
      "prompt_batches:   5%|█▎                         | 6/124 [00:05<01:25,  1.38it/s]\u001b[A\n",
      "prompt_batches:   6%|█▌                         | 7/124 [00:07<01:57,  1.00s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/124 [00:07<01:38,  1.18it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/124 [00:08<01:05,  1.73it/s]\u001b[A\n",
      "prompt_batches:  10%|██▌                       | 12/124 [00:10<01:38,  1.14it/s]\u001b[A\n",
      "prompt_batches:  12%|███▏                      | 15/124 [00:11<00:59,  1.84it/s]\u001b[A\n",
      "prompt_batches:  14%|███▌                      | 17/124 [00:13<01:13,  1.46it/s]\u001b[A\n",
      "prompt_batches:  15%|███▉                      | 19/124 [00:15<01:21,  1.28it/s]\u001b[A\n",
      "prompt_batches:  19%|████▊                     | 23/124 [00:16<00:56,  1.80it/s]\u001b[A\n",
      "prompt_batches:  19%|█████                     | 24/124 [00:17<01:09,  1.44it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 26/124 [00:20<01:18,  1.25it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 29/124 [00:20<00:57,  1.66it/s]\u001b[A\n",
      "prompt_batches:  25%|██████▌                   | 31/124 [00:22<00:59,  1.57it/s]\u001b[A\n",
      "prompt_batches:  26%|██████▋                   | 32/124 [00:23<01:08,  1.35it/s]\u001b[A\n",
      "prompt_batches:  27%|██████▉                   | 33/124 [00:24<01:03,  1.44it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 35/124 [00:26<01:11,  1.24it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 36/124 [00:27<01:11,  1.24it/s]\u001b[A\n",
      "prompt_batches:  32%|████████▍                 | 40/124 [00:28<00:42,  1.99it/s]\u001b[A\n",
      "prompt_batches:  33%|████████▌                 | 41/124 [00:29<01:00,  1.38it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▍                | 45/124 [00:32<00:54,  1.46it/s]\u001b[A\n",
      "prompt_batches:  39%|██████████                | 48/124 [00:33<00:39,  1.92it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 49/124 [00:36<01:05,  1.14it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▎              | 54/124 [00:37<00:37,  1.89it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▋              | 56/124 [00:38<00:35,  1.89it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 57/124 [00:40<00:53,  1.25it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▎             | 59/124 [00:40<00:39,  1.63it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 62/124 [00:41<00:31,  1.97it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 63/124 [00:42<00:35,  1.71it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 64/124 [00:43<00:35,  1.71it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▋            | 65/124 [00:44<00:42,  1.38it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▎           | 68/124 [00:45<00:30,  1.85it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▍           | 69/124 [00:46<00:27,  1.97it/s]\u001b[A\n",
      "prompt_batches:  57%|██████████████▉           | 71/124 [00:47<00:31,  1.66it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 72/124 [00:47<00:27,  1.87it/s]\u001b[A\n",
      "prompt_batches:  60%|███████████████▋          | 75/124 [00:54<01:06,  1.35s/it]\u001b[A\n",
      "prompt_batches:  61%|███████████████▉          | 76/124 [00:55<00:54,  1.13s/it]\u001b[A\n",
      "prompt_batches:  65%|████████████████▉         | 81/124 [00:55<00:22,  1.89it/s]\u001b[A\n",
      "prompt_batches:  67%|█████████████████▍        | 83/124 [00:56<00:24,  1.66it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▌        | 84/124 [00:59<00:35,  1.12it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 88/124 [01:00<00:22,  1.61it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▋       | 89/124 [01:00<00:19,  1.77it/s]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 92/124 [01:02<00:18,  1.74it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 93/124 [01:04<00:22,  1.36it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 94/124 [01:05<00:26,  1.12it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████▊     | 99/124 [01:07<00:13,  1.87it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▏    | 100/124 [01:07<00:13,  1.82it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 101/124 [01:08<00:11,  1.95it/s]\u001b[A\n",
      "prompt_batches:  83%|████████████████████▊    | 103/124 [01:08<00:08,  2.44it/s]\u001b[A\n",
      "prompt_batches:  84%|████████████████████▉    | 104/124 [01:09<00:08,  2.41it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▏   | 105/124 [01:12<00:19,  1.02s/it]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▏  | 110/124 [01:16<00:12,  1.11it/s]\u001b[A\n",
      "prompt_batches:  92%|██████████████████████▉  | 114/124 [01:17<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 115/124 [01:17<00:05,  1.62it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▍ | 116/124 [01:19<00:05,  1.40it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▌ | 117/124 [01:19<00:05,  1.38it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 118/124 [01:20<00:04,  1.36it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 120/124 [01:21<00:02,  1.79it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 122/124 [01:23<00:01,  1.27it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 124/124 [01:24<00:00,  1.47it/s]\u001b[A\n",
      "INFO:root:Completed 124 examples in 84.6 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  86%|███████████████████████▏   | 6/7 [09:08<01:29, 89.38s/it]INFO:root:Annotating 37 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 37 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                    | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   3%|▊                           | 1/37 [00:03<02:03,  3.43s/it]\u001b[A\n",
      "prompt_batches:  16%|████▌                       | 6/37 [00:04<00:21,  1.45it/s]\u001b[A\n",
      "prompt_batches:  19%|█████▎                      | 7/37 [00:05<00:19,  1.55it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▊                     | 9/37 [00:07<00:22,  1.26it/s]\u001b[A\n",
      "prompt_batches:  30%|████████                   | 11/37 [00:08<00:17,  1.46it/s]\u001b[A\n",
      "prompt_batches:  32%|████████▊                  | 12/37 [00:11<00:27,  1.08s/it]\u001b[A\n",
      "prompt_batches:  41%|██████████▉                | 15/37 [00:12<00:15,  1.39it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▊             | 19/37 [00:12<00:07,  2.40it/s]\u001b[A\n",
      "prompt_batches:  54%|██████████████▌            | 20/37 [00:14<00:10,  1.61it/s]\u001b[A\n",
      "prompt_batches:  59%|████████████████           | 22/37 [00:15<00:08,  1.77it/s]\u001b[A\n",
      "prompt_batches:  65%|█████████████████▌         | 24/37 [00:17<00:10,  1.28it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▉        | 26/37 [00:20<00:10,  1.03it/s]\u001b[A\n",
      "prompt_batches:  84%|██████████████████████▌    | 31/37 [00:21<00:03,  1.68it/s]\u001b[A\n",
      "prompt_batches:  89%|████████████████████████   | 33/37 [00:24<00:02,  1.36it/s]\u001b[A\n",
      "prompt_batches: 100%|███████████████████████████| 37/37 [00:26<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 37 examples in 26.8 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk: 100%|███████████████████████████| 7/7 [09:35<00:00, 82.20s/it]\n",
      "/dccstor/data-pruning/wpq/github/mitibm2023/external/alpaca_eval/src/alpaca_eval/metrics.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  series_preferences[series_preferences == 0] = 1.5\n",
      "INFO:root:Saving all results to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Price (per-example / total) = 0.0191 / 15.29\n",
      "Time  (per-example / total) = 0.7184 / 574.70\n",
      "                                                                                                                           model  win_rate  standard_error  n_wins  n_wins_base  n_draws  n_total       mode  avg_length  avg_output_tok_length  price\n",
      "0  llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10-greedy-long     19.32            1.39     153          647        5      805  community         607                 172.59  15.29\n",
      "Map: 100%|███████████████████████████| 805/805 [00:00<00:00, 2978.74 examples/s]\n",
      "Filter (num_proc=4): 100%|███████████| 805/805 [00:00<00:00, 4447.74 examples/s]\n",
      "Creating json from Arrow format: 100%|███████████| 1/1 [00:00<00:00, 178.53ba/s]\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3 --max_new_tokens 2048 --save_dir results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt --eval_batch_size 10 --annotators_config alpaca_eval_gpt4_turbo_fn --use_vllm --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype bfloat16\n",
      "[2024-01-21 21:22:39,160] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:loading data and model...\n",
      "INFO 01-21 21:22:41 llm_engine.py:73] Initializing an LLM engine with config: model='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3', tokenizer='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO 01-21 21:22:41 tokenizer.py:32] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "MegaBlocks not found. Please install it by `pip install megablocks`. Note that MegaBlocks depends on mosaicml-turbo, which only supports Python 3.10 for now.\n",
      "STK not found: please see https://github.com/stanford-futuredata/stk\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/eval/alpaca_farm/run_eval.py\", line 160, in <module>\n",
      "    main(args)\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/eval/alpaca_farm/run_eval.py\", line 38, in main\n",
      "    model = vllm.LLM(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/entrypoints/llm.py\", line 93, in __init__\n",
      "    self.llm_engine = LLMEngine.from_engine_args(engine_args)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 246, in from_engine_args\n",
      "    engine = cls(*engine_configs,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 109, in __init__\n",
      "    self._init_workers(distributed_init_method)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 145, in _init_workers\n",
      "    self._run_workers(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 750, in _run_workers\n",
      "    self._run_workers_in_batch(workers, method, *args, **kwargs))\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 724, in _run_workers_in_batch\n",
      "    output = executor(*args, **kwargs)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/worker/worker.py\", line 72, in load_model\n",
      "    self.model_runner.load_model()\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 36, in load_model\n",
      "    self.model = get_model(self.model_config)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/model_loader.py\", line 124, in get_model\n",
      "    model.load_weights(model_config.model, model_config.download_dir,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 335, in load_weights\n",
      "    weight_loader(param, loaded_weight, shard_id)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 303, in weight_loader\n",
      "    param_data.copy_(loaded_weight)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_eval.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859d6d6",
   "metadata": {},
   "source": [
    "# Visualize Eval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b033ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./1387915.out does not have `--save_dir` specified. Probably still running.\n",
      "./1387916.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1387899.out exited with error code. --save_dir=results/oi5_dolly:llama-7b/llama-7b_dolly_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=chatgpt_chatfmt\n"
     ]
    }
   ],
   "source": [
    "# if job successfully ran, lsf system will generate a summary in log_dir,\n",
    "# call this function to move lsf summary to save_dir if job is successful.\n",
    "move_lsf_job_summary_to_save_dir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4392e9ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_fmt=mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aa45f td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_aa45f_row0_col0, #T_aa45f_row1_col0, #T_aa45f_row2_col0, #T_aa45f_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_aa45f_row0_col1, #T_aa45f_row1_col1, #T_aa45f_row2_col1, #T_aa45f_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_aa45f_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row0_col4, #T_aa45f_row0_col6, #T_aa45f_row0_col8, #T_aa45f_row0_col9, #T_aa45f_row1_col10, #T_aa45f_row2_col2, #T_aa45f_row2_col3, #T_aa45f_row2_col5, #T_aa45f_row2_col7, #T_aa45f_row2_col11, #T_aa45f_row2_col12, #T_aa45f_row2_col13, #T_aa45f_row2_col17, #T_aa45f_row3_col14, #T_aa45f_row3_col15, #T_aa45f_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa45f_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa45f_row0_col10, #T_aa45f_row0_col11, #T_aa45f_row0_col12, #T_aa45f_row0_col16, #T_aa45f_row0_col17, #T_aa45f_row1_col13, #T_aa45f_row1_col14, #T_aa45f_row1_col15, #T_aa45f_row1_col17, #T_aa45f_row3_col2, #T_aa45f_row3_col3, #T_aa45f_row3_col4, #T_aa45f_row3_col5, #T_aa45f_row3_col6, #T_aa45f_row3_col7, #T_aa45f_row3_col8, #T_aa45f_row3_col9, #T_aa45f_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa45f_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa45f_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa45f_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row1_col6, #T_aa45f_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa45f_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa45f_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #b3cdfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa45f_row2_col6, #T_aa45f_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa45f_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_aa45f_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa45f_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa45f_row3_col11, #T_aa45f_row3_col12, #T_aa45f_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aa45f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aa45f_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_aa45f_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_aa45f_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_aa45f_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_aa45f_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_aa45f_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_aa45f_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_aa45f_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_aa45f_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_aa45f_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_aa45f_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_aa45f_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_aa45f_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_aa45f_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_aa45f_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_aa45f_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_aa45f_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_aa45f_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aa45f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aa45f_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_aa45f_row0_col1\" class=\"data row0 col1\" >10000</td>\n",
       "      <td id=\"T_aa45f_row0_col2\" class=\"data row0 col2\" >34.7</td>\n",
       "      <td id=\"T_aa45f_row0_col3\" class=\"data row0 col3\" >37.0</td>\n",
       "      <td id=\"T_aa45f_row0_col4\" class=\"data row0 col4\" >3.4</td>\n",
       "      <td id=\"T_aa45f_row0_col5\" class=\"data row0 col5\" >10.0</td>\n",
       "      <td id=\"T_aa45f_row0_col6\" class=\"data row0 col6\" >30.9</td>\n",
       "      <td id=\"T_aa45f_row0_col7\" class=\"data row0 col7\" >30.1</td>\n",
       "      <td id=\"T_aa45f_row0_col8\" class=\"data row0 col8\" >6.4</td>\n",
       "      <td id=\"T_aa45f_row0_col9\" class=\"data row0 col9\" >35.4</td>\n",
       "      <td id=\"T_aa45f_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_aa45f_row0_col11\" class=\"data row0 col11\" >22.5</td>\n",
       "      <td id=\"T_aa45f_row0_col12\" class=\"data row0 col12\" >298.0</td>\n",
       "      <td id=\"T_aa45f_row0_col13\" class=\"data row0 col13\" >33.6</td>\n",
       "      <td id=\"T_aa45f_row0_col14\" class=\"data row0 col14\" >18.1</td>\n",
       "      <td id=\"T_aa45f_row0_col15\" class=\"data row0 col15\" >25.9</td>\n",
       "      <td id=\"T_aa45f_row0_col16\" class=\"data row0 col16\" >42.6</td>\n",
       "      <td id=\"T_aa45f_row0_col17\" class=\"data row0 col17\" >-23.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa45f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_aa45f_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_aa45f_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_aa45f_row1_col2\" class=\"data row1 col2\" >33.3</td>\n",
       "      <td id=\"T_aa45f_row1_col3\" class=\"data row1 col3\" >37.1</td>\n",
       "      <td id=\"T_aa45f_row1_col4\" class=\"data row1 col4\" >4.6</td>\n",
       "      <td id=\"T_aa45f_row1_col5\" class=\"data row1 col5\" >9.4</td>\n",
       "      <td id=\"T_aa45f_row1_col6\" class=\"data row1 col6\" >31.4</td>\n",
       "      <td id=\"T_aa45f_row1_col7\" class=\"data row1 col7\" >28.7</td>\n",
       "      <td id=\"T_aa45f_row1_col8\" class=\"data row1 col8\" >7.3</td>\n",
       "      <td id=\"T_aa45f_row1_col9\" class=\"data row1 col9\" >35.9</td>\n",
       "      <td id=\"T_aa45f_row1_col10\" class=\"data row1 col10\" >7.5</td>\n",
       "      <td id=\"T_aa45f_row1_col11\" class=\"data row1 col11\" >19.2</td>\n",
       "      <td id=\"T_aa45f_row1_col12\" class=\"data row1 col12\" >172.6</td>\n",
       "      <td id=\"T_aa45f_row1_col13\" class=\"data row1 col13\" >38.2</td>\n",
       "      <td id=\"T_aa45f_row1_col14\" class=\"data row1 col14\" >20.0</td>\n",
       "      <td id=\"T_aa45f_row1_col15\" class=\"data row1 col15\" >29.1</td>\n",
       "      <td id=\"T_aa45f_row1_col16\" class=\"data row1 col16\" >33.9</td>\n",
       "      <td id=\"T_aa45f_row1_col17\" class=\"data row1 col17\" >-23.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa45f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_aa45f_row2_col0\" class=\"data row2 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_aa45f_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_aa45f_row2_col2\" class=\"data row2 col2\" >30.9</td>\n",
       "      <td id=\"T_aa45f_row2_col3\" class=\"data row2 col3\" >34.8</td>\n",
       "      <td id=\"T_aa45f_row2_col4\" class=\"data row2 col4\" >5.0</td>\n",
       "      <td id=\"T_aa45f_row2_col5\" class=\"data row2 col5\" >8.4</td>\n",
       "      <td id=\"T_aa45f_row2_col6\" class=\"data row2 col6\" >32.9</td>\n",
       "      <td id=\"T_aa45f_row2_col7\" class=\"data row2 col7\" >25.7</td>\n",
       "      <td id=\"T_aa45f_row2_col8\" class=\"data row2 col8\" >8.0</td>\n",
       "      <td id=\"T_aa45f_row2_col9\" class=\"data row2 col9\" >41.0</td>\n",
       "      <td id=\"T_aa45f_row2_col10\" class=\"data row2 col10\" >7.9</td>\n",
       "      <td id=\"T_aa45f_row2_col11\" class=\"data row2 col11\" >15.5</td>\n",
       "      <td id=\"T_aa45f_row2_col12\" class=\"data row2 col12\" >101.5</td>\n",
       "      <td id=\"T_aa45f_row2_col13\" class=\"data row2 col13\" >33.2</td>\n",
       "      <td id=\"T_aa45f_row2_col14\" class=\"data row2 col14\" >17.7</td>\n",
       "      <td id=\"T_aa45f_row2_col15\" class=\"data row2 col15\" >25.5</td>\n",
       "      <td id=\"T_aa45f_row2_col16\" class=\"data row2 col16\" >27.7</td>\n",
       "      <td id=\"T_aa45f_row2_col17\" class=\"data row2 col17\" >-25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa45f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_aa45f_row3_col0\" class=\"data row3 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_aa45f_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_aa45f_row3_col2\" class=\"data row3 col2\" >38.5</td>\n",
       "      <td id=\"T_aa45f_row3_col3\" class=\"data row3 col3\" >38.5</td>\n",
       "      <td id=\"T_aa45f_row3_col4\" class=\"data row3 col4\" >5.4</td>\n",
       "      <td id=\"T_aa45f_row3_col5\" class=\"data row3 col5\" >10.8</td>\n",
       "      <td id=\"T_aa45f_row3_col6\" class=\"data row3 col6\" >34.0</td>\n",
       "      <td id=\"T_aa45f_row3_col7\" class=\"data row3 col7\" >31.3</td>\n",
       "      <td id=\"T_aa45f_row3_col8\" class=\"data row3 col8\" >9.0</td>\n",
       "      <td id=\"T_aa45f_row3_col9\" class=\"data row3 col9\" >44.0</td>\n",
       "      <td id=\"T_aa45f_row3_col10\" class=\"data row3 col10\" >10.4</td>\n",
       "      <td id=\"T_aa45f_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_aa45f_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_aa45f_row3_col13\" class=\"data row3 col13\" >34.0</td>\n",
       "      <td id=\"T_aa45f_row3_col14\" class=\"data row3 col14\" >16.8</td>\n",
       "      <td id=\"T_aa45f_row3_col15\" class=\"data row3 col15\" >25.5</td>\n",
       "      <td id=\"T_aa45f_row3_col16\" class=\"data row3 col16\" >24.8</td>\n",
       "      <td id=\"T_aa45f_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe8b0c70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b3779 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_b3779_row0_col0, #T_b3779_row1_col0, #T_b3779_row2_col0, #T_b3779_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b3779_row0_col1, #T_b3779_row1_col1, #T_b3779_row2_col1, #T_b3779_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b3779_row0_col2, #T_b3779_row0_col3, #T_b3779_row0_col6, #T_b3779_row0_col7, #T_b3779_row0_col11, #T_b3779_row0_col17, #T_b3779_row1_col8, #T_b3779_row1_col9, #T_b3779_row1_col10, #T_b3779_row2_col4, #T_b3779_row2_col5, #T_b3779_row2_col7, #T_b3779_row2_col12, #T_b3779_row3_col10, #T_b3779_row3_col13, #T_b3779_row3_col14, #T_b3779_row3_col15, #T_b3779_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3779_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3779_row0_col8, #T_b3779_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3779_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3779_row0_col10, #T_b3779_row0_col12, #T_b3779_row0_col14, #T_b3779_row0_col16, #T_b3779_row1_col3, #T_b3779_row1_col4, #T_b3779_row1_col7, #T_b3779_row1_col11, #T_b3779_row1_col17, #T_b3779_row2_col6, #T_b3779_row2_col13, #T_b3779_row2_col15, #T_b3779_row3_col2, #T_b3779_row3_col5, #T_b3779_row3_col8, #T_b3779_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3779_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3779_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row2_col2, #T_b3779_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3779_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3779_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3779_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3779_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3779_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3779_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3779_row3_col11, #T_b3779_row3_col12, #T_b3779_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b3779\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b3779_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_b3779_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_b3779_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_b3779_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_b3779_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_b3779_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_b3779_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_b3779_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_b3779_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_b3779_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_b3779_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_b3779_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_b3779_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_b3779_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_b3779_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_b3779_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_b3779_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_b3779_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b3779_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b3779_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_b3779_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_b3779_row0_col2\" class=\"data row0 col2\" >36.1</td>\n",
       "      <td id=\"T_b3779_row0_col3\" class=\"data row0 col3\" >35.0</td>\n",
       "      <td id=\"T_b3779_row0_col4\" class=\"data row0 col4\" >4.4</td>\n",
       "      <td id=\"T_b3779_row0_col5\" class=\"data row0 col5\" >10.2</td>\n",
       "      <td id=\"T_b3779_row0_col6\" class=\"data row0 col6\" >31.2</td>\n",
       "      <td id=\"T_b3779_row0_col7\" class=\"data row0 col7\" >30.3</td>\n",
       "      <td id=\"T_b3779_row0_col8\" class=\"data row0 col8\" >8.6</td>\n",
       "      <td id=\"T_b3779_row0_col9\" class=\"data row0 col9\" >42.1</td>\n",
       "      <td id=\"T_b3779_row0_col10\" class=\"data row0 col10\" >11.6</td>\n",
       "      <td id=\"T_b3779_row0_col11\" class=\"data row0 col11\" >12.0</td>\n",
       "      <td id=\"T_b3779_row0_col12\" class=\"data row0 col12\" >277.6</td>\n",
       "      <td id=\"T_b3779_row0_col13\" class=\"data row0 col13\" >35.8</td>\n",
       "      <td id=\"T_b3779_row0_col14\" class=\"data row0 col14\" >19.7</td>\n",
       "      <td id=\"T_b3779_row0_col15\" class=\"data row0 col15\" >27.8</td>\n",
       "      <td id=\"T_b3779_row0_col16\" class=\"data row0 col16\" >41.6</td>\n",
       "      <td id=\"T_b3779_row0_col17\" class=\"data row0 col17\" >-19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3779_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b3779_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_b3779_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_b3779_row1_col2\" class=\"data row1 col2\" >36.6</td>\n",
       "      <td id=\"T_b3779_row1_col3\" class=\"data row1 col3\" >39.2</td>\n",
       "      <td id=\"T_b3779_row1_col4\" class=\"data row1 col4\" >5.6</td>\n",
       "      <td id=\"T_b3779_row1_col5\" class=\"data row1 col5\" >9.6</td>\n",
       "      <td id=\"T_b3779_row1_col6\" class=\"data row1 col6\" >33.5</td>\n",
       "      <td id=\"T_b3779_row1_col7\" class=\"data row1 col7\" >33.1</td>\n",
       "      <td id=\"T_b3779_row1_col8\" class=\"data row1 col8\" >7.5</td>\n",
       "      <td id=\"T_b3779_row1_col9\" class=\"data row1 col9\" >37.7</td>\n",
       "      <td id=\"T_b3779_row1_col10\" class=\"data row1 col10\" >10.4</td>\n",
       "      <td id=\"T_b3779_row1_col11\" class=\"data row1 col11\" >17.6</td>\n",
       "      <td id=\"T_b3779_row1_col12\" class=\"data row1 col12\" >263.1</td>\n",
       "      <td id=\"T_b3779_row1_col13\" class=\"data row1 col13\" >38.5</td>\n",
       "      <td id=\"T_b3779_row1_col14\" class=\"data row1 col14\" >19.5</td>\n",
       "      <td id=\"T_b3779_row1_col15\" class=\"data row1 col15\" >29.1</td>\n",
       "      <td id=\"T_b3779_row1_col16\" class=\"data row1 col16\" >41.5</td>\n",
       "      <td id=\"T_b3779_row1_col17\" class=\"data row1 col17\" >-17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3779_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b3779_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_b3779_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_b3779_row2_col2\" class=\"data row2 col2\" >36.9</td>\n",
       "      <td id=\"T_b3779_row2_col3\" class=\"data row2 col3\" >37.1</td>\n",
       "      <td id=\"T_b3779_row2_col4\" class=\"data row2 col4\" >3.0</td>\n",
       "      <td id=\"T_b3779_row2_col5\" class=\"data row2 col5\" >9.4</td>\n",
       "      <td id=\"T_b3779_row2_col6\" class=\"data row2 col6\" >34.1</td>\n",
       "      <td id=\"T_b3779_row2_col7\" class=\"data row2 col7\" >30.3</td>\n",
       "      <td id=\"T_b3779_row2_col8\" class=\"data row2 col8\" >8.0</td>\n",
       "      <td id=\"T_b3779_row2_col9\" class=\"data row2 col9\" >40.9</td>\n",
       "      <td id=\"T_b3779_row2_col10\" class=\"data row2 col10\" >10.6</td>\n",
       "      <td id=\"T_b3779_row2_col11\" class=\"data row2 col11\" >13.9</td>\n",
       "      <td id=\"T_b3779_row2_col12\" class=\"data row2 col12\" >260.5</td>\n",
       "      <td id=\"T_b3779_row2_col13\" class=\"data row2 col13\" >40.1</td>\n",
       "      <td id=\"T_b3779_row2_col14\" class=\"data row2 col14\" >18.2</td>\n",
       "      <td id=\"T_b3779_row2_col15\" class=\"data row2 col15\" >29.4</td>\n",
       "      <td id=\"T_b3779_row2_col16\" class=\"data row2 col16\" >40.9</td>\n",
       "      <td id=\"T_b3779_row2_col17\" class=\"data row2 col17\" >-19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3779_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b3779_row3_col0\" class=\"data row3 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_b3779_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_b3779_row3_col2\" class=\"data row3 col2\" >38.5</td>\n",
       "      <td id=\"T_b3779_row3_col3\" class=\"data row3 col3\" >38.5</td>\n",
       "      <td id=\"T_b3779_row3_col4\" class=\"data row3 col4\" >5.4</td>\n",
       "      <td id=\"T_b3779_row3_col5\" class=\"data row3 col5\" >10.8</td>\n",
       "      <td id=\"T_b3779_row3_col6\" class=\"data row3 col6\" >34.0</td>\n",
       "      <td id=\"T_b3779_row3_col7\" class=\"data row3 col7\" >31.3</td>\n",
       "      <td id=\"T_b3779_row3_col8\" class=\"data row3 col8\" >9.0</td>\n",
       "      <td id=\"T_b3779_row3_col9\" class=\"data row3 col9\" >44.0</td>\n",
       "      <td id=\"T_b3779_row3_col10\" class=\"data row3 col10\" >10.4</td>\n",
       "      <td id=\"T_b3779_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_b3779_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_b3779_row3_col13\" class=\"data row3 col13\" >34.0</td>\n",
       "      <td id=\"T_b3779_row3_col14\" class=\"data row3 col14\" >16.8</td>\n",
       "      <td id=\"T_b3779_row3_col15\" class=\"data row3 col15\" >25.5</td>\n",
       "      <td id=\"T_b3779_row3_col16\" class=\"data row3 col16\" >24.8</td>\n",
       "      <td id=\"T_b3779_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfea45fc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c1b2e td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_c1b2e_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c1b2e_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c1b2e_row0_col2, #T_c1b2e_row0_col3, #T_c1b2e_row0_col4, #T_c1b2e_row0_col5, #T_c1b2e_row0_col6, #T_c1b2e_row0_col7, #T_c1b2e_row0_col8, #T_c1b2e_row0_col9, #T_c1b2e_row0_col10, #T_c1b2e_row0_col13, #T_c1b2e_row0_col14, #T_c1b2e_row0_col15, #T_c1b2e_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c1b2e_row0_col11, #T_c1b2e_row0_col12, #T_c1b2e_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c1b2e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c1b2e_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_c1b2e_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_c1b2e_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_c1b2e_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_c1b2e_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_c1b2e_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_c1b2e_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_c1b2e_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_c1b2e_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_c1b2e_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_c1b2e_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_c1b2e_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_c1b2e_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_c1b2e_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_c1b2e_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_c1b2e_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_c1b2e_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_c1b2e_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c1b2e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c1b2e_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_c1b2e_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_c1b2e_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_c1b2e_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_c1b2e_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_c1b2e_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_c1b2e_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_c1b2e_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_c1b2e_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_c1b2e_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_c1b2e_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_c1b2e_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_c1b2e_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_c1b2e_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_c1b2e_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_c1b2e_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_c1b2e_row0_col16\" class=\"data row0 col16\" >24.8</td>\n",
       "      <td id=\"T_c1b2e_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cff8a0100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_87536 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_87536_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_87536_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_87536_row0_col2, #T_87536_row0_col3, #T_87536_row0_col4, #T_87536_row0_col5, #T_87536_row0_col6, #T_87536_row0_col7, #T_87536_row0_col8, #T_87536_row0_col9, #T_87536_row0_col10, #T_87536_row0_col13, #T_87536_row0_col14, #T_87536_row0_col15, #T_87536_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_87536_row0_col11, #T_87536_row0_col12, #T_87536_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_87536\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_87536_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_87536_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_87536_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_87536_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_87536_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_87536_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_87536_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_87536_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_87536_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_87536_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_87536_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_87536_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_87536_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_87536_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_87536_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_87536_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_87536_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_87536_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_87536_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_87536_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_87536_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_87536_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_87536_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_87536_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_87536_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_87536_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_87536_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_87536_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_87536_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_87536_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_87536_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_87536_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_87536_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_87536_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_87536_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_87536_row0_col16\" class=\"data row0 col16\" >24.8</td>\n",
       "      <td id=\"T_87536_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe774a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d824b td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_d824b_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d824b_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d824b_row0_col2, #T_d824b_row0_col3, #T_d824b_row0_col4, #T_d824b_row0_col5, #T_d824b_row0_col6, #T_d824b_row0_col7, #T_d824b_row0_col8, #T_d824b_row0_col9, #T_d824b_row0_col10, #T_d824b_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d824b_row0_col11, #T_d824b_row0_col12, #T_d824b_row0_col13, #T_d824b_row0_col14, #T_d824b_row0_col15, #T_d824b_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d824b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d824b_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d824b_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_d824b_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d824b_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d824b_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_d824b_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_d824b_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_d824b_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_d824b_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d824b_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d824b_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d824b_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_d824b_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_d824b_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_d824b_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_d824b_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_d824b_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_d824b_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d824b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d824b_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_d824b_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_d824b_row0_col2\" class=\"data row0 col2\" >44.3</td>\n",
       "      <td id=\"T_d824b_row0_col3\" class=\"data row0 col3\" >45.7</td>\n",
       "      <td id=\"T_d824b_row0_col4\" class=\"data row0 col4\" >3.0</td>\n",
       "      <td id=\"T_d824b_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_d824b_row0_col6\" class=\"data row0 col6\" >36.8</td>\n",
       "      <td id=\"T_d824b_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_d824b_row0_col8\" class=\"data row0 col8\" >8.4</td>\n",
       "      <td id=\"T_d824b_row0_col9\" class=\"data row0 col9\" >43.3</td>\n",
       "      <td id=\"T_d824b_row0_col10\" class=\"data row0 col10\" >8.5</td>\n",
       "      <td id=\"T_d824b_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_d824b_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_d824b_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_d824b_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_d824b_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_d824b_row0_col16\" class=\"data row0 col16\" >26.3</td>\n",
       "      <td id=\"T_d824b_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cff8a1540>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ee75c td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_ee75c_row0_col0, #T_ee75c_row1_col0, #T_ee75c_row2_col0, #T_ee75c_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ee75c_row0_col1, #T_ee75c_row1_col1, #T_ee75c_row2_col1, #T_ee75c_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ee75c_row0_col2, #T_ee75c_row0_col3, #T_ee75c_row0_col6, #T_ee75c_row0_col7, #T_ee75c_row0_col9, #T_ee75c_row0_col16, #T_ee75c_row1_col4, #T_ee75c_row1_col14, #T_ee75c_row2_col13, #T_ee75c_row3_col5, #T_ee75c_row3_col8, #T_ee75c_row3_col10, #T_ee75c_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee75c_row0_col4, #T_ee75c_row0_col10, #T_ee75c_row1_col13, #T_ee75c_row1_col15, #T_ee75c_row2_col5, #T_ee75c_row2_col7, #T_ee75c_row2_col8, #T_ee75c_row2_col9, #T_ee75c_row2_col14, #T_ee75c_row3_col2, #T_ee75c_row3_col3, #T_ee75c_row3_col6, #T_ee75c_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee75c_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee75c_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee75c_row0_col11, #T_ee75c_row0_col12, #T_ee75c_row0_col13, #T_ee75c_row0_col14, #T_ee75c_row0_col15, #T_ee75c_row0_col17, #T_ee75c_row1_col11, #T_ee75c_row1_col12, #T_ee75c_row1_col17, #T_ee75c_row2_col11, #T_ee75c_row2_col12, #T_ee75c_row2_col17, #T_ee75c_row3_col11, #T_ee75c_row3_col12, #T_ee75c_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee75c_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee75c_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee75c_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee75c_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee75c_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee75c_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee75c_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee75c_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee75c_row1_col16, #T_ee75c_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee75c_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee75c_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee75c_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee75c_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee75c_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee75c_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee75c_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee75c_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee75c_row3_col9, #T_ee75c_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee75c_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ee75c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ee75c_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_ee75c_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_ee75c_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_ee75c_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_ee75c_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_ee75c_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_ee75c_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_ee75c_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_ee75c_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_ee75c_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_ee75c_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_ee75c_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_ee75c_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_ee75c_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_ee75c_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_ee75c_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_ee75c_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_ee75c_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ee75c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ee75c_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_ee75c_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_ee75c_row0_col2\" class=\"data row0 col2\" >44.3</td>\n",
       "      <td id=\"T_ee75c_row0_col3\" class=\"data row0 col3\" >45.7</td>\n",
       "      <td id=\"T_ee75c_row0_col4\" class=\"data row0 col4\" >3.0</td>\n",
       "      <td id=\"T_ee75c_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_ee75c_row0_col6\" class=\"data row0 col6\" >36.8</td>\n",
       "      <td id=\"T_ee75c_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_ee75c_row0_col8\" class=\"data row0 col8\" >8.4</td>\n",
       "      <td id=\"T_ee75c_row0_col9\" class=\"data row0 col9\" >43.3</td>\n",
       "      <td id=\"T_ee75c_row0_col10\" class=\"data row0 col10\" >8.5</td>\n",
       "      <td id=\"T_ee75c_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_ee75c_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_ee75c_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_ee75c_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_ee75c_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_ee75c_row0_col16\" class=\"data row0 col16\" >26.3</td>\n",
       "      <td id=\"T_ee75c_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee75c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ee75c_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v250k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_ee75c_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_ee75c_row1_col2\" class=\"data row1 col2\" >42.0</td>\n",
       "      <td id=\"T_ee75c_row1_col3\" class=\"data row1 col3\" >42.2</td>\n",
       "      <td id=\"T_ee75c_row1_col4\" class=\"data row1 col4\" >5.6</td>\n",
       "      <td id=\"T_ee75c_row1_col5\" class=\"data row1 col5\" >12.0</td>\n",
       "      <td id=\"T_ee75c_row1_col6\" class=\"data row1 col6\" >33.9</td>\n",
       "      <td id=\"T_ee75c_row1_col7\" class=\"data row1 col7\" >33.3</td>\n",
       "      <td id=\"T_ee75c_row1_col8\" class=\"data row1 col8\" >8.1</td>\n",
       "      <td id=\"T_ee75c_row1_col9\" class=\"data row1 col9\" >38.6</td>\n",
       "      <td id=\"T_ee75c_row1_col10\" class=\"data row1 col10\" >9.1</td>\n",
       "      <td id=\"T_ee75c_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_ee75c_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_ee75c_row1_col13\" class=\"data row1 col13\" >23.5</td>\n",
       "      <td id=\"T_ee75c_row1_col14\" class=\"data row1 col14\" >18.4</td>\n",
       "      <td id=\"T_ee75c_row1_col15\" class=\"data row1 col15\" >20.9</td>\n",
       "      <td id=\"T_ee75c_row1_col16\" class=\"data row1 col16\" >24.0</td>\n",
       "      <td id=\"T_ee75c_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee75c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ee75c_row2_col0\" class=\"data row2 col0\" >llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_ee75c_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_ee75c_row2_col2\" class=\"data row2 col2\" >41.6</td>\n",
       "      <td id=\"T_ee75c_row2_col3\" class=\"data row2 col3\" >40.0</td>\n",
       "      <td id=\"T_ee75c_row2_col4\" class=\"data row2 col4\" >3.4</td>\n",
       "      <td id=\"T_ee75c_row2_col5\" class=\"data row2 col5\" >10.8</td>\n",
       "      <td id=\"T_ee75c_row2_col6\" class=\"data row2 col6\" >36.2</td>\n",
       "      <td id=\"T_ee75c_row2_col7\" class=\"data row2 col7\" >32.4</td>\n",
       "      <td id=\"T_ee75c_row2_col8\" class=\"data row2 col8\" >7.4</td>\n",
       "      <td id=\"T_ee75c_row2_col9\" class=\"data row2 col9\" >37.3</td>\n",
       "      <td id=\"T_ee75c_row2_col10\" class=\"data row2 col10\" >8.9</td>\n",
       "      <td id=\"T_ee75c_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_ee75c_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_ee75c_row2_col13\" class=\"data row2 col13\" >25.9</td>\n",
       "      <td id=\"T_ee75c_row2_col14\" class=\"data row2 col14\" >16.2</td>\n",
       "      <td id=\"T_ee75c_row2_col15\" class=\"data row2 col15\" >21.1</td>\n",
       "      <td id=\"T_ee75c_row2_col16\" class=\"data row2 col16\" >23.4</td>\n",
       "      <td id=\"T_ee75c_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee75c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ee75c_row3_col0\" class=\"data row3 col0\" >llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_ee75c_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_ee75c_row3_col2\" class=\"data row3 col2\" >34.9</td>\n",
       "      <td id=\"T_ee75c_row3_col3\" class=\"data row3 col3\" >34.1</td>\n",
       "      <td id=\"T_ee75c_row3_col4\" class=\"data row3 col4\" >5.0</td>\n",
       "      <td id=\"T_ee75c_row3_col5\" class=\"data row3 col5\" >15.4</td>\n",
       "      <td id=\"T_ee75c_row3_col6\" class=\"data row3 col6\" >31.7</td>\n",
       "      <td id=\"T_ee75c_row3_col7\" class=\"data row3 col7\" >34.0</td>\n",
       "      <td id=\"T_ee75c_row3_col8\" class=\"data row3 col8\" >8.9</td>\n",
       "      <td id=\"T_ee75c_row3_col9\" class=\"data row3 col9\" >42.2</td>\n",
       "      <td id=\"T_ee75c_row3_col10\" class=\"data row3 col10\" >10.6</td>\n",
       "      <td id=\"T_ee75c_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_ee75c_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_ee75c_row3_col13\" class=\"data row3 col13\" >24.6</td>\n",
       "      <td id=\"T_ee75c_row3_col14\" class=\"data row3 col14\" >18.0</td>\n",
       "      <td id=\"T_ee75c_row3_col15\" class=\"data row3 col15\" >21.3</td>\n",
       "      <td id=\"T_ee75c_row3_col16\" class=\"data row3 col16\" >23.4</td>\n",
       "      <td id=\"T_ee75c_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cff8a0100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bdf34 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_bdf34_row0_col0, #T_bdf34_row1_col0, #T_bdf34_row2_col0, #T_bdf34_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bdf34_row0_col1, #T_bdf34_row1_col1, #T_bdf34_row2_col1, #T_bdf34_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bdf34_row0_col2, #T_bdf34_row0_col4, #T_bdf34_row0_col5, #T_bdf34_row0_col14, #T_bdf34_row0_col16, #T_bdf34_row1_col2, #T_bdf34_row1_col3, #T_bdf34_row1_col6, #T_bdf34_row1_col8, #T_bdf34_row1_col9, #T_bdf34_row2_col7, #T_bdf34_row2_col13, #T_bdf34_row2_col15, #T_bdf34_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bdf34_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bdf34_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bdf34_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bdf34_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bdf34_row0_col9, #T_bdf34_row0_col13, #T_bdf34_row1_col4, #T_bdf34_row1_col5, #T_bdf34_row1_col10, #T_bdf34_row2_col2, #T_bdf34_row2_col3, #T_bdf34_row2_col6, #T_bdf34_row2_col8, #T_bdf34_row3_col7, #T_bdf34_row3_col14, #T_bdf34_row3_col15, #T_bdf34_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bdf34_row0_col10, #T_bdf34_row0_col11, #T_bdf34_row0_col12, #T_bdf34_row0_col17, #T_bdf34_row1_col11, #T_bdf34_row1_col12, #T_bdf34_row1_col13, #T_bdf34_row1_col14, #T_bdf34_row1_col15, #T_bdf34_row1_col17, #T_bdf34_row2_col11, #T_bdf34_row2_col12, #T_bdf34_row2_col17, #T_bdf34_row3_col11, #T_bdf34_row3_col12, #T_bdf34_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bdf34_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bdf34_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bdf34_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bdf34_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bdf34_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bdf34_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bdf34_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bdf34_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bdf34_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bdf34_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bdf34_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bdf34_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bdf34_row3_col5, #T_bdf34_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bdf34_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bdf34_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bdf34_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bdf34\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bdf34_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_bdf34_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_bdf34_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_bdf34_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_bdf34_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_bdf34_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_bdf34_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_bdf34_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_bdf34_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_bdf34_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_bdf34_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_bdf34_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_bdf34_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_bdf34_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_bdf34_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_bdf34_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_bdf34_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_bdf34_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bdf34_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bdf34_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_bdf34_row0_col1\" class=\"data row0 col1\" >60000</td>\n",
       "      <td id=\"T_bdf34_row0_col2\" class=\"data row0 col2\" >44.3</td>\n",
       "      <td id=\"T_bdf34_row0_col3\" class=\"data row0 col3\" >45.1</td>\n",
       "      <td id=\"T_bdf34_row0_col4\" class=\"data row0 col4\" >4.4</td>\n",
       "      <td id=\"T_bdf34_row0_col5\" class=\"data row0 col5\" >14.8</td>\n",
       "      <td id=\"T_bdf34_row0_col6\" class=\"data row0 col6\" >36.3</td>\n",
       "      <td id=\"T_bdf34_row0_col7\" class=\"data row0 col7\" >34.3</td>\n",
       "      <td id=\"T_bdf34_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_bdf34_row0_col9\" class=\"data row0 col9\" >40.2</td>\n",
       "      <td id=\"T_bdf34_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_bdf34_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_bdf34_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_bdf34_row0_col13\" class=\"data row0 col13\" >22.1</td>\n",
       "      <td id=\"T_bdf34_row0_col14\" class=\"data row0 col14\" >19.0</td>\n",
       "      <td id=\"T_bdf34_row0_col15\" class=\"data row0 col15\" >20.6</td>\n",
       "      <td id=\"T_bdf34_row0_col16\" class=\"data row0 col16\" >26.3</td>\n",
       "      <td id=\"T_bdf34_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bdf34_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bdf34_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_bdf34_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_bdf34_row1_col2\" class=\"data row1 col2\" >44.3</td>\n",
       "      <td id=\"T_bdf34_row1_col3\" class=\"data row1 col3\" >45.7</td>\n",
       "      <td id=\"T_bdf34_row1_col4\" class=\"data row1 col4\" >3.0</td>\n",
       "      <td id=\"T_bdf34_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_bdf34_row1_col6\" class=\"data row1 col6\" >36.8</td>\n",
       "      <td id=\"T_bdf34_row1_col7\" class=\"data row1 col7\" >34.4</td>\n",
       "      <td id=\"T_bdf34_row1_col8\" class=\"data row1 col8\" >8.4</td>\n",
       "      <td id=\"T_bdf34_row1_col9\" class=\"data row1 col9\" >43.3</td>\n",
       "      <td id=\"T_bdf34_row1_col10\" class=\"data row1 col10\" >8.5</td>\n",
       "      <td id=\"T_bdf34_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_bdf34_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_bdf34_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_bdf34_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_bdf34_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_bdf34_row1_col16\" class=\"data row1 col16\" >26.3</td>\n",
       "      <td id=\"T_bdf34_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bdf34_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bdf34_row2_col0\" class=\"data row2 col0\" >llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_bdf34_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_bdf34_row2_col2\" class=\"data row2 col2\" >40.6</td>\n",
       "      <td id=\"T_bdf34_row2_col3\" class=\"data row2 col3\" >41.1</td>\n",
       "      <td id=\"T_bdf34_row2_col4\" class=\"data row2 col4\" >4.0</td>\n",
       "      <td id=\"T_bdf34_row2_col5\" class=\"data row2 col5\" >12.4</td>\n",
       "      <td id=\"T_bdf34_row2_col6\" class=\"data row2 col6\" >33.7</td>\n",
       "      <td id=\"T_bdf34_row2_col7\" class=\"data row2 col7\" >35.6</td>\n",
       "      <td id=\"T_bdf34_row2_col8\" class=\"data row2 col8\" >7.9</td>\n",
       "      <td id=\"T_bdf34_row2_col9\" class=\"data row2 col9\" >40.4</td>\n",
       "      <td id=\"T_bdf34_row2_col10\" class=\"data row2 col10\" >8.7</td>\n",
       "      <td id=\"T_bdf34_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_bdf34_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_bdf34_row2_col13\" class=\"data row2 col13\" >24.0</td>\n",
       "      <td id=\"T_bdf34_row2_col14\" class=\"data row2 col14\" >18.4</td>\n",
       "      <td id=\"T_bdf34_row2_col15\" class=\"data row2 col15\" >21.2</td>\n",
       "      <td id=\"T_bdf34_row2_col16\" class=\"data row2 col16\" >24.0</td>\n",
       "      <td id=\"T_bdf34_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bdf34_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bdf34_row3_col0\" class=\"data row3 col0\" >llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_bdf34_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_bdf34_row3_col2\" class=\"data row3 col2\" >43.4</td>\n",
       "      <td id=\"T_bdf34_row3_col3\" class=\"data row3 col3\" >41.5</td>\n",
       "      <td id=\"T_bdf34_row3_col4\" class=\"data row3 col4\" >3.6</td>\n",
       "      <td id=\"T_bdf34_row3_col5\" class=\"data row3 col5\" >12.6</td>\n",
       "      <td id=\"T_bdf34_row3_col6\" class=\"data row3 col6\" >35.3</td>\n",
       "      <td id=\"T_bdf34_row3_col7\" class=\"data row3 col7\" >32.7</td>\n",
       "      <td id=\"T_bdf34_row3_col8\" class=\"data row3 col8\" >8.1</td>\n",
       "      <td id=\"T_bdf34_row3_col9\" class=\"data row3 col9\" >42.8</td>\n",
       "      <td id=\"T_bdf34_row3_col10\" class=\"data row3 col10\" >9.3</td>\n",
       "      <td id=\"T_bdf34_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_bdf34_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_bdf34_row3_col13\" class=\"data row3 col13\" >22.6</td>\n",
       "      <td id=\"T_bdf34_row3_col14\" class=\"data row3 col14\" >15.9</td>\n",
       "      <td id=\"T_bdf34_row3_col15\" class=\"data row3 col15\" >19.2</td>\n",
       "      <td id=\"T_bdf34_row3_col16\" class=\"data row3 col16\" >23.9</td>\n",
       "      <td id=\"T_bdf34_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cff8a03d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_30e0f td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_30e0f_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_30e0f_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_30e0f_row0_col2, #T_30e0f_row0_col3, #T_30e0f_row0_col4, #T_30e0f_row0_col5, #T_30e0f_row0_col6, #T_30e0f_row0_col7, #T_30e0f_row0_col8, #T_30e0f_row0_col9, #T_30e0f_row0_col10, #T_30e0f_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_30e0f_row0_col11, #T_30e0f_row0_col12, #T_30e0f_row0_col13, #T_30e0f_row0_col14, #T_30e0f_row0_col15, #T_30e0f_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_30e0f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_30e0f_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_30e0f_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_30e0f_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_30e0f_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_30e0f_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_30e0f_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_30e0f_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_30e0f_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_30e0f_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_30e0f_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_30e0f_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_30e0f_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_30e0f_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_30e0f_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_30e0f_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_30e0f_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_30e0f_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_30e0f_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_30e0f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_30e0f_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_30e0f_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_30e0f_row0_col2\" class=\"data row0 col2\" >44.3</td>\n",
       "      <td id=\"T_30e0f_row0_col3\" class=\"data row0 col3\" >45.7</td>\n",
       "      <td id=\"T_30e0f_row0_col4\" class=\"data row0 col4\" >3.0</td>\n",
       "      <td id=\"T_30e0f_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_30e0f_row0_col6\" class=\"data row0 col6\" >36.8</td>\n",
       "      <td id=\"T_30e0f_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_30e0f_row0_col8\" class=\"data row0 col8\" >8.4</td>\n",
       "      <td id=\"T_30e0f_row0_col9\" class=\"data row0 col9\" >43.3</td>\n",
       "      <td id=\"T_30e0f_row0_col10\" class=\"data row0 col10\" >8.5</td>\n",
       "      <td id=\"T_30e0f_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_30e0f_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_30e0f_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_30e0f_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_30e0f_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_30e0f_row0_col16\" class=\"data row0 col16\" >26.3</td>\n",
       "      <td id=\"T_30e0f_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe5a9ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9980d td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_9980d_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9980d_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9980d_row0_col2, #T_9980d_row0_col3, #T_9980d_row0_col4, #T_9980d_row0_col5, #T_9980d_row0_col6, #T_9980d_row0_col7, #T_9980d_row0_col8, #T_9980d_row0_col9, #T_9980d_row0_col10, #T_9980d_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9980d_row0_col11, #T_9980d_row0_col12, #T_9980d_row0_col13, #T_9980d_row0_col14, #T_9980d_row0_col15, #T_9980d_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9980d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9980d_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_9980d_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_9980d_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_9980d_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_9980d_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_9980d_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_9980d_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_9980d_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_9980d_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_9980d_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_9980d_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_9980d_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_9980d_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_9980d_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_9980d_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_9980d_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_9980d_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_9980d_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9980d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9980d_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_9980d_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_9980d_row0_col2\" class=\"data row0 col2\" >31.3</td>\n",
       "      <td id=\"T_9980d_row0_col3\" class=\"data row0 col3\" >34.6</td>\n",
       "      <td id=\"T_9980d_row0_col4\" class=\"data row0 col4\" >5.2</td>\n",
       "      <td id=\"T_9980d_row0_col5\" class=\"data row0 col5\" >10.2</td>\n",
       "      <td id=\"T_9980d_row0_col6\" class=\"data row0 col6\" >32.6</td>\n",
       "      <td id=\"T_9980d_row0_col7\" class=\"data row0 col7\" >32.8</td>\n",
       "      <td id=\"T_9980d_row0_col8\" class=\"data row0 col8\" >8.9</td>\n",
       "      <td id=\"T_9980d_row0_col9\" class=\"data row0 col9\" >31.9</td>\n",
       "      <td id=\"T_9980d_row0_col10\" class=\"data row0 col10\" >9.8</td>\n",
       "      <td id=\"T_9980d_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_9980d_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_9980d_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_9980d_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_9980d_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_9980d_row0_col16\" class=\"data row0 col16\" >21.9</td>\n",
       "      <td id=\"T_9980d_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe776140>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d5b97 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_d5b97_row0_col0, #T_d5b97_row1_col0, #T_d5b97_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d5b97_row0_col1, #T_d5b97_row1_col1, #T_d5b97_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d5b97_row0_col2, #T_d5b97_row0_col3, #T_d5b97_row0_col4, #T_d5b97_row0_col5, #T_d5b97_row0_col6, #T_d5b97_row0_col7, #T_d5b97_row0_col8, #T_d5b97_row0_col9, #T_d5b97_row0_col10, #T_d5b97_row0_col13, #T_d5b97_row0_col15, #T_d5b97_row1_col2, #T_d5b97_row1_col3, #T_d5b97_row1_col4, #T_d5b97_row1_col5, #T_d5b97_row1_col6, #T_d5b97_row1_col7, #T_d5b97_row1_col8, #T_d5b97_row1_col9, #T_d5b97_row1_col10, #T_d5b97_row1_col14, #T_d5b97_row2_col2, #T_d5b97_row2_col3, #T_d5b97_row2_col4, #T_d5b97_row2_col5, #T_d5b97_row2_col6, #T_d5b97_row2_col7, #T_d5b97_row2_col8, #T_d5b97_row2_col9, #T_d5b97_row2_col10, #T_d5b97_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d5b97_row0_col11, #T_d5b97_row0_col12, #T_d5b97_row0_col17, #T_d5b97_row1_col11, #T_d5b97_row1_col12, #T_d5b97_row1_col17, #T_d5b97_row2_col11, #T_d5b97_row2_col12, #T_d5b97_row2_col13, #T_d5b97_row2_col14, #T_d5b97_row2_col15, #T_d5b97_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d5b97_row0_col14, #T_d5b97_row0_col16, #T_d5b97_row1_col13, #T_d5b97_row1_col15, #T_d5b97_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d5b97\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d5b97_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d5b97_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_d5b97_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d5b97_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d5b97_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_d5b97_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_d5b97_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_d5b97_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_d5b97_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d5b97_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d5b97_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d5b97_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_d5b97_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_d5b97_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_d5b97_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_d5b97_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_d5b97_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_d5b97_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b97_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d5b97_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_d5b97_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_d5b97_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_d5b97_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "      <td id=\"T_d5b97_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "      <td id=\"T_d5b97_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_d5b97_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_d5b97_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_d5b97_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_d5b97_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "      <td id=\"T_d5b97_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_d5b97_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_d5b97_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_d5b97_row0_col13\" class=\"data row0 col13\" >39.5</td>\n",
       "      <td id=\"T_d5b97_row0_col14\" class=\"data row0 col14\" >27.6</td>\n",
       "      <td id=\"T_d5b97_row0_col15\" class=\"data row0 col15\" >33.6</td>\n",
       "      <td id=\"T_d5b97_row0_col16\" class=\"data row0 col16\" >33.6</td>\n",
       "      <td id=\"T_d5b97_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b97_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d5b97_row1_col0\" class=\"data row1 col0\" >llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_d5b97_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_d5b97_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_d5b97_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_d5b97_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_d5b97_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_d5b97_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_d5b97_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_d5b97_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_d5b97_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_d5b97_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_d5b97_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_d5b97_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_d5b97_row1_col13\" class=\"data row1 col13\" >39.8</td>\n",
       "      <td id=\"T_d5b97_row1_col14\" class=\"data row1 col14\" >27.3</td>\n",
       "      <td id=\"T_d5b97_row1_col15\" class=\"data row1 col15\" >33.6</td>\n",
       "      <td id=\"T_d5b97_row1_col16\" class=\"data row1 col16\" >33.6</td>\n",
       "      <td id=\"T_d5b97_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5b97_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d5b97_row2_col0\" class=\"data row2 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_d5b97_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_d5b97_row2_col2\" class=\"data row2 col2\" >31.3</td>\n",
       "      <td id=\"T_d5b97_row2_col3\" class=\"data row2 col3\" >34.6</td>\n",
       "      <td id=\"T_d5b97_row2_col4\" class=\"data row2 col4\" >5.2</td>\n",
       "      <td id=\"T_d5b97_row2_col5\" class=\"data row2 col5\" >10.2</td>\n",
       "      <td id=\"T_d5b97_row2_col6\" class=\"data row2 col6\" >32.6</td>\n",
       "      <td id=\"T_d5b97_row2_col7\" class=\"data row2 col7\" >32.8</td>\n",
       "      <td id=\"T_d5b97_row2_col8\" class=\"data row2 col8\" >8.9</td>\n",
       "      <td id=\"T_d5b97_row2_col9\" class=\"data row2 col9\" >31.9</td>\n",
       "      <td id=\"T_d5b97_row2_col10\" class=\"data row2 col10\" >9.8</td>\n",
       "      <td id=\"T_d5b97_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_d5b97_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_d5b97_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_d5b97_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_d5b97_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_d5b97_row2_col16\" class=\"data row2 col16\" >21.9</td>\n",
       "      <td id=\"T_d5b97_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe539450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cb801 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_cb801_row0_col0, #T_cb801_row1_col0, #T_cb801_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_cb801_row0_col1, #T_cb801_row1_col1, #T_cb801_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_cb801_row0_col2, #T_cb801_row0_col3, #T_cb801_row0_col4, #T_cb801_row0_col5, #T_cb801_row0_col6, #T_cb801_row0_col7, #T_cb801_row0_col8, #T_cb801_row0_col9, #T_cb801_row0_col10, #T_cb801_row1_col2, #T_cb801_row1_col3, #T_cb801_row1_col4, #T_cb801_row1_col5, #T_cb801_row1_col6, #T_cb801_row1_col7, #T_cb801_row1_col8, #T_cb801_row1_col9, #T_cb801_row1_col10, #T_cb801_row1_col13, #T_cb801_row1_col14, #T_cb801_row1_col15, #T_cb801_row2_col2, #T_cb801_row2_col3, #T_cb801_row2_col4, #T_cb801_row2_col5, #T_cb801_row2_col6, #T_cb801_row2_col7, #T_cb801_row2_col8, #T_cb801_row2_col9, #T_cb801_row2_col10, #T_cb801_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cb801_row0_col11, #T_cb801_row0_col12, #T_cb801_row0_col17, #T_cb801_row1_col11, #T_cb801_row1_col12, #T_cb801_row1_col17, #T_cb801_row2_col11, #T_cb801_row2_col12, #T_cb801_row2_col13, #T_cb801_row2_col14, #T_cb801_row2_col15, #T_cb801_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cb801_row0_col13, #T_cb801_row0_col14, #T_cb801_row0_col15, #T_cb801_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cb801_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cb801\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cb801_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_cb801_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_cb801_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_cb801_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_cb801_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_cb801_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_cb801_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_cb801_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_cb801_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_cb801_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_cb801_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_cb801_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_cb801_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_cb801_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_cb801_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_cb801_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_cb801_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_cb801_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cb801_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cb801_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_cb801_row0_col1\" class=\"data row0 col1\" >60000</td>\n",
       "      <td id=\"T_cb801_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_cb801_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "      <td id=\"T_cb801_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "      <td id=\"T_cb801_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_cb801_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_cb801_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_cb801_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_cb801_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "      <td id=\"T_cb801_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_cb801_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_cb801_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_cb801_row0_col13\" class=\"data row0 col13\" >43.2</td>\n",
       "      <td id=\"T_cb801_row0_col14\" class=\"data row0 col14\" >31.6</td>\n",
       "      <td id=\"T_cb801_row0_col15\" class=\"data row0 col15\" >37.4</td>\n",
       "      <td id=\"T_cb801_row0_col16\" class=\"data row0 col16\" >37.4</td>\n",
       "      <td id=\"T_cb801_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb801_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cb801_row1_col0\" class=\"data row1 col0\" >llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_cb801_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_cb801_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_cb801_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_cb801_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_cb801_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_cb801_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_cb801_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_cb801_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_cb801_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_cb801_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_cb801_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_cb801_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_cb801_row1_col13\" class=\"data row1 col13\" >41.6</td>\n",
       "      <td id=\"T_cb801_row1_col14\" class=\"data row1 col14\" >27.3</td>\n",
       "      <td id=\"T_cb801_row1_col15\" class=\"data row1 col15\" >34.5</td>\n",
       "      <td id=\"T_cb801_row1_col16\" class=\"data row1 col16\" >34.5</td>\n",
       "      <td id=\"T_cb801_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb801_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cb801_row2_col0\" class=\"data row2 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_cb801_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_cb801_row2_col2\" class=\"data row2 col2\" >31.3</td>\n",
       "      <td id=\"T_cb801_row2_col3\" class=\"data row2 col3\" >34.6</td>\n",
       "      <td id=\"T_cb801_row2_col4\" class=\"data row2 col4\" >5.2</td>\n",
       "      <td id=\"T_cb801_row2_col5\" class=\"data row2 col5\" >10.2</td>\n",
       "      <td id=\"T_cb801_row2_col6\" class=\"data row2 col6\" >32.6</td>\n",
       "      <td id=\"T_cb801_row2_col7\" class=\"data row2 col7\" >32.8</td>\n",
       "      <td id=\"T_cb801_row2_col8\" class=\"data row2 col8\" >8.9</td>\n",
       "      <td id=\"T_cb801_row2_col9\" class=\"data row2 col9\" >31.9</td>\n",
       "      <td id=\"T_cb801_row2_col10\" class=\"data row2 col10\" >9.8</td>\n",
       "      <td id=\"T_cb801_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_cb801_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_cb801_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_cb801_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_cb801_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_cb801_row2_col16\" class=\"data row2 col16\" >21.9</td>\n",
       "      <td id=\"T_cb801_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe709150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_149c6 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_149c6_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_149c6_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_149c6_row0_col2, #T_149c6_row0_col3, #T_149c6_row0_col4, #T_149c6_row0_col5, #T_149c6_row0_col6, #T_149c6_row0_col7, #T_149c6_row0_col8, #T_149c6_row0_col9, #T_149c6_row0_col10, #T_149c6_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_149c6_row0_col11, #T_149c6_row0_col12, #T_149c6_row0_col13, #T_149c6_row0_col14, #T_149c6_row0_col15, #T_149c6_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_149c6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_149c6_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_149c6_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_149c6_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_149c6_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_149c6_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_149c6_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_149c6_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_149c6_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_149c6_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_149c6_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_149c6_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_149c6_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_149c6_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_149c6_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_149c6_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_149c6_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_149c6_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_149c6_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_149c6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_149c6_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_149c6_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_149c6_row0_col2\" class=\"data row0 col2\" >31.3</td>\n",
       "      <td id=\"T_149c6_row0_col3\" class=\"data row0 col3\" >34.6</td>\n",
       "      <td id=\"T_149c6_row0_col4\" class=\"data row0 col4\" >5.2</td>\n",
       "      <td id=\"T_149c6_row0_col5\" class=\"data row0 col5\" >10.2</td>\n",
       "      <td id=\"T_149c6_row0_col6\" class=\"data row0 col6\" >32.6</td>\n",
       "      <td id=\"T_149c6_row0_col7\" class=\"data row0 col7\" >32.8</td>\n",
       "      <td id=\"T_149c6_row0_col8\" class=\"data row0 col8\" >8.9</td>\n",
       "      <td id=\"T_149c6_row0_col9\" class=\"data row0 col9\" >31.9</td>\n",
       "      <td id=\"T_149c6_row0_col10\" class=\"data row0 col10\" >9.8</td>\n",
       "      <td id=\"T_149c6_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_149c6_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_149c6_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_149c6_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_149c6_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_149c6_row0_col16\" class=\"data row0 col16\" >21.9</td>\n",
       "      <td id=\"T_149c6_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe8b1600>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dcdb7 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_dcdb7_row0_col0, #T_dcdb7_row1_col0, #T_dcdb7_row2_col0, #T_dcdb7_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_dcdb7_row0_col1, #T_dcdb7_row1_col1, #T_dcdb7_row2_col1, #T_dcdb7_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_dcdb7_row0_col2, #T_dcdb7_row0_col3, #T_dcdb7_row0_col5, #T_dcdb7_row0_col7, #T_dcdb7_row0_col9, #T_dcdb7_row0_col10, #T_dcdb7_row0_col13, #T_dcdb7_row0_col14, #T_dcdb7_row0_col15, #T_dcdb7_row0_col16, #T_dcdb7_row1_col4, #T_dcdb7_row1_col6, #T_dcdb7_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dcdb7_row0_col4, #T_dcdb7_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row0_col6, #T_dcdb7_row1_col10, #T_dcdb7_row1_col14, #T_dcdb7_row2_col2, #T_dcdb7_row2_col3, #T_dcdb7_row2_col7, #T_dcdb7_row2_col9, #T_dcdb7_row3_col4, #T_dcdb7_row3_col5, #T_dcdb7_row3_col8, #T_dcdb7_row3_col13, #T_dcdb7_row3_col15, #T_dcdb7_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dcdb7_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row0_col11, #T_dcdb7_row0_col12, #T_dcdb7_row0_col17, #T_dcdb7_row1_col11, #T_dcdb7_row1_col12, #T_dcdb7_row1_col17, #T_dcdb7_row2_col11, #T_dcdb7_row2_col12, #T_dcdb7_row2_col17, #T_dcdb7_row3_col11, #T_dcdb7_row3_col12, #T_dcdb7_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dcdb7_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dcdb7_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dcdb7_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dcdb7_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dcdb7_row2_col5, #T_dcdb7_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dcdb7_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dcdb7_row2_col13, #T_dcdb7_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dcdb7_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dcdb7_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dcdb7_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dcdb7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dcdb7_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_dcdb7_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_dcdb7_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_dcdb7_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_dcdb7_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_dcdb7_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_dcdb7_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_dcdb7_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_dcdb7_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_dcdb7_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_dcdb7_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_dcdb7_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_dcdb7_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_dcdb7_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_dcdb7_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_dcdb7_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_dcdb7_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_dcdb7_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dcdb7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_dcdb7_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_dcdb7_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_dcdb7_row0_col2\" class=\"data row0 col2\" >39.0</td>\n",
       "      <td id=\"T_dcdb7_row0_col3\" class=\"data row0 col3\" >38.8</td>\n",
       "      <td id=\"T_dcdb7_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_dcdb7_row0_col5\" class=\"data row0 col5\" >16.0</td>\n",
       "      <td id=\"T_dcdb7_row0_col6\" class=\"data row0 col6\" >29.9</td>\n",
       "      <td id=\"T_dcdb7_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_dcdb7_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_dcdb7_row0_col9\" class=\"data row0 col9\" >34.9</td>\n",
       "      <td id=\"T_dcdb7_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_dcdb7_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_dcdb7_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_dcdb7_row0_col13\" class=\"data row0 col13\" >54.4</td>\n",
       "      <td id=\"T_dcdb7_row0_col14\" class=\"data row0 col14\" >36.0</td>\n",
       "      <td id=\"T_dcdb7_row0_col15\" class=\"data row0 col15\" >45.3</td>\n",
       "      <td id=\"T_dcdb7_row0_col16\" class=\"data row0 col16\" >29.7</td>\n",
       "      <td id=\"T_dcdb7_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dcdb7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_dcdb7_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_dcdb7_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_dcdb7_row1_col2\" class=\"data row1 col2\" >32.9</td>\n",
       "      <td id=\"T_dcdb7_row1_col3\" class=\"data row1 col3\" >34.7</td>\n",
       "      <td id=\"T_dcdb7_row1_col4\" class=\"data row1 col4\" >6.8</td>\n",
       "      <td id=\"T_dcdb7_row1_col5\" class=\"data row1 col5\" >12.0</td>\n",
       "      <td id=\"T_dcdb7_row1_col6\" class=\"data row1 col6\" >35.0</td>\n",
       "      <td id=\"T_dcdb7_row1_col7\" class=\"data row1 col7\" >31.4</td>\n",
       "      <td id=\"T_dcdb7_row1_col8\" class=\"data row1 col8\" >8.9</td>\n",
       "      <td id=\"T_dcdb7_row1_col9\" class=\"data row1 col9\" >32.1</td>\n",
       "      <td id=\"T_dcdb7_row1_col10\" class=\"data row1 col10\" >8.7</td>\n",
       "      <td id=\"T_dcdb7_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_dcdb7_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_dcdb7_row1_col13\" class=\"data row1 col13\" >46.0</td>\n",
       "      <td id=\"T_dcdb7_row1_col14\" class=\"data row1 col14\" >31.8</td>\n",
       "      <td id=\"T_dcdb7_row1_col15\" class=\"data row1 col15\" >38.9</td>\n",
       "      <td id=\"T_dcdb7_row1_col16\" class=\"data row1 col16\" >26.6</td>\n",
       "      <td id=\"T_dcdb7_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dcdb7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_dcdb7_row2_col0\" class=\"data row2 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_dcdb7_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_dcdb7_row2_col2\" class=\"data row2 col2\" >30.9</td>\n",
       "      <td id=\"T_dcdb7_row2_col3\" class=\"data row2 col3\" >33.0</td>\n",
       "      <td id=\"T_dcdb7_row2_col4\" class=\"data row2 col4\" >6.4</td>\n",
       "      <td id=\"T_dcdb7_row2_col5\" class=\"data row2 col5\" >13.6</td>\n",
       "      <td id=\"T_dcdb7_row2_col6\" class=\"data row2 col6\" >33.5</td>\n",
       "      <td id=\"T_dcdb7_row2_col7\" class=\"data row2 col7\" >30.7</td>\n",
       "      <td id=\"T_dcdb7_row2_col8\" class=\"data row2 col8\" >7.3</td>\n",
       "      <td id=\"T_dcdb7_row2_col9\" class=\"data row2 col9\" >28.3</td>\n",
       "      <td id=\"T_dcdb7_row2_col10\" class=\"data row2 col10\" >12.2</td>\n",
       "      <td id=\"T_dcdb7_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_dcdb7_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_dcdb7_row2_col13\" class=\"data row2 col13\" >46.4</td>\n",
       "      <td id=\"T_dcdb7_row2_col14\" class=\"data row2 col14\" >34.0</td>\n",
       "      <td id=\"T_dcdb7_row2_col15\" class=\"data row2 col15\" >40.2</td>\n",
       "      <td id=\"T_dcdb7_row2_col16\" class=\"data row2 col16\" >26.4</td>\n",
       "      <td id=\"T_dcdb7_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dcdb7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_dcdb7_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_dcdb7_row3_col1\" class=\"data row3 col1\" >10000</td>\n",
       "      <td id=\"T_dcdb7_row3_col2\" class=\"data row3 col2\" >31.7</td>\n",
       "      <td id=\"T_dcdb7_row3_col3\" class=\"data row3 col3\" >37.0</td>\n",
       "      <td id=\"T_dcdb7_row3_col4\" class=\"data row3 col4\" >6.0</td>\n",
       "      <td id=\"T_dcdb7_row3_col5\" class=\"data row3 col5\" >9.6</td>\n",
       "      <td id=\"T_dcdb7_row3_col6\" class=\"data row3 col6\" >31.2</td>\n",
       "      <td id=\"T_dcdb7_row3_col7\" class=\"data row3 col7\" >33.1</td>\n",
       "      <td id=\"T_dcdb7_row3_col8\" class=\"data row3 col8\" >7.0</td>\n",
       "      <td id=\"T_dcdb7_row3_col9\" class=\"data row3 col9\" >30.0</td>\n",
       "      <td id=\"T_dcdb7_row3_col10\" class=\"data row3 col10\" >11.8</td>\n",
       "      <td id=\"T_dcdb7_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_dcdb7_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_dcdb7_row3_col13\" class=\"data row3 col13\" >43.5</td>\n",
       "      <td id=\"T_dcdb7_row3_col14\" class=\"data row3 col14\" >31.9</td>\n",
       "      <td id=\"T_dcdb7_row3_col15\" class=\"data row3 col15\" >37.7</td>\n",
       "      <td id=\"T_dcdb7_row3_col16\" class=\"data row3 col16\" >25.9</td>\n",
       "      <td id=\"T_dcdb7_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe708fa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fa645 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_fa645_row0_col0, #T_fa645_row1_col0, #T_fa645_row2_col0, #T_fa645_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fa645_row0_col1, #T_fa645_row1_col1, #T_fa645_row2_col1, #T_fa645_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fa645_row0_col2, #T_fa645_row0_col3, #T_fa645_row0_col4, #T_fa645_row0_col5, #T_fa645_row0_col9, #T_fa645_row0_col13, #T_fa645_row0_col16, #T_fa645_row1_col14, #T_fa645_row1_col15, #T_fa645_row2_col7, #T_fa645_row3_col6, #T_fa645_row3_col8, #T_fa645_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa645_row0_col6, #T_fa645_row1_col7, #T_fa645_row1_col10, #T_fa645_row2_col8, #T_fa645_row2_col9, #T_fa645_row3_col2, #T_fa645_row3_col3, #T_fa645_row3_col4, #T_fa645_row3_col5, #T_fa645_row3_col13, #T_fa645_row3_col14, #T_fa645_row3_col15, #T_fa645_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa645_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa645_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row0_col11, #T_fa645_row0_col12, #T_fa645_row0_col17, #T_fa645_row1_col11, #T_fa645_row1_col12, #T_fa645_row1_col17, #T_fa645_row2_col11, #T_fa645_row2_col12, #T_fa645_row2_col17, #T_fa645_row3_col11, #T_fa645_row3_col12, #T_fa645_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa645_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa645_row0_col15, #T_fa645_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa645_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa645_row1_col8, #T_fa645_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa645_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa645_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa645_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fa645_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row2_col10, #T_fa645_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fa645_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fa645\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fa645_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_fa645_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_fa645_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_fa645_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_fa645_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_fa645_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_fa645_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_fa645_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_fa645_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_fa645_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_fa645_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_fa645_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_fa645_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_fa645_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_fa645_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_fa645_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_fa645_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_fa645_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fa645_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fa645_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_fa645_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_fa645_row0_col2\" class=\"data row0 col2\" >39.0</td>\n",
       "      <td id=\"T_fa645_row0_col3\" class=\"data row0 col3\" >38.8</td>\n",
       "      <td id=\"T_fa645_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_fa645_row0_col5\" class=\"data row0 col5\" >16.0</td>\n",
       "      <td id=\"T_fa645_row0_col6\" class=\"data row0 col6\" >29.9</td>\n",
       "      <td id=\"T_fa645_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_fa645_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_fa645_row0_col9\" class=\"data row0 col9\" >34.9</td>\n",
       "      <td id=\"T_fa645_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_fa645_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_fa645_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_fa645_row0_col13\" class=\"data row0 col13\" >54.4</td>\n",
       "      <td id=\"T_fa645_row0_col14\" class=\"data row0 col14\" >36.0</td>\n",
       "      <td id=\"T_fa645_row0_col15\" class=\"data row0 col15\" >45.3</td>\n",
       "      <td id=\"T_fa645_row0_col16\" class=\"data row0 col16\" >29.7</td>\n",
       "      <td id=\"T_fa645_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fa645_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fa645_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_fa645_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_fa645_row1_col2\" class=\"data row1 col2\" >37.9</td>\n",
       "      <td id=\"T_fa645_row1_col3\" class=\"data row1 col3\" >37.7</td>\n",
       "      <td id=\"T_fa645_row1_col4\" class=\"data row1 col4\" >6.0</td>\n",
       "      <td id=\"T_fa645_row1_col5\" class=\"data row1 col5\" >13.0</td>\n",
       "      <td id=\"T_fa645_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_fa645_row1_col7\" class=\"data row1 col7\" >33.9</td>\n",
       "      <td id=\"T_fa645_row1_col8\" class=\"data row1 col8\" >8.7</td>\n",
       "      <td id=\"T_fa645_row1_col9\" class=\"data row1 col9\" >33.6</td>\n",
       "      <td id=\"T_fa645_row1_col10\" class=\"data row1 col10\" >11.4</td>\n",
       "      <td id=\"T_fa645_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_fa645_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_fa645_row1_col13\" class=\"data row1 col13\" >53.1</td>\n",
       "      <td id=\"T_fa645_row1_col14\" class=\"data row1 col14\" >40.5</td>\n",
       "      <td id=\"T_fa645_row1_col15\" class=\"data row1 col15\" >46.9</td>\n",
       "      <td id=\"T_fa645_row1_col16\" class=\"data row1 col16\" >29.4</td>\n",
       "      <td id=\"T_fa645_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fa645_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fa645_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_fa645_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_fa645_row2_col2\" class=\"data row2 col2\" >35.0</td>\n",
       "      <td id=\"T_fa645_row2_col3\" class=\"data row2 col3\" >35.7</td>\n",
       "      <td id=\"T_fa645_row2_col4\" class=\"data row2 col4\" >5.8</td>\n",
       "      <td id=\"T_fa645_row2_col5\" class=\"data row2 col5\" >14.4</td>\n",
       "      <td id=\"T_fa645_row2_col6\" class=\"data row2 col6\" >32.8</td>\n",
       "      <td id=\"T_fa645_row2_col7\" class=\"data row2 col7\" >34.5</td>\n",
       "      <td id=\"T_fa645_row2_col8\" class=\"data row2 col8\" >7.5</td>\n",
       "      <td id=\"T_fa645_row2_col9\" class=\"data row2 col9\" >31.3</td>\n",
       "      <td id=\"T_fa645_row2_col10\" class=\"data row2 col10\" >12.8</td>\n",
       "      <td id=\"T_fa645_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_fa645_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_fa645_row2_col13\" class=\"data row2 col13\" >48.6</td>\n",
       "      <td id=\"T_fa645_row2_col14\" class=\"data row2 col14\" >39.2</td>\n",
       "      <td id=\"T_fa645_row2_col15\" class=\"data row2 col15\" >44.0</td>\n",
       "      <td id=\"T_fa645_row2_col16\" class=\"data row2 col16\" >28.5</td>\n",
       "      <td id=\"T_fa645_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fa645_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fa645_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_fa645_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_fa645_row3_col2\" class=\"data row3 col2\" >33.9</td>\n",
       "      <td id=\"T_fa645_row3_col3\" class=\"data row3 col3\" >35.2</td>\n",
       "      <td id=\"T_fa645_row3_col4\" class=\"data row3 col4\" >5.2</td>\n",
       "      <td id=\"T_fa645_row3_col5\" class=\"data row3 col5\" >11.0</td>\n",
       "      <td id=\"T_fa645_row3_col6\" class=\"data row3 col6\" >34.1</td>\n",
       "      <td id=\"T_fa645_row3_col7\" class=\"data row3 col7\" >34.2</td>\n",
       "      <td id=\"T_fa645_row3_col8\" class=\"data row3 col8\" >8.9</td>\n",
       "      <td id=\"T_fa645_row3_col9\" class=\"data row3 col9\" >32.8</td>\n",
       "      <td id=\"T_fa645_row3_col10\" class=\"data row3 col10\" >14.0</td>\n",
       "      <td id=\"T_fa645_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_fa645_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_fa645_row3_col13\" class=\"data row3 col13\" >45.9</td>\n",
       "      <td id=\"T_fa645_row3_col14\" class=\"data row3 col14\" >35.4</td>\n",
       "      <td id=\"T_fa645_row3_col15\" class=\"data row3 col15\" >40.6</td>\n",
       "      <td id=\"T_fa645_row3_col16\" class=\"data row3 col16\" >27.6</td>\n",
       "      <td id=\"T_fa645_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cff6e2350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e2ee2 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_e2ee2_row0_col0, #T_e2ee2_row1_col0, #T_e2ee2_row2_col0, #T_e2ee2_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e2ee2_row0_col1, #T_e2ee2_row1_col1, #T_e2ee2_row2_col1, #T_e2ee2_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e2ee2_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2ee2_row0_col3, #T_e2ee2_row0_col4, #T_e2ee2_row0_col6, #T_e2ee2_row0_col14, #T_e2ee2_row0_col16, #T_e2ee2_row1_col4, #T_e2ee2_row1_col5, #T_e2ee2_row1_col9, #T_e2ee2_row1_col10, #T_e2ee2_row1_col13, #T_e2ee2_row1_col15, #T_e2ee2_row2_col2, #T_e2ee2_row2_col8, #T_e2ee2_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2ee2_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2ee2_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2ee2_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2ee2_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2ee2_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2ee2_row0_col11, #T_e2ee2_row0_col12, #T_e2ee2_row0_col17, #T_e2ee2_row1_col11, #T_e2ee2_row1_col12, #T_e2ee2_row1_col17, #T_e2ee2_row2_col11, #T_e2ee2_row2_col12, #T_e2ee2_row2_col17, #T_e2ee2_row3_col11, #T_e2ee2_row3_col12, #T_e2ee2_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2ee2_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2ee2_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2ee2_row1_col2, #T_e2ee2_row1_col6, #T_e2ee2_row2_col3, #T_e2ee2_row2_col4, #T_e2ee2_row2_col5, #T_e2ee2_row2_col7, #T_e2ee2_row2_col13, #T_e2ee2_row3_col5, #T_e2ee2_row3_col8, #T_e2ee2_row3_col9, #T_e2ee2_row3_col10, #T_e2ee2_row3_col14, #T_e2ee2_row3_col15, #T_e2ee2_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2ee2_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2ee2_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2ee2_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2ee2_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2ee2_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #ba162b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2ee2_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2ee2_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2ee2_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2ee2_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2ee2_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2ee2_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2ee2_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2ee2_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2ee2_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2ee2_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2ee2_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e2ee2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e2ee2_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_e2ee2_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_e2ee2_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_e2ee2_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_e2ee2_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_e2ee2_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_e2ee2_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_e2ee2_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_e2ee2_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_e2ee2_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_e2ee2_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_e2ee2_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_e2ee2_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_e2ee2_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_e2ee2_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_e2ee2_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_e2ee2_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_e2ee2_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e2ee2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e2ee2_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_e2ee2_row0_col1\" class=\"data row0 col1\" >60000</td>\n",
       "      <td id=\"T_e2ee2_row0_col2\" class=\"data row0 col2\" >40.0</td>\n",
       "      <td id=\"T_e2ee2_row0_col3\" class=\"data row0 col3\" >39.4</td>\n",
       "      <td id=\"T_e2ee2_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_e2ee2_row0_col5\" class=\"data row0 col5\" >14.4</td>\n",
       "      <td id=\"T_e2ee2_row0_col6\" class=\"data row0 col6\" >32.4</td>\n",
       "      <td id=\"T_e2ee2_row0_col7\" class=\"data row0 col7\" >34.6</td>\n",
       "      <td id=\"T_e2ee2_row0_col8\" class=\"data row0 col8\" >7.8</td>\n",
       "      <td id=\"T_e2ee2_row0_col9\" class=\"data row0 col9\" >34.4</td>\n",
       "      <td id=\"T_e2ee2_row0_col10\" class=\"data row0 col10\" >11.4</td>\n",
       "      <td id=\"T_e2ee2_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_e2ee2_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_e2ee2_row0_col13\" class=\"data row0 col13\" >51.8</td>\n",
       "      <td id=\"T_e2ee2_row0_col14\" class=\"data row0 col14\" >38.8</td>\n",
       "      <td id=\"T_e2ee2_row0_col15\" class=\"data row0 col15\" >45.2</td>\n",
       "      <td id=\"T_e2ee2_row0_col16\" class=\"data row0 col16\" >29.7</td>\n",
       "      <td id=\"T_e2ee2_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e2ee2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e2ee2_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_e2ee2_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_e2ee2_row1_col2\" class=\"data row1 col2\" >39.0</td>\n",
       "      <td id=\"T_e2ee2_row1_col3\" class=\"data row1 col3\" >38.8</td>\n",
       "      <td id=\"T_e2ee2_row1_col4\" class=\"data row1 col4\" >6.4</td>\n",
       "      <td id=\"T_e2ee2_row1_col5\" class=\"data row1 col5\" >16.0</td>\n",
       "      <td id=\"T_e2ee2_row1_col6\" class=\"data row1 col6\" >29.9</td>\n",
       "      <td id=\"T_e2ee2_row1_col7\" class=\"data row1 col7\" >34.4</td>\n",
       "      <td id=\"T_e2ee2_row1_col8\" class=\"data row1 col8\" >8.0</td>\n",
       "      <td id=\"T_e2ee2_row1_col9\" class=\"data row1 col9\" >34.9</td>\n",
       "      <td id=\"T_e2ee2_row1_col10\" class=\"data row1 col10\" >13.2</td>\n",
       "      <td id=\"T_e2ee2_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_e2ee2_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_e2ee2_row1_col13\" class=\"data row1 col13\" >54.4</td>\n",
       "      <td id=\"T_e2ee2_row1_col14\" class=\"data row1 col14\" >36.0</td>\n",
       "      <td id=\"T_e2ee2_row1_col15\" class=\"data row1 col15\" >45.3</td>\n",
       "      <td id=\"T_e2ee2_row1_col16\" class=\"data row1 col16\" >29.7</td>\n",
       "      <td id=\"T_e2ee2_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e2ee2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e2ee2_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_e2ee2_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_e2ee2_row2_col2\" class=\"data row2 col2\" >40.2</td>\n",
       "      <td id=\"T_e2ee2_row2_col3\" class=\"data row2 col3\" >37.6</td>\n",
       "      <td id=\"T_e2ee2_row2_col4\" class=\"data row2 col4\" >5.6</td>\n",
       "      <td id=\"T_e2ee2_row2_col5\" class=\"data row2 col5\" >14.0</td>\n",
       "      <td id=\"T_e2ee2_row2_col6\" class=\"data row2 col6\" >32.2</td>\n",
       "      <td id=\"T_e2ee2_row2_col7\" class=\"data row2 col7\" >33.5</td>\n",
       "      <td id=\"T_e2ee2_row2_col8\" class=\"data row2 col8\" >8.2</td>\n",
       "      <td id=\"T_e2ee2_row2_col9\" class=\"data row2 col9\" >32.7</td>\n",
       "      <td id=\"T_e2ee2_row2_col10\" class=\"data row2 col10\" >12.4</td>\n",
       "      <td id=\"T_e2ee2_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_e2ee2_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_e2ee2_row2_col13\" class=\"data row2 col13\" >49.6</td>\n",
       "      <td id=\"T_e2ee2_row2_col14\" class=\"data row2 col14\" >36.6</td>\n",
       "      <td id=\"T_e2ee2_row2_col15\" class=\"data row2 col15\" >43.1</td>\n",
       "      <td id=\"T_e2ee2_row2_col16\" class=\"data row2 col16\" >28.8</td>\n",
       "      <td id=\"T_e2ee2_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e2ee2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e2ee2_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_e2ee2_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_e2ee2_row3_col2\" class=\"data row3 col2\" >39.6</td>\n",
       "      <td id=\"T_e2ee2_row3_col3\" class=\"data row3 col3\" >38.6</td>\n",
       "      <td id=\"T_e2ee2_row3_col4\" class=\"data row3 col4\" >6.2</td>\n",
       "      <td id=\"T_e2ee2_row3_col5\" class=\"data row3 col5\" >14.0</td>\n",
       "      <td id=\"T_e2ee2_row3_col6\" class=\"data row3 col6\" >32.3</td>\n",
       "      <td id=\"T_e2ee2_row3_col7\" class=\"data row3 col7\" >35.9</td>\n",
       "      <td id=\"T_e2ee2_row3_col8\" class=\"data row3 col8\" >7.5</td>\n",
       "      <td id=\"T_e2ee2_row3_col9\" class=\"data row3 col9\" >30.6</td>\n",
       "      <td id=\"T_e2ee2_row3_col10\" class=\"data row3 col10\" >11.0</td>\n",
       "      <td id=\"T_e2ee2_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_e2ee2_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_e2ee2_row3_col13\" class=\"data row3 col13\" >50.6</td>\n",
       "      <td id=\"T_e2ee2_row3_col14\" class=\"data row3 col14\" >35.2</td>\n",
       "      <td id=\"T_e2ee2_row3_col15\" class=\"data row3 col15\" >43.0</td>\n",
       "      <td id=\"T_e2ee2_row3_col16\" class=\"data row3 col16\" >28.7</td>\n",
       "      <td id=\"T_e2ee2_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe8b1de0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_04c4c td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_04c4c_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_04c4c_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_04c4c_row0_col2, #T_04c4c_row0_col3, #T_04c4c_row0_col4, #T_04c4c_row0_col5, #T_04c4c_row0_col6, #T_04c4c_row0_col7, #T_04c4c_row0_col8, #T_04c4c_row0_col9, #T_04c4c_row0_col10, #T_04c4c_row0_col13, #T_04c4c_row0_col14, #T_04c4c_row0_col15, #T_04c4c_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_04c4c_row0_col11, #T_04c4c_row0_col12, #T_04c4c_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_04c4c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_04c4c_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_04c4c_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_04c4c_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_04c4c_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_04c4c_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_04c4c_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_04c4c_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_04c4c_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_04c4c_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_04c4c_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_04c4c_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_04c4c_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_04c4c_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_04c4c_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_04c4c_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_04c4c_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_04c4c_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_04c4c_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_04c4c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_04c4c_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_04c4c_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_04c4c_row0_col2\" class=\"data row0 col2\" >39.0</td>\n",
       "      <td id=\"T_04c4c_row0_col3\" class=\"data row0 col3\" >38.8</td>\n",
       "      <td id=\"T_04c4c_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_04c4c_row0_col5\" class=\"data row0 col5\" >16.0</td>\n",
       "      <td id=\"T_04c4c_row0_col6\" class=\"data row0 col6\" >29.9</td>\n",
       "      <td id=\"T_04c4c_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_04c4c_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_04c4c_row0_col9\" class=\"data row0 col9\" >34.9</td>\n",
       "      <td id=\"T_04c4c_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_04c4c_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_04c4c_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_04c4c_row0_col13\" class=\"data row0 col13\" >54.4</td>\n",
       "      <td id=\"T_04c4c_row0_col14\" class=\"data row0 col14\" >36.0</td>\n",
       "      <td id=\"T_04c4c_row0_col15\" class=\"data row0 col15\" >45.3</td>\n",
       "      <td id=\"T_04c4c_row0_col16\" class=\"data row0 col16\" >29.7</td>\n",
       "      <td id=\"T_04c4c_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe4997e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aa56d td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_aa56d_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_aa56d_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_aa56d_row0_col2, #T_aa56d_row0_col3, #T_aa56d_row0_col4, #T_aa56d_row0_col5, #T_aa56d_row0_col6, #T_aa56d_row0_col7, #T_aa56d_row0_col8, #T_aa56d_row0_col9, #T_aa56d_row0_col10, #T_aa56d_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_aa56d_row0_col11, #T_aa56d_row0_col12, #T_aa56d_row0_col13, #T_aa56d_row0_col14, #T_aa56d_row0_col15, #T_aa56d_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aa56d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aa56d_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_aa56d_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_aa56d_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_aa56d_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_aa56d_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_aa56d_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_aa56d_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_aa56d_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_aa56d_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_aa56d_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_aa56d_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_aa56d_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_aa56d_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_aa56d_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_aa56d_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_aa56d_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_aa56d_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_aa56d_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aa56d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aa56d_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_aa56d_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_aa56d_row0_col2\" class=\"data row0 col2\" >42.2</td>\n",
       "      <td id=\"T_aa56d_row0_col3\" class=\"data row0 col3\" >42.6</td>\n",
       "      <td id=\"T_aa56d_row0_col4\" class=\"data row0 col4\" >4.0</td>\n",
       "      <td id=\"T_aa56d_row0_col5\" class=\"data row0 col5\" >5.0</td>\n",
       "      <td id=\"T_aa56d_row0_col6\" class=\"data row0 col6\" >33.6</td>\n",
       "      <td id=\"T_aa56d_row0_col7\" class=\"data row0 col7\" >31.7</td>\n",
       "      <td id=\"T_aa56d_row0_col8\" class=\"data row0 col8\" >7.2</td>\n",
       "      <td id=\"T_aa56d_row0_col9\" class=\"data row0 col9\" >33.9</td>\n",
       "      <td id=\"T_aa56d_row0_col10\" class=\"data row0 col10\" >10.8</td>\n",
       "      <td id=\"T_aa56d_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_aa56d_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_aa56d_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_aa56d_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_aa56d_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_aa56d_row0_col16\" class=\"data row0 col16\" >23.5</td>\n",
       "      <td id=\"T_aa56d_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151d0280bc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_62e6a td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_62e6a_row0_col0, #T_62e6a_row1_col0, #T_62e6a_row2_col0, #T_62e6a_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_62e6a_row0_col1, #T_62e6a_row1_col1, #T_62e6a_row2_col1, #T_62e6a_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_62e6a_row0_col2, #T_62e6a_row0_col3, #T_62e6a_row0_col4, #T_62e6a_row0_col5, #T_62e6a_row0_col6, #T_62e6a_row0_col7, #T_62e6a_row0_col8, #T_62e6a_row0_col9, #T_62e6a_row0_col10, #T_62e6a_row1_col2, #T_62e6a_row1_col3, #T_62e6a_row1_col4, #T_62e6a_row1_col5, #T_62e6a_row1_col6, #T_62e6a_row1_col7, #T_62e6a_row1_col8, #T_62e6a_row1_col9, #T_62e6a_row1_col10, #T_62e6a_row2_col2, #T_62e6a_row2_col3, #T_62e6a_row2_col4, #T_62e6a_row2_col5, #T_62e6a_row2_col6, #T_62e6a_row2_col7, #T_62e6a_row2_col8, #T_62e6a_row2_col9, #T_62e6a_row2_col10, #T_62e6a_row2_col13, #T_62e6a_row2_col14, #T_62e6a_row2_col15, #T_62e6a_row3_col2, #T_62e6a_row3_col3, #T_62e6a_row3_col4, #T_62e6a_row3_col5, #T_62e6a_row3_col6, #T_62e6a_row3_col7, #T_62e6a_row3_col8, #T_62e6a_row3_col9, #T_62e6a_row3_col10, #T_62e6a_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_62e6a_row0_col11, #T_62e6a_row0_col12, #T_62e6a_row0_col17, #T_62e6a_row1_col11, #T_62e6a_row1_col12, #T_62e6a_row1_col17, #T_62e6a_row2_col11, #T_62e6a_row2_col12, #T_62e6a_row2_col17, #T_62e6a_row3_col11, #T_62e6a_row3_col12, #T_62e6a_row3_col13, #T_62e6a_row3_col14, #T_62e6a_row3_col15, #T_62e6a_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_62e6a_row0_col13, #T_62e6a_row0_col14, #T_62e6a_row0_col15, #T_62e6a_row0_col16, #T_62e6a_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_62e6a_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_62e6a_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_62e6a_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_62e6a_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_62e6a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_62e6a_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_62e6a_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_62e6a_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_62e6a_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_62e6a_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_62e6a_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_62e6a_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_62e6a_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_62e6a_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_62e6a_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_62e6a_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_62e6a_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_62e6a_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_62e6a_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_62e6a_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_62e6a_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_62e6a_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_62e6a_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_62e6a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_62e6a_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_62e6a_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_62e6a_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_62e6a_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "      <td id=\"T_62e6a_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "      <td id=\"T_62e6a_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_62e6a_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_62e6a_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_62e6a_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_62e6a_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "      <td id=\"T_62e6a_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_62e6a_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_62e6a_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_62e6a_row0_col13\" class=\"data row0 col13\" >40.6</td>\n",
       "      <td id=\"T_62e6a_row0_col14\" class=\"data row0 col14\" >27.7</td>\n",
       "      <td id=\"T_62e6a_row0_col15\" class=\"data row0 col15\" >34.3</td>\n",
       "      <td id=\"T_62e6a_row0_col16\" class=\"data row0 col16\" >34.2</td>\n",
       "      <td id=\"T_62e6a_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62e6a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_62e6a_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_62e6a_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_62e6a_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_62e6a_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_62e6a_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_62e6a_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_62e6a_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_62e6a_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_62e6a_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_62e6a_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_62e6a_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_62e6a_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_62e6a_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_62e6a_row1_col13\" class=\"data row1 col13\" >40.6</td>\n",
       "      <td id=\"T_62e6a_row1_col14\" class=\"data row1 col14\" >27.5</td>\n",
       "      <td id=\"T_62e6a_row1_col15\" class=\"data row1 col15\" >34.1</td>\n",
       "      <td id=\"T_62e6a_row1_col16\" class=\"data row1 col16\" >34.1</td>\n",
       "      <td id=\"T_62e6a_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62e6a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_62e6a_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_62e6a_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_62e6a_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_62e6a_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_62e6a_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "      <td id=\"T_62e6a_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_62e6a_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "      <td id=\"T_62e6a_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_62e6a_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_62e6a_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_62e6a_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_62e6a_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_62e6a_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_62e6a_row2_col13\" class=\"data row2 col13\" >39.5</td>\n",
       "      <td id=\"T_62e6a_row2_col14\" class=\"data row2 col14\" >26.6</td>\n",
       "      <td id=\"T_62e6a_row2_col15\" class=\"data row2 col15\" >33.1</td>\n",
       "      <td id=\"T_62e6a_row2_col16\" class=\"data row2 col16\" >33.1</td>\n",
       "      <td id=\"T_62e6a_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62e6a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_62e6a_row3_col0\" class=\"data row3 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_62e6a_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_62e6a_row3_col2\" class=\"data row3 col2\" >42.2</td>\n",
       "      <td id=\"T_62e6a_row3_col3\" class=\"data row3 col3\" >42.6</td>\n",
       "      <td id=\"T_62e6a_row3_col4\" class=\"data row3 col4\" >4.0</td>\n",
       "      <td id=\"T_62e6a_row3_col5\" class=\"data row3 col5\" >5.0</td>\n",
       "      <td id=\"T_62e6a_row3_col6\" class=\"data row3 col6\" >33.6</td>\n",
       "      <td id=\"T_62e6a_row3_col7\" class=\"data row3 col7\" >31.7</td>\n",
       "      <td id=\"T_62e6a_row3_col8\" class=\"data row3 col8\" >7.2</td>\n",
       "      <td id=\"T_62e6a_row3_col9\" class=\"data row3 col9\" >33.9</td>\n",
       "      <td id=\"T_62e6a_row3_col10\" class=\"data row3 col10\" >10.8</td>\n",
       "      <td id=\"T_62e6a_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_62e6a_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_62e6a_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_62e6a_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_62e6a_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_62e6a_row3_col16\" class=\"data row3 col16\" >23.5</td>\n",
       "      <td id=\"T_62e6a_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe70a0b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4dfa4 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_4dfa4_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4dfa4_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4dfa4_row0_col2, #T_4dfa4_row0_col3, #T_4dfa4_row0_col4, #T_4dfa4_row0_col5, #T_4dfa4_row0_col6, #T_4dfa4_row0_col7, #T_4dfa4_row0_col8, #T_4dfa4_row0_col9, #T_4dfa4_row0_col10, #T_4dfa4_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4dfa4_row0_col11, #T_4dfa4_row0_col12, #T_4dfa4_row0_col13, #T_4dfa4_row0_col14, #T_4dfa4_row0_col15, #T_4dfa4_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4dfa4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4dfa4_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_4dfa4_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_4dfa4_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_4dfa4_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_4dfa4_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_4dfa4_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_4dfa4_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_4dfa4_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_4dfa4_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_4dfa4_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_4dfa4_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_4dfa4_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_4dfa4_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_4dfa4_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_4dfa4_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_4dfa4_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_4dfa4_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_4dfa4_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4dfa4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4dfa4_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_4dfa4_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_4dfa4_row0_col2\" class=\"data row0 col2\" >42.2</td>\n",
       "      <td id=\"T_4dfa4_row0_col3\" class=\"data row0 col3\" >42.6</td>\n",
       "      <td id=\"T_4dfa4_row0_col4\" class=\"data row0 col4\" >4.0</td>\n",
       "      <td id=\"T_4dfa4_row0_col5\" class=\"data row0 col5\" >5.0</td>\n",
       "      <td id=\"T_4dfa4_row0_col6\" class=\"data row0 col6\" >33.6</td>\n",
       "      <td id=\"T_4dfa4_row0_col7\" class=\"data row0 col7\" >31.7</td>\n",
       "      <td id=\"T_4dfa4_row0_col8\" class=\"data row0 col8\" >7.2</td>\n",
       "      <td id=\"T_4dfa4_row0_col9\" class=\"data row0 col9\" >33.9</td>\n",
       "      <td id=\"T_4dfa4_row0_col10\" class=\"data row0 col10\" >10.8</td>\n",
       "      <td id=\"T_4dfa4_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_4dfa4_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_4dfa4_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_4dfa4_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_4dfa4_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_4dfa4_row0_col16\" class=\"data row0 col16\" >23.5</td>\n",
       "      <td id=\"T_4dfa4_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151e602d2e00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0b70a td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_0b70a_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0b70a_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0b70a_row0_col2, #T_0b70a_row0_col3, #T_0b70a_row0_col4, #T_0b70a_row0_col5, #T_0b70a_row0_col6, #T_0b70a_row0_col7, #T_0b70a_row0_col8, #T_0b70a_row0_col9, #T_0b70a_row0_col10, #T_0b70a_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0b70a_row0_col11, #T_0b70a_row0_col12, #T_0b70a_row0_col13, #T_0b70a_row0_col14, #T_0b70a_row0_col15, #T_0b70a_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0b70a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0b70a_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_0b70a_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_0b70a_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_0b70a_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_0b70a_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_0b70a_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_0b70a_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_0b70a_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_0b70a_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_0b70a_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_0b70a_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_0b70a_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_0b70a_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_0b70a_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_0b70a_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_0b70a_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_0b70a_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_0b70a_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0b70a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0b70a_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_0b70a_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_0b70a_row0_col2\" class=\"data row0 col2\" >42.2</td>\n",
       "      <td id=\"T_0b70a_row0_col3\" class=\"data row0 col3\" >42.6</td>\n",
       "      <td id=\"T_0b70a_row0_col4\" class=\"data row0 col4\" >4.0</td>\n",
       "      <td id=\"T_0b70a_row0_col5\" class=\"data row0 col5\" >5.0</td>\n",
       "      <td id=\"T_0b70a_row0_col6\" class=\"data row0 col6\" >33.6</td>\n",
       "      <td id=\"T_0b70a_row0_col7\" class=\"data row0 col7\" >31.7</td>\n",
       "      <td id=\"T_0b70a_row0_col8\" class=\"data row0 col8\" >7.2</td>\n",
       "      <td id=\"T_0b70a_row0_col9\" class=\"data row0 col9\" >33.9</td>\n",
       "      <td id=\"T_0b70a_row0_col10\" class=\"data row0 col10\" >10.8</td>\n",
       "      <td id=\"T_0b70a_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_0b70a_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_0b70a_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_0b70a_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_0b70a_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_0b70a_row0_col16\" class=\"data row0 col16\" >23.5</td>\n",
       "      <td id=\"T_0b70a_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cff8a0220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0ed1d td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_0ed1d_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0ed1d_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0ed1d_row0_col2, #T_0ed1d_row0_col3, #T_0ed1d_row0_col4, #T_0ed1d_row0_col5, #T_0ed1d_row0_col6, #T_0ed1d_row0_col7, #T_0ed1d_row0_col8, #T_0ed1d_row0_col9, #T_0ed1d_row0_col10, #T_0ed1d_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0ed1d_row0_col11, #T_0ed1d_row0_col12, #T_0ed1d_row0_col13, #T_0ed1d_row0_col14, #T_0ed1d_row0_col15, #T_0ed1d_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0ed1d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0ed1d_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_0ed1d_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_0ed1d_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_0ed1d_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_0ed1d_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_0ed1d_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_0ed1d_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_0ed1d_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_0ed1d_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_0ed1d_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_0ed1d_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_0ed1d_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_0ed1d_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_0ed1d_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_0ed1d_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_0ed1d_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_0ed1d_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_0ed1d_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0ed1d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0ed1d_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_0ed1d_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_0ed1d_row0_col2\" class=\"data row0 col2\" >38.4</td>\n",
       "      <td id=\"T_0ed1d_row0_col3\" class=\"data row0 col3\" >36.5</td>\n",
       "      <td id=\"T_0ed1d_row0_col4\" class=\"data row0 col4\" >6.6</td>\n",
       "      <td id=\"T_0ed1d_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_0ed1d_row0_col6\" class=\"data row0 col6\" >31.3</td>\n",
       "      <td id=\"T_0ed1d_row0_col7\" class=\"data row0 col7\" >34.1</td>\n",
       "      <td id=\"T_0ed1d_row0_col8\" class=\"data row0 col8\" >7.9</td>\n",
       "      <td id=\"T_0ed1d_row0_col9\" class=\"data row0 col9\" >33.3</td>\n",
       "      <td id=\"T_0ed1d_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_0ed1d_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_0ed1d_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_0ed1d_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_0ed1d_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_0ed1d_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_0ed1d_row0_col16\" class=\"data row0 col16\" >23.4</td>\n",
       "      <td id=\"T_0ed1d_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe498fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_158d9 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_158d9_row0_col0, #T_158d9_row1_col0, #T_158d9_row2_col0, #T_158d9_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_158d9_row0_col1, #T_158d9_row1_col1, #T_158d9_row2_col1, #T_158d9_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_158d9_row0_col2, #T_158d9_row0_col5, #T_158d9_row0_col7, #T_158d9_row1_col5, #T_158d9_row1_col9, #T_158d9_row1_col10, #T_158d9_row2_col3, #T_158d9_row2_col4, #T_158d9_row2_col13, #T_158d9_row2_col14, #T_158d9_row2_col15, #T_158d9_row3_col6, #T_158d9_row3_col8, #T_158d9_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_158d9_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_158d9_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_158d9_row0_col6, #T_158d9_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_158d9_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_158d9_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_158d9_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_158d9_row0_col11, #T_158d9_row0_col12, #T_158d9_row0_col17, #T_158d9_row1_col11, #T_158d9_row1_col12, #T_158d9_row1_col17, #T_158d9_row2_col11, #T_158d9_row2_col12, #T_158d9_row2_col17, #T_158d9_row3_col11, #T_158d9_row3_col12, #T_158d9_row3_col13, #T_158d9_row3_col14, #T_158d9_row3_col15, #T_158d9_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_158d9_row0_col13, #T_158d9_row0_col14, #T_158d9_row0_col15, #T_158d9_row0_col16, #T_158d9_row1_col2, #T_158d9_row1_col3, #T_158d9_row1_col7, #T_158d9_row1_col8, #T_158d9_row2_col5, #T_158d9_row2_col6, #T_158d9_row2_col10, #T_158d9_row3_col4, #T_158d9_row3_col5, #T_158d9_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_158d9_row1_col6, #T_158d9_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_158d9_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_158d9_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_158d9_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_158d9_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_158d9_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_158d9_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_158d9_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_158d9_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_158d9_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_158d9_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_158d9_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_158d9_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_158d9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_158d9_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_158d9_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_158d9_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_158d9_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_158d9_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_158d9_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_158d9_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_158d9_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_158d9_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_158d9_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_158d9_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_158d9_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_158d9_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_158d9_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_158d9_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_158d9_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_158d9_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_158d9_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_158d9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_158d9_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_158d9_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_158d9_row0_col2\" class=\"data row0 col2\" >36.7</td>\n",
       "      <td id=\"T_158d9_row0_col3\" class=\"data row0 col3\" >35.9</td>\n",
       "      <td id=\"T_158d9_row0_col4\" class=\"data row0 col4\" >5.6</td>\n",
       "      <td id=\"T_158d9_row0_col5\" class=\"data row0 col5\" >9.4</td>\n",
       "      <td id=\"T_158d9_row0_col6\" class=\"data row0 col6\" >33.0</td>\n",
       "      <td id=\"T_158d9_row0_col7\" class=\"data row0 col7\" >33.2</td>\n",
       "      <td id=\"T_158d9_row0_col8\" class=\"data row0 col8\" >8.3</td>\n",
       "      <td id=\"T_158d9_row0_col9\" class=\"data row0 col9\" >31.9</td>\n",
       "      <td id=\"T_158d9_row0_col10\" class=\"data row0 col10\" >11.6</td>\n",
       "      <td id=\"T_158d9_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_158d9_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_158d9_row0_col13\" class=\"data row0 col13\" >50.6</td>\n",
       "      <td id=\"T_158d9_row0_col14\" class=\"data row0 col14\" >36.7</td>\n",
       "      <td id=\"T_158d9_row0_col15\" class=\"data row0 col15\" >43.7</td>\n",
       "      <td id=\"T_158d9_row0_col16\" class=\"data row0 col16\" >28.0</td>\n",
       "      <td id=\"T_158d9_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_158d9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_158d9_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_158d9_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_158d9_row1_col2\" class=\"data row1 col2\" >38.7</td>\n",
       "      <td id=\"T_158d9_row1_col3\" class=\"data row1 col3\" >37.5</td>\n",
       "      <td id=\"T_158d9_row1_col4\" class=\"data row1 col4\" >6.4</td>\n",
       "      <td id=\"T_158d9_row1_col5\" class=\"data row1 col5\" >9.4</td>\n",
       "      <td id=\"T_158d9_row1_col6\" class=\"data row1 col6\" >32.8</td>\n",
       "      <td id=\"T_158d9_row1_col7\" class=\"data row1 col7\" >35.1</td>\n",
       "      <td id=\"T_158d9_row1_col8\" class=\"data row1 col8\" >9.1</td>\n",
       "      <td id=\"T_158d9_row1_col9\" class=\"data row1 col9\" >30.3</td>\n",
       "      <td id=\"T_158d9_row1_col10\" class=\"data row1 col10\" >8.9</td>\n",
       "      <td id=\"T_158d9_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_158d9_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_158d9_row1_col13\" class=\"data row1 col13\" >44.9</td>\n",
       "      <td id=\"T_158d9_row1_col14\" class=\"data row1 col14\" >33.0</td>\n",
       "      <td id=\"T_158d9_row1_col15\" class=\"data row1 col15\" >38.9</td>\n",
       "      <td id=\"T_158d9_row1_col16\" class=\"data row1 col16\" >27.1</td>\n",
       "      <td id=\"T_158d9_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_158d9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_158d9_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_158d9_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_158d9_row2_col2\" class=\"data row2 col2\" >37.0</td>\n",
       "      <td id=\"T_158d9_row2_col3\" class=\"data row2 col3\" >34.9</td>\n",
       "      <td id=\"T_158d9_row2_col4\" class=\"data row2 col4\" >5.2</td>\n",
       "      <td id=\"T_158d9_row2_col5\" class=\"data row2 col5\" >10.8</td>\n",
       "      <td id=\"T_158d9_row2_col6\" class=\"data row2 col6\" >33.2</td>\n",
       "      <td id=\"T_158d9_row2_col7\" class=\"data row2 col7\" >34.2</td>\n",
       "      <td id=\"T_158d9_row2_col8\" class=\"data row2 col8\" >8.7</td>\n",
       "      <td id=\"T_158d9_row2_col9\" class=\"data row2 col9\" >32.1</td>\n",
       "      <td id=\"T_158d9_row2_col10\" class=\"data row2 col10\" >12.6</td>\n",
       "      <td id=\"T_158d9_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_158d9_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_158d9_row2_col13\" class=\"data row2 col13\" >44.1</td>\n",
       "      <td id=\"T_158d9_row2_col14\" class=\"data row2 col14\" >32.3</td>\n",
       "      <td id=\"T_158d9_row2_col15\" class=\"data row2 col15\" >38.2</td>\n",
       "      <td id=\"T_158d9_row2_col16\" class=\"data row2 col16\" >26.9</td>\n",
       "      <td id=\"T_158d9_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_158d9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_158d9_row3_col0\" class=\"data row3 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_158d9_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_158d9_row3_col2\" class=\"data row3 col2\" >38.4</td>\n",
       "      <td id=\"T_158d9_row3_col3\" class=\"data row3 col3\" >36.5</td>\n",
       "      <td id=\"T_158d9_row3_col4\" class=\"data row3 col4\" >6.6</td>\n",
       "      <td id=\"T_158d9_row3_col5\" class=\"data row3 col5\" >10.8</td>\n",
       "      <td id=\"T_158d9_row3_col6\" class=\"data row3 col6\" >31.3</td>\n",
       "      <td id=\"T_158d9_row3_col7\" class=\"data row3 col7\" >34.1</td>\n",
       "      <td id=\"T_158d9_row3_col8\" class=\"data row3 col8\" >7.9</td>\n",
       "      <td id=\"T_158d9_row3_col9\" class=\"data row3 col9\" >33.3</td>\n",
       "      <td id=\"T_158d9_row3_col10\" class=\"data row3 col10\" >11.8</td>\n",
       "      <td id=\"T_158d9_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_158d9_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_158d9_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_158d9_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_158d9_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_158d9_row3_col16\" class=\"data row3 col16\" >23.4</td>\n",
       "      <td id=\"T_158d9_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cff6e2350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5d92f td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_5d92f_row0_col0, #T_5d92f_row1_col0, #T_5d92f_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5d92f_row0_col1, #T_5d92f_row1_col1, #T_5d92f_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5d92f_row0_col2, #T_5d92f_row0_col4, #T_5d92f_row0_col7, #T_5d92f_row0_col9, #T_5d92f_row0_col14, #T_5d92f_row1_col3, #T_5d92f_row1_col4, #T_5d92f_row1_col5, #T_5d92f_row1_col10, #T_5d92f_row1_col13, #T_5d92f_row1_col15, #T_5d92f_row2_col6, #T_5d92f_row2_col8, #T_5d92f_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d92f_row0_col3, #T_5d92f_row0_col13, #T_5d92f_row0_col15, #T_5d92f_row0_col16, #T_5d92f_row1_col2, #T_5d92f_row1_col6, #T_5d92f_row1_col8, #T_5d92f_row1_col14, #T_5d92f_row2_col4, #T_5d92f_row2_col5, #T_5d92f_row2_col7, #T_5d92f_row2_col9, #T_5d92f_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d92f_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d92f_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d92f_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d92f_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5d92f_row0_col11, #T_5d92f_row0_col12, #T_5d92f_row0_col17, #T_5d92f_row1_col11, #T_5d92f_row1_col12, #T_5d92f_row1_col17, #T_5d92f_row2_col11, #T_5d92f_row2_col12, #T_5d92f_row2_col13, #T_5d92f_row2_col14, #T_5d92f_row2_col15, #T_5d92f_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d92f_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5d92f_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5d92f_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d92f_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5d92f_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5d92f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5d92f_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_5d92f_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_5d92f_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_5d92f_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_5d92f_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_5d92f_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_5d92f_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_5d92f_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_5d92f_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_5d92f_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_5d92f_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_5d92f_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_5d92f_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_5d92f_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_5d92f_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_5d92f_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_5d92f_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_5d92f_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5d92f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5d92f_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_5d92f_row0_col1\" class=\"data row0 col1\" >60000</td>\n",
       "      <td id=\"T_5d92f_row0_col2\" class=\"data row0 col2\" >37.3</td>\n",
       "      <td id=\"T_5d92f_row0_col3\" class=\"data row0 col3\" >36.6</td>\n",
       "      <td id=\"T_5d92f_row0_col4\" class=\"data row0 col4\" >5.8</td>\n",
       "      <td id=\"T_5d92f_row0_col5\" class=\"data row0 col5\" >10.6</td>\n",
       "      <td id=\"T_5d92f_row0_col6\" class=\"data row0 col6\" >32.7</td>\n",
       "      <td id=\"T_5d92f_row0_col7\" class=\"data row0 col7\" >33.1</td>\n",
       "      <td id=\"T_5d92f_row0_col8\" class=\"data row0 col8\" >7.9</td>\n",
       "      <td id=\"T_5d92f_row0_col9\" class=\"data row0 col9\" >30.4</td>\n",
       "      <td id=\"T_5d92f_row0_col10\" class=\"data row0 col10\" >11.2</td>\n",
       "      <td id=\"T_5d92f_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_5d92f_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_5d92f_row0_col13\" class=\"data row0 col13\" >50.4</td>\n",
       "      <td id=\"T_5d92f_row0_col14\" class=\"data row0 col14\" >37.5</td>\n",
       "      <td id=\"T_5d92f_row0_col15\" class=\"data row0 col15\" >44.0</td>\n",
       "      <td id=\"T_5d92f_row0_col16\" class=\"data row0 col16\" >28.1</td>\n",
       "      <td id=\"T_5d92f_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d92f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5d92f_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_5d92f_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_5d92f_row1_col2\" class=\"data row1 col2\" >38.9</td>\n",
       "      <td id=\"T_5d92f_row1_col3\" class=\"data row1 col3\" >34.5</td>\n",
       "      <td id=\"T_5d92f_row1_col4\" class=\"data row1 col4\" >5.8</td>\n",
       "      <td id=\"T_5d92f_row1_col5\" class=\"data row1 col5\" >9.0</td>\n",
       "      <td id=\"T_5d92f_row1_col6\" class=\"data row1 col6\" >33.0</td>\n",
       "      <td id=\"T_5d92f_row1_col7\" class=\"data row1 col7\" >33.5</td>\n",
       "      <td id=\"T_5d92f_row1_col8\" class=\"data row1 col8\" >8.2</td>\n",
       "      <td id=\"T_5d92f_row1_col9\" class=\"data row1 col9\" >31.2</td>\n",
       "      <td id=\"T_5d92f_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_5d92f_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_5d92f_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_5d92f_row1_col13\" class=\"data row1 col13\" >49.1</td>\n",
       "      <td id=\"T_5d92f_row1_col14\" class=\"data row1 col14\" >37.6</td>\n",
       "      <td id=\"T_5d92f_row1_col15\" class=\"data row1 col15\" >43.4</td>\n",
       "      <td id=\"T_5d92f_row1_col16\" class=\"data row1 col16\" >27.9</td>\n",
       "      <td id=\"T_5d92f_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d92f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5d92f_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_5d92f_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_5d92f_row2_col2\" class=\"data row2 col2\" >38.4</td>\n",
       "      <td id=\"T_5d92f_row2_col3\" class=\"data row2 col3\" >36.5</td>\n",
       "      <td id=\"T_5d92f_row2_col4\" class=\"data row2 col4\" >6.6</td>\n",
       "      <td id=\"T_5d92f_row2_col5\" class=\"data row2 col5\" >10.8</td>\n",
       "      <td id=\"T_5d92f_row2_col6\" class=\"data row2 col6\" >31.3</td>\n",
       "      <td id=\"T_5d92f_row2_col7\" class=\"data row2 col7\" >34.1</td>\n",
       "      <td id=\"T_5d92f_row2_col8\" class=\"data row2 col8\" >7.9</td>\n",
       "      <td id=\"T_5d92f_row2_col9\" class=\"data row2 col9\" >33.3</td>\n",
       "      <td id=\"T_5d92f_row2_col10\" class=\"data row2 col10\" >11.8</td>\n",
       "      <td id=\"T_5d92f_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_5d92f_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_5d92f_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_5d92f_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_5d92f_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_5d92f_row2_col16\" class=\"data row2 col16\" >23.4</td>\n",
       "      <td id=\"T_5d92f_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151d0280a7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3ca3c td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_3ca3c_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3ca3c_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3ca3c_row0_col2, #T_3ca3c_row0_col3, #T_3ca3c_row0_col4, #T_3ca3c_row0_col5, #T_3ca3c_row0_col6, #T_3ca3c_row0_col7, #T_3ca3c_row0_col8, #T_3ca3c_row0_col9, #T_3ca3c_row0_col10, #T_3ca3c_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ca3c_row0_col11, #T_3ca3c_row0_col12, #T_3ca3c_row0_col13, #T_3ca3c_row0_col14, #T_3ca3c_row0_col15, #T_3ca3c_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3ca3c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3ca3c_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_3ca3c_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_3ca3c_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_3ca3c_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_3ca3c_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_3ca3c_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_3ca3c_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_3ca3c_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_3ca3c_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_3ca3c_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_3ca3c_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_3ca3c_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_3ca3c_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_3ca3c_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_3ca3c_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_3ca3c_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_3ca3c_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_3ca3c_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3ca3c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3ca3c_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_3ca3c_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_3ca3c_row0_col2\" class=\"data row0 col2\" >38.4</td>\n",
       "      <td id=\"T_3ca3c_row0_col3\" class=\"data row0 col3\" >36.5</td>\n",
       "      <td id=\"T_3ca3c_row0_col4\" class=\"data row0 col4\" >6.6</td>\n",
       "      <td id=\"T_3ca3c_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_3ca3c_row0_col6\" class=\"data row0 col6\" >31.3</td>\n",
       "      <td id=\"T_3ca3c_row0_col7\" class=\"data row0 col7\" >34.1</td>\n",
       "      <td id=\"T_3ca3c_row0_col8\" class=\"data row0 col8\" >7.9</td>\n",
       "      <td id=\"T_3ca3c_row0_col9\" class=\"data row0 col9\" >33.3</td>\n",
       "      <td id=\"T_3ca3c_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_3ca3c_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_3ca3c_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_3ca3c_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_3ca3c_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_3ca3c_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_3ca3c_row0_col16\" class=\"data row0 col16\" >23.4</td>\n",
       "      <td id=\"T_3ca3c_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cff8a0100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3a3b7 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_3a3b7_row0_col0, #T_3a3b7_row1_col0, #T_3a3b7_row2_col0, #T_3a3b7_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3a3b7_row0_col1, #T_3a3b7_row1_col1, #T_3a3b7_row2_col1, #T_3a3b7_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3a3b7_row0_col2, #T_3a3b7_row0_col3, #T_3a3b7_row0_col7, #T_3a3b7_row0_col8, #T_3a3b7_row0_col9, #T_3a3b7_row0_col10, #T_3a3b7_row0_col13, #T_3a3b7_row1_col6, #T_3a3b7_row1_col7, #T_3a3b7_row1_col8, #T_3a3b7_row1_col9, #T_3a3b7_row1_col10, #T_3a3b7_row2_col5, #T_3a3b7_row2_col7, #T_3a3b7_row2_col8, #T_3a3b7_row2_col9, #T_3a3b7_row2_col10, #T_3a3b7_row2_col14, #T_3a3b7_row2_col15, #T_3a3b7_row3_col4, #T_3a3b7_row3_col7, #T_3a3b7_row3_col8, #T_3a3b7_row3_col9, #T_3a3b7_row3_col10, #T_3a3b7_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a3b7_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a3b7_row0_col5, #T_3a3b7_row0_col6, #T_3a3b7_row0_col11, #T_3a3b7_row0_col12, #T_3a3b7_row0_col17, #T_3a3b7_row1_col11, #T_3a3b7_row1_col12, #T_3a3b7_row1_col17, #T_3a3b7_row2_col6, #T_3a3b7_row2_col11, #T_3a3b7_row2_col12, #T_3a3b7_row2_col17, #T_3a3b7_row3_col11, #T_3a3b7_row3_col12, #T_3a3b7_row3_col13, #T_3a3b7_row3_col14, #T_3a3b7_row3_col15, #T_3a3b7_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a3b7_row0_col14, #T_3a3b7_row0_col16, #T_3a3b7_row1_col13, #T_3a3b7_row1_col15, #T_3a3b7_row2_col3, #T_3a3b7_row2_col4, #T_3a3b7_row3_col2, #T_3a3b7_row3_col5, #T_3a3b7_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a3b7_row0_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a3b7_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a3b7_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a3b7_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a3b7_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a3b7_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a3b7_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a3b7_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a3b7_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3a3b7_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3a3b7_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3a3b7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3a3b7_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_3a3b7_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_3a3b7_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_3a3b7_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_3a3b7_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_3a3b7_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_3a3b7_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_3a3b7_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_3a3b7_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_3a3b7_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_3a3b7_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_3a3b7_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_3a3b7_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_3a3b7_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_3a3b7_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_3a3b7_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_3a3b7_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_3a3b7_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3a3b7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3a3b7_row0_col0\" class=\"data row0 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_3a3b7_row0_col1\" class=\"data row0 col1\" >10000</td>\n",
       "      <td id=\"T_3a3b7_row0_col2\" class=\"data row0 col2\" >29.4</td>\n",
       "      <td id=\"T_3a3b7_row0_col3\" class=\"data row0 col3\" >32.9</td>\n",
       "      <td id=\"T_3a3b7_row0_col4\" class=\"data row0 col4\" >4.6</td>\n",
       "      <td id=\"T_3a3b7_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row0_col13\" class=\"data row0 col13\" >43.9</td>\n",
       "      <td id=\"T_3a3b7_row0_col14\" class=\"data row0 col14\" >28.9</td>\n",
       "      <td id=\"T_3a3b7_row0_col15\" class=\"data row0 col15\" >36.4</td>\n",
       "      <td id=\"T_3a3b7_row0_col16\" class=\"data row0 col16\" >29.3</td>\n",
       "      <td id=\"T_3a3b7_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a3b7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3a3b7_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_3a3b7_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_3a3b7_row1_col2\" class=\"data row1 col2\" >32.6</td>\n",
       "      <td id=\"T_3a3b7_row1_col3\" class=\"data row1 col3\" >35.4</td>\n",
       "      <td id=\"T_3a3b7_row1_col4\" class=\"data row1 col4\" >3.8</td>\n",
       "      <td id=\"T_3a3b7_row1_col5\" class=\"data row1 col5\" >12.8</td>\n",
       "      <td id=\"T_3a3b7_row1_col6\" class=\"data row1 col6\" >33.4</td>\n",
       "      <td id=\"T_3a3b7_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row1_col13\" class=\"data row1 col13\" >46.2</td>\n",
       "      <td id=\"T_3a3b7_row1_col14\" class=\"data row1 col14\" >26.6</td>\n",
       "      <td id=\"T_3a3b7_row1_col15\" class=\"data row1 col15\" >36.5</td>\n",
       "      <td id=\"T_3a3b7_row1_col16\" class=\"data row1 col16\" >28.4</td>\n",
       "      <td id=\"T_3a3b7_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a3b7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3a3b7_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_3a3b7_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_3a3b7_row2_col2\" class=\"data row2 col2\" >34.0</td>\n",
       "      <td id=\"T_3a3b7_row2_col3\" class=\"data row2 col3\" >37.8</td>\n",
       "      <td id=\"T_3a3b7_row2_col4\" class=\"data row2 col4\" >4.8</td>\n",
       "      <td id=\"T_3a3b7_row2_col5\" class=\"data row2 col5\" >12.0</td>\n",
       "      <td id=\"T_3a3b7_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row2_col13\" class=\"data row2 col13\" >44.2</td>\n",
       "      <td id=\"T_3a3b7_row2_col14\" class=\"data row2 col14\" >25.9</td>\n",
       "      <td id=\"T_3a3b7_row2_col15\" class=\"data row2 col15\" >35.4</td>\n",
       "      <td id=\"T_3a3b7_row2_col16\" class=\"data row2 col16\" >27.7</td>\n",
       "      <td id=\"T_3a3b7_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a3b7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3a3b7_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_3a3b7_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_3a3b7_row3_col2\" class=\"data row3 col2\" >35.0</td>\n",
       "      <td id=\"T_3a3b7_row3_col3\" class=\"data row3 col3\" >37.0</td>\n",
       "      <td id=\"T_3a3b7_row3_col4\" class=\"data row3 col4\" >2.8</td>\n",
       "      <td id=\"T_3a3b7_row3_col5\" class=\"data row3 col5\" >13.4</td>\n",
       "      <td id=\"T_3a3b7_row3_col6\" class=\"data row3 col6\" >33.7</td>\n",
       "      <td id=\"T_3a3b7_row3_col7\" class=\"data row3 col7\" >32.5</td>\n",
       "      <td id=\"T_3a3b7_row3_col8\" class=\"data row3 col8\" >7.7</td>\n",
       "      <td id=\"T_3a3b7_row3_col9\" class=\"data row3 col9\" >30.1</td>\n",
       "      <td id=\"T_3a3b7_row3_col10\" class=\"data row3 col10\" >14.6</td>\n",
       "      <td id=\"T_3a3b7_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_3a3b7_row3_col16\" class=\"data row3 col16\" >23.0</td>\n",
       "      <td id=\"T_3a3b7_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cff6e0d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4e7c4 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_4e7c4_row0_col0, #T_4e7c4_row1_col0, #T_4e7c4_row2_col0, #T_4e7c4_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4e7c4_row0_col1, #T_4e7c4_row1_col1, #T_4e7c4_row2_col1, #T_4e7c4_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4e7c4_row0_col2, #T_4e7c4_row0_col3, #T_4e7c4_row0_col4, #T_4e7c4_row0_col13, #T_4e7c4_row0_col15, #T_4e7c4_row0_col16, #T_4e7c4_row1_col5, #T_4e7c4_row1_col6, #T_4e7c4_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4e7c4_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4e7c4_row0_col6, #T_4e7c4_row0_col11, #T_4e7c4_row0_col12, #T_4e7c4_row0_col17, #T_4e7c4_row1_col11, #T_4e7c4_row1_col12, #T_4e7c4_row1_col17, #T_4e7c4_row2_col11, #T_4e7c4_row2_col12, #T_4e7c4_row2_col17, #T_4e7c4_row3_col11, #T_4e7c4_row3_col12, #T_4e7c4_row3_col13, #T_4e7c4_row3_col14, #T_4e7c4_row3_col15, #T_4e7c4_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4e7c4_row0_col7, #T_4e7c4_row0_col8, #T_4e7c4_row0_col9, #T_4e7c4_row0_col10, #T_4e7c4_row1_col7, #T_4e7c4_row1_col8, #T_4e7c4_row1_col9, #T_4e7c4_row1_col10, #T_4e7c4_row1_col13, #T_4e7c4_row1_col14, #T_4e7c4_row1_col15, #T_4e7c4_row2_col2, #T_4e7c4_row2_col3, #T_4e7c4_row2_col5, #T_4e7c4_row2_col7, #T_4e7c4_row2_col8, #T_4e7c4_row2_col9, #T_4e7c4_row2_col10, #T_4e7c4_row3_col4, #T_4e7c4_row3_col6, #T_4e7c4_row3_col7, #T_4e7c4_row3_col8, #T_4e7c4_row3_col9, #T_4e7c4_row3_col10, #T_4e7c4_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4e7c4_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4e7c4_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4e7c4_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4e7c4_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4e7c4_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4e7c4_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4e7c4_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4e7c4_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4e7c4_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4e7c4_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4e7c4_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4e7c4_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4e7c4_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4e7c4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4e7c4_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_4e7c4_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_4e7c4_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_4e7c4_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_4e7c4_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_4e7c4_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_4e7c4_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_4e7c4_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_4e7c4_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_4e7c4_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_4e7c4_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_4e7c4_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_4e7c4_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_4e7c4_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_4e7c4_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_4e7c4_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_4e7c4_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_4e7c4_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4e7c4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4e7c4_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_4e7c4_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_4e7c4_row0_col2\" class=\"data row0 col2\" >35.6</td>\n",
       "      <td id=\"T_4e7c4_row0_col3\" class=\"data row0 col3\" >37.6</td>\n",
       "      <td id=\"T_4e7c4_row0_col4\" class=\"data row0 col4\" >4.8</td>\n",
       "      <td id=\"T_4e7c4_row0_col5\" class=\"data row0 col5\" >13.2</td>\n",
       "      <td id=\"T_4e7c4_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row0_col13\" class=\"data row0 col13\" >49.2</td>\n",
       "      <td id=\"T_4e7c4_row0_col14\" class=\"data row0 col14\" >32.8</td>\n",
       "      <td id=\"T_4e7c4_row0_col15\" class=\"data row0 col15\" >41.1</td>\n",
       "      <td id=\"T_4e7c4_row0_col16\" class=\"data row0 col16\" >30.6</td>\n",
       "      <td id=\"T_4e7c4_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4e7c4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4e7c4_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_4e7c4_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_4e7c4_row1_col2\" class=\"data row1 col2\" >35.2</td>\n",
       "      <td id=\"T_4e7c4_row1_col3\" class=\"data row1 col3\" >35.4</td>\n",
       "      <td id=\"T_4e7c4_row1_col4\" class=\"data row1 col4\" >4.6</td>\n",
       "      <td id=\"T_4e7c4_row1_col5\" class=\"data row1 col5\" >14.0</td>\n",
       "      <td id=\"T_4e7c4_row1_col6\" class=\"data row1 col6\" >34.5</td>\n",
       "      <td id=\"T_4e7c4_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row1_col13\" class=\"data row1 col13\" >45.9</td>\n",
       "      <td id=\"T_4e7c4_row1_col14\" class=\"data row1 col14\" >28.1</td>\n",
       "      <td id=\"T_4e7c4_row1_col15\" class=\"data row1 col15\" >37.0</td>\n",
       "      <td id=\"T_4e7c4_row1_col16\" class=\"data row1 col16\" >29.3</td>\n",
       "      <td id=\"T_4e7c4_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4e7c4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4e7c4_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_4e7c4_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_4e7c4_row2_col2\" class=\"data row2 col2\" >28.5</td>\n",
       "      <td id=\"T_4e7c4_row2_col3\" class=\"data row2 col3\" >31.5</td>\n",
       "      <td id=\"T_4e7c4_row2_col4\" class=\"data row2 col4\" >3.8</td>\n",
       "      <td id=\"T_4e7c4_row2_col5\" class=\"data row2 col5\" >12.0</td>\n",
       "      <td id=\"T_4e7c4_row2_col6\" class=\"data row2 col6\" >34.4</td>\n",
       "      <td id=\"T_4e7c4_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row2_col13\" class=\"data row2 col13\" >46.8</td>\n",
       "      <td id=\"T_4e7c4_row2_col14\" class=\"data row2 col14\" >34.8</td>\n",
       "      <td id=\"T_4e7c4_row2_col15\" class=\"data row2 col15\" >40.8</td>\n",
       "      <td id=\"T_4e7c4_row2_col16\" class=\"data row2 col16\" >29.1</td>\n",
       "      <td id=\"T_4e7c4_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4e7c4_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4e7c4_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_4e7c4_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_4e7c4_row3_col2\" class=\"data row3 col2\" >35.0</td>\n",
       "      <td id=\"T_4e7c4_row3_col3\" class=\"data row3 col3\" >37.0</td>\n",
       "      <td id=\"T_4e7c4_row3_col4\" class=\"data row3 col4\" >2.8</td>\n",
       "      <td id=\"T_4e7c4_row3_col5\" class=\"data row3 col5\" >13.4</td>\n",
       "      <td id=\"T_4e7c4_row3_col6\" class=\"data row3 col6\" >33.7</td>\n",
       "      <td id=\"T_4e7c4_row3_col7\" class=\"data row3 col7\" >32.5</td>\n",
       "      <td id=\"T_4e7c4_row3_col8\" class=\"data row3 col8\" >7.7</td>\n",
       "      <td id=\"T_4e7c4_row3_col9\" class=\"data row3 col9\" >30.1</td>\n",
       "      <td id=\"T_4e7c4_row3_col10\" class=\"data row3 col10\" >14.6</td>\n",
       "      <td id=\"T_4e7c4_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_4e7c4_row3_col16\" class=\"data row3 col16\" >23.0</td>\n",
       "      <td id=\"T_4e7c4_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe774a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_81690 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_81690_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_81690_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_81690_row0_col2, #T_81690_row0_col3, #T_81690_row0_col4, #T_81690_row0_col5, #T_81690_row0_col6, #T_81690_row0_col7, #T_81690_row0_col8, #T_81690_row0_col9, #T_81690_row0_col10, #T_81690_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_81690_row0_col11, #T_81690_row0_col12, #T_81690_row0_col13, #T_81690_row0_col14, #T_81690_row0_col15, #T_81690_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_81690\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_81690_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_81690_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_81690_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_81690_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_81690_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_81690_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_81690_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_81690_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_81690_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_81690_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_81690_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_81690_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_81690_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_81690_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_81690_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_81690_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_81690_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_81690_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_81690_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_81690_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_81690_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_81690_row0_col2\" class=\"data row0 col2\" >35.0</td>\n",
       "      <td id=\"T_81690_row0_col3\" class=\"data row0 col3\" >37.0</td>\n",
       "      <td id=\"T_81690_row0_col4\" class=\"data row0 col4\" >2.8</td>\n",
       "      <td id=\"T_81690_row0_col5\" class=\"data row0 col5\" >13.4</td>\n",
       "      <td id=\"T_81690_row0_col6\" class=\"data row0 col6\" >33.7</td>\n",
       "      <td id=\"T_81690_row0_col7\" class=\"data row0 col7\" >32.5</td>\n",
       "      <td id=\"T_81690_row0_col8\" class=\"data row0 col8\" >7.7</td>\n",
       "      <td id=\"T_81690_row0_col9\" class=\"data row0 col9\" >30.1</td>\n",
       "      <td id=\"T_81690_row0_col10\" class=\"data row0 col10\" >14.6</td>\n",
       "      <td id=\"T_81690_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_81690_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_81690_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_81690_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_81690_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_81690_row0_col16\" class=\"data row0 col16\" >23.0</td>\n",
       "      <td id=\"T_81690_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe498fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3959393328.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3959393328.py:394: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0b1f0 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_0b1f0_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0b1f0_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0b1f0_row0_col2, #T_0b1f0_row0_col3, #T_0b1f0_row0_col4, #T_0b1f0_row0_col5, #T_0b1f0_row0_col6, #T_0b1f0_row0_col7, #T_0b1f0_row0_col8, #T_0b1f0_row0_col9, #T_0b1f0_row0_col10, #T_0b1f0_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0b1f0_row0_col11, #T_0b1f0_row0_col12, #T_0b1f0_row0_col13, #T_0b1f0_row0_col14, #T_0b1f0_row0_col15, #T_0b1f0_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0b1f0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0b1f0_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_0b1f0_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_0b1f0_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_0b1f0_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_0b1f0_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_0b1f0_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_0b1f0_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_0b1f0_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_0b1f0_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_0b1f0_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_0b1f0_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_0b1f0_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_0b1f0_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_0b1f0_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_0b1f0_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_0b1f0_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_0b1f0_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_0b1f0_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0b1f0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0b1f0_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_0b1f0_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_0b1f0_row0_col2\" class=\"data row0 col2\" >35.0</td>\n",
       "      <td id=\"T_0b1f0_row0_col3\" class=\"data row0 col3\" >37.0</td>\n",
       "      <td id=\"T_0b1f0_row0_col4\" class=\"data row0 col4\" >2.8</td>\n",
       "      <td id=\"T_0b1f0_row0_col5\" class=\"data row0 col5\" >13.4</td>\n",
       "      <td id=\"T_0b1f0_row0_col6\" class=\"data row0 col6\" >33.7</td>\n",
       "      <td id=\"T_0b1f0_row0_col7\" class=\"data row0 col7\" >32.5</td>\n",
       "      <td id=\"T_0b1f0_row0_col8\" class=\"data row0 col8\" >7.7</td>\n",
       "      <td id=\"T_0b1f0_row0_col9\" class=\"data row0 col9\" >30.1</td>\n",
       "      <td id=\"T_0b1f0_row0_col10\" class=\"data row0 col10\" >14.6</td>\n",
       "      <td id=\"T_0b1f0_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_0b1f0_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_0b1f0_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_0b1f0_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_0b1f0_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_0b1f0_row0_col16\" class=\"data row0 col16\" >23.0</td>\n",
       "      <td id=\"T_0b1f0_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cff7b3280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_sort_rows_by_avg_ranking\n",
    "from llm.evaluate import EvalResults, get_eval_results\n",
    "\n",
    "\n",
    "\n",
    "exp_dir = ''\n",
    "chat_fmt = None\n",
    "sort_rows = True\n",
    "use_normalized_preferred_metric = False\n",
    "\n",
    "\n",
    "# ## investigate code change / package update effect on eval baselines.\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# use_normalized_preferred_metric = False\n",
    "# sort_rows = False\n",
    "# save_dirs = [\n",
    "#     # llama\n",
    "#     ('llama-7b_12.13update_before', '../results/baselines/huggyllama/llama-7b_12.13update_before/'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('llama-7b_10.30update', '../results/baselines/huggyllama/llama-7b_10.30update/'),\n",
    "# #     ('llama-7b_09.23update', '../results/baselines/huggyllama/llama-7b_09.23update/'),\n",
    "# #     ('llama-7b_09.23update_before', '../results/baselines/huggyllama/llama-7b_09.23update_before/'),\n",
    "# #     # llama2\n",
    "#     ('llama2-7b_12.13update_before', '../results/baselines/NousResearch/Llama-2-7b-hf_12.13update_before/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('llama2-7b-chat', '../results/baselines/NousResearch/Llama-2-7b-chat-hf/'),\n",
    "# #     ('llama2-7b_10.30update', '../results/baselines/NousResearch/Llama-2-7b-hf_10.30update/'),\n",
    "# #     ('llama2-7b_original', '../results/baselines/NousResearch/Llama-2-7b-hf_original/'),\n",
    "# #     # mistral\n",
    "# #     ('mistral-7b_10.16update', '../results/baselines/mistralai/Mistral-7B-v0.1_10.16update/'),\n",
    "#     ('mistral-7b-Instruct-v0.1_12.13update_before', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1_12.13update_before'),\n",
    "#     ('mistral-7b-Instruct-v0.1', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     # zephyr\n",
    "#     ('zephyr-7b-beta_12.13update_before', '../results/baselines/HuggingFaceH4/zephyr-7b-beta_12.13update_before'),\n",
    "#     ('zephyr-7b-beta', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "\n",
    "# # baselines\n",
    "# save_dirs = []\n",
    "# save_dirs += [\n",
    "# #     ('gpt2', '../results/baselines/gpt2'),\n",
    "# #     ('gpt2m', '../results/baselines/gpt2-medium'),\n",
    "# #     ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "# #     ('llama2-7b+humanmix', '../results/llama2-7b_humanmix'),\n",
    "# #     ('pythia-1.4b', '../results/baselines/EleutherAI/pythia-1.4b'),\n",
    "# #     ('pythia-2.8b', '../results/baselines/EleutherAI/pythia-2.8b'),\n",
    "# #     ('pythia-6.9b', '../results/baselines/EleutherAI/pythia-6.9b'),\n",
    "# #     ('dolly-v2-7b', '../results/baselines/databricks/dolly-v2-7b'),\n",
    "#     ('mistral-7b-v0.1', '../results/baselines/mistralai/Mistral-7B-v0.1'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b+lima_ep=2', '../results/ft1_ep=2/llama-7b_lima/'),\n",
    "# #     ('mistral-7b+lima_ep=2', '../results/ft1_ep=2/mistral-7b_lima/'), \n",
    "# ]\n",
    "# exp_dir = '../results/oi2/'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "\n",
    "# exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# # exp_dir = '../results/ft2'\n",
    "# # exp_dir = '../results/ft1'\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# # save_dirs = [\n",
    "# #     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "# #     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1/'),\n",
    "# # ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'tuluv1m' in x]\n",
    "\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "# # exp_dir = '../results/oi4'\n",
    "# # exp_dir = '../results/oi4_perf_cross_time'\n",
    "# # exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'\n",
    "# exp_dir = '../results/oi4_flan_v2_vary_subsetsize'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi4_flan2022_1m'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #              ('llama-7b_flan_v2_ep=2', '../results/ft1/llama-7b_flan_v2'),\n",
    "# #              ('llama-7b_humanmix_ep=2', '../results/ft1/llama-7b_humanmix'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "# #              ('llama-7b_cot:flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_cot:flanv2'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# # exp_dir = '../results/oi4_tulu_v1_mix'\n",
    "# exp_dir = '../results/oi4_tulu_v1_mix_ep=3'\n",
    "# use_normalized_preferred_metric = False\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# ###### ultrachat\n",
    "# save_dirs = [\n",
    "#     # baselines \n",
    "#     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "#     ('mistral-7b_ultrachat200k_aftersplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k'),\n",
    "#     ('mistral-7b_ultrachat200k_beforesplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k_beforesplitlongconv'),\n",
    "    \n",
    "#     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     ('mistral-7b_sft-alpha', '../results/baselines/HuggingFaceH4/mistral-7b-sft-alpha'),\n",
    "#     ('mistral-7b-sft-beta', '../results/baselines/HuggingFaceH4/mistral-7b-sft-beta'),\n",
    "#     ('mistral-7b-sft-alpha+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-alpha'),\n",
    "#     ('mistral-7b-sft-beta+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "# # exp_dir = '../results/oi5_ultrachat:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_ultrachat200k:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# exp_dir = '../results/oi5_ultrachat15:mistral-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "# dataset = 'stanford_alpaca'\n",
    "# dataset = 'open_orca_slim'\n",
    "# dataset = 'sharegptv2'\n",
    "# dataset = 'ultrachat200kv2'\n",
    "# dataset = 'wizardlm'\n",
    "# dataset = 'wizardlmv2'\n",
    "# dataset = 'tulu_v2'\n",
    "# dataset = 'flan_v2'\n",
    "# dataset = 'oasst1'\n",
    "# dataset = 'dolly'\n",
    "# dataset_list = [\n",
    "#     'dolly',\n",
    "#     'oasst1', \n",
    "#     'flan_v2', \n",
    "#     'stanford_alpaca', \n",
    "#     'wizardlmv2', \n",
    "#     'sharegptv2', \n",
    "#     'ultrachat200kv2',\n",
    "# ]; finetune_type = 'sft'\n",
    "dataset_list = [\n",
    "    'dolly',\n",
    "#     'oasst1', \n",
    "#     'flan_v250k', \n",
    "#     'stanford_alpaca50k', \n",
    "#     'wizardlm50k', \n",
    "    'sharegpt50k', \n",
    "#     'ultrachat50k',\n",
    "]; finetune_type = 'sft'\n",
    "# dataset_list = [\n",
    "#     'dolly',\n",
    "# #     'oasst1', \n",
    "# #     'flan_v2', \n",
    "# #     'stanford_alpaca', \n",
    "# #     'wizardlmv2', \n",
    "# #     'sharegptv2', \n",
    "# #     'ultrachat200kv2',\n",
    "# ]; finetune_type = 'sft'\n",
    "# dataset_list = [\n",
    "#     'ultrafeedback',\n",
    "# #     'ultrafeedbackfull',\n",
    "# ]; finetune_type = 'pref'\n",
    "dataset_list = [\n",
    "    'dolly',\n",
    "    'flan_v250k',\n",
    "    'stanford_alpaca50k', \n",
    "    'oasst2',\n",
    "    'wizardlm50k', \n",
    "    'sharegpt50k',\n",
    "    'ultrachat50k',\n",
    "]; finetune_type = 'sft'\n",
    "\n",
    "## older\n",
    "# dataset = 'tulu_v1_mix'\n",
    "save_dirs = []\n",
    "save_dirs += [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b'),\n",
    "#     ('llama-7b_lima_ep=5', '../results/oi2/llama-7b_lima_ep=5/'),\n",
    "#     ('llama-7b_lima_ep=10', '../results/oi2/llama-7b_lima_ep=10/'),\n",
    "]\n",
    "for dataset in dataset_list:\n",
    "    if dataset == 'tulu_v2':\n",
    "        save_dirs += [('llama-7b_tulu_v2:100k_ep=2', '../results/oi2/llama-7b_tulu_v2:100k_ep=2'),]\n",
    "    elif dataset == 'open_orca_slim':\n",
    "        save_dirs += [('llama-7b_openorcaslim:100k_ep=2', '../results/oi2/llama-7b_openorcaslim:100k_ep=2'),]\n",
    "    elif dataset == 'sharegptv2':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_sharegptv2_ep=2', '../results/oi2/llama-7b_sharegptv2_ep=2'),\n",
    "            ('llama-7b_sharegpt_ep=2', '../results/ft1_ep=2/llama-7b_sharegpt'),]\n",
    "    elif dataset == 'tulu_v1_mix':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "            # oi4_tulu_v1_mix_ep=3 models before transformers update.\n",
    "            # ('llama-7b_tuluv1m:50k_log_prob_decr_<10.16update', '../results/oi4_tulu_v1_mix_ep=3/llama-7b_tuluv1m:50k_log_prob_decr'),\n",
    "        ]\n",
    "    elif dataset == 'ultrafeedback':\n",
    "        exp_dir = f'../results/dpo1/'\n",
    "        save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "    else:\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=2', f'../results/oi2/llama-7b_{dataset}_ep=2'),]\n",
    "    \n",
    "    if finetune_type == 'sft':\n",
    "        exp_dir = f'../results/oi5_{dataset}:llama-7b'\n",
    "    elif finetune_type == 'pref':\n",
    "        exp_dir = f'../results/dpo2_{dataset}:llama-7b+sharegptv2ep2/'\n",
    "    save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'dppmapbd' not in x and 'semdedup' not in x]\n",
    "    \n",
    "    if finetune_type == 'pref':\n",
    "        sft_model_dataset = 'sharegptv2'\n",
    "        save_dirs += [('llama-7b_sharegptv2_ep=2', f'../results/oi2/llama-7b_{sft_model_dataset}_ep=2')]\n",
    "# ## just compare dppmap grad vs. text\n",
    "# save_dirs = [x for x in save_dirs if 'prune:size=10000:ep=10' in x[1] and (\n",
    "#         'random' in x[1] or \n",
    "#         'dppmap' in x[1]\n",
    "#     )\n",
    "# ]\n",
    "#####\n",
    "\n",
    "\n",
    "# ##### code instructions\n",
    "# save_dirs = [\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('codellama-7b', '../results/baselines/codellama/CodeLlama-7b-hf/'),\n",
    "#     ('codellama-7b-instruct', '../results/baselines/codellama/CodeLlama-7b-Python-hf/'),\n",
    "#     ('codellama-7b-python', '../results/baselines/codellama/CodeLlama-7b-Instruct-hf/'),\n",
    "# ]\n",
    "\n",
    "# exp_dir = '../results/oi2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'starcoder' in x]\n",
    "# exp_dir = '../results/oi6_starcoder_ep=5'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstr:codellama-7b'\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstrv2:codellama-7b'\n",
    "# exp_dir = '../results/oi5_starcoder_commentinstrv5:codellama-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "###### \n",
    "\n",
    "from llm.evaluate import detect_oom_evals\n",
    "oom_eval_paths = detect_oom_evals([x for l in [glob.glob(os.path.join(x[1], 'eval/*/*.out')) for x in save_dirs] for x in l])\n",
    "if oom_eval_paths: print(oom_eval_paths)\n",
    "    \n",
    "cols_avg_blacklist = ['AlpacaFarm/Len']\n",
    "\n",
    "# chat_fmt = False\n",
    "chat_fmt = True\n",
    "chat_fmt = 'both'\n",
    "# chat_fmt = 'auto' # base model no chatfmt, tuned model with chatfmt\n",
    "chat_fmt = 'mix'  # non-alpacaeval no chatfmt, alpacaeval chatfmt\n",
    "alpacafarm_judge = 'chatgpt'\n",
    "alpacafarm_judge = 'alpaca:eval:gpt4:turbo:fn'\n",
    "mtbench_judge = 'gpt:4:1106:preview'\n",
    "\n",
    "ft_args_fields = {\n",
    "    'run_name': ('run_name',),\n",
    "    'model_name_or_path': ('model_args.model_name_or_path', 'model_name_or_path'),\n",
    "    'subsample_mixture': ('data_args.subsample_mixture',),\n",
    "    'max_train_samples': ('data_args.max_train_samples', 'max_train_samples'),\n",
    "    'train_file': ('data_args.train_file', 'train_file'),\n",
    "}\n",
    "\n",
    "cols = []\n",
    "# cols += [f'AlpacaFarm({alpacafarm_judge})/WR',  f'AlpacaFarm({alpacafarm_judge})/ΔWR', f'AlpacaFarm({alpacafarm_judge})/Rep', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "cols += ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1'] \n",
    "cols += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "cols += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "# cols += [f'MTBench({mtbench_judge})/Turn-1']\n",
    "\n",
    "\n",
    "\n",
    "# cols = [f'BBH {x}' for x in ['reasoning', 'nlu', 'knowledge', 'multilingual']]; cols = [x+'/Direct' for x in cols] + [x+'/CoT' for x in cols]\n",
    "# cols = [f'MMLU {x}' for x in ['STEM', 'humanities', 'social sciences', 'other']]; cols = [x+'/0-shot' for x in cols] + [x+'/5-shot' for x in cols]\n",
    "\n",
    "if 'open_orca_slim' in exp_dir:\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'BBH/Direct', 'BBH/CoT']\n",
    "    cols = ['MMLU/0-shot', 'BBH/Direct']\n",
    "if 'starcoder' in exp_dir:\n",
    "    cols = ['Codex-Eval/Pass@1']\n",
    "    chat_fmt = 'both'\n",
    "print(f'chat_fmt={chat_fmt}')\n",
    "df = get_eval_results(save_dirs, chat_fmt=chat_fmt, ft_args_fields=ft_args_fields, use_normalized_preferred_metric=use_normalized_preferred_metric)\n",
    "\n",
    "cols = [x for x in cols if x in df.columns]\n",
    "df = df[list(ft_args_fields.keys()) + cols]\n",
    "if chat_fmt == 'both':\n",
    "    for col_lvl2 in ['', 'chatfmt']:\n",
    "        df[('Average', col_lvl2)] = df[list(set(df.columns) & set([(x, col_lvl2) for x in list(set(cols)-set(cols_avg_blacklist))]))].mean(axis=1)\n",
    "else:\n",
    "    df['Average'] = df[list(set(cols)-set(cols_avg_blacklist))].mean(axis=1)\n",
    "if sort_rows:\n",
    "    df = pd_sort_rows_by_avg_ranking(df); df['ranking'] = -df['ranking']\n",
    "    sort_value_col, sort_value_col_ascending = ('Average', 'chatfmt') if chat_fmt=='both' else 'Average', False\n",
    "#     sort_value_col, sort_value_col_ascending = 'ranking', False\n",
    "    df = df.sort_values(by=sort_value_col, ascending=sort_value_col_ascending)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def compute_total_train_samples(x):\n",
    "    match = re.search(r'size=(\\d+)', x['run_name' if chat_fmt!='both' else ('run_name', '')])\n",
    "    total_train_samples = match.group(1) if match else None\n",
    "    return total_train_samples\n",
    "df.insert(1, 'total_train_samples' if chat_fmt!='both' else ('total_train_samples', ''), df.apply(compute_total_train_samples, axis=1))\n",
    "def extract_dataset_from_train_file(x):\n",
    "    if x is None: return None\n",
    "    x = x.split('/')[-1].split('.jsonl')[0]\n",
    "    if x.endswith('_data'): x = x[:-5]\n",
    "    if x.endswith('_train'): x = x[:-6]\n",
    "    return x\n",
    "df.insert(1, 'dataset' if chat_fmt!='both' else ('dataset', ''), df['train_file'].apply(extract_dataset_from_train_file))\n",
    "df = df.drop('train_file', axis=1)\n",
    "\n",
    "if any(exp_dir.endswith(x) for x in ['ft2']):\n",
    "#     for model_name_contain in ['gpt2', 'llama', 'pythia-1.4b']:\n",
    "#         for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "    for model_name_contain in ['llama']:\n",
    "        for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "#         for total_train_samples in [200000, 400000, 600000]:\n",
    "            dfc = df.copy()\n",
    "            dfc.insert(0, 'total_train_samples',  dfc['subsample_mixture'].apply(\n",
    "                lambda d: sum(list(d.values())) if d else 200000))\n",
    "            dfc = dfc[dfc['total_train_samples'].apply(\n",
    "                lambda x: total_train_samples-20000<x<total_train_samples+20000)]\n",
    "            dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "                lambda x: model_name_contain in x)]\n",
    "            dfc['total_train_samples'] = dfc['total_train_samples'].astype(str)\n",
    "            dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture'])\n",
    "            dfc = dfc.reset_index(drop=True)\n",
    "            if len(dfc):\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .format(precision=2))\n",
    "else:\n",
    "    for model_name_contain in ['llama', 'pythia-1.4b', 'mistral', 'zephyr']:\n",
    "        dfc = df.copy()\n",
    "        dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "            lambda x: model_name_contain in x.lower())]\n",
    "        if not len(dfc): continue\n",
    "        from rosemary import pd_average_col_contains_substr\n",
    "        Ns = sorted(np.unique([int(x) for x in df['total_train_samples'].to_numpy() if x]).tolist())\n",
    "        datasets = sorted(np.unique([x for x in df['dataset'] if x is not None]).tolist())\n",
    "        for dataset in datasets:\n",
    "            for N in Ns+[None]:\n",
    "                dfc = df.copy()\n",
    "                dfc = dfc[dfc['total_train_samples'].apply(lambda x: int(x) == N if x else True)]\n",
    "                dfc = dfc[dfc['dataset'].apply(lambda x: x == dataset if x else True)]\n",
    "                if not len(dfc): continue\n",
    "                col_runname = 'run_name' if chat_fmt != 'both' else ('run_name', '')\n",
    "                substitute = True\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, '_random_', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=10000:ep=10', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=50000:ep=5', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=3', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=1', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=100000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=200000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=400000', substitute=substitute)\n",
    "                #     dfc = dfc.sort_values(['ranking'], ascending=False)\n",
    "                col = ('Average', 'chatfmt') if chat_fmt == 'both' else 'Average'\n",
    "            #     col = 'AlpacaFarm/WR'\n",
    "            #     col = 'MMLU/0-shot'|\n",
    "            #     col = 'GSM/CoT'\n",
    "            #     col = 'BBH/Direct'\n",
    "            #     col = 'TydiQA/GP'\n",
    "                dfc = dfc.sort_values(by=[col], ascending=False)\n",
    "                dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture', 'max_train_samples', 'dataset'], \n",
    "                               axis=1, level=0 if chat_fmt=='both' else None)\n",
    "                dfc = dfc.reset_index(drop=True)\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .applymap(lambda x: f'max-width: 60ch;', subset=['run_name'])\n",
    "                        .set_table_styles([{'selector': 'td', 'props': [('white-space', 'pre-wrap'), ('word-wrap', 'break-word')]}])\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .applymap(lambda x: 'text-decoration: underline;' \\\n",
    "                                  if x in dfc[list(set(dfc.columns) & set([(x, '') for x in cols]))+[col] if chat_fmt=='both' else cols+[col]].values.flatten() and chat_fmt=='both' else '')\n",
    "                        .format(precision=1))\n",
    "\n",
    "# llama-7b_tulu_v1_mix(paper)\n",
    "# MMLU/0-shot, MMLU/5-shot, GSM/Direct, GSM/CoT, BBH/Direct, BBH/CoT, TydiQA/GP, TydiQA/CB, CodexEval/Pass@1, AlpacaEval(vs.Davinci-003)\n",
    "# 44.8       , 47.1       , 7.0       , 25.0   , 38.5      , 38.5   , 43.5,    , 8.0      , 18.6,           , 48.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deeba0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_name',\n",
       " 'nonchat',\n",
       " 'sort_by',\n",
       " 'total_train_samples',\n",
       " 'model_name_or_path',\n",
       " 'subsample_mixture',\n",
       " 'max_train_samples',\n",
       " 'MMLU/0-shot',\n",
       " 'MMLU/5-shot',\n",
       " 'GSM/Direct',\n",
       " 'GSM/CoT',\n",
       " 'BBH/Direct',\n",
       " 'BBH/CoT',\n",
       " 'TydiQA/CB',\n",
       " 'TydiQA/GP',\n",
       " 'Codex-Eval/Pass@1',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len',\n",
       " 'MTBench(gpt:4:1106:preview)/Turn-1',\n",
       " 'MTBench(gpt:4:1106:preview)/Turn-2',\n",
       " 'MTBench(gpt:4:1106:preview)/Rating',\n",
       " 'Average',\n",
       " 'ranking']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rosemary import parse_kv_from_string\n",
    "\n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', ]\n",
    "# non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', ]\n",
    "\n",
    "def compute_nonchateval_average_performance(row):\n",
    "    L = [row[k] for k in non_chateval_task_names if k in row]\n",
    "    return np.average(L)\n",
    "\n",
    "def parse_prune_subset_size(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'(?<=pace=)([^_]+)', run_name)\n",
    "    if match:\n",
    "        pace = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(pace)\n",
    "        subset_size = int(kvs['size'] / kvs['ep'])\n",
    "        return subset_size\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_sort_by_from_run_name(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'score=([^_]+)', run_name)\n",
    "    if match:\n",
    "        sort_by = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(sort_by)\n",
    "    else:\n",
    "        kvs = {}\n",
    "    return kvs\n",
    "\n",
    "\n",
    "def parse_sort_by_type(row):\n",
    "    d = row['sort_by']\n",
    "    if not d:\n",
    "        return None\n",
    "    if d[0] == 'dppmap':\n",
    "        if d['k']=='vmf' and d['kmd']=='mpnet': #and (d['gamma']==1 or d['gamma'] == 'auto1000'):\n",
    "            return 'vmf+text'\n",
    "        elif d['k']=='rbf' and d['kemb']=='text+embedding' and d['kmd'] == 'llama7br512p4096':\n",
    "            return f\"rbf+text_gamma={d['gamma']}\"\n",
    "        elif d['k']=='vmf' and d['kemb']=='grad+rp+loraB' and d['kmd'] == 'llama7br512p4096':\n",
    "            return f\"vmf+grad_gamma={d['gamma']}\"\n",
    "        else:\n",
    "            return None\n",
    "    elif d[0] == 'random':\n",
    "        return 'random'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "dfc.insert(1, 'sort_by' if chat_fmt!='both' else ('sort_by', ''), dfc.apply(parse_sort_by_from_run_name, axis=1))\n",
    "dfc.insert(1, 'sort_by_type' if chat_fmt!='both' else ('sort_by_type', ''), dfc.apply(parse_sort_by_type, axis=1))\n",
    "dfc.insert(1, 'subset_size' if chat_fmt!='both' else ('subset_size', ''), dfc.apply(parse_prune_subset_size, axis=1))\n",
    "dfc.insert(1, 'nonchat' if chat_fmt!='both' else ('nonchat', ''), dfc.apply(compute_nonchateval_average_performance, axis=1))\n",
    "\n",
    "\n",
    "dfc = dfc[dfc['sort_by_type'].notnull()]\n",
    "startswithstrs = ('rbf+text', 'random')\n",
    "startswithstrs = (\n",
    "    'random', \n",
    "    'rbf+text_gamma=0.001', \n",
    "    'vmf+grad_gamma=1',\n",
    "#     'rbf+text_gamma=auto1000', \n",
    "    'vmf+grad_gamma=auto1000',\n",
    ")\n",
    "dfc = dfc[dfc.apply(lambda x: x['sort_by_type'].startswith(startswithstrs)\n",
    "                   , axis=1)]\n",
    "dfc['subset_size'] = dfc['subset_size'].apply(lambda x: int(x) if x else x)\n",
    "# dfc = dfc[dfc['subset_size']>1_000]\n",
    "\n",
    "\n",
    "D = dfc.set_index(['sort_by_type', 'dataset', 'subset_size']).to_dict()\n",
    "from dataclasses import dataclass\n",
    "@dataclass(unsafe_hash=True)\n",
    "class DKey:\n",
    "    sort_by_type: str\n",
    "    dataset: str\n",
    "    subset_size: int\n",
    "def convert_key_to_dataclass(d):\n",
    "    return {DKey(*k): v for k, v in d.items()}\n",
    "D = {k: convert_key_to_dataclass(v) for k, v in D.items()}\n",
    "\n",
    "list(D.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "662539cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1700x1200 with 42 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "yaxis_type = 'abs'\n",
    "# yaxis_type = 'delta_random'\n",
    "assert(yaxis_type in ['delta_random', 'abs'])\n",
    "datasets = ['flan_v2', 'dolly', 'stanford_alpaca', 'oasst1', 'ultrachat200kv2', 'wizardlmv2', 'sharegptv2']\n",
    "task_names = ['nonchat', 'MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR*',]\n",
    "\n",
    "datasets = ['dolly', 'sharegpt50k']\n",
    "datasets = list(np.unique(dfc['dataset']))\n",
    "task_names = []\n",
    "task_names += ['nonchat']\n",
    "# task_names += ['MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1',]\n",
    "task_names += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "# task_names += [f'MTBench({mtbench_judge})/Rating']\n",
    "task_names += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "\n",
    "\n",
    "\n",
    "w = 2\n",
    "ncols = len(datasets)\n",
    "nrows = len(task_names)\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(w*ncols+3,w*nrows), sharey='row', sharex=True)\n",
    "\n",
    "xs_possible = []\n",
    "\n",
    "for axi, task_name in enumerate(task_names):\n",
    "    d = D[task_name]\n",
    "    for axj, dataset in enumerate(datasets):\n",
    "        ax = axs.reshape(nrows, ncols)[axi, axj]\n",
    "        sort_by_types = sorted(set(x.sort_by_type for x in d.keys()))\n",
    "\n",
    "        for i, sort_by_type in enumerate(sort_by_types):\n",
    "            xs = sorted([x.subset_size for x in d.keys()\n",
    "                         if x.dataset == dataset and x.sort_by_type==sort_by_type])\n",
    "            xs_possible += list(set(xs) - set(xs_possible))\n",
    "            ys = [d[DKey(sort_by_type, dataset, x)] for x in xs]\n",
    "            if yaxis_type == 'delta_random':\n",
    "                if not all(DKey('random', dataset, x) in d for x in xs): continue\n",
    "                ys = [y-d[DKey('random', dataset, x)] for x, y in zip(xs, ys)] \n",
    "            if 'random' in sort_by_type:\n",
    "                marker_style = 'o-'\n",
    "            else:\n",
    "                marker_style = 'o-'\n",
    "            ax.plot(xs, ys, marker_style, label=sort_by_type)\n",
    "        \n",
    "#         ax.set_yscale('log')\n",
    "            \n",
    "for axi, task_name in enumerate(task_names):\n",
    "    task_name_shortened = task_name.replace(f'({mtbench_judge})', '').replace(f'({alpacafarm_judge})', '')\n",
    "    axs.reshape(nrows, ncols)[axi, 0].set_ylabel('△ '+task_name_shortened if yaxis_type.startswith('delta') else task_name_shortened, fontsize=13)\n",
    "    axs.reshape(nrows, ncols)[axi, -1].legend(loc='center left', bbox_to_anchor=(1.1, 0.5))\n",
    "for axj, dataset in enumerate(datasets):\n",
    "    axs.reshape(nrows, ncols)[0, axj].set_title(dataset, fontsize=15)\n",
    "    axs.reshape(nrows, ncols)[0, axj].set_xticks(xs_possible, xs_possible)\n",
    "\n",
    "space = 0.05\n",
    "fig.subplots_adjust(wspace=space, hspace=space)  # Adjust the value as needed\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5fdb69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e2f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39874bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
