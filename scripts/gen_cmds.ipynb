{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 831,
   "id": "3da1794b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'x86_64', 'cluster': 'ccc', 'queue': 'alt_7d'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "import re\n",
    "from llm.submit import (\n",
    "    multiline_to_singleline,\n",
    "    submit_job_ccc,\n",
    "    submit_job_aimos,\n",
    "    submit_job,\n",
    "        get_run_statistics)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import datetime\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import base64\n",
    "string_to_alphanumeric = lambda s: base64.urlsafe_b64encode(s.encode('utf-8')).decode('utf-8')\n",
    "alphanumeric_to_string = lambda a: base64.urlsafe_b64decode(a).decode('utf-8')\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm, shell_scripts_template_lsf, get_host_info, move_lsf_job_summary_to_save_dir\n",
    "from note_pruning_analysis import open_instruct_dir, assets_dir\n",
    "os.makedirs(assets_dir, exist_ok=True)\n",
    "\n",
    "import getpass\n",
    "\n",
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "info = get_host_info()\n",
    "info.update({'queue': queue})\n",
    "arch, cluster = info['arch'], info['cluster']\n",
    "print(info)\n",
    "\n",
    "os.environ['TORCHELASTIC_ERROR_FILE'] = os.path.join(os.getcwd(), 'torchelastic_error_file') \n",
    "\n",
    "## jobs submitted in notebook inherits env variables.\n",
    "cache_dir = os.path.normpath(os.path.join(os.getcwd(), '../../../../mitibm2023/cache')) \\\n",
    "    if arch == 'ppc64le' else '/dccstor/data-pruning/cache'\n",
    "os.environ['WANDB_DIR'] = cache_dir\n",
    "os.makedirs(os.environ['WANDB_DIR'], exist_ok=True, mode=0o777)\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_PROJECT'] = 'mitibm'\n",
    "##\n",
    "##\n",
    "\n",
    "shell_scripts_template = shell_scripts_template_slurm \\\n",
    "    if arch == 'ppc64le' else shell_scripts_template_lsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c421d1",
   "metadata": {},
   "source": [
    "# DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c09b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/oi2/llama-7b_sharegptv2_ep=2 using 6 GPUs, 1 batch size per GPU, 1 gradient accumulation steps, 30 effective batch size.\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp7pssto1b', 'job_id': 1354503}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2p8zx1bt', 'job_id': 1354504}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2_mpillk', 'job_id': 1354505}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm\n",
    "debug = False\n",
    "if debug:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'INFO'\n",
    "    os.environ['NCCL_DEBUG'] = 'INFO'\n",
    "else:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'WARNING'\n",
    "    os.environ['NCCL_DEBUG'] = ''\n",
    "num_cpus = 144 if arch == 'ppc64le' else 32\n",
    "cpu_mem =  650 if arch == 'ppc64le' else 64\n",
    "\n",
    "preprocessing_num_workers = 32\n",
    "report_to = 'wandb'\n",
    "mixed_precision = 'bf16' if arch == 'x86_64' else 'fp16'\n",
    "torch_dtype = 'bfloat16' if arch=='x86_64' else 'float32'\n",
    "gradient_checkpointing = True\n",
    "use_fast_tokenizer = True\n",
    "hf_models_dir = 'results/baselines/'\n",
    "resume_from_checkpoint = True # resume from latest checkpoint if exists, otherwise train from scratch\n",
    "num_train_epochs = 2\n",
    "checkpointing_steps = 300 # (50_000 / 32) * 2 / 6 ~= 500 (data size of 50k, bsz=32, ep=2, total save 6 times at most)\n",
    "max_train_steps = None\n",
    "subsample_inds_file_list = [None]\n",
    "dataloader_sampler = 'RandomSampler'\n",
    "overwrite_cache = True\n",
    "\n",
    "\n",
    "# #####\n",
    "# job_name = 'dpo1'\n",
    "\n",
    "# # model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-410m-deduped'; max_seq_length = 2048; abbr_model_name = 'pythia-410m'\n",
    "# # model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "\n",
    "# train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "\n",
    "\n",
    "# M = 60_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 20_000\n",
    "# M = 50_000; pacing_fn_list = [f'prune_size={M}_ep=5']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "#     (10_000, 10), # 1k\n",
    "#     (30_000, 3),  # 10k\n",
    "    (60_000, 3),  # 20k\n",
    "]]\n",
    "\n",
    "gen_output_md = 'llama7br512p4096'\n",
    "# gen_output_md = 'llama7b+sharegptv2ep2+r512p4096'\n",
    "# gen_output_model_name = 'all-mpnet-base-v2'\n",
    "\n",
    "scoring_fn_list = []\n",
    "scoring_fn_list += ['random_s=0']\n",
    "# scoring_fn_list += ['random_s=1']\n",
    "scoring_fn_list += [ \n",
    "    f'dppmap_k=vmf_gamma=1_kmd={gen_output_md}_kemb=grad+rp+loraB',\n",
    "    f'dppmap_k=rbf_gamma=1e-3_kmd={gen_output_md}_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1_kmd=mpnet_kemb=text+embedding',\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'dpo2_{dataset}:{abbr_model_name}'\n",
    "    \n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12\n",
    "# nodes = 2; num_gpus = 1; gpu_type = 'v100'; job_duration = 6; cpu_mem = 100; num_cpus = 32; max_train_steps = 5; checkpointing_steps = 2; report_to = 'tensorboard'\n",
    "    \n",
    "#####\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs = 1 # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "use_deepspeed = True\n",
    "deepspeed_config_file = 'ds_configs/stage3_no_offloading_accelerate.conf'\n",
    "\n",
    "per_device_train_batch_size = 1; total_batch_size = 32\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"{effective_batch_size} effective batch size.\")\n",
    "\n",
    "# reference: https://gist.github.com/pacman100/1cb1f17b2f1b3139a63b764263e70b25\n",
    "launcher = f\"\"\"accelerate launch \\\n",
    "    --mixed_precision {mixed_precision} \\\n",
    "    --num_machines {nodes} \\\n",
    "    --num_processes {num_gpus*nodes} \\\n",
    "    {'--use_deepspeed' if use_deepspeed else ''} \\\n",
    "    {'--deepspeed_config_file '+deepspeed_config_file if use_deepspeed else ''} \\\n",
    "    {'--main_process_ip $master_addr' if use_deepspeed else ''} \\\n",
    "    {'--main_process_port $master_port' if use_deepspeed else ''} \\\n",
    "    {'--machine_rank $SLURM_PROCID' if use_deepspeed else ''} \\\n",
    "    {'--rdzv_backend c10d' if use_deepspeed and nodes>1 else ''} \\\n",
    "    {'--deepspeed_multinode_launcher standard' if use_deepspeed and nodes>1 else ''} \\\n",
    "\"\"\"\n",
    "\n",
    "cmds = []\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    subsample_inds_file_list,\n",
    ")\n",
    "\n",
    "output_dirname_list = []\n",
    "for (subsample_inds_file,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{dataset}\"\n",
    "    if any(job_name == y for y in ['dpo1']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "\n",
    "    if subsample_inds_file:\n",
    "        assert(num_train_epochs==1)\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                s = f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "\n",
    "    if subsample_inds_file is not None:\n",
    "        assert(dataloader_sampler=='SequentialSampler')\n",
    "        assert(num_train_epochs==1)\n",
    "    else:\n",
    "        assert(dataloader_sampler=='RandomSampler')\n",
    "\n",
    "    output_dir = os.path.join('results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join('results', job_name), exist_ok=True)\n",
    "    wandb_run_name = output_dir.replace('results/', '')\n",
    "\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {f'cd .. && CUDA_VISIBLE_DEVICES={os.environ[\"CUDA_VISIBLE_DEVICES\"]} ' if test_run else ''}{launcher}\n",
    "        open_instruct/dpo_tune.py \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --tokenizer_name {model_name_or_path} \\\n",
    "        {'--use_slow_tokenizer' if not  use_fast_tokenizer else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        --train_file {train_file} \\\n",
    "        --max_seq_length {max_seq_length} \\\n",
    "        {'--subsample_inds_file '+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        --dataloader_sampler {dataloader_sampler} \\\n",
    "        --preprocessing_num_workers {preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size {per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
    "        --learning_rate 5e-7 \\\n",
    "        --lr_scheduler_type linear \\\n",
    "        --warmup_ratio 0.1 \\\n",
    "        --weight_decay 0. \\\n",
    "        --num_train_epochs {num_train_epochs} \\\n",
    "        --with_tracking \\\n",
    "        {'--report_to \"'+str(report_to)+'\"' if report_to else ''} \\\n",
    "        --checkpointing_steps {checkpointing_steps} \\\n",
    "        {'--max_train_steps '+str(max_train_steps) if max_train_steps else ''} \\\n",
    "        {'--resume_from_checkpoint' if resume_from_checkpoint else ''} \\\n",
    "        {'--low_cpu_mem_usage' if not use_deepspeed else ''} \\\n",
    "        {'--overwrite_cache' if overwrite_cache else ''} \\\n",
    "        --logging_steps 1 \\\n",
    "        --output_dir {output_dir}\n",
    "    \"\"\"\n",
    "    # if test_run:\n",
    "    #     print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    if test_run:\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64': # ccc\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "        queue=queue,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda1f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prune: {1k@10, 10k@3}, datasets={dolly, stanford_alpaca}, scoring={random, dppmapx2}\n",
    "# need to gen curriculum for 50k sft datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b79b9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_dpo.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce604bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=5\n",
      "+ cd ..\n",
      "+ CUDA_VISIBLE_DEVICES=2,5\n",
      "+ accelerate launch --mixed_precision fp16 --num_machines 1 --num_processes 2 --use_deepspeed --deepspeed_config_file ds_configs/stage3_no_offloading_accelerate.conf open_instruct/dpo_tune.py --model_name_or_path results/baselines/huggyllama/llama-7b --tokenizer_name results/baselines/huggyllama/llama-7b --gradient_checkpointing --train_file data/processed/ultrafeedback/ultrafeedback_data.jsonl --max_seq_length 2048 --preprocessing_num_workers 32 --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --learning_rate 5e-7 --lr_scheduler_type linear --warmup_ratio 0.1 --weight_decay 0. --num_train_epochs 2 --with_tracking --report_to tensorboard --checkpointing_steps 500 --logging_steps 1 --output_dir results/dpo1/jpt_llama-7b_ultrafeedback\n",
      "[2024-01-08 20:41:08,547] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "[2024-01-08 20:41:17,396] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-08 20:41:17,400] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:662:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,611] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 1\n",
      "Local process index: 1\n",
      "Device: cuda:1\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 251.17it/s]\n",
      "01/08/2024 20:41:25 - WARNING - datasets.builder - Found cached dataset json (/gpfs/u/scratch/PTFM/PTFMqngp/huggingface_cache/datasets/json/default-201ebfceee303348/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 252.78it/s]\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:26,493] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 6.74B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.74s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:16<00:00,  8.11s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:43,556] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 13.48B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.60s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "01/08/2024 20:42:20 - INFO - accelerate.accelerator - Updating DeepSpeed's gradient accumulation steps to 16 from 1.\n",
      "[2024-01-08 20:42:20,382] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.1+23a11a39, git-hash=23a11a39, git-branch=master\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 1\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "[2024-01-08 20:42:20,751] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n",
      "[2024-01-08 20:42:20,779] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\n",
      "[2024-01-08 20:42:20,891] [INFO] [utils.py:786:see_memory_usage] Stage 3 initialize beginning\n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 14.16 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.9 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:118:__init__] Reduce bucket size 16777216\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:119:__init__] Prefetch bucket size 15099494\n",
      "[2024-01-08 20:42:20,995] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 13.64 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n",
      "[2024-01-08 20:42:21,139] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.76 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:21,240] [INFO] [utils.py:786:see_memory_usage] Before creating fp16 partitions\n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.4 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:23,090] [INFO] [utils.py:786:see_memory_usage] After creating fp16 partitions: 4\n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.4 GB         CA 14.6 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.99 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,190] [INFO] [utils.py:786:see_memory_usage] Before creating fp32 partitions\n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.39 GB         CA 14.6 GB         Max_CA 15 GB \n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.81 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,742] [INFO] [utils.py:786:see_memory_usage] After creating fp32 partitions\n",
      "[2024-01-08 20:42:23,743] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 26.61 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,744] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 116.15 GB, percent = 16.7%\n",
      "[2024-01-08 20:42:23,836] [INFO] [utils.py:786:see_memory_usage] Before initializing optimizer states\n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 25.94 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 117.28 GB, percent = 16.8%\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 1; 31.75 GiB total capacity; 25.93 GiB already allocated; 3.34 GiB free; 27.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 0; 31.75 GiB total capacity; 25.94 GiB already allocated; 3.21 GiB free; 27.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 409110) of binary: /gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/python3.10\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 964, in launch_command\r\n",
      "    deepspeed_launcher(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 687, in deepspeed_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "open_instruct/dpo_tune.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 409111)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 409110)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_dpo.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c8b",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune_trainer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "19aebd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=10_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/baselines/huggyllama/llama-7b using 4 GPUs, 1 batch size per GPU, 32 gradient accumulation steps, Effective batch size 128\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_ultrachat50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 64,\n",
      "    \"cpu_mem\": 384,\n",
      "    \"num_gpus\": 4,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_ultrachat50k:llama-7b -mem 384g -cores 1x64+4 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/ultrachat/ultrachat50k_train_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=32 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=90000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/ultrachat50k/random_s=0/inds_prune_size=90000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=90000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=90000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1431089}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_ultrachat50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 64,\n",
      "    \"cpu_mem\": 384,\n",
      "    \"num_gpus\": 4,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_ultrachat50k:llama-7b -mem 384g -cores 1x64+4 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/ultrachat/ultrachat50k_train_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=32 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/ultrachat50k/dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB/inds_prune_size=90000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1431090}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_ultrachat50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 64,\n",
      "    \"cpu_mem\": 384,\n",
      "    \"num_gpus\": 4,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_ultrachat50k:llama-7b -mem 384g -cores 1x64+4 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/ultrachat/ultrachat50k_train_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=32 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/ultrachat50k/dppmap_k=vmf_gamma=10_kmd=llama7br512p4096_kemb=text+embedding/inds_prune_size=90000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1431091}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "add_hardwarespec_to_dirname = False\n",
    "save_strategy = 'steps'\n",
    "save_steps = 200 if getpass.getuser() in ('PTFMqngp', 'wpq') else 1_000_000\n",
    "save_total_limit = 1\n",
    "preprocessing_num_workers = 32\n",
    "evaluation_strategy = 'no' # set do_eval=False\n",
    "eval_steps = save_steps\n",
    "report_to = 'tensorboard wandb'\n",
    "suffix = None\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0.03\n",
    "dataloader_sampler = None\n",
    "hf_models_dir = 'results/baselines/'\n",
    "subsample_inds_file_list = [None]\n",
    "max_train_samples_list = [None]\n",
    "num_train_epochs_list = [1]\n",
    "scoring_fn_and_pacing_fn = None\n",
    "\n",
    "\n",
    "# ########### sft baselines\n",
    "\n",
    "\n",
    "# job_name = 'oi2'; num_train_epochs_list = [3]\n",
    "# # model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "\n",
    "# # train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca'; \n",
    "# # train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# # train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2'; max_train_samples_list=[100_000]\n",
    "\n",
    "# ## 50k sft datasets\n",
    "# # train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# # train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# # train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "# # train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "\n",
    "# # train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2'; max_train_samples_list=[100_000]\n",
    "# ###########\n",
    "\n",
    "\n",
    "############ pruning runs\n",
    "\n",
    "# model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048; gen_output_md = 'mistral7br512p4096'\n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048; gen_output_md = 'llama7br512p4096'\n",
    "\n",
    "\n",
    "# # 50k sft datasets\n",
    "# dataset = 'flan_v250k'; train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca50k'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# dataset = 'wizardlm50k'; train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "dataset = 'sharegpt50k'; train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "dataset = 'ultrachat50k'; train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "\n",
    "# dataset = 'flan_v2'; train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca';\n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# dataset = 'wizardlmv2'; train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2';\n",
    "# dataset = 'sharegptv2'; train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2';\n",
    "# dataset = 'ultrachat200kv2'; train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2';\n",
    "\n",
    "\n",
    "# dataset = 'oasst1'; train_file = 'data/processed/oasst/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# dataset = 'open_orca_slim'; train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; \n",
    "# dataset = 'tulu_v2'; train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2';\n",
    "        \n",
    "# M = 80_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 40_000\n",
    "# M = 40_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 20_000\n",
    "# M = 30_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [\n",
    "    f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "#         (10_000, 10), # -> 1k, 2%\n",
    "#         (30_000, 3),  # -> 10k, 20%\n",
    "#         (60_000, 3),  # -> 20k, 40%\n",
    "        (90_000, 3),  # -> 30k, 60%\n",
    "#         (120_000, 3),  # -> 40k, 80%\n",
    "    ]\n",
    "]\n",
    "#         + [running] 10k prune size. 4 datasets, compare {vmf,rbf} x {text,grad}\n",
    "\n",
    "\n",
    "        \n",
    "kmd = 'llama7br512p4096'\n",
    "scoring_fn_list = [\n",
    "    'random_s=0',\n",
    "#     'random_s=1',\n",
    "#     'log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n',\n",
    "#     'ifd_neg', 'log_pmi_neg',\n",
    "#     'numtoks_input_neg', 'numtoks_output_neg', 'numtoks_total_neg',\n",
    "#     f'dppmap_k=vmf_gamma=1_kmd=mpnet', #_kemb=text+embedding',\n",
    "    ##\n",
    "#     f'dppmap_k=rbf_gamma=1e-3_kmd={kmd}_kemb=text+embedding',\n",
    "    f'dppmap_k=vmf_gamma=1_kmd={kmd}_kemb=grad+rp+loraB',\n",
    "    # added baseline\n",
    "    f'dppmap_k=vmf_gamma=10_kmd={kmd}_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1e-2_kmd={kmd}_kemb=grad+rp+loraB',\n",
    "]\n",
    "\n",
    "scoring_fn_list += [ # vary kernel embedding model \n",
    "#     f'dppmap_k=vmf_gamma=auto{subset_size}_kmd={kmd}_kemb=grad+rp+loraB'\n",
    "#     for kmd in ['llama7br256p4096', 'llama7br512p4096', 'pythia1br512p4096']\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'oi5_{dataset}:{abbr_model_name}'\n",
    "############ \n",
    "\n",
    "\n",
    "    \n",
    "# add_hardwarespec_to_dirname = True\n",
    "# job_name += '_debug' # wpq debug\n",
    "# max_train_samples_list=[128*2]\n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "test_run = 0\n",
    "test_run = bool(test_run)\n",
    "debug_mode = test_run\n",
    "\n",
    "if arch == 'x86_64':\n",
    "#     nodes = 1; num_gpus = 8; gpu_type = 'a100_80gb'; job_duration = 6\n",
    "    nodes = 1; num_gpus = 4; gpu_type = 'a100_80gb'; job_duration = 6 \n",
    "    num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus); preprocessing_num_workers = 128 # tok takes quite a bit.\n",
    "    per_device_train_batch_size = 1\n",
    "    gradient_checkpointing = False\n",
    "    mixed_precision = 'bf16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = True \n",
    "    save_model_torch_dtype = 'bfloat16' # typically save fp32 weights, but for disk space sake, convert to bf16.\n",
    "else:\n",
    "    nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_checkpointing = True\n",
    "    mixed_precision = 'fp16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = False\n",
    "    save_model_torch_dtype = None\n",
    "\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs_list = [1] # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "overwrite_output_dir = True if test_run else False # always continue from ckpt if run from cluster.\n",
    "\n",
    "total_batch_size = 128\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "optimizer = 'adamw_hf'\n",
    "\n",
    "deepspeed = ''; fsdp = False if num_gpus == 1 else \"full_shard auto_wrap\" \n",
    "if 'gpt2' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPT2Block'\n",
    "elif 'llama' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'LlamaDecoderLayer'\n",
    "elif 'mpt' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MPTBlock'\n",
    "elif 'pythia' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPTNeoXLayer'        \n",
    "elif 'mistral' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MistralDecoderLayer'\n",
    "else: raise ValueError('Not sure how to set `fsdp_transformer_layer_cls_to_wrap`')\n",
    "    \n",
    "# deepspeed = './ds_configs/ds_zero3_cpu_offload.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/ds_zero3.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/stage3_no_offloading.conf'; fsdp = False # error with loading... something wrong with the config.\n",
    "# fsdp = False; deepspeed = False\n",
    "\n",
    "if fsdp and deepspeed:\n",
    "    raise ValueError('either fsdp or deepspeed, not both')\n",
    "\n",
    "use_lora = False\n",
    "lora_rank = 256 \n",
    "lora_alpha = lora_rank \n",
    "lora_dropout = 0.05\n",
    "if use_lora:\n",
    "    abbr_model_name += f'+lora(r={lora_rank},a={lora_alpha})'\n",
    "load_in_8bit = False\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"Effective batch size {effective_batch_size}\")\n",
    "\n",
    "\n",
    "if nodes == 1:\n",
    "    exe = 'python' if num_gpus==1 else \\\n",
    "        f\"torchrun --nnodes 1 --nproc_per_node={num_gpus} --rdzv_backend=c10d --rdzv_endpoint=localhost:0\" # assigns random port. https://github.com/pytorch/pytorch/issues/73320\n",
    "else:\n",
    "    exe = f\"torchrun --nnodes={nodes} --nproc_per_node={num_gpus} --rdzv-id=${'SLURM_JOB_ID' if arch == 'ppcle64' else 'LSB_JOBID'} --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT\"\n",
    "\n",
    "if test_run:\n",
    "    exe = f\"CUDA_VISIBLE_DEVICES={','.join(map(str, range(num_gpus)))} {exe}\"\n",
    "if test_run and debug_mode:\n",
    "    exe = 'TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO ' + exe\n",
    "    error_file = os.path.join(open_instruct_dir, 'scripts', 'error_file')\n",
    "    exe = f'TORCHELASTIC_ERROR_FILE={error_file} {exe}'\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "options_list = itertools.product(\n",
    "    num_train_epochs_list,\n",
    "    subsample_inds_file_list,\n",
    "    max_train_samples_list,\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "output_dirname_list = []\n",
    "for (num_train_epochs,\n",
    "     subsample_inds_file,\n",
    "     max_train_samples,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{abbr_train_file}\"\n",
    "    if max_train_samples:\n",
    "        output_dirname += f\":{int(max_train_samples/1000)}k\"\n",
    "            \n",
    "    if any(job_name == y for y in ['oi2']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "        \n",
    "    if subsample_inds_file:\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                return f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            else:\n",
    "                return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "            \n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "            \n",
    "    if add_hardwarespec_to_dirname:\n",
    "        output_dirname += \\\n",
    "            ('_fsdp='+fsdp.split(' ')[0] if fsdp else '')+\\\n",
    "            ('_deepspeed='+os.path.basename(deepspeed).split('.')[0] if deepspeed else '')+\\\n",
    "            ('_gradckpt='+str(gradient_checkpointing) if gradient_checkpointing else '')+\\\n",
    "            '_mbsz='+str(per_device_train_batch_size)+\\\n",
    "            ('_dtype='+torch_dtype if torch_dtype is not None else '')+\\\n",
    "            ('_mp='+str(mixed_precision) if mixed_precision else '_mp=none')+\\\n",
    "            '_seqlen='+str(max_seq_length)+\\\n",
    "            '_nodes='+str(nodes)+\\\n",
    "            '_ngpus='+str(num_gpus)+\\\n",
    "            ('_fa2' if use_flash_attn else '')\n",
    "    if suffix:\n",
    "        output_dirname += suffix\n",
    "    output_dir = os.path.join(open_instruct_dir, 'results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join(open_instruct_dir, 'results', job_name), exist_ok=True)\n",
    "    if arch == 'x86_64':\n",
    "        wandb_run_name = 'ccc'+output_dir[output_dir.find('results'):][7:] # e.g., ccc/oi2/run_name\n",
    "    else:\n",
    "        wandb_run_name = output_dir.replace('results/', '') # e.g., oi2/run_name\n",
    "    \n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {'cd .. && ' if test_run else ''}{exe}\n",
    "        open_instruct/finetune_trainer.py \\\n",
    "        --model_name_or_path={model_name_or_path} \\\n",
    "        --tokenizer_name={model_name_or_path} \\\n",
    "        {'--load_in_8bit' if load_in_8bit else ''} \\\n",
    "        --use_fast_tokenizer=True \\\n",
    "        --train_file={train_file} \\\n",
    "        --max_seq_length={max_seq_length} \\\n",
    "        {'--max_train_samples='+str(max_train_samples) if max_train_samples else ''} \\\n",
    "        {'--use_lora' if use_lora else ''} \\\n",
    "        {'--lora_rank='+str(lora_rank) if use_lora else ''} \\\n",
    "        {'--lora_alpha='+str(lora_alpha) if use_lora else ''} \\\n",
    "        {'--lora_dropout='+str(lora_dropout) if use_lora else ''} \\\n",
    "        --do_train \\\n",
    "        --preprocessing_num_workers={preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size={per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
    "        --learning_rate=2e-5 \\\n",
    "        --lr_scheduler_type={lr_scheduler_type} \\\n",
    "        --warmup_ratio={warmup_ratio} \\\n",
    "        --weight_decay=0. \\\n",
    "        --optim={optimizer} \\\n",
    "        --evaluation_strategy={evaluation_strategy} \\\n",
    "        {'--eval_steps='+str(eval_steps) if eval_steps else ''} \\\n",
    "        {'--report_to '+str(report_to) if report_to else ''} \\\n",
    "        --run_name {wandb_run_name} \\\n",
    "        --logging_strategy=steps \\\n",
    "        --logging_first_step \\\n",
    "        --logging_steps=1 \\\n",
    "        --save_strategy={save_strategy} \\\n",
    "        --save_steps={save_steps} \\\n",
    "        --save_total_limit={save_total_limit} \\\n",
    "        --num_train_epochs={num_train_epochs} \\\n",
    "        --ddp_timeout=7200 \\\n",
    "        {'--fsdp=\"'+fsdp+'\"' if fsdp else ''} \\\n",
    "        {'--fsdp_transformer_layer_cls_to_wrap=\"'+fsdp_transformer_layer_cls_to_wrap+'\"' \n",
    "            if fsdp else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        {'--torch_dtype='+str(torch_dtype) if torch_dtype else ''} \\\n",
    "        {'--save_model_torch_dtype='+str(save_model_torch_dtype) if save_model_torch_dtype else ''} \\\n",
    "        --dataloader_num_workers=8 \\\n",
    "        {f'--{mixed_precision}=True' if mixed_precision else ''} \\\n",
    "        {f'--tf32=True' if use_tf32 else ''} \\\n",
    "        {'--overwrite_output_dir' if overwrite_output_dir else ''} \\\n",
    "        {'--deepspeed='+deepspeed if deepspeed else ''} \\\n",
    "        {'--subsample_inds_file='+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        {'--dataloader_sampler '+str(dataloader_sampler) if dataloader_sampler else ''} \\\n",
    "        --use_flash_attn {'True' if use_flash_attn else 'False'} \\\n",
    "        --low_cpu_mem_usage \\\n",
    "        --overwrite_cache \\\n",
    "        --output_dir=\"{output_dir}\" \\\n",
    "    \"\"\" \n",
    "    #  --overwrite_cache   # if delete a dataset and need to refresh cache\n",
    "\n",
    "    if test_run:\n",
    "        print()\n",
    "        print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64':\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        queue=queue,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12fc2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_sft.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed0c2894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ cd ..\n",
      "+ TORCHELASTIC_ERROR_FILE=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/error_file\n",
      "+ TORCH_CPP_LOG_LEVEL=INFO\n",
      "+ NCCL_DEBUG=INFO\n",
      "+ LOGLEVEL=INFO\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/oasst1/oasst1_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=32 --per_device_train_batch_size=1 --gradient_accumulation_steps=128 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=200 --report_to tensorboard wandb --run_name /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=200 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --overwrite_output_dir --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl --dataloader_sampler SequentialSampler --use_flash_attn True --low_cpu_mem_usage --overwrite_cache --output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10\n",
      "[2024-01-19 02:04:37,834] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Saving args dict to /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10.args.json\n",
      "01/19/2024 02:04:39 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "01/19/2024 02:04:39 - INFO - __main__ - Training parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=8,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_sampler=SequentialSampler,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=7200,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=200.0,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=128,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10/runs/Jan19_02-04-39_cccxc552,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1.0,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard', 'wandb'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=True,\n",
      "save_steps=200,\n",
      "save_strategy=steps,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=True,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "Using custom data configuration default-b03eccd42e843020\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Using custom data configuration default-b03eccd42e843020\n",
      "Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "[INFO|configuration_utils.py:715] 2024-01-19 02:04:39,135 >> loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "[INFO|configuration_utils.py:777] 2024-01-19 02:04:39,136 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3118] 2024-01-19 02:04:39,229 >> loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1222] 2024-01-19 02:04:39,229 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[WARNING|modeling_utils.py:1304] 2024-01-19 02:04:39,230 >> You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:39,230 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.07it/s]\n",
      "[INFO|modeling_utils.py:3950] 2024-01-19 02:04:41,778 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:3958] 2024-01-19 02:04:41,778 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:749] 2024-01-19 02:04:41,781 >> loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:41,781 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "01/19/2024 02:04:41 - INFO - __main__ - [wpq] model.dtype=torch.bfloat16\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1648] 2024-01-19 02:04:41,845 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spawning 32 processes\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Spawning 32 processes\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 0/33717 [00:Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 22/33717 [00Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   1%| | 361/33717 [0Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):   3%| | 1001/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   5%| | 1719/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   7%| | 2251/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):  12%| | 4021/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  14%|▏| 4841/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  18%|▏| 5957/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32): 100%|█| 33717/33717 \n",
      "Concatenating 32 shards\n",
      "01/19/2024 02:04:55 - INFO - datasets.arrow_dataset - Concatenating 32 shards\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - __main__ - Subsample dataset according to indices: /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl\n",
      "01/19/2024 02:04:56 - INFO - __main__ - subsample_inds_file has 10000 indices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[wpq] Example 0 of train_dataset: \r\n",
      "{'dataset': 'oasst1', 'id': 'oasst1_20480', 'messages': [{'role': 'user', 'content': 'Cómo manejar un carro manual'}, {'role': 'assistant', 'content': 'Lo primero que tienes que hacer, si nunca has conducido un coche manual, es familiarizarte con el embrague y palanca de cambios. Si conduces habitualmente un coche automático, estarás acostumbrado a no utilizar para nada el pie izquierdo ni la palanca del cambio. Encontrarás tres pedales, siendo el embrague el que está situado a la izquierda y el que tendrás que pisar cada vez que cambies de marcha. Por otro lado, la palanca del cambio se ubica siempre en la consola central.\\n\\nPara arrancar un coche manual, es necesario seguir una serie de pasos que, al principio, pueden parecer muchos, pero que, con el tiempo, acabarás haciéndolos sin darte cuenta:\\n\\n1) Comprueba que la palanca del cambio está en punto muerto\\n2) Coloca el pie derecho en el pedal del freno\\n3) Arranca el motor\\n4) Pisa el embrague con el pie izquierdo\\n5) Coloca la palanca del cambio en la primera marcha, sin levantar el pedal del freno\\n6) Suelta el freno de mano\\n7) Suelta el pedal del freno\\nYa estás listo para iniciar la marcha, soltando suavemente el embrague, a medida que aceleras.\\n\\nUna vez que ya estás en marcha, debes hacer un uso correcto del cambio manual para cambiar las marchas de forma correcta. Un uso incorrecto de la caja de cambios manual puede repercutir negativamente en tu seguridad y también afectar gravemente al embrague y a la transmisión, lo que se traduce en serias averías de coste muy elevado. Para evitarlo, te explicamos cómo debes proceder:\\n\\nUna vez que hayas arrancado, pisa el acelerador muy lentamente. Notarás que el régimen del motor aumenta. En ese momento, comienza a soltar suavemente el pedal del embrague. Verás que el motor vuelve a bajar de vueltas. En ese momento, puedes presionar un poco más el acelerador y el coche comenzará a avanzar.\\n\\nAhora llega el momento de meter la segunda marcha. Dependiendo del tipo de coche y combustible, podrás circular a un régimen de giro más bajo o alto. El régimen de giro en coche de gasolina, por lo general, oscila entre loas 2.500 y 3.000 vueltas. Si el motor está sobrealimentado por turbo, te permitirá circular por debajo de ese rango, ya que algunos coches turbos modernos entregan la totalidad de su par motor, incluso por debajo de las 2.000 vueltas.\\n\\nUn coche con motor turbodiésel te permite circular a un régimen muy bajo, por debajo de las 2.000 vueltas, ya que la entrega de par se produce antes que en un motor de gasolina.\\n\\nCuando el coche alcance un régimen de vueltas apropiado, suelta el pedal del acelerador y vuelve a pisar el embrague. Coge la palanca del cambio y baja para meter segunda. Suelta el embrague y presiona nuevamente el acelerador. A partir de aquí, cada vez que quieras cambiar de marcha, deberás repetir el mismo proceso: soltar el acelerador, pisar embrague, meter la marcha, soltar embrague y volver a acelerar.\\n\\n¡Buen viaje!'}], 'input_ids': tensor([    1,   529, 29989,  1792, 29989, 29958,    13, 29907, 29980,  4346,\r\n",
      "          767, 29872,  4758,   443,  1559,   307, 12219,    13, 29966, 29989,\r\n",
      "          465, 22137, 29989, 29958,    13,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'labels': tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:593] 2024-01-19 02:04:57,333 >> Using auto half precision backend\n",
      "[INFO|trainer.py:738] 2024-01-19 02:04:57,494 >> The following columns in the training set don't have a corresponding argument in `LlamaForCausalLM.forward` and have been ignored: messages, id, dataset. If messages, id, dataset are not expected by `LlamaForCausalLM.forward`,  you can safely ignore this message.\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1723] 2024-01-19 02:04:57,514 >> ***** Running training *****\n",
      "[INFO|trainer.py:1724] 2024-01-19 02:04:57,514 >>   Num examples = 10,000\n",
      "[INFO|trainer.py:1725] 2024-01-19 02:04:57,514 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1726] 2024-01-19 02:04:57,514 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:1729] 2024-01-19 02:04:57,514 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1730] 2024-01-19 02:04:57,514 >>   Gradient Accumulation steps = 128\n",
      "[INFO|trainer.py:1731] 2024-01-19 02:04:57,514 >>   Total optimization steps = 78\n",
      "[INFO|trainer.py:1732] 2024-01-19 02:04:57,515 >>   Number of trainable parameters = 6,738,423,808\n",
      "[INFO|integration_utils.py:718] 2024-01-19 02:04:57,519 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "  0%|                                                    | 0/78 [00:00<?, ?it/s][WARNING|logging.py:314] 2024-01-19 02:05:01,563 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,569 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,572 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,576 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,577 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 1.6425, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}         \n",
      "{'loss': 1.7168, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.03}        \n",
      "  3%|█▏                                          | 2/78 [00:42<26:54, 21.24s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash gen_cmds_sft.sh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:177\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:646\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGCONT)\n\u001b[0;32m--> 646\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_sft.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831fe55",
   "metadata": {},
   "source": [
    "# eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "499d6f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mmlu_s=0', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('humaneval', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('humaneval_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=0', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('humaneval', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('humaneval_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=5', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_cot', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('humaneval', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=5_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_cot_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('humaneval_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('humaneval', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('humaneval_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3')\n",
      "('mmlu_s=0', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=5', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_cot', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('humaneval', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=5_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_cot_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('humaneval_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('humaneval', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('humaneval_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "#cmds:  108 \n",
      "\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=0_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.mmlu_s=5_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.gsm_s=8_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.bbh_s=3_cot_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.humaneval_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_cb_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from gen_cmds_utils import remove_all_symlinks, create_unique_symlinks, get_chat_formatting_function, get_resource_for_task, OPENAI_MODEL_LIST\n",
    "\n",
    "\n",
    "create_symlinks = False\n",
    "include_checkpoints = False\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "use_slow_tokenizer = True\n",
    "launch_one_job_per_model = True\n",
    "\n",
    "task_names = [\n",
    "    'mmlu_s=0',\n",
    "    'mmlu_s=5', \n",
    "    'gsm_s=8',\n",
    "    'gsm_s=8_cot',\n",
    "    'bbh_s=3',\n",
    "    'bbh_s=3_cot', # max_datapoints_per_task=40 -> 40min.\n",
    "    'humaneval',\n",
    "    'tydiqa_s=1_cb', # 3min\n",
    "    'tydiqa_s=1_gp',\n",
    "    # 'toxigen', # ~1.5hr\n",
    "#     'alpacafarm_ann=gpt35:turbo:1106',\n",
    "    # 'alpacafarm_ann=chatgpt', # ~$1 per eval.\n",
    "]\n",
    "task_names_chatfmt = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "\n",
    "task_names_mtbench = ['mtbench_ann=gpt:4:1106:preview_chatfmt'] # ann=gpt:4, ann=gpt:3.5:turbo:1106, gpt:4:1106:preview (gpt4-turbo)\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:3.5:turbo:1106_chatfmt'] # for debug sake, prefer gpt4\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:4_chatfmt']\n",
    "# task_names_alpacafarm = ['alpacafarm_ann=chatgpt_chatfmt']\n",
    "task_names_alpacafarm = ['alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt']\n",
    "task_names_chateval = task_names_mtbench + task_names_alpacafarm\n",
    "\n",
    "\n",
    "# # ## baselines eval \n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "# #     'huggyllama/llama-7b', \n",
    "# #     'mistralai/Mistral-7B-v0.1',\n",
    "# #     'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "# #     'NousResearch/Llama-2-7b-hf',\n",
    "# #     'NousResearch/Llama-2-7b-chat-hf',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-beta',\n",
    "# #     'HuggingFaceH4/zephyr-7b-alpha',\n",
    "#     'HuggingFaceH4/zephyr-7b-beta',\n",
    "# #     'codellama/CodeLlama-7b-hf',\n",
    "# #     'codellama/CodeLlama-7b-Python-hf',\n",
    "# #     'codellama/CodeLlama-7b-Instruct-hf',\n",
    "# ]]\n",
    "# # task_names = task_names + task_names_chatfmt\n",
    "# task_names = task_names_mtbench\n",
    "\n",
    "# # oi5\n",
    "# exp_dir = 'results/oi2'\n",
    "# exp_dir = 'results/oi5_flan_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_dolly:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlm50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegpt50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b_debug'\n",
    "# exp_dir = 'results/oi5_stanford_alpaca:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlmv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegptv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_ultrachat200kv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_tulu_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_open_orca_slim:llama-7b'\n",
    "# exp_dir = 'results/dpo1'\n",
    "# exp_dir = 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2'\n",
    "exp_dirs = [\n",
    "    'results/baselines/huggyllama',\n",
    "    'results/oi2',\n",
    "    'results/oi5_dolly:llama-7b',\n",
    "    'results/oi5_flan_v250k:llama-7b',\n",
    "    'results/oi5_stanford_alpaca50k:llama-7b',\n",
    "    'results/oi5_oasst2:llama-7b',\n",
    "    'results/oi5_wizardlm50k:llama-7b',\n",
    "    'results/oi5_sharegpt50k:llama-7b',\n",
    "    'results/oi5_ultrachat50k:llama-7b',\n",
    "]\n",
    "exp_dirs = [\n",
    "    'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2',\n",
    "]\n",
    "\n",
    "# subdir_filter_fn = lambda x: 'ultrachat' in x\n",
    "task_names = task_names + task_names_chatfmt;\n",
    "# task_names = ['mtbench_ann=gpt:4_chatfmt'] \n",
    "# task_names = task_names_alpacafarm; \n",
    "# task_names = task_names_mtbench\n",
    "# task_names = task_names + task_names_chatfmt + task_names_mtbench\n",
    "# task_names = task_names\n",
    "# task_names = ['alpacafarm_ann=gpt35:turbo:1106_chatfmt']\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "num_gpus = 1\n",
    "if arch == 'x86_64': # ccc\n",
    "    gpu_type = 'a100_80gb'; num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus)\n",
    "    use_vllm = True; torch_dtype = 'bfloat16'\n",
    "else:\n",
    "    gpu_type = 'v100'\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    use_vllm = False; torch_dtype = 'float16'\n",
    "    \n",
    "    \n",
    "if len(subdir_path_list)==0:\n",
    "    subdir_path_list = []\n",
    "    for exp_dir in exp_dirs:\n",
    "        if create_symlinks:\n",
    "            remove_all_symlinks(exp_dir)\n",
    "        subdirs = list(os.listdir(exp_dir))\n",
    "        subdirs = filter(subdir_filter_fn, subdirs)\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(exp_dir, subdir)\n",
    "            if include_checkpoints:\n",
    "                subdir_path_list += glob.glob(os.path.join(subdir_path, 'checkpoint-*'))\n",
    "            if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "                continue\n",
    "            subdir_path_list.append(subdir_path)\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not os.path.islink(subdir_path) and \\\n",
    "                not os.path.isfile(os.path.join(subdir_path, 'eval', task_name, 'metrics.json')):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "                print((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "\n",
    "print('#cmds: ', len(list(task_name_and_model)), '\\n')\n",
    "\n",
    "if create_symlinks:\n",
    "    # create symlink for each directory.\n",
    "    symlink_path_dict = create_unique_symlinks(\n",
    "        list([x[1] for x in task_name_and_model]))\n",
    "    options_list = list(map(lambda x: (x[0], symlink_path_dict[x[1]]), task_name_and_model))\n",
    "else:\n",
    "    options_list = task_name_and_model\n",
    "    \n",
    "    \n",
    "dfo = pd.DataFrame(options_list, columns=['task_name', 'model_name_or_path'])\n",
    "model_and_task_list = dfo.groupby('model_name_or_path')['task_name'].agg(list).to_dict()\n",
    "\n",
    "\n",
    "info = {}  \n",
    "cmds = []\n",
    "for model_name_or_path, task_name_list in model_and_task_list.items():\n",
    "    num_tasks = len(task_name_list)\n",
    "    cmds_per_model = []\n",
    "    for i, task_name in enumerate(task_name_list):\n",
    "        queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else \\\n",
    "            ('alt_7d' if task_name.startswith('mtbench') else 'alt_1h')\n",
    "\n",
    "        use_chat_format = 'chatfmt' in task_name\n",
    "        chat_formatting_function = get_chat_formatting_function(model_name_or_path)\n",
    "\n",
    "        try:\n",
    "            with open(os.path.join(model_name_or_path, 'ft_args.json'), 'r') as f:\n",
    "                ft_args = json.load(f)\n",
    "            # note `model_name_or_path` could be anything, e.g., soft links with arbitrary names.\n",
    "            # but `ft_args_model_name_or_path` indicates the finetuned model name.\n",
    "            if 'model_args' in ft_args:\n",
    "                ft_args_model_name_or_path = ft_args['model_args']['model_name_or_path']\n",
    "            else:\n",
    "                ft_args_model_name_or_path = ft_args['model_name_or_path']\n",
    "        except:\n",
    "            ft_args_model_name_or_path = model_name_or_path\n",
    "\n",
    "        batch_size, job_duration = get_resource_for_task(\n",
    "            task_name, ft_args_model_name_or_path)\n",
    "\n",
    "        job_name = f'eval.{task_name}'\n",
    "        save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "\n",
    "        if task_name.startswith('mmlu'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 5)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.mmlu.run_eval \\\n",
    "                --data_dir data/eval/mmlu \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --ntrain {n_shot} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('gsm'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 8)\n",
    "            # open-instruct used 200 examples. use higher amount to get a more accurate number\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.gsm.run_eval \\\n",
    "                --data_dir data/eval/gsm/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_num_examples 500 \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('bbh'):\n",
    "            max_num_examples_per_task = 40\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 3)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.bbh.run_eval \\\n",
    "                --data_dir data/eval/bbh/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                --n_shot {n_shot} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--max_num_examples_per_task '+str(max_num_examples_per_task) if max_num_examples_per_task else ''} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('humaneval'):\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.codex_humaneval.run_eval \\\n",
    "                --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens 512 \\\n",
    "                --eval_pass_at_ks 1 \\\n",
    "                --unbiased_sampling_size_n 3 \\\n",
    "                --temperature 0.1 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('tydiqa'):\n",
    "            no_context = 'cb' in task_name\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot in [0,1])\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.tydiqa.run_eval \\\n",
    "                --data_dir data/eval/tydiqa \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_num_examples_per_lang 100 \\\n",
    "                --max_context_length 512 \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_context' if no_context else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('toxigen'):\n",
    "            # max_prompts_per_group=500 (out of 1000) is open-instruct default.\n",
    "            # eval batch size=1 much faster (llama-7b) not sure why.\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.toxigen.run_eval \\\n",
    "                --data_dir data/eval/toxigen \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size 1 \\\n",
    "                --max_prompts_per_group 200 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('alpacafarm'):\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            annotators_config = match.group(1)\n",
    "            annotators_config = annotators_config.replace(':', '_')\n",
    "            if not annotators_config in ['chatgpt', 'alpaca_eval_gpt4_0314', 'gpt35_turbo_1106', 'alpaca_eval_gpt4_turbo_fn']:\n",
    "                raise ValueError('Just support 2 annotators_config.')\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.alpaca_farm.run_eval \\\n",
    "                --reference_path alpaca_eval_data \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --max_new_tokens 2048 \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --annotators_config {annotators_config} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('mtbench'):\n",
    "            assert('chatfmt' in task_name)\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            judge_model = match.group(1).replace(':', '-')\n",
    "            if not judge_model in OPENAI_MODEL_LIST:\n",
    "                raise ValueError('fastchat does not support the judge model.')\n",
    "            os.makedirs(save_dir, exist_ok=True) # since not using python file, make the directory now.\n",
    "            fastchat_mtbench_data_dir = os.path.normpath(os.path.join(open_instruct_dir, '../FastChat/fastchat/llm_judge/data'))\n",
    "            question_file = os.path.join(fastchat_mtbench_data_dir, 'mt_bench/question.jsonl')\n",
    "            rating_file = os.path.join(save_dir, f'{judge_model}_single.jsonl')\n",
    "            question_begin, question_end = (0, 1) if False else (None, None)\n",
    "            model_id = os.path.basename(model_name_or_path) if 'results/baselines' in save_dir else 'tulu'\n",
    "            cmd = \"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_model_answer \\\n",
    "                    --model-path {model_name_or_path} \\\n",
    "                    --model-id {model_id} \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --question-file {question_file} \\\n",
    "                    {'--question-begin '+str(question_begin) if question_begin else ''} \\\n",
    "                    {'--question-end '+str(question_end) if question_end else ''} \\\n",
    "                    --max-new-token 2048 \\\n",
    "                    --answer-file {os.path.join(save_dir, 'model_answer.jsonl')} \\\n",
    "                    --dtype {torch_dtype} \\\n",
    "                && \\\n",
    "            \"\"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_judgment \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --judge-file {os.path.join(fastchat_mtbench_data_dir, 'judge_prompts.jsonl')} \\\n",
    "                    --judge-model {judge_model} \\\n",
    "                    --mode single \\\n",
    "                    --question-file {question_file} \\\n",
    "                    --answer-dir {save_dir} \\\n",
    "                    --ref-answer-dir {os.path.join(fastchat_mtbench_data_dir, 'mt_bench/reference_answer')} \\\n",
    "                    --output-file {rating_file} \\\n",
    "                && \\\n",
    "                python -m fastchat.llm_judge.show_result \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --input-file {rating_file} \\\n",
    "                    --mode single \\\n",
    "                    --save-to-json\n",
    "            \"\"\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'{task_name} not supported.')\n",
    "            \n",
    "        if task_name.startswith('alpacafarm') and (getpass.getuser() not in ('PTFMqngp', 'wpq')):\n",
    "            queue = 'alt_6h'\n",
    "\n",
    "        if test_run:\n",
    "            print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd.strip())]))\n",
    "\n",
    "        cmd = multiline_to_singleline(cmd)\n",
    "        cmds.append(cmd)\n",
    "        cmds_per_model.append(cmd)\n",
    "        \n",
    "        if launch_one_job_per_model:\n",
    "            shell_scripts = shell_scripts_template.format(\n",
    "                conda_env='open-instruct',\n",
    "                cwd=os.path.dirname(os.getcwd()),\n",
    "                cmd=cmd,\n",
    "                log_dir=os.getcwd(),\n",
    "                save_dir=save_dir,\n",
    "            )\n",
    "            if arch == 'x86_64': # ccc\n",
    "                shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "            out = submit_job(\n",
    "                shell_scripts, \n",
    "                job_name=job_name,\n",
    "                num_cpus=num_cpus,\n",
    "                cpu_mem=cpu_mem,\n",
    "                num_gpus=num_gpus,\n",
    "                gpu_type=gpu_type,\n",
    "                test_run=test_run,\n",
    "                job_duration=job_duration,\n",
    "                queue=queue,\n",
    "            )\n",
    "        else:\n",
    "            if i + 1 == num_tasks:\n",
    "                assert(len(cmds_per_model) == num_tasks)\n",
    "                cmd = ' && '.join(cmds_per_model)\n",
    "                if test_run:\n",
    "                    print(cmd)\n",
    "                shell_scripts = shell_scripts_template.format(\n",
    "                    conda_env='open-instruct',\n",
    "                    cwd=os.path.dirname(os.getcwd()),\n",
    "                    cmd=cmd,\n",
    "                    log_dir=os.getcwd(),\n",
    "                    save_dir=os.getcwd(), # just delete afterwards.\n",
    "                )\n",
    "                if arch == 'x86_64': # ccc\n",
    "                    shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "                out = submit_job(\n",
    "                    shell_scripts, \n",
    "                    job_name=f'eval.{os.path.basename(model_name_or_path)}',\n",
    "                    num_cpus=num_cpus,\n",
    "                    cpu_mem=cpu_mem,\n",
    "                    num_gpus=num_gpus,\n",
    "                    gpu_type=gpu_type,\n",
    "                    test_run=test_run,\n",
    "                    job_duration=6,\n",
    "                    queue=None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_6b',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ea7ac978",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_eval.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b3939309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10 --max_new_tokens 2048 --save_dir results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt --eval_batch_size 10 --annotators_config alpaca_eval_gpt4_turbo_fn --use_vllm --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype bfloat16\n",
      "[2024-01-21 21:11:36,716] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:loading data and model...\n",
      "INFO 01-21 21:11:39 llm_engine.py:73] Initializing an LLM engine with config: model='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10', tokenizer='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO 01-21 21:11:39 tokenizer.py:32] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "MegaBlocks not found. Please install it by `pip install megablocks`. Note that MegaBlocks depends on mosaicml-turbo, which only supports Python 3.10 for now.\n",
      "STK not found: please see https://github.com/stanford-futuredata/stk\n",
      "INFO 01-21 21:11:53 llm_engine.py:222] # GPU blocks: 7451, # CPU blocks: 512\n",
      "Processed prompts: 100%|██████████████████████| 805/805 [01:01<00:00, 13.00it/s]\n",
      "INFO:root:Evaluating the llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10-greedy-long outputs.\n",
      "INFO:root:Creating the annotator from `alpaca_eval_gpt4_turbo_fn`.\n",
      "WARNING:root:Saving_path is given but not 'auto', make sure that it's different for different seeds.\n",
      "Annotation chunk:   0%|                                   | 0/7 [00:00<?, ?it/s]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:02<06:07,  2.90s/it]\u001b[A\n",
      "prompt_batches:   2%|▋                          | 3/128 [00:03<01:52,  1.11it/s]\u001b[A\n",
      "prompt_batches:   3%|▊                          | 4/128 [00:06<03:40,  1.78s/it]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/128 [00:11<02:02,  1.04s/it]\u001b[A\n",
      "prompt_batches:   9%|██▍                       | 12/128 [00:14<02:13,  1.15s/it]\u001b[A\n",
      "prompt_batches:  14%|███▋                      | 18/128 [00:14<01:00,  1.81it/s]\u001b[A\n",
      "prompt_batches:  16%|████                      | 20/128 [00:15<01:02,  1.73it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:18<01:16,  1.38it/s]\u001b[A\n",
      "prompt_batches:  18%|████▋                     | 23/128 [00:18<01:08,  1.52it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:21<01:29,  1.16it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/128 [00:21<01:17,  1.31it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:23<01:36,  1.05it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:25<01:27,  1.12it/s]\u001b[A\n",
      "prompt_batches:  25%|██████▌                   | 32/128 [00:29<01:47,  1.12s/it]\u001b[A\n",
      "prompt_batches:  30%|███████▋                  | 38/128 [00:34<01:27,  1.03it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/128 [00:36<01:25,  1.03it/s]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:38<01:15,  1.12it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▎                | 46/128 [00:46<01:56,  1.42s/it]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:47<01:01,  1.21it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▌              | 57/128 [00:49<00:49,  1.43it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▊              | 58/128 [00:50<00:54,  1.29it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 59/128 [00:53<01:04,  1.08it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:54<00:48,  1.36it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▊             | 63/128 [00:55<00:52,  1.23it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 64/128 [00:56<00:56,  1.13it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 65/128 [00:56<00:47,  1.32it/s]\u001b[A\n",
      "prompt_batches:  53%|█████████████▊            | 68/128 [00:58<00:39,  1.53it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [01:11<02:16,  2.36s/it]\u001b[A\n",
      "prompt_batches:  66%|█████████████████▎        | 85/128 [01:11<00:25,  1.69it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:13<00:21,  1.79it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:19<00:37,  1.02it/s]\u001b[A\n",
      "prompt_batches:  78%|███████████████████▌     | 100/128 [01:21<00:16,  1.71it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:25<00:17,  1.45it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:28<00:12,  1.55it/s]\u001b[A\n",
      "prompt_batches:  86%|█████████████████████▍   | 110/128 [01:28<00:10,  1.76it/s]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▎  | 114/128 [01:29<00:06,  2.21it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:30<00:07,  1.70it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 117/128 [01:32<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 119/128 [01:33<00:05,  1.66it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▋ | 121/128 [01:35<00:04,  1.46it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▍| 125/128 [01:36<00:01,  2.04it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 126/128 [01:36<00:01,  1.92it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:37<00:00,  1.31it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 97.8 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  14%|███▊                       | 1/7 [01:37<09:47, 97.89s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:05<12:20,  5.83s/it]\u001b[A\n",
      "prompt_batches:   5%|█▍                         | 7/128 [00:15<03:59,  1.98s/it]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:19<02:12,  1.16s/it]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:19<01:50,  1.02it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:20<01:07,  1.59it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:22<01:22,  1.28it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:23<01:03,  1.63it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/128 [00:24<01:05,  1.56it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:24<00:58,  1.73it/s]\u001b[A\n",
      "prompt_batches:  22%|█████▋                    | 28/128 [00:25<01:02,  1.59it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/128 [00:26<01:06,  1.48it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:26<01:08,  1.42it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▎                   | 31/128 [00:29<01:45,  1.09s/it]\u001b[A\n",
      "prompt_batches:  27%|██████▉                   | 34/128 [00:29<00:52,  1.78it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 36/128 [00:29<00:42,  2.14it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/128 [00:30<00:38,  2.34it/s]\u001b[A\n",
      "prompt_batches:  30%|███████▋                  | 38/128 [00:38<03:11,  2.12s/it]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:40<01:28,  1.04s/it]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:41<00:43,  1.79it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:42<00:36,  2.06it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▏              | 55/128 [00:43<00:40,  1.81it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▌              | 57/128 [00:46<00:54,  1.31it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:47<00:33,  1.97it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 64/128 [00:55<01:15,  1.18s/it]\u001b[A\n",
      "prompt_batches:  56%|██████████████▋           | 72/128 [00:55<00:32,  1.71it/s]\u001b[A\n",
      "prompt_batches:  57%|██████████████▊           | 73/128 [00:56<00:32,  1.71it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 74/128 [01:05<01:23,  1.54s/it]\u001b[A\n",
      "prompt_batches:  67%|█████████████████▍        | 86/128 [01:06<00:24,  1.71it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▋        | 87/128 [01:07<00:23,  1.74it/s]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▉        | 88/128 [01:07<00:21,  1.82it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:08<00:22,  1.76it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:12<00:43,  1.13s/it]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 95/128 [01:13<00:19,  1.67it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:13<00:20,  1.57it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:15<00:25,  1.23it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:17<00:18,  1.44it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:19<00:19,  1.31it/s]\u001b[A\n",
      "prompt_batches:  84%|████████████████████▉    | 107/128 [01:20<00:10,  2.09it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:20<00:10,  1.95it/s]\u001b[A\n",
      "prompt_batches:  86%|█████████████████████▍   | 110/128 [01:22<00:10,  1.67it/s]\u001b[A\n",
      "prompt_batches:  88%|█████████████████████▉   | 112/128 [01:24<00:12,  1.33it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:25<00:07,  1.82it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▋  | 116/128 [01:27<00:08,  1.43it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 117/128 [01:27<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 119/128 [01:28<00:05,  1.71it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▍ | 120/128 [01:30<00:06,  1.17it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:32<00:05,  1.03it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:33<00:00,  1.37it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 93.5 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  29%|███████▋                   | 2/7 [03:11<07:56, 95.40s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:03<07:34,  3.58s/it]\u001b[A\n",
      "prompt_batches:   2%|▍                          | 2/128 [00:06<06:45,  3.22s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/128 [00:07<01:14,  1.60it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/128 [00:08<01:16,  1.54it/s]\u001b[A\n",
      "prompt_batches:   9%|██▏                       | 11/128 [00:09<01:20,  1.45it/s]\u001b[A\n",
      "prompt_batches:   9%|██▍                       | 12/128 [00:10<01:29,  1.30it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:10<01:00,  1.89it/s]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:12<01:07,  1.65it/s]\u001b[A\n",
      "prompt_batches:  13%|███▍                      | 17/128 [00:13<01:10,  1.57it/s]\u001b[A\n",
      "prompt_batches:  14%|███▋                      | 18/128 [00:14<01:21,  1.35it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:15<01:08,  1.57it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:16<01:17,  1.36it/s]\u001b[A\n",
      "prompt_batches:  18%|████▋                     | 23/128 [00:17<01:23,  1.26it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:18<01:07,  1.53it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:20<01:06,  1.51it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:23<01:22,  1.18it/s]\u001b[A\n",
      "prompt_batches:  26%|██████▋                   | 33/128 [00:23<00:54,  1.75it/s]\u001b[A\n",
      "prompt_batches:  27%|███████                   | 35/128 [00:24<00:48,  1.93it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 36/128 [00:25<00:53,  1.73it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/128 [00:25<00:50,  1.82it/s]\u001b[A\n",
      "prompt_batches:  30%|███████▉                  | 39/128 [00:27<00:51,  1.74it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/128 [00:29<01:28,  1.01s/it]\u001b[A\n",
      "prompt_batches:  34%|████████▉                 | 44/128 [00:30<00:42,  1.97it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████▏                | 45/128 [00:32<01:06,  1.24it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▎                | 46/128 [00:32<00:55,  1.47it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▊                | 48/128 [00:32<00:37,  2.12it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▉                | 49/128 [00:34<01:00,  1.30it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:34<00:39,  1.95it/s]\u001b[A\n",
      "prompt_batches:  42%|██████████▉               | 54/128 [00:38<01:00,  1.22it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▏              | 55/128 [00:39<00:57,  1.28it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▍              | 56/128 [00:40<01:05,  1.09it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 59/128 [00:43<01:06,  1.05it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:43<00:40,  1.65it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▊             | 63/128 [00:44<00:40,  1.59it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 65/128 [00:46<00:46,  1.37it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 66/128 [00:46<00:38,  1.61it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▌            | 67/128 [00:46<00:34,  1.78it/s]\u001b[A\n",
      "prompt_batches:  54%|██████████████            | 69/128 [00:47<00:27,  2.11it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [00:49<00:48,  1.18it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▍           | 71/128 [00:50<00:50,  1.13it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▏          | 75/128 [00:51<00:25,  2.05it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▍          | 76/128 [00:54<00:45,  1.14it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████          | 79/128 [00:54<00:28,  1.72it/s]\u001b[A\n",
      "prompt_batches:  63%|████████████████▍         | 81/128 [00:55<00:25,  1.81it/s]\u001b[A\n",
      "prompt_batches:  64%|████████████████▋         | 82/128 [00:57<00:32,  1.42it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 83/128 [01:00<00:55,  1.24s/it]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▉        | 88/128 [01:01<00:22,  1.76it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:02<00:24,  1.60it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 91/128 [01:05<00:33,  1.10it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▋       | 92/128 [01:06<00:35,  1.03it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:07<00:19,  1.63it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:07<00:16,  1.85it/s]\u001b[A\n",
      "prompt_batches:  77%|███████████████████▉      | 98/128 [01:08<00:18,  1.62it/s]\u001b[A\n",
      "prompt_batches:  77%|████████████████████      | 99/128 [01:10<00:25,  1.13it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:11<00:20,  1.29it/s]\u001b[A\n",
      "prompt_batches:  80%|███████████████████▉     | 102/128 [01:12<00:16,  1.55it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 104/128 [01:12<00:14,  1.70it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▌    | 105/128 [01:15<00:22,  1.02it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:16<00:13,  1.53it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▎   | 109/128 [01:17<00:14,  1.33it/s]\u001b[A\n",
      "prompt_batches:  87%|█████████████████████▋   | 111/128 [01:19<00:15,  1.10it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:23<00:11,  1.16it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▋  | 116/128 [01:28<00:18,  1.51s/it]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:29<00:04,  1.36it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:32<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 92.2 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation chunk:  43%|███████████▌               | 3/7 [04:43<06:15, 93.97s/it]INFO:root:Annotating 127 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 127 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/127 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/127 [00:03<07:05,  3.38s/it]\u001b[A\n",
      "prompt_batches:   2%|▍                          | 2/127 [00:04<03:43,  1.79s/it]\u001b[A\n",
      "prompt_batches:   5%|█▎                         | 6/127 [00:04<01:06,  1.81it/s]\u001b[A\n",
      "prompt_batches:   6%|█▍                         | 7/127 [00:06<01:38,  1.22it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/127 [00:06<00:56,  2.05it/s]\u001b[A\n",
      "prompt_batches:   9%|██▎                       | 11/127 [00:10<01:59,  1.03s/it]\u001b[A\n",
      "prompt_batches:  10%|██▋                       | 13/127 [00:11<01:41,  1.12it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/127 [00:12<01:31,  1.24it/s]\u001b[A\n",
      "prompt_batches:  13%|███▍                      | 17/127 [00:14<01:24,  1.30it/s]\u001b[A\n",
      "prompt_batches:  15%|███▉                      | 19/127 [00:15<01:13,  1.48it/s]\u001b[A\n",
      "prompt_batches:  17%|████▎                     | 21/127 [00:15<00:59,  1.77it/s]\u001b[A\n",
      "prompt_batches:  19%|████▉                     | 24/127 [00:18<01:04,  1.59it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/127 [00:19<01:00,  1.66it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/127 [00:23<01:36,  1.02it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/127 [00:24<00:41,  2.16it/s]\u001b[A\n",
      "prompt_batches:  31%|███████▉                  | 39/127 [00:26<00:49,  1.79it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/127 [00:26<00:44,  1.94it/s]\u001b[A\n",
      "prompt_batches:  33%|████████▌                 | 42/127 [00:27<00:39,  2.17it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████                 | 44/127 [00:27<00:32,  2.56it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████▏                | 45/127 [00:28<00:28,  2.84it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▍                | 46/127 [00:28<00:36,  2.23it/s]\u001b[A\n",
      "prompt_batches:  37%|█████████▌                | 47/127 [00:29<00:42,  1.86it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▊                | 48/127 [00:31<01:08,  1.15it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▋               | 52/127 [00:32<00:40,  1.87it/s]\u001b[A\n",
      "prompt_batches:  42%|██████████▊               | 53/127 [00:34<00:47,  1.56it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████               | 54/127 [00:35<00:52,  1.40it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▎              | 55/127 [00:35<00:53,  1.35it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▊              | 58/127 [00:37<00:41,  1.65it/s]\u001b[A\n",
      "prompt_batches:  46%|████████████              | 59/127 [00:37<00:40,  1.68it/s]\u001b[A\n",
      "prompt_batches:  47%|████████████▎             | 60/127 [00:38<00:36,  1.85it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▋             | 62/127 [00:39<00:43,  1.49it/s]\u001b[A\n",
      "prompt_batches:  50%|████████████▉             | 63/127 [00:42<01:10,  1.10s/it]\u001b[A\n",
      "prompt_batches:  54%|█████████████▉            | 68/127 [00:43<00:28,  2.08it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▎           | 70/127 [00:45<00:41,  1.36it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▌           | 71/127 [00:51<01:21,  1.45s/it]\u001b[A\n",
      "prompt_batches:  59%|███████████████▎          | 75/127 [00:52<00:45,  1.15it/s]\u001b[A\n",
      "prompt_batches:  61%|███████████████▊          | 77/127 [00:53<00:37,  1.32it/s]\u001b[A\n",
      "prompt_batches:  63%|████████████████▍         | 80/127 [00:53<00:24,  1.93it/s]\u001b[A\n",
      "prompt_batches:  64%|████████████████▌         | 81/127 [00:55<00:32,  1.43it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 82/127 [00:56<00:34,  1.32it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▉         | 83/127 [00:56<00:29,  1.50it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▌        | 86/127 [00:56<00:17,  2.41it/s]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▊        | 87/127 [00:58<00:25,  1.54it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 90/127 [01:00<00:22,  1.64it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▊       | 92/127 [01:00<00:18,  1.90it/s]\u001b[A\n",
      "prompt_batches:  73%|███████████████████       | 93/127 [01:01<00:17,  1.94it/s]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▏      | 94/127 [01:01<00:17,  1.93it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▍      | 95/127 [01:02<00:15,  2.08it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 96/127 [01:03<00:23,  1.33it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▊      | 97/127 [01:03<00:18,  1.59it/s]\u001b[A\n",
      "prompt_batches:  78%|████████████████████▎     | 99/127 [01:04<00:15,  1.78it/s]\u001b[A\n",
      "prompt_batches:  80%|███████████████████▉     | 101/127 [01:06<00:16,  1.61it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 102/127 [01:08<00:21,  1.16it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▍    | 104/127 [01:10<00:20,  1.10it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 107/127 [01:10<00:11,  1.69it/s]\u001b[A\n",
      "prompt_batches:  87%|█████████████████████▋   | 110/127 [01:16<00:19,  1.13s/it]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 116/127 [01:18<00:07,  1.39it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 121/127 [01:19<00:03,  1.93it/s]\u001b[A\n",
      "prompt_batches:  96%|████████████████████████ | 122/127 [01:21<00:03,  1.47it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 123/127 [01:24<00:03,  1.10it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 127/127 [01:27<00:00,  1.45it/s]\u001b[A\n",
      "INFO:root:Completed 127 examples in 87.5 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation chunk:  57%|███████████████▍           | 4/7 [06:11<04:34, 91.46s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:04<10:20,  4.88s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/128 [00:07<01:36,  1.25it/s]\u001b[A\n",
      "prompt_batches:   7%|█▉                         | 9/128 [00:07<01:24,  1.41it/s]\u001b[A\n",
      "prompt_batches:  10%|██▋                       | 13/128 [00:08<00:53,  2.16it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:10<01:12,  1.57it/s]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:10<01:02,  1.80it/s]\u001b[A\n",
      "prompt_batches:  15%|███▊                      | 19/128 [00:12<01:00,  1.79it/s]\u001b[A\n",
      "prompt_batches:  16%|████                      | 20/128 [00:13<01:08,  1.58it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:13<00:59,  1.79it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:14<00:59,  1.78it/s]\u001b[A\n",
      "prompt_batches:  19%|████▉                     | 24/128 [00:16<01:22,  1.25it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:17<00:54,  1.86it/s]\u001b[A\n",
      "prompt_batches:  22%|█████▋                    | 28/128 [00:18<00:55,  1.79it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/128 [00:18<00:57,  1.72it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:21<01:35,  1.02it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▎                   | 31/128 [00:26<03:17,  2.04s/it]\u001b[A\n",
      "prompt_batches:  32%|████████▎                 | 41/128 [00:29<01:00,  1.44it/s]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:30<00:55,  1.52it/s]\u001b[A\n",
      "prompt_batches:  37%|█████████▌                | 47/128 [00:32<00:51,  1.59it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:33<00:38,  1.99it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▌               | 52/128 [00:36<00:51,  1.48it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:36<00:52,  1.43it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▍              | 56/128 [00:37<00:38,  1.85it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▊              | 58/128 [00:38<00:31,  2.20it/s]\u001b[A\n",
      "prompt_batches:  47%|████████████▏             | 60/128 [00:45<01:26,  1.26s/it]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 66/128 [00:46<00:42,  1.47it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▌            | 67/128 [00:47<00:47,  1.27it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [00:49<00:39,  1.49it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▋           | 72/128 [00:49<00:32,  1.72it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 74/128 [00:52<00:40,  1.35it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▍          | 76/128 [00:52<00:33,  1.55it/s]\u001b[A\n",
      "prompt_batches:  60%|███████████████▋          | 77/128 [00:55<00:46,  1.10it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████          | 79/128 [00:57<00:45,  1.09it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████▎         | 80/128 [00:57<00:42,  1.14it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 83/128 [00:59<00:34,  1.31it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▋        | 87/128 [01:01<00:24,  1.65it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:02<00:21,  1.80it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:02<00:19,  1.98it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 91/128 [01:05<00:39,  1.07s/it]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 95/128 [01:07<00:22,  1.45it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:08<00:24,  1.31it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:09<00:24,  1.27it/s]\u001b[A\n",
      "prompt_batches:  77%|████████████████████      | 99/128 [01:10<00:19,  1.47it/s]\u001b[A\n",
      "prompt_batches:  78%|███████████████████▌     | 100/128 [01:11<00:20,  1.38it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:11<00:18,  1.43it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:12<00:16,  1.54it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 104/128 [01:13<00:17,  1.41it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▌    | 105/128 [01:15<00:22,  1.01it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:18<00:18,  1.07it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▎   | 109/128 [01:20<00:21,  1.12s/it]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▎  | 114/128 [01:22<00:10,  1.35it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:26<00:15,  1.21s/it]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:26<00:03,  1.94it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 124/128 [01:28<00:02,  1.81it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 126/128 [01:29<00:01,  1.73it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:32<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 92.2 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  71%|███████████████████▎       | 5/7 [07:43<03:03, 91.78s/it]INFO:root:Annotating 124 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 124 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/124 [00:04<08:16,  4.04s/it]\u001b[A\n",
      "prompt_batches:   5%|█▎                         | 6/124 [00:05<01:25,  1.38it/s]\u001b[A\n",
      "prompt_batches:   6%|█▌                         | 7/124 [00:07<01:57,  1.00s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/124 [00:07<01:38,  1.18it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/124 [00:08<01:05,  1.73it/s]\u001b[A\n",
      "prompt_batches:  10%|██▌                       | 12/124 [00:10<01:38,  1.14it/s]\u001b[A\n",
      "prompt_batches:  12%|███▏                      | 15/124 [00:11<00:59,  1.84it/s]\u001b[A\n",
      "prompt_batches:  14%|███▌                      | 17/124 [00:13<01:13,  1.46it/s]\u001b[A\n",
      "prompt_batches:  15%|███▉                      | 19/124 [00:15<01:21,  1.28it/s]\u001b[A\n",
      "prompt_batches:  19%|████▊                     | 23/124 [00:16<00:56,  1.80it/s]\u001b[A\n",
      "prompt_batches:  19%|█████                     | 24/124 [00:17<01:09,  1.44it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 26/124 [00:20<01:18,  1.25it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 29/124 [00:20<00:57,  1.66it/s]\u001b[A\n",
      "prompt_batches:  25%|██████▌                   | 31/124 [00:22<00:59,  1.57it/s]\u001b[A\n",
      "prompt_batches:  26%|██████▋                   | 32/124 [00:23<01:08,  1.35it/s]\u001b[A\n",
      "prompt_batches:  27%|██████▉                   | 33/124 [00:24<01:03,  1.44it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 35/124 [00:26<01:11,  1.24it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 36/124 [00:27<01:11,  1.24it/s]\u001b[A\n",
      "prompt_batches:  32%|████████▍                 | 40/124 [00:28<00:42,  1.99it/s]\u001b[A\n",
      "prompt_batches:  33%|████████▌                 | 41/124 [00:29<01:00,  1.38it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▍                | 45/124 [00:32<00:54,  1.46it/s]\u001b[A\n",
      "prompt_batches:  39%|██████████                | 48/124 [00:33<00:39,  1.92it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 49/124 [00:36<01:05,  1.14it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▎              | 54/124 [00:37<00:37,  1.89it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▋              | 56/124 [00:38<00:35,  1.89it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 57/124 [00:40<00:53,  1.25it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▎             | 59/124 [00:40<00:39,  1.63it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 62/124 [00:41<00:31,  1.97it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 63/124 [00:42<00:35,  1.71it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 64/124 [00:43<00:35,  1.71it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▋            | 65/124 [00:44<00:42,  1.38it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▎           | 68/124 [00:45<00:30,  1.85it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▍           | 69/124 [00:46<00:27,  1.97it/s]\u001b[A\n",
      "prompt_batches:  57%|██████████████▉           | 71/124 [00:47<00:31,  1.66it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 72/124 [00:47<00:27,  1.87it/s]\u001b[A\n",
      "prompt_batches:  60%|███████████████▋          | 75/124 [00:54<01:06,  1.35s/it]\u001b[A\n",
      "prompt_batches:  61%|███████████████▉          | 76/124 [00:55<00:54,  1.13s/it]\u001b[A\n",
      "prompt_batches:  65%|████████████████▉         | 81/124 [00:55<00:22,  1.89it/s]\u001b[A\n",
      "prompt_batches:  67%|█████████████████▍        | 83/124 [00:56<00:24,  1.66it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▌        | 84/124 [00:59<00:35,  1.12it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 88/124 [01:00<00:22,  1.61it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▋       | 89/124 [01:00<00:19,  1.77it/s]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 92/124 [01:02<00:18,  1.74it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 93/124 [01:04<00:22,  1.36it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 94/124 [01:05<00:26,  1.12it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████▊     | 99/124 [01:07<00:13,  1.87it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▏    | 100/124 [01:07<00:13,  1.82it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 101/124 [01:08<00:11,  1.95it/s]\u001b[A\n",
      "prompt_batches:  83%|████████████████████▊    | 103/124 [01:08<00:08,  2.44it/s]\u001b[A\n",
      "prompt_batches:  84%|████████████████████▉    | 104/124 [01:09<00:08,  2.41it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▏   | 105/124 [01:12<00:19,  1.02s/it]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▏  | 110/124 [01:16<00:12,  1.11it/s]\u001b[A\n",
      "prompt_batches:  92%|██████████████████████▉  | 114/124 [01:17<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 115/124 [01:17<00:05,  1.62it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▍ | 116/124 [01:19<00:05,  1.40it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▌ | 117/124 [01:19<00:05,  1.38it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 118/124 [01:20<00:04,  1.36it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 120/124 [01:21<00:02,  1.79it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 122/124 [01:23<00:01,  1.27it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 124/124 [01:24<00:00,  1.47it/s]\u001b[A\n",
      "INFO:root:Completed 124 examples in 84.6 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  86%|███████████████████████▏   | 6/7 [09:08<01:29, 89.38s/it]INFO:root:Annotating 37 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 37 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                    | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   3%|▊                           | 1/37 [00:03<02:03,  3.43s/it]\u001b[A\n",
      "prompt_batches:  16%|████▌                       | 6/37 [00:04<00:21,  1.45it/s]\u001b[A\n",
      "prompt_batches:  19%|█████▎                      | 7/37 [00:05<00:19,  1.55it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▊                     | 9/37 [00:07<00:22,  1.26it/s]\u001b[A\n",
      "prompt_batches:  30%|████████                   | 11/37 [00:08<00:17,  1.46it/s]\u001b[A\n",
      "prompt_batches:  32%|████████▊                  | 12/37 [00:11<00:27,  1.08s/it]\u001b[A\n",
      "prompt_batches:  41%|██████████▉                | 15/37 [00:12<00:15,  1.39it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▊             | 19/37 [00:12<00:07,  2.40it/s]\u001b[A\n",
      "prompt_batches:  54%|██████████████▌            | 20/37 [00:14<00:10,  1.61it/s]\u001b[A\n",
      "prompt_batches:  59%|████████████████           | 22/37 [00:15<00:08,  1.77it/s]\u001b[A\n",
      "prompt_batches:  65%|█████████████████▌         | 24/37 [00:17<00:10,  1.28it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▉        | 26/37 [00:20<00:10,  1.03it/s]\u001b[A\n",
      "prompt_batches:  84%|██████████████████████▌    | 31/37 [00:21<00:03,  1.68it/s]\u001b[A\n",
      "prompt_batches:  89%|████████████████████████   | 33/37 [00:24<00:02,  1.36it/s]\u001b[A\n",
      "prompt_batches: 100%|███████████████████████████| 37/37 [00:26<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 37 examples in 26.8 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk: 100%|███████████████████████████| 7/7 [09:35<00:00, 82.20s/it]\n",
      "/dccstor/data-pruning/wpq/github/mitibm2023/external/alpaca_eval/src/alpaca_eval/metrics.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  series_preferences[series_preferences == 0] = 1.5\n",
      "INFO:root:Saving all results to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Price (per-example / total) = 0.0191 / 15.29\n",
      "Time  (per-example / total) = 0.7184 / 574.70\n",
      "                                                                                                                           model  win_rate  standard_error  n_wins  n_wins_base  n_draws  n_total       mode  avg_length  avg_output_tok_length  price\n",
      "0  llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10-greedy-long     19.32            1.39     153          647        5      805  community         607                 172.59  15.29\n",
      "Map: 100%|███████████████████████████| 805/805 [00:00<00:00, 2978.74 examples/s]\n",
      "Filter (num_proc=4): 100%|███████████| 805/805 [00:00<00:00, 4447.74 examples/s]\n",
      "Creating json from Arrow format: 100%|███████████| 1/1 [00:00<00:00, 178.53ba/s]\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3 --max_new_tokens 2048 --save_dir results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt --eval_batch_size 10 --annotators_config alpaca_eval_gpt4_turbo_fn --use_vllm --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype bfloat16\n",
      "[2024-01-21 21:22:39,160] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:loading data and model...\n",
      "INFO 01-21 21:22:41 llm_engine.py:73] Initializing an LLM engine with config: model='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3', tokenizer='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO 01-21 21:22:41 tokenizer.py:32] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "MegaBlocks not found. Please install it by `pip install megablocks`. Note that MegaBlocks depends on mosaicml-turbo, which only supports Python 3.10 for now.\n",
      "STK not found: please see https://github.com/stanford-futuredata/stk\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/eval/alpaca_farm/run_eval.py\", line 160, in <module>\n",
      "    main(args)\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/eval/alpaca_farm/run_eval.py\", line 38, in main\n",
      "    model = vllm.LLM(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/entrypoints/llm.py\", line 93, in __init__\n",
      "    self.llm_engine = LLMEngine.from_engine_args(engine_args)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 246, in from_engine_args\n",
      "    engine = cls(*engine_configs,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 109, in __init__\n",
      "    self._init_workers(distributed_init_method)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 145, in _init_workers\n",
      "    self._run_workers(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 750, in _run_workers\n",
      "    self._run_workers_in_batch(workers, method, *args, **kwargs))\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 724, in _run_workers_in_batch\n",
      "    output = executor(*args, **kwargs)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/worker/worker.py\", line 72, in load_model\n",
      "    self.model_runner.load_model()\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 36, in load_model\n",
      "    self.model = get_model(self.model_config)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/model_loader.py\", line 124, in get_model\n",
      "    model.load_weights(model_config.model, model_config.download_dir,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 335, in load_weights\n",
      "    weight_loader(param, loaded_weight, shard_id)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 303, in weight_loader\n",
      "    param_data.copy_(loaded_weight)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_eval.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859d6d6",
   "metadata": {},
   "source": [
    "# Visualize Eval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1b033ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move ./1397708.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/bbh_s=3_cot_chatfmt/1397708.out.lsf\n",
      "Job ./1388986.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/mmlu_s=0_chatfmt\n",
      "Job ./1389187.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=0_chatfmt\n",
      "Move ./1397603.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3/eval/mmlu_s=5/1397603.out.lsf\n",
      "Move ./1397594.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=5_chatfmt/1397594.out.lsf\n",
      "Move ./1398282.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp/1398282.out.lsf\n",
      "Job ./1397600.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_cb_chatfmt\n",
      "Move ./1397652.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/bbh_s=3/1397652.out.lsf\n",
      "Job ./1394502.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=0\n",
      "Job ./1396996.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "./1394831.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1396995.out exited with error code. --save_dir=results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Move ./1398502.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/1398502.out.lsf\n",
      "Move ./1397699.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/bbh_s=3_cot/1397699.out.lsf\n",
      "Move ./1397702.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_gp/1397702.out.lsf\n",
      "Move ./1398283.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_cb/1398283.out.lsf\n",
      "Job ./1397663.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/humaneval_chatfmt\n",
      "Job ./1388963.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/bbh_s=3\n",
      "Job ./1389159.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp\n",
      "Job ./1397561.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/gsm_s=8_cot\n",
      "./1388921.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1388458.out exited with error code. --save_dir=results/oi2/llama-7b_sharegpt50k_ep=2/eval/mmlu_s=0\n",
      "./1388192.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1397164.out exited with error code. --save_dir=results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/mmlu_s=5\n",
      "Move ./1397678.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/humaneval_chatfmt/1397678.out.lsf\n",
      "Job ./1397644.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/bbh_s=3_cot_chatfmt\n",
      "Job ./1397642.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/gsm_s=8_cot_chatfmt\n",
      "./1394835.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1393671.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/humaneval\n",
      "Job ./1397168.out exited with error code. --save_dir=results/oi5_stanford_alpaca50k:llama-7b/llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/bbh_s=3_cot\n",
      "Move ./1397655.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_cb/1397655.out.lsf\n",
      "Job ./1397003.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Job ./1396671.out exited with error code. --save_dir=results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/gsm_s=8_chatfmt\n",
      "./1388919.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1397615.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3/eval/bbh_s=3_chatfmt\n",
      "Job ./1388463.out exited with error code. --save_dir=results/oi2/llama-7b_sharegpt50k_ep=2/eval/mmlu_s=5_chatfmt\n",
      "Job ./1397072.out exited with error code. --save_dir=results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3/eval/humaneval\n",
      "Job ./1388948.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/tydiqa_s=1_cb\n",
      "./1396744.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1389161.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/mmlu_s=0_chatfmt\n",
      "Job ./1388971.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/gsm_s=8_cot_chatfmt\n",
      "Job ./1393673.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_gp\n",
      "Move ./1397671.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/tydiqa_s=1_gp/1397671.out.lsf\n",
      "Move ./1397689.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/bbh_s=3_chatfmt/1397689.out.lsf\n",
      "Job ./1394503.out exited with error code. --save_dir=results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/mmlu_s=0\n",
      "Move ./1397648.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/mmlu_s=0/1397648.out.lsf\n",
      "./1396354.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1396997.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Move ./1398299.out -> /dccstor/data-pruning/results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/1398299.out.lsf\n",
      "Job ./1396413.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp\n",
      "Job ./1393687.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/gsm_s=8_cot\n",
      "Move ./1397703.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/mmlu_s=0_chatfmt/1397703.out.lsf\n",
      "Job ./1397014.out exited with error code. --save_dir=results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "./1397179.out does not have `--save_dir` specified. Probably still running.\n",
      "Move ./1397700.out -> /dccstor/data-pruning/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/humaneval/1397700.out.lsf\n",
      "Job ./1388947.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10/eval/humaneval\n",
      "Job ./1389097.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/gsm_s=8_cot\n",
      "Job ./1388991.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=10000:ep=10/eval/bbh_s=3_cot_chatfmt\n",
      "Job ./1397093.out exited with error code. --save_dir=results/oi5_oasst2:llama-7b/llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3/eval/gsm_s=8\n",
      "Job ./1388976.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/tydiqa_s=1_gp_chatfmt\n",
      "Job ./1396720.out exited with error code. --save_dir=results/oi5_flan_v250k:llama-7b/llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3/eval/humaneval\n",
      "Job ./1388969.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mmlu_s=5_chatfmt\n",
      "Job ./1396437.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/bbh_s=3_cot_chatfmt\n",
      "Job ./1397004.out exited with error code. --save_dir=results/oi5_ultrachat50k:llama-7b/llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Job ./1393700.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3/eval/tydiqa_s=1_cb_chatfmt\n",
      "Job ./1389178.out exited with error code. --save_dir=results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/mmlu_s=5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/model_outputs/sft/llama-7b+lora:r=512:a=11585+proj=4096;/1389415.out.lsf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:816\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './1389415.out' -> '/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/model_outputs/sft/llama-7b+lora:r=512:a=11585+proj=4096;/1389415.out.lsf'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# if job successfully ran, lsf system will generate a summary in log_dir,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# call this function to move lsf summary to save_dir if job is successful.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmove_lsf_job_summary_to_save_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/wpq/github/mitibm2023/src/llm/submit.py:464\u001b[0m, in \u001b[0;36mmove_lsf_job_summary_to_save_dir\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m    462\u001b[0m     target_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, save_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(out_file)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.lsf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    463\u001b[0m     target_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(target_path)\n\u001b[0;32m--> 464\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMove \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExited with exit code\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m t:\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:836\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    834\u001b[0m         rmtree(src)\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 836\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    433\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 434\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m             \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[1;32m    259\u001b[0m                 \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/model_outputs/sft/llama-7b+lora:r=512:a=11585+proj=4096;/1389415.out.lsf'"
     ]
    }
   ],
   "source": [
    "# if job successfully ran, lsf system will generate a summary in log_dir,\n",
    "# call this function to move lsf summary to save_dir if job is successful.\n",
    "move_lsf_job_summary_to_save_dir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "4392e9ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_fmt=mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d510b td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_d510b_row0_col0, #T_d510b_row1_col0, #T_d510b_row2_col0, #T_d510b_row3_col0, #T_d510b_row4_col0, #T_d510b_row5_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d510b_row0_col1, #T_d510b_row1_col1, #T_d510b_row2_col1, #T_d510b_row3_col1, #T_d510b_row4_col1, #T_d510b_row5_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d510b_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row0_col3, #T_d510b_row0_col6, #T_d510b_row0_col11, #T_d510b_row1_col14, #T_d510b_row1_col15, #T_d510b_row2_col4, #T_d510b_row2_col8, #T_d510b_row2_col9, #T_d510b_row4_col10, #T_d510b_row5_col2, #T_d510b_row5_col5, #T_d510b_row5_col7, #T_d510b_row5_col12, #T_d510b_row5_col13, #T_d510b_row5_col16, #T_d510b_row5_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row0_col4, #T_d510b_row0_col5, #T_d510b_row0_col7, #T_d510b_row0_col8, #T_d510b_row0_col12, #T_d510b_row0_col16, #T_d510b_row1_col3, #T_d510b_row1_col4, #T_d510b_row1_col9, #T_d510b_row1_col10, #T_d510b_row1_col17, #T_d510b_row2_col10, #T_d510b_row2_col11, #T_d510b_row3_col2, #T_d510b_row3_col6, #T_d510b_row4_col13, #T_d510b_row4_col14, #T_d510b_row4_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row0_col13, #T_d510b_row0_col14, #T_d510b_row0_col15, #T_d510b_row0_col17, #T_d510b_row3_col13, #T_d510b_row3_col14, #T_d510b_row3_col15, #T_d510b_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row1_col7, #T_d510b_row1_col8, #T_d510b_row3_col4, #T_d510b_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row1_col11, #T_d510b_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row2_col3, #T_d510b_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row2_col13, #T_d510b_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row2_col17, #T_d510b_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row3_col3, #T_d510b_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row4_col3, #T_d510b_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row4_col12, #T_d510b_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row5_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row5_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d510b_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row5_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d510b_row5_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d510b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d510b_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d510b_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_d510b_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d510b_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d510b_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_d510b_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_d510b_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_d510b_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_d510b_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d510b_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d510b_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d510b_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_d510b_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_d510b_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_d510b_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_d510b_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_d510b_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_d510b_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d510b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d510b_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_d510b_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_d510b_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_d510b_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_d510b_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_d510b_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_d510b_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_d510b_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_d510b_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_d510b_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_d510b_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_d510b_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_d510b_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_d510b_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_d510b_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_d510b_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_d510b_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_d510b_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d510b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d510b_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_d510b_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_d510b_row1_col2\" class=\"data row1 col2\" >38.5</td>\n",
       "      <td id=\"T_d510b_row1_col3\" class=\"data row1 col3\" >38.5</td>\n",
       "      <td id=\"T_d510b_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_d510b_row1_col5\" class=\"data row1 col5\" >10.8</td>\n",
       "      <td id=\"T_d510b_row1_col6\" class=\"data row1 col6\" >34.0</td>\n",
       "      <td id=\"T_d510b_row1_col7\" class=\"data row1 col7\" >31.3</td>\n",
       "      <td id=\"T_d510b_row1_col8\" class=\"data row1 col8\" >9.0</td>\n",
       "      <td id=\"T_d510b_row1_col9\" class=\"data row1 col9\" >44.0</td>\n",
       "      <td id=\"T_d510b_row1_col10\" class=\"data row1 col10\" >10.4</td>\n",
       "      <td id=\"T_d510b_row1_col11\" class=\"data row1 col11\" >11.1</td>\n",
       "      <td id=\"T_d510b_row1_col12\" class=\"data row1 col12\" >319.7</td>\n",
       "      <td id=\"T_d510b_row1_col13\" class=\"data row1 col13\" >34.0</td>\n",
       "      <td id=\"T_d510b_row1_col14\" class=\"data row1 col14\" >16.8</td>\n",
       "      <td id=\"T_d510b_row1_col15\" class=\"data row1 col15\" >25.5</td>\n",
       "      <td id=\"T_d510b_row1_col16\" class=\"data row1 col16\" >44.9</td>\n",
       "      <td id=\"T_d510b_row1_col17\" class=\"data row1 col17\" >-31.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d510b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d510b_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_d510b_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_d510b_row2_col2\" class=\"data row2 col2\" >34.7</td>\n",
       "      <td id=\"T_d510b_row2_col3\" class=\"data row2 col3\" >37.0</td>\n",
       "      <td id=\"T_d510b_row2_col4\" class=\"data row2 col4\" >3.4</td>\n",
       "      <td id=\"T_d510b_row2_col5\" class=\"data row2 col5\" >10.0</td>\n",
       "      <td id=\"T_d510b_row2_col6\" class=\"data row2 col6\" >30.9</td>\n",
       "      <td id=\"T_d510b_row2_col7\" class=\"data row2 col7\" >30.1</td>\n",
       "      <td id=\"T_d510b_row2_col8\" class=\"data row2 col8\" >6.4</td>\n",
       "      <td id=\"T_d510b_row2_col9\" class=\"data row2 col9\" >35.4</td>\n",
       "      <td id=\"T_d510b_row2_col10\" class=\"data row2 col10\" >10.4</td>\n",
       "      <td id=\"T_d510b_row2_col11\" class=\"data row2 col11\" >22.5</td>\n",
       "      <td id=\"T_d510b_row2_col12\" class=\"data row2 col12\" >298.0</td>\n",
       "      <td id=\"T_d510b_row2_col13\" class=\"data row2 col13\" >33.6</td>\n",
       "      <td id=\"T_d510b_row2_col14\" class=\"data row2 col14\" >18.1</td>\n",
       "      <td id=\"T_d510b_row2_col15\" class=\"data row2 col15\" >25.9</td>\n",
       "      <td id=\"T_d510b_row2_col16\" class=\"data row2 col16\" >42.6</td>\n",
       "      <td id=\"T_d510b_row2_col17\" class=\"data row2 col17\" >-48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d510b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d510b_row3_col0\" class=\"data row3 col0\" >llama-7b_dolly_ep=3</td>\n",
       "      <td id=\"T_d510b_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_d510b_row3_col2\" class=\"data row3 col2\" >38.7</td>\n",
       "      <td id=\"T_d510b_row3_col3\" class=\"data row3 col3\" >37.9</td>\n",
       "      <td id=\"T_d510b_row3_col4\" class=\"data row3 col4\" >5.0</td>\n",
       "      <td id=\"T_d510b_row3_col5\" class=\"data row3 col5\" >9.8</td>\n",
       "      <td id=\"T_d510b_row3_col6\" class=\"data row3 col6\" >34.1</td>\n",
       "      <td id=\"T_d510b_row3_col7\" class=\"data row3 col7\" >31.8</td>\n",
       "      <td id=\"T_d510b_row3_col8\" class=\"data row3 col8\" >8.4</td>\n",
       "      <td id=\"T_d510b_row3_col9\" class=\"data row3 col9\" >42.0</td>\n",
       "      <td id=\"T_d510b_row3_col10\" class=\"data row3 col10\" >9.1</td>\n",
       "      <td id=\"T_d510b_row3_col11\" class=\"data row3 col11\" >14.3</td>\n",
       "      <td id=\"T_d510b_row3_col12\" class=\"data row3 col12\" >215.5</td>\n",
       "      <td id=\"T_d510b_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_d510b_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_d510b_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_d510b_row3_col16\" class=\"data row3 col16\" >40.6</td>\n",
       "      <td id=\"T_d510b_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d510b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d510b_row4_col0\" class=\"data row4 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_d510b_row4_col1\" class=\"data row4 col1\" >10000</td>\n",
       "      <td id=\"T_d510b_row4_col2\" class=\"data row4 col2\" >33.3</td>\n",
       "      <td id=\"T_d510b_row4_col3\" class=\"data row4 col3\" >37.1</td>\n",
       "      <td id=\"T_d510b_row4_col4\" class=\"data row4 col4\" >4.6</td>\n",
       "      <td id=\"T_d510b_row4_col5\" class=\"data row4 col5\" >9.4</td>\n",
       "      <td id=\"T_d510b_row4_col6\" class=\"data row4 col6\" >31.4</td>\n",
       "      <td id=\"T_d510b_row4_col7\" class=\"data row4 col7\" >28.7</td>\n",
       "      <td id=\"T_d510b_row4_col8\" class=\"data row4 col8\" >7.3</td>\n",
       "      <td id=\"T_d510b_row4_col9\" class=\"data row4 col9\" >35.9</td>\n",
       "      <td id=\"T_d510b_row4_col10\" class=\"data row4 col10\" >7.5</td>\n",
       "      <td id=\"T_d510b_row4_col11\" class=\"data row4 col11\" >19.2</td>\n",
       "      <td id=\"T_d510b_row4_col12\" class=\"data row4 col12\" >172.6</td>\n",
       "      <td id=\"T_d510b_row4_col13\" class=\"data row4 col13\" >38.2</td>\n",
       "      <td id=\"T_d510b_row4_col14\" class=\"data row4 col14\" >20.0</td>\n",
       "      <td id=\"T_d510b_row4_col15\" class=\"data row4 col15\" >29.1</td>\n",
       "      <td id=\"T_d510b_row4_col16\" class=\"data row4 col16\" >33.9</td>\n",
       "      <td id=\"T_d510b_row4_col17\" class=\"data row4 col17\" >-52.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d510b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d510b_row5_col0\" class=\"data row5 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_d510b_row5_col1\" class=\"data row5 col1\" >10000</td>\n",
       "      <td id=\"T_d510b_row5_col2\" class=\"data row5 col2\" >30.9</td>\n",
       "      <td id=\"T_d510b_row5_col3\" class=\"data row5 col3\" >34.8</td>\n",
       "      <td id=\"T_d510b_row5_col4\" class=\"data row5 col4\" >5.0</td>\n",
       "      <td id=\"T_d510b_row5_col5\" class=\"data row5 col5\" >8.4</td>\n",
       "      <td id=\"T_d510b_row5_col6\" class=\"data row5 col6\" >32.9</td>\n",
       "      <td id=\"T_d510b_row5_col7\" class=\"data row5 col7\" >25.7</td>\n",
       "      <td id=\"T_d510b_row5_col8\" class=\"data row5 col8\" >8.0</td>\n",
       "      <td id=\"T_d510b_row5_col9\" class=\"data row5 col9\" >41.0</td>\n",
       "      <td id=\"T_d510b_row5_col10\" class=\"data row5 col10\" >7.9</td>\n",
       "      <td id=\"T_d510b_row5_col11\" class=\"data row5 col11\" >15.5</td>\n",
       "      <td id=\"T_d510b_row5_col12\" class=\"data row5 col12\" >101.5</td>\n",
       "      <td id=\"T_d510b_row5_col13\" class=\"data row5 col13\" >33.2</td>\n",
       "      <td id=\"T_d510b_row5_col14\" class=\"data row5 col14\" >17.7</td>\n",
       "      <td id=\"T_d510b_row5_col15\" class=\"data row5 col15\" >25.5</td>\n",
       "      <td id=\"T_d510b_row5_col16\" class=\"data row5 col16\" >27.7</td>\n",
       "      <td id=\"T_d510b_row5_col17\" class=\"data row5 col17\" >-53.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf6987970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3bb1f td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_3bb1f_row0_col0, #T_3bb1f_row1_col0, #T_3bb1f_row2_col0, #T_3bb1f_row3_col0, #T_3bb1f_row4_col0, #T_3bb1f_row5_col0, #T_3bb1f_row6_col0, #T_3bb1f_row7_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3bb1f_row0_col1, #T_3bb1f_row1_col1, #T_3bb1f_row2_col1, #T_3bb1f_row3_col1, #T_3bb1f_row4_col1, #T_3bb1f_row5_col1, #T_3bb1f_row6_col1, #T_3bb1f_row7_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3bb1f_row0_col2, #T_3bb1f_row0_col3, #T_3bb1f_row0_col6, #T_3bb1f_row0_col11, #T_3bb1f_row1_col13, #T_3bb1f_row1_col14, #T_3bb1f_row1_col15, #T_3bb1f_row3_col9, #T_3bb1f_row4_col4, #T_3bb1f_row4_col5, #T_3bb1f_row4_col17, #T_3bb1f_row5_col10, #T_3bb1f_row6_col8, #T_3bb1f_row7_col7, #T_3bb1f_row7_col12, #T_3bb1f_row7_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row0_col4, #T_3bb1f_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row0_col8, #T_3bb1f_row0_col12, #T_3bb1f_row0_col16, #T_3bb1f_row1_col9, #T_3bb1f_row1_col17, #T_3bb1f_row2_col10, #T_3bb1f_row2_col14, #T_3bb1f_row3_col3, #T_3bb1f_row3_col4, #T_3bb1f_row3_col7, #T_3bb1f_row3_col11, #T_3bb1f_row4_col6, #T_3bb1f_row4_col13, #T_3bb1f_row4_col15, #T_3bb1f_row5_col2, #T_3bb1f_row5_col6, #T_3bb1f_row6_col5, #T_3bb1f_row7_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row0_col13, #T_3bb1f_row0_col14, #T_3bb1f_row0_col15, #T_3bb1f_row0_col17, #T_3bb1f_row5_col13, #T_3bb1f_row5_col14, #T_3bb1f_row5_col15, #T_3bb1f_row5_col17, #T_3bb1f_row6_col13, #T_3bb1f_row6_col14, #T_3bb1f_row6_col15, #T_3bb1f_row6_col17, #T_3bb1f_row7_col13, #T_3bb1f_row7_col14, #T_3bb1f_row7_col15, #T_3bb1f_row7_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row1_col2, #T_3bb1f_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row1_col10, #T_3bb1f_row3_col10, #T_3bb1f_row6_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row1_col11, #T_3bb1f_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row1_col12, #T_3bb1f_row5_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row2_col5, #T_3bb1f_row7_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row2_col7, #T_3bb1f_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f2c9b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row2_col9, #T_3bb1f_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row2_col11, #T_3bb1f_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row2_col16, #T_3bb1f_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row3_col5, #T_3bb1f_row5_col12, #T_3bb1f_row6_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row3_col12, #T_3bb1f_row4_col12, #T_3bb1f_row6_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row3_col15, #T_3bb1f_row7_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row4_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row4_col16, #T_3bb1f_row5_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row5_col4, #T_3bb1f_row7_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row6_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row6_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row6_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row6_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row6_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row6_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row6_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3bb1f_row7_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row7_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row7_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row7_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3bb1f_row7_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3bb1f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3bb1f_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_3bb1f_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_3bb1f_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_3bb1f_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_3bb1f_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_3bb1f_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_3bb1f_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_3bb1f_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_3bb1f_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_3bb1f_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_3bb1f_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_3bb1f_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_3bb1f_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_3bb1f_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_3bb1f_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_3bb1f_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_3bb1f_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_3bb1f_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3bb1f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3bb1f_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_3bb1f_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_3bb1f_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_3bb1f_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_3bb1f_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_3bb1f_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_3bb1f_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_3bb1f_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_3bb1f_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_3bb1f_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_3bb1f_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_3bb1f_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_3bb1f_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_3bb1f_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_3bb1f_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_3bb1f_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_3bb1f_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_3bb1f_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bb1f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3bb1f_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_3bb1f_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_3bb1f_row1_col2\" class=\"data row1 col2\" >38.5</td>\n",
       "      <td id=\"T_3bb1f_row1_col3\" class=\"data row1 col3\" >38.5</td>\n",
       "      <td id=\"T_3bb1f_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_3bb1f_row1_col5\" class=\"data row1 col5\" >10.8</td>\n",
       "      <td id=\"T_3bb1f_row1_col6\" class=\"data row1 col6\" >34.0</td>\n",
       "      <td id=\"T_3bb1f_row1_col7\" class=\"data row1 col7\" >31.3</td>\n",
       "      <td id=\"T_3bb1f_row1_col8\" class=\"data row1 col8\" >9.0</td>\n",
       "      <td id=\"T_3bb1f_row1_col9\" class=\"data row1 col9\" >44.0</td>\n",
       "      <td id=\"T_3bb1f_row1_col10\" class=\"data row1 col10\" >10.4</td>\n",
       "      <td id=\"T_3bb1f_row1_col11\" class=\"data row1 col11\" >11.1</td>\n",
       "      <td id=\"T_3bb1f_row1_col12\" class=\"data row1 col12\" >319.7</td>\n",
       "      <td id=\"T_3bb1f_row1_col13\" class=\"data row1 col13\" >34.0</td>\n",
       "      <td id=\"T_3bb1f_row1_col14\" class=\"data row1 col14\" >16.8</td>\n",
       "      <td id=\"T_3bb1f_row1_col15\" class=\"data row1 col15\" >25.5</td>\n",
       "      <td id=\"T_3bb1f_row1_col16\" class=\"data row1 col16\" >44.9</td>\n",
       "      <td id=\"T_3bb1f_row1_col17\" class=\"data row1 col17\" >-31.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bb1f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3bb1f_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_3bb1f_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_3bb1f_row2_col2\" class=\"data row2 col2\" >36.1</td>\n",
       "      <td id=\"T_3bb1f_row2_col3\" class=\"data row2 col3\" >35.0</td>\n",
       "      <td id=\"T_3bb1f_row2_col4\" class=\"data row2 col4\" >4.4</td>\n",
       "      <td id=\"T_3bb1f_row2_col5\" class=\"data row2 col5\" >10.2</td>\n",
       "      <td id=\"T_3bb1f_row2_col6\" class=\"data row2 col6\" >31.2</td>\n",
       "      <td id=\"T_3bb1f_row2_col7\" class=\"data row2 col7\" >30.3</td>\n",
       "      <td id=\"T_3bb1f_row2_col8\" class=\"data row2 col8\" >8.6</td>\n",
       "      <td id=\"T_3bb1f_row2_col9\" class=\"data row2 col9\" >42.1</td>\n",
       "      <td id=\"T_3bb1f_row2_col10\" class=\"data row2 col10\" >11.6</td>\n",
       "      <td id=\"T_3bb1f_row2_col11\" class=\"data row2 col11\" >12.0</td>\n",
       "      <td id=\"T_3bb1f_row2_col12\" class=\"data row2 col12\" >277.6</td>\n",
       "      <td id=\"T_3bb1f_row2_col13\" class=\"data row2 col13\" >35.8</td>\n",
       "      <td id=\"T_3bb1f_row2_col14\" class=\"data row2 col14\" >19.7</td>\n",
       "      <td id=\"T_3bb1f_row2_col15\" class=\"data row2 col15\" >27.8</td>\n",
       "      <td id=\"T_3bb1f_row2_col16\" class=\"data row2 col16\" >41.6</td>\n",
       "      <td id=\"T_3bb1f_row2_col17\" class=\"data row2 col17\" >-42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bb1f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3bb1f_row3_col0\" class=\"data row3 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_3bb1f_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_3bb1f_row3_col2\" class=\"data row3 col2\" >36.6</td>\n",
       "      <td id=\"T_3bb1f_row3_col3\" class=\"data row3 col3\" >39.2</td>\n",
       "      <td id=\"T_3bb1f_row3_col4\" class=\"data row3 col4\" >5.6</td>\n",
       "      <td id=\"T_3bb1f_row3_col5\" class=\"data row3 col5\" >9.6</td>\n",
       "      <td id=\"T_3bb1f_row3_col6\" class=\"data row3 col6\" >33.5</td>\n",
       "      <td id=\"T_3bb1f_row3_col7\" class=\"data row3 col7\" >33.1</td>\n",
       "      <td id=\"T_3bb1f_row3_col8\" class=\"data row3 col8\" >7.5</td>\n",
       "      <td id=\"T_3bb1f_row3_col9\" class=\"data row3 col9\" >37.7</td>\n",
       "      <td id=\"T_3bb1f_row3_col10\" class=\"data row3 col10\" >10.4</td>\n",
       "      <td id=\"T_3bb1f_row3_col11\" class=\"data row3 col11\" >17.6</td>\n",
       "      <td id=\"T_3bb1f_row3_col12\" class=\"data row3 col12\" >263.1</td>\n",
       "      <td id=\"T_3bb1f_row3_col13\" class=\"data row3 col13\" >38.5</td>\n",
       "      <td id=\"T_3bb1f_row3_col14\" class=\"data row3 col14\" >19.5</td>\n",
       "      <td id=\"T_3bb1f_row3_col15\" class=\"data row3 col15\" >29.1</td>\n",
       "      <td id=\"T_3bb1f_row3_col16\" class=\"data row3 col16\" >41.5</td>\n",
       "      <td id=\"T_3bb1f_row3_col17\" class=\"data row3 col17\" >-37.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bb1f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3bb1f_row4_col0\" class=\"data row4 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_3bb1f_row4_col1\" class=\"data row4 col1\" >30000</td>\n",
       "      <td id=\"T_3bb1f_row4_col2\" class=\"data row4 col2\" >36.9</td>\n",
       "      <td id=\"T_3bb1f_row4_col3\" class=\"data row4 col3\" >37.1</td>\n",
       "      <td id=\"T_3bb1f_row4_col4\" class=\"data row4 col4\" >3.0</td>\n",
       "      <td id=\"T_3bb1f_row4_col5\" class=\"data row4 col5\" >9.4</td>\n",
       "      <td id=\"T_3bb1f_row4_col6\" class=\"data row4 col6\" >34.1</td>\n",
       "      <td id=\"T_3bb1f_row4_col7\" class=\"data row4 col7\" >30.3</td>\n",
       "      <td id=\"T_3bb1f_row4_col8\" class=\"data row4 col8\" >8.0</td>\n",
       "      <td id=\"T_3bb1f_row4_col9\" class=\"data row4 col9\" >40.9</td>\n",
       "      <td id=\"T_3bb1f_row4_col10\" class=\"data row4 col10\" >10.6</td>\n",
       "      <td id=\"T_3bb1f_row4_col11\" class=\"data row4 col11\" >13.9</td>\n",
       "      <td id=\"T_3bb1f_row4_col12\" class=\"data row4 col12\" >260.5</td>\n",
       "      <td id=\"T_3bb1f_row4_col13\" class=\"data row4 col13\" >40.1</td>\n",
       "      <td id=\"T_3bb1f_row4_col14\" class=\"data row4 col14\" >18.2</td>\n",
       "      <td id=\"T_3bb1f_row4_col15\" class=\"data row4 col15\" >29.4</td>\n",
       "      <td id=\"T_3bb1f_row4_col16\" class=\"data row4 col16\" >40.9</td>\n",
       "      <td id=\"T_3bb1f_row4_col17\" class=\"data row4 col17\" >-42.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bb1f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3bb1f_row5_col0\" class=\"data row5 col0\" >llama-7b_dolly_ep=3</td>\n",
       "      <td id=\"T_3bb1f_row5_col1\" class=\"data row5 col1\" >None</td>\n",
       "      <td id=\"T_3bb1f_row5_col2\" class=\"data row5 col2\" >38.7</td>\n",
       "      <td id=\"T_3bb1f_row5_col3\" class=\"data row5 col3\" >37.9</td>\n",
       "      <td id=\"T_3bb1f_row5_col4\" class=\"data row5 col4\" >5.0</td>\n",
       "      <td id=\"T_3bb1f_row5_col5\" class=\"data row5 col5\" >9.8</td>\n",
       "      <td id=\"T_3bb1f_row5_col6\" class=\"data row5 col6\" >34.1</td>\n",
       "      <td id=\"T_3bb1f_row5_col7\" class=\"data row5 col7\" >31.8</td>\n",
       "      <td id=\"T_3bb1f_row5_col8\" class=\"data row5 col8\" >8.4</td>\n",
       "      <td id=\"T_3bb1f_row5_col9\" class=\"data row5 col9\" >42.0</td>\n",
       "      <td id=\"T_3bb1f_row5_col10\" class=\"data row5 col10\" >9.1</td>\n",
       "      <td id=\"T_3bb1f_row5_col11\" class=\"data row5 col11\" >14.3</td>\n",
       "      <td id=\"T_3bb1f_row5_col12\" class=\"data row5 col12\" >215.5</td>\n",
       "      <td id=\"T_3bb1f_row5_col13\" class=\"data row5 col13\" >nan</td>\n",
       "      <td id=\"T_3bb1f_row5_col14\" class=\"data row5 col14\" >nan</td>\n",
       "      <td id=\"T_3bb1f_row5_col15\" class=\"data row5 col15\" >nan</td>\n",
       "      <td id=\"T_3bb1f_row5_col16\" class=\"data row5 col16\" >40.6</td>\n",
       "      <td id=\"T_3bb1f_row5_col17\" class=\"data row5 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bb1f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3bb1f_row6_col0\" class=\"data row6 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_3bb1f_row6_col1\" class=\"data row6 col1\" >30000</td>\n",
       "      <td id=\"T_3bb1f_row6_col2\" class=\"data row6 col2\" >36.6</td>\n",
       "      <td id=\"T_3bb1f_row6_col3\" class=\"data row6 col3\" >37.2</td>\n",
       "      <td id=\"T_3bb1f_row6_col4\" class=\"data row6 col4\" >4.0</td>\n",
       "      <td id=\"T_3bb1f_row6_col5\" class=\"data row6 col5\" >13.0</td>\n",
       "      <td id=\"T_3bb1f_row6_col6\" class=\"data row6 col6\" >30.9</td>\n",
       "      <td id=\"T_3bb1f_row6_col7\" class=\"data row6 col7\" >31.5</td>\n",
       "      <td id=\"T_3bb1f_row6_col8\" class=\"data row6 col8\" >7.0</td>\n",
       "      <td id=\"T_3bb1f_row6_col9\" class=\"data row6 col9\" >41.3</td>\n",
       "      <td id=\"T_3bb1f_row6_col10\" class=\"data row6 col10\" >10.4</td>\n",
       "      <td id=\"T_3bb1f_row6_col11\" class=\"data row6 col11\" >15.0</td>\n",
       "      <td id=\"T_3bb1f_row6_col12\" class=\"data row6 col12\" >214.2</td>\n",
       "      <td id=\"T_3bb1f_row6_col13\" class=\"data row6 col13\" >nan</td>\n",
       "      <td id=\"T_3bb1f_row6_col14\" class=\"data row6 col14\" >nan</td>\n",
       "      <td id=\"T_3bb1f_row6_col15\" class=\"data row6 col15\" >nan</td>\n",
       "      <td id=\"T_3bb1f_row6_col16\" class=\"data row6 col16\" >40.1</td>\n",
       "      <td id=\"T_3bb1f_row6_col17\" class=\"data row6 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bb1f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3bb1f_row7_col0\" class=\"data row7 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-2:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_3bb1f_row7_col1\" class=\"data row7 col1\" >30000</td>\n",
       "      <td id=\"T_3bb1f_row7_col2\" class=\"data row7 col2\" >38.1</td>\n",
       "      <td id=\"T_3bb1f_row7_col3\" class=\"data row7 col3\" >37.1</td>\n",
       "      <td id=\"T_3bb1f_row7_col4\" class=\"data row7 col4\" >5.0</td>\n",
       "      <td id=\"T_3bb1f_row7_col5\" class=\"data row7 col5\" >10.2</td>\n",
       "      <td id=\"T_3bb1f_row7_col6\" class=\"data row7 col6\" >32.0</td>\n",
       "      <td id=\"T_3bb1f_row7_col7\" class=\"data row7 col7\" >28.1</td>\n",
       "      <td id=\"T_3bb1f_row7_col8\" class=\"data row7 col8\" >8.4</td>\n",
       "      <td id=\"T_3bb1f_row7_col9\" class=\"data row7 col9\" >40.4</td>\n",
       "      <td id=\"T_3bb1f_row7_col10\" class=\"data row7 col10\" >11.6</td>\n",
       "      <td id=\"T_3bb1f_row7_col11\" class=\"data row7 col11\" >14.0</td>\n",
       "      <td id=\"T_3bb1f_row7_col12\" class=\"data row7 col12\" >112.2</td>\n",
       "      <td id=\"T_3bb1f_row7_col13\" class=\"data row7 col13\" >nan</td>\n",
       "      <td id=\"T_3bb1f_row7_col14\" class=\"data row7 col14\" >nan</td>\n",
       "      <td id=\"T_3bb1f_row7_col15\" class=\"data row7 col15\" >nan</td>\n",
       "      <td id=\"T_3bb1f_row7_col16\" class=\"data row7 col16\" >30.6</td>\n",
       "      <td id=\"T_3bb1f_row7_col17\" class=\"data row7 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf5fe65c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9c7c5 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_9c7c5_row0_col0, #T_9c7c5_row1_col0, #T_9c7c5_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9c7c5_row0_col1, #T_9c7c5_row1_col1, #T_9c7c5_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9c7c5_row0_col2, #T_9c7c5_row0_col3, #T_9c7c5_row0_col6, #T_9c7c5_row0_col9, #T_9c7c5_row0_col11, #T_9c7c5_row0_col13, #T_9c7c5_row0_col14, #T_9c7c5_row0_col15, #T_9c7c5_row0_col17, #T_9c7c5_row1_col7, #T_9c7c5_row1_col13, #T_9c7c5_row1_col14, #T_9c7c5_row1_col15, #T_9c7c5_row1_col17, #T_9c7c5_row2_col4, #T_9c7c5_row2_col5, #T_9c7c5_row2_col8, #T_9c7c5_row2_col10, #T_9c7c5_row2_col12, #T_9c7c5_row2_col13, #T_9c7c5_row2_col14, #T_9c7c5_row2_col15, #T_9c7c5_row2_col16, #T_9c7c5_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9c7c5_row0_col4, #T_9c7c5_row0_col5, #T_9c7c5_row0_col7, #T_9c7c5_row0_col8, #T_9c7c5_row0_col12, #T_9c7c5_row0_col16, #T_9c7c5_row1_col3, #T_9c7c5_row1_col4, #T_9c7c5_row1_col9, #T_9c7c5_row1_col10, #T_9c7c5_row2_col2, #T_9c7c5_row2_col6, #T_9c7c5_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9c7c5_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9c7c5_row1_col2, #T_9c7c5_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9c7c5_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9c7c5_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9c7c5_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9c7c5_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9c7c5_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9c7c5_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9c7c5_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9c7c5_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9c7c5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9c7c5_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_9c7c5_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_9c7c5_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_9c7c5_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_9c7c5_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_9c7c5_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_9c7c5_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_9c7c5_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_9c7c5_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_9c7c5_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_9c7c5_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_9c7c5_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_9c7c5_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_9c7c5_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_9c7c5_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_9c7c5_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_9c7c5_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_9c7c5_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9c7c5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9c7c5_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_9c7c5_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_9c7c5_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_9c7c5_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_9c7c5_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_9c7c5_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_9c7c5_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_9c7c5_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_9c7c5_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_9c7c5_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_9c7c5_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_9c7c5_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_9c7c5_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_9c7c5_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_9c7c5_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_9c7c5_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_9c7c5_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_9c7c5_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c7c5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9c7c5_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_9c7c5_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_9c7c5_row1_col2\" class=\"data row1 col2\" >38.5</td>\n",
       "      <td id=\"T_9c7c5_row1_col3\" class=\"data row1 col3\" >38.5</td>\n",
       "      <td id=\"T_9c7c5_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_9c7c5_row1_col5\" class=\"data row1 col5\" >10.8</td>\n",
       "      <td id=\"T_9c7c5_row1_col6\" class=\"data row1 col6\" >34.0</td>\n",
       "      <td id=\"T_9c7c5_row1_col7\" class=\"data row1 col7\" >31.3</td>\n",
       "      <td id=\"T_9c7c5_row1_col8\" class=\"data row1 col8\" >9.0</td>\n",
       "      <td id=\"T_9c7c5_row1_col9\" class=\"data row1 col9\" >44.0</td>\n",
       "      <td id=\"T_9c7c5_row1_col10\" class=\"data row1 col10\" >10.4</td>\n",
       "      <td id=\"T_9c7c5_row1_col11\" class=\"data row1 col11\" >11.1</td>\n",
       "      <td id=\"T_9c7c5_row1_col12\" class=\"data row1 col12\" >319.7</td>\n",
       "      <td id=\"T_9c7c5_row1_col13\" class=\"data row1 col13\" >34.0</td>\n",
       "      <td id=\"T_9c7c5_row1_col14\" class=\"data row1 col14\" >16.8</td>\n",
       "      <td id=\"T_9c7c5_row1_col15\" class=\"data row1 col15\" >25.5</td>\n",
       "      <td id=\"T_9c7c5_row1_col16\" class=\"data row1 col16\" >44.9</td>\n",
       "      <td id=\"T_9c7c5_row1_col17\" class=\"data row1 col17\" >-31.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9c7c5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9c7c5_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_ep=3</td>\n",
       "      <td id=\"T_9c7c5_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_9c7c5_row2_col2\" class=\"data row2 col2\" >38.7</td>\n",
       "      <td id=\"T_9c7c5_row2_col3\" class=\"data row2 col3\" >37.9</td>\n",
       "      <td id=\"T_9c7c5_row2_col4\" class=\"data row2 col4\" >5.0</td>\n",
       "      <td id=\"T_9c7c5_row2_col5\" class=\"data row2 col5\" >9.8</td>\n",
       "      <td id=\"T_9c7c5_row2_col6\" class=\"data row2 col6\" >34.1</td>\n",
       "      <td id=\"T_9c7c5_row2_col7\" class=\"data row2 col7\" >31.8</td>\n",
       "      <td id=\"T_9c7c5_row2_col8\" class=\"data row2 col8\" >8.4</td>\n",
       "      <td id=\"T_9c7c5_row2_col9\" class=\"data row2 col9\" >42.0</td>\n",
       "      <td id=\"T_9c7c5_row2_col10\" class=\"data row2 col10\" >9.1</td>\n",
       "      <td id=\"T_9c7c5_row2_col11\" class=\"data row2 col11\" >14.3</td>\n",
       "      <td id=\"T_9c7c5_row2_col12\" class=\"data row2 col12\" >215.5</td>\n",
       "      <td id=\"T_9c7c5_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_9c7c5_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_9c7c5_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_9c7c5_row2_col16\" class=\"data row2 col16\" >40.6</td>\n",
       "      <td id=\"T_9c7c5_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfee6b5e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_99169 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_99169_row0_col0, #T_99169_row1_col0, #T_99169_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_99169_row0_col1, #T_99169_row1_col1, #T_99169_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_99169_row0_col2, #T_99169_row0_col3, #T_99169_row0_col6, #T_99169_row0_col9, #T_99169_row0_col11, #T_99169_row0_col13, #T_99169_row0_col14, #T_99169_row0_col15, #T_99169_row0_col17, #T_99169_row1_col7, #T_99169_row1_col13, #T_99169_row1_col14, #T_99169_row1_col15, #T_99169_row1_col17, #T_99169_row2_col4, #T_99169_row2_col5, #T_99169_row2_col8, #T_99169_row2_col10, #T_99169_row2_col12, #T_99169_row2_col13, #T_99169_row2_col14, #T_99169_row2_col15, #T_99169_row2_col16, #T_99169_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_99169_row0_col4, #T_99169_row0_col5, #T_99169_row0_col7, #T_99169_row0_col8, #T_99169_row0_col12, #T_99169_row0_col16, #T_99169_row1_col3, #T_99169_row1_col4, #T_99169_row1_col9, #T_99169_row1_col10, #T_99169_row2_col2, #T_99169_row2_col6, #T_99169_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_99169_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_99169_row1_col2, #T_99169_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_99169_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_99169_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_99169_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_99169_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_99169_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_99169_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_99169_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_99169_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_99169\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_99169_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_99169_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_99169_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_99169_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_99169_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_99169_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_99169_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_99169_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_99169_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_99169_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_99169_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_99169_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_99169_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_99169_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_99169_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_99169_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_99169_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_99169_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_99169_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_99169_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_99169_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_99169_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_99169_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_99169_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_99169_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_99169_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_99169_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_99169_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_99169_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_99169_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_99169_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_99169_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_99169_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_99169_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_99169_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_99169_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_99169_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99169_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_99169_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_99169_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_99169_row1_col2\" class=\"data row1 col2\" >38.5</td>\n",
       "      <td id=\"T_99169_row1_col3\" class=\"data row1 col3\" >38.5</td>\n",
       "      <td id=\"T_99169_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_99169_row1_col5\" class=\"data row1 col5\" >10.8</td>\n",
       "      <td id=\"T_99169_row1_col6\" class=\"data row1 col6\" >34.0</td>\n",
       "      <td id=\"T_99169_row1_col7\" class=\"data row1 col7\" >31.3</td>\n",
       "      <td id=\"T_99169_row1_col8\" class=\"data row1 col8\" >9.0</td>\n",
       "      <td id=\"T_99169_row1_col9\" class=\"data row1 col9\" >44.0</td>\n",
       "      <td id=\"T_99169_row1_col10\" class=\"data row1 col10\" >10.4</td>\n",
       "      <td id=\"T_99169_row1_col11\" class=\"data row1 col11\" >11.1</td>\n",
       "      <td id=\"T_99169_row1_col12\" class=\"data row1 col12\" >319.7</td>\n",
       "      <td id=\"T_99169_row1_col13\" class=\"data row1 col13\" >34.0</td>\n",
       "      <td id=\"T_99169_row1_col14\" class=\"data row1 col14\" >16.8</td>\n",
       "      <td id=\"T_99169_row1_col15\" class=\"data row1 col15\" >25.5</td>\n",
       "      <td id=\"T_99169_row1_col16\" class=\"data row1 col16\" >44.9</td>\n",
       "      <td id=\"T_99169_row1_col17\" class=\"data row1 col17\" >-31.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99169_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_99169_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_ep=3</td>\n",
       "      <td id=\"T_99169_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_99169_row2_col2\" class=\"data row2 col2\" >38.7</td>\n",
       "      <td id=\"T_99169_row2_col3\" class=\"data row2 col3\" >37.9</td>\n",
       "      <td id=\"T_99169_row2_col4\" class=\"data row2 col4\" >5.0</td>\n",
       "      <td id=\"T_99169_row2_col5\" class=\"data row2 col5\" >9.8</td>\n",
       "      <td id=\"T_99169_row2_col6\" class=\"data row2 col6\" >34.1</td>\n",
       "      <td id=\"T_99169_row2_col7\" class=\"data row2 col7\" >31.8</td>\n",
       "      <td id=\"T_99169_row2_col8\" class=\"data row2 col8\" >8.4</td>\n",
       "      <td id=\"T_99169_row2_col9\" class=\"data row2 col9\" >42.0</td>\n",
       "      <td id=\"T_99169_row2_col10\" class=\"data row2 col10\" >9.1</td>\n",
       "      <td id=\"T_99169_row2_col11\" class=\"data row2 col11\" >14.3</td>\n",
       "      <td id=\"T_99169_row2_col12\" class=\"data row2 col12\" >215.5</td>\n",
       "      <td id=\"T_99169_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_99169_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_99169_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_99169_row2_col16\" class=\"data row2 col16\" >40.6</td>\n",
       "      <td id=\"T_99169_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfee6beb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1993c td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_1993c_row0_col0, #T_1993c_row1_col0, #T_1993c_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_1993c_row0_col1, #T_1993c_row1_col1, #T_1993c_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_1993c_row0_col2, #T_1993c_row0_col3, #T_1993c_row0_col6, #T_1993c_row0_col9, #T_1993c_row0_col11, #T_1993c_row0_col13, #T_1993c_row0_col14, #T_1993c_row0_col15, #T_1993c_row0_col17, #T_1993c_row1_col7, #T_1993c_row1_col13, #T_1993c_row1_col14, #T_1993c_row1_col15, #T_1993c_row1_col17, #T_1993c_row2_col4, #T_1993c_row2_col5, #T_1993c_row2_col8, #T_1993c_row2_col10, #T_1993c_row2_col12, #T_1993c_row2_col13, #T_1993c_row2_col14, #T_1993c_row2_col15, #T_1993c_row2_col16, #T_1993c_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1993c_row0_col4, #T_1993c_row0_col5, #T_1993c_row0_col7, #T_1993c_row0_col8, #T_1993c_row0_col12, #T_1993c_row0_col16, #T_1993c_row1_col3, #T_1993c_row1_col4, #T_1993c_row1_col9, #T_1993c_row1_col10, #T_1993c_row2_col2, #T_1993c_row2_col6, #T_1993c_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1993c_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1993c_row1_col2, #T_1993c_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1993c_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1993c_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1993c_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1993c_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1993c_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1993c_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1993c_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1993c_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1993c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1993c_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_1993c_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_1993c_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_1993c_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_1993c_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_1993c_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_1993c_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_1993c_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_1993c_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_1993c_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_1993c_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_1993c_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_1993c_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_1993c_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_1993c_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_1993c_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_1993c_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_1993c_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1993c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1993c_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_1993c_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_1993c_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_1993c_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_1993c_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_1993c_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_1993c_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_1993c_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_1993c_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_1993c_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_1993c_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_1993c_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_1993c_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_1993c_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_1993c_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_1993c_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_1993c_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_1993c_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1993c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1993c_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_1993c_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_1993c_row1_col2\" class=\"data row1 col2\" >38.5</td>\n",
       "      <td id=\"T_1993c_row1_col3\" class=\"data row1 col3\" >38.5</td>\n",
       "      <td id=\"T_1993c_row1_col4\" class=\"data row1 col4\" >5.4</td>\n",
       "      <td id=\"T_1993c_row1_col5\" class=\"data row1 col5\" >10.8</td>\n",
       "      <td id=\"T_1993c_row1_col6\" class=\"data row1 col6\" >34.0</td>\n",
       "      <td id=\"T_1993c_row1_col7\" class=\"data row1 col7\" >31.3</td>\n",
       "      <td id=\"T_1993c_row1_col8\" class=\"data row1 col8\" >9.0</td>\n",
       "      <td id=\"T_1993c_row1_col9\" class=\"data row1 col9\" >44.0</td>\n",
       "      <td id=\"T_1993c_row1_col10\" class=\"data row1 col10\" >10.4</td>\n",
       "      <td id=\"T_1993c_row1_col11\" class=\"data row1 col11\" >11.1</td>\n",
       "      <td id=\"T_1993c_row1_col12\" class=\"data row1 col12\" >319.7</td>\n",
       "      <td id=\"T_1993c_row1_col13\" class=\"data row1 col13\" >34.0</td>\n",
       "      <td id=\"T_1993c_row1_col14\" class=\"data row1 col14\" >16.8</td>\n",
       "      <td id=\"T_1993c_row1_col15\" class=\"data row1 col15\" >25.5</td>\n",
       "      <td id=\"T_1993c_row1_col16\" class=\"data row1 col16\" >44.9</td>\n",
       "      <td id=\"T_1993c_row1_col17\" class=\"data row1 col17\" >-31.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1993c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1993c_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_ep=3</td>\n",
       "      <td id=\"T_1993c_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_1993c_row2_col2\" class=\"data row2 col2\" >38.7</td>\n",
       "      <td id=\"T_1993c_row2_col3\" class=\"data row2 col3\" >37.9</td>\n",
       "      <td id=\"T_1993c_row2_col4\" class=\"data row2 col4\" >5.0</td>\n",
       "      <td id=\"T_1993c_row2_col5\" class=\"data row2 col5\" >9.8</td>\n",
       "      <td id=\"T_1993c_row2_col6\" class=\"data row2 col6\" >34.1</td>\n",
       "      <td id=\"T_1993c_row2_col7\" class=\"data row2 col7\" >31.8</td>\n",
       "      <td id=\"T_1993c_row2_col8\" class=\"data row2 col8\" >8.4</td>\n",
       "      <td id=\"T_1993c_row2_col9\" class=\"data row2 col9\" >42.0</td>\n",
       "      <td id=\"T_1993c_row2_col10\" class=\"data row2 col10\" >9.1</td>\n",
       "      <td id=\"T_1993c_row2_col11\" class=\"data row2 col11\" >14.3</td>\n",
       "      <td id=\"T_1993c_row2_col12\" class=\"data row2 col12\" >215.5</td>\n",
       "      <td id=\"T_1993c_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_1993c_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_1993c_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_1993c_row2_col16\" class=\"data row2 col16\" >40.6</td>\n",
       "      <td id=\"T_1993c_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfe68b400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cbe5e td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_cbe5e_row0_col0, #T_cbe5e_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_cbe5e_row0_col1, #T_cbe5e_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_cbe5e_row0_col2, #T_cbe5e_row0_col3, #T_cbe5e_row0_col5, #T_cbe5e_row0_col6, #T_cbe5e_row0_col7, #T_cbe5e_row0_col9, #T_cbe5e_row0_col11, #T_cbe5e_row1_col4, #T_cbe5e_row1_col5, #T_cbe5e_row1_col8, #T_cbe5e_row1_col10, #T_cbe5e_row1_col12, #T_cbe5e_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cbe5e_row0_col4, #T_cbe5e_row0_col8, #T_cbe5e_row0_col10, #T_cbe5e_row0_col12, #T_cbe5e_row0_col16, #T_cbe5e_row1_col2, #T_cbe5e_row1_col3, #T_cbe5e_row1_col6, #T_cbe5e_row1_col7, #T_cbe5e_row1_col9, #T_cbe5e_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cbe5e_row0_col13, #T_cbe5e_row0_col14, #T_cbe5e_row0_col15, #T_cbe5e_row0_col17, #T_cbe5e_row1_col13, #T_cbe5e_row1_col14, #T_cbe5e_row1_col15, #T_cbe5e_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cbe5e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cbe5e_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_cbe5e_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_cbe5e_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_cbe5e_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_cbe5e_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_cbe5e_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_cbe5e_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_cbe5e_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_cbe5e_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_cbe5e_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_cbe5e_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_cbe5e_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_cbe5e_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_cbe5e_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_cbe5e_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_cbe5e_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_cbe5e_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_cbe5e_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cbe5e_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_cbe5e_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_cbe5e_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_cbe5e_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_cbe5e_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_cbe5e_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_cbe5e_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_cbe5e_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_cbe5e_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_cbe5e_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_cbe5e_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_cbe5e_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_cbe5e_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_cbe5e_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_cbe5e_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_cbe5e_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_cbe5e_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_cbe5e_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbe5e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cbe5e_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_cbe5e_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_cbe5e_row1_col2\" class=\"data row1 col2\" >44.3</td>\n",
       "      <td id=\"T_cbe5e_row1_col3\" class=\"data row1 col3\" >45.7</td>\n",
       "      <td id=\"T_cbe5e_row1_col4\" class=\"data row1 col4\" >3.0</td>\n",
       "      <td id=\"T_cbe5e_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_cbe5e_row1_col6\" class=\"data row1 col6\" >36.8</td>\n",
       "      <td id=\"T_cbe5e_row1_col7\" class=\"data row1 col7\" >34.4</td>\n",
       "      <td id=\"T_cbe5e_row1_col8\" class=\"data row1 col8\" >8.4</td>\n",
       "      <td id=\"T_cbe5e_row1_col9\" class=\"data row1 col9\" >43.3</td>\n",
       "      <td id=\"T_cbe5e_row1_col10\" class=\"data row1 col10\" >8.5</td>\n",
       "      <td id=\"T_cbe5e_row1_col11\" class=\"data row1 col11\" >4.2</td>\n",
       "      <td id=\"T_cbe5e_row1_col12\" class=\"data row1 col12\" >101.4</td>\n",
       "      <td id=\"T_cbe5e_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_cbe5e_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_cbe5e_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_cbe5e_row1_col16\" class=\"data row1 col16\" >31.1</td>\n",
       "      <td id=\"T_cbe5e_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf5378580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0c016 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_0c016_row0_col0, #T_0c016_row1_col0, #T_0c016_row2_col0, #T_0c016_row3_col0, #T_0c016_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0c016_row0_col1, #T_0c016_row1_col1, #T_0c016_row2_col1, #T_0c016_row3_col1, #T_0c016_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0c016_row0_col2, #T_0c016_row0_col6, #T_0c016_row0_col11, #T_0c016_row1_col4, #T_0c016_row1_col10, #T_0c016_row2_col3, #T_0c016_row3_col12, #T_0c016_row3_col13, #T_0c016_row3_col15, #T_0c016_row3_col16, #T_0c016_row4_col5, #T_0c016_row4_col7, #T_0c016_row4_col8, #T_0c016_row4_col9, #T_0c016_row4_col12, #T_0c016_row4_col14, #T_0c016_row4_col16, #T_0c016_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row0_col3, #T_0c016_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row0_col5, #T_0c016_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row0_col8, #T_0c016_row0_col12, #T_0c016_row0_col16, #T_0c016_row1_col2, #T_0c016_row1_col3, #T_0c016_row1_col6, #T_0c016_row1_col7, #T_0c016_row1_col9, #T_0c016_row2_col5, #T_0c016_row2_col10, #T_0c016_row2_col11, #T_0c016_row2_col15, #T_0c016_row3_col4, #T_0c016_row3_col14, #T_0c016_row3_col17, #T_0c016_row4_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row0_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row0_col13, #T_0c016_row0_col14, #T_0c016_row0_col15, #T_0c016_row0_col17, #T_0c016_row1_col13, #T_0c016_row1_col14, #T_0c016_row1_col15, #T_0c016_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row2_col9, #T_0c016_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row2_col17, #T_0c016_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0c016_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0c016_row4_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0c016\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0c016_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_0c016_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_0c016_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_0c016_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_0c016_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_0c016_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_0c016_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_0c016_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_0c016_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_0c016_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_0c016_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_0c016_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_0c016_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_0c016_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_0c016_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_0c016_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_0c016_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_0c016_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0c016_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0c016_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_0c016_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_0c016_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_0c016_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_0c016_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_0c016_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_0c016_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_0c016_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_0c016_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_0c016_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_0c016_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_0c016_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_0c016_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_0c016_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_0c016_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_0c016_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_0c016_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_0c016_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c016_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0c016_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_0c016_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_0c016_row1_col2\" class=\"data row1 col2\" >44.3</td>\n",
       "      <td id=\"T_0c016_row1_col3\" class=\"data row1 col3\" >45.7</td>\n",
       "      <td id=\"T_0c016_row1_col4\" class=\"data row1 col4\" >3.0</td>\n",
       "      <td id=\"T_0c016_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_0c016_row1_col6\" class=\"data row1 col6\" >36.8</td>\n",
       "      <td id=\"T_0c016_row1_col7\" class=\"data row1 col7\" >34.4</td>\n",
       "      <td id=\"T_0c016_row1_col8\" class=\"data row1 col8\" >8.4</td>\n",
       "      <td id=\"T_0c016_row1_col9\" class=\"data row1 col9\" >43.3</td>\n",
       "      <td id=\"T_0c016_row1_col10\" class=\"data row1 col10\" >8.5</td>\n",
       "      <td id=\"T_0c016_row1_col11\" class=\"data row1 col11\" >4.2</td>\n",
       "      <td id=\"T_0c016_row1_col12\" class=\"data row1 col12\" >101.4</td>\n",
       "      <td id=\"T_0c016_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_0c016_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_0c016_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_0c016_row1_col16\" class=\"data row1 col16\" >31.1</td>\n",
       "      <td id=\"T_0c016_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c016_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0c016_row2_col0\" class=\"data row2 col0\" >llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_0c016_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_0c016_row2_col2\" class=\"data row2 col2\" >34.9</td>\n",
       "      <td id=\"T_0c016_row2_col3\" class=\"data row2 col3\" >34.1</td>\n",
       "      <td id=\"T_0c016_row2_col4\" class=\"data row2 col4\" >5.0</td>\n",
       "      <td id=\"T_0c016_row2_col5\" class=\"data row2 col5\" >15.4</td>\n",
       "      <td id=\"T_0c016_row2_col6\" class=\"data row2 col6\" >31.7</td>\n",
       "      <td id=\"T_0c016_row2_col7\" class=\"data row2 col7\" >34.0</td>\n",
       "      <td id=\"T_0c016_row2_col8\" class=\"data row2 col8\" >8.9</td>\n",
       "      <td id=\"T_0c016_row2_col9\" class=\"data row2 col9\" >42.2</td>\n",
       "      <td id=\"T_0c016_row2_col10\" class=\"data row2 col10\" >10.6</td>\n",
       "      <td id=\"T_0c016_row2_col11\" class=\"data row2 col11\" >7.8</td>\n",
       "      <td id=\"T_0c016_row2_col12\" class=\"data row2 col12\" >140.7</td>\n",
       "      <td id=\"T_0c016_row2_col13\" class=\"data row2 col13\" >24.6</td>\n",
       "      <td id=\"T_0c016_row2_col14\" class=\"data row2 col14\" >18.0</td>\n",
       "      <td id=\"T_0c016_row2_col15\" class=\"data row2 col15\" >21.3</td>\n",
       "      <td id=\"T_0c016_row2_col16\" class=\"data row2 col16\" >30.7</td>\n",
       "      <td id=\"T_0c016_row2_col17\" class=\"data row2 col17\" >-40.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c016_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0c016_row3_col0\" class=\"data row3 col0\" >llama-7b_flan_v250k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_0c016_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_0c016_row3_col2\" class=\"data row3 col2\" >42.0</td>\n",
       "      <td id=\"T_0c016_row3_col3\" class=\"data row3 col3\" >42.2</td>\n",
       "      <td id=\"T_0c016_row3_col4\" class=\"data row3 col4\" >5.6</td>\n",
       "      <td id=\"T_0c016_row3_col5\" class=\"data row3 col5\" >12.0</td>\n",
       "      <td id=\"T_0c016_row3_col6\" class=\"data row3 col6\" >33.9</td>\n",
       "      <td id=\"T_0c016_row3_col7\" class=\"data row3 col7\" >33.3</td>\n",
       "      <td id=\"T_0c016_row3_col8\" class=\"data row3 col8\" >8.1</td>\n",
       "      <td id=\"T_0c016_row3_col9\" class=\"data row3 col9\" >38.6</td>\n",
       "      <td id=\"T_0c016_row3_col10\" class=\"data row3 col10\" >9.1</td>\n",
       "      <td id=\"T_0c016_row3_col11\" class=\"data row3 col11\" >5.1</td>\n",
       "      <td id=\"T_0c016_row3_col12\" class=\"data row3 col12\" >85.9</td>\n",
       "      <td id=\"T_0c016_row3_col13\" class=\"data row3 col13\" >23.5</td>\n",
       "      <td id=\"T_0c016_row3_col14\" class=\"data row3 col14\" >18.4</td>\n",
       "      <td id=\"T_0c016_row3_col15\" class=\"data row3 col15\" >20.9</td>\n",
       "      <td id=\"T_0c016_row3_col16\" class=\"data row3 col16\" >27.1</td>\n",
       "      <td id=\"T_0c016_row3_col17\" class=\"data row3 col17\" >-37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c016_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0c016_row4_col0\" class=\"data row4 col0\" >llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_0c016_row4_col1\" class=\"data row4 col1\" >30000</td>\n",
       "      <td id=\"T_0c016_row4_col2\" class=\"data row4 col2\" >41.6</td>\n",
       "      <td id=\"T_0c016_row4_col3\" class=\"data row4 col3\" >40.0</td>\n",
       "      <td id=\"T_0c016_row4_col4\" class=\"data row4 col4\" >3.4</td>\n",
       "      <td id=\"T_0c016_row4_col5\" class=\"data row4 col5\" >10.8</td>\n",
       "      <td id=\"T_0c016_row4_col6\" class=\"data row4 col6\" >36.2</td>\n",
       "      <td id=\"T_0c016_row4_col7\" class=\"data row4 col7\" >32.4</td>\n",
       "      <td id=\"T_0c016_row4_col8\" class=\"data row4 col8\" >7.4</td>\n",
       "      <td id=\"T_0c016_row4_col9\" class=\"data row4 col9\" >37.3</td>\n",
       "      <td id=\"T_0c016_row4_col10\" class=\"data row4 col10\" >8.9</td>\n",
       "      <td id=\"T_0c016_row4_col11\" class=\"data row4 col11\" >4.3</td>\n",
       "      <td id=\"T_0c016_row4_col12\" class=\"data row4 col12\" >90.2</td>\n",
       "      <td id=\"T_0c016_row4_col13\" class=\"data row4 col13\" >25.9</td>\n",
       "      <td id=\"T_0c016_row4_col14\" class=\"data row4 col14\" >16.2</td>\n",
       "      <td id=\"T_0c016_row4_col15\" class=\"data row4 col15\" >21.1</td>\n",
       "      <td id=\"T_0c016_row4_col16\" class=\"data row4 col16\" >26.8</td>\n",
       "      <td id=\"T_0c016_row4_col17\" class=\"data row4 col17\" >-45.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfd815b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_91f02 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_91f02_row0_col0, #T_91f02_row1_col0, #T_91f02_row2_col0, #T_91f02_row3_col0, #T_91f02_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_91f02_row0_col1, #T_91f02_row1_col1, #T_91f02_row2_col1, #T_91f02_row3_col1, #T_91f02_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_91f02_row0_col2, #T_91f02_row0_col3, #T_91f02_row0_col5, #T_91f02_row0_col6, #T_91f02_row0_col7, #T_91f02_row0_col9, #T_91f02_row0_col11, #T_91f02_row1_col4, #T_91f02_row1_col5, #T_91f02_row1_col10, #T_91f02_row1_col12, #T_91f02_row2_col8, #T_91f02_row2_col17, #T_91f02_row3_col12, #T_91f02_row3_col13, #T_91f02_row4_col7, #T_91f02_row4_col14, #T_91f02_row4_col15, #T_91f02_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row0_col4, #T_91f02_row0_col8, #T_91f02_row0_col10, #T_91f02_row0_col12, #T_91f02_row0_col16, #T_91f02_row1_col2, #T_91f02_row1_col3, #T_91f02_row1_col6, #T_91f02_row1_col9, #T_91f02_row2_col7, #T_91f02_row2_col11, #T_91f02_row2_col13, #T_91f02_row2_col15, #T_91f02_row3_col2, #T_91f02_row3_col5, #T_91f02_row3_col14, #T_91f02_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row0_col13, #T_91f02_row0_col14, #T_91f02_row0_col15, #T_91f02_row0_col17, #T_91f02_row1_col13, #T_91f02_row1_col14, #T_91f02_row1_col15, #T_91f02_row1_col17, #T_91f02_row4_col11, #T_91f02_row4_col12, #T_91f02_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c8b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row3_col10, #T_91f02_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d55042;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row4_col5, #T_91f02_row4_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_91f02_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_91f02_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_91f02\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_91f02_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_91f02_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_91f02_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_91f02_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_91f02_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_91f02_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_91f02_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_91f02_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_91f02_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_91f02_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_91f02_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_91f02_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_91f02_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_91f02_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_91f02_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_91f02_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_91f02_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_91f02_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_91f02_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_91f02_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_91f02_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_91f02_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_91f02_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_91f02_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_91f02_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_91f02_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_91f02_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_91f02_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_91f02_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_91f02_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_91f02_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_91f02_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_91f02_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_91f02_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_91f02_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_91f02_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_91f02_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91f02_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_91f02_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_91f02_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_91f02_row1_col2\" class=\"data row1 col2\" >44.3</td>\n",
       "      <td id=\"T_91f02_row1_col3\" class=\"data row1 col3\" >45.7</td>\n",
       "      <td id=\"T_91f02_row1_col4\" class=\"data row1 col4\" >3.0</td>\n",
       "      <td id=\"T_91f02_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_91f02_row1_col6\" class=\"data row1 col6\" >36.8</td>\n",
       "      <td id=\"T_91f02_row1_col7\" class=\"data row1 col7\" >34.4</td>\n",
       "      <td id=\"T_91f02_row1_col8\" class=\"data row1 col8\" >8.4</td>\n",
       "      <td id=\"T_91f02_row1_col9\" class=\"data row1 col9\" >43.3</td>\n",
       "      <td id=\"T_91f02_row1_col10\" class=\"data row1 col10\" >8.5</td>\n",
       "      <td id=\"T_91f02_row1_col11\" class=\"data row1 col11\" >4.2</td>\n",
       "      <td id=\"T_91f02_row1_col12\" class=\"data row1 col12\" >101.4</td>\n",
       "      <td id=\"T_91f02_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_91f02_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_91f02_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_91f02_row1_col16\" class=\"data row1 col16\" >31.1</td>\n",
       "      <td id=\"T_91f02_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91f02_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_91f02_row2_col0\" class=\"data row2 col0\" >llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_91f02_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_91f02_row2_col2\" class=\"data row2 col2\" >40.6</td>\n",
       "      <td id=\"T_91f02_row2_col3\" class=\"data row2 col3\" >41.1</td>\n",
       "      <td id=\"T_91f02_row2_col4\" class=\"data row2 col4\" >4.0</td>\n",
       "      <td id=\"T_91f02_row2_col5\" class=\"data row2 col5\" >12.4</td>\n",
       "      <td id=\"T_91f02_row2_col6\" class=\"data row2 col6\" >33.7</td>\n",
       "      <td id=\"T_91f02_row2_col7\" class=\"data row2 col7\" >35.6</td>\n",
       "      <td id=\"T_91f02_row2_col8\" class=\"data row2 col8\" >7.9</td>\n",
       "      <td id=\"T_91f02_row2_col9\" class=\"data row2 col9\" >40.4</td>\n",
       "      <td id=\"T_91f02_row2_col10\" class=\"data row2 col10\" >8.7</td>\n",
       "      <td id=\"T_91f02_row2_col11\" class=\"data row2 col11\" >5.3</td>\n",
       "      <td id=\"T_91f02_row2_col12\" class=\"data row2 col12\" >122.3</td>\n",
       "      <td id=\"T_91f02_row2_col13\" class=\"data row2 col13\" >24.0</td>\n",
       "      <td id=\"T_91f02_row2_col14\" class=\"data row2 col14\" >18.4</td>\n",
       "      <td id=\"T_91f02_row2_col15\" class=\"data row2 col15\" >21.2</td>\n",
       "      <td id=\"T_91f02_row2_col16\" class=\"data row2 col16\" >29.7</td>\n",
       "      <td id=\"T_91f02_row2_col17\" class=\"data row2 col17\" >-38.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91f02_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_91f02_row3_col0\" class=\"data row3 col0\" >llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_91f02_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_91f02_row3_col2\" class=\"data row3 col2\" >44.3</td>\n",
       "      <td id=\"T_91f02_row3_col3\" class=\"data row3 col3\" >45.1</td>\n",
       "      <td id=\"T_91f02_row3_col4\" class=\"data row3 col4\" >4.4</td>\n",
       "      <td id=\"T_91f02_row3_col5\" class=\"data row3 col5\" >14.8</td>\n",
       "      <td id=\"T_91f02_row3_col6\" class=\"data row3 col6\" >36.3</td>\n",
       "      <td id=\"T_91f02_row3_col7\" class=\"data row3 col7\" >34.3</td>\n",
       "      <td id=\"T_91f02_row3_col8\" class=\"data row3 col8\" >8.0</td>\n",
       "      <td id=\"T_91f02_row3_col9\" class=\"data row3 col9\" >40.2</td>\n",
       "      <td id=\"T_91f02_row3_col10\" class=\"data row3 col10\" >9.3</td>\n",
       "      <td id=\"T_91f02_row3_col11\" class=\"data row3 col11\" >4.8</td>\n",
       "      <td id=\"T_91f02_row3_col12\" class=\"data row3 col12\" >107.2</td>\n",
       "      <td id=\"T_91f02_row3_col13\" class=\"data row3 col13\" >22.1</td>\n",
       "      <td id=\"T_91f02_row3_col14\" class=\"data row3 col14\" >19.0</td>\n",
       "      <td id=\"T_91f02_row3_col15\" class=\"data row3 col15\" >20.6</td>\n",
       "      <td id=\"T_91f02_row3_col16\" class=\"data row3 col16\" >29.3</td>\n",
       "      <td id=\"T_91f02_row3_col17\" class=\"data row3 col17\" >-35.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91f02_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_91f02_row4_col0\" class=\"data row4 col0\" >llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_91f02_row4_col1\" class=\"data row4 col1\" >60000</td>\n",
       "      <td id=\"T_91f02_row4_col2\" class=\"data row4 col2\" >43.4</td>\n",
       "      <td id=\"T_91f02_row4_col3\" class=\"data row4 col3\" >41.5</td>\n",
       "      <td id=\"T_91f02_row4_col4\" class=\"data row4 col4\" >3.6</td>\n",
       "      <td id=\"T_91f02_row4_col5\" class=\"data row4 col5\" >12.6</td>\n",
       "      <td id=\"T_91f02_row4_col6\" class=\"data row4 col6\" >35.3</td>\n",
       "      <td id=\"T_91f02_row4_col7\" class=\"data row4 col7\" >32.7</td>\n",
       "      <td id=\"T_91f02_row4_col8\" class=\"data row4 col8\" >8.1</td>\n",
       "      <td id=\"T_91f02_row4_col9\" class=\"data row4 col9\" >42.8</td>\n",
       "      <td id=\"T_91f02_row4_col10\" class=\"data row4 col10\" >9.3</td>\n",
       "      <td id=\"T_91f02_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_91f02_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "      <td id=\"T_91f02_row4_col13\" class=\"data row4 col13\" >22.6</td>\n",
       "      <td id=\"T_91f02_row4_col14\" class=\"data row4 col14\" >15.9</td>\n",
       "      <td id=\"T_91f02_row4_col15\" class=\"data row4 col15\" >19.2</td>\n",
       "      <td id=\"T_91f02_row4_col16\" class=\"data row4 col16\" >23.9</td>\n",
       "      <td id=\"T_91f02_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf56cd300>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_12d54 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_12d54_row0_col0, #T_12d54_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_12d54_row0_col1, #T_12d54_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_12d54_row0_col2, #T_12d54_row0_col3, #T_12d54_row0_col5, #T_12d54_row0_col6, #T_12d54_row0_col7, #T_12d54_row0_col9, #T_12d54_row0_col11, #T_12d54_row1_col4, #T_12d54_row1_col5, #T_12d54_row1_col8, #T_12d54_row1_col10, #T_12d54_row1_col12, #T_12d54_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_12d54_row0_col4, #T_12d54_row0_col8, #T_12d54_row0_col10, #T_12d54_row0_col12, #T_12d54_row0_col16, #T_12d54_row1_col2, #T_12d54_row1_col3, #T_12d54_row1_col6, #T_12d54_row1_col7, #T_12d54_row1_col9, #T_12d54_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_12d54_row0_col13, #T_12d54_row0_col14, #T_12d54_row0_col15, #T_12d54_row0_col17, #T_12d54_row1_col13, #T_12d54_row1_col14, #T_12d54_row1_col15, #T_12d54_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_12d54\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_12d54_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_12d54_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_12d54_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_12d54_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_12d54_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_12d54_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_12d54_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_12d54_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_12d54_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_12d54_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_12d54_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_12d54_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_12d54_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_12d54_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_12d54_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_12d54_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_12d54_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_12d54_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_12d54_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_12d54_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_12d54_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_12d54_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_12d54_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_12d54_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_12d54_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_12d54_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_12d54_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_12d54_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_12d54_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_12d54_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_12d54_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_12d54_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_12d54_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_12d54_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_12d54_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_12d54_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_12d54_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_12d54_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_12d54_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_12d54_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_12d54_row1_col2\" class=\"data row1 col2\" >44.3</td>\n",
       "      <td id=\"T_12d54_row1_col3\" class=\"data row1 col3\" >45.7</td>\n",
       "      <td id=\"T_12d54_row1_col4\" class=\"data row1 col4\" >3.0</td>\n",
       "      <td id=\"T_12d54_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_12d54_row1_col6\" class=\"data row1 col6\" >36.8</td>\n",
       "      <td id=\"T_12d54_row1_col7\" class=\"data row1 col7\" >34.4</td>\n",
       "      <td id=\"T_12d54_row1_col8\" class=\"data row1 col8\" >8.4</td>\n",
       "      <td id=\"T_12d54_row1_col9\" class=\"data row1 col9\" >43.3</td>\n",
       "      <td id=\"T_12d54_row1_col10\" class=\"data row1 col10\" >8.5</td>\n",
       "      <td id=\"T_12d54_row1_col11\" class=\"data row1 col11\" >4.2</td>\n",
       "      <td id=\"T_12d54_row1_col12\" class=\"data row1 col12\" >101.4</td>\n",
       "      <td id=\"T_12d54_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_12d54_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_12d54_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_12d54_row1_col16\" class=\"data row1 col16\" >31.1</td>\n",
       "      <td id=\"T_12d54_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf3552bc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b9c9e td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_b9c9e_row0_col0, #T_b9c9e_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b9c9e_row0_col1, #T_b9c9e_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b9c9e_row0_col2, #T_b9c9e_row0_col3, #T_b9c9e_row0_col5, #T_b9c9e_row0_col6, #T_b9c9e_row0_col7, #T_b9c9e_row0_col9, #T_b9c9e_row0_col11, #T_b9c9e_row1_col4, #T_b9c9e_row1_col5, #T_b9c9e_row1_col8, #T_b9c9e_row1_col10, #T_b9c9e_row1_col12, #T_b9c9e_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b9c9e_row0_col4, #T_b9c9e_row0_col8, #T_b9c9e_row0_col10, #T_b9c9e_row0_col12, #T_b9c9e_row0_col16, #T_b9c9e_row1_col2, #T_b9c9e_row1_col3, #T_b9c9e_row1_col6, #T_b9c9e_row1_col7, #T_b9c9e_row1_col9, #T_b9c9e_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b9c9e_row0_col13, #T_b9c9e_row0_col14, #T_b9c9e_row0_col15, #T_b9c9e_row0_col17, #T_b9c9e_row1_col13, #T_b9c9e_row1_col14, #T_b9c9e_row1_col15, #T_b9c9e_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b9c9e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b9c9e_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_b9c9e_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_b9c9e_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_b9c9e_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_b9c9e_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_b9c9e_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_b9c9e_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_b9c9e_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_b9c9e_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_b9c9e_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_b9c9e_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_b9c9e_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_b9c9e_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_b9c9e_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_b9c9e_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_b9c9e_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_b9c9e_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_b9c9e_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b9c9e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b9c9e_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_b9c9e_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_b9c9e_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_b9c9e_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_b9c9e_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_b9c9e_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_b9c9e_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_b9c9e_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_b9c9e_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_b9c9e_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_b9c9e_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_b9c9e_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_b9c9e_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_b9c9e_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_b9c9e_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_b9c9e_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_b9c9e_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_b9c9e_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b9c9e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b9c9e_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_b9c9e_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_b9c9e_row1_col2\" class=\"data row1 col2\" >44.3</td>\n",
       "      <td id=\"T_b9c9e_row1_col3\" class=\"data row1 col3\" >45.7</td>\n",
       "      <td id=\"T_b9c9e_row1_col4\" class=\"data row1 col4\" >3.0</td>\n",
       "      <td id=\"T_b9c9e_row1_col5\" class=\"data row1 col5\" >11.8</td>\n",
       "      <td id=\"T_b9c9e_row1_col6\" class=\"data row1 col6\" >36.8</td>\n",
       "      <td id=\"T_b9c9e_row1_col7\" class=\"data row1 col7\" >34.4</td>\n",
       "      <td id=\"T_b9c9e_row1_col8\" class=\"data row1 col8\" >8.4</td>\n",
       "      <td id=\"T_b9c9e_row1_col9\" class=\"data row1 col9\" >43.3</td>\n",
       "      <td id=\"T_b9c9e_row1_col10\" class=\"data row1 col10\" >8.5</td>\n",
       "      <td id=\"T_b9c9e_row1_col11\" class=\"data row1 col11\" >4.2</td>\n",
       "      <td id=\"T_b9c9e_row1_col12\" class=\"data row1 col12\" >101.4</td>\n",
       "      <td id=\"T_b9c9e_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_b9c9e_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_b9c9e_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_b9c9e_row1_col16\" class=\"data row1 col16\" >31.1</td>\n",
       "      <td id=\"T_b9c9e_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf77ef190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7ea84 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_7ea84_row0_col0, #T_7ea84_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7ea84_row0_col1, #T_7ea84_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7ea84_row0_col2, #T_7ea84_row0_col4, #T_7ea84_row0_col5, #T_7ea84_row0_col8, #T_7ea84_row0_col9, #T_7ea84_row0_col10, #T_7ea84_row0_col12, #T_7ea84_row0_col16, #T_7ea84_row1_col3, #T_7ea84_row1_col6, #T_7ea84_row1_col7, #T_7ea84_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7ea84_row0_col3, #T_7ea84_row0_col6, #T_7ea84_row0_col7, #T_7ea84_row0_col11, #T_7ea84_row1_col2, #T_7ea84_row1_col4, #T_7ea84_row1_col5, #T_7ea84_row1_col8, #T_7ea84_row1_col9, #T_7ea84_row1_col10, #T_7ea84_row1_col12, #T_7ea84_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7ea84_row0_col13, #T_7ea84_row0_col14, #T_7ea84_row0_col15, #T_7ea84_row0_col17, #T_7ea84_row1_col13, #T_7ea84_row1_col14, #T_7ea84_row1_col15, #T_7ea84_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7ea84\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7ea84_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_7ea84_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_7ea84_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_7ea84_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_7ea84_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_7ea84_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_7ea84_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_7ea84_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_7ea84_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_7ea84_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_7ea84_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_7ea84_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_7ea84_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_7ea84_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_7ea84_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_7ea84_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_7ea84_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_7ea84_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7ea84_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7ea84_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_7ea84_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_7ea84_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_7ea84_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_7ea84_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_7ea84_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_7ea84_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_7ea84_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_7ea84_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_7ea84_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_7ea84_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_7ea84_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_7ea84_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_7ea84_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_7ea84_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_7ea84_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_7ea84_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_7ea84_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ea84_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7ea84_row1_col0\" class=\"data row1 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_7ea84_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_7ea84_row1_col2\" class=\"data row1 col2\" >31.3</td>\n",
       "      <td id=\"T_7ea84_row1_col3\" class=\"data row1 col3\" >34.6</td>\n",
       "      <td id=\"T_7ea84_row1_col4\" class=\"data row1 col4\" >5.2</td>\n",
       "      <td id=\"T_7ea84_row1_col5\" class=\"data row1 col5\" >10.2</td>\n",
       "      <td id=\"T_7ea84_row1_col6\" class=\"data row1 col6\" >32.6</td>\n",
       "      <td id=\"T_7ea84_row1_col7\" class=\"data row1 col7\" >32.8</td>\n",
       "      <td id=\"T_7ea84_row1_col8\" class=\"data row1 col8\" >8.9</td>\n",
       "      <td id=\"T_7ea84_row1_col9\" class=\"data row1 col9\" >31.9</td>\n",
       "      <td id=\"T_7ea84_row1_col10\" class=\"data row1 col10\" >9.8</td>\n",
       "      <td id=\"T_7ea84_row1_col11\" class=\"data row1 col11\" >38.3</td>\n",
       "      <td id=\"T_7ea84_row1_col12\" class=\"data row1 col12\" >278.1</td>\n",
       "      <td id=\"T_7ea84_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_7ea84_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_7ea84_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_7ea84_row1_col16\" class=\"data row1 col16\" >46.7</td>\n",
       "      <td id=\"T_7ea84_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf515ee60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b38de td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_b38de_row0_col0, #T_b38de_row1_col0, #T_b38de_row2_col0, #T_b38de_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b38de_row0_col1, #T_b38de_row1_col1, #T_b38de_row2_col1, #T_b38de_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b38de_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b38de_row0_col3, #T_b38de_row0_col6, #T_b38de_row0_col11, #T_b38de_row1_col7, #T_b38de_row1_col9, #T_b38de_row1_col10, #T_b38de_row1_col13, #T_b38de_row1_col15, #T_b38de_row1_col17, #T_b38de_row2_col8, #T_b38de_row2_col14, #T_b38de_row2_col16, #T_b38de_row3_col2, #T_b38de_row3_col4, #T_b38de_row3_col5, #T_b38de_row3_col12, #T_b38de_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b38de_row0_col4, #T_b38de_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b38de_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b38de_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b38de_row0_col8, #T_b38de_row0_col9, #T_b38de_row0_col12, #T_b38de_row0_col16, #T_b38de_row1_col3, #T_b38de_row1_col4, #T_b38de_row1_col6, #T_b38de_row1_col11, #T_b38de_row1_col14, #T_b38de_row2_col2, #T_b38de_row2_col5, #T_b38de_row2_col7, #T_b38de_row2_col10, #T_b38de_row2_col13, #T_b38de_row2_col15, #T_b38de_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b38de_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b38de_row0_col13, #T_b38de_row0_col14, #T_b38de_row0_col15, #T_b38de_row0_col17, #T_b38de_row3_col13, #T_b38de_row3_col14, #T_b38de_row3_col15, #T_b38de_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b38de_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b38de_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b38de_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b38de_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b38de_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b38de_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b38de_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b38de_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b38de_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b38de_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b38de_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b38de_row3_col6, #T_b38de_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b38de_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b38de_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b38de_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b38de_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b38de\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b38de_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_b38de_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_b38de_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_b38de_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_b38de_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_b38de_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_b38de_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_b38de_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_b38de_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_b38de_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_b38de_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_b38de_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_b38de_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_b38de_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_b38de_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_b38de_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_b38de_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_b38de_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b38de_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b38de_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_b38de_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_b38de_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_b38de_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_b38de_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_b38de_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_b38de_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_b38de_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_b38de_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_b38de_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_b38de_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_b38de_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_b38de_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_b38de_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_b38de_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_b38de_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_b38de_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_b38de_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b38de_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b38de_row1_col0\" class=\"data row1 col0\" >llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_b38de_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_b38de_row1_col2\" class=\"data row1 col2\" >33.1</td>\n",
       "      <td id=\"T_b38de_row1_col3\" class=\"data row1 col3\" >36.7</td>\n",
       "      <td id=\"T_b38de_row1_col4\" class=\"data row1 col4\" >6.2</td>\n",
       "      <td id=\"T_b38de_row1_col5\" class=\"data row1 col5\" >11.0</td>\n",
       "      <td id=\"T_b38de_row1_col6\" class=\"data row1 col6\" >33.9</td>\n",
       "      <td id=\"T_b38de_row1_col7\" class=\"data row1 col7\" >32.5</td>\n",
       "      <td id=\"T_b38de_row1_col8\" class=\"data row1 col8\" >8.0</td>\n",
       "      <td id=\"T_b38de_row1_col9\" class=\"data row1 col9\" >29.1</td>\n",
       "      <td id=\"T_b38de_row1_col10\" class=\"data row1 col10\" >7.9</td>\n",
       "      <td id=\"T_b38de_row1_col11\" class=\"data row1 col11\" >40.1</td>\n",
       "      <td id=\"T_b38de_row1_col12\" class=\"data row1 col12\" >363.7</td>\n",
       "      <td id=\"T_b38de_row1_col13\" class=\"data row1 col13\" >39.5</td>\n",
       "      <td id=\"T_b38de_row1_col14\" class=\"data row1 col14\" >27.6</td>\n",
       "      <td id=\"T_b38de_row1_col15\" class=\"data row1 col15\" >33.6</td>\n",
       "      <td id=\"T_b38de_row1_col16\" class=\"data row1 col16\" >50.2</td>\n",
       "      <td id=\"T_b38de_row1_col17\" class=\"data row1 col17\" >-36.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b38de_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b38de_row2_col0\" class=\"data row2 col0\" >llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_b38de_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_b38de_row2_col2\" class=\"data row2 col2\" >33.7</td>\n",
       "      <td id=\"T_b38de_row2_col3\" class=\"data row2 col3\" >35.7</td>\n",
       "      <td id=\"T_b38de_row2_col4\" class=\"data row2 col4\" >5.4</td>\n",
       "      <td id=\"T_b38de_row2_col5\" class=\"data row2 col5\" >12.4</td>\n",
       "      <td id=\"T_b38de_row2_col6\" class=\"data row2 col6\" >33.6</td>\n",
       "      <td id=\"T_b38de_row2_col7\" class=\"data row2 col7\" >34.1</td>\n",
       "      <td id=\"T_b38de_row2_col8\" class=\"data row2 col8\" >7.4</td>\n",
       "      <td id=\"T_b38de_row2_col9\" class=\"data row2 col9\" >31.7</td>\n",
       "      <td id=\"T_b38de_row2_col10\" class=\"data row2 col10\" >11.0</td>\n",
       "      <td id=\"T_b38de_row2_col11\" class=\"data row2 col11\" >33.1</td>\n",
       "      <td id=\"T_b38de_row2_col12\" class=\"data row2 col12\" >321.7</td>\n",
       "      <td id=\"T_b38de_row2_col13\" class=\"data row2 col13\" >39.8</td>\n",
       "      <td id=\"T_b38de_row2_col14\" class=\"data row2 col14\" >27.3</td>\n",
       "      <td id=\"T_b38de_row2_col15\" class=\"data row2 col15\" >33.6</td>\n",
       "      <td id=\"T_b38de_row2_col16\" class=\"data row2 col16\" >47.2</td>\n",
       "      <td id=\"T_b38de_row2_col17\" class=\"data row2 col17\" >-34.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b38de_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b38de_row3_col0\" class=\"data row3 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_b38de_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_b38de_row3_col2\" class=\"data row3 col2\" >31.3</td>\n",
       "      <td id=\"T_b38de_row3_col3\" class=\"data row3 col3\" >34.6</td>\n",
       "      <td id=\"T_b38de_row3_col4\" class=\"data row3 col4\" >5.2</td>\n",
       "      <td id=\"T_b38de_row3_col5\" class=\"data row3 col5\" >10.2</td>\n",
       "      <td id=\"T_b38de_row3_col6\" class=\"data row3 col6\" >32.6</td>\n",
       "      <td id=\"T_b38de_row3_col7\" class=\"data row3 col7\" >32.8</td>\n",
       "      <td id=\"T_b38de_row3_col8\" class=\"data row3 col8\" >8.9</td>\n",
       "      <td id=\"T_b38de_row3_col9\" class=\"data row3 col9\" >31.9</td>\n",
       "      <td id=\"T_b38de_row3_col10\" class=\"data row3 col10\" >9.8</td>\n",
       "      <td id=\"T_b38de_row3_col11\" class=\"data row3 col11\" >38.3</td>\n",
       "      <td id=\"T_b38de_row3_col12\" class=\"data row3 col12\" >278.1</td>\n",
       "      <td id=\"T_b38de_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_b38de_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_b38de_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_b38de_row3_col16\" class=\"data row3 col16\" >46.7</td>\n",
       "      <td id=\"T_b38de_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfd814820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_32fb7 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_32fb7_row0_col0, #T_32fb7_row1_col0, #T_32fb7_row2_col0, #T_32fb7_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_32fb7_row0_col1, #T_32fb7_row1_col1, #T_32fb7_row2_col1, #T_32fb7_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_32fb7_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row0_col3, #T_32fb7_row0_col7, #T_32fb7_row0_col11, #T_32fb7_row1_col4, #T_32fb7_row1_col6, #T_32fb7_row1_col10, #T_32fb7_row1_col13, #T_32fb7_row1_col14, #T_32fb7_row1_col15, #T_32fb7_row2_col2, #T_32fb7_row2_col5, #T_32fb7_row2_col10, #T_32fb7_row2_col12, #T_32fb7_row3_col8, #T_32fb7_row3_col9, #T_32fb7_row3_col12, #T_32fb7_row3_col16, #T_32fb7_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row0_col4, #T_32fb7_row0_col8, #T_32fb7_row0_col9, #T_32fb7_row0_col12, #T_32fb7_row0_col16, #T_32fb7_row1_col2, #T_32fb7_row1_col3, #T_32fb7_row1_col5, #T_32fb7_row1_col7, #T_32fb7_row1_col17, #T_32fb7_row3_col4, #T_32fb7_row3_col6, #T_32fb7_row3_col10, #T_32fb7_row3_col11, #T_32fb7_row3_col13, #T_32fb7_row3_col14, #T_32fb7_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row0_col13, #T_32fb7_row0_col14, #T_32fb7_row0_col15, #T_32fb7_row0_col17, #T_32fb7_row2_col13, #T_32fb7_row2_col14, #T_32fb7_row2_col15, #T_32fb7_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_32fb7_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_32fb7_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_32fb7_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_32fb7_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_32fb7_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_32fb7_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c83836;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_32fb7_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_32fb7_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_32fb7_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_32fb7_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_32fb7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_32fb7_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_32fb7_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_32fb7_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_32fb7_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_32fb7_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_32fb7_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_32fb7_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_32fb7_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_32fb7_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_32fb7_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_32fb7_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_32fb7_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_32fb7_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_32fb7_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_32fb7_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_32fb7_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_32fb7_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_32fb7_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_32fb7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_32fb7_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_32fb7_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_32fb7_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_32fb7_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_32fb7_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_32fb7_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_32fb7_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_32fb7_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_32fb7_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_32fb7_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_32fb7_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_32fb7_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_32fb7_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_32fb7_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_32fb7_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_32fb7_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_32fb7_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_32fb7_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32fb7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_32fb7_row1_col0\" class=\"data row1 col0\" >llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_32fb7_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_32fb7_row1_col2\" class=\"data row1 col2\" >35.8</td>\n",
       "      <td id=\"T_32fb7_row1_col3\" class=\"data row1 col3\" >37.5</td>\n",
       "      <td id=\"T_32fb7_row1_col4\" class=\"data row1 col4\" >4.6</td>\n",
       "      <td id=\"T_32fb7_row1_col5\" class=\"data row1 col5\" >12.2</td>\n",
       "      <td id=\"T_32fb7_row1_col6\" class=\"data row1 col6\" >30.4</td>\n",
       "      <td id=\"T_32fb7_row1_col7\" class=\"data row1 col7\" >33.9</td>\n",
       "      <td id=\"T_32fb7_row1_col8\" class=\"data row1 col8\" >8.5</td>\n",
       "      <td id=\"T_32fb7_row1_col9\" class=\"data row1 col9\" >33.1</td>\n",
       "      <td id=\"T_32fb7_row1_col10\" class=\"data row1 col10\" >9.8</td>\n",
       "      <td id=\"T_32fb7_row1_col11\" class=\"data row1 col11\" >38.4</td>\n",
       "      <td id=\"T_32fb7_row1_col12\" class=\"data row1 col12\" >356.8</td>\n",
       "      <td id=\"T_32fb7_row1_col13\" class=\"data row1 col13\" >41.6</td>\n",
       "      <td id=\"T_32fb7_row1_col14\" class=\"data row1 col14\" >27.3</td>\n",
       "      <td id=\"T_32fb7_row1_col15\" class=\"data row1 col15\" >34.5</td>\n",
       "      <td id=\"T_32fb7_row1_col16\" class=\"data row1 col16\" >50.3</td>\n",
       "      <td id=\"T_32fb7_row1_col17\" class=\"data row1 col17\" >-33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32fb7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_32fb7_row2_col0\" class=\"data row2 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_32fb7_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_32fb7_row2_col2\" class=\"data row2 col2\" >31.3</td>\n",
       "      <td id=\"T_32fb7_row2_col3\" class=\"data row2 col3\" >34.6</td>\n",
       "      <td id=\"T_32fb7_row2_col4\" class=\"data row2 col4\" >5.2</td>\n",
       "      <td id=\"T_32fb7_row2_col5\" class=\"data row2 col5\" >10.2</td>\n",
       "      <td id=\"T_32fb7_row2_col6\" class=\"data row2 col6\" >32.6</td>\n",
       "      <td id=\"T_32fb7_row2_col7\" class=\"data row2 col7\" >32.8</td>\n",
       "      <td id=\"T_32fb7_row2_col8\" class=\"data row2 col8\" >8.9</td>\n",
       "      <td id=\"T_32fb7_row2_col9\" class=\"data row2 col9\" >31.9</td>\n",
       "      <td id=\"T_32fb7_row2_col10\" class=\"data row2 col10\" >9.8</td>\n",
       "      <td id=\"T_32fb7_row2_col11\" class=\"data row2 col11\" >38.3</td>\n",
       "      <td id=\"T_32fb7_row2_col12\" class=\"data row2 col12\" >278.1</td>\n",
       "      <td id=\"T_32fb7_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_32fb7_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_32fb7_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_32fb7_row2_col16\" class=\"data row2 col16\" >46.7</td>\n",
       "      <td id=\"T_32fb7_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_32fb7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_32fb7_row3_col0\" class=\"data row3 col0\" >llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_32fb7_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_32fb7_row3_col2\" class=\"data row3 col2\" >34.5</td>\n",
       "      <td id=\"T_32fb7_row3_col3\" class=\"data row3 col3\" >35.7</td>\n",
       "      <td id=\"T_32fb7_row3_col4\" class=\"data row3 col4\" >5.4</td>\n",
       "      <td id=\"T_32fb7_row3_col5\" class=\"data row3 col5\" >11.0</td>\n",
       "      <td id=\"T_32fb7_row3_col6\" class=\"data row3 col6\" >33.7</td>\n",
       "      <td id=\"T_32fb7_row3_col7\" class=\"data row3 col7\" >33.7</td>\n",
       "      <td id=\"T_32fb7_row3_col8\" class=\"data row3 col8\" >7.6</td>\n",
       "      <td id=\"T_32fb7_row3_col9\" class=\"data row3 col9\" >28.9</td>\n",
       "      <td id=\"T_32fb7_row3_col10\" class=\"data row3 col10\" >13.0</td>\n",
       "      <td id=\"T_32fb7_row3_col11\" class=\"data row3 col11\" >40.6</td>\n",
       "      <td id=\"T_32fb7_row3_col12\" class=\"data row3 col12\" >277.1</td>\n",
       "      <td id=\"T_32fb7_row3_col13\" class=\"data row3 col13\" >43.2</td>\n",
       "      <td id=\"T_32fb7_row3_col14\" class=\"data row3 col14\" >31.6</td>\n",
       "      <td id=\"T_32fb7_row3_col15\" class=\"data row3 col15\" >37.4</td>\n",
       "      <td id=\"T_32fb7_row3_col16\" class=\"data row3 col16\" >45.2</td>\n",
       "      <td id=\"T_32fb7_row3_col17\" class=\"data row3 col17\" >-35.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf5f2ae30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_62084 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_62084_row0_col0, #T_62084_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_62084_row0_col1, #T_62084_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_62084_row0_col2, #T_62084_row0_col4, #T_62084_row0_col5, #T_62084_row0_col8, #T_62084_row0_col9, #T_62084_row0_col10, #T_62084_row0_col12, #T_62084_row0_col16, #T_62084_row1_col3, #T_62084_row1_col6, #T_62084_row1_col7, #T_62084_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_62084_row0_col3, #T_62084_row0_col6, #T_62084_row0_col7, #T_62084_row0_col11, #T_62084_row1_col2, #T_62084_row1_col4, #T_62084_row1_col5, #T_62084_row1_col8, #T_62084_row1_col9, #T_62084_row1_col10, #T_62084_row1_col12, #T_62084_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_62084_row0_col13, #T_62084_row0_col14, #T_62084_row0_col15, #T_62084_row0_col17, #T_62084_row1_col13, #T_62084_row1_col14, #T_62084_row1_col15, #T_62084_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_62084\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_62084_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_62084_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_62084_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_62084_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_62084_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_62084_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_62084_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_62084_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_62084_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_62084_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_62084_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_62084_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_62084_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_62084_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_62084_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_62084_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_62084_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_62084_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_62084_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_62084_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_62084_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_62084_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_62084_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_62084_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_62084_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_62084_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_62084_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_62084_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_62084_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_62084_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_62084_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_62084_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_62084_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_62084_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_62084_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_62084_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_62084_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62084_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_62084_row1_col0\" class=\"data row1 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_62084_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_62084_row1_col2\" class=\"data row1 col2\" >31.3</td>\n",
       "      <td id=\"T_62084_row1_col3\" class=\"data row1 col3\" >34.6</td>\n",
       "      <td id=\"T_62084_row1_col4\" class=\"data row1 col4\" >5.2</td>\n",
       "      <td id=\"T_62084_row1_col5\" class=\"data row1 col5\" >10.2</td>\n",
       "      <td id=\"T_62084_row1_col6\" class=\"data row1 col6\" >32.6</td>\n",
       "      <td id=\"T_62084_row1_col7\" class=\"data row1 col7\" >32.8</td>\n",
       "      <td id=\"T_62084_row1_col8\" class=\"data row1 col8\" >8.9</td>\n",
       "      <td id=\"T_62084_row1_col9\" class=\"data row1 col9\" >31.9</td>\n",
       "      <td id=\"T_62084_row1_col10\" class=\"data row1 col10\" >9.8</td>\n",
       "      <td id=\"T_62084_row1_col11\" class=\"data row1 col11\" >38.3</td>\n",
       "      <td id=\"T_62084_row1_col12\" class=\"data row1 col12\" >278.1</td>\n",
       "      <td id=\"T_62084_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_62084_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_62084_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_62084_row1_col16\" class=\"data row1 col16\" >46.7</td>\n",
       "      <td id=\"T_62084_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf77ef190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6c079 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_6c079_row0_col0, #T_6c079_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6c079_row0_col1, #T_6c079_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6c079_row0_col2, #T_6c079_row0_col4, #T_6c079_row0_col5, #T_6c079_row0_col8, #T_6c079_row0_col9, #T_6c079_row0_col10, #T_6c079_row0_col12, #T_6c079_row0_col16, #T_6c079_row1_col3, #T_6c079_row1_col6, #T_6c079_row1_col7, #T_6c079_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c079_row0_col3, #T_6c079_row0_col6, #T_6c079_row0_col7, #T_6c079_row0_col11, #T_6c079_row1_col2, #T_6c079_row1_col4, #T_6c079_row1_col5, #T_6c079_row1_col8, #T_6c079_row1_col9, #T_6c079_row1_col10, #T_6c079_row1_col12, #T_6c079_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6c079_row0_col13, #T_6c079_row0_col14, #T_6c079_row0_col15, #T_6c079_row0_col17, #T_6c079_row1_col13, #T_6c079_row1_col14, #T_6c079_row1_col15, #T_6c079_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6c079\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6c079_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_6c079_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_6c079_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_6c079_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_6c079_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_6c079_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_6c079_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_6c079_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_6c079_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_6c079_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_6c079_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_6c079_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_6c079_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_6c079_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_6c079_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_6c079_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_6c079_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_6c079_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6c079_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6c079_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_6c079_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_6c079_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_6c079_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_6c079_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_6c079_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_6c079_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_6c079_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_6c079_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_6c079_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_6c079_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_6c079_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_6c079_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_6c079_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_6c079_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_6c079_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_6c079_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_6c079_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c079_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6c079_row1_col0\" class=\"data row1 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_6c079_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_6c079_row1_col2\" class=\"data row1 col2\" >31.3</td>\n",
       "      <td id=\"T_6c079_row1_col3\" class=\"data row1 col3\" >34.6</td>\n",
       "      <td id=\"T_6c079_row1_col4\" class=\"data row1 col4\" >5.2</td>\n",
       "      <td id=\"T_6c079_row1_col5\" class=\"data row1 col5\" >10.2</td>\n",
       "      <td id=\"T_6c079_row1_col6\" class=\"data row1 col6\" >32.6</td>\n",
       "      <td id=\"T_6c079_row1_col7\" class=\"data row1 col7\" >32.8</td>\n",
       "      <td id=\"T_6c079_row1_col8\" class=\"data row1 col8\" >8.9</td>\n",
       "      <td id=\"T_6c079_row1_col9\" class=\"data row1 col9\" >31.9</td>\n",
       "      <td id=\"T_6c079_row1_col10\" class=\"data row1 col10\" >9.8</td>\n",
       "      <td id=\"T_6c079_row1_col11\" class=\"data row1 col11\" >38.3</td>\n",
       "      <td id=\"T_6c079_row1_col12\" class=\"data row1 col12\" >278.1</td>\n",
       "      <td id=\"T_6c079_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_6c079_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_6c079_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_6c079_row1_col16\" class=\"data row1 col16\" >46.7</td>\n",
       "      <td id=\"T_6c079_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf72f25f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_56cf1 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_56cf1_row0_col0, #T_56cf1_row1_col0, #T_56cf1_row2_col0, #T_56cf1_row3_col0, #T_56cf1_row4_col0, #T_56cf1_row5_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_56cf1_row0_col1, #T_56cf1_row1_col1, #T_56cf1_row2_col1, #T_56cf1_row3_col1, #T_56cf1_row4_col1, #T_56cf1_row5_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_56cf1_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row0_col4, #T_56cf1_row0_col11, #T_56cf1_row1_col12, #T_56cf1_row2_col6, #T_56cf1_row2_col12, #T_56cf1_row3_col2, #T_56cf1_row3_col3, #T_56cf1_row3_col7, #T_56cf1_row3_col9, #T_56cf1_row4_col5, #T_56cf1_row4_col8, #T_56cf1_row4_col13, #T_56cf1_row4_col15, #T_56cf1_row4_col16, #T_56cf1_row4_col17, #T_56cf1_row5_col10, #T_56cf1_row5_col14, #T_56cf1_row5_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row0_col8, #T_56cf1_row0_col9, #T_56cf1_row0_col12, #T_56cf1_row0_col16, #T_56cf1_row1_col2, #T_56cf1_row1_col3, #T_56cf1_row1_col7, #T_56cf1_row1_col11, #T_56cf1_row2_col5, #T_56cf1_row2_col10, #T_56cf1_row2_col13, #T_56cf1_row2_col14, #T_56cf1_row2_col15, #T_56cf1_row2_col17, #T_56cf1_row5_col4, #T_56cf1_row5_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row0_col13, #T_56cf1_row0_col14, #T_56cf1_row0_col15, #T_56cf1_row0_col17, #T_56cf1_row1_col13, #T_56cf1_row1_col14, #T_56cf1_row1_col15, #T_56cf1_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row1_col16, #T_56cf1_row4_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row2_col2, #T_56cf1_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row2_col4, #T_56cf1_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row2_col16, #T_56cf1_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row3_col6, #T_56cf1_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row5_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row5_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row5_col7, #T_56cf1_row5_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_56cf1_row5_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row5_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56cf1_row5_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_56cf1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_56cf1_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_56cf1_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_56cf1_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_56cf1_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_56cf1_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_56cf1_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_56cf1_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_56cf1_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_56cf1_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_56cf1_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_56cf1_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_56cf1_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_56cf1_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_56cf1_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_56cf1_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_56cf1_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_56cf1_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_56cf1_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_56cf1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_56cf1_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_56cf1_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_56cf1_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_56cf1_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_56cf1_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_56cf1_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_56cf1_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_56cf1_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_56cf1_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_56cf1_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_56cf1_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_56cf1_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_56cf1_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_56cf1_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_56cf1_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_56cf1_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_56cf1_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_56cf1_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56cf1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_56cf1_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_ep=3</td>\n",
       "      <td id=\"T_56cf1_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_56cf1_row1_col2\" class=\"data row1 col2\" >40.6</td>\n",
       "      <td id=\"T_56cf1_row1_col3\" class=\"data row1 col3\" >40.9</td>\n",
       "      <td id=\"T_56cf1_row1_col4\" class=\"data row1 col4\" >6.6</td>\n",
       "      <td id=\"T_56cf1_row1_col5\" class=\"data row1 col5\" >15.0</td>\n",
       "      <td id=\"T_56cf1_row1_col6\" class=\"data row1 col6\" >31.0</td>\n",
       "      <td id=\"T_56cf1_row1_col7\" class=\"data row1 col7\" >34.7</td>\n",
       "      <td id=\"T_56cf1_row1_col8\" class=\"data row1 col8\" >7.4</td>\n",
       "      <td id=\"T_56cf1_row1_col9\" class=\"data row1 col9\" >33.1</td>\n",
       "      <td id=\"T_56cf1_row1_col10\" class=\"data row1 col10\" >10.8</td>\n",
       "      <td id=\"T_56cf1_row1_col11\" class=\"data row1 col11\" >56.0</td>\n",
       "      <td id=\"T_56cf1_row1_col12\" class=\"data row1 col12\" >280.3</td>\n",
       "      <td id=\"T_56cf1_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_56cf1_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_56cf1_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_56cf1_row1_col16\" class=\"data row1 col16\" >50.6</td>\n",
       "      <td id=\"T_56cf1_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56cf1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_56cf1_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_56cf1_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_56cf1_row2_col2\" class=\"data row2 col2\" >39.0</td>\n",
       "      <td id=\"T_56cf1_row2_col3\" class=\"data row2 col3\" >38.8</td>\n",
       "      <td id=\"T_56cf1_row2_col4\" class=\"data row2 col4\" >6.4</td>\n",
       "      <td id=\"T_56cf1_row2_col5\" class=\"data row2 col5\" >16.0</td>\n",
       "      <td id=\"T_56cf1_row2_col6\" class=\"data row2 col6\" >29.9</td>\n",
       "      <td id=\"T_56cf1_row2_col7\" class=\"data row2 col7\" >34.4</td>\n",
       "      <td id=\"T_56cf1_row2_col8\" class=\"data row2 col8\" >8.0</td>\n",
       "      <td id=\"T_56cf1_row2_col9\" class=\"data row2 col9\" >34.9</td>\n",
       "      <td id=\"T_56cf1_row2_col10\" class=\"data row2 col10\" >13.2</td>\n",
       "      <td id=\"T_56cf1_row2_col11\" class=\"data row2 col11\" >46.3</td>\n",
       "      <td id=\"T_56cf1_row2_col12\" class=\"data row2 col12\" >279.4</td>\n",
       "      <td id=\"T_56cf1_row2_col13\" class=\"data row2 col13\" >54.4</td>\n",
       "      <td id=\"T_56cf1_row2_col14\" class=\"data row2 col14\" >36.0</td>\n",
       "      <td id=\"T_56cf1_row2_col15\" class=\"data row2 col15\" >45.3</td>\n",
       "      <td id=\"T_56cf1_row2_col16\" class=\"data row2 col16\" >48.7</td>\n",
       "      <td id=\"T_56cf1_row2_col17\" class=\"data row2 col17\" >-18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56cf1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_56cf1_row3_col0\" class=\"data row3 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_56cf1_row3_col1\" class=\"data row3 col1\" >10000</td>\n",
       "      <td id=\"T_56cf1_row3_col2\" class=\"data row3 col2\" >30.9</td>\n",
       "      <td id=\"T_56cf1_row3_col3\" class=\"data row3 col3\" >33.0</td>\n",
       "      <td id=\"T_56cf1_row3_col4\" class=\"data row3 col4\" >6.4</td>\n",
       "      <td id=\"T_56cf1_row3_col5\" class=\"data row3 col5\" >13.6</td>\n",
       "      <td id=\"T_56cf1_row3_col6\" class=\"data row3 col6\" >33.5</td>\n",
       "      <td id=\"T_56cf1_row3_col7\" class=\"data row3 col7\" >30.7</td>\n",
       "      <td id=\"T_56cf1_row3_col8\" class=\"data row3 col8\" >7.3</td>\n",
       "      <td id=\"T_56cf1_row3_col9\" class=\"data row3 col9\" >28.3</td>\n",
       "      <td id=\"T_56cf1_row3_col10\" class=\"data row3 col10\" >12.2</td>\n",
       "      <td id=\"T_56cf1_row3_col11\" class=\"data row3 col11\" >51.0</td>\n",
       "      <td id=\"T_56cf1_row3_col12\" class=\"data row3 col12\" >314.6</td>\n",
       "      <td id=\"T_56cf1_row3_col13\" class=\"data row3 col13\" >46.4</td>\n",
       "      <td id=\"T_56cf1_row3_col14\" class=\"data row3 col14\" >34.0</td>\n",
       "      <td id=\"T_56cf1_row3_col15\" class=\"data row3 col15\" >40.2</td>\n",
       "      <td id=\"T_56cf1_row3_col16\" class=\"data row3 col16\" >48.7</td>\n",
       "      <td id=\"T_56cf1_row3_col17\" class=\"data row3 col17\" >-33.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56cf1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_56cf1_row4_col0\" class=\"data row4 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_56cf1_row4_col1\" class=\"data row4 col1\" >10000</td>\n",
       "      <td id=\"T_56cf1_row4_col2\" class=\"data row4 col2\" >31.7</td>\n",
       "      <td id=\"T_56cf1_row4_col3\" class=\"data row4 col3\" >37.0</td>\n",
       "      <td id=\"T_56cf1_row4_col4\" class=\"data row4 col4\" >6.0</td>\n",
       "      <td id=\"T_56cf1_row4_col5\" class=\"data row4 col5\" >9.6</td>\n",
       "      <td id=\"T_56cf1_row4_col6\" class=\"data row4 col6\" >31.2</td>\n",
       "      <td id=\"T_56cf1_row4_col7\" class=\"data row4 col7\" >33.1</td>\n",
       "      <td id=\"T_56cf1_row4_col8\" class=\"data row4 col8\" >7.0</td>\n",
       "      <td id=\"T_56cf1_row4_col9\" class=\"data row4 col9\" >30.0</td>\n",
       "      <td id=\"T_56cf1_row4_col10\" class=\"data row4 col10\" >11.8</td>\n",
       "      <td id=\"T_56cf1_row4_col11\" class=\"data row4 col11\" >46.8</td>\n",
       "      <td id=\"T_56cf1_row4_col12\" class=\"data row4 col12\" >299.0</td>\n",
       "      <td id=\"T_56cf1_row4_col13\" class=\"data row4 col13\" >43.5</td>\n",
       "      <td id=\"T_56cf1_row4_col14\" class=\"data row4 col14\" >31.9</td>\n",
       "      <td id=\"T_56cf1_row4_col15\" class=\"data row4 col15\" >37.7</td>\n",
       "      <td id=\"T_56cf1_row4_col16\" class=\"data row4 col16\" >46.9</td>\n",
       "      <td id=\"T_56cf1_row4_col17\" class=\"data row4 col17\" >-38.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56cf1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_56cf1_row5_col0\" class=\"data row5 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_56cf1_row5_col1\" class=\"data row5 col1\" >10000</td>\n",
       "      <td id=\"T_56cf1_row5_col2\" class=\"data row5 col2\" >32.9</td>\n",
       "      <td id=\"T_56cf1_row5_col3\" class=\"data row5 col3\" >34.7</td>\n",
       "      <td id=\"T_56cf1_row5_col4\" class=\"data row5 col4\" >6.8</td>\n",
       "      <td id=\"T_56cf1_row5_col5\" class=\"data row5 col5\" >12.0</td>\n",
       "      <td id=\"T_56cf1_row5_col6\" class=\"data row5 col6\" >35.0</td>\n",
       "      <td id=\"T_56cf1_row5_col7\" class=\"data row5 col7\" >31.4</td>\n",
       "      <td id=\"T_56cf1_row5_col8\" class=\"data row5 col8\" >8.9</td>\n",
       "      <td id=\"T_56cf1_row5_col9\" class=\"data row5 col9\" >32.1</td>\n",
       "      <td id=\"T_56cf1_row5_col10\" class=\"data row5 col10\" >8.7</td>\n",
       "      <td id=\"T_56cf1_row5_col11\" class=\"data row5 col11\" >42.2</td>\n",
       "      <td id=\"T_56cf1_row5_col12\" class=\"data row5 col12\" >288.6</td>\n",
       "      <td id=\"T_56cf1_row5_col13\" class=\"data row5 col13\" >46.0</td>\n",
       "      <td id=\"T_56cf1_row5_col14\" class=\"data row5 col14\" >31.8</td>\n",
       "      <td id=\"T_56cf1_row5_col15\" class=\"data row5 col15\" >38.9</td>\n",
       "      <td id=\"T_56cf1_row5_col16\" class=\"data row5 col16\" >46.4</td>\n",
       "      <td id=\"T_56cf1_row5_col17\" class=\"data row5 col17\" >-32.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf60e8dc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_963f2 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_963f2_row0_col0, #T_963f2_row1_col0, #T_963f2_row2_col0, #T_963f2_row3_col0, #T_963f2_row4_col0, #T_963f2_row5_col0, #T_963f2_row6_col0, #T_963f2_row7_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_963f2_row0_col1, #T_963f2_row1_col1, #T_963f2_row2_col1, #T_963f2_row3_col1, #T_963f2_row4_col1, #T_963f2_row5_col1, #T_963f2_row6_col1, #T_963f2_row7_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_963f2_row0_col2, #T_963f2_row0_col3, #T_963f2_row0_col7, #T_963f2_row0_col10, #T_963f2_row0_col11, #T_963f2_row2_col4, #T_963f2_row3_col8, #T_963f2_row4_col5, #T_963f2_row4_col13, #T_963f2_row4_col14, #T_963f2_row4_col15, #T_963f2_row5_col6, #T_963f2_row6_col9, #T_963f2_row6_col17, #T_963f2_row7_col12, #T_963f2_row7_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row0_col5, #T_963f2_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row0_col6, #T_963f2_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row0_col8, #T_963f2_row0_col9, #T_963f2_row0_col12, #T_963f2_row0_col16, #T_963f2_row1_col14, #T_963f2_row1_col15, #T_963f2_row3_col2, #T_963f2_row3_col3, #T_963f2_row3_col4, #T_963f2_row3_col7, #T_963f2_row3_col11, #T_963f2_row4_col6, #T_963f2_row4_col10, #T_963f2_row5_col5, #T_963f2_row5_col13, #T_963f2_row5_col17, #T_963f2_row7_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row0_col13, #T_963f2_row0_col14, #T_963f2_row0_col15, #T_963f2_row0_col17, #T_963f2_row2_col13, #T_963f2_row2_col14, #T_963f2_row2_col15, #T_963f2_row2_col17, #T_963f2_row3_col13, #T_963f2_row3_col14, #T_963f2_row3_col15, #T_963f2_row3_col17, #T_963f2_row7_col13, #T_963f2_row7_col14, #T_963f2_row7_col15, #T_963f2_row7_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row1_col4, #T_963f2_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row1_col9, #T_963f2_row6_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row1_col13, #T_963f2_row6_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row1_col16, #T_963f2_row7_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b3cdfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row2_col7, #T_963f2_row5_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row2_col8, #T_963f2_row6_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row2_col12, #T_963f2_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row2_col16, #T_963f2_row3_col16, #T_963f2_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row3_col12, #T_963f2_row5_col12, #T_963f2_row6_col12, #T_963f2_row6_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row4_col4, #T_963f2_row7_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row4_col8, #T_963f2_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row4_col9, #T_963f2_row7_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row5_col4, #T_963f2_row6_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row5_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row5_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row5_col15, #T_963f2_row6_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row5_col16, #T_963f2_row6_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row6_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row6_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row6_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row6_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row6_col10, #T_963f2_row7_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row6_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row7_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row7_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row7_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_963f2_row7_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_963f2_row7_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_963f2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_963f2_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_963f2_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_963f2_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_963f2_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_963f2_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_963f2_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_963f2_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_963f2_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_963f2_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_963f2_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_963f2_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_963f2_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_963f2_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_963f2_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_963f2_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_963f2_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_963f2_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_963f2_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_963f2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_963f2_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_963f2_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_963f2_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_963f2_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_963f2_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_963f2_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_963f2_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_963f2_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_963f2_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_963f2_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_963f2_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_963f2_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_963f2_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_963f2_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_963f2_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_963f2_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_963f2_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_963f2_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_963f2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_963f2_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_963f2_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_963f2_row1_col2\" class=\"data row1 col2\" >37.9</td>\n",
       "      <td id=\"T_963f2_row1_col3\" class=\"data row1 col3\" >37.7</td>\n",
       "      <td id=\"T_963f2_row1_col4\" class=\"data row1 col4\" >6.0</td>\n",
       "      <td id=\"T_963f2_row1_col5\" class=\"data row1 col5\" >13.0</td>\n",
       "      <td id=\"T_963f2_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_963f2_row1_col7\" class=\"data row1 col7\" >33.9</td>\n",
       "      <td id=\"T_963f2_row1_col8\" class=\"data row1 col8\" >8.7</td>\n",
       "      <td id=\"T_963f2_row1_col9\" class=\"data row1 col9\" >33.6</td>\n",
       "      <td id=\"T_963f2_row1_col10\" class=\"data row1 col10\" >11.4</td>\n",
       "      <td id=\"T_963f2_row1_col11\" class=\"data row1 col11\" >48.9</td>\n",
       "      <td id=\"T_963f2_row1_col12\" class=\"data row1 col12\" >347.0</td>\n",
       "      <td id=\"T_963f2_row1_col13\" class=\"data row1 col13\" >53.1</td>\n",
       "      <td id=\"T_963f2_row1_col14\" class=\"data row1 col14\" >40.5</td>\n",
       "      <td id=\"T_963f2_row1_col15\" class=\"data row1 col15\" >46.9</td>\n",
       "      <td id=\"T_963f2_row1_col16\" class=\"data row1 col16\" >53.5</td>\n",
       "      <td id=\"T_963f2_row1_col17\" class=\"data row1 col17\" >-19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_963f2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_963f2_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_963f2_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_963f2_row2_col2\" class=\"data row2 col2\" >34.2</td>\n",
       "      <td id=\"T_963f2_row2_col3\" class=\"data row2 col3\" >37.8</td>\n",
       "      <td id=\"T_963f2_row2_col4\" class=\"data row2 col4\" >4.4</td>\n",
       "      <td id=\"T_963f2_row2_col5\" class=\"data row2 col5\" >12.8</td>\n",
       "      <td id=\"T_963f2_row2_col6\" class=\"data row2 col6\" >33.1</td>\n",
       "      <td id=\"T_963f2_row2_col7\" class=\"data row2 col7\" >34.4</td>\n",
       "      <td id=\"T_963f2_row2_col8\" class=\"data row2 col8\" >7.8</td>\n",
       "      <td id=\"T_963f2_row2_col9\" class=\"data row2 col9\" >32.3</td>\n",
       "      <td id=\"T_963f2_row2_col10\" class=\"data row2 col10\" >13.4</td>\n",
       "      <td id=\"T_963f2_row2_col11\" class=\"data row2 col11\" >51.6</td>\n",
       "      <td id=\"T_963f2_row2_col12\" class=\"data row2 col12\" >295.1</td>\n",
       "      <td id=\"T_963f2_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_963f2_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_963f2_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_963f2_row2_col16\" class=\"data row2 col16\" >50.6</td>\n",
       "      <td id=\"T_963f2_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_963f2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_963f2_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_ep=3</td>\n",
       "      <td id=\"T_963f2_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_963f2_row3_col2\" class=\"data row3 col2\" >40.6</td>\n",
       "      <td id=\"T_963f2_row3_col3\" class=\"data row3 col3\" >40.9</td>\n",
       "      <td id=\"T_963f2_row3_col4\" class=\"data row3 col4\" >6.6</td>\n",
       "      <td id=\"T_963f2_row3_col5\" class=\"data row3 col5\" >15.0</td>\n",
       "      <td id=\"T_963f2_row3_col6\" class=\"data row3 col6\" >31.0</td>\n",
       "      <td id=\"T_963f2_row3_col7\" class=\"data row3 col7\" >34.7</td>\n",
       "      <td id=\"T_963f2_row3_col8\" class=\"data row3 col8\" >7.4</td>\n",
       "      <td id=\"T_963f2_row3_col9\" class=\"data row3 col9\" >33.1</td>\n",
       "      <td id=\"T_963f2_row3_col10\" class=\"data row3 col10\" >10.8</td>\n",
       "      <td id=\"T_963f2_row3_col11\" class=\"data row3 col11\" >56.0</td>\n",
       "      <td id=\"T_963f2_row3_col12\" class=\"data row3 col12\" >280.3</td>\n",
       "      <td id=\"T_963f2_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_963f2_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_963f2_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_963f2_row3_col16\" class=\"data row3 col16\" >50.6</td>\n",
       "      <td id=\"T_963f2_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_963f2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_963f2_row4_col0\" class=\"data row4 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_963f2_row4_col1\" class=\"data row4 col1\" >30000</td>\n",
       "      <td id=\"T_963f2_row4_col2\" class=\"data row4 col2\" >33.9</td>\n",
       "      <td id=\"T_963f2_row4_col3\" class=\"data row4 col3\" >35.2</td>\n",
       "      <td id=\"T_963f2_row4_col4\" class=\"data row4 col4\" >5.2</td>\n",
       "      <td id=\"T_963f2_row4_col5\" class=\"data row4 col5\" >11.0</td>\n",
       "      <td id=\"T_963f2_row4_col6\" class=\"data row4 col6\" >34.1</td>\n",
       "      <td id=\"T_963f2_row4_col7\" class=\"data row4 col7\" >34.2</td>\n",
       "      <td id=\"T_963f2_row4_col8\" class=\"data row4 col8\" >8.9</td>\n",
       "      <td id=\"T_963f2_row4_col9\" class=\"data row4 col9\" >32.8</td>\n",
       "      <td id=\"T_963f2_row4_col10\" class=\"data row4 col10\" >14.0</td>\n",
       "      <td id=\"T_963f2_row4_col11\" class=\"data row4 col11\" >52.4</td>\n",
       "      <td id=\"T_963f2_row4_col12\" class=\"data row4 col12\" >311.7</td>\n",
       "      <td id=\"T_963f2_row4_col13\" class=\"data row4 col13\" >45.9</td>\n",
       "      <td id=\"T_963f2_row4_col14\" class=\"data row4 col14\" >35.4</td>\n",
       "      <td id=\"T_963f2_row4_col15\" class=\"data row4 col15\" >40.6</td>\n",
       "      <td id=\"T_963f2_row4_col16\" class=\"data row4 col16\" >49.7</td>\n",
       "      <td id=\"T_963f2_row4_col17\" class=\"data row4 col17\" >-23.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_963f2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_963f2_row5_col0\" class=\"data row5 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_963f2_row5_col1\" class=\"data row5 col1\" >None</td>\n",
       "      <td id=\"T_963f2_row5_col2\" class=\"data row5 col2\" >39.0</td>\n",
       "      <td id=\"T_963f2_row5_col3\" class=\"data row5 col3\" >38.8</td>\n",
       "      <td id=\"T_963f2_row5_col4\" class=\"data row5 col4\" >6.4</td>\n",
       "      <td id=\"T_963f2_row5_col5\" class=\"data row5 col5\" >16.0</td>\n",
       "      <td id=\"T_963f2_row5_col6\" class=\"data row5 col6\" >29.9</td>\n",
       "      <td id=\"T_963f2_row5_col7\" class=\"data row5 col7\" >34.4</td>\n",
       "      <td id=\"T_963f2_row5_col8\" class=\"data row5 col8\" >8.0</td>\n",
       "      <td id=\"T_963f2_row5_col9\" class=\"data row5 col9\" >34.9</td>\n",
       "      <td id=\"T_963f2_row5_col10\" class=\"data row5 col10\" >13.2</td>\n",
       "      <td id=\"T_963f2_row5_col11\" class=\"data row5 col11\" >46.3</td>\n",
       "      <td id=\"T_963f2_row5_col12\" class=\"data row5 col12\" >279.4</td>\n",
       "      <td id=\"T_963f2_row5_col13\" class=\"data row5 col13\" >54.4</td>\n",
       "      <td id=\"T_963f2_row5_col14\" class=\"data row5 col14\" >36.0</td>\n",
       "      <td id=\"T_963f2_row5_col15\" class=\"data row5 col15\" >45.3</td>\n",
       "      <td id=\"T_963f2_row5_col16\" class=\"data row5 col16\" >48.7</td>\n",
       "      <td id=\"T_963f2_row5_col17\" class=\"data row5 col17\" >-18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_963f2_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_963f2_row6_col0\" class=\"data row6 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_963f2_row6_col1\" class=\"data row6 col1\" >30000</td>\n",
       "      <td id=\"T_963f2_row6_col2\" class=\"data row6 col2\" >35.0</td>\n",
       "      <td id=\"T_963f2_row6_col3\" class=\"data row6 col3\" >35.7</td>\n",
       "      <td id=\"T_963f2_row6_col4\" class=\"data row6 col4\" >5.8</td>\n",
       "      <td id=\"T_963f2_row6_col5\" class=\"data row6 col5\" >14.4</td>\n",
       "      <td id=\"T_963f2_row6_col6\" class=\"data row6 col6\" >32.8</td>\n",
       "      <td id=\"T_963f2_row6_col7\" class=\"data row6 col7\" >34.5</td>\n",
       "      <td id=\"T_963f2_row6_col8\" class=\"data row6 col8\" >7.5</td>\n",
       "      <td id=\"T_963f2_row6_col9\" class=\"data row6 col9\" >31.3</td>\n",
       "      <td id=\"T_963f2_row6_col10\" class=\"data row6 col10\" >12.8</td>\n",
       "      <td id=\"T_963f2_row6_col11\" class=\"data row6 col11\" >47.8</td>\n",
       "      <td id=\"T_963f2_row6_col12\" class=\"data row6 col12\" >283.6</td>\n",
       "      <td id=\"T_963f2_row6_col13\" class=\"data row6 col13\" >48.6</td>\n",
       "      <td id=\"T_963f2_row6_col14\" class=\"data row6 col14\" >39.2</td>\n",
       "      <td id=\"T_963f2_row6_col15\" class=\"data row6 col15\" >44.0</td>\n",
       "      <td id=\"T_963f2_row6_col16\" class=\"data row6 col16\" >48.1</td>\n",
       "      <td id=\"T_963f2_row6_col17\" class=\"data row6 col17\" >-26.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_963f2_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_963f2_row7_col0\" class=\"data row7 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-2:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_963f2_row7_col1\" class=\"data row7 col1\" >30000</td>\n",
       "      <td id=\"T_963f2_row7_col2\" class=\"data row7 col2\" >37.8</td>\n",
       "      <td id=\"T_963f2_row7_col3\" class=\"data row7 col3\" >34.9</td>\n",
       "      <td id=\"T_963f2_row7_col4\" class=\"data row7 col4\" >5.2</td>\n",
       "      <td id=\"T_963f2_row7_col5\" class=\"data row7 col5\" >13.6</td>\n",
       "      <td id=\"T_963f2_row7_col6\" class=\"data row7 col6\" >31.3</td>\n",
       "      <td id=\"T_963f2_row7_col7\" class=\"data row7 col7\" >33.3</td>\n",
       "      <td id=\"T_963f2_row7_col8\" class=\"data row7 col8\" >7.5</td>\n",
       "      <td id=\"T_963f2_row7_col9\" class=\"data row7 col9\" >32.8</td>\n",
       "      <td id=\"T_963f2_row7_col10\" class=\"data row7 col10\" >14.0</td>\n",
       "      <td id=\"T_963f2_row7_col11\" class=\"data row7 col11\" >39.4</td>\n",
       "      <td id=\"T_963f2_row7_col12\" class=\"data row7 col12\" >209.7</td>\n",
       "      <td id=\"T_963f2_row7_col13\" class=\"data row7 col13\" >nan</td>\n",
       "      <td id=\"T_963f2_row7_col14\" class=\"data row7 col14\" >nan</td>\n",
       "      <td id=\"T_963f2_row7_col15\" class=\"data row7 col15\" >nan</td>\n",
       "      <td id=\"T_963f2_row7_col16\" class=\"data row7 col16\" >41.8</td>\n",
       "      <td id=\"T_963f2_row7_col17\" class=\"data row7 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf6985390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_585ec td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_585ec_row0_col0, #T_585ec_row1_col0, #T_585ec_row2_col0, #T_585ec_row3_col0, #T_585ec_row4_col0, #T_585ec_row5_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_585ec_row0_col1, #T_585ec_row1_col1, #T_585ec_row2_col1, #T_585ec_row3_col1, #T_585ec_row4_col1, #T_585ec_row5_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_585ec_row0_col2, #T_585ec_row0_col3, #T_585ec_row0_col4, #T_585ec_row0_col5, #T_585ec_row0_col7, #T_585ec_row0_col10, #T_585ec_row0_col11, #T_585ec_row2_col8, #T_585ec_row2_col12, #T_585ec_row3_col9, #T_585ec_row3_col14, #T_585ec_row3_col15, #T_585ec_row3_col17, #T_585ec_row4_col13, #T_585ec_row4_col16, #T_585ec_row4_col17, #T_585ec_row5_col6, #T_585ec_row5_col12, #T_585ec_row5_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row0_col8, #T_585ec_row0_col9, #T_585ec_row0_col12, #T_585ec_row0_col16, #T_585ec_row1_col6, #T_585ec_row1_col14, #T_585ec_row1_col17, #T_585ec_row2_col2, #T_585ec_row2_col3, #T_585ec_row2_col4, #T_585ec_row2_col11, #T_585ec_row3_col7, #T_585ec_row5_col5, #T_585ec_row5_col10, #T_585ec_row5_col13, #T_585ec_row5_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row0_col13, #T_585ec_row0_col14, #T_585ec_row0_col15, #T_585ec_row0_col17, #T_585ec_row2_col13, #T_585ec_row2_col14, #T_585ec_row2_col15, #T_585ec_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f39577;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row1_col4, #T_585ec_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row1_col9, #T_585ec_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row2_col6, #T_585ec_row5_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row2_col16, #T_585ec_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row3_col5, #T_585ec_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row3_col16, #T_585ec_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row4_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row4_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row5_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_585ec_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_585ec_row5_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_585ec\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_585ec_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_585ec_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_585ec_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_585ec_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_585ec_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_585ec_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_585ec_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_585ec_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_585ec_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_585ec_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_585ec_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_585ec_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_585ec_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_585ec_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_585ec_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_585ec_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_585ec_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_585ec_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_585ec_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_585ec_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_585ec_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_585ec_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_585ec_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_585ec_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_585ec_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_585ec_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_585ec_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_585ec_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_585ec_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_585ec_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_585ec_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_585ec_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_585ec_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_585ec_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_585ec_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_585ec_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_585ec_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_585ec_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_585ec_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_585ec_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_585ec_row1_col2\" class=\"data row1 col2\" >40.0</td>\n",
       "      <td id=\"T_585ec_row1_col3\" class=\"data row1 col3\" >39.4</td>\n",
       "      <td id=\"T_585ec_row1_col4\" class=\"data row1 col4\" >6.4</td>\n",
       "      <td id=\"T_585ec_row1_col5\" class=\"data row1 col5\" >14.4</td>\n",
       "      <td id=\"T_585ec_row1_col6\" class=\"data row1 col6\" >32.4</td>\n",
       "      <td id=\"T_585ec_row1_col7\" class=\"data row1 col7\" >34.6</td>\n",
       "      <td id=\"T_585ec_row1_col8\" class=\"data row1 col8\" >7.8</td>\n",
       "      <td id=\"T_585ec_row1_col9\" class=\"data row1 col9\" >34.4</td>\n",
       "      <td id=\"T_585ec_row1_col10\" class=\"data row1 col10\" >11.4</td>\n",
       "      <td id=\"T_585ec_row1_col11\" class=\"data row1 col11\" >54.6</td>\n",
       "      <td id=\"T_585ec_row1_col12\" class=\"data row1 col12\" >326.7</td>\n",
       "      <td id=\"T_585ec_row1_col13\" class=\"data row1 col13\" >51.8</td>\n",
       "      <td id=\"T_585ec_row1_col14\" class=\"data row1 col14\" >38.8</td>\n",
       "      <td id=\"T_585ec_row1_col15\" class=\"data row1 col15\" >45.2</td>\n",
       "      <td id=\"T_585ec_row1_col16\" class=\"data row1 col16\" >52.7</td>\n",
       "      <td id=\"T_585ec_row1_col17\" class=\"data row1 col17\" >-15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_585ec_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_585ec_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_ep=3</td>\n",
       "      <td id=\"T_585ec_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_585ec_row2_col2\" class=\"data row2 col2\" >40.6</td>\n",
       "      <td id=\"T_585ec_row2_col3\" class=\"data row2 col3\" >40.9</td>\n",
       "      <td id=\"T_585ec_row2_col4\" class=\"data row2 col4\" >6.6</td>\n",
       "      <td id=\"T_585ec_row2_col5\" class=\"data row2 col5\" >15.0</td>\n",
       "      <td id=\"T_585ec_row2_col6\" class=\"data row2 col6\" >31.0</td>\n",
       "      <td id=\"T_585ec_row2_col7\" class=\"data row2 col7\" >34.7</td>\n",
       "      <td id=\"T_585ec_row2_col8\" class=\"data row2 col8\" >7.4</td>\n",
       "      <td id=\"T_585ec_row2_col9\" class=\"data row2 col9\" >33.1</td>\n",
       "      <td id=\"T_585ec_row2_col10\" class=\"data row2 col10\" >10.8</td>\n",
       "      <td id=\"T_585ec_row2_col11\" class=\"data row2 col11\" >56.0</td>\n",
       "      <td id=\"T_585ec_row2_col12\" class=\"data row2 col12\" >280.3</td>\n",
       "      <td id=\"T_585ec_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_585ec_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_585ec_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_585ec_row2_col16\" class=\"data row2 col16\" >50.6</td>\n",
       "      <td id=\"T_585ec_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_585ec_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_585ec_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_585ec_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_585ec_row3_col2\" class=\"data row3 col2\" >39.6</td>\n",
       "      <td id=\"T_585ec_row3_col3\" class=\"data row3 col3\" >38.6</td>\n",
       "      <td id=\"T_585ec_row3_col4\" class=\"data row3 col4\" >6.2</td>\n",
       "      <td id=\"T_585ec_row3_col5\" class=\"data row3 col5\" >14.0</td>\n",
       "      <td id=\"T_585ec_row3_col6\" class=\"data row3 col6\" >32.3</td>\n",
       "      <td id=\"T_585ec_row3_col7\" class=\"data row3 col7\" >35.9</td>\n",
       "      <td id=\"T_585ec_row3_col8\" class=\"data row3 col8\" >7.5</td>\n",
       "      <td id=\"T_585ec_row3_col9\" class=\"data row3 col9\" >30.6</td>\n",
       "      <td id=\"T_585ec_row3_col10\" class=\"data row3 col10\" >11.0</td>\n",
       "      <td id=\"T_585ec_row3_col11\" class=\"data row3 col11\" >50.8</td>\n",
       "      <td id=\"T_585ec_row3_col12\" class=\"data row3 col12\" >302.1</td>\n",
       "      <td id=\"T_585ec_row3_col13\" class=\"data row3 col13\" >50.6</td>\n",
       "      <td id=\"T_585ec_row3_col14\" class=\"data row3 col14\" >35.2</td>\n",
       "      <td id=\"T_585ec_row3_col15\" class=\"data row3 col15\" >43.0</td>\n",
       "      <td id=\"T_585ec_row3_col16\" class=\"data row3 col16\" >49.8</td>\n",
       "      <td id=\"T_585ec_row3_col17\" class=\"data row3 col17\" >-21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_585ec_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_585ec_row4_col0\" class=\"data row4 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_585ec_row4_col1\" class=\"data row4 col1\" >60000</td>\n",
       "      <td id=\"T_585ec_row4_col2\" class=\"data row4 col2\" >40.2</td>\n",
       "      <td id=\"T_585ec_row4_col3\" class=\"data row4 col3\" >37.6</td>\n",
       "      <td id=\"T_585ec_row4_col4\" class=\"data row4 col4\" >5.6</td>\n",
       "      <td id=\"T_585ec_row4_col5\" class=\"data row4 col5\" >14.0</td>\n",
       "      <td id=\"T_585ec_row4_col6\" class=\"data row4 col6\" >32.2</td>\n",
       "      <td id=\"T_585ec_row4_col7\" class=\"data row4 col7\" >33.5</td>\n",
       "      <td id=\"T_585ec_row4_col8\" class=\"data row4 col8\" >8.2</td>\n",
       "      <td id=\"T_585ec_row4_col9\" class=\"data row4 col9\" >32.7</td>\n",
       "      <td id=\"T_585ec_row4_col10\" class=\"data row4 col10\" >12.4</td>\n",
       "      <td id=\"T_585ec_row4_col11\" class=\"data row4 col11\" >50.4</td>\n",
       "      <td id=\"T_585ec_row4_col12\" class=\"data row4 col12\" >288.3</td>\n",
       "      <td id=\"T_585ec_row4_col13\" class=\"data row4 col13\" >49.6</td>\n",
       "      <td id=\"T_585ec_row4_col14\" class=\"data row4 col14\" >36.6</td>\n",
       "      <td id=\"T_585ec_row4_col15\" class=\"data row4 col15\" >43.1</td>\n",
       "      <td id=\"T_585ec_row4_col16\" class=\"data row4 col16\" >48.9</td>\n",
       "      <td id=\"T_585ec_row4_col17\" class=\"data row4 col17\" >-21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_585ec_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_585ec_row5_col0\" class=\"data row5 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_585ec_row5_col1\" class=\"data row5 col1\" >None</td>\n",
       "      <td id=\"T_585ec_row5_col2\" class=\"data row5 col2\" >39.0</td>\n",
       "      <td id=\"T_585ec_row5_col3\" class=\"data row5 col3\" >38.8</td>\n",
       "      <td id=\"T_585ec_row5_col4\" class=\"data row5 col4\" >6.4</td>\n",
       "      <td id=\"T_585ec_row5_col5\" class=\"data row5 col5\" >16.0</td>\n",
       "      <td id=\"T_585ec_row5_col6\" class=\"data row5 col6\" >29.9</td>\n",
       "      <td id=\"T_585ec_row5_col7\" class=\"data row5 col7\" >34.4</td>\n",
       "      <td id=\"T_585ec_row5_col8\" class=\"data row5 col8\" >8.0</td>\n",
       "      <td id=\"T_585ec_row5_col9\" class=\"data row5 col9\" >34.9</td>\n",
       "      <td id=\"T_585ec_row5_col10\" class=\"data row5 col10\" >13.2</td>\n",
       "      <td id=\"T_585ec_row5_col11\" class=\"data row5 col11\" >46.3</td>\n",
       "      <td id=\"T_585ec_row5_col12\" class=\"data row5 col12\" >279.4</td>\n",
       "      <td id=\"T_585ec_row5_col13\" class=\"data row5 col13\" >54.4</td>\n",
       "      <td id=\"T_585ec_row5_col14\" class=\"data row5 col14\" >36.0</td>\n",
       "      <td id=\"T_585ec_row5_col15\" class=\"data row5 col15\" >45.3</td>\n",
       "      <td id=\"T_585ec_row5_col16\" class=\"data row5 col16\" >48.7</td>\n",
       "      <td id=\"T_585ec_row5_col17\" class=\"data row5 col17\" >-18.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfee69270>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_63cf8 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_63cf8_row0_col0, #T_63cf8_row1_col0, #T_63cf8_row2_col0, #T_63cf8_row3_col0, #T_63cf8_row4_col0, #T_63cf8_row5_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_63cf8_row0_col1, #T_63cf8_row1_col1, #T_63cf8_row2_col1, #T_63cf8_row3_col1, #T_63cf8_row4_col1, #T_63cf8_row5_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_63cf8_row0_col2, #T_63cf8_row0_col3, #T_63cf8_row0_col5, #T_63cf8_row0_col7, #T_63cf8_row0_col10, #T_63cf8_row0_col11, #T_63cf8_row0_col13, #T_63cf8_row0_col14, #T_63cf8_row0_col15, #T_63cf8_row0_col17, #T_63cf8_row1_col4, #T_63cf8_row1_col13, #T_63cf8_row1_col14, #T_63cf8_row1_col15, #T_63cf8_row1_col17, #T_63cf8_row2_col12, #T_63cf8_row2_col13, #T_63cf8_row2_col14, #T_63cf8_row2_col15, #T_63cf8_row2_col17, #T_63cf8_row3_col9, #T_63cf8_row3_col13, #T_63cf8_row3_col14, #T_63cf8_row3_col15, #T_63cf8_row3_col17, #T_63cf8_row4_col8, #T_63cf8_row4_col12, #T_63cf8_row4_col13, #T_63cf8_row4_col14, #T_63cf8_row4_col15, #T_63cf8_row4_col17, #T_63cf8_row5_col6, #T_63cf8_row5_col12, #T_63cf8_row5_col13, #T_63cf8_row5_col14, #T_63cf8_row5_col15, #T_63cf8_row5_col16, #T_63cf8_row5_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row0_col4, #T_63cf8_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row0_col8, #T_63cf8_row0_col9, #T_63cf8_row0_col12, #T_63cf8_row0_col16, #T_63cf8_row1_col2, #T_63cf8_row1_col5, #T_63cf8_row2_col7, #T_63cf8_row2_col10, #T_63cf8_row2_col11, #T_63cf8_row3_col6, #T_63cf8_row4_col2, #T_63cf8_row4_col3, #T_63cf8_row4_col4, #T_63cf8_row5_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row1_col10, #T_63cf8_row3_col5, #T_63cf8_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row2_col9, #T_63cf8_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row3_col4, #T_63cf8_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row3_col16, #T_63cf8_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row4_col6, #T_63cf8_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f1ccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row5_col2, #T_63cf8_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row5_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63cf8_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63cf8_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_63cf8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_63cf8_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_63cf8_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_63cf8_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_63cf8_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_63cf8_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_63cf8_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_63cf8_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_63cf8_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_63cf8_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_63cf8_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_63cf8_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_63cf8_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_63cf8_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_63cf8_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_63cf8_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_63cf8_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_63cf8_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_63cf8_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_63cf8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_63cf8_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_63cf8_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_63cf8_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_63cf8_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_63cf8_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_63cf8_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_63cf8_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_63cf8_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_63cf8_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_63cf8_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_63cf8_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_63cf8_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_63cf8_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_63cf8_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_63cf8_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_63cf8_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_63cf8_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_63cf8_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63cf8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_63cf8_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_63cf8_row1_col1\" class=\"data row1 col1\" >90000</td>\n",
       "      <td id=\"T_63cf8_row1_col2\" class=\"data row1 col2\" >40.6</td>\n",
       "      <td id=\"T_63cf8_row1_col3\" class=\"data row1 col3\" >38.5</td>\n",
       "      <td id=\"T_63cf8_row1_col4\" class=\"data row1 col4\" >5.2</td>\n",
       "      <td id=\"T_63cf8_row1_col5\" class=\"data row1 col5\" >16.6</td>\n",
       "      <td id=\"T_63cf8_row1_col6\" class=\"data row1 col6\" >33.1</td>\n",
       "      <td id=\"T_63cf8_row1_col7\" class=\"data row1 col7\" >34.5</td>\n",
       "      <td id=\"T_63cf8_row1_col8\" class=\"data row1 col8\" >8.3</td>\n",
       "      <td id=\"T_63cf8_row1_col9\" class=\"data row1 col9\" >33.8</td>\n",
       "      <td id=\"T_63cf8_row1_col10\" class=\"data row1 col10\" >12.2</td>\n",
       "      <td id=\"T_63cf8_row1_col11\" class=\"data row1 col11\" >53.9</td>\n",
       "      <td id=\"T_63cf8_row1_col12\" class=\"data row1 col12\" >294.2</td>\n",
       "      <td id=\"T_63cf8_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_63cf8_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_63cf8_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_63cf8_row1_col16\" class=\"data row1 col16\" >51.9</td>\n",
       "      <td id=\"T_63cf8_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63cf8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_63cf8_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_63cf8_row2_col1\" class=\"data row2 col1\" >90000</td>\n",
       "      <td id=\"T_63cf8_row2_col2\" class=\"data row2 col2\" >40.1</td>\n",
       "      <td id=\"T_63cf8_row2_col3\" class=\"data row2 col3\" >40.3</td>\n",
       "      <td id=\"T_63cf8_row2_col4\" class=\"data row2 col4\" >5.4</td>\n",
       "      <td id=\"T_63cf8_row2_col5\" class=\"data row2 col5\" >14.6</td>\n",
       "      <td id=\"T_63cf8_row2_col6\" class=\"data row2 col6\" >32.2</td>\n",
       "      <td id=\"T_63cf8_row2_col7\" class=\"data row2 col7\" >36.1</td>\n",
       "      <td id=\"T_63cf8_row2_col8\" class=\"data row2 col8\" >8.1</td>\n",
       "      <td id=\"T_63cf8_row2_col9\" class=\"data row2 col9\" >33.1</td>\n",
       "      <td id=\"T_63cf8_row2_col10\" class=\"data row2 col10\" >13.2</td>\n",
       "      <td id=\"T_63cf8_row2_col11\" class=\"data row2 col11\" >56.8</td>\n",
       "      <td id=\"T_63cf8_row2_col12\" class=\"data row2 col12\" >284.9</td>\n",
       "      <td id=\"T_63cf8_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_63cf8_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_63cf8_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_63cf8_row2_col16\" class=\"data row2 col16\" >51.3</td>\n",
       "      <td id=\"T_63cf8_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63cf8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_63cf8_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_63cf8_row3_col1\" class=\"data row3 col1\" >90000</td>\n",
       "      <td id=\"T_63cf8_row3_col2\" class=\"data row3 col2\" >40.2</td>\n",
       "      <td id=\"T_63cf8_row3_col3\" class=\"data row3 col3\" >38.5</td>\n",
       "      <td id=\"T_63cf8_row3_col4\" class=\"data row3 col4\" >6.4</td>\n",
       "      <td id=\"T_63cf8_row3_col5\" class=\"data row3 col5\" >15.0</td>\n",
       "      <td id=\"T_63cf8_row3_col6\" class=\"data row3 col6\" >34.0</td>\n",
       "      <td id=\"T_63cf8_row3_col7\" class=\"data row3 col7\" >34.3</td>\n",
       "      <td id=\"T_63cf8_row3_col8\" class=\"data row3 col8\" >7.9</td>\n",
       "      <td id=\"T_63cf8_row3_col9\" class=\"data row3 col9\" >32.5</td>\n",
       "      <td id=\"T_63cf8_row3_col10\" class=\"data row3 col10\" >12.6</td>\n",
       "      <td id=\"T_63cf8_row3_col11\" class=\"data row3 col11\" >53.1</td>\n",
       "      <td id=\"T_63cf8_row3_col12\" class=\"data row3 col12\" >286.6</td>\n",
       "      <td id=\"T_63cf8_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_63cf8_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_63cf8_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_63cf8_row3_col16\" class=\"data row3 col16\" >51.0</td>\n",
       "      <td id=\"T_63cf8_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63cf8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_63cf8_row4_col0\" class=\"data row4 col0\" >llama-7b_sharegpt50k_ep=3</td>\n",
       "      <td id=\"T_63cf8_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_63cf8_row4_col2\" class=\"data row4 col2\" >40.6</td>\n",
       "      <td id=\"T_63cf8_row4_col3\" class=\"data row4 col3\" >40.9</td>\n",
       "      <td id=\"T_63cf8_row4_col4\" class=\"data row4 col4\" >6.6</td>\n",
       "      <td id=\"T_63cf8_row4_col5\" class=\"data row4 col5\" >15.0</td>\n",
       "      <td id=\"T_63cf8_row4_col6\" class=\"data row4 col6\" >31.0</td>\n",
       "      <td id=\"T_63cf8_row4_col7\" class=\"data row4 col7\" >34.7</td>\n",
       "      <td id=\"T_63cf8_row4_col8\" class=\"data row4 col8\" >7.4</td>\n",
       "      <td id=\"T_63cf8_row4_col9\" class=\"data row4 col9\" >33.1</td>\n",
       "      <td id=\"T_63cf8_row4_col10\" class=\"data row4 col10\" >10.8</td>\n",
       "      <td id=\"T_63cf8_row4_col11\" class=\"data row4 col11\" >56.0</td>\n",
       "      <td id=\"T_63cf8_row4_col12\" class=\"data row4 col12\" >280.3</td>\n",
       "      <td id=\"T_63cf8_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_63cf8_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_63cf8_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_63cf8_row4_col16\" class=\"data row4 col16\" >50.6</td>\n",
       "      <td id=\"T_63cf8_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63cf8_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_63cf8_row5_col0\" class=\"data row5 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_63cf8_row5_col1\" class=\"data row5 col1\" >None</td>\n",
       "      <td id=\"T_63cf8_row5_col2\" class=\"data row5 col2\" >39.0</td>\n",
       "      <td id=\"T_63cf8_row5_col3\" class=\"data row5 col3\" >38.8</td>\n",
       "      <td id=\"T_63cf8_row5_col4\" class=\"data row5 col4\" >6.4</td>\n",
       "      <td id=\"T_63cf8_row5_col5\" class=\"data row5 col5\" >16.0</td>\n",
       "      <td id=\"T_63cf8_row5_col6\" class=\"data row5 col6\" >29.9</td>\n",
       "      <td id=\"T_63cf8_row5_col7\" class=\"data row5 col7\" >34.4</td>\n",
       "      <td id=\"T_63cf8_row5_col8\" class=\"data row5 col8\" >8.0</td>\n",
       "      <td id=\"T_63cf8_row5_col9\" class=\"data row5 col9\" >34.9</td>\n",
       "      <td id=\"T_63cf8_row5_col10\" class=\"data row5 col10\" >13.2</td>\n",
       "      <td id=\"T_63cf8_row5_col11\" class=\"data row5 col11\" >46.3</td>\n",
       "      <td id=\"T_63cf8_row5_col12\" class=\"data row5 col12\" >279.4</td>\n",
       "      <td id=\"T_63cf8_row5_col13\" class=\"data row5 col13\" >54.4</td>\n",
       "      <td id=\"T_63cf8_row5_col14\" class=\"data row5 col14\" >36.0</td>\n",
       "      <td id=\"T_63cf8_row5_col15\" class=\"data row5 col15\" >45.3</td>\n",
       "      <td id=\"T_63cf8_row5_col16\" class=\"data row5 col16\" >48.7</td>\n",
       "      <td id=\"T_63cf8_row5_col17\" class=\"data row5 col17\" >-18.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfee69270>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_139cd td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_139cd_row0_col0, #T_139cd_row1_col0, #T_139cd_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_139cd_row0_col1, #T_139cd_row1_col1, #T_139cd_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_139cd_row0_col2, #T_139cd_row0_col3, #T_139cd_row0_col4, #T_139cd_row0_col5, #T_139cd_row0_col7, #T_139cd_row0_col10, #T_139cd_row0_col11, #T_139cd_row0_col13, #T_139cd_row0_col14, #T_139cd_row0_col15, #T_139cd_row0_col17, #T_139cd_row1_col8, #T_139cd_row1_col9, #T_139cd_row1_col12, #T_139cd_row1_col13, #T_139cd_row1_col14, #T_139cd_row1_col15, #T_139cd_row1_col17, #T_139cd_row2_col6, #T_139cd_row2_col12, #T_139cd_row2_col13, #T_139cd_row2_col14, #T_139cd_row2_col15, #T_139cd_row2_col16, #T_139cd_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_139cd_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_139cd_row0_col8, #T_139cd_row0_col9, #T_139cd_row0_col12, #T_139cd_row0_col16, #T_139cd_row1_col2, #T_139cd_row1_col3, #T_139cd_row1_col4, #T_139cd_row1_col6, #T_139cd_row1_col7, #T_139cd_row1_col11, #T_139cd_row2_col5, #T_139cd_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_139cd_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_139cd_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_139cd_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_139cd_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_139cd_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_139cd_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_139cd_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_139cd_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_139cd_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_139cd_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_139cd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_139cd_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_139cd_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_139cd_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_139cd_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_139cd_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_139cd_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_139cd_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_139cd_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_139cd_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_139cd_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_139cd_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_139cd_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_139cd_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_139cd_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_139cd_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_139cd_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_139cd_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_139cd_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_139cd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_139cd_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_139cd_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_139cd_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_139cd_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_139cd_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_139cd_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_139cd_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_139cd_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_139cd_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_139cd_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_139cd_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_139cd_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_139cd_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_139cd_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_139cd_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_139cd_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_139cd_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_139cd_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_139cd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_139cd_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_ep=3</td>\n",
       "      <td id=\"T_139cd_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_139cd_row1_col2\" class=\"data row1 col2\" >40.6</td>\n",
       "      <td id=\"T_139cd_row1_col3\" class=\"data row1 col3\" >40.9</td>\n",
       "      <td id=\"T_139cd_row1_col4\" class=\"data row1 col4\" >6.6</td>\n",
       "      <td id=\"T_139cd_row1_col5\" class=\"data row1 col5\" >15.0</td>\n",
       "      <td id=\"T_139cd_row1_col6\" class=\"data row1 col6\" >31.0</td>\n",
       "      <td id=\"T_139cd_row1_col7\" class=\"data row1 col7\" >34.7</td>\n",
       "      <td id=\"T_139cd_row1_col8\" class=\"data row1 col8\" >7.4</td>\n",
       "      <td id=\"T_139cd_row1_col9\" class=\"data row1 col9\" >33.1</td>\n",
       "      <td id=\"T_139cd_row1_col10\" class=\"data row1 col10\" >10.8</td>\n",
       "      <td id=\"T_139cd_row1_col11\" class=\"data row1 col11\" >56.0</td>\n",
       "      <td id=\"T_139cd_row1_col12\" class=\"data row1 col12\" >280.3</td>\n",
       "      <td id=\"T_139cd_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_139cd_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_139cd_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_139cd_row1_col16\" class=\"data row1 col16\" >50.6</td>\n",
       "      <td id=\"T_139cd_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_139cd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_139cd_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_139cd_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_139cd_row2_col2\" class=\"data row2 col2\" >39.0</td>\n",
       "      <td id=\"T_139cd_row2_col3\" class=\"data row2 col3\" >38.8</td>\n",
       "      <td id=\"T_139cd_row2_col4\" class=\"data row2 col4\" >6.4</td>\n",
       "      <td id=\"T_139cd_row2_col5\" class=\"data row2 col5\" >16.0</td>\n",
       "      <td id=\"T_139cd_row2_col6\" class=\"data row2 col6\" >29.9</td>\n",
       "      <td id=\"T_139cd_row2_col7\" class=\"data row2 col7\" >34.4</td>\n",
       "      <td id=\"T_139cd_row2_col8\" class=\"data row2 col8\" >8.0</td>\n",
       "      <td id=\"T_139cd_row2_col9\" class=\"data row2 col9\" >34.9</td>\n",
       "      <td id=\"T_139cd_row2_col10\" class=\"data row2 col10\" >13.2</td>\n",
       "      <td id=\"T_139cd_row2_col11\" class=\"data row2 col11\" >46.3</td>\n",
       "      <td id=\"T_139cd_row2_col12\" class=\"data row2 col12\" >279.4</td>\n",
       "      <td id=\"T_139cd_row2_col13\" class=\"data row2 col13\" >54.4</td>\n",
       "      <td id=\"T_139cd_row2_col14\" class=\"data row2 col14\" >36.0</td>\n",
       "      <td id=\"T_139cd_row2_col15\" class=\"data row2 col15\" >45.3</td>\n",
       "      <td id=\"T_139cd_row2_col16\" class=\"data row2 col16\" >48.7</td>\n",
       "      <td id=\"T_139cd_row2_col17\" class=\"data row2 col17\" >-18.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf5fe4d60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c3e16 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_c3e16_row0_col0, #T_c3e16_row1_col0, #T_c3e16_row2_col0, #T_c3e16_row3_col0, #T_c3e16_row4_col0, #T_c3e16_row5_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c3e16_row0_col1, #T_c3e16_row1_col1, #T_c3e16_row2_col1, #T_c3e16_row3_col1, #T_c3e16_row4_col1, #T_c3e16_row5_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c3e16_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row0_col4, #T_c3e16_row0_col5, #T_c3e16_row0_col7, #T_c3e16_row0_col8, #T_c3e16_row0_col9, #T_c3e16_row0_col12, #T_c3e16_row0_col16, #T_c3e16_row1_col11, #T_c3e16_row2_col2, #T_c3e16_row2_col3, #T_c3e16_row2_col6, #T_c3e16_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row0_col6, #T_c3e16_row0_col11, #T_c3e16_row1_col10, #T_c3e16_row2_col5, #T_c3e16_row3_col5, #T_c3e16_row3_col8, #T_c3e16_row4_col4, #T_c3e16_row4_col9, #T_c3e16_row5_col2, #T_c3e16_row5_col3, #T_c3e16_row5_col7, #T_c3e16_row5_col12, #T_c3e16_row5_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row0_col13, #T_c3e16_row0_col14, #T_c3e16_row0_col15, #T_c3e16_row0_col17, #T_c3e16_row1_col13, #T_c3e16_row1_col14, #T_c3e16_row1_col15, #T_c3e16_row1_col17, #T_c3e16_row2_col13, #T_c3e16_row2_col14, #T_c3e16_row2_col15, #T_c3e16_row2_col17, #T_c3e16_row3_col13, #T_c3e16_row3_col14, #T_c3e16_row3_col15, #T_c3e16_row3_col17, #T_c3e16_row4_col13, #T_c3e16_row4_col14, #T_c3e16_row4_col15, #T_c3e16_row4_col17, #T_c3e16_row5_col13, #T_c3e16_row5_col14, #T_c3e16_row5_col15, #T_c3e16_row5_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row2_col4, #T_c3e16_row3_col4, #T_c3e16_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row2_col7, #T_c3e16_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row2_col12, #T_c3e16_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row3_col16, #T_c3e16_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row5_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row5_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3e16_row5_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3e16_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c3e16\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c3e16_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_c3e16_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_c3e16_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_c3e16_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_c3e16_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_c3e16_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_c3e16_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_c3e16_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_c3e16_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_c3e16_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_c3e16_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_c3e16_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_c3e16_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_c3e16_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_c3e16_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_c3e16_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_c3e16_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_c3e16_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c3e16_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c3e16_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_c3e16_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_c3e16_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_c3e16_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_c3e16_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_c3e16_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_c3e16_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_c3e16_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_c3e16_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_c3e16_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_c3e16_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_c3e16_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_c3e16_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_c3e16_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_c3e16_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_c3e16_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_c3e16_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_c3e16_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3e16_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c3e16_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_c3e16_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_c3e16_row1_col2\" class=\"data row1 col2\" >37.8</td>\n",
       "      <td id=\"T_c3e16_row1_col3\" class=\"data row1 col3\" >36.8</td>\n",
       "      <td id=\"T_c3e16_row1_col4\" class=\"data row1 col4\" >4.8</td>\n",
       "      <td id=\"T_c3e16_row1_col5\" class=\"data row1 col5\" >11.2</td>\n",
       "      <td id=\"T_c3e16_row1_col6\" class=\"data row1 col6\" >31.5</td>\n",
       "      <td id=\"T_c3e16_row1_col7\" class=\"data row1 col7\" >31.2</td>\n",
       "      <td id=\"T_c3e16_row1_col8\" class=\"data row1 col8\" >8.4</td>\n",
       "      <td id=\"T_c3e16_row1_col9\" class=\"data row1 col9\" >35.9</td>\n",
       "      <td id=\"T_c3e16_row1_col10\" class=\"data row1 col10\" >8.9</td>\n",
       "      <td id=\"T_c3e16_row1_col11\" class=\"data row1 col11\" >27.5</td>\n",
       "      <td id=\"T_c3e16_row1_col12\" class=\"data row1 col12\" >178.0</td>\n",
       "      <td id=\"T_c3e16_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_c3e16_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_c3e16_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_c3e16_row1_col16\" class=\"data row1 col16\" >37.5</td>\n",
       "      <td id=\"T_c3e16_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3e16_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c3e16_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_c3e16_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_c3e16_row2_col2\" class=\"data row2 col2\" >42.2</td>\n",
       "      <td id=\"T_c3e16_row2_col3\" class=\"data row2 col3\" >42.6</td>\n",
       "      <td id=\"T_c3e16_row2_col4\" class=\"data row2 col4\" >4.0</td>\n",
       "      <td id=\"T_c3e16_row2_col5\" class=\"data row2 col5\" >5.0</td>\n",
       "      <td id=\"T_c3e16_row2_col6\" class=\"data row2 col6\" >33.6</td>\n",
       "      <td id=\"T_c3e16_row2_col7\" class=\"data row2 col7\" >31.7</td>\n",
       "      <td id=\"T_c3e16_row2_col8\" class=\"data row2 col8\" >7.2</td>\n",
       "      <td id=\"T_c3e16_row2_col9\" class=\"data row2 col9\" >33.9</td>\n",
       "      <td id=\"T_c3e16_row2_col10\" class=\"data row2 col10\" >10.8</td>\n",
       "      <td id=\"T_c3e16_row2_col11\" class=\"data row2 col11\" >20.6</td>\n",
       "      <td id=\"T_c3e16_row2_col12\" class=\"data row2 col12\" >146.4</td>\n",
       "      <td id=\"T_c3e16_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_c3e16_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_c3e16_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_c3e16_row2_col16\" class=\"data row2 col16\" >34.4</td>\n",
       "      <td id=\"T_c3e16_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3e16_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c3e16_row3_col0\" class=\"data row3 col0\" >llama-7b_stanford_alpaca50k_ep=3</td>\n",
       "      <td id=\"T_c3e16_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_c3e16_row3_col2\" class=\"data row3 col2\" >41.8</td>\n",
       "      <td id=\"T_c3e16_row3_col3\" class=\"data row3 col3\" >41.6</td>\n",
       "      <td id=\"T_c3e16_row3_col4\" class=\"data row3 col4\" >4.0</td>\n",
       "      <td id=\"T_c3e16_row3_col5\" class=\"data row3 col5\" >5.0</td>\n",
       "      <td id=\"T_c3e16_row3_col6\" class=\"data row3 col6\" >33.1</td>\n",
       "      <td id=\"T_c3e16_row3_col7\" class=\"data row3 col7\" >31.4</td>\n",
       "      <td id=\"T_c3e16_row3_col8\" class=\"data row3 col8\" >6.5</td>\n",
       "      <td id=\"T_c3e16_row3_col9\" class=\"data row3 col9\" >33.8</td>\n",
       "      <td id=\"T_c3e16_row3_col10\" class=\"data row3 col10\" >9.8</td>\n",
       "      <td id=\"T_c3e16_row3_col11\" class=\"data row3 col11\" >24.5</td>\n",
       "      <td id=\"T_c3e16_row3_col12\" class=\"data row3 col12\" >127.4</td>\n",
       "      <td id=\"T_c3e16_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_c3e16_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_c3e16_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_c3e16_row3_col16\" class=\"data row3 col16\" >32.6</td>\n",
       "      <td id=\"T_c3e16_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3e16_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c3e16_row4_col0\" class=\"data row4 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_c3e16_row4_col1\" class=\"data row4 col1\" >10000</td>\n",
       "      <td id=\"T_c3e16_row4_col2\" class=\"data row4 col2\" >25.7</td>\n",
       "      <td id=\"T_c3e16_row4_col3\" class=\"data row4 col3\" >33.5</td>\n",
       "      <td id=\"T_c3e16_row4_col4\" class=\"data row4 col4\" >3.8</td>\n",
       "      <td id=\"T_c3e16_row4_col5\" class=\"data row4 col5\" >6.0</td>\n",
       "      <td id=\"T_c3e16_row4_col6\" class=\"data row4 col6\" >33.2</td>\n",
       "      <td id=\"T_c3e16_row4_col7\" class=\"data row4 col7\" >31.0</td>\n",
       "      <td id=\"T_c3e16_row4_col8\" class=\"data row4 col8\" >7.0</td>\n",
       "      <td id=\"T_c3e16_row4_col9\" class=\"data row4 col9\" >29.7</td>\n",
       "      <td id=\"T_c3e16_row4_col10\" class=\"data row4 col10\" >9.6</td>\n",
       "      <td id=\"T_c3e16_row4_col11\" class=\"data row4 col11\" >25.5</td>\n",
       "      <td id=\"T_c3e16_row4_col12\" class=\"data row4 col12\" >133.3</td>\n",
       "      <td id=\"T_c3e16_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_c3e16_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_c3e16_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_c3e16_row4_col16\" class=\"data row4 col16\" >30.7</td>\n",
       "      <td id=\"T_c3e16_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3e16_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c3e16_row5_col0\" class=\"data row5 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_c3e16_row5_col1\" class=\"data row5 col1\" >10000</td>\n",
       "      <td id=\"T_c3e16_row5_col2\" class=\"data row5 col2\" >25.2</td>\n",
       "      <td id=\"T_c3e16_row5_col3\" class=\"data row5 col3\" >30.3</td>\n",
       "      <td id=\"T_c3e16_row5_col4\" class=\"data row5 col4\" >4.0</td>\n",
       "      <td id=\"T_c3e16_row5_col5\" class=\"data row5 col5\" >5.6</td>\n",
       "      <td id=\"T_c3e16_row5_col6\" class=\"data row5 col6\" >32.2</td>\n",
       "      <td id=\"T_c3e16_row5_col7\" class=\"data row5 col7\" >19.7</td>\n",
       "      <td id=\"T_c3e16_row5_col8\" class=\"data row5 col8\" >7.6</td>\n",
       "      <td id=\"T_c3e16_row5_col9\" class=\"data row5 col9\" >34.2</td>\n",
       "      <td id=\"T_c3e16_row5_col10\" class=\"data row5 col10\" >9.3</td>\n",
       "      <td id=\"T_c3e16_row5_col11\" class=\"data row5 col11\" >22.7</td>\n",
       "      <td id=\"T_c3e16_row5_col12\" class=\"data row5 col12\" >114.9</td>\n",
       "      <td id=\"T_c3e16_row5_col13\" class=\"data row5 col13\" >nan</td>\n",
       "      <td id=\"T_c3e16_row5_col14\" class=\"data row5 col14\" >nan</td>\n",
       "      <td id=\"T_c3e16_row5_col15\" class=\"data row5 col15\" >nan</td>\n",
       "      <td id=\"T_c3e16_row5_col16\" class=\"data row5 col16\" >27.8</td>\n",
       "      <td id=\"T_c3e16_row5_col17\" class=\"data row5 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf5f28130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b0059 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_b0059_row0_col0, #T_b0059_row1_col0, #T_b0059_row2_col0, #T_b0059_row3_col0, #T_b0059_row4_col0, #T_b0059_row5_col0, #T_b0059_row6_col0, #T_b0059_row7_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b0059_row0_col1, #T_b0059_row1_col1, #T_b0059_row2_col1, #T_b0059_row3_col1, #T_b0059_row4_col1, #T_b0059_row5_col1, #T_b0059_row6_col1, #T_b0059_row7_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b0059_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row0_col4, #T_b0059_row0_col5, #T_b0059_row0_col8, #T_b0059_row0_col12, #T_b0059_row0_col16, #T_b0059_row1_col6, #T_b0059_row1_col7, #T_b0059_row1_col11, #T_b0059_row1_col13, #T_b0059_row1_col17, #T_b0059_row2_col2, #T_b0059_row2_col3, #T_b0059_row3_col10, #T_b0059_row4_col13, #T_b0059_row4_col14, #T_b0059_row4_col15, #T_b0059_row7_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row0_col7, #T_b0059_row6_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c83836;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row0_col9, #T_b0059_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row0_col11, #T_b0059_row1_col2, #T_b0059_row1_col3, #T_b0059_row2_col4, #T_b0059_row2_col5, #T_b0059_row3_col6, #T_b0059_row5_col4, #T_b0059_row5_col5, #T_b0059_row5_col8, #T_b0059_row5_col9, #T_b0059_row6_col4, #T_b0059_row6_col10, #T_b0059_row6_col13, #T_b0059_row6_col14, #T_b0059_row6_col15, #T_b0059_row6_col17, #T_b0059_row7_col7, #T_b0059_row7_col10, #T_b0059_row7_col12, #T_b0059_row7_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row0_col13, #T_b0059_row0_col14, #T_b0059_row0_col15, #T_b0059_row0_col17, #T_b0059_row2_col13, #T_b0059_row2_col14, #T_b0059_row2_col15, #T_b0059_row2_col17, #T_b0059_row3_col13, #T_b0059_row3_col14, #T_b0059_row3_col15, #T_b0059_row3_col17, #T_b0059_row5_col13, #T_b0059_row5_col14, #T_b0059_row5_col15, #T_b0059_row5_col17, #T_b0059_row7_col13, #T_b0059_row7_col14, #T_b0059_row7_col15, #T_b0059_row7_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row1_col4, #T_b0059_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row1_col8, #T_b0059_row6_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row1_col12, #T_b0059_row1_col16, #T_b0059_row2_col16, #T_b0059_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row2_col8, #T_b0059_row6_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row2_col12, #T_b0059_row3_col12, #T_b0059_row4_col16, #T_b0059_row5_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row4_col7, #T_b0059_row6_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row5_col2, #T_b0059_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row5_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row5_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row5_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row6_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row6_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row6_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row6_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row6_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row6_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row7_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row7_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d55042;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row7_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row7_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b0059_row7_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row7_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b0059_row7_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b0059\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b0059_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_b0059_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_b0059_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_b0059_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_b0059_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_b0059_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_b0059_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_b0059_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_b0059_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_b0059_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_b0059_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_b0059_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_b0059_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_b0059_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_b0059_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_b0059_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_b0059_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_b0059_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b0059_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b0059_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_b0059_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_b0059_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_b0059_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_b0059_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_b0059_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_b0059_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_b0059_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_b0059_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_b0059_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_b0059_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_b0059_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_b0059_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_b0059_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_b0059_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_b0059_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_b0059_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_b0059_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0059_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b0059_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_b0059_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_b0059_row1_col2\" class=\"data row1 col2\" >27.3</td>\n",
       "      <td id=\"T_b0059_row1_col3\" class=\"data row1 col3\" >30.3</td>\n",
       "      <td id=\"T_b0059_row1_col4\" class=\"data row1 col4\" >5.0</td>\n",
       "      <td id=\"T_b0059_row1_col5\" class=\"data row1 col5\" >9.8</td>\n",
       "      <td id=\"T_b0059_row1_col6\" class=\"data row1 col6\" >34.8</td>\n",
       "      <td id=\"T_b0059_row1_col7\" class=\"data row1 col7\" >33.4</td>\n",
       "      <td id=\"T_b0059_row1_col8\" class=\"data row1 col8\" >7.8</td>\n",
       "      <td id=\"T_b0059_row1_col9\" class=\"data row1 col9\" >37.4</td>\n",
       "      <td id=\"T_b0059_row1_col10\" class=\"data row1 col10\" >9.6</td>\n",
       "      <td id=\"T_b0059_row1_col11\" class=\"data row1 col11\" >25.3</td>\n",
       "      <td id=\"T_b0059_row1_col12\" class=\"data row1 col12\" >161.5</td>\n",
       "      <td id=\"T_b0059_row1_col13\" class=\"data row1 col13\" >40.6</td>\n",
       "      <td id=\"T_b0059_row1_col14\" class=\"data row1 col14\" >27.5</td>\n",
       "      <td id=\"T_b0059_row1_col15\" class=\"data row1 col15\" >34.1</td>\n",
       "      <td id=\"T_b0059_row1_col16\" class=\"data row1 col16\" >34.6</td>\n",
       "      <td id=\"T_b0059_row1_col17\" class=\"data row1 col17\" >-43.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0059_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b0059_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_b0059_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_b0059_row2_col2\" class=\"data row2 col2\" >42.2</td>\n",
       "      <td id=\"T_b0059_row2_col3\" class=\"data row2 col3\" >42.6</td>\n",
       "      <td id=\"T_b0059_row2_col4\" class=\"data row2 col4\" >4.0</td>\n",
       "      <td id=\"T_b0059_row2_col5\" class=\"data row2 col5\" >5.0</td>\n",
       "      <td id=\"T_b0059_row2_col6\" class=\"data row2 col6\" >33.6</td>\n",
       "      <td id=\"T_b0059_row2_col7\" class=\"data row2 col7\" >31.7</td>\n",
       "      <td id=\"T_b0059_row2_col8\" class=\"data row2 col8\" >7.2</td>\n",
       "      <td id=\"T_b0059_row2_col9\" class=\"data row2 col9\" >33.9</td>\n",
       "      <td id=\"T_b0059_row2_col10\" class=\"data row2 col10\" >10.8</td>\n",
       "      <td id=\"T_b0059_row2_col11\" class=\"data row2 col11\" >20.6</td>\n",
       "      <td id=\"T_b0059_row2_col12\" class=\"data row2 col12\" >146.4</td>\n",
       "      <td id=\"T_b0059_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_b0059_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_b0059_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_b0059_row2_col16\" class=\"data row2 col16\" >34.4</td>\n",
       "      <td id=\"T_b0059_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0059_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b0059_row3_col0\" class=\"data row3 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_b0059_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_b0059_row3_col2\" class=\"data row3 col2\" >37.4</td>\n",
       "      <td id=\"T_b0059_row3_col3\" class=\"data row3 col3\" >38.5</td>\n",
       "      <td id=\"T_b0059_row3_col4\" class=\"data row3 col4\" >4.6</td>\n",
       "      <td id=\"T_b0059_row3_col5\" class=\"data row3 col5\" >9.2</td>\n",
       "      <td id=\"T_b0059_row3_col6\" class=\"data row3 col6\" >30.0</td>\n",
       "      <td id=\"T_b0059_row3_col7\" class=\"data row3 col7\" >29.8</td>\n",
       "      <td id=\"T_b0059_row3_col8\" class=\"data row3 col8\" >6.6</td>\n",
       "      <td id=\"T_b0059_row3_col9\" class=\"data row3 col9\" >35.4</td>\n",
       "      <td id=\"T_b0059_row3_col10\" class=\"data row3 col10\" >11.2</td>\n",
       "      <td id=\"T_b0059_row3_col11\" class=\"data row3 col11\" >23.8</td>\n",
       "      <td id=\"T_b0059_row3_col12\" class=\"data row3 col12\" >148.6</td>\n",
       "      <td id=\"T_b0059_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_b0059_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_b0059_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_b0059_row3_col16\" class=\"data row3 col16\" >34.1</td>\n",
       "      <td id=\"T_b0059_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0059_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b0059_row4_col0\" class=\"data row4 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_b0059_row4_col1\" class=\"data row4 col1\" >30000</td>\n",
       "      <td id=\"T_b0059_row4_col2\" class=\"data row4 col2\" >35.6</td>\n",
       "      <td id=\"T_b0059_row4_col3\" class=\"data row4 col3\" >38.3</td>\n",
       "      <td id=\"T_b0059_row4_col4\" class=\"data row4 col4\" >5.0</td>\n",
       "      <td id=\"T_b0059_row4_col5\" class=\"data row4 col5\" >5.2</td>\n",
       "      <td id=\"T_b0059_row4_col6\" class=\"data row4 col6\" >31.3</td>\n",
       "      <td id=\"T_b0059_row4_col7\" class=\"data row4 col7\" >31.9</td>\n",
       "      <td id=\"T_b0059_row4_col8\" class=\"data row4 col8\" >7.1</td>\n",
       "      <td id=\"T_b0059_row4_col9\" class=\"data row4 col9\" >35.8</td>\n",
       "      <td id=\"T_b0059_row4_col10\" class=\"data row4 col10\" >8.7</td>\n",
       "      <td id=\"T_b0059_row4_col11\" class=\"data row4 col11\" >24.7</td>\n",
       "      <td id=\"T_b0059_row4_col12\" class=\"data row4 col12\" >137.7</td>\n",
       "      <td id=\"T_b0059_row4_col13\" class=\"data row4 col13\" >40.6</td>\n",
       "      <td id=\"T_b0059_row4_col14\" class=\"data row4 col14\" >27.7</td>\n",
       "      <td id=\"T_b0059_row4_col15\" class=\"data row4 col15\" >34.3</td>\n",
       "      <td id=\"T_b0059_row4_col16\" class=\"data row4 col16\" >33.1</td>\n",
       "      <td id=\"T_b0059_row4_col17\" class=\"data row4 col17\" >-47.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0059_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b0059_row5_col0\" class=\"data row5 col0\" >llama-7b_stanford_alpaca50k_ep=3</td>\n",
       "      <td id=\"T_b0059_row5_col1\" class=\"data row5 col1\" >None</td>\n",
       "      <td id=\"T_b0059_row5_col2\" class=\"data row5 col2\" >41.8</td>\n",
       "      <td id=\"T_b0059_row5_col3\" class=\"data row5 col3\" >41.6</td>\n",
       "      <td id=\"T_b0059_row5_col4\" class=\"data row5 col4\" >4.0</td>\n",
       "      <td id=\"T_b0059_row5_col5\" class=\"data row5 col5\" >5.0</td>\n",
       "      <td id=\"T_b0059_row5_col6\" class=\"data row5 col6\" >33.1</td>\n",
       "      <td id=\"T_b0059_row5_col7\" class=\"data row5 col7\" >31.4</td>\n",
       "      <td id=\"T_b0059_row5_col8\" class=\"data row5 col8\" >6.5</td>\n",
       "      <td id=\"T_b0059_row5_col9\" class=\"data row5 col9\" >33.8</td>\n",
       "      <td id=\"T_b0059_row5_col10\" class=\"data row5 col10\" >9.8</td>\n",
       "      <td id=\"T_b0059_row5_col11\" class=\"data row5 col11\" >24.5</td>\n",
       "      <td id=\"T_b0059_row5_col12\" class=\"data row5 col12\" >127.4</td>\n",
       "      <td id=\"T_b0059_row5_col13\" class=\"data row5 col13\" >nan</td>\n",
       "      <td id=\"T_b0059_row5_col14\" class=\"data row5 col14\" >nan</td>\n",
       "      <td id=\"T_b0059_row5_col15\" class=\"data row5 col15\" >nan</td>\n",
       "      <td id=\"T_b0059_row5_col16\" class=\"data row5 col16\" >32.6</td>\n",
       "      <td id=\"T_b0059_row5_col17\" class=\"data row5 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0059_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b0059_row6_col0\" class=\"data row6 col0\" >llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_b0059_row6_col1\" class=\"data row6 col1\" >30000</td>\n",
       "      <td id=\"T_b0059_row6_col2\" class=\"data row6 col2\" >30.9</td>\n",
       "      <td id=\"T_b0059_row6_col3\" class=\"data row6 col3\" >33.6</td>\n",
       "      <td id=\"T_b0059_row6_col4\" class=\"data row6 col4\" >4.0</td>\n",
       "      <td id=\"T_b0059_row6_col5\" class=\"data row6 col5\" >5.6</td>\n",
       "      <td id=\"T_b0059_row6_col6\" class=\"data row6 col6\" >34.5</td>\n",
       "      <td id=\"T_b0059_row6_col7\" class=\"data row6 col7\" >32.3</td>\n",
       "      <td id=\"T_b0059_row6_col8\" class=\"data row6 col8\" >7.9</td>\n",
       "      <td id=\"T_b0059_row6_col9\" class=\"data row6 col9\" >36.8</td>\n",
       "      <td id=\"T_b0059_row6_col10\" class=\"data row6 col10\" >8.5</td>\n",
       "      <td id=\"T_b0059_row6_col11\" class=\"data row6 col11\" >22.4</td>\n",
       "      <td id=\"T_b0059_row6_col12\" class=\"data row6 col12\" >121.3</td>\n",
       "      <td id=\"T_b0059_row6_col13\" class=\"data row6 col13\" >39.5</td>\n",
       "      <td id=\"T_b0059_row6_col14\" class=\"data row6 col14\" >26.6</td>\n",
       "      <td id=\"T_b0059_row6_col15\" class=\"data row6 col15\" >33.1</td>\n",
       "      <td id=\"T_b0059_row6_col16\" class=\"data row6 col16\" >31.2</td>\n",
       "      <td id=\"T_b0059_row6_col17\" class=\"data row6 col17\" >-50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0059_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b0059_row7_col0\" class=\"data row7 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-2:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_b0059_row7_col1\" class=\"data row7 col1\" >30000</td>\n",
       "      <td id=\"T_b0059_row7_col2\" class=\"data row7 col2\" >41.2</td>\n",
       "      <td id=\"T_b0059_row7_col3\" class=\"data row7 col3\" >41.4</td>\n",
       "      <td id=\"T_b0059_row7_col4\" class=\"data row7 col4\" >4.8</td>\n",
       "      <td id=\"T_b0059_row7_col5\" class=\"data row7 col5\" >5.8</td>\n",
       "      <td id=\"T_b0059_row7_col6\" class=\"data row7 col6\" >32.8</td>\n",
       "      <td id=\"T_b0059_row7_col7\" class=\"data row7 col7\" >19.9</td>\n",
       "      <td id=\"T_b0059_row7_col8\" class=\"data row7 col8\" >8.7</td>\n",
       "      <td id=\"T_b0059_row7_col9\" class=\"data row7 col9\" >41.3</td>\n",
       "      <td id=\"T_b0059_row7_col10\" class=\"data row7 col10\" >8.5</td>\n",
       "      <td id=\"T_b0059_row7_col11\" class=\"data row7 col11\" >8.9</td>\n",
       "      <td id=\"T_b0059_row7_col12\" class=\"data row7 col12\" >54.2</td>\n",
       "      <td id=\"T_b0059_row7_col13\" class=\"data row7 col13\" >nan</td>\n",
       "      <td id=\"T_b0059_row7_col14\" class=\"data row7 col14\" >nan</td>\n",
       "      <td id=\"T_b0059_row7_col15\" class=\"data row7 col15\" >nan</td>\n",
       "      <td id=\"T_b0059_row7_col16\" class=\"data row7 col16\" >24.3</td>\n",
       "      <td id=\"T_b0059_row7_col17\" class=\"data row7 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf72f25f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_344db td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_344db_row0_col0, #T_344db_row1_col0, #T_344db_row2_col0, #T_344db_row3_col0, #T_344db_row4_col0, #T_344db_row5_col0, #T_344db_row6_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_344db_row0_col1, #T_344db_row1_col1, #T_344db_row2_col1, #T_344db_row3_col1, #T_344db_row4_col1, #T_344db_row5_col1, #T_344db_row6_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_344db_row0_col2, #T_344db_row0_col3, #T_344db_row0_col6, #T_344db_row0_col11, #T_344db_row2_col5, #T_344db_row5_col4, #T_344db_row5_col10, #T_344db_row6_col5, #T_344db_row6_col7, #T_344db_row6_col8, #T_344db_row6_col9, #T_344db_row6_col12, #T_344db_row6_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row0_col4, #T_344db_row0_col5, #T_344db_row0_col8, #T_344db_row0_col9, #T_344db_row0_col12, #T_344db_row0_col16, #T_344db_row2_col2, #T_344db_row2_col3, #T_344db_row2_col10, #T_344db_row4_col7, #T_344db_row4_col11, #T_344db_row5_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row0_col13, #T_344db_row0_col14, #T_344db_row0_col15, #T_344db_row0_col17, #T_344db_row1_col13, #T_344db_row1_col14, #T_344db_row1_col15, #T_344db_row1_col17, #T_344db_row2_col13, #T_344db_row2_col14, #T_344db_row2_col15, #T_344db_row2_col17, #T_344db_row3_col13, #T_344db_row3_col14, #T_344db_row3_col15, #T_344db_row3_col17, #T_344db_row4_col13, #T_344db_row4_col14, #T_344db_row4_col15, #T_344db_row4_col17, #T_344db_row5_col13, #T_344db_row5_col14, #T_344db_row5_col15, #T_344db_row5_col17, #T_344db_row6_col13, #T_344db_row6_col14, #T_344db_row6_col15, #T_344db_row6_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row1_col7, #T_344db_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row1_col10, #T_344db_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row2_col4, #T_344db_row3_col4, #T_344db_row6_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ed8366;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row2_col12, #T_344db_row2_col16, #T_344db_row3_col12, #T_344db_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f2c9b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row3_col9, #T_344db_row6_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row4_col12, #T_344db_row4_col16, #T_344db_row5_col12, #T_344db_row5_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row5_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row5_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_344db_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row6_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row6_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row6_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_344db_row6_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_344db\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_344db_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_344db_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_344db_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_344db_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_344db_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_344db_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_344db_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_344db_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_344db_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_344db_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_344db_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_344db_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_344db_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_344db_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_344db_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_344db_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_344db_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_344db_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_344db_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_344db_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_344db_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_344db_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_344db_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_344db_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_344db_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_344db_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_344db_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_344db_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_344db_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_344db_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_344db_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_344db_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_344db_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_344db_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_344db_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_344db_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_344db_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_344db_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_344db_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_344db_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_344db_row1_col2\" class=\"data row1 col2\" >38.7</td>\n",
       "      <td id=\"T_344db_row1_col3\" class=\"data row1 col3\" >38.1</td>\n",
       "      <td id=\"T_344db_row1_col4\" class=\"data row1 col4\" >4.8</td>\n",
       "      <td id=\"T_344db_row1_col5\" class=\"data row1 col5\" >6.0</td>\n",
       "      <td id=\"T_344db_row1_col6\" class=\"data row1 col6\" >31.3</td>\n",
       "      <td id=\"T_344db_row1_col7\" class=\"data row1 col7\" >31.8</td>\n",
       "      <td id=\"T_344db_row1_col8\" class=\"data row1 col8\" >7.7</td>\n",
       "      <td id=\"T_344db_row1_col9\" class=\"data row1 col9\" >35.6</td>\n",
       "      <td id=\"T_344db_row1_col10\" class=\"data row1 col10\" >9.1</td>\n",
       "      <td id=\"T_344db_row1_col11\" class=\"data row1 col11\" >25.6</td>\n",
       "      <td id=\"T_344db_row1_col12\" class=\"data row1 col12\" >164.8</td>\n",
       "      <td id=\"T_344db_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_344db_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_344db_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_344db_row1_col16\" class=\"data row1 col16\" >35.8</td>\n",
       "      <td id=\"T_344db_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_344db_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_344db_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_344db_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_344db_row2_col2\" class=\"data row2 col2\" >42.2</td>\n",
       "      <td id=\"T_344db_row2_col3\" class=\"data row2 col3\" >42.6</td>\n",
       "      <td id=\"T_344db_row2_col4\" class=\"data row2 col4\" >4.0</td>\n",
       "      <td id=\"T_344db_row2_col5\" class=\"data row2 col5\" >5.0</td>\n",
       "      <td id=\"T_344db_row2_col6\" class=\"data row2 col6\" >33.6</td>\n",
       "      <td id=\"T_344db_row2_col7\" class=\"data row2 col7\" >31.7</td>\n",
       "      <td id=\"T_344db_row2_col8\" class=\"data row2 col8\" >7.2</td>\n",
       "      <td id=\"T_344db_row2_col9\" class=\"data row2 col9\" >33.9</td>\n",
       "      <td id=\"T_344db_row2_col10\" class=\"data row2 col10\" >10.8</td>\n",
       "      <td id=\"T_344db_row2_col11\" class=\"data row2 col11\" >20.6</td>\n",
       "      <td id=\"T_344db_row2_col12\" class=\"data row2 col12\" >146.4</td>\n",
       "      <td id=\"T_344db_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_344db_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_344db_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_344db_row2_col16\" class=\"data row2 col16\" >34.4</td>\n",
       "      <td id=\"T_344db_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_344db_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_344db_row3_col0\" class=\"data row3 col0\" >llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_344db_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_344db_row3_col2\" class=\"data row3 col2\" >38.4</td>\n",
       "      <td id=\"T_344db_row3_col3\" class=\"data row3 col3\" >38.5</td>\n",
       "      <td id=\"T_344db_row3_col4\" class=\"data row3 col4\" >4.0</td>\n",
       "      <td id=\"T_344db_row3_col5\" class=\"data row3 col5\" >8.2</td>\n",
       "      <td id=\"T_344db_row3_col6\" class=\"data row3 col6\" >32.5</td>\n",
       "      <td id=\"T_344db_row3_col7\" class=\"data row3 col7\" >32.0</td>\n",
       "      <td id=\"T_344db_row3_col8\" class=\"data row3 col8\" >7.5</td>\n",
       "      <td id=\"T_344db_row3_col9\" class=\"data row3 col9\" >38.2</td>\n",
       "      <td id=\"T_344db_row3_col10\" class=\"data row3 col10\" >9.1</td>\n",
       "      <td id=\"T_344db_row3_col11\" class=\"data row3 col11\" >22.4</td>\n",
       "      <td id=\"T_344db_row3_col12\" class=\"data row3 col12\" >143.2</td>\n",
       "      <td id=\"T_344db_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_344db_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_344db_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_344db_row3_col16\" class=\"data row3 col16\" >34.0</td>\n",
       "      <td id=\"T_344db_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_344db_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_344db_row4_col0\" class=\"data row4 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_344db_row4_col1\" class=\"data row4 col1\" >60000</td>\n",
       "      <td id=\"T_344db_row4_col2\" class=\"data row4 col2\" >40.3</td>\n",
       "      <td id=\"T_344db_row4_col3\" class=\"data row4 col3\" >41.3</td>\n",
       "      <td id=\"T_344db_row4_col4\" class=\"data row4 col4\" >4.2</td>\n",
       "      <td id=\"T_344db_row4_col5\" class=\"data row4 col5\" >6.2</td>\n",
       "      <td id=\"T_344db_row4_col6\" class=\"data row4 col6\" >32.4</td>\n",
       "      <td id=\"T_344db_row4_col7\" class=\"data row4 col7\" >33.3</td>\n",
       "      <td id=\"T_344db_row4_col8\" class=\"data row4 col8\" >7.6</td>\n",
       "      <td id=\"T_344db_row4_col9\" class=\"data row4 col9\" >35.3</td>\n",
       "      <td id=\"T_344db_row4_col10\" class=\"data row4 col10\" >8.1</td>\n",
       "      <td id=\"T_344db_row4_col11\" class=\"data row4 col11\" >25.7</td>\n",
       "      <td id=\"T_344db_row4_col12\" class=\"data row4 col12\" >136.5</td>\n",
       "      <td id=\"T_344db_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_344db_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_344db_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_344db_row4_col16\" class=\"data row4 col16\" >33.7</td>\n",
       "      <td id=\"T_344db_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_344db_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_344db_row5_col0\" class=\"data row5 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_344db_row5_col1\" class=\"data row5 col1\" >60000</td>\n",
       "      <td id=\"T_344db_row5_col2\" class=\"data row5 col2\" >41.9</td>\n",
       "      <td id=\"T_344db_row5_col3\" class=\"data row5 col3\" >41.9</td>\n",
       "      <td id=\"T_344db_row5_col4\" class=\"data row5 col4\" >3.4</td>\n",
       "      <td id=\"T_344db_row5_col5\" class=\"data row5 col5\" >6.6</td>\n",
       "      <td id=\"T_344db_row5_col6\" class=\"data row5 col6\" >33.7</td>\n",
       "      <td id=\"T_344db_row5_col7\" class=\"data row5 col7\" >32.1</td>\n",
       "      <td id=\"T_344db_row5_col8\" class=\"data row5 col8\" >6.8</td>\n",
       "      <td id=\"T_344db_row5_col9\" class=\"data row5 col9\" >34.7</td>\n",
       "      <td id=\"T_344db_row5_col10\" class=\"data row5 col10\" >6.9</td>\n",
       "      <td id=\"T_344db_row5_col11\" class=\"data row5 col11\" >23.4</td>\n",
       "      <td id=\"T_344db_row5_col12\" class=\"data row5 col12\" >135.6</td>\n",
       "      <td id=\"T_344db_row5_col13\" class=\"data row5 col13\" >nan</td>\n",
       "      <td id=\"T_344db_row5_col14\" class=\"data row5 col14\" >nan</td>\n",
       "      <td id=\"T_344db_row5_col15\" class=\"data row5 col15\" >nan</td>\n",
       "      <td id=\"T_344db_row5_col16\" class=\"data row5 col16\" >33.4</td>\n",
       "      <td id=\"T_344db_row5_col17\" class=\"data row5 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_344db_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_344db_row6_col0\" class=\"data row6 col0\" >llama-7b_stanford_alpaca50k_ep=3</td>\n",
       "      <td id=\"T_344db_row6_col1\" class=\"data row6 col1\" >None</td>\n",
       "      <td id=\"T_344db_row6_col2\" class=\"data row6 col2\" >41.8</td>\n",
       "      <td id=\"T_344db_row6_col3\" class=\"data row6 col3\" >41.6</td>\n",
       "      <td id=\"T_344db_row6_col4\" class=\"data row6 col4\" >4.0</td>\n",
       "      <td id=\"T_344db_row6_col5\" class=\"data row6 col5\" >5.0</td>\n",
       "      <td id=\"T_344db_row6_col6\" class=\"data row6 col6\" >33.1</td>\n",
       "      <td id=\"T_344db_row6_col7\" class=\"data row6 col7\" >31.4</td>\n",
       "      <td id=\"T_344db_row6_col8\" class=\"data row6 col8\" >6.5</td>\n",
       "      <td id=\"T_344db_row6_col9\" class=\"data row6 col9\" >33.8</td>\n",
       "      <td id=\"T_344db_row6_col10\" class=\"data row6 col10\" >9.8</td>\n",
       "      <td id=\"T_344db_row6_col11\" class=\"data row6 col11\" >24.5</td>\n",
       "      <td id=\"T_344db_row6_col12\" class=\"data row6 col12\" >127.4</td>\n",
       "      <td id=\"T_344db_row6_col13\" class=\"data row6 col13\" >nan</td>\n",
       "      <td id=\"T_344db_row6_col14\" class=\"data row6 col14\" >nan</td>\n",
       "      <td id=\"T_344db_row6_col15\" class=\"data row6 col15\" >nan</td>\n",
       "      <td id=\"T_344db_row6_col16\" class=\"data row6 col16\" >32.6</td>\n",
       "      <td id=\"T_344db_row6_col17\" class=\"data row6 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf60e8dc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0ec09 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_0ec09_row0_col0, #T_0ec09_row1_col0, #T_0ec09_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0ec09_row0_col1, #T_0ec09_row1_col1, #T_0ec09_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0ec09_row0_col2, #T_0ec09_row0_col3, #T_0ec09_row0_col6, #T_0ec09_row0_col11, #T_0ec09_row1_col4, #T_0ec09_row1_col5, #T_0ec09_row2_col4, #T_0ec09_row2_col5, #T_0ec09_row2_col7, #T_0ec09_row2_col8, #T_0ec09_row2_col9, #T_0ec09_row2_col10, #T_0ec09_row2_col12, #T_0ec09_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0ec09_row0_col4, #T_0ec09_row0_col5, #T_0ec09_row0_col7, #T_0ec09_row0_col8, #T_0ec09_row0_col9, #T_0ec09_row0_col12, #T_0ec09_row0_col16, #T_0ec09_row1_col2, #T_0ec09_row1_col3, #T_0ec09_row1_col6, #T_0ec09_row1_col10, #T_0ec09_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0ec09_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0ec09_row0_col13, #T_0ec09_row0_col14, #T_0ec09_row0_col15, #T_0ec09_row0_col17, #T_0ec09_row1_col13, #T_0ec09_row1_col14, #T_0ec09_row1_col15, #T_0ec09_row1_col17, #T_0ec09_row2_col13, #T_0ec09_row2_col14, #T_0ec09_row2_col15, #T_0ec09_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0ec09_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0ec09_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0ec09_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0ec09_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0ec09_row1_col12, #T_0ec09_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0ec09_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0ec09_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0ec09_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0ec09\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0ec09_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_0ec09_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_0ec09_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_0ec09_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_0ec09_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_0ec09_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_0ec09_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_0ec09_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_0ec09_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_0ec09_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_0ec09_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_0ec09_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_0ec09_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_0ec09_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_0ec09_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_0ec09_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_0ec09_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_0ec09_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0ec09_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0ec09_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_0ec09_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_0ec09_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_0ec09_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_0ec09_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_0ec09_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_0ec09_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_0ec09_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_0ec09_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_0ec09_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_0ec09_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_0ec09_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_0ec09_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_0ec09_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_0ec09_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_0ec09_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_0ec09_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_0ec09_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0ec09_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0ec09_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_0ec09_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_0ec09_row1_col2\" class=\"data row1 col2\" >42.2</td>\n",
       "      <td id=\"T_0ec09_row1_col3\" class=\"data row1 col3\" >42.6</td>\n",
       "      <td id=\"T_0ec09_row1_col4\" class=\"data row1 col4\" >4.0</td>\n",
       "      <td id=\"T_0ec09_row1_col5\" class=\"data row1 col5\" >5.0</td>\n",
       "      <td id=\"T_0ec09_row1_col6\" class=\"data row1 col6\" >33.6</td>\n",
       "      <td id=\"T_0ec09_row1_col7\" class=\"data row1 col7\" >31.7</td>\n",
       "      <td id=\"T_0ec09_row1_col8\" class=\"data row1 col8\" >7.2</td>\n",
       "      <td id=\"T_0ec09_row1_col9\" class=\"data row1 col9\" >33.9</td>\n",
       "      <td id=\"T_0ec09_row1_col10\" class=\"data row1 col10\" >10.8</td>\n",
       "      <td id=\"T_0ec09_row1_col11\" class=\"data row1 col11\" >20.6</td>\n",
       "      <td id=\"T_0ec09_row1_col12\" class=\"data row1 col12\" >146.4</td>\n",
       "      <td id=\"T_0ec09_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_0ec09_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_0ec09_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_0ec09_row1_col16\" class=\"data row1 col16\" >34.4</td>\n",
       "      <td id=\"T_0ec09_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0ec09_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0ec09_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca50k_ep=3</td>\n",
       "      <td id=\"T_0ec09_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_0ec09_row2_col2\" class=\"data row2 col2\" >41.8</td>\n",
       "      <td id=\"T_0ec09_row2_col3\" class=\"data row2 col3\" >41.6</td>\n",
       "      <td id=\"T_0ec09_row2_col4\" class=\"data row2 col4\" >4.0</td>\n",
       "      <td id=\"T_0ec09_row2_col5\" class=\"data row2 col5\" >5.0</td>\n",
       "      <td id=\"T_0ec09_row2_col6\" class=\"data row2 col6\" >33.1</td>\n",
       "      <td id=\"T_0ec09_row2_col7\" class=\"data row2 col7\" >31.4</td>\n",
       "      <td id=\"T_0ec09_row2_col8\" class=\"data row2 col8\" >6.5</td>\n",
       "      <td id=\"T_0ec09_row2_col9\" class=\"data row2 col9\" >33.8</td>\n",
       "      <td id=\"T_0ec09_row2_col10\" class=\"data row2 col10\" >9.8</td>\n",
       "      <td id=\"T_0ec09_row2_col11\" class=\"data row2 col11\" >24.5</td>\n",
       "      <td id=\"T_0ec09_row2_col12\" class=\"data row2 col12\" >127.4</td>\n",
       "      <td id=\"T_0ec09_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_0ec09_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_0ec09_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_0ec09_row2_col16\" class=\"data row2 col16\" >32.6</td>\n",
       "      <td id=\"T_0ec09_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf515e140>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7bfe5 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_7bfe5_row0_col0, #T_7bfe5_row1_col0, #T_7bfe5_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7bfe5_row0_col1, #T_7bfe5_row1_col1, #T_7bfe5_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7bfe5_row0_col2, #T_7bfe5_row0_col3, #T_7bfe5_row0_col6, #T_7bfe5_row0_col11, #T_7bfe5_row1_col4, #T_7bfe5_row1_col5, #T_7bfe5_row2_col4, #T_7bfe5_row2_col5, #T_7bfe5_row2_col7, #T_7bfe5_row2_col8, #T_7bfe5_row2_col9, #T_7bfe5_row2_col10, #T_7bfe5_row2_col12, #T_7bfe5_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7bfe5_row0_col4, #T_7bfe5_row0_col5, #T_7bfe5_row0_col7, #T_7bfe5_row0_col8, #T_7bfe5_row0_col9, #T_7bfe5_row0_col12, #T_7bfe5_row0_col16, #T_7bfe5_row1_col2, #T_7bfe5_row1_col3, #T_7bfe5_row1_col6, #T_7bfe5_row1_col10, #T_7bfe5_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7bfe5_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7bfe5_row0_col13, #T_7bfe5_row0_col14, #T_7bfe5_row0_col15, #T_7bfe5_row0_col17, #T_7bfe5_row1_col13, #T_7bfe5_row1_col14, #T_7bfe5_row1_col15, #T_7bfe5_row1_col17, #T_7bfe5_row2_col13, #T_7bfe5_row2_col14, #T_7bfe5_row2_col15, #T_7bfe5_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7bfe5_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7bfe5_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7bfe5_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7bfe5_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7bfe5_row1_col12, #T_7bfe5_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7bfe5_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7bfe5_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7bfe5_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7bfe5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7bfe5_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_7bfe5_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_7bfe5_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_7bfe5_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_7bfe5_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_7bfe5_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_7bfe5_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_7bfe5_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_7bfe5_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_7bfe5_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_7bfe5_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_7bfe5_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_7bfe5_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_7bfe5_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_7bfe5_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_7bfe5_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_7bfe5_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_7bfe5_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7bfe5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7bfe5_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_7bfe5_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_7bfe5_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_7bfe5_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_7bfe5_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_7bfe5_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_7bfe5_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_7bfe5_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_7bfe5_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_7bfe5_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_7bfe5_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_7bfe5_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_7bfe5_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_7bfe5_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_7bfe5_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_7bfe5_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_7bfe5_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_7bfe5_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7bfe5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7bfe5_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_7bfe5_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_7bfe5_row1_col2\" class=\"data row1 col2\" >42.2</td>\n",
       "      <td id=\"T_7bfe5_row1_col3\" class=\"data row1 col3\" >42.6</td>\n",
       "      <td id=\"T_7bfe5_row1_col4\" class=\"data row1 col4\" >4.0</td>\n",
       "      <td id=\"T_7bfe5_row1_col5\" class=\"data row1 col5\" >5.0</td>\n",
       "      <td id=\"T_7bfe5_row1_col6\" class=\"data row1 col6\" >33.6</td>\n",
       "      <td id=\"T_7bfe5_row1_col7\" class=\"data row1 col7\" >31.7</td>\n",
       "      <td id=\"T_7bfe5_row1_col8\" class=\"data row1 col8\" >7.2</td>\n",
       "      <td id=\"T_7bfe5_row1_col9\" class=\"data row1 col9\" >33.9</td>\n",
       "      <td id=\"T_7bfe5_row1_col10\" class=\"data row1 col10\" >10.8</td>\n",
       "      <td id=\"T_7bfe5_row1_col11\" class=\"data row1 col11\" >20.6</td>\n",
       "      <td id=\"T_7bfe5_row1_col12\" class=\"data row1 col12\" >146.4</td>\n",
       "      <td id=\"T_7bfe5_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_7bfe5_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_7bfe5_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_7bfe5_row1_col16\" class=\"data row1 col16\" >34.4</td>\n",
       "      <td id=\"T_7bfe5_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7bfe5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7bfe5_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca50k_ep=3</td>\n",
       "      <td id=\"T_7bfe5_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_7bfe5_row2_col2\" class=\"data row2 col2\" >41.8</td>\n",
       "      <td id=\"T_7bfe5_row2_col3\" class=\"data row2 col3\" >41.6</td>\n",
       "      <td id=\"T_7bfe5_row2_col4\" class=\"data row2 col4\" >4.0</td>\n",
       "      <td id=\"T_7bfe5_row2_col5\" class=\"data row2 col5\" >5.0</td>\n",
       "      <td id=\"T_7bfe5_row2_col6\" class=\"data row2 col6\" >33.1</td>\n",
       "      <td id=\"T_7bfe5_row2_col7\" class=\"data row2 col7\" >31.4</td>\n",
       "      <td id=\"T_7bfe5_row2_col8\" class=\"data row2 col8\" >6.5</td>\n",
       "      <td id=\"T_7bfe5_row2_col9\" class=\"data row2 col9\" >33.8</td>\n",
       "      <td id=\"T_7bfe5_row2_col10\" class=\"data row2 col10\" >9.8</td>\n",
       "      <td id=\"T_7bfe5_row2_col11\" class=\"data row2 col11\" >24.5</td>\n",
       "      <td id=\"T_7bfe5_row2_col12\" class=\"data row2 col12\" >127.4</td>\n",
       "      <td id=\"T_7bfe5_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_7bfe5_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_7bfe5_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_7bfe5_row2_col16\" class=\"data row2 col16\" >32.6</td>\n",
       "      <td id=\"T_7bfe5_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfee6bc70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_19697 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_19697_row0_col0, #T_19697_row1_col0, #T_19697_row2_col0, #T_19697_row3_col0, #T_19697_row4_col0, #T_19697_row5_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_19697_row0_col1, #T_19697_row1_col1, #T_19697_row2_col1, #T_19697_row3_col1, #T_19697_row4_col1, #T_19697_row5_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_19697_row0_col2, #T_19697_row0_col3, #T_19697_row0_col4, #T_19697_row0_col11, #T_19697_row3_col4, #T_19697_row4_col5, #T_19697_row4_col6, #T_19697_row4_col8, #T_19697_row4_col9, #T_19697_row4_col10, #T_19697_row4_col16, #T_19697_row5_col6, #T_19697_row5_col7, #T_19697_row5_col12, #T_19697_row5_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row0_col8, #T_19697_row0_col9, #T_19697_row0_col12, #T_19697_row0_col16, #T_19697_row1_col7, #T_19697_row1_col10, #T_19697_row2_col2, #T_19697_row2_col11, #T_19697_row3_col3, #T_19697_row3_col5, #T_19697_row3_col6, #T_19697_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row0_col13, #T_19697_row0_col14, #T_19697_row0_col15, #T_19697_row0_col17, #T_19697_row1_col13, #T_19697_row1_col14, #T_19697_row1_col15, #T_19697_row1_col17, #T_19697_row2_col13, #T_19697_row2_col14, #T_19697_row2_col15, #T_19697_row2_col17, #T_19697_row3_col13, #T_19697_row3_col14, #T_19697_row3_col15, #T_19697_row3_col17, #T_19697_row4_col13, #T_19697_row4_col14, #T_19697_row4_col15, #T_19697_row4_col17, #T_19697_row5_col13, #T_19697_row5_col14, #T_19697_row5_col15, #T_19697_row5_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row1_col2, #T_19697_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row1_col4, #T_19697_row3_col10, #T_19697_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row1_col11, #T_19697_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row1_col12, #T_19697_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row2_col12, #T_19697_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e16751;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19697_row5_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row5_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row5_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19697_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_19697\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_19697_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_19697_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_19697_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_19697_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_19697_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_19697_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_19697_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_19697_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_19697_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_19697_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_19697_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_19697_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_19697_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_19697_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_19697_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_19697_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_19697_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_19697_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_19697_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_19697_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_19697_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_19697_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_19697_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_19697_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_19697_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_19697_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_19697_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_19697_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_19697_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_19697_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_19697_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_19697_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_19697_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_19697_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_19697_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_19697_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_19697_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19697_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_19697_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_19697_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_19697_row1_col2\" class=\"data row1 col2\" >38.4</td>\n",
       "      <td id=\"T_19697_row1_col3\" class=\"data row1 col3\" >36.5</td>\n",
       "      <td id=\"T_19697_row1_col4\" class=\"data row1 col4\" >6.6</td>\n",
       "      <td id=\"T_19697_row1_col5\" class=\"data row1 col5\" >10.8</td>\n",
       "      <td id=\"T_19697_row1_col6\" class=\"data row1 col6\" >31.3</td>\n",
       "      <td id=\"T_19697_row1_col7\" class=\"data row1 col7\" >34.1</td>\n",
       "      <td id=\"T_19697_row1_col8\" class=\"data row1 col8\" >7.9</td>\n",
       "      <td id=\"T_19697_row1_col9\" class=\"data row1 col9\" >33.3</td>\n",
       "      <td id=\"T_19697_row1_col10\" class=\"data row1 col10\" >11.8</td>\n",
       "      <td id=\"T_19697_row1_col11\" class=\"data row1 col11\" >48.5</td>\n",
       "      <td id=\"T_19697_row1_col12\" class=\"data row1 col12\" >252.2</td>\n",
       "      <td id=\"T_19697_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_19697_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_19697_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_19697_row1_col16\" class=\"data row1 col16\" >46.5</td>\n",
       "      <td id=\"T_19697_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19697_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_19697_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_ep=3</td>\n",
       "      <td id=\"T_19697_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_19697_row2_col2\" class=\"data row2 col2\" >39.1</td>\n",
       "      <td id=\"T_19697_row2_col3\" class=\"data row2 col3\" >36.6</td>\n",
       "      <td id=\"T_19697_row2_col4\" class=\"data row2 col4\" >5.6</td>\n",
       "      <td id=\"T_19697_row2_col5\" class=\"data row2 col5\" >10.0</td>\n",
       "      <td id=\"T_19697_row2_col6\" class=\"data row2 col6\" >30.7</td>\n",
       "      <td id=\"T_19697_row2_col7\" class=\"data row2 col7\" >33.4</td>\n",
       "      <td id=\"T_19697_row2_col8\" class=\"data row2 col8\" >7.9</td>\n",
       "      <td id=\"T_19697_row2_col9\" class=\"data row2 col9\" >32.5</td>\n",
       "      <td id=\"T_19697_row2_col10\" class=\"data row2 col10\" >10.4</td>\n",
       "      <td id=\"T_19697_row2_col11\" class=\"data row2 col11\" >52.5</td>\n",
       "      <td id=\"T_19697_row2_col12\" class=\"data row2 col12\" >236.0</td>\n",
       "      <td id=\"T_19697_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_19697_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_19697_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_19697_row2_col16\" class=\"data row2 col16\" >45.0</td>\n",
       "      <td id=\"T_19697_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19697_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_19697_row3_col0\" class=\"data row3 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_19697_row3_col1\" class=\"data row3 col1\" >10000</td>\n",
       "      <td id=\"T_19697_row3_col2\" class=\"data row3 col2\" >38.4</td>\n",
       "      <td id=\"T_19697_row3_col3\" class=\"data row3 col3\" >38.0</td>\n",
       "      <td id=\"T_19697_row3_col4\" class=\"data row3 col4\" >5.4</td>\n",
       "      <td id=\"T_19697_row3_col5\" class=\"data row3 col5\" >12.0</td>\n",
       "      <td id=\"T_19697_row3_col6\" class=\"data row3 col6\" >33.1</td>\n",
       "      <td id=\"T_19697_row3_col7\" class=\"data row3 col7\" >28.3</td>\n",
       "      <td id=\"T_19697_row3_col8\" class=\"data row3 col8\" >7.8</td>\n",
       "      <td id=\"T_19697_row3_col9\" class=\"data row3 col9\" >31.2</td>\n",
       "      <td id=\"T_19697_row3_col10\" class=\"data row3 col10\" >10.0</td>\n",
       "      <td id=\"T_19697_row3_col11\" class=\"data row3 col11\" >45.3</td>\n",
       "      <td id=\"T_19697_row3_col12\" class=\"data row3 col12\" >239.8</td>\n",
       "      <td id=\"T_19697_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_19697_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_19697_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_19697_row3_col16\" class=\"data row3 col16\" >44.5</td>\n",
       "      <td id=\"T_19697_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19697_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_19697_row4_col0\" class=\"data row4 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_19697_row4_col1\" class=\"data row4 col1\" >10000</td>\n",
       "      <td id=\"T_19697_row4_col2\" class=\"data row4 col2\" >33.7</td>\n",
       "      <td id=\"T_19697_row4_col3\" class=\"data row4 col3\" >37.8</td>\n",
       "      <td id=\"T_19697_row4_col4\" class=\"data row4 col4\" >6.6</td>\n",
       "      <td id=\"T_19697_row4_col5\" class=\"data row4 col5\" >8.6</td>\n",
       "      <td id=\"T_19697_row4_col6\" class=\"data row4 col6\" >30.5</td>\n",
       "      <td id=\"T_19697_row4_col7\" class=\"data row4 col7\" >30.1</td>\n",
       "      <td id=\"T_19697_row4_col8\" class=\"data row4 col8\" >7.1</td>\n",
       "      <td id=\"T_19697_row4_col9\" class=\"data row4 col9\" >27.6</td>\n",
       "      <td id=\"T_19697_row4_col10\" class=\"data row4 col10\" >6.3</td>\n",
       "      <td id=\"T_19697_row4_col11\" class=\"data row4 col11\" >41.8</td>\n",
       "      <td id=\"T_19697_row4_col12\" class=\"data row4 col12\" >232.5</td>\n",
       "      <td id=\"T_19697_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_19697_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_19697_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_19697_row4_col16\" class=\"data row4 col16\" >42.1</td>\n",
       "      <td id=\"T_19697_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19697_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_19697_row5_col0\" class=\"data row5 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_19697_row5_col1\" class=\"data row5 col1\" >10000</td>\n",
       "      <td id=\"T_19697_row5_col2\" class=\"data row5 col2\" >35.5</td>\n",
       "      <td id=\"T_19697_row5_col3\" class=\"data row5 col3\" >36.7</td>\n",
       "      <td id=\"T_19697_row5_col4\" class=\"data row5 col4\" >7.2</td>\n",
       "      <td id=\"T_19697_row5_col5\" class=\"data row5 col5\" >9.8</td>\n",
       "      <td id=\"T_19697_row5_col6\" class=\"data row5 col6\" >30.5</td>\n",
       "      <td id=\"T_19697_row5_col7\" class=\"data row5 col7\" >28.1</td>\n",
       "      <td id=\"T_19697_row5_col8\" class=\"data row5 col8\" >8.8</td>\n",
       "      <td id=\"T_19697_row5_col9\" class=\"data row5 col9\" >32.4</td>\n",
       "      <td id=\"T_19697_row5_col10\" class=\"data row5 col10\" >8.9</td>\n",
       "      <td id=\"T_19697_row5_col11\" class=\"data row5 col11\" >42.0</td>\n",
       "      <td id=\"T_19697_row5_col12\" class=\"data row5 col12\" >222.6</td>\n",
       "      <td id=\"T_19697_row5_col13\" class=\"data row5 col13\" >nan</td>\n",
       "      <td id=\"T_19697_row5_col14\" class=\"data row5 col14\" >nan</td>\n",
       "      <td id=\"T_19697_row5_col15\" class=\"data row5 col15\" >nan</td>\n",
       "      <td id=\"T_19697_row5_col16\" class=\"data row5 col16\" >42.0</td>\n",
       "      <td id=\"T_19697_row5_col17\" class=\"data row5 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf77ef190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ed1f8 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_ed1f8_row0_col0, #T_ed1f8_row1_col0, #T_ed1f8_row2_col0, #T_ed1f8_row3_col0, #T_ed1f8_row4_col0, #T_ed1f8_row5_col0, #T_ed1f8_row6_col0, #T_ed1f8_row7_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ed1f8_row0_col1, #T_ed1f8_row1_col1, #T_ed1f8_row2_col1, #T_ed1f8_row3_col1, #T_ed1f8_row4_col1, #T_ed1f8_row5_col1, #T_ed1f8_row6_col1, #T_ed1f8_row7_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ed1f8_row0_col2, #T_ed1f8_row0_col3, #T_ed1f8_row0_col6, #T_ed1f8_row0_col7, #T_ed1f8_row0_col11, #T_ed1f8_row1_col5, #T_ed1f8_row3_col5, #T_ed1f8_row4_col8, #T_ed1f8_row4_col9, #T_ed1f8_row5_col5, #T_ed1f8_row5_col10, #T_ed1f8_row6_col12, #T_ed1f8_row6_col16, #T_ed1f8_row7_col4, #T_ed1f8_row7_col13, #T_ed1f8_row7_col14, #T_ed1f8_row7_col15, #T_ed1f8_row7_col16, #T_ed1f8_row7_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row0_col5, #T_ed1f8_row0_col8, #T_ed1f8_row0_col9, #T_ed1f8_row0_col12, #T_ed1f8_row0_col16, #T_ed1f8_row1_col3, #T_ed1f8_row2_col4, #T_ed1f8_row3_col13, #T_ed1f8_row3_col14, #T_ed1f8_row3_col15, #T_ed1f8_row3_col17, #T_ed1f8_row4_col10, #T_ed1f8_row5_col7, #T_ed1f8_row6_col2, #T_ed1f8_row6_col11, #T_ed1f8_row7_col6, #T_ed1f8_row7_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row0_col10, #T_ed1f8_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row0_col13, #T_ed1f8_row0_col14, #T_ed1f8_row0_col15, #T_ed1f8_row0_col17, #T_ed1f8_row1_col13, #T_ed1f8_row1_col14, #T_ed1f8_row1_col15, #T_ed1f8_row1_col17, #T_ed1f8_row2_col13, #T_ed1f8_row2_col14, #T_ed1f8_row2_col15, #T_ed1f8_row2_col17, #T_ed1f8_row4_col13, #T_ed1f8_row4_col14, #T_ed1f8_row4_col15, #T_ed1f8_row4_col17, #T_ed1f8_row6_col13, #T_ed1f8_row6_col14, #T_ed1f8_row6_col15, #T_ed1f8_row6_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row1_col2, #T_ed1f8_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #de614d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row1_col8, #T_ed1f8_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row1_col12, #T_ed1f8_row3_col12, #T_ed1f8_row5_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row2_col5, #T_ed1f8_row7_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #efcebd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row2_col6, #T_ed1f8_row6_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row2_col12, #T_ed1f8_row2_col16, #T_ed1f8_row3_col16, #T_ed1f8_row4_col12, #T_ed1f8_row7_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row3_col4, #T_ed1f8_row6_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row4_col3, #T_ed1f8_row5_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row4_col4, #T_ed1f8_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row4_col16, #T_ed1f8_row5_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row5_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row5_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row5_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row5_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row5_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row6_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row6_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row6_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row6_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row6_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row6_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row7_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row7_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ed1f8_row7_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row7_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row7_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ed1f8_row7_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ed1f8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ed1f8_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_ed1f8_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_ed1f8_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_ed1f8_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_ed1f8_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_ed1f8_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_ed1f8_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_ed1f8_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_ed1f8_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_ed1f8_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_ed1f8_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_ed1f8_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_ed1f8_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_ed1f8_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_ed1f8_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_ed1f8_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_ed1f8_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_ed1f8_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ed1f8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ed1f8_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_ed1f8_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_ed1f8_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_ed1f8_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_ed1f8_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_ed1f8_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_ed1f8_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_ed1f8_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_ed1f8_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_ed1f8_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_ed1f8_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_ed1f8_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_ed1f8_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_ed1f8_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_ed1f8_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed1f8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ed1f8_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=10:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_ed1f8_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_ed1f8_row1_col2\" class=\"data row1 col2\" >38.2</td>\n",
       "      <td id=\"T_ed1f8_row1_col3\" class=\"data row1 col3\" >38.5</td>\n",
       "      <td id=\"T_ed1f8_row1_col4\" class=\"data row1 col4\" >6.0</td>\n",
       "      <td id=\"T_ed1f8_row1_col5\" class=\"data row1 col5\" >9.4</td>\n",
       "      <td id=\"T_ed1f8_row1_col6\" class=\"data row1 col6\" >32.5</td>\n",
       "      <td id=\"T_ed1f8_row1_col7\" class=\"data row1 col7\" >33.7</td>\n",
       "      <td id=\"T_ed1f8_row1_col8\" class=\"data row1 col8\" >8.3</td>\n",
       "      <td id=\"T_ed1f8_row1_col9\" class=\"data row1 col9\" >29.7</td>\n",
       "      <td id=\"T_ed1f8_row1_col10\" class=\"data row1 col10\" >10.2</td>\n",
       "      <td id=\"T_ed1f8_row1_col11\" class=\"data row1 col11\" >45.9</td>\n",
       "      <td id=\"T_ed1f8_row1_col12\" class=\"data row1 col12\" >266.9</td>\n",
       "      <td id=\"T_ed1f8_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row1_col16\" class=\"data row1 col16\" >47.2</td>\n",
       "      <td id=\"T_ed1f8_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed1f8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ed1f8_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_ed1f8_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_ed1f8_row2_col2\" class=\"data row2 col2\" >38.4</td>\n",
       "      <td id=\"T_ed1f8_row2_col3\" class=\"data row2 col3\" >36.5</td>\n",
       "      <td id=\"T_ed1f8_row2_col4\" class=\"data row2 col4\" >6.6</td>\n",
       "      <td id=\"T_ed1f8_row2_col5\" class=\"data row2 col5\" >10.8</td>\n",
       "      <td id=\"T_ed1f8_row2_col6\" class=\"data row2 col6\" >31.3</td>\n",
       "      <td id=\"T_ed1f8_row2_col7\" class=\"data row2 col7\" >34.1</td>\n",
       "      <td id=\"T_ed1f8_row2_col8\" class=\"data row2 col8\" >7.9</td>\n",
       "      <td id=\"T_ed1f8_row2_col9\" class=\"data row2 col9\" >33.3</td>\n",
       "      <td id=\"T_ed1f8_row2_col10\" class=\"data row2 col10\" >11.8</td>\n",
       "      <td id=\"T_ed1f8_row2_col11\" class=\"data row2 col11\" >48.5</td>\n",
       "      <td id=\"T_ed1f8_row2_col12\" class=\"data row2 col12\" >252.2</td>\n",
       "      <td id=\"T_ed1f8_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row2_col16\" class=\"data row2 col16\" >46.5</td>\n",
       "      <td id=\"T_ed1f8_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed1f8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ed1f8_row3_col0\" class=\"data row3 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_ed1f8_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_ed1f8_row3_col2\" class=\"data row3 col2\" >36.7</td>\n",
       "      <td id=\"T_ed1f8_row3_col3\" class=\"data row3 col3\" >35.9</td>\n",
       "      <td id=\"T_ed1f8_row3_col4\" class=\"data row3 col4\" >5.6</td>\n",
       "      <td id=\"T_ed1f8_row3_col5\" class=\"data row3 col5\" >9.4</td>\n",
       "      <td id=\"T_ed1f8_row3_col6\" class=\"data row3 col6\" >33.0</td>\n",
       "      <td id=\"T_ed1f8_row3_col7\" class=\"data row3 col7\" >33.2</td>\n",
       "      <td id=\"T_ed1f8_row3_col8\" class=\"data row3 col8\" >8.3</td>\n",
       "      <td id=\"T_ed1f8_row3_col9\" class=\"data row3 col9\" >31.9</td>\n",
       "      <td id=\"T_ed1f8_row3_col10\" class=\"data row3 col10\" >11.6</td>\n",
       "      <td id=\"T_ed1f8_row3_col11\" class=\"data row3 col11\" >47.8</td>\n",
       "      <td id=\"T_ed1f8_row3_col12\" class=\"data row3 col12\" >264.3</td>\n",
       "      <td id=\"T_ed1f8_row3_col13\" class=\"data row3 col13\" >50.6</td>\n",
       "      <td id=\"T_ed1f8_row3_col14\" class=\"data row3 col14\" >36.7</td>\n",
       "      <td id=\"T_ed1f8_row3_col15\" class=\"data row3 col15\" >43.7</td>\n",
       "      <td id=\"T_ed1f8_row3_col16\" class=\"data row3 col16\" >46.3</td>\n",
       "      <td id=\"T_ed1f8_row3_col17\" class=\"data row3 col17\" >-30.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed1f8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ed1f8_row4_col0\" class=\"data row4 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-2:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_ed1f8_row4_col1\" class=\"data row4 col1\" >30000</td>\n",
       "      <td id=\"T_ed1f8_row4_col2\" class=\"data row4 col2\" >37.3</td>\n",
       "      <td id=\"T_ed1f8_row4_col3\" class=\"data row4 col3\" >37.8</td>\n",
       "      <td id=\"T_ed1f8_row4_col4\" class=\"data row4 col4\" >6.4</td>\n",
       "      <td id=\"T_ed1f8_row4_col5\" class=\"data row4 col5\" >9.8</td>\n",
       "      <td id=\"T_ed1f8_row4_col6\" class=\"data row4 col6\" >31.9</td>\n",
       "      <td id=\"T_ed1f8_row4_col7\" class=\"data row4 col7\" >34.4</td>\n",
       "      <td id=\"T_ed1f8_row4_col8\" class=\"data row4 col8\" >7.1</td>\n",
       "      <td id=\"T_ed1f8_row4_col9\" class=\"data row4 col9\" >28.2</td>\n",
       "      <td id=\"T_ed1f8_row4_col10\" class=\"data row4 col10\" >12.6</td>\n",
       "      <td id=\"T_ed1f8_row4_col11\" class=\"data row4 col11\" >45.5</td>\n",
       "      <td id=\"T_ed1f8_row4_col12\" class=\"data row4 col12\" >252.7</td>\n",
       "      <td id=\"T_ed1f8_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row4_col16\" class=\"data row4 col16\" >45.8</td>\n",
       "      <td id=\"T_ed1f8_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed1f8_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ed1f8_row5_col0\" class=\"data row5 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_ed1f8_row5_col1\" class=\"data row5 col1\" >30000</td>\n",
       "      <td id=\"T_ed1f8_row5_col2\" class=\"data row5 col2\" >38.7</td>\n",
       "      <td id=\"T_ed1f8_row5_col3\" class=\"data row5 col3\" >37.5</td>\n",
       "      <td id=\"T_ed1f8_row5_col4\" class=\"data row5 col4\" >6.4</td>\n",
       "      <td id=\"T_ed1f8_row5_col5\" class=\"data row5 col5\" >9.4</td>\n",
       "      <td id=\"T_ed1f8_row5_col6\" class=\"data row5 col6\" >32.8</td>\n",
       "      <td id=\"T_ed1f8_row5_col7\" class=\"data row5 col7\" >35.1</td>\n",
       "      <td id=\"T_ed1f8_row5_col8\" class=\"data row5 col8\" >9.1</td>\n",
       "      <td id=\"T_ed1f8_row5_col9\" class=\"data row5 col9\" >30.3</td>\n",
       "      <td id=\"T_ed1f8_row5_col10\" class=\"data row5 col10\" >8.9</td>\n",
       "      <td id=\"T_ed1f8_row5_col11\" class=\"data row5 col11\" >44.8</td>\n",
       "      <td id=\"T_ed1f8_row5_col12\" class=\"data row5 col12\" >270.1</td>\n",
       "      <td id=\"T_ed1f8_row5_col13\" class=\"data row5 col13\" >44.9</td>\n",
       "      <td id=\"T_ed1f8_row5_col14\" class=\"data row5 col14\" >33.0</td>\n",
       "      <td id=\"T_ed1f8_row5_col15\" class=\"data row5 col15\" >38.9</td>\n",
       "      <td id=\"T_ed1f8_row5_col16\" class=\"data row5 col16\" >45.7</td>\n",
       "      <td id=\"T_ed1f8_row5_col17\" class=\"data row5 col17\" >-30.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed1f8_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ed1f8_row6_col0\" class=\"data row6 col0\" >llama-7b_ultrachat50k_ep=3</td>\n",
       "      <td id=\"T_ed1f8_row6_col1\" class=\"data row6 col1\" >None</td>\n",
       "      <td id=\"T_ed1f8_row6_col2\" class=\"data row6 col2\" >39.1</td>\n",
       "      <td id=\"T_ed1f8_row6_col3\" class=\"data row6 col3\" >36.6</td>\n",
       "      <td id=\"T_ed1f8_row6_col4\" class=\"data row6 col4\" >5.6</td>\n",
       "      <td id=\"T_ed1f8_row6_col5\" class=\"data row6 col5\" >10.0</td>\n",
       "      <td id=\"T_ed1f8_row6_col6\" class=\"data row6 col6\" >30.7</td>\n",
       "      <td id=\"T_ed1f8_row6_col7\" class=\"data row6 col7\" >33.4</td>\n",
       "      <td id=\"T_ed1f8_row6_col8\" class=\"data row6 col8\" >7.9</td>\n",
       "      <td id=\"T_ed1f8_row6_col9\" class=\"data row6 col9\" >32.5</td>\n",
       "      <td id=\"T_ed1f8_row6_col10\" class=\"data row6 col10\" >10.4</td>\n",
       "      <td id=\"T_ed1f8_row6_col11\" class=\"data row6 col11\" >52.5</td>\n",
       "      <td id=\"T_ed1f8_row6_col12\" class=\"data row6 col12\" >236.0</td>\n",
       "      <td id=\"T_ed1f8_row6_col13\" class=\"data row6 col13\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row6_col14\" class=\"data row6 col14\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row6_col15\" class=\"data row6 col15\" >nan</td>\n",
       "      <td id=\"T_ed1f8_row6_col16\" class=\"data row6 col16\" >45.0</td>\n",
       "      <td id=\"T_ed1f8_row6_col17\" class=\"data row6 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed1f8_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ed1f8_row7_col0\" class=\"data row7 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_ed1f8_row7_col1\" class=\"data row7 col1\" >30000</td>\n",
       "      <td id=\"T_ed1f8_row7_col2\" class=\"data row7 col2\" >37.0</td>\n",
       "      <td id=\"T_ed1f8_row7_col3\" class=\"data row7 col3\" >34.9</td>\n",
       "      <td id=\"T_ed1f8_row7_col4\" class=\"data row7 col4\" >5.2</td>\n",
       "      <td id=\"T_ed1f8_row7_col5\" class=\"data row7 col5\" >10.8</td>\n",
       "      <td id=\"T_ed1f8_row7_col6\" class=\"data row7 col6\" >33.2</td>\n",
       "      <td id=\"T_ed1f8_row7_col7\" class=\"data row7 col7\" >34.2</td>\n",
       "      <td id=\"T_ed1f8_row7_col8\" class=\"data row7 col8\" >8.7</td>\n",
       "      <td id=\"T_ed1f8_row7_col9\" class=\"data row7 col9\" >32.1</td>\n",
       "      <td id=\"T_ed1f8_row7_col10\" class=\"data row7 col10\" >12.6</td>\n",
       "      <td id=\"T_ed1f8_row7_col11\" class=\"data row7 col11\" >48.8</td>\n",
       "      <td id=\"T_ed1f8_row7_col12\" class=\"data row7 col12\" >255.6</td>\n",
       "      <td id=\"T_ed1f8_row7_col13\" class=\"data row7 col13\" >44.1</td>\n",
       "      <td id=\"T_ed1f8_row7_col14\" class=\"data row7 col14\" >32.3</td>\n",
       "      <td id=\"T_ed1f8_row7_col15\" class=\"data row7 col15\" >38.2</td>\n",
       "      <td id=\"T_ed1f8_row7_col16\" class=\"data row7 col16\" >44.8</td>\n",
       "      <td id=\"T_ed1f8_row7_col17\" class=\"data row7 col17\" >-30.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf3552bc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fbc2e td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_fbc2e_row0_col0, #T_fbc2e_row1_col0, #T_fbc2e_row2_col0, #T_fbc2e_row3_col0, #T_fbc2e_row4_col0, #T_fbc2e_row5_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fbc2e_row0_col1, #T_fbc2e_row1_col1, #T_fbc2e_row2_col1, #T_fbc2e_row3_col1, #T_fbc2e_row4_col1, #T_fbc2e_row5_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fbc2e_row0_col2, #T_fbc2e_row0_col3, #T_fbc2e_row0_col4, #T_fbc2e_row0_col6, #T_fbc2e_row0_col7, #T_fbc2e_row0_col10, #T_fbc2e_row0_col11, #T_fbc2e_row2_col8, #T_fbc2e_row2_col9, #T_fbc2e_row3_col14, #T_fbc2e_row4_col12, #T_fbc2e_row5_col5, #T_fbc2e_row5_col10, #T_fbc2e_row5_col12, #T_fbc2e_row5_col13, #T_fbc2e_row5_col15, #T_fbc2e_row5_col16, #T_fbc2e_row5_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row0_col5, #T_fbc2e_row0_col8, #T_fbc2e_row0_col9, #T_fbc2e_row0_col12, #T_fbc2e_row0_col16, #T_fbc2e_row1_col4, #T_fbc2e_row1_col10, #T_fbc2e_row2_col7, #T_fbc2e_row3_col3, #T_fbc2e_row3_col13, #T_fbc2e_row3_col15, #T_fbc2e_row3_col17, #T_fbc2e_row4_col2, #T_fbc2e_row4_col11, #T_fbc2e_row5_col6, #T_fbc2e_row5_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row0_col13, #T_fbc2e_row0_col14, #T_fbc2e_row0_col15, #T_fbc2e_row0_col17, #T_fbc2e_row1_col13, #T_fbc2e_row1_col14, #T_fbc2e_row1_col15, #T_fbc2e_row1_col17, #T_fbc2e_row2_col13, #T_fbc2e_row2_col14, #T_fbc2e_row2_col15, #T_fbc2e_row2_col17, #T_fbc2e_row4_col13, #T_fbc2e_row4_col14, #T_fbc2e_row4_col15, #T_fbc2e_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #ca3b37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row1_col8, #T_fbc2e_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row1_col12, #T_fbc2e_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row3_col4, #T_fbc2e_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #dc5d4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row3_col12, #T_fbc2e_row3_col16, #T_fbc2e_row4_col16, #T_fbc2e_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row4_col3, #T_fbc2e_row5_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row5_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_fbc2e_row5_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_fbc2e_row5_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #e0654f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fbc2e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fbc2e_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_fbc2e_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_fbc2e_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_fbc2e_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_fbc2e_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_fbc2e_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_fbc2e_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_fbc2e_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_fbc2e_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_fbc2e_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_fbc2e_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_fbc2e_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_fbc2e_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_fbc2e_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_fbc2e_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_fbc2e_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_fbc2e_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_fbc2e_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fbc2e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fbc2e_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_fbc2e_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_fbc2e_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_fbc2e_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_fbc2e_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_fbc2e_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_fbc2e_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_fbc2e_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_fbc2e_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_fbc2e_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_fbc2e_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_fbc2e_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_fbc2e_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_fbc2e_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_fbc2e_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_fbc2e_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_fbc2e_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_fbc2e_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbc2e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fbc2e_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_fbc2e_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_fbc2e_row1_col2\" class=\"data row1 col2\" >38.4</td>\n",
       "      <td id=\"T_fbc2e_row1_col3\" class=\"data row1 col3\" >36.5</td>\n",
       "      <td id=\"T_fbc2e_row1_col4\" class=\"data row1 col4\" >6.6</td>\n",
       "      <td id=\"T_fbc2e_row1_col5\" class=\"data row1 col5\" >10.8</td>\n",
       "      <td id=\"T_fbc2e_row1_col6\" class=\"data row1 col6\" >31.3</td>\n",
       "      <td id=\"T_fbc2e_row1_col7\" class=\"data row1 col7\" >34.1</td>\n",
       "      <td id=\"T_fbc2e_row1_col8\" class=\"data row1 col8\" >7.9</td>\n",
       "      <td id=\"T_fbc2e_row1_col9\" class=\"data row1 col9\" >33.3</td>\n",
       "      <td id=\"T_fbc2e_row1_col10\" class=\"data row1 col10\" >11.8</td>\n",
       "      <td id=\"T_fbc2e_row1_col11\" class=\"data row1 col11\" >48.5</td>\n",
       "      <td id=\"T_fbc2e_row1_col12\" class=\"data row1 col12\" >252.2</td>\n",
       "      <td id=\"T_fbc2e_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_fbc2e_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_fbc2e_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_fbc2e_row1_col16\" class=\"data row1 col16\" >46.5</td>\n",
       "      <td id=\"T_fbc2e_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbc2e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fbc2e_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_fbc2e_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_fbc2e_row2_col2\" class=\"data row2 col2\" >37.9</td>\n",
       "      <td id=\"T_fbc2e_row2_col3\" class=\"data row2 col3\" >35.1</td>\n",
       "      <td id=\"T_fbc2e_row2_col4\" class=\"data row2 col4\" >6.2</td>\n",
       "      <td id=\"T_fbc2e_row2_col5\" class=\"data row2 col5\" >11.0</td>\n",
       "      <td id=\"T_fbc2e_row2_col6\" class=\"data row2 col6\" >32.6</td>\n",
       "      <td id=\"T_fbc2e_row2_col7\" class=\"data row2 col7\" >34.2</td>\n",
       "      <td id=\"T_fbc2e_row2_col8\" class=\"data row2 col8\" >7.5</td>\n",
       "      <td id=\"T_fbc2e_row2_col9\" class=\"data row2 col9\" >30.0</td>\n",
       "      <td id=\"T_fbc2e_row2_col10\" class=\"data row2 col10\" >10.8</td>\n",
       "      <td id=\"T_fbc2e_row2_col11\" class=\"data row2 col11\" >50.7</td>\n",
       "      <td id=\"T_fbc2e_row2_col12\" class=\"data row2 col12\" >251.4</td>\n",
       "      <td id=\"T_fbc2e_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_fbc2e_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_fbc2e_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_fbc2e_row2_col16\" class=\"data row2 col16\" >46.1</td>\n",
       "      <td id=\"T_fbc2e_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbc2e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fbc2e_row3_col0\" class=\"data row3 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_fbc2e_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_fbc2e_row3_col2\" class=\"data row3 col2\" >37.3</td>\n",
       "      <td id=\"T_fbc2e_row3_col3\" class=\"data row3 col3\" >36.6</td>\n",
       "      <td id=\"T_fbc2e_row3_col4\" class=\"data row3 col4\" >5.8</td>\n",
       "      <td id=\"T_fbc2e_row3_col5\" class=\"data row3 col5\" >10.6</td>\n",
       "      <td id=\"T_fbc2e_row3_col6\" class=\"data row3 col6\" >32.7</td>\n",
       "      <td id=\"T_fbc2e_row3_col7\" class=\"data row3 col7\" >33.1</td>\n",
       "      <td id=\"T_fbc2e_row3_col8\" class=\"data row3 col8\" >7.9</td>\n",
       "      <td id=\"T_fbc2e_row3_col9\" class=\"data row3 col9\" >30.4</td>\n",
       "      <td id=\"T_fbc2e_row3_col10\" class=\"data row3 col10\" >11.2</td>\n",
       "      <td id=\"T_fbc2e_row3_col11\" class=\"data row3 col11\" >48.9</td>\n",
       "      <td id=\"T_fbc2e_row3_col12\" class=\"data row3 col12\" >247.5</td>\n",
       "      <td id=\"T_fbc2e_row3_col13\" class=\"data row3 col13\" >50.4</td>\n",
       "      <td id=\"T_fbc2e_row3_col14\" class=\"data row3 col14\" >37.5</td>\n",
       "      <td id=\"T_fbc2e_row3_col15\" class=\"data row3 col15\" >44.0</td>\n",
       "      <td id=\"T_fbc2e_row3_col16\" class=\"data row3 col16\" >45.3</td>\n",
       "      <td id=\"T_fbc2e_row3_col17\" class=\"data row3 col17\" >-32.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbc2e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_fbc2e_row4_col0\" class=\"data row4 col0\" >llama-7b_ultrachat50k_ep=3</td>\n",
       "      <td id=\"T_fbc2e_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_fbc2e_row4_col2\" class=\"data row4 col2\" >39.1</td>\n",
       "      <td id=\"T_fbc2e_row4_col3\" class=\"data row4 col3\" >36.6</td>\n",
       "      <td id=\"T_fbc2e_row4_col4\" class=\"data row4 col4\" >5.6</td>\n",
       "      <td id=\"T_fbc2e_row4_col5\" class=\"data row4 col5\" >10.0</td>\n",
       "      <td id=\"T_fbc2e_row4_col6\" class=\"data row4 col6\" >30.7</td>\n",
       "      <td id=\"T_fbc2e_row4_col7\" class=\"data row4 col7\" >33.4</td>\n",
       "      <td id=\"T_fbc2e_row4_col8\" class=\"data row4 col8\" >7.9</td>\n",
       "      <td id=\"T_fbc2e_row4_col9\" class=\"data row4 col9\" >32.5</td>\n",
       "      <td id=\"T_fbc2e_row4_col10\" class=\"data row4 col10\" >10.4</td>\n",
       "      <td id=\"T_fbc2e_row4_col11\" class=\"data row4 col11\" >52.5</td>\n",
       "      <td id=\"T_fbc2e_row4_col12\" class=\"data row4 col12\" >236.0</td>\n",
       "      <td id=\"T_fbc2e_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_fbc2e_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_fbc2e_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_fbc2e_row4_col16\" class=\"data row4 col16\" >45.0</td>\n",
       "      <td id=\"T_fbc2e_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fbc2e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_fbc2e_row5_col0\" class=\"data row5 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_fbc2e_row5_col1\" class=\"data row5 col1\" >60000</td>\n",
       "      <td id=\"T_fbc2e_row5_col2\" class=\"data row5 col2\" >38.9</td>\n",
       "      <td id=\"T_fbc2e_row5_col3\" class=\"data row5 col3\" >34.5</td>\n",
       "      <td id=\"T_fbc2e_row5_col4\" class=\"data row5 col4\" >5.8</td>\n",
       "      <td id=\"T_fbc2e_row5_col5\" class=\"data row5 col5\" >9.0</td>\n",
       "      <td id=\"T_fbc2e_row5_col6\" class=\"data row5 col6\" >33.0</td>\n",
       "      <td id=\"T_fbc2e_row5_col7\" class=\"data row5 col7\" >33.5</td>\n",
       "      <td id=\"T_fbc2e_row5_col8\" class=\"data row5 col8\" >8.2</td>\n",
       "      <td id=\"T_fbc2e_row5_col9\" class=\"data row5 col9\" >31.2</td>\n",
       "      <td id=\"T_fbc2e_row5_col10\" class=\"data row5 col10\" >10.2</td>\n",
       "      <td id=\"T_fbc2e_row5_col11\" class=\"data row5 col11\" >45.5</td>\n",
       "      <td id=\"T_fbc2e_row5_col12\" class=\"data row5 col12\" >236.8</td>\n",
       "      <td id=\"T_fbc2e_row5_col13\" class=\"data row5 col13\" >49.1</td>\n",
       "      <td id=\"T_fbc2e_row5_col14\" class=\"data row5 col14\" >37.6</td>\n",
       "      <td id=\"T_fbc2e_row5_col15\" class=\"data row5 col15\" >43.4</td>\n",
       "      <td id=\"T_fbc2e_row5_col16\" class=\"data row5 col16\" >44.1</td>\n",
       "      <td id=\"T_fbc2e_row5_col17\" class=\"data row5 col17\" >-33.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cfd814a60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c89ac td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_c89ac_row0_col0, #T_c89ac_row1_col0, #T_c89ac_row2_col0, #T_c89ac_row3_col0, #T_c89ac_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c89ac_row0_col1, #T_c89ac_row1_col1, #T_c89ac_row2_col1, #T_c89ac_row3_col1, #T_c89ac_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c89ac_row0_col2, #T_c89ac_row0_col3, #T_c89ac_row0_col4, #T_c89ac_row0_col6, #T_c89ac_row0_col7, #T_c89ac_row0_col11, #T_c89ac_row2_col6, #T_c89ac_row2_col8, #T_c89ac_row2_col9, #T_c89ac_row2_col10, #T_c89ac_row3_col12, #T_c89ac_row3_col16, #T_c89ac_row4_col5, #T_c89ac_row4_col12, #T_c89ac_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row0_col5, #T_c89ac_row0_col8, #T_c89ac_row0_col9, #T_c89ac_row0_col12, #T_c89ac_row0_col16, #T_c89ac_row1_col4, #T_c89ac_row1_col10, #T_c89ac_row3_col3, #T_c89ac_row3_col5, #T_c89ac_row3_col6, #T_c89ac_row3_col7, #T_c89ac_row4_col2, #T_c89ac_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row0_col10, #T_c89ac_row2_col4, #T_c89ac_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c89ac_row0_col13, #T_c89ac_row0_col14, #T_c89ac_row0_col15, #T_c89ac_row0_col17, #T_c89ac_row1_col13, #T_c89ac_row1_col14, #T_c89ac_row1_col15, #T_c89ac_row1_col17, #T_c89ac_row2_col13, #T_c89ac_row2_col14, #T_c89ac_row2_col15, #T_c89ac_row2_col17, #T_c89ac_row3_col13, #T_c89ac_row3_col14, #T_c89ac_row3_col15, #T_c89ac_row3_col17, #T_c89ac_row4_col13, #T_c89ac_row4_col14, #T_c89ac_row4_col15, #T_c89ac_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c89ac_row1_col5, #T_c89ac_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c89ac_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c89ac_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row1_col12, #T_c89ac_row1_col16, #T_c89ac_row2_col12, #T_c89ac_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c89ac_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row2_col11, #T_c89ac_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c89ac_row3_col4, #T_c89ac_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c89ac_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c89ac_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c89ac_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c89ac\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c89ac_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_c89ac_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_c89ac_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_c89ac_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_c89ac_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_c89ac_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_c89ac_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_c89ac_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_c89ac_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_c89ac_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_c89ac_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_c89ac_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_c89ac_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_c89ac_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_c89ac_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_c89ac_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_c89ac_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_c89ac_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c89ac_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c89ac_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_c89ac_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_c89ac_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_c89ac_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_c89ac_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_c89ac_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_c89ac_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_c89ac_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_c89ac_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_c89ac_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_c89ac_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_c89ac_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_c89ac_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_c89ac_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_c89ac_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_c89ac_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_c89ac_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_c89ac_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c89ac_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c89ac_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_c89ac_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_c89ac_row1_col2\" class=\"data row1 col2\" >38.4</td>\n",
       "      <td id=\"T_c89ac_row1_col3\" class=\"data row1 col3\" >36.5</td>\n",
       "      <td id=\"T_c89ac_row1_col4\" class=\"data row1 col4\" >6.6</td>\n",
       "      <td id=\"T_c89ac_row1_col5\" class=\"data row1 col5\" >10.8</td>\n",
       "      <td id=\"T_c89ac_row1_col6\" class=\"data row1 col6\" >31.3</td>\n",
       "      <td id=\"T_c89ac_row1_col7\" class=\"data row1 col7\" >34.1</td>\n",
       "      <td id=\"T_c89ac_row1_col8\" class=\"data row1 col8\" >7.9</td>\n",
       "      <td id=\"T_c89ac_row1_col9\" class=\"data row1 col9\" >33.3</td>\n",
       "      <td id=\"T_c89ac_row1_col10\" class=\"data row1 col10\" >11.8</td>\n",
       "      <td id=\"T_c89ac_row1_col11\" class=\"data row1 col11\" >48.5</td>\n",
       "      <td id=\"T_c89ac_row1_col12\" class=\"data row1 col12\" >252.2</td>\n",
       "      <td id=\"T_c89ac_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_c89ac_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_c89ac_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_c89ac_row1_col16\" class=\"data row1 col16\" >46.5</td>\n",
       "      <td id=\"T_c89ac_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c89ac_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c89ac_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_c89ac_row2_col1\" class=\"data row2 col1\" >90000</td>\n",
       "      <td id=\"T_c89ac_row2_col2\" class=\"data row2 col2\" >38.6</td>\n",
       "      <td id=\"T_c89ac_row2_col3\" class=\"data row2 col3\" >35.5</td>\n",
       "      <td id=\"T_c89ac_row2_col4\" class=\"data row2 col4\" >5.8</td>\n",
       "      <td id=\"T_c89ac_row2_col5\" class=\"data row2 col5\" >10.8</td>\n",
       "      <td id=\"T_c89ac_row2_col6\" class=\"data row2 col6\" >30.6</td>\n",
       "      <td id=\"T_c89ac_row2_col7\" class=\"data row2 col7\" >35.2</td>\n",
       "      <td id=\"T_c89ac_row2_col8\" class=\"data row2 col8\" >7.7</td>\n",
       "      <td id=\"T_c89ac_row2_col9\" class=\"data row2 col9\" >32.4</td>\n",
       "      <td id=\"T_c89ac_row2_col10\" class=\"data row2 col10\" >9.3</td>\n",
       "      <td id=\"T_c89ac_row2_col11\" class=\"data row2 col11\" >51.0</td>\n",
       "      <td id=\"T_c89ac_row2_col12\" class=\"data row2 col12\" >251.1</td>\n",
       "      <td id=\"T_c89ac_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_c89ac_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_c89ac_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_c89ac_row2_col16\" class=\"data row2 col16\" >46.2</td>\n",
       "      <td id=\"T_c89ac_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c89ac_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c89ac_row3_col0\" class=\"data row3 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=90000:ep=3</td>\n",
       "      <td id=\"T_c89ac_row3_col1\" class=\"data row3 col1\" >90000</td>\n",
       "      <td id=\"T_c89ac_row3_col2\" class=\"data row3 col2\" >36.7</td>\n",
       "      <td id=\"T_c89ac_row3_col3\" class=\"data row3 col3\" >37.4</td>\n",
       "      <td id=\"T_c89ac_row3_col4\" class=\"data row3 col4\" >5.6</td>\n",
       "      <td id=\"T_c89ac_row3_col5\" class=\"data row3 col5\" >11.8</td>\n",
       "      <td id=\"T_c89ac_row3_col6\" class=\"data row3 col6\" >33.5</td>\n",
       "      <td id=\"T_c89ac_row3_col7\" class=\"data row3 col7\" >35.5</td>\n",
       "      <td id=\"T_c89ac_row3_col8\" class=\"data row3 col8\" >7.8</td>\n",
       "      <td id=\"T_c89ac_row3_col9\" class=\"data row3 col9\" >32.6</td>\n",
       "      <td id=\"T_c89ac_row3_col10\" class=\"data row3 col10\" >10.2</td>\n",
       "      <td id=\"T_c89ac_row3_col11\" class=\"data row3 col11\" >51.1</td>\n",
       "      <td id=\"T_c89ac_row3_col12\" class=\"data row3 col12\" >235.5</td>\n",
       "      <td id=\"T_c89ac_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_c89ac_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_c89ac_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_c89ac_row3_col16\" class=\"data row3 col16\" >45.2</td>\n",
       "      <td id=\"T_c89ac_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c89ac_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c89ac_row4_col0\" class=\"data row4 col0\" >llama-7b_ultrachat50k_ep=3</td>\n",
       "      <td id=\"T_c89ac_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_c89ac_row4_col2\" class=\"data row4 col2\" >39.1</td>\n",
       "      <td id=\"T_c89ac_row4_col3\" class=\"data row4 col3\" >36.6</td>\n",
       "      <td id=\"T_c89ac_row4_col4\" class=\"data row4 col4\" >5.6</td>\n",
       "      <td id=\"T_c89ac_row4_col5\" class=\"data row4 col5\" >10.0</td>\n",
       "      <td id=\"T_c89ac_row4_col6\" class=\"data row4 col6\" >30.7</td>\n",
       "      <td id=\"T_c89ac_row4_col7\" class=\"data row4 col7\" >33.4</td>\n",
       "      <td id=\"T_c89ac_row4_col8\" class=\"data row4 col8\" >7.9</td>\n",
       "      <td id=\"T_c89ac_row4_col9\" class=\"data row4 col9\" >32.5</td>\n",
       "      <td id=\"T_c89ac_row4_col10\" class=\"data row4 col10\" >10.4</td>\n",
       "      <td id=\"T_c89ac_row4_col11\" class=\"data row4 col11\" >52.5</td>\n",
       "      <td id=\"T_c89ac_row4_col12\" class=\"data row4 col12\" >236.0</td>\n",
       "      <td id=\"T_c89ac_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_c89ac_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_c89ac_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_c89ac_row4_col16\" class=\"data row4 col16\" >45.0</td>\n",
       "      <td id=\"T_c89ac_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf3d7b130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7948c td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_7948c_row0_col0, #T_7948c_row1_col0, #T_7948c_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7948c_row0_col1, #T_7948c_row1_col1, #T_7948c_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7948c_row0_col2, #T_7948c_row0_col3, #T_7948c_row0_col4, #T_7948c_row0_col6, #T_7948c_row0_col7, #T_7948c_row0_col10, #T_7948c_row0_col11, #T_7948c_row1_col8, #T_7948c_row2_col5, #T_7948c_row2_col9, #T_7948c_row2_col12, #T_7948c_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7948c_row0_col5, #T_7948c_row0_col8, #T_7948c_row0_col9, #T_7948c_row0_col12, #T_7948c_row0_col16, #T_7948c_row1_col4, #T_7948c_row1_col6, #T_7948c_row1_col7, #T_7948c_row1_col10, #T_7948c_row2_col2, #T_7948c_row2_col3, #T_7948c_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7948c_row0_col13, #T_7948c_row0_col14, #T_7948c_row0_col15, #T_7948c_row0_col17, #T_7948c_row1_col13, #T_7948c_row1_col14, #T_7948c_row1_col15, #T_7948c_row1_col17, #T_7948c_row2_col13, #T_7948c_row2_col14, #T_7948c_row2_col15, #T_7948c_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7948c_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7948c_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7948c_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7948c_row1_col9, #T_7948c_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7948c_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7948c_row1_col12, #T_7948c_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7948c_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7948c_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7948c_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7948c_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7948c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7948c_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_7948c_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_7948c_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_7948c_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_7948c_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_7948c_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_7948c_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_7948c_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_7948c_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_7948c_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_7948c_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_7948c_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_7948c_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_7948c_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_7948c_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_7948c_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_7948c_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_7948c_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7948c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7948c_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_7948c_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_7948c_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_7948c_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_7948c_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_7948c_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_7948c_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_7948c_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_7948c_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_7948c_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_7948c_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_7948c_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_7948c_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_7948c_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_7948c_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_7948c_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_7948c_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_7948c_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7948c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7948c_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_7948c_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_7948c_row1_col2\" class=\"data row1 col2\" >38.4</td>\n",
       "      <td id=\"T_7948c_row1_col3\" class=\"data row1 col3\" >36.5</td>\n",
       "      <td id=\"T_7948c_row1_col4\" class=\"data row1 col4\" >6.6</td>\n",
       "      <td id=\"T_7948c_row1_col5\" class=\"data row1 col5\" >10.8</td>\n",
       "      <td id=\"T_7948c_row1_col6\" class=\"data row1 col6\" >31.3</td>\n",
       "      <td id=\"T_7948c_row1_col7\" class=\"data row1 col7\" >34.1</td>\n",
       "      <td id=\"T_7948c_row1_col8\" class=\"data row1 col8\" >7.9</td>\n",
       "      <td id=\"T_7948c_row1_col9\" class=\"data row1 col9\" >33.3</td>\n",
       "      <td id=\"T_7948c_row1_col10\" class=\"data row1 col10\" >11.8</td>\n",
       "      <td id=\"T_7948c_row1_col11\" class=\"data row1 col11\" >48.5</td>\n",
       "      <td id=\"T_7948c_row1_col12\" class=\"data row1 col12\" >252.2</td>\n",
       "      <td id=\"T_7948c_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_7948c_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_7948c_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_7948c_row1_col16\" class=\"data row1 col16\" >46.5</td>\n",
       "      <td id=\"T_7948c_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7948c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7948c_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_ep=3</td>\n",
       "      <td id=\"T_7948c_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_7948c_row2_col2\" class=\"data row2 col2\" >39.1</td>\n",
       "      <td id=\"T_7948c_row2_col3\" class=\"data row2 col3\" >36.6</td>\n",
       "      <td id=\"T_7948c_row2_col4\" class=\"data row2 col4\" >5.6</td>\n",
       "      <td id=\"T_7948c_row2_col5\" class=\"data row2 col5\" >10.0</td>\n",
       "      <td id=\"T_7948c_row2_col6\" class=\"data row2 col6\" >30.7</td>\n",
       "      <td id=\"T_7948c_row2_col7\" class=\"data row2 col7\" >33.4</td>\n",
       "      <td id=\"T_7948c_row2_col8\" class=\"data row2 col8\" >7.9</td>\n",
       "      <td id=\"T_7948c_row2_col9\" class=\"data row2 col9\" >32.5</td>\n",
       "      <td id=\"T_7948c_row2_col10\" class=\"data row2 col10\" >10.4</td>\n",
       "      <td id=\"T_7948c_row2_col11\" class=\"data row2 col11\" >52.5</td>\n",
       "      <td id=\"T_7948c_row2_col12\" class=\"data row2 col12\" >236.0</td>\n",
       "      <td id=\"T_7948c_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_7948c_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_7948c_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_7948c_row2_col16\" class=\"data row2 col16\" >45.0</td>\n",
       "      <td id=\"T_7948c_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf4e030d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d4d93 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_d4d93_row0_col0, #T_d4d93_row1_col0, #T_d4d93_row2_col0, #T_d4d93_row3_col0, #T_d4d93_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d4d93_row0_col1, #T_d4d93_row1_col1, #T_d4d93_row2_col1, #T_d4d93_row3_col1, #T_d4d93_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d4d93_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row0_col4, #T_d4d93_row0_col8, #T_d4d93_row0_col9, #T_d4d93_row0_col12, #T_d4d93_row0_col16, #T_d4d93_row1_col2, #T_d4d93_row1_col5, #T_d4d93_row1_col6, #T_d4d93_row1_col10, #T_d4d93_row1_col11, #T_d4d93_row2_col7, #T_d4d93_row2_col13, #T_d4d93_row2_col15, #T_d4d93_row2_col17, #T_d4d93_row3_col3, #T_d4d93_row4_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row0_col6, #T_d4d93_row0_col11, #T_d4d93_row1_col4, #T_d4d93_row3_col7, #T_d4d93_row3_col8, #T_d4d93_row3_col9, #T_d4d93_row3_col10, #T_d4d93_row3_col14, #T_d4d93_row3_col15, #T_d4d93_row4_col2, #T_d4d93_row4_col3, #T_d4d93_row4_col5, #T_d4d93_row4_col12, #T_d4d93_row4_col13, #T_d4d93_row4_col16, #T_d4d93_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row0_col10, #T_d4d93_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row0_col13, #T_d4d93_row0_col14, #T_d4d93_row0_col15, #T_d4d93_row0_col17, #T_d4d93_row1_col13, #T_d4d93_row1_col14, #T_d4d93_row1_col15, #T_d4d93_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row1_col12, #T_d4d93_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row2_col6, #T_d4d93_row4_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ec7f63;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d4d93_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d4d93_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d4d93\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d4d93_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d4d93_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_d4d93_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d4d93_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d4d93_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_d4d93_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_d4d93_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_d4d93_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_d4d93_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d4d93_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d4d93_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d4d93_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_d4d93_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_d4d93_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_d4d93_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_d4d93_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_d4d93_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_d4d93_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d4d93_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d4d93_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_d4d93_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_d4d93_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_d4d93_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_d4d93_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_d4d93_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_d4d93_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_d4d93_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_d4d93_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_d4d93_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_d4d93_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_d4d93_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_d4d93_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_d4d93_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_d4d93_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_d4d93_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_d4d93_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_d4d93_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4d93_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d4d93_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_d4d93_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_d4d93_row1_col2\" class=\"data row1 col2\" >35.0</td>\n",
       "      <td id=\"T_d4d93_row1_col3\" class=\"data row1 col3\" >37.0</td>\n",
       "      <td id=\"T_d4d93_row1_col4\" class=\"data row1 col4\" >2.8</td>\n",
       "      <td id=\"T_d4d93_row1_col5\" class=\"data row1 col5\" >13.4</td>\n",
       "      <td id=\"T_d4d93_row1_col6\" class=\"data row1 col6\" >33.7</td>\n",
       "      <td id=\"T_d4d93_row1_col7\" class=\"data row1 col7\" >32.5</td>\n",
       "      <td id=\"T_d4d93_row1_col8\" class=\"data row1 col8\" >7.7</td>\n",
       "      <td id=\"T_d4d93_row1_col9\" class=\"data row1 col9\" >30.1</td>\n",
       "      <td id=\"T_d4d93_row1_col10\" class=\"data row1 col10\" >14.6</td>\n",
       "      <td id=\"T_d4d93_row1_col11\" class=\"data row1 col11\" >44.8</td>\n",
       "      <td id=\"T_d4d93_row1_col12\" class=\"data row1 col12\" >261.7</td>\n",
       "      <td id=\"T_d4d93_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_d4d93_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_d4d93_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_d4d93_row1_col16\" class=\"data row1 col16\" >46.7</td>\n",
       "      <td id=\"T_d4d93_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4d93_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d4d93_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_d4d93_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_d4d93_row2_col2\" class=\"data row2 col2\" >32.6</td>\n",
       "      <td id=\"T_d4d93_row2_col3\" class=\"data row2 col3\" >35.4</td>\n",
       "      <td id=\"T_d4d93_row2_col4\" class=\"data row2 col4\" >3.8</td>\n",
       "      <td id=\"T_d4d93_row2_col5\" class=\"data row2 col5\" >12.8</td>\n",
       "      <td id=\"T_d4d93_row2_col6\" class=\"data row2 col6\" >33.4</td>\n",
       "      <td id=\"T_d4d93_row2_col7\" class=\"data row2 col7\" >33.4</td>\n",
       "      <td id=\"T_d4d93_row2_col8\" class=\"data row2 col8\" >8.3</td>\n",
       "      <td id=\"T_d4d93_row2_col9\" class=\"data row2 col9\" >32.0</td>\n",
       "      <td id=\"T_d4d93_row2_col10\" class=\"data row2 col10\" >10.2</td>\n",
       "      <td id=\"T_d4d93_row2_col11\" class=\"data row2 col11\" >40.4</td>\n",
       "      <td id=\"T_d4d93_row2_col12\" class=\"data row2 col12\" >263.0</td>\n",
       "      <td id=\"T_d4d93_row2_col13\" class=\"data row2 col13\" >46.2</td>\n",
       "      <td id=\"T_d4d93_row2_col14\" class=\"data row2 col14\" >26.6</td>\n",
       "      <td id=\"T_d4d93_row2_col15\" class=\"data row2 col15\" >36.5</td>\n",
       "      <td id=\"T_d4d93_row2_col16\" class=\"data row2 col16\" >43.9</td>\n",
       "      <td id=\"T_d4d93_row2_col17\" class=\"data row2 col17\" >-38.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4d93_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d4d93_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_d4d93_row3_col1\" class=\"data row3 col1\" >10000</td>\n",
       "      <td id=\"T_d4d93_row3_col2\" class=\"data row3 col2\" >34.0</td>\n",
       "      <td id=\"T_d4d93_row3_col3\" class=\"data row3 col3\" >37.8</td>\n",
       "      <td id=\"T_d4d93_row3_col4\" class=\"data row3 col4\" >4.8</td>\n",
       "      <td id=\"T_d4d93_row3_col5\" class=\"data row3 col5\" >12.0</td>\n",
       "      <td id=\"T_d4d93_row3_col6\" class=\"data row3 col6\" >32.9</td>\n",
       "      <td id=\"T_d4d93_row3_col7\" class=\"data row3 col7\" >30.6</td>\n",
       "      <td id=\"T_d4d93_row3_col8\" class=\"data row3 col8\" >7.0</td>\n",
       "      <td id=\"T_d4d93_row3_col9\" class=\"data row3 col9\" >28.3</td>\n",
       "      <td id=\"T_d4d93_row3_col10\" class=\"data row3 col10\" >6.3</td>\n",
       "      <td id=\"T_d4d93_row3_col11\" class=\"data row3 col11\" >36.3</td>\n",
       "      <td id=\"T_d4d93_row3_col12\" class=\"data row3 col12\" >244.3</td>\n",
       "      <td id=\"T_d4d93_row3_col13\" class=\"data row3 col13\" >44.2</td>\n",
       "      <td id=\"T_d4d93_row3_col14\" class=\"data row3 col14\" >25.9</td>\n",
       "      <td id=\"T_d4d93_row3_col15\" class=\"data row3 col15\" >35.4</td>\n",
       "      <td id=\"T_d4d93_row3_col16\" class=\"data row3 col16\" >41.4</td>\n",
       "      <td id=\"T_d4d93_row3_col17\" class=\"data row3 col17\" >-47.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4d93_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d4d93_row4_col0\" class=\"data row4 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_d4d93_row4_col1\" class=\"data row4 col1\" >10000</td>\n",
       "      <td id=\"T_d4d93_row4_col2\" class=\"data row4 col2\" >29.4</td>\n",
       "      <td id=\"T_d4d93_row4_col3\" class=\"data row4 col3\" >32.9</td>\n",
       "      <td id=\"T_d4d93_row4_col4\" class=\"data row4 col4\" >4.6</td>\n",
       "      <td id=\"T_d4d93_row4_col5\" class=\"data row4 col5\" >11.4</td>\n",
       "      <td id=\"T_d4d93_row4_col6\" class=\"data row4 col6\" >30.8</td>\n",
       "      <td id=\"T_d4d93_row4_col7\" class=\"data row4 col7\" >31.8</td>\n",
       "      <td id=\"T_d4d93_row4_col8\" class=\"data row4 col8\" >7.8</td>\n",
       "      <td id=\"T_d4d93_row4_col9\" class=\"data row4 col9\" >29.7</td>\n",
       "      <td id=\"T_d4d93_row4_col10\" class=\"data row4 col10\" >10.0</td>\n",
       "      <td id=\"T_d4d93_row4_col11\" class=\"data row4 col11\" >35.9</td>\n",
       "      <td id=\"T_d4d93_row4_col12\" class=\"data row4 col12\" >221.6</td>\n",
       "      <td id=\"T_d4d93_row4_col13\" class=\"data row4 col13\" >43.9</td>\n",
       "      <td id=\"T_d4d93_row4_col14\" class=\"data row4 col14\" >28.9</td>\n",
       "      <td id=\"T_d4d93_row4_col15\" class=\"data row4 col15\" >36.4</td>\n",
       "      <td id=\"T_d4d93_row4_col16\" class=\"data row4 col16\" >39.6</td>\n",
       "      <td id=\"T_d4d93_row4_col17\" class=\"data row4 col17\" >-49.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf5a92500>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c2a4f td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_c2a4f_row0_col0, #T_c2a4f_row1_col0, #T_c2a4f_row2_col0, #T_c2a4f_row3_col0, #T_c2a4f_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c2a4f_row0_col1, #T_c2a4f_row1_col1, #T_c2a4f_row2_col1, #T_c2a4f_row3_col1, #T_c2a4f_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c2a4f_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row0_col4, #T_c2a4f_row0_col8, #T_c2a4f_row0_col9, #T_c2a4f_row0_col12, #T_c2a4f_row0_col16, #T_c2a4f_row1_col2, #T_c2a4f_row1_col3, #T_c2a4f_row1_col11, #T_c2a4f_row1_col13, #T_c2a4f_row1_col15, #T_c2a4f_row1_col17, #T_c2a4f_row2_col10, #T_c2a4f_row3_col5, #T_c2a4f_row3_col6, #T_c2a4f_row3_col7, #T_c2a4f_row4_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row0_col5, #T_c2a4f_row0_col6, #T_c2a4f_row0_col10, #T_c2a4f_row0_col11, #T_c2a4f_row2_col4, #T_c2a4f_row2_col7, #T_c2a4f_row2_col9, #T_c2a4f_row2_col12, #T_c2a4f_row2_col16, #T_c2a4f_row3_col8, #T_c2a4f_row3_col9, #T_c2a4f_row3_col10, #T_c2a4f_row3_col13, #T_c2a4f_row3_col14, #T_c2a4f_row3_col15, #T_c2a4f_row3_col16, #T_c2a4f_row4_col2, #T_c2a4f_row4_col3, #T_c2a4f_row4_col16, #T_c2a4f_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row0_col13, #T_c2a4f_row0_col14, #T_c2a4f_row0_col15, #T_c2a4f_row0_col17, #T_c2a4f_row2_col13, #T_c2a4f_row2_col14, #T_c2a4f_row2_col15, #T_c2a4f_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row1_col5, #T_c2a4f_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f08a6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row2_col11, #T_c2a4f_row3_col11, #T_c2a4f_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row3_col12, #T_c2a4f_row4_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c2a4f_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row4_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c2a4f_row4_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c2a4f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c2a4f_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_c2a4f_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_c2a4f_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_c2a4f_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_c2a4f_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_c2a4f_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_c2a4f_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_c2a4f_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_c2a4f_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_c2a4f_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_c2a4f_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_c2a4f_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_c2a4f_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_c2a4f_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_c2a4f_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_c2a4f_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_c2a4f_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_c2a4f_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c2a4f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c2a4f_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_c2a4f_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_c2a4f_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_c2a4f_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_c2a4f_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_c2a4f_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_c2a4f_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_c2a4f_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_c2a4f_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_c2a4f_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_c2a4f_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_c2a4f_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_c2a4f_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_c2a4f_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_c2a4f_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_c2a4f_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_c2a4f_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_c2a4f_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c2a4f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c2a4f_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_c2a4f_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_c2a4f_row1_col2\" class=\"data row1 col2\" >35.6</td>\n",
       "      <td id=\"T_c2a4f_row1_col3\" class=\"data row1 col3\" >37.6</td>\n",
       "      <td id=\"T_c2a4f_row1_col4\" class=\"data row1 col4\" >4.8</td>\n",
       "      <td id=\"T_c2a4f_row1_col5\" class=\"data row1 col5\" >13.2</td>\n",
       "      <td id=\"T_c2a4f_row1_col6\" class=\"data row1 col6\" >33.3</td>\n",
       "      <td id=\"T_c2a4f_row1_col7\" class=\"data row1 col7\" >33.2</td>\n",
       "      <td id=\"T_c2a4f_row1_col8\" class=\"data row1 col8\" >8.4</td>\n",
       "      <td id=\"T_c2a4f_row1_col9\" class=\"data row1 col9\" >31.3</td>\n",
       "      <td id=\"T_c2a4f_row1_col10\" class=\"data row1 col10\" >13.0</td>\n",
       "      <td id=\"T_c2a4f_row1_col11\" class=\"data row1 col11\" >46.9</td>\n",
       "      <td id=\"T_c2a4f_row1_col12\" class=\"data row1 col12\" >280.9</td>\n",
       "      <td id=\"T_c2a4f_row1_col13\" class=\"data row1 col13\" >49.2</td>\n",
       "      <td id=\"T_c2a4f_row1_col14\" class=\"data row1 col14\" >32.8</td>\n",
       "      <td id=\"T_c2a4f_row1_col15\" class=\"data row1 col15\" >41.1</td>\n",
       "      <td id=\"T_c2a4f_row1_col16\" class=\"data row1 col16\" >47.2</td>\n",
       "      <td id=\"T_c2a4f_row1_col17\" class=\"data row1 col17\" >-26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c2a4f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c2a4f_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_c2a4f_row2_col1\" class=\"data row2 col1\" >None</td>\n",
       "      <td id=\"T_c2a4f_row2_col2\" class=\"data row2 col2\" >35.0</td>\n",
       "      <td id=\"T_c2a4f_row2_col3\" class=\"data row2 col3\" >37.0</td>\n",
       "      <td id=\"T_c2a4f_row2_col4\" class=\"data row2 col4\" >2.8</td>\n",
       "      <td id=\"T_c2a4f_row2_col5\" class=\"data row2 col5\" >13.4</td>\n",
       "      <td id=\"T_c2a4f_row2_col6\" class=\"data row2 col6\" >33.7</td>\n",
       "      <td id=\"T_c2a4f_row2_col7\" class=\"data row2 col7\" >32.5</td>\n",
       "      <td id=\"T_c2a4f_row2_col8\" class=\"data row2 col8\" >7.7</td>\n",
       "      <td id=\"T_c2a4f_row2_col9\" class=\"data row2 col9\" >30.1</td>\n",
       "      <td id=\"T_c2a4f_row2_col10\" class=\"data row2 col10\" >14.6</td>\n",
       "      <td id=\"T_c2a4f_row2_col11\" class=\"data row2 col11\" >44.8</td>\n",
       "      <td id=\"T_c2a4f_row2_col12\" class=\"data row2 col12\" >261.7</td>\n",
       "      <td id=\"T_c2a4f_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_c2a4f_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_c2a4f_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_c2a4f_row2_col16\" class=\"data row2 col16\" >46.7</td>\n",
       "      <td id=\"T_c2a4f_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c2a4f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c2a4f_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_c2a4f_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_c2a4f_row3_col2\" class=\"data row3 col2\" >35.2</td>\n",
       "      <td id=\"T_c2a4f_row3_col3\" class=\"data row3 col3\" >35.4</td>\n",
       "      <td id=\"T_c2a4f_row3_col4\" class=\"data row3 col4\" >4.6</td>\n",
       "      <td id=\"T_c2a4f_row3_col5\" class=\"data row3 col5\" >14.0</td>\n",
       "      <td id=\"T_c2a4f_row3_col6\" class=\"data row3 col6\" >34.5</td>\n",
       "      <td id=\"T_c2a4f_row3_col7\" class=\"data row3 col7\" >35.5</td>\n",
       "      <td id=\"T_c2a4f_row3_col8\" class=\"data row3 col8\" >7.1</td>\n",
       "      <td id=\"T_c2a4f_row3_col9\" class=\"data row3 col9\" >30.1</td>\n",
       "      <td id=\"T_c2a4f_row3_col10\" class=\"data row3 col10\" >10.2</td>\n",
       "      <td id=\"T_c2a4f_row3_col11\" class=\"data row3 col11\" >44.8</td>\n",
       "      <td id=\"T_c2a4f_row3_col12\" class=\"data row3 col12\" >288.3</td>\n",
       "      <td id=\"T_c2a4f_row3_col13\" class=\"data row3 col13\" >45.9</td>\n",
       "      <td id=\"T_c2a4f_row3_col14\" class=\"data row3 col14\" >28.1</td>\n",
       "      <td id=\"T_c2a4f_row3_col15\" class=\"data row3 col15\" >37.0</td>\n",
       "      <td id=\"T_c2a4f_row3_col16\" class=\"data row3 col16\" >46.5</td>\n",
       "      <td id=\"T_c2a4f_row3_col17\" class=\"data row3 col17\" >-33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c2a4f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c2a4f_row4_col0\" class=\"data row4 col0\" >llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_c2a4f_row4_col1\" class=\"data row4 col1\" >30000</td>\n",
       "      <td id=\"T_c2a4f_row4_col2\" class=\"data row4 col2\" >28.5</td>\n",
       "      <td id=\"T_c2a4f_row4_col3\" class=\"data row4 col3\" >31.5</td>\n",
       "      <td id=\"T_c2a4f_row4_col4\" class=\"data row4 col4\" >3.8</td>\n",
       "      <td id=\"T_c2a4f_row4_col5\" class=\"data row4 col5\" >12.0</td>\n",
       "      <td id=\"T_c2a4f_row4_col6\" class=\"data row4 col6\" >34.4</td>\n",
       "      <td id=\"T_c2a4f_row4_col7\" class=\"data row4 col7\" >34.5</td>\n",
       "      <td id=\"T_c2a4f_row4_col8\" class=\"data row4 col8\" >7.8</td>\n",
       "      <td id=\"T_c2a4f_row4_col9\" class=\"data row4 col9\" >31.2</td>\n",
       "      <td id=\"T_c2a4f_row4_col10\" class=\"data row4 col10\" >13.2</td>\n",
       "      <td id=\"T_c2a4f_row4_col11\" class=\"data row4 col11\" >44.8</td>\n",
       "      <td id=\"T_c2a4f_row4_col12\" class=\"data row4 col12\" >283.5</td>\n",
       "      <td id=\"T_c2a4f_row4_col13\" class=\"data row4 col13\" >46.8</td>\n",
       "      <td id=\"T_c2a4f_row4_col14\" class=\"data row4 col14\" >34.8</td>\n",
       "      <td id=\"T_c2a4f_row4_col15\" class=\"data row4 col15\" >40.8</td>\n",
       "      <td id=\"T_c2a4f_row4_col16\" class=\"data row4 col16\" >46.2</td>\n",
       "      <td id=\"T_c2a4f_row4_col17\" class=\"data row4 col17\" >-33.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf6bf8250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a3720 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_a3720_row0_col0, #T_a3720_row1_col0, #T_a3720_row2_col0, #T_a3720_row3_col0, #T_a3720_row4_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a3720_row0_col1, #T_a3720_row1_col1, #T_a3720_row2_col1, #T_a3720_row3_col1, #T_a3720_row4_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a3720_row0_col2, #T_a3720_row0_col3, #T_a3720_row0_col5, #T_a3720_row0_col6, #T_a3720_row0_col10, #T_a3720_row0_col11, #T_a3720_row1_col4, #T_a3720_row1_col7, #T_a3720_row1_col8, #T_a3720_row1_col9, #T_a3720_row3_col13, #T_a3720_row3_col14, #T_a3720_row3_col15, #T_a3720_row3_col16, #T_a3720_row3_col17, #T_a3720_row4_col12, #T_a3720_row4_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row0_col4, #T_a3720_row0_col8, #T_a3720_row0_col9, #T_a3720_row0_col12, #T_a3720_row0_col16, #T_a3720_row1_col10, #T_a3720_row2_col3, #T_a3720_row2_col5, #T_a3720_row2_col7, #T_a3720_row2_col13, #T_a3720_row2_col14, #T_a3720_row2_col15, #T_a3720_row2_col17, #T_a3720_row3_col2, #T_a3720_row3_col3, #T_a3720_row3_col6, #T_a3720_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row0_col7, #T_a3720_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row0_col13, #T_a3720_row0_col14, #T_a3720_row0_col15, #T_a3720_row0_col17, #T_a3720_row1_col13, #T_a3720_row1_col14, #T_a3720_row1_col15, #T_a3720_row1_col17, #T_a3720_row4_col13, #T_a3720_row4_col14, #T_a3720_row4_col15, #T_a3720_row4_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row1_col12, #T_a3720_row1_col16, #T_a3720_row2_col16, #T_a3720_row3_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row2_col8, #T_a3720_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #bd1f2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row3_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row4_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row4_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f29274;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row4_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a3720_row4_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a3720_row4_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a3720\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a3720_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_a3720_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_a3720_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_a3720_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_a3720_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_a3720_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_a3720_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_a3720_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_a3720_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_a3720_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_a3720_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_a3720_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_a3720_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_a3720_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_a3720_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_a3720_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_a3720_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_a3720_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a3720_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a3720_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_a3720_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_a3720_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_a3720_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_a3720_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_a3720_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_a3720_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_a3720_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_a3720_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_a3720_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_a3720_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_a3720_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_a3720_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_a3720_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_a3720_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_a3720_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_a3720_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_a3720_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3720_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a3720_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_a3720_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_a3720_row1_col2\" class=\"data row1 col2\" >35.0</td>\n",
       "      <td id=\"T_a3720_row1_col3\" class=\"data row1 col3\" >37.0</td>\n",
       "      <td id=\"T_a3720_row1_col4\" class=\"data row1 col4\" >2.8</td>\n",
       "      <td id=\"T_a3720_row1_col5\" class=\"data row1 col5\" >13.4</td>\n",
       "      <td id=\"T_a3720_row1_col6\" class=\"data row1 col6\" >33.7</td>\n",
       "      <td id=\"T_a3720_row1_col7\" class=\"data row1 col7\" >32.5</td>\n",
       "      <td id=\"T_a3720_row1_col8\" class=\"data row1 col8\" >7.7</td>\n",
       "      <td id=\"T_a3720_row1_col9\" class=\"data row1 col9\" >30.1</td>\n",
       "      <td id=\"T_a3720_row1_col10\" class=\"data row1 col10\" >14.6</td>\n",
       "      <td id=\"T_a3720_row1_col11\" class=\"data row1 col11\" >44.8</td>\n",
       "      <td id=\"T_a3720_row1_col12\" class=\"data row1 col12\" >261.7</td>\n",
       "      <td id=\"T_a3720_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_a3720_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_a3720_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_a3720_row1_col16\" class=\"data row1 col16\" >46.7</td>\n",
       "      <td id=\"T_a3720_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3720_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a3720_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_a3720_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_a3720_row2_col2\" class=\"data row2 col2\" >32.2</td>\n",
       "      <td id=\"T_a3720_row2_col3\" class=\"data row2 col3\" >38.1</td>\n",
       "      <td id=\"T_a3720_row2_col4\" class=\"data row2 col4\" >4.4</td>\n",
       "      <td id=\"T_a3720_row2_col5\" class=\"data row2 col5\" >15.6</td>\n",
       "      <td id=\"T_a3720_row2_col6\" class=\"data row2 col6\" >33.9</td>\n",
       "      <td id=\"T_a3720_row2_col7\" class=\"data row2 col7\" >34.9</td>\n",
       "      <td id=\"T_a3720_row2_col8\" class=\"data row2 col8\" >8.1</td>\n",
       "      <td id=\"T_a3720_row2_col9\" class=\"data row2 col9\" >32.4</td>\n",
       "      <td id=\"T_a3720_row2_col10\" class=\"data row2 col10\" >13.2</td>\n",
       "      <td id=\"T_a3720_row2_col11\" class=\"data row2 col11\" >47.7</td>\n",
       "      <td id=\"T_a3720_row2_col12\" class=\"data row2 col12\" >268.2</td>\n",
       "      <td id=\"T_a3720_row2_col13\" class=\"data row2 col13\" >46.6</td>\n",
       "      <td id=\"T_a3720_row2_col14\" class=\"data row2 col14\" >35.4</td>\n",
       "      <td id=\"T_a3720_row2_col15\" class=\"data row2 col15\" >41.1</td>\n",
       "      <td id=\"T_a3720_row2_col16\" class=\"data row2 col16\" >46.6</td>\n",
       "      <td id=\"T_a3720_row2_col17\" class=\"data row2 col17\" >-24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3720_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a3720_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_a3720_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_a3720_row3_col2\" class=\"data row3 col2\" >38.0</td>\n",
       "      <td id=\"T_a3720_row3_col3\" class=\"data row3 col3\" >38.1</td>\n",
       "      <td id=\"T_a3720_row3_col4\" class=\"data row3 col4\" >3.8</td>\n",
       "      <td id=\"T_a3720_row3_col5\" class=\"data row3 col5\" >13.8</td>\n",
       "      <td id=\"T_a3720_row3_col6\" class=\"data row3 col6\" >36.4</td>\n",
       "      <td id=\"T_a3720_row3_col7\" class=\"data row3 col7\" >34.5</td>\n",
       "      <td id=\"T_a3720_row3_col8\" class=\"data row3 col8\" >7.8</td>\n",
       "      <td id=\"T_a3720_row3_col9\" class=\"data row3 col9\" >33.1</td>\n",
       "      <td id=\"T_a3720_row3_col10\" class=\"data row3 col10\" >12.6</td>\n",
       "      <td id=\"T_a3720_row3_col11\" class=\"data row3 col11\" >48.9</td>\n",
       "      <td id=\"T_a3720_row3_col12\" class=\"data row3 col12\" >264.1</td>\n",
       "      <td id=\"T_a3720_row3_col13\" class=\"data row3 col13\" >46.2</td>\n",
       "      <td id=\"T_a3720_row3_col14\" class=\"data row3 col14\" >32.1</td>\n",
       "      <td id=\"T_a3720_row3_col15\" class=\"data row3 col15\" >39.2</td>\n",
       "      <td id=\"T_a3720_row3_col16\" class=\"data row3 col16\" >46.3</td>\n",
       "      <td id=\"T_a3720_row3_col17\" class=\"data row3 col17\" >-24.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3720_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a3720_row4_col0\" class=\"data row4 col0\" >llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_a3720_row4_col1\" class=\"data row4 col1\" >60000</td>\n",
       "      <td id=\"T_a3720_row4_col2\" class=\"data row4 col2\" >33.4</td>\n",
       "      <td id=\"T_a3720_row4_col3\" class=\"data row4 col3\" >35.3</td>\n",
       "      <td id=\"T_a3720_row4_col4\" class=\"data row4 col4\" >4.8</td>\n",
       "      <td id=\"T_a3720_row4_col5\" class=\"data row4 col5\" >13.2</td>\n",
       "      <td id=\"T_a3720_row4_col6\" class=\"data row4 col6\" >35.4</td>\n",
       "      <td id=\"T_a3720_row4_col7\" class=\"data row4 col7\" >33.5</td>\n",
       "      <td id=\"T_a3720_row4_col8\" class=\"data row4 col8\" >8.1</td>\n",
       "      <td id=\"T_a3720_row4_col9\" class=\"data row4 col9\" >30.7</td>\n",
       "      <td id=\"T_a3720_row4_col10\" class=\"data row4 col10\" >12.4</td>\n",
       "      <td id=\"T_a3720_row4_col11\" class=\"data row4 col11\" >46.2</td>\n",
       "      <td id=\"T_a3720_row4_col12\" class=\"data row4 col12\" >252.1</td>\n",
       "      <td id=\"T_a3720_row4_col13\" class=\"data row4 col13\" >nan</td>\n",
       "      <td id=\"T_a3720_row4_col14\" class=\"data row4 col14\" >nan</td>\n",
       "      <td id=\"T_a3720_row4_col15\" class=\"data row4 col15\" >nan</td>\n",
       "      <td id=\"T_a3720_row4_col16\" class=\"data row4 col16\" >45.9</td>\n",
       "      <td id=\"T_a3720_row4_col17\" class=\"data row4 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf56cf9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ae34e td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_ae34e_row0_col0, #T_ae34e_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ae34e_row0_col1, #T_ae34e_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ae34e_row0_col2, #T_ae34e_row0_col3, #T_ae34e_row0_col5, #T_ae34e_row0_col6, #T_ae34e_row0_col10, #T_ae34e_row0_col11, #T_ae34e_row1_col4, #T_ae34e_row1_col7, #T_ae34e_row1_col8, #T_ae34e_row1_col9, #T_ae34e_row1_col12, #T_ae34e_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ae34e_row0_col4, #T_ae34e_row0_col7, #T_ae34e_row0_col8, #T_ae34e_row0_col9, #T_ae34e_row0_col12, #T_ae34e_row0_col16, #T_ae34e_row1_col2, #T_ae34e_row1_col3, #T_ae34e_row1_col5, #T_ae34e_row1_col6, #T_ae34e_row1_col10, #T_ae34e_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ae34e_row0_col13, #T_ae34e_row0_col14, #T_ae34e_row0_col15, #T_ae34e_row0_col17, #T_ae34e_row1_col13, #T_ae34e_row1_col14, #T_ae34e_row1_col15, #T_ae34e_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ae34e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ae34e_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_ae34e_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_ae34e_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_ae34e_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_ae34e_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_ae34e_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_ae34e_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_ae34e_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_ae34e_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_ae34e_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_ae34e_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_ae34e_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_ae34e_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_ae34e_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_ae34e_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_ae34e_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_ae34e_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_ae34e_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ae34e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ae34e_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_ae34e_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_ae34e_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_ae34e_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_ae34e_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_ae34e_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_ae34e_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_ae34e_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_ae34e_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_ae34e_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_ae34e_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_ae34e_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_ae34e_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_ae34e_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_ae34e_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_ae34e_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_ae34e_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_ae34e_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ae34e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ae34e_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_ae34e_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_ae34e_row1_col2\" class=\"data row1 col2\" >35.0</td>\n",
       "      <td id=\"T_ae34e_row1_col3\" class=\"data row1 col3\" >37.0</td>\n",
       "      <td id=\"T_ae34e_row1_col4\" class=\"data row1 col4\" >2.8</td>\n",
       "      <td id=\"T_ae34e_row1_col5\" class=\"data row1 col5\" >13.4</td>\n",
       "      <td id=\"T_ae34e_row1_col6\" class=\"data row1 col6\" >33.7</td>\n",
       "      <td id=\"T_ae34e_row1_col7\" class=\"data row1 col7\" >32.5</td>\n",
       "      <td id=\"T_ae34e_row1_col8\" class=\"data row1 col8\" >7.7</td>\n",
       "      <td id=\"T_ae34e_row1_col9\" class=\"data row1 col9\" >30.1</td>\n",
       "      <td id=\"T_ae34e_row1_col10\" class=\"data row1 col10\" >14.6</td>\n",
       "      <td id=\"T_ae34e_row1_col11\" class=\"data row1 col11\" >44.8</td>\n",
       "      <td id=\"T_ae34e_row1_col12\" class=\"data row1 col12\" >261.7</td>\n",
       "      <td id=\"T_ae34e_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_ae34e_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_ae34e_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_ae34e_row1_col16\" class=\"data row1 col16\" >46.7</td>\n",
       "      <td id=\"T_ae34e_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf6bf8250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182110/3320746127.py:372: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_182110/3320746127.py:378: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ff27e td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_ff27e_row0_col0, #T_ff27e_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ff27e_row0_col1, #T_ff27e_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ff27e_row0_col2, #T_ff27e_row0_col3, #T_ff27e_row0_col5, #T_ff27e_row0_col6, #T_ff27e_row0_col10, #T_ff27e_row0_col11, #T_ff27e_row1_col4, #T_ff27e_row1_col7, #T_ff27e_row1_col8, #T_ff27e_row1_col9, #T_ff27e_row1_col12, #T_ff27e_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff27e_row0_col4, #T_ff27e_row0_col7, #T_ff27e_row0_col8, #T_ff27e_row0_col9, #T_ff27e_row0_col12, #T_ff27e_row0_col16, #T_ff27e_row1_col2, #T_ff27e_row1_col3, #T_ff27e_row1_col5, #T_ff27e_row1_col6, #T_ff27e_row1_col10, #T_ff27e_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ff27e_row0_col13, #T_ff27e_row0_col14, #T_ff27e_row0_col15, #T_ff27e_row0_col17, #T_ff27e_row1_col13, #T_ff27e_row1_col14, #T_ff27e_row1_col15, #T_ff27e_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ff27e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ff27e_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_ff27e_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_ff27e_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_ff27e_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_ff27e_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_ff27e_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_ff27e_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_ff27e_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_ff27e_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_ff27e_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_ff27e_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_ff27e_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th id=\"T_ff27e_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th id=\"T_ff27e_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_ff27e_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_ff27e_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_ff27e_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_ff27e_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ff27e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ff27e_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_ff27e_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_ff27e_row0_col2\" class=\"data row0 col2\" >31.8</td>\n",
       "      <td id=\"T_ff27e_row0_col3\" class=\"data row0 col3\" >34.5</td>\n",
       "      <td id=\"T_ff27e_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_ff27e_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_ff27e_row0_col6\" class=\"data row0 col6\" >30.6</td>\n",
       "      <td id=\"T_ff27e_row0_col7\" class=\"data row0 col7\" >32.7</td>\n",
       "      <td id=\"T_ff27e_row0_col8\" class=\"data row0 col8\" >9.6</td>\n",
       "      <td id=\"T_ff27e_row0_col9\" class=\"data row0 col9\" >38.4</td>\n",
       "      <td id=\"T_ff27e_row0_col10\" class=\"data row0 col10\" >10.2</td>\n",
       "      <td id=\"T_ff27e_row0_col11\" class=\"data row0 col11\" >0.0</td>\n",
       "      <td id=\"T_ff27e_row0_col12\" class=\"data row0 col12\" >1992.1</td>\n",
       "      <td id=\"T_ff27e_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_ff27e_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_ff27e_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_ff27e_row0_col16\" class=\"data row0 col16\" >199.7</td>\n",
       "      <td id=\"T_ff27e_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff27e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ff27e_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_ff27e_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_ff27e_row1_col2\" class=\"data row1 col2\" >35.0</td>\n",
       "      <td id=\"T_ff27e_row1_col3\" class=\"data row1 col3\" >37.0</td>\n",
       "      <td id=\"T_ff27e_row1_col4\" class=\"data row1 col4\" >2.8</td>\n",
       "      <td id=\"T_ff27e_row1_col5\" class=\"data row1 col5\" >13.4</td>\n",
       "      <td id=\"T_ff27e_row1_col6\" class=\"data row1 col6\" >33.7</td>\n",
       "      <td id=\"T_ff27e_row1_col7\" class=\"data row1 col7\" >32.5</td>\n",
       "      <td id=\"T_ff27e_row1_col8\" class=\"data row1 col8\" >7.7</td>\n",
       "      <td id=\"T_ff27e_row1_col9\" class=\"data row1 col9\" >30.1</td>\n",
       "      <td id=\"T_ff27e_row1_col10\" class=\"data row1 col10\" >14.6</td>\n",
       "      <td id=\"T_ff27e_row1_col11\" class=\"data row1 col11\" >44.8</td>\n",
       "      <td id=\"T_ff27e_row1_col12\" class=\"data row1 col12\" >261.7</td>\n",
       "      <td id=\"T_ff27e_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_ff27e_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_ff27e_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_ff27e_row1_col16\" class=\"data row1 col16\" >46.7</td>\n",
       "      <td id=\"T_ff27e_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x151cf3d7b130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_sort_rows_by_avg_ranking\n",
    "from llm.evaluate import EvalResults, get_eval_results\n",
    "\n",
    "\n",
    "\n",
    "exp_dir = ''\n",
    "chat_fmt = None\n",
    "sort_rows = True\n",
    "use_normalized_preferred_metric = False\n",
    "\n",
    "\n",
    "# ## investigate code change / package update effect on eval baselines.\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# use_normalized_preferred_metric = False\n",
    "# sort_rows = False\n",
    "# save_dirs = [\n",
    "#     # llama\n",
    "#     ('llama-7b_12.13update_before', '../results/baselines/huggyllama/llama-7b_12.13update_before/'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('llama-7b_10.30update', '../results/baselines/huggyllama/llama-7b_10.30update/'),\n",
    "# #     ('llama-7b_09.23update', '../results/baselines/huggyllama/llama-7b_09.23update/'),\n",
    "# #     ('llama-7b_09.23update_before', '../results/baselines/huggyllama/llama-7b_09.23update_before/'),\n",
    "# #     # llama2\n",
    "#     ('llama2-7b_12.13update_before', '../results/baselines/NousResearch/Llama-2-7b-hf_12.13update_before/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('llama2-7b-chat', '../results/baselines/NousResearch/Llama-2-7b-chat-hf/'),\n",
    "# #     ('llama2-7b_10.30update', '../results/baselines/NousResearch/Llama-2-7b-hf_10.30update/'),\n",
    "# #     ('llama2-7b_original', '../results/baselines/NousResearch/Llama-2-7b-hf_original/'),\n",
    "# #     # mistral\n",
    "# #     ('mistral-7b_10.16update', '../results/baselines/mistralai/Mistral-7B-v0.1_10.16update/'),\n",
    "#     ('mistral-7b-Instruct-v0.1_12.13update_before', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1_12.13update_before'),\n",
    "#     ('mistral-7b-Instruct-v0.1', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     # zephyr\n",
    "#     ('zephyr-7b-beta_12.13update_before', '../results/baselines/HuggingFaceH4/zephyr-7b-beta_12.13update_before'),\n",
    "#     ('zephyr-7b-beta', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "\n",
    "# # baselines\n",
    "# save_dirs = []\n",
    "# save_dirs += [\n",
    "# #     ('gpt2', '../results/baselines/gpt2'),\n",
    "# #     ('gpt2m', '../results/baselines/gpt2-medium'),\n",
    "# #     ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "# #     ('llama2-7b+humanmix', '../results/llama2-7b_humanmix'),\n",
    "# #     ('pythia-1.4b', '../results/baselines/EleutherAI/pythia-1.4b'),\n",
    "# #     ('pythia-2.8b', '../results/baselines/EleutherAI/pythia-2.8b'),\n",
    "# #     ('pythia-6.9b', '../results/baselines/EleutherAI/pythia-6.9b'),\n",
    "# #     ('dolly-v2-7b', '../results/baselines/databricks/dolly-v2-7b'),\n",
    "#     ('mistral-7b-v0.1', '../results/baselines/mistralai/Mistral-7B-v0.1'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b+lima_ep=2', '../results/ft1_ep=2/llama-7b_lima/'),\n",
    "# #     ('mistral-7b+lima_ep=2', '../results/ft1_ep=2/mistral-7b_lima/'), \n",
    "# ]\n",
    "# exp_dir = '../results/oi2/'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "\n",
    "# exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# # exp_dir = '../results/ft2'\n",
    "# # exp_dir = '../results/ft1'\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# # save_dirs = [\n",
    "# #     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "# #     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1/'),\n",
    "# # ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'tuluv1m' in x]\n",
    "\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "# # exp_dir = '../results/oi4'\n",
    "# # exp_dir = '../results/oi4_perf_cross_time'\n",
    "# # exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'\n",
    "# exp_dir = '../results/oi4_flan_v2_vary_subsetsize'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi4_flan2022_1m'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #              ('llama-7b_flan_v2_ep=2', '../results/ft1/llama-7b_flan_v2'),\n",
    "# #              ('llama-7b_humanmix_ep=2', '../results/ft1/llama-7b_humanmix'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "# #              ('llama-7b_cot:flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_cot:flanv2'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# # exp_dir = '../results/oi4_tulu_v1_mix'\n",
    "# exp_dir = '../results/oi4_tulu_v1_mix_ep=3'\n",
    "# use_normalized_preferred_metric = False\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# ###### ultrachat\n",
    "# save_dirs = [\n",
    "#     # baselines \n",
    "#     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "#     ('mistral-7b_ultrachat200k_aftersplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k'),\n",
    "#     ('mistral-7b_ultrachat200k_beforesplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k_beforesplitlongconv'),\n",
    "    \n",
    "#     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     ('mistral-7b_sft-alpha', '../results/baselines/HuggingFaceH4/mistral-7b-sft-alpha'),\n",
    "#     ('mistral-7b-sft-beta', '../results/baselines/HuggingFaceH4/mistral-7b-sft-beta'),\n",
    "#     ('mistral-7b-sft-alpha+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-alpha'),\n",
    "#     ('mistral-7b-sft-beta+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "# # exp_dir = '../results/oi5_ultrachat:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_ultrachat200k:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# exp_dir = '../results/oi5_ultrachat15:mistral-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "# dataset = 'stanford_alpaca'\n",
    "# dataset = 'open_orca_slim'\n",
    "# dataset = 'sharegptv2'\n",
    "# dataset = 'ultrachat200kv2'\n",
    "# dataset = 'wizardlm'\n",
    "# dataset = 'wizardlmv2'\n",
    "# dataset = 'tulu_v2'\n",
    "# dataset = 'flan_v2'\n",
    "# dataset = 'oasst1'\n",
    "# dataset = 'dolly'\n",
    "# dataset_list = [\n",
    "#     'dolly',\n",
    "#     'oasst1', \n",
    "#     'flan_v2', \n",
    "#     'stanford_alpaca', \n",
    "#     'wizardlmv2', \n",
    "#     'sharegptv2', \n",
    "#     'ultrachat200kv2',\n",
    "# ]; finetune_type = 'sft'\n",
    "# dataset_list = [\n",
    "#     'ultrafeedback',\n",
    "# #     'ultrafeedbackfull',\n",
    "# ]; finetune_type = 'pref'\n",
    "dataset_list = [\n",
    "    'dolly',\n",
    "    'flan_v250k',\n",
    "    'stanford_alpaca50k', \n",
    "    'oasst2',\n",
    "    'wizardlm50k', \n",
    "    'sharegpt50k',\n",
    "    'ultrachat50k',\n",
    "]; finetune_type = 'sft'\n",
    "\n",
    "## older\n",
    "# dataset = 'tulu_v1_mix'\n",
    "save_dirs = []\n",
    "save_dirs += [\n",
    "    ('llama-7b', '../results/baselines/huggyllama/llama-7b'),\n",
    "#     ('llama-7b_lima_ep=5', '../results/oi2/llama-7b_lima_ep=5/'),\n",
    "#     ('llama-7b_lima_ep=10', '../results/oi2/llama-7b_lima_ep=10/'),\n",
    "]\n",
    "for dataset in dataset_list:\n",
    "    if dataset == 'tulu_v2':\n",
    "        save_dirs += [('llama-7b_tulu_v2:100k_ep=2', '../results/oi2/llama-7b_tulu_v2:100k_ep=2'),]\n",
    "    elif dataset == 'open_orca_slim':\n",
    "        save_dirs += [('llama-7b_openorcaslim:100k_ep=2', '../results/oi2/llama-7b_openorcaslim:100k_ep=2'),]\n",
    "    elif dataset == 'sharegptv2':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_sharegptv2_ep=2', '../results/oi2/llama-7b_sharegptv2_ep=2'),\n",
    "            ('llama-7b_sharegpt_ep=2', '../results/ft1_ep=2/llama-7b_sharegpt'),]\n",
    "    elif dataset == 'tulu_v1_mix':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "            # oi4_tulu_v1_mix_ep=3 models before transformers update.\n",
    "            # ('llama-7b_tuluv1m:50k_log_prob_decr_<10.16update', '../results/oi4_tulu_v1_mix_ep=3/llama-7b_tuluv1m:50k_log_prob_decr'),\n",
    "        ]\n",
    "    elif dataset == 'ultrafeedback':\n",
    "        exp_dir = f'../results/dpo1/'\n",
    "        save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "    else:\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=2', f'../results/oi2/llama-7b_{dataset}_ep=2'),]\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=3', f'../results/oi2/llama-7b_{dataset}_ep=3'),]\n",
    "    \n",
    "    if finetune_type == 'sft':\n",
    "        exp_dir = f'../results/oi5_{dataset}:llama-7b'\n",
    "    elif finetune_type == 'pref':\n",
    "        exp_dir = f'../results/dpo2_{dataset}:llama-7b+sharegptv2ep2/'\n",
    "    save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'dppmapbd' not in x and 'semdedup' not in x]\n",
    "    \n",
    "    if finetune_type == 'pref':\n",
    "        sft_model_dataset = 'sharegptv2'\n",
    "        save_dirs += [('llama-7b_sharegptv2_ep=2', f'../results/oi2/llama-7b_{sft_model_dataset}_ep=2')]\n",
    "# ## just compare dppmap grad vs. text\n",
    "# save_dirs = [x for x in save_dirs if 'prune:size=10000:ep=10' in x[1] and (\n",
    "#         'random' in x[1] or \n",
    "#         'dppmap' in x[1]\n",
    "#     )\n",
    "# ]\n",
    "save_dirs = [x for x in save_dirs if ('size=80000:ep=2' not in x[1]) and ('size=80000:ep=3' not in x[1])]\n",
    "#####\n",
    "\n",
    "\n",
    "# ##### code instructions\n",
    "# save_dirs = [\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('codellama-7b', '../results/baselines/codellama/CodeLlama-7b-hf/'),\n",
    "#     ('codellama-7b-instruct', '../results/baselines/codellama/CodeLlama-7b-Python-hf/'),\n",
    "#     ('codellama-7b-python', '../results/baselines/codellama/CodeLlama-7b-Instruct-hf/'),\n",
    "# ]\n",
    "\n",
    "# exp_dir = '../results/oi2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'starcoder' in x]\n",
    "# exp_dir = '../results/oi6_starcoder_ep=5'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstr:codellama-7b'\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstrv2:codellama-7b'\n",
    "# exp_dir = '../results/oi5_starcoder_commentinstrv5:codellama-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "###### \n",
    "\n",
    "from llm.evaluate import detect_oom_evals\n",
    "oom_eval_paths = detect_oom_evals([x for l in [glob.glob(os.path.join(x[1], 'eval/*/*.out')) for x in save_dirs] for x in l])\n",
    "if oom_eval_paths: print(oom_eval_paths)\n",
    "    \n",
    "cols_avg_blacklist = ['AlpacaFarm/Len']\n",
    "\n",
    "# chat_fmt = False\n",
    "# chat_fmt = True\n",
    "# chat_fmt = 'both'\n",
    "# chat_fmt = 'auto' # base model no chatfmt, tuned model with chatfmt\n",
    "chat_fmt = 'mix'  # non-alpacaeval no chatfmt, alpacaeval chatfmt\n",
    "alpacafarm_judge = 'chatgpt'\n",
    "alpacafarm_judge = 'alpaca:eval:gpt4:turbo:fn'\n",
    "mtbench_judge = 'gpt:4:1106:preview'\n",
    "\n",
    "ft_args_fields = {\n",
    "    'run_name': ('run_name',),\n",
    "    'model_name_or_path': ('model_args.model_name_or_path', 'model_name_or_path'),\n",
    "    'subsample_mixture': ('data_args.subsample_mixture',),\n",
    "    'max_train_samples': ('data_args.max_train_samples', 'max_train_samples'),\n",
    "    'train_file': ('data_args.train_file', 'train_file'),\n",
    "}\n",
    "\n",
    "cols = []\n",
    "# cols += [f'AlpacaFarm({alpacafarm_judge})/WR',  f'AlpacaFarm({alpacafarm_judge})/ΔWR', f'AlpacaFarm({alpacafarm_judge})/Rep', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "cols += ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1'] \n",
    "cols += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "cols += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "# cols += [f'MTBench({mtbench_judge})/Turn-1']\n",
    "\n",
    "\n",
    "\n",
    "# cols = [f'BBH {x}' for x in ['reasoning', 'nlu', 'knowledge', 'multilingual']]; cols = [x+'/Direct' for x in cols] + [x+'/CoT' for x in cols]\n",
    "# cols = [f'MMLU {x}' for x in ['STEM', 'humanities', 'social sciences', 'other']]; cols = [x+'/0-shot' for x in cols] + [x+'/5-shot' for x in cols]\n",
    "\n",
    "if 'open_orca_slim' in exp_dir:\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'BBH/Direct', 'BBH/CoT']\n",
    "    cols = ['MMLU/0-shot', 'BBH/Direct']\n",
    "if 'starcoder' in exp_dir:\n",
    "    cols = ['Codex-Eval/Pass@1']\n",
    "    chat_fmt = 'both'\n",
    "print(f'chat_fmt={chat_fmt}')\n",
    "df = get_eval_results(save_dirs, chat_fmt=chat_fmt, ft_args_fields=ft_args_fields, use_normalized_preferred_metric=use_normalized_preferred_metric)\n",
    "\n",
    "cols = [x for x in cols if x in df.columns]\n",
    "df = df[list(ft_args_fields.keys()) + cols]\n",
    "if chat_fmt == 'both':\n",
    "    for col_lvl2 in ['', 'chatfmt']:\n",
    "        df[('Average', col_lvl2)] = df[list(set(df.columns) & set([(x, col_lvl2) for x in list(set(cols)-set(cols_avg_blacklist))]))].mean(axis=1)\n",
    "else:\n",
    "    df['Average'] = df[list(set(cols)-set(cols_avg_blacklist))].mean(axis=1)\n",
    "if sort_rows:\n",
    "    df = pd_sort_rows_by_avg_ranking(df); df['ranking'] = -df['ranking']\n",
    "    sort_value_col, sort_value_col_ascending = ('Average', 'chatfmt') if chat_fmt=='both' else 'Average', False\n",
    "#     sort_value_col, sort_value_col_ascending = 'ranking', False\n",
    "    df = df.sort_values(by=sort_value_col, ascending=sort_value_col_ascending)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def compute_total_train_samples(x):\n",
    "    match = re.search(r'size=(\\d+)', x['run_name' if chat_fmt!='both' else ('run_name', '')])\n",
    "    total_train_samples = match.group(1) if match else None\n",
    "    return total_train_samples\n",
    "df.insert(1, 'total_train_samples' if chat_fmt!='both' else ('total_train_samples', ''), df.apply(compute_total_train_samples, axis=1))\n",
    "def extract_dataset_from_train_file(x):\n",
    "    if x is None: return None\n",
    "    x = x.split('/')[-1].split('.jsonl')[0]\n",
    "    if x.endswith('_data'): x = x[:-5]\n",
    "    if x.endswith('_train'): x = x[:-6]\n",
    "    return x\n",
    "df.insert(1, 'dataset' if chat_fmt!='both' else ('dataset', ''), df['train_file'].apply(extract_dataset_from_train_file))\n",
    "df = df.drop('train_file', axis=1)\n",
    "\n",
    "if any(exp_dir.endswith(x) for x in ['ft2']):\n",
    "#     for model_name_contain in ['gpt2', 'llama', 'pythia-1.4b']:\n",
    "#         for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "    for model_name_contain in ['llama']:\n",
    "        for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "#         for total_train_samples in [200000, 400000, 600000]:\n",
    "            dfc = df.copy()\n",
    "            dfc.insert(0, 'total_train_samples',  dfc['subsample_mixture'].apply(\n",
    "                lambda d: sum(list(d.values())) if d else 200000))\n",
    "            dfc = dfc[dfc['total_train_samples'].apply(\n",
    "                lambda x: total_train_samples-20000<x<total_train_samples+20000)]\n",
    "            dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "                lambda x: model_name_contain in x)]\n",
    "            dfc['total_train_samples'] = dfc['total_train_samples'].astype(str)\n",
    "            dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture'])\n",
    "            dfc = dfc.reset_index(drop=True)\n",
    "            if len(dfc):\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .format(precision=2))\n",
    "else:\n",
    "    for model_name_contain in ['llama', 'pythia-1.4b', 'mistral', 'zephyr']:\n",
    "        dfc = df.copy()\n",
    "        dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "            lambda x: model_name_contain in x.lower())]\n",
    "        if not len(dfc): continue\n",
    "        from rosemary import pd_average_col_contains_substr\n",
    "        Ns = sorted(np.unique([int(x) for x in df['total_train_samples'].to_numpy() if x]).tolist())\n",
    "        datasets = sorted(np.unique([x for x in df['dataset'] if x is not None]).tolist())\n",
    "        for dataset in datasets:\n",
    "            for N in Ns+[None]:\n",
    "                dfc = df.copy()\n",
    "                dfc = dfc[dfc['total_train_samples'].apply(lambda x: int(x) == N if x else True)]\n",
    "                dfc = dfc[dfc['dataset'].apply(lambda x: x == dataset if x else True)]\n",
    "                if not len(dfc): continue\n",
    "                col_runname = 'run_name' if chat_fmt != 'both' else ('run_name', '')\n",
    "                substitute = True\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, '_random_', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=10000:ep=10', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=50000:ep=5', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=3', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=1', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=100000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=200000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=400000', substitute=substitute)\n",
    "                #     dfc = dfc.sort_values(['ranking'], ascending=False)\n",
    "                col = ('Average', 'chatfmt') if chat_fmt == 'both' else 'Average'\n",
    "            #     col = 'AlpacaFarm/WR'\n",
    "            #     col = 'MMLU/0-shot'|\n",
    "            #     col = 'GSM/CoT'\n",
    "            #     col = 'BBH/Direct'\n",
    "            #     col = 'TydiQA/GP'\n",
    "                dfc = dfc.sort_values(by=[col], ascending=False)\n",
    "                dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture', 'max_train_samples', 'dataset'], \n",
    "                               axis=1, level=0 if chat_fmt=='both' else None)\n",
    "                dfc = dfc.reset_index(drop=True)\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .applymap(lambda x: f'max-width: 60ch;', subset=['run_name'])\n",
    "                        .set_table_styles([{'selector': 'td', 'props': [('white-space', 'pre-wrap'), ('word-wrap', 'break-word')]}])\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .applymap(lambda x: 'text-decoration: underline;' \\\n",
    "                                  if x in dfc[list(set(dfc.columns) & set([(x, '') for x in cols]))+[col] if chat_fmt=='both' else cols+[col]].values.flatten() and chat_fmt=='both' else '')\n",
    "                        .format(precision=1))\n",
    "\n",
    "# llama-7b_tulu_v1_mix(paper)\n",
    "# MMLU/0-shot, MMLU/5-shot, GSM/Direct, GSM/CoT, BBH/Direct, BBH/CoT, TydiQA/GP, TydiQA/CB, CodexEval/Pass@1, AlpacaEval(vs.Davinci-003)\n",
    "# 44.8       , 47.1       , 7.0       , 25.0   , 38.5      , 38.5   , 43.5,    , 8.0      , 18.6,           , 48.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "deeba0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_name',\n",
       " 'nonchat',\n",
       " 'compute',\n",
       " 'sort_by',\n",
       " 'total_train_samples',\n",
       " 'model_name_or_path',\n",
       " 'subsample_mixture',\n",
       " 'max_train_samples',\n",
       " 'MMLU/0-shot',\n",
       " 'MMLU/5-shot',\n",
       " 'GSM/Direct',\n",
       " 'GSM/CoT',\n",
       " 'BBH/Direct',\n",
       " 'BBH/CoT',\n",
       " 'TydiQA/CB',\n",
       " 'TydiQA/GP',\n",
       " 'Codex-Eval/Pass@1',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*',\n",
       " 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len',\n",
       " 'MTBench(gpt:4:1106:preview)/Turn-1',\n",
       " 'MTBench(gpt:4:1106:preview)/Turn-2',\n",
       " 'MTBench(gpt:4:1106:preview)/Rating',\n",
       " 'Average',\n",
       " 'ranking']"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rosemary import parse_kv_from_string\n",
    "from functools import partial\n",
    "\n",
    "def get_dataset_size(dataset):\n",
    "    if dataset == 'dolly':\n",
    "        return 14956\n",
    "    else:\n",
    "        return 50_000\n",
    "    \n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', ]\n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', ]\n",
    "\n",
    "N = 50_000\n",
    "full_sft_run_name_substr = '_ep=3'\n",
    "# full_sft_run_name_substr = '_ep=2'\n",
    "full_sft_short = 'sft_full'\n",
    "\n",
    "\n",
    "def compute_nonchateval_average_performance(row):\n",
    "    L = [row[k] for k in non_chateval_task_names if k in row]\n",
    "    return np.average(L)\n",
    "\n",
    "\n",
    "def parse_prune_subset_size_and_compute(row, return_total_size=True):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'(?<=pace=)([^_]+)', run_name)\n",
    "    if match:\n",
    "        pace = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(pace)\n",
    "        if return_total_size:\n",
    "            return kvs['size']\n",
    "        else:\n",
    "            return int(kvs['size'] / kvs['ep'])\n",
    "    else:\n",
    "        N = get_dataset_size(row['dataset'])\n",
    "        if run_name.endswith(full_sft_run_name_substr):\n",
    "            ep = int(re.search(r\"ep=(\\d+)\", run_name).group(1))\n",
    "            if return_total_size:\n",
    "                return N*ep\n",
    "            else:\n",
    "                return N\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def parse_sort_by_from_run_name(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'score=([^_]+)', run_name)\n",
    "    if match:\n",
    "        sort_by = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(sort_by)\n",
    "    else:\n",
    "        if run_name.endswith(full_sft_run_name_substr):\n",
    "            kvs = {0: 'sft_full'}\n",
    "        else:\n",
    "            kvs = {}\n",
    "    return kvs\n",
    "\n",
    "\n",
    "def parse_sort_by_type(row):\n",
    "    d = row['sort_by']\n",
    "    if not d:\n",
    "        return None\n",
    "    if d[0] == 'dppmap':\n",
    "        if d['k']=='vmf' and d['kmd']=='mpnet': #and (d['gamma']==1 or d['gamma'] == 'auto1000'):\n",
    "            return 'vmf+text'\n",
    "        elif d['kemb']=='text+embedding' and d['kmd'] == 'llama7br512p4096':\n",
    "            if d['k']=='rbf': return f\"rbf+text_gamma={d['gamma']}\"\n",
    "            elif d['k'] == 'vmf': return f\"vmf+text_gamma={d['gamma']}\"\n",
    "        elif d['kemb']=='grad+rp+loraB' and d['kmd'] == 'llama7br512p4096':\n",
    "            if d['k']=='rbf': return f\"rbf+grad_gamma={d['gamma']}\"\n",
    "            elif d['k']=='vmf': return f\"vmf+grad_gamma={d['gamma']}\"\n",
    "        else:\n",
    "            print(d)\n",
    "            return None\n",
    "    elif d[0] == 'random':\n",
    "        return 'random'\n",
    "    elif d[0].startswith('sft'):\n",
    "        return d[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "base_model_perf = df[df['run_name'] == 'llama-7b'].to_dict(orient='records')[0]\n",
    "base_model_perf['nonchat'] = compute_nonchateval_average_performance(base_model_perf)\n",
    "\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "dfc.insert(1, 'sort_by' if chat_fmt!='both' else ('sort_by', ''), dfc.apply(parse_sort_by_from_run_name, axis=1))\n",
    "dfc.insert(1, 'sort_by_type' if chat_fmt!='both' else ('sort_by_type', ''), dfc.apply(parse_sort_by_type, axis=1))\n",
    "dfc.insert(1, 'subset_size' if chat_fmt!='both' else ('subset_size', ''), dfc.apply(partial(parse_prune_subset_size_and_compute, return_total_size=False), axis=1))\n",
    "dfc.insert(1, 'compute' if chat_fmt!='both' else ('compute', ''), dfc.apply(partial(parse_prune_subset_size_and_compute, return_total_size=True), axis=1))\n",
    "dfc.insert(1, 'nonchat' if chat_fmt!='both' else ('nonchat', ''), dfc.apply(compute_nonchateval_average_performance, axis=1))\n",
    "\n",
    "\n",
    "dfc = dfc[dfc['sort_by_type'].notnull()]\n",
    "startswithstrs = ('rbf+text', 'random')\n",
    "startswithstrs = (\n",
    "    full_sft_short,\n",
    "    'random', \n",
    "    'vmf+grad_gamma=1',\n",
    "#     'rbf+text_gamma=0.001', \n",
    "#     'vmf+text_gamma=10',\n",
    "#     'rbf+grad_gamma=0.01',\n",
    "#     'rbf+text_gamma=auto1000', \n",
    "#     'vmf+grad_gamma=auto1000',\n",
    ")\n",
    "dfc = dfc[dfc.apply(lambda x: x['sort_by_type'].startswith(startswithstrs)\n",
    "                   , axis=1)]\n",
    "dfc['subset_size'] = dfc['subset_size'].apply(lambda x: int(x) if x else x)\n",
    "dfc['compute'] = dfc['compute'].apply(lambda x: int(x) if x else x)\n",
    "# dfc = dfc[dfc['subset_size'].apply(lambda x: x == 20_000)]\n",
    "\n",
    "\n",
    "D = dfc.set_index(['sort_by_type', 'dataset', 'subset_size']).to_dict()\n",
    "from dataclasses import dataclass\n",
    "@dataclass(unsafe_hash=True)\n",
    "class DKey:\n",
    "    sort_by_type: str\n",
    "    dataset: str\n",
    "    subset_size: int\n",
    "def convert_key_to_dataclass(d):\n",
    "    return {DKey(*k): v for k, v in d.items()}\n",
    "D = {k: convert_key_to_dataclass(v) for k, v in D.items()}\n",
    "\n",
    "list(D.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "df966911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>nonchat</th>\n",
       "      <th>compute</th>\n",
       "      <th>subset_size</th>\n",
       "      <th>sort_by_type</th>\n",
       "      <th>sort_by</th>\n",
       "      <th>dataset</th>\n",
       "      <th>total_train_samples</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>subsample_mixture</th>\n",
       "      <th>...</th>\n",
       "      <th>TydiQA/CB</th>\n",
       "      <th>TydiQA/GP</th>\n",
       "      <th>Codex-Eval/Pass@1</th>\n",
       "      <th>AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*</th>\n",
       "      <th>AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len</th>\n",
       "      <th>MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th>MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th>MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th>Average</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td>24.353010</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>sharegpt50k</td>\n",
       "      <td>30000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.682985</td>\n",
       "      <td>33.608573</td>\n",
       "      <td>11.382114</td>\n",
       "      <td>48.944099</td>\n",
       "      <td>346.985093</td>\n",
       "      <td>53.125</td>\n",
       "      <td>40.506329</td>\n",
       "      <td>46.855346</td>\n",
       "      <td>53.512749</td>\n",
       "      <td>-19.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td>25.513615</td>\n",
       "      <td>60000</td>\n",
       "      <td>20000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>sharegpt50k</td>\n",
       "      <td>60000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.787952</td>\n",
       "      <td>34.435272</td>\n",
       "      <td>11.382114</td>\n",
       "      <td>54.596273</td>\n",
       "      <td>326.693168</td>\n",
       "      <td>51.750</td>\n",
       "      <td>38.750000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>52.704141</td>\n",
       "      <td>-15.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3</td>\n",
       "      <td>25.988269</td>\n",
       "      <td>90000</td>\n",
       "      <td>30000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>sharegpt50k</td>\n",
       "      <td>90000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.114699</td>\n",
       "      <td>33.072397</td>\n",
       "      <td>13.211382</td>\n",
       "      <td>56.770186</td>\n",
       "      <td>284.870807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.340543</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=90000:ep=3</td>\n",
       "      <td>25.855976</td>\n",
       "      <td>90000</td>\n",
       "      <td>30000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>sharegpt50k</td>\n",
       "      <td>90000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.934978</td>\n",
       "      <td>32.476766</td>\n",
       "      <td>12.601626</td>\n",
       "      <td>53.105590</td>\n",
       "      <td>286.649689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.014441</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama-7b_sharegpt50k_ep=3</td>\n",
       "      <td>25.659797</td>\n",
       "      <td>150000</td>\n",
       "      <td>50000</td>\n",
       "      <td>sft_full</td>\n",
       "      <td>{0: 'sft_full'}</td>\n",
       "      <td>sharegpt50k</td>\n",
       "      <td>None</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.404910</td>\n",
       "      <td>33.076438</td>\n",
       "      <td>10.772358</td>\n",
       "      <td>55.962733</td>\n",
       "      <td>280.284472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.577012</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td>23.449338</td>\n",
       "      <td>60000</td>\n",
       "      <td>20000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>oasst2</td>\n",
       "      <td>60000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.482175</td>\n",
       "      <td>33.053241</td>\n",
       "      <td>9.756098</td>\n",
       "      <td>38.447205</td>\n",
       "      <td>356.831056</td>\n",
       "      <td>41.625</td>\n",
       "      <td>27.341772</td>\n",
       "      <td>34.528302</td>\n",
       "      <td>50.318151</td>\n",
       "      <td>-33.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td>23.033590</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>oasst2</td>\n",
       "      <td>30000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.012248</td>\n",
       "      <td>29.147260</td>\n",
       "      <td>7.926829</td>\n",
       "      <td>40.062112</td>\n",
       "      <td>363.681988</td>\n",
       "      <td>39.500</td>\n",
       "      <td>27.625000</td>\n",
       "      <td>33.562500</td>\n",
       "      <td>50.201874</td>\n",
       "      <td>-36.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td>23.941923</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>sharegpt50k</td>\n",
       "      <td>30000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.883713</td>\n",
       "      <td>32.838123</td>\n",
       "      <td>14.024390</td>\n",
       "      <td>52.360248</td>\n",
       "      <td>311.680745</td>\n",
       "      <td>45.875</td>\n",
       "      <td>35.375000</td>\n",
       "      <td>40.625000</td>\n",
       "      <td>49.659378</td>\n",
       "      <td>-23.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td>25.078363</td>\n",
       "      <td>60000</td>\n",
       "      <td>20000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>sharegpt50k</td>\n",
       "      <td>60000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.229089</td>\n",
       "      <td>32.741452</td>\n",
       "      <td>12.398374</td>\n",
       "      <td>50.372671</td>\n",
       "      <td>288.319255</td>\n",
       "      <td>49.625</td>\n",
       "      <td>36.625000</td>\n",
       "      <td>43.125000</td>\n",
       "      <td>48.899001</td>\n",
       "      <td>-21.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=10000:ep=10</td>\n",
       "      <td>22.901829</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>sharegpt50k</td>\n",
       "      <td>10000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.282947</td>\n",
       "      <td>28.273825</td>\n",
       "      <td>12.195122</td>\n",
       "      <td>50.993789</td>\n",
       "      <td>314.621118</td>\n",
       "      <td>46.375</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>40.187500</td>\n",
       "      <td>48.717642</td>\n",
       "      <td>-33.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td>24.396701</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>wizardlm50k</td>\n",
       "      <td>30000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.440357</td>\n",
       "      <td>31.304623</td>\n",
       "      <td>13.008130</td>\n",
       "      <td>46.894410</td>\n",
       "      <td>280.853416</td>\n",
       "      <td>49.250</td>\n",
       "      <td>32.784810</td>\n",
       "      <td>41.069182</td>\n",
       "      <td>47.240979</td>\n",
       "      <td>-26.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td>24.625021</td>\n",
       "      <td>60000</td>\n",
       "      <td>20000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>wizardlm50k</td>\n",
       "      <td>60000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.084618</td>\n",
       "      <td>32.355604</td>\n",
       "      <td>13.211382</td>\n",
       "      <td>47.701863</td>\n",
       "      <td>268.175155</td>\n",
       "      <td>46.625</td>\n",
       "      <td>35.384615</td>\n",
       "      <td>41.075949</td>\n",
       "      <td>46.555568</td>\n",
       "      <td>-24.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td>23.073099</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>sharegpt50k</td>\n",
       "      <td>10000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.854762</td>\n",
       "      <td>32.053478</td>\n",
       "      <td>8.739837</td>\n",
       "      <td>42.236025</td>\n",
       "      <td>288.613665</td>\n",
       "      <td>46.000</td>\n",
       "      <td>31.772152</td>\n",
       "      <td>38.930818</td>\n",
       "      <td>46.426614</td>\n",
       "      <td>-32.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td>23.622440</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>ultrachat50k</td>\n",
       "      <td>30000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.258062</td>\n",
       "      <td>31.851278</td>\n",
       "      <td>11.585366</td>\n",
       "      <td>47.826087</td>\n",
       "      <td>264.288199</td>\n",
       "      <td>50.625</td>\n",
       "      <td>36.708861</td>\n",
       "      <td>43.710692</td>\n",
       "      <td>46.330376</td>\n",
       "      <td>-30.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td>22.556978</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>wizardlm50k</td>\n",
       "      <td>30000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.767049</td>\n",
       "      <td>31.174715</td>\n",
       "      <td>13.211382</td>\n",
       "      <td>44.844720</td>\n",
       "      <td>283.506832</td>\n",
       "      <td>46.750</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>46.245869</td>\n",
       "      <td>-33.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3</td>\n",
       "      <td>23.696420</td>\n",
       "      <td>90000</td>\n",
       "      <td>30000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>ultrachat50k</td>\n",
       "      <td>90000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.694827</td>\n",
       "      <td>32.354570</td>\n",
       "      <td>9.349593</td>\n",
       "      <td>50.993789</td>\n",
       "      <td>251.132919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.186458</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td>23.958953</td>\n",
       "      <td>60000</td>\n",
       "      <td>20000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>ultrachat50k</td>\n",
       "      <td>60000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.539529</td>\n",
       "      <td>29.951814</td>\n",
       "      <td>10.772358</td>\n",
       "      <td>50.745342</td>\n",
       "      <td>251.397516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.122443</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td>23.991207</td>\n",
       "      <td>60000</td>\n",
       "      <td>20000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>wizardlm50k</td>\n",
       "      <td>60000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.101167</td>\n",
       "      <td>30.696673</td>\n",
       "      <td>12.398374</td>\n",
       "      <td>46.211180</td>\n",
       "      <td>252.111801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.914479</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td>23.900686</td>\n",
       "      <td>60000</td>\n",
       "      <td>20000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>ultrachat50k</td>\n",
       "      <td>60000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.872376</td>\n",
       "      <td>30.390822</td>\n",
       "      <td>11.178862</td>\n",
       "      <td>48.881988</td>\n",
       "      <td>247.469565</td>\n",
       "      <td>50.375</td>\n",
       "      <td>37.468354</td>\n",
       "      <td>43.962264</td>\n",
       "      <td>45.266084</td>\n",
       "      <td>-32.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td>23.855818</td>\n",
       "      <td>60000</td>\n",
       "      <td>20000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>oasst2</td>\n",
       "      <td>60000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.597158</td>\n",
       "      <td>28.892248</td>\n",
       "      <td>13.008130</td>\n",
       "      <td>40.621118</td>\n",
       "      <td>277.067081</td>\n",
       "      <td>43.250</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>37.437500</td>\n",
       "      <td>45.248631</td>\n",
       "      <td>-35.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=90000:ep=3</td>\n",
       "      <td>24.378619</td>\n",
       "      <td>90000</td>\n",
       "      <td>30000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>ultrachat50k</td>\n",
       "      <td>90000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.840521</td>\n",
       "      <td>32.605795</td>\n",
       "      <td>10.162602</td>\n",
       "      <td>51.055901</td>\n",
       "      <td>235.505590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.241649</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>llama-7b_ultrachat50k_ep=3</td>\n",
       "      <td>23.684465</td>\n",
       "      <td>150000</td>\n",
       "      <td>50000</td>\n",
       "      <td>sft_full</td>\n",
       "      <td>{0: 'sft_full'}</td>\n",
       "      <td>ultrachat50k</td>\n",
       "      <td>None</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.912641</td>\n",
       "      <td>32.465762</td>\n",
       "      <td>10.365854</td>\n",
       "      <td>52.546584</td>\n",
       "      <td>235.997516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.973978</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td>23.989855</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>ultrachat50k</td>\n",
       "      <td>30000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.746092</td>\n",
       "      <td>32.050918</td>\n",
       "      <td>12.601626</td>\n",
       "      <td>48.819876</td>\n",
       "      <td>255.604969</td>\n",
       "      <td>44.125</td>\n",
       "      <td>32.278481</td>\n",
       "      <td>38.238994</td>\n",
       "      <td>44.842380</td>\n",
       "      <td>-30.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=10000:ep=10</td>\n",
       "      <td>23.592516</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>ultrachat50k</td>\n",
       "      <td>10000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.836692</td>\n",
       "      <td>31.200762</td>\n",
       "      <td>9.959350</td>\n",
       "      <td>45.279503</td>\n",
       "      <td>239.781366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.476903</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td>22.361916</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>dolly</td>\n",
       "      <td>10000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>6.427229</td>\n",
       "      <td>35.375491</td>\n",
       "      <td>10.365854</td>\n",
       "      <td>22.484472</td>\n",
       "      <td>297.956522</td>\n",
       "      <td>33.625</td>\n",
       "      <td>18.076923</td>\n",
       "      <td>25.949367</td>\n",
       "      <td>42.602030</td>\n",
       "      <td>-48.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td>21.932524</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>ultrachat50k</td>\n",
       "      <td>10000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.136182</td>\n",
       "      <td>27.619956</td>\n",
       "      <td>6.300813</td>\n",
       "      <td>41.801242</td>\n",
       "      <td>232.539130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.056744</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>llama-7b_dolly_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td>22.686205</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>dolly</td>\n",
       "      <td>30000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.599339</td>\n",
       "      <td>42.061917</td>\n",
       "      <td>11.585366</td>\n",
       "      <td>12.049689</td>\n",
       "      <td>277.636025</td>\n",
       "      <td>35.750</td>\n",
       "      <td>19.746835</td>\n",
       "      <td>27.798742</td>\n",
       "      <td>41.603285</td>\n",
       "      <td>-41.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td>23.999724</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>dolly</td>\n",
       "      <td>30000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.549075</td>\n",
       "      <td>37.688146</td>\n",
       "      <td>10.365854</td>\n",
       "      <td>17.639752</td>\n",
       "      <td>263.125466</td>\n",
       "      <td>38.500</td>\n",
       "      <td>19.487179</td>\n",
       "      <td>29.113924</td>\n",
       "      <td>41.507258</td>\n",
       "      <td>-37.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td>22.621001</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>wizardlm50k</td>\n",
       "      <td>10000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.008973</td>\n",
       "      <td>28.272535</td>\n",
       "      <td>6.300813</td>\n",
       "      <td>36.335404</td>\n",
       "      <td>244.347826</td>\n",
       "      <td>44.250</td>\n",
       "      <td>25.866667</td>\n",
       "      <td>35.354839</td>\n",
       "      <td>41.413089</td>\n",
       "      <td>-47.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>llama-7b_dolly_ep=3</td>\n",
       "      <td>23.769367</td>\n",
       "      <td>44868</td>\n",
       "      <td>14956</td>\n",
       "      <td>sft_full</td>\n",
       "      <td>{0: 'sft_full'}</td>\n",
       "      <td>dolly</td>\n",
       "      <td>None</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.387274</td>\n",
       "      <td>41.959276</td>\n",
       "      <td>9.146341</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>215.524224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.594733</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10</td>\n",
       "      <td>21.556213</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>wizardlm50k</td>\n",
       "      <td>10000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.775932</td>\n",
       "      <td>29.674795</td>\n",
       "      <td>9.959350</td>\n",
       "      <td>35.900621</td>\n",
       "      <td>221.600000</td>\n",
       "      <td>43.875</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>36.375000</td>\n",
       "      <td>39.640703</td>\n",
       "      <td>-49.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td>23.179199</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>stanford_alpaca50k</td>\n",
       "      <td>10000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.419178</td>\n",
       "      <td>35.946771</td>\n",
       "      <td>8.943089</td>\n",
       "      <td>27.515528</td>\n",
       "      <td>177.985093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.465542</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td>22.822478</td>\n",
       "      <td>60000</td>\n",
       "      <td>20000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>stanford_alpaca50k</td>\n",
       "      <td>60000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.656193</td>\n",
       "      <td>35.599459</td>\n",
       "      <td>9.146341</td>\n",
       "      <td>25.590062</td>\n",
       "      <td>164.834783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.767077</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td>21.452979</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>stanford_alpaca50k</td>\n",
       "      <td>30000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.765854</td>\n",
       "      <td>37.432546</td>\n",
       "      <td>9.552846</td>\n",
       "      <td>25.279503</td>\n",
       "      <td>161.469565</td>\n",
       "      <td>40.625</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>34.062500</td>\n",
       "      <td>34.593273</td>\n",
       "      <td>-43.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td>23.262604</td>\n",
       "      <td>60000</td>\n",
       "      <td>20000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>stanford_alpaca50k</td>\n",
       "      <td>60000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.526025</td>\n",
       "      <td>38.236144</td>\n",
       "      <td>9.146341</td>\n",
       "      <td>22.360248</td>\n",
       "      <td>143.154037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.010426</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>llama-7b_stanford_alpaca50k_ep=3</td>\n",
       "      <td>23.798014</td>\n",
       "      <td>150000</td>\n",
       "      <td>50000</td>\n",
       "      <td>sft_full</td>\n",
       "      <td>{0: 'sft_full'}</td>\n",
       "      <td>stanford_alpaca50k</td>\n",
       "      <td>None</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>6.502103</td>\n",
       "      <td>33.821772</td>\n",
       "      <td>9.756098</td>\n",
       "      <td>24.534161</td>\n",
       "      <td>127.362733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.618806</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td>21.359469</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>stanford_alpaca50k</td>\n",
       "      <td>30000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.924680</td>\n",
       "      <td>36.838938</td>\n",
       "      <td>8.536585</td>\n",
       "      <td>22.360248</td>\n",
       "      <td>121.284472</td>\n",
       "      <td>39.500</td>\n",
       "      <td>26.625000</td>\n",
       "      <td>33.062500</td>\n",
       "      <td>31.222294</td>\n",
       "      <td>-50.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td>23.666750</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>flan_v250k</td>\n",
       "      <td>30000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.918577</td>\n",
       "      <td>42.230975</td>\n",
       "      <td>10.569106</td>\n",
       "      <td>7.826087</td>\n",
       "      <td>140.740373</td>\n",
       "      <td>24.625</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>21.312500</td>\n",
       "      <td>30.665768</td>\n",
       "      <td>-40.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td>25.165851</td>\n",
       "      <td>60000</td>\n",
       "      <td>20000</td>\n",
       "      <td>vmf+grad_gamma=1</td>\n",
       "      <td>{0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}</td>\n",
       "      <td>flan_v250k</td>\n",
       "      <td>60000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.891699</td>\n",
       "      <td>40.396945</td>\n",
       "      <td>8.739837</td>\n",
       "      <td>5.279503</td>\n",
       "      <td>122.274534</td>\n",
       "      <td>24.000</td>\n",
       "      <td>18.354430</td>\n",
       "      <td>21.194969</td>\n",
       "      <td>29.682360</td>\n",
       "      <td>-38.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td>26.938923</td>\n",
       "      <td>60000</td>\n",
       "      <td>20000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>flan_v250k</td>\n",
       "      <td>60000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.973332</td>\n",
       "      <td>40.191982</td>\n",
       "      <td>9.349593</td>\n",
       "      <td>4.782609</td>\n",
       "      <td>107.213665</td>\n",
       "      <td>22.125</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.562500</td>\n",
       "      <td>29.315825</td>\n",
       "      <td>-35.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=10000:ep=10</td>\n",
       "      <td>18.066149</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>stanford_alpaca50k</td>\n",
       "      <td>10000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>7.579665</td>\n",
       "      <td>34.176513</td>\n",
       "      <td>9.349593</td>\n",
       "      <td>22.732919</td>\n",
       "      <td>114.880745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.802990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>llama-7b_dolly_score=random:s=0_pace=prune:size=10000:ep=10</td>\n",
       "      <td>20.801764</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>dolly</td>\n",
       "      <td>10000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.047657</td>\n",
       "      <td>40.987191</td>\n",
       "      <td>7.926829</td>\n",
       "      <td>15.527950</td>\n",
       "      <td>101.516770</td>\n",
       "      <td>33.250</td>\n",
       "      <td>17.721519</td>\n",
       "      <td>25.534591</td>\n",
       "      <td>27.728430</td>\n",
       "      <td>-53.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>llama-7b_flan_v250k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td>25.450247</td>\n",
       "      <td>30000</td>\n",
       "      <td>10000</td>\n",
       "      <td>random</td>\n",
       "      <td>{0: 'random', 's': 0}</td>\n",
       "      <td>flan_v250k</td>\n",
       "      <td>30000</td>\n",
       "      <td>results/baselines/huggyllama/llama-7b</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>8.141089</td>\n",
       "      <td>38.614081</td>\n",
       "      <td>9.146341</td>\n",
       "      <td>5.093168</td>\n",
       "      <td>85.898137</td>\n",
       "      <td>23.500</td>\n",
       "      <td>18.375000</td>\n",
       "      <td>20.937500</td>\n",
       "      <td>27.050765</td>\n",
       "      <td>-37.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      run_name  \\\n",
       "1           llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3   \n",
       "2           llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3   \n",
       "4           llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3   \n",
       "5                                                             llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=90000:ep=3   \n",
       "7                                                                                                    llama-7b_sharegpt50k_ep=3   \n",
       "8                llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3   \n",
       "9                                                                  llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3   \n",
       "11                                                            llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3   \n",
       "12                                                            llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3   \n",
       "14                                                           llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=10000:ep=10   \n",
       "16          llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3   \n",
       "22          llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3   \n",
       "25         llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10   \n",
       "27                                                           llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3   \n",
       "28                                                            llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3   \n",
       "29         llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=90000:ep=3   \n",
       "30         llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3   \n",
       "31                                                            llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3   \n",
       "34                                                           llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=60000:ep=3   \n",
       "35                                                                 llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3   \n",
       "36                                                           llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=90000:ep=3   \n",
       "37                                                                                                  llama-7b_ultrachat50k_ep=3   \n",
       "39         llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3   \n",
       "40                                                          llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=10000:ep=10   \n",
       "43               llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10   \n",
       "44        llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10   \n",
       "47                                                                  llama-7b_dolly_score=random:s=0_pace=prune:size=30000:ep=3   \n",
       "48                llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3   \n",
       "49         llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10   \n",
       "51                                                                                                         llama-7b_dolly_ep=3   \n",
       "53                                                           llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10   \n",
       "54  llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10   \n",
       "55   llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3   \n",
       "56   llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3   \n",
       "59                                                     llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=60000:ep=3   \n",
       "64                                                                                            llama-7b_stanford_alpaca50k_ep=3   \n",
       "65                                                     llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3   \n",
       "68           llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3   \n",
       "70           llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3   \n",
       "71                                                             llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3   \n",
       "72                                                    llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=10000:ep=10   \n",
       "73                                                                 llama-7b_dolly_score=random:s=0_pace=prune:size=10000:ep=10   \n",
       "74                                                             llama-7b_flan_v250k_score=random:s=0_pace=prune:size=30000:ep=3   \n",
       "\n",
       "      nonchat  compute  subset_size      sort_by_type  \\\n",
       "1   24.353010    30000        10000  vmf+grad_gamma=1   \n",
       "2   25.513615    60000        20000  vmf+grad_gamma=1   \n",
       "4   25.988269    90000        30000  vmf+grad_gamma=1   \n",
       "5   25.855976    90000        30000            random   \n",
       "7   25.659797   150000        50000          sft_full   \n",
       "8   23.449338    60000        20000  vmf+grad_gamma=1   \n",
       "9   23.033590    30000        10000            random   \n",
       "11  23.941923    30000        10000            random   \n",
       "12  25.078363    60000        20000            random   \n",
       "14  22.901829    10000         1000            random   \n",
       "16  24.396701    30000        10000  vmf+grad_gamma=1   \n",
       "22  24.625021    60000        20000  vmf+grad_gamma=1   \n",
       "25  23.073099    10000         1000  vmf+grad_gamma=1   \n",
       "27  23.622440    30000        10000            random   \n",
       "28  22.556978    30000        10000            random   \n",
       "29  23.696420    90000        30000  vmf+grad_gamma=1   \n",
       "30  23.958953    60000        20000  vmf+grad_gamma=1   \n",
       "31  23.991207    60000        20000            random   \n",
       "34  23.900686    60000        20000            random   \n",
       "35  23.855818    60000        20000            random   \n",
       "36  24.378619    90000        30000            random   \n",
       "37  23.684465   150000        50000          sft_full   \n",
       "39  23.989855    30000        10000  vmf+grad_gamma=1   \n",
       "40  23.592516    10000         1000            random   \n",
       "43  22.361916    10000         1000  vmf+grad_gamma=1   \n",
       "44  21.932524    10000         1000  vmf+grad_gamma=1   \n",
       "47  22.686205    30000        10000            random   \n",
       "48  23.999724    30000        10000  vmf+grad_gamma=1   \n",
       "49  22.621001    10000         1000  vmf+grad_gamma=1   \n",
       "51  23.769367    44868        14956          sft_full   \n",
       "53  21.556213    10000         1000            random   \n",
       "54  23.179199    10000         1000  vmf+grad_gamma=1   \n",
       "55  22.822478    60000        20000  vmf+grad_gamma=1   \n",
       "56  21.452979    30000        10000  vmf+grad_gamma=1   \n",
       "59  23.262604    60000        20000            random   \n",
       "64  23.798014   150000        50000          sft_full   \n",
       "65  21.359469    30000        10000            random   \n",
       "68  23.666750    30000        10000  vmf+grad_gamma=1   \n",
       "70  25.165851    60000        20000  vmf+grad_gamma=1   \n",
       "71  26.938923    60000        20000            random   \n",
       "72  18.066149    10000         1000            random   \n",
       "73  20.801764    10000         1000            random   \n",
       "74  25.450247    30000        10000            random   \n",
       "\n",
       "                                                                                      sort_by  \\\n",
       "1   {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "2   {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "4   {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "5                                                                       {0: 'random', 's': 0}   \n",
       "7                                                                             {0: 'sft_full'}   \n",
       "8   {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "9                                                                       {0: 'random', 's': 0}   \n",
       "11                                                                      {0: 'random', 's': 0}   \n",
       "12                                                                      {0: 'random', 's': 0}   \n",
       "14                                                                      {0: 'random', 's': 0}   \n",
       "16  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "22  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "25  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "27                                                                      {0: 'random', 's': 0}   \n",
       "28                                                                      {0: 'random', 's': 0}   \n",
       "29  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "30  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "31                                                                      {0: 'random', 's': 0}   \n",
       "34                                                                      {0: 'random', 's': 0}   \n",
       "35                                                                      {0: 'random', 's': 0}   \n",
       "36                                                                      {0: 'random', 's': 0}   \n",
       "37                                                                            {0: 'sft_full'}   \n",
       "39  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "40                                                                      {0: 'random', 's': 0}   \n",
       "43  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "44  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "47                                                                      {0: 'random', 's': 0}   \n",
       "48  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "49  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "51                                                                            {0: 'sft_full'}   \n",
       "53                                                                      {0: 'random', 's': 0}   \n",
       "54  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "55  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "56  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "59                                                                      {0: 'random', 's': 0}   \n",
       "64                                                                            {0: 'sft_full'}   \n",
       "65                                                                      {0: 'random', 's': 0}   \n",
       "68  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "70  {0: 'dppmap', 'k': 'vmf', 'gamma': 1, 'kmd': 'llama7br512p4096', 'kemb': 'grad+rp+loraB'}   \n",
       "71                                                                      {0: 'random', 's': 0}   \n",
       "72                                                                      {0: 'random', 's': 0}   \n",
       "73                                                                      {0: 'random', 's': 0}   \n",
       "74                                                                      {0: 'random', 's': 0}   \n",
       "\n",
       "               dataset total_train_samples  \\\n",
       "1          sharegpt50k               30000   \n",
       "2          sharegpt50k               60000   \n",
       "4          sharegpt50k               90000   \n",
       "5          sharegpt50k               90000   \n",
       "7          sharegpt50k                None   \n",
       "8               oasst2               60000   \n",
       "9               oasst2               30000   \n",
       "11         sharegpt50k               30000   \n",
       "12         sharegpt50k               60000   \n",
       "14         sharegpt50k               10000   \n",
       "16         wizardlm50k               30000   \n",
       "22         wizardlm50k               60000   \n",
       "25         sharegpt50k               10000   \n",
       "27        ultrachat50k               30000   \n",
       "28         wizardlm50k               30000   \n",
       "29        ultrachat50k               90000   \n",
       "30        ultrachat50k               60000   \n",
       "31         wizardlm50k               60000   \n",
       "34        ultrachat50k               60000   \n",
       "35              oasst2               60000   \n",
       "36        ultrachat50k               90000   \n",
       "37        ultrachat50k                None   \n",
       "39        ultrachat50k               30000   \n",
       "40        ultrachat50k               10000   \n",
       "43               dolly               10000   \n",
       "44        ultrachat50k               10000   \n",
       "47               dolly               30000   \n",
       "48               dolly               30000   \n",
       "49         wizardlm50k               10000   \n",
       "51               dolly                None   \n",
       "53         wizardlm50k               10000   \n",
       "54  stanford_alpaca50k               10000   \n",
       "55  stanford_alpaca50k               60000   \n",
       "56  stanford_alpaca50k               30000   \n",
       "59  stanford_alpaca50k               60000   \n",
       "64  stanford_alpaca50k                None   \n",
       "65  stanford_alpaca50k               30000   \n",
       "68          flan_v250k               30000   \n",
       "70          flan_v250k               60000   \n",
       "71          flan_v250k               60000   \n",
       "72  stanford_alpaca50k               10000   \n",
       "73               dolly               10000   \n",
       "74          flan_v250k               30000   \n",
       "\n",
       "                       model_name_or_path subsample_mixture  ... TydiQA/CB  \\\n",
       "1   results/baselines/huggyllama/llama-7b              None  ...  8.682985   \n",
       "2   results/baselines/huggyllama/llama-7b              None  ...  7.787952   \n",
       "4   results/baselines/huggyllama/llama-7b              None  ...  8.114699   \n",
       "5   results/baselines/huggyllama/llama-7b              None  ...  7.934978   \n",
       "7   results/baselines/huggyllama/llama-7b              None  ...  7.404910   \n",
       "8   results/baselines/huggyllama/llama-7b              None  ...  8.482175   \n",
       "9   results/baselines/huggyllama/llama-7b              None  ...  8.012248   \n",
       "11  results/baselines/huggyllama/llama-7b              None  ...  8.883713   \n",
       "12  results/baselines/huggyllama/llama-7b              None  ...  8.229089   \n",
       "14  results/baselines/huggyllama/llama-7b              None  ...  7.282947   \n",
       "16  results/baselines/huggyllama/llama-7b              None  ...  8.440357   \n",
       "22  results/baselines/huggyllama/llama-7b              None  ...  8.084618   \n",
       "25  results/baselines/huggyllama/llama-7b              None  ...  8.854762   \n",
       "27  results/baselines/huggyllama/llama-7b              None  ...  8.258062   \n",
       "28  results/baselines/huggyllama/llama-7b              None  ...  7.767049   \n",
       "29  results/baselines/huggyllama/llama-7b              None  ...  7.694827   \n",
       "30  results/baselines/huggyllama/llama-7b              None  ...  7.539529   \n",
       "31  results/baselines/huggyllama/llama-7b              None  ...  8.101167   \n",
       "34  results/baselines/huggyllama/llama-7b              None  ...  7.872376   \n",
       "35  results/baselines/huggyllama/llama-7b              None  ...  7.597158   \n",
       "36  results/baselines/huggyllama/llama-7b              None  ...  7.840521   \n",
       "37  results/baselines/huggyllama/llama-7b              None  ...  7.912641   \n",
       "39  results/baselines/huggyllama/llama-7b              None  ...  8.746092   \n",
       "40  results/baselines/huggyllama/llama-7b              None  ...  7.836692   \n",
       "43  results/baselines/huggyllama/llama-7b              None  ...  6.427229   \n",
       "44  results/baselines/huggyllama/llama-7b              None  ...  7.136182   \n",
       "47  results/baselines/huggyllama/llama-7b              None  ...  8.599339   \n",
       "48  results/baselines/huggyllama/llama-7b              None  ...  7.549075   \n",
       "49  results/baselines/huggyllama/llama-7b              None  ...  7.008973   \n",
       "51  results/baselines/huggyllama/llama-7b              None  ...  8.387274   \n",
       "53  results/baselines/huggyllama/llama-7b              None  ...  7.775932   \n",
       "54  results/baselines/huggyllama/llama-7b              None  ...  8.419178   \n",
       "55  results/baselines/huggyllama/llama-7b              None  ...  7.656193   \n",
       "56  results/baselines/huggyllama/llama-7b              None  ...  7.765854   \n",
       "59  results/baselines/huggyllama/llama-7b              None  ...  7.526025   \n",
       "64  results/baselines/huggyllama/llama-7b              None  ...  6.502103   \n",
       "65  results/baselines/huggyllama/llama-7b              None  ...  7.924680   \n",
       "68  results/baselines/huggyllama/llama-7b              None  ...  8.918577   \n",
       "70  results/baselines/huggyllama/llama-7b              None  ...  7.891699   \n",
       "71  results/baselines/huggyllama/llama-7b              None  ...  7.973332   \n",
       "72  results/baselines/huggyllama/llama-7b              None  ...  7.579665   \n",
       "73  results/baselines/huggyllama/llama-7b              None  ...  8.047657   \n",
       "74  results/baselines/huggyllama/llama-7b              None  ...  8.141089   \n",
       "\n",
       "    TydiQA/GP  Codex-Eval/Pass@1  AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*  \\\n",
       "1   33.608573          11.382114                                  48.944099   \n",
       "2   34.435272          11.382114                                  54.596273   \n",
       "4   33.072397          13.211382                                  56.770186   \n",
       "5   32.476766          12.601626                                  53.105590   \n",
       "7   33.076438          10.772358                                  55.962733   \n",
       "8   33.053241           9.756098                                  38.447205   \n",
       "9   29.147260           7.926829                                  40.062112   \n",
       "11  32.838123          14.024390                                  52.360248   \n",
       "12  32.741452          12.398374                                  50.372671   \n",
       "14  28.273825          12.195122                                  50.993789   \n",
       "16  31.304623          13.008130                                  46.894410   \n",
       "22  32.355604          13.211382                                  47.701863   \n",
       "25  32.053478           8.739837                                  42.236025   \n",
       "27  31.851278          11.585366                                  47.826087   \n",
       "28  31.174715          13.211382                                  44.844720   \n",
       "29  32.354570           9.349593                                  50.993789   \n",
       "30  29.951814          10.772358                                  50.745342   \n",
       "31  30.696673          12.398374                                  46.211180   \n",
       "34  30.390822          11.178862                                  48.881988   \n",
       "35  28.892248          13.008130                                  40.621118   \n",
       "36  32.605795          10.162602                                  51.055901   \n",
       "37  32.465762          10.365854                                  52.546584   \n",
       "39  32.050918          12.601626                                  48.819876   \n",
       "40  31.200762           9.959350                                  45.279503   \n",
       "43  35.375491          10.365854                                  22.484472   \n",
       "44  27.619956           6.300813                                  41.801242   \n",
       "47  42.061917          11.585366                                  12.049689   \n",
       "48  37.688146          10.365854                                  17.639752   \n",
       "49  28.272535           6.300813                                  36.335404   \n",
       "51  41.959276           9.146341                                  14.285714   \n",
       "53  29.674795           9.959350                                  35.900621   \n",
       "54  35.946771           8.943089                                  27.515528   \n",
       "55  35.599459           9.146341                                  25.590062   \n",
       "56  37.432546           9.552846                                  25.279503   \n",
       "59  38.236144           9.146341                                  22.360248   \n",
       "64  33.821772           9.756098                                  24.534161   \n",
       "65  36.838938           8.536585                                  22.360248   \n",
       "68  42.230975          10.569106                                   7.826087   \n",
       "70  40.396945           8.739837                                   5.279503   \n",
       "71  40.191982           9.349593                                   4.782609   \n",
       "72  34.176513           9.349593                                  22.732919   \n",
       "73  40.987191           7.926829                                  15.527950   \n",
       "74  38.614081           9.146341                                   5.093168   \n",
       "\n",
       "    AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/Len  \\\n",
       "1                                  346.985093   \n",
       "2                                  326.693168   \n",
       "4                                  284.870807   \n",
       "5                                  286.649689   \n",
       "7                                  280.284472   \n",
       "8                                  356.831056   \n",
       "9                                  363.681988   \n",
       "11                                 311.680745   \n",
       "12                                 288.319255   \n",
       "14                                 314.621118   \n",
       "16                                 280.853416   \n",
       "22                                 268.175155   \n",
       "25                                 288.613665   \n",
       "27                                 264.288199   \n",
       "28                                 283.506832   \n",
       "29                                 251.132919   \n",
       "30                                 251.397516   \n",
       "31                                 252.111801   \n",
       "34                                 247.469565   \n",
       "35                                 277.067081   \n",
       "36                                 235.505590   \n",
       "37                                 235.997516   \n",
       "39                                 255.604969   \n",
       "40                                 239.781366   \n",
       "43                                 297.956522   \n",
       "44                                 232.539130   \n",
       "47                                 277.636025   \n",
       "48                                 263.125466   \n",
       "49                                 244.347826   \n",
       "51                                 215.524224   \n",
       "53                                 221.600000   \n",
       "54                                 177.985093   \n",
       "55                                 164.834783   \n",
       "56                                 161.469565   \n",
       "59                                 143.154037   \n",
       "64                                 127.362733   \n",
       "65                                 121.284472   \n",
       "68                                 140.740373   \n",
       "70                                 122.274534   \n",
       "71                                 107.213665   \n",
       "72                                 114.880745   \n",
       "73                                 101.516770   \n",
       "74                                  85.898137   \n",
       "\n",
       "    MTBench(gpt:4:1106:preview)/Turn-1  MTBench(gpt:4:1106:preview)/Turn-2  \\\n",
       "1                               53.125                           40.506329   \n",
       "2                               51.750                           38.750000   \n",
       "4                                  NaN                                 NaN   \n",
       "5                                  NaN                                 NaN   \n",
       "7                                  NaN                                 NaN   \n",
       "8                               41.625                           27.341772   \n",
       "9                               39.500                           27.625000   \n",
       "11                              45.875                           35.375000   \n",
       "12                              49.625                           36.625000   \n",
       "14                              46.375                           34.000000   \n",
       "16                              49.250                           32.784810   \n",
       "22                              46.625                           35.384615   \n",
       "25                              46.000                           31.772152   \n",
       "27                              50.625                           36.708861   \n",
       "28                              46.750                           34.750000   \n",
       "29                                 NaN                                 NaN   \n",
       "30                                 NaN                                 NaN   \n",
       "31                                 NaN                                 NaN   \n",
       "34                              50.375                           37.468354   \n",
       "35                              43.250                           31.625000   \n",
       "36                                 NaN                                 NaN   \n",
       "37                                 NaN                                 NaN   \n",
       "39                              44.125                           32.278481   \n",
       "40                                 NaN                                 NaN   \n",
       "43                              33.625                           18.076923   \n",
       "44                                 NaN                                 NaN   \n",
       "47                              35.750                           19.746835   \n",
       "48                              38.500                           19.487179   \n",
       "49                              44.250                           25.866667   \n",
       "51                                 NaN                                 NaN   \n",
       "53                              43.875                           28.875000   \n",
       "54                                 NaN                                 NaN   \n",
       "55                                 NaN                                 NaN   \n",
       "56                              40.625                           27.500000   \n",
       "59                                 NaN                                 NaN   \n",
       "64                                 NaN                                 NaN   \n",
       "65                              39.500                           26.625000   \n",
       "68                              24.625                           18.000000   \n",
       "70                              24.000                           18.354430   \n",
       "71                              22.125                           19.000000   \n",
       "72                                 NaN                                 NaN   \n",
       "73                              33.250                           17.721519   \n",
       "74                              23.500                           18.375000   \n",
       "\n",
       "    MTBench(gpt:4:1106:preview)/Rating    Average    ranking  \n",
       "1                            46.855346  53.512749 -19.933333  \n",
       "2                            45.250000  52.704141 -15.233333  \n",
       "4                                  NaN  51.340543        NaN  \n",
       "5                                  NaN  51.014441        NaN  \n",
       "7                                  NaN  50.577012        NaN  \n",
       "8                            34.528302  50.318151 -33.433333  \n",
       "9                            33.562500  50.201874 -36.300000  \n",
       "11                           40.625000  49.659378 -23.233333  \n",
       "12                           43.125000  48.899001 -21.466667  \n",
       "14                           40.187500  48.717642 -33.066667  \n",
       "16                           41.069182  47.240979 -26.500000  \n",
       "22                           41.075949  46.555568 -24.400000  \n",
       "25                           38.930818  46.426614 -32.300000  \n",
       "27                           43.710692  46.330376 -30.233333  \n",
       "28                           40.750000  46.245869 -33.700000  \n",
       "29                                 NaN  46.186458        NaN  \n",
       "30                                 NaN  46.122443        NaN  \n",
       "31                                 NaN  45.914479        NaN  \n",
       "34                           43.962264  45.266084 -32.100000  \n",
       "35                           37.437500  45.248631 -35.533333  \n",
       "36                                 NaN  45.241649        NaN  \n",
       "37                                 NaN  44.973978        NaN  \n",
       "39                           38.238994  44.842380 -30.866667  \n",
       "40                                 NaN  44.476903        NaN  \n",
       "43                           25.949367  42.602030 -48.400000  \n",
       "44                                 NaN  42.056744        NaN  \n",
       "47                           27.798742  41.603285 -41.966667  \n",
       "48                           29.113924  41.507258 -37.633333  \n",
       "49                           35.354839  41.413089 -47.400000  \n",
       "51                                 NaN  40.594733        NaN  \n",
       "53                           36.375000  39.640703 -49.666667  \n",
       "54                                 NaN  37.465542        NaN  \n",
       "55                                 NaN  35.767077        NaN  \n",
       "56                           34.062500  34.593273 -43.700000  \n",
       "59                                 NaN  34.010426        NaN  \n",
       "64                                 NaN  32.618806        NaN  \n",
       "65                           33.062500  31.222294 -50.033333  \n",
       "68                           21.312500  30.665768 -40.933333  \n",
       "70                           21.194969  29.682360 -38.566667  \n",
       "71                           20.562500  29.315825 -35.100000  \n",
       "72                                 NaN  27.802990        NaN  \n",
       "73                           25.534591  27.728430 -53.133333  \n",
       "74                           20.937500  27.050765 -37.200000  \n",
       "\n",
       "[43 rows x 27 columns]"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "662539cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_task_name_display(task_name):\n",
    "    if task_name == 'AlpacaFarm(alpaca:eval:gpt4:turbo:fn)/WR*': return 'AlpacaFarm\\n(Win Rate)'\n",
    "    elif task_name == 'nonchat': return 'Benchmark\\n(Average Score)'\n",
    "    else: raise ValueError(f'{task_name} not defined display name')\n",
    "        \n",
    "def get_dataset_display(dataset):\n",
    "    if 'dolly' in dataset: return 'Dolly'\n",
    "    elif 'stanford_alpaca' in dataset: return 'Alpaca'\n",
    "    elif 'ultrachat' in dataset: return 'UltraChat'\n",
    "    elif 'sharegpt' in dataset: return 'ShareGPT'\n",
    "    else: raise ValueError(f'{dataset} not defined display name')\n",
    "\n",
    "\n",
    "data_to_compute_dict = dfc.set_index(['subset_size']).to_dict()['compute']\n",
    "data_to_compute_pct = lambda x: data_to_compute_dict[x]/max(data_to_compute_dict.values())*100\n",
    "\n",
    "\n",
    "plt_base_model = True\n",
    "plt_full_finetune = True\n",
    "xaxis_type = 'data' # 'compute'\n",
    "yaxis_type = 'abs'\n",
    "yaxis_type = 'delta_fullfinetune'; \n",
    "assert(yaxis_type in ['abs', 'delta_fullfinetune'])\n",
    "\n",
    "datasets = ['dolly', 'stanford_alpaca50k', 'ultrachat50k', 'sharegpt50k']\n",
    "# datasets = ['flan_v250k', 'dolly', 'stanford_alpaca50k', 'oasst2', 'ultrachat50k', 'wizardlm50k', 'sharegpt50k']\n",
    "# datasets = list(np.unique(dfc['dataset']))\n",
    "\n",
    "task_names = []\n",
    "task_names += ['nonchat']\n",
    "# task_names += ['nonchat', 'MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR*',]\n",
    "# task_names += ['MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1',]\n",
    "# task_names += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "# task_names += [f'MTBench({mtbench_judge})/Rating']\n",
    "# task_names += [f'MTBench({mtbench_judge})/Turn-1']\n",
    "task_names += [f'AlpacaFarm({alpacafarm_judge})/WR*']\n",
    "# task_names += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "\n",
    "\n",
    "\n",
    "w = 2; h = 2\n",
    "ncols = len(datasets)\n",
    "nrows = len(task_names)\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(w*ncols+3, h*nrows), sharey='row', sharex='col')\n",
    "\n",
    "xticks_data = defaultdict(list)\n",
    "\n",
    "for axi, task_name in enumerate(task_names):\n",
    "    d = D[task_name]\n",
    "    for axj, dataset in enumerate(datasets):\n",
    "        ax = axs.reshape(nrows, ncols)[axi, axj]\n",
    "        dataset_size = get_dataset_size(dataset)\n",
    "\n",
    "        if plt_base_model and axi == 0:\n",
    "            k = DKey(full_sft_short, dataset, N)\n",
    "            if k in d:\n",
    "                y_fullfinetune = d[k]\n",
    "                y_base = base_model_perf[task_name]\n",
    "                y = y_base-y_fullfinetune if yaxis_type == 'delta_fullfinetune' else y_base\n",
    "                ax.axhline(y=y, linestyle='--', color='#FFE0B2', label='base')\n",
    "        if plt_full_finetune:\n",
    "            k = DKey(full_sft_short, dataset, dataset_size)\n",
    "            if k in d:\n",
    "                y = 0 if yaxis_type == 'delta_fullfinetune' else d[k]\n",
    "                ax.axhline(y=y, linestyle='--', color='#FFA500', label=full_sft_short)\n",
    "\n",
    "        sort_by_types = sorted(set(x.sort_by_type for x in d.keys())) # -set(['sft_ep=2'])\n",
    "        for i, sort_by_type in enumerate(sort_by_types):\n",
    "            xs = sorted([x.subset_size for x in d.keys()\n",
    "                         if x.dataset == dataset and x.sort_by_type==sort_by_type])\n",
    "            xticks_data[dataset] += list(set(xs) - set(xticks_data[dataset]))\n",
    "\n",
    "            ys = [d[DKey(sort_by_type, dataset, x)] for x in xs]\n",
    "            if yaxis_type == 'delta_random':\n",
    "                if not all(DKey('random', dataset, x) in d for x in xs): continue\n",
    "                ys = [y-d[DKey('random', dataset, x)] for x, y in zip(xs, ys)] \n",
    "            elif yaxis_type == 'delta_fullfinetune':\n",
    "                if DKey(full_sft_short, dataset, dataset_size) not in d: continue\n",
    "                ys = [y-d[DKey(full_sft_short, dataset, dataset_size)] for y in ys]\n",
    "            kwargs = {}\n",
    "            if 'random' in sort_by_type:\n",
    "                kwargs['color'] = 'gray'\n",
    "            elif full_sft_short in sort_by_type:\n",
    "                kwargs['color'] = '#FFA500'\n",
    "            if full_sft_short not in sort_by_type:\n",
    "                kwargs['label'] = sort_by_type\n",
    "            xs = xs if xaxis_type == 'data' else [data_to_compute_pct(x) for x in xs]\n",
    "            ax.plot(xs, ys, 'o-', **kwargs)\n",
    "#             ax.set_xticks(xs, [f'{x*100:.0f}%' for x in np.array(xs)/dataset_size], fontsize=13, rotation=45)\n",
    "            ax.grid(visible=True, axis='both')\n",
    "\n",
    "#             print(task_name, dataset, xs, [f'{x*100:.0f}%' for x in np.array(xs)/dataset_size], dataset_size)\n",
    "\n",
    "\n",
    "for axi, task_name in enumerate(task_names):\n",
    "#     task_name_shortened = task_name.replace(f'({mtbench_judge})', '').replace(f'({alpacafarm_judge})', '')\n",
    "    task_name_shortened = get_task_name_display(task_name)\n",
    "    axs.reshape(nrows, ncols)[axi, 0].set_ylabel('△ '+task_name_shortened if yaxis_type.startswith('delta') else task_name_shortened, fontsize=13)\n",
    "    axs.reshape(nrows, ncols)[axi, -1].legend(loc='center left', bbox_to_anchor=(1.1, 0.5))\n",
    "\n",
    "\n",
    "for axj, dataset in enumerate(datasets):\n",
    "    dataset_size = get_dataset_size(dataset)\n",
    "    xticks = np.array(sorted(xticks_data[dataset]))\n",
    "    ax = axs.reshape(nrows, ncols)[nrows-1, axj]\n",
    "    c = .1; ax.set_xlim((-N*c, N+c*N))\n",
    "    if dataset_size != N:\n",
    "        ax.set_xticks(list(xticks), [f'{x*100:.0f}%' for x in xticks/get_dataset_size(dataset)], fontsize=13, rotation=45)\n",
    "    else:\n",
    "        ax.set_xticks(xticks, [f'{x*100:.0f}%' for x in xticks/get_dataset_size(dataset)], fontsize=13, rotation=45)\n",
    "\n",
    "    ax = axs.reshape(nrows, ncols)[0, axj]\n",
    "    ax.set_title(get_dataset_display(dataset), fontsize=18)\n",
    "\n",
    "    if 'nonchat' in task_names and yaxis_type != 'abs':\n",
    "        axi = task_names.index('nonchat')\n",
    "        axs.reshape(nrows, ncols)[axi, axj].set_ylim((-4, 1))\n",
    "\n",
    "axs.reshape(nrows, ncols)[nrows-1, ncols-1].annotate('Data', xy=(1.2, -.15), xycoords=\"axes fraction\", ha='left', va='center', fontsize=15)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "save_path = os.path.join(assets_dir, 'fig_vmf_grad_vs_random_cross_datasets.pdf')\n",
    "fig.savefig(save_path, bbox_inches='tight', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "id": "72726540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "39874bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dolly [ 1000 10000 14956] ['7%', '67%', '100%']\n",
      "stanford_alpaca50k [ 1000 10000 20000 50000] ['2%', '20%', '40%', '100%']\n",
      "ultrachat50k [ 1000 10000 20000 30000 50000] ['2%', '20%', '40%', '60%', '100%']\n",
      "sharegpt50k [ 1000 10000 20000 30000 50000] ['2%', '20%', '40%', '60%', '100%']\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    xticks = np.array(sorted(xticks_data[dataset]))\n",
    "    print(dataset, xticks, [f'{x*100:.0f}%' for x in xticks/get_dataset_size(dataset)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "97ac259e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20%', '60%']"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{x*100:.0f}%' for x in np.array(xs)/dataset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca750966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
