{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da1794b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/__init__.py:25: UserWarning: Install `torch` for functionalities dependent on torch\n",
      "  warn(f'Install `torch` for functionalities dependent on torch')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'ppc64le', 'cluster': 'dcs'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "import re\n",
    "from llm.submit import (\n",
    "    multiline_to_singleline,\n",
    "    submit_job_ccc,\n",
    "    submit_job_aimos,\n",
    "    submit_job,\n",
    "        get_run_statistics)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import datetime\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import base64\n",
    "string_to_alphanumeric = lambda s: base64.urlsafe_b64encode(s.encode('utf-8')).decode('utf-8')\n",
    "alphanumeric_to_string = lambda a: base64.urlsafe_b64decode(a).decode('utf-8')\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm, shell_scripts_template_lsf, get_host_info, move_lsf_job_summary_to_save_dir\n",
    "from note_pruning_analysis import open_instruct_dir\n",
    "\n",
    "info = get_host_info()\n",
    "arch, cluster = info['arch'], info['cluster']\n",
    "print(info)\n",
    "\n",
    "os.environ['TORCHELASTIC_ERROR_FILE'] = os.path.join(os.getcwd(), 'torchelastic_error_file') \n",
    "\n",
    "## jobs submitted in notebook inherits env variables.\n",
    "cache_dir = '../../../../mitibm2023/cache'\n",
    "os.environ['WANDB_DIR'] = cache_dir\n",
    "os.makedirs(os.environ['WANDB_DIR'], exist_ok=True)\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_PROJECT'] = 'mitibm'\n",
    "##\n",
    "##\n",
    "\n",
    "shell_scripts_template = shell_scripts_template_slurm \\\n",
    "    if arch == 'ppc64le' else shell_scripts_template_lsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c421d1",
   "metadata": {},
   "source": [
    "# DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c09b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/oi2/llama-7b_sharegptv2_ep=2 using 6 GPUs, 1 batch size per GPU, 1 gradient accumulation steps, 30 effective batch size.\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp7pssto1b', 'job_id': 1354503}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2p8zx1bt', 'job_id': 1354504}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2_mpillk', 'job_id': 1354505}]\n"
     ]
    }
   ],
   "source": [
    "from llm.submit import shell_scripts_template_slurm\n",
    "debug = False\n",
    "if debug:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'INFO'\n",
    "    os.environ['NCCL_DEBUG'] = 'INFO'\n",
    "else:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'WARNING'\n",
    "    os.environ['NCCL_DEBUG'] = ''\n",
    "num_cpus = 144 if arch == 'ppc64le' else 32\n",
    "cpu_mem =  650 if arch == 'ppc64le' else 64\n",
    "\n",
    "preprocessing_num_workers = 32\n",
    "report_to = 'wandb'\n",
    "mixed_precision = 'bf16' if arch == 'x86_64' else 'fp16'\n",
    "torch_dtype = 'bfloat16' if arch=='x86_64' else 'float32'\n",
    "gradient_checkpointing = True\n",
    "use_fast_tokenizer = True\n",
    "hf_models_dir = 'results/baselines/'\n",
    "resume_from_checkpoint = True # resume from latest checkpoint if exists, otherwise train from scratch\n",
    "num_train_epochs = 2\n",
    "checkpointing_steps = 300 # (50_000 / 32) * 2 / 6 ~= 500 (data size of 50k, bsz=32, ep=2, total save 6 times at most)\n",
    "max_train_steps = None\n",
    "subsample_inds_file_list = [None]\n",
    "dataloader_sampler = 'RandomSampler'\n",
    "overwrite_cache = True\n",
    "\n",
    "\n",
    "# #####\n",
    "# job_name = 'dpo1'\n",
    "\n",
    "# # model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-410m-deduped'; max_seq_length = 2048; abbr_model_name = 'pythia-410m'\n",
    "# # model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "\n",
    "# train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "\n",
    "\n",
    "# M = 60_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 20_000\n",
    "# M = 50_000; pacing_fn_list = [f'prune_size={M}_ep=5']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "    (10_000, 10),\n",
    "#     (30_000, 3),\n",
    "]]\n",
    "\n",
    "gen_output_md = 'llama7br512p4096'\n",
    "# gen_output_md = 'llama7b+sharegptv2ep2+r512p4096'\n",
    "# gen_output_model_name = 'all-mpnet-base-v2'\n",
    "\n",
    "scoring_fn_list = []\n",
    "scoring_fn_list += ['random_s=0']\n",
    "# scoring_fn_list += ['random_s=1']\n",
    "scoring_fn_list += [ \n",
    "    f'dppmap_k=vmf_gamma=1_kmd={gen_output_md}_kemb=grad+rp+loraB',\n",
    "    f'dppmap_k=rbf_gamma=1e-3_kmd={gen_output_md}_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1_kmd=mpnet_kemb=text+embedding',\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'dpo2_{dataset}:{abbr_model_name}'\n",
    "    \n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12\n",
    "# nodes = 2; num_gpus = 1; gpu_type = 'v100'; job_duration = 6; cpu_mem = 100; num_cpus = 32; max_train_steps = 5; checkpointing_steps = 2; report_to = 'tensorboard'\n",
    "\n",
    "    \n",
    "#####\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs = 1 # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "use_deepspeed = True\n",
    "deepspeed_config_file = 'ds_configs/stage3_no_offloading_accelerate.conf'\n",
    "\n",
    "per_device_train_batch_size = 1; total_batch_size = 32\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"{effective_batch_size} effective batch size.\")\n",
    "\n",
    "# reference: https://gist.github.com/pacman100/1cb1f17b2f1b3139a63b764263e70b25\n",
    "launcher = f\"\"\"accelerate launch \\\n",
    "    --mixed_precision {mixed_precision} \\\n",
    "    --num_machines {nodes} \\\n",
    "    --num_processes {num_gpus*nodes} \\\n",
    "    {'--use_deepspeed' if use_deepspeed else ''} \\\n",
    "    {'--deepspeed_config_file '+deepspeed_config_file if use_deepspeed else ''} \\\n",
    "    {'--main_process_ip $master_addr' if use_deepspeed else ''} \\\n",
    "    {'--main_process_port $master_port' if use_deepspeed else ''} \\\n",
    "    {'--machine_rank $SLURM_PROCID' if use_deepspeed else ''} \\\n",
    "    {'--rdzv_backend c10d' if use_deepspeed and nodes>1 else ''} \\\n",
    "    {'--deepspeed_multinode_launcher standard' if use_deepspeed and nodes>1 else ''} \\\n",
    "\"\"\"\n",
    "\n",
    "cmds = []\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    subsample_inds_file_list,\n",
    ")\n",
    "\n",
    "output_dirname_list = []\n",
    "for (subsample_inds_file,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{dataset}\"\n",
    "    if any(job_name == y for y in ['dpo1']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "\n",
    "    if subsample_inds_file:\n",
    "        assert(num_train_epochs==1)\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                s = f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "\n",
    "    if subsample_inds_file is not None:\n",
    "        assert(dataloader_sampler=='SequentialSampler')\n",
    "        assert(num_train_epochs==1)\n",
    "    else:\n",
    "        assert(dataloader_sampler=='RandomSampler')\n",
    "\n",
    "    output_dir = os.path.join('results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join('results', job_name), exist_ok=True)\n",
    "    wandb_run_name = output_dir.replace('results/', '')\n",
    "\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {f'cd .. && CUDA_VISIBLE_DEVICES={os.environ[\"CUDA_VISIBLE_DEVICES\"]} ' if test_run else ''}{launcher}\n",
    "        open_instruct/dpo_tune.py \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --tokenizer_name {model_name_or_path} \\\n",
    "        {'--use_slow_tokenizer' if not  use_fast_tokenizer else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        --train_file {train_file} \\\n",
    "        --max_seq_length {max_seq_length} \\\n",
    "        {'--subsample_inds_file '+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        --dataloader_sampler {dataloader_sampler} \\\n",
    "        --preprocessing_num_workers {preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size {per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
    "        --learning_rate 5e-7 \\\n",
    "        --lr_scheduler_type linear \\\n",
    "        --warmup_ratio 0.1 \\\n",
    "        --weight_decay 0. \\\n",
    "        --num_train_epochs {num_train_epochs} \\\n",
    "        --with_tracking \\\n",
    "        {'--report_to \"'+str(report_to)+'\"' if report_to else ''} \\\n",
    "        --checkpointing_steps {checkpointing_steps} \\\n",
    "        {'--max_train_steps '+str(max_train_steps) if max_train_steps else ''} \\\n",
    "        {'--resume_from_checkpoint' if resume_from_checkpoint else ''} \\\n",
    "        {'--low_cpu_mem_usage' if not use_deepspeed else ''} \\\n",
    "        {'--overwrite_cache' if overwrite_cache else ''} \\\n",
    "        --logging_steps 1 \\\n",
    "        --output_dir {output_dir}\n",
    "    \"\"\"\n",
    "    # if test_run:\n",
    "    #     print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    if test_run:\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64': # ccc\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b79b9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_dpo.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce604bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=5\n",
      "+ cd ..\n",
      "+ CUDA_VISIBLE_DEVICES=2,5\n",
      "+ accelerate launch --mixed_precision fp16 --num_machines 1 --num_processes 2 --use_deepspeed --deepspeed_config_file ds_configs/stage3_no_offloading_accelerate.conf open_instruct/dpo_tune.py --model_name_or_path results/baselines/huggyllama/llama-7b --tokenizer_name results/baselines/huggyllama/llama-7b --gradient_checkpointing --train_file data/processed/ultrafeedback/ultrafeedback_data.jsonl --max_seq_length 2048 --preprocessing_num_workers 32 --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --learning_rate 5e-7 --lr_scheduler_type linear --warmup_ratio 0.1 --weight_decay 0. --num_train_epochs 2 --with_tracking --report_to tensorboard --checkpointing_steps 500 --logging_steps 1 --output_dir results/dpo1/jpt_llama-7b_ultrafeedback\n",
      "[2024-01-08 20:41:08,547] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "[2024-01-08 20:41:17,396] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-08 20:41:17,400] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:662:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,611] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 1\n",
      "Local process index: 1\n",
      "Device: cuda:1\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 251.17it/s]\n",
      "01/08/2024 20:41:25 - WARNING - datasets.builder - Found cached dataset json (/gpfs/u/scratch/PTFM/PTFMqngp/huggingface_cache/datasets/json/default-201ebfceee303348/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 252.78it/s]\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:26,493] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 6.74B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.74s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:16<00:00,  8.11s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:43,556] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 13.48B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.60s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "01/08/2024 20:42:20 - INFO - accelerate.accelerator - Updating DeepSpeed's gradient accumulation steps to 16 from 1.\n",
      "[2024-01-08 20:42:20,382] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.1+23a11a39, git-hash=23a11a39, git-branch=master\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 1\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "[2024-01-08 20:42:20,751] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n",
      "[2024-01-08 20:42:20,779] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\n",
      "[2024-01-08 20:42:20,891] [INFO] [utils.py:786:see_memory_usage] Stage 3 initialize beginning\n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 14.16 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.9 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:118:__init__] Reduce bucket size 16777216\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:119:__init__] Prefetch bucket size 15099494\n",
      "[2024-01-08 20:42:20,995] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 13.64 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n",
      "[2024-01-08 20:42:21,139] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.76 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:21,240] [INFO] [utils.py:786:see_memory_usage] Before creating fp16 partitions\n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.4 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:23,090] [INFO] [utils.py:786:see_memory_usage] After creating fp16 partitions: 4\n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.4 GB         CA 14.6 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.99 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,190] [INFO] [utils.py:786:see_memory_usage] Before creating fp32 partitions\n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.39 GB         CA 14.6 GB         Max_CA 15 GB \n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.81 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,742] [INFO] [utils.py:786:see_memory_usage] After creating fp32 partitions\n",
      "[2024-01-08 20:42:23,743] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 26.61 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,744] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 116.15 GB, percent = 16.7%\n",
      "[2024-01-08 20:42:23,836] [INFO] [utils.py:786:see_memory_usage] Before initializing optimizer states\n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 25.94 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 117.28 GB, percent = 16.8%\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 1; 31.75 GiB total capacity; 25.93 GiB already allocated; 3.34 GiB free; 27.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 0; 31.75 GiB total capacity; 25.94 GiB already allocated; 3.21 GiB free; 27.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 409110) of binary: /gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/python3.10\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 964, in launch_command\r\n",
      "    deepspeed_launcher(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 687, in deepspeed_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "open_instruct/dpo_tune.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 409111)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 409110)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_dpo.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c8b",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune_trainer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19aebd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results/baselines/huggyllama/llama-7b using 2 GPUs, 2 batch size per GPU, 32 gradient accumulation steps, Effective batch size 128\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi2\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 192,\n",
      "    \"num_gpus\": 2,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"x86_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue x86_6h -name oi2 -mem 192g -cores 1x32+2 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nproc_per_node=2 --master_port=10002 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/dolly/dolly_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=32 --per_device_train_batch_size=2 --gradient_accumulation_steps=32 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=100 --report_to tensorboard wandb --run_name /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi2/llama-7b_dolly_ep=2 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=100 --save_total_limit=1 --num_train_epochs=2 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --gradient_checkpointing --torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --use_flash_attn True --low_cpu_mem_usage --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi2/llama-7b_dolly_ep=2\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi2/llama-7b_dolly_ep=2 ||:\\'', 'job_id': 1223352}]\n"
     ]
    }
   ],
   "source": [
    "add_hardwarespec_to_dirname = False\n",
    "save_strategy = 'steps'\n",
    "save_steps = 100\n",
    "save_total_limit = 1\n",
    "preprocessing_num_workers = 32\n",
    "evaluation_strategy = 'no' # set do_eval=False\n",
    "eval_steps = save_steps\n",
    "report_to = 'tensorboard wandb'\n",
    "suffix = None\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0.03\n",
    "dataloader_sampler = None\n",
    "hf_models_dir = 'results/baselines/'\n",
    "subsample_inds_file_list = [None]\n",
    "max_train_samples_list = [None]\n",
    "num_train_epochs_list = [1]\n",
    "scoring_fn_and_pacing_fn = None\n",
    "\n",
    "\n",
    "########### sft baselines\n",
    "\n",
    "\n",
    "job_name = 'oi2'; num_train_epochs_list = [2] \n",
    "# model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048\n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "\n",
    "# train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2'\n",
    "# train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; max_train_samples_list=[100_000]\n",
    "# train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca'; \n",
    "# train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2';\n",
    "# train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2'; max_train_samples_list=[100_000]\n",
    "###########\n",
    "\n",
    "\n",
    "# ############ pruning runs\n",
    "\n",
    "# # model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048; gen_output_md = 'mistral7br512p4096'\n",
    "# model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048; gen_output_md = 'llama7br512p4096'\n",
    "\n",
    "# # dataset = 'wizardlmv2'; train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2';\n",
    "# # dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # dataset = 'flan_v2'; train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# # dataset = 'oasst1'; train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1'; \n",
    "# # dataset = 'sharegptv2'; train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2';\n",
    "# # dataset = 'stanford_alpaca'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca';\n",
    "# # dataset = 'ultrachat200kv2'; train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2';\n",
    "# # dataset = 'open_orca_slim'; train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; \n",
    "# # dataset = 'tulu_v2'; train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2';\n",
    "\n",
    "# # M = 80_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 40_000\n",
    "# # M = 60_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 20_000\n",
    "# # M = 50_000; pacing_fn_list = [f'prune_size={M}_ep=5']; subset_size = 10_000\n",
    "# # M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "\n",
    "\n",
    "# scoring_fn_list = [\n",
    "#     'random_s=0', 'random_s=1',\n",
    "#     'log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n',\n",
    "#     'ifd_neg', 'log_pmi_neg',\n",
    "#     'numtoks_input_neg', 'numtoks_output_neg', 'numtoks_total_neg',\n",
    "#     f'dppmap_k=vmf_gamma=1_kmd=mpnet', #_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding',\n",
    "#     f'dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB',\n",
    "# ]\n",
    "\n",
    "# scoring_fn_list += [ # vary kernel embedding model \n",
    "# #     f'dppmap_k=vmf_gamma=auto{subset_size}_kmd={kmd}_kemb=grad+rp+loraB'\n",
    "# #     for kmd in ['llama7br256p4096', 'llama7br512p4096', 'pythia1br512p4096']\n",
    "# ]\n",
    "# scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "# job_name = f'oi5_{dataset}:{abbr_model_name}'\n",
    "# ############ \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "debug_mode = test_run\n",
    "\n",
    "if arch == 'x86_64':\n",
    "#     nodes = 1; num_gpus = 1; gpu_type = 'a100_80gb'; job_duration = 6\n",
    "    nodes = 1; num_gpus = 2; gpu_type = 'a100_80gb'; job_duration = 6\n",
    "    num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus)\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_checkpointing = True\n",
    "    mixed_precision = 'bf16'; torch_dtype = 'bfloat16'; use_flash_attn = True\n",
    "else:\n",
    "    nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "#     nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12\n",
    "#     nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 18\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_checkpointing = True\n",
    "    mixed_precision = 'fp16'; torch_dtype = 'float32'; use_flash_attn = False\n",
    "    \n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs_list = [1] # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "overwrite_output_dir = True if test_run else False # always continue from ckpt if run from cluster.\n",
    "\n",
    "total_batch_size = 128\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "optimizer = 'adamw_hf'\n",
    "\n",
    "deepspeed = ''; fsdp = False if num_gpus == 1 else \"full_shard auto_wrap\" \n",
    "if 'gpt2' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPT2Block'\n",
    "elif 'llama' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'LlamaDecoderLayer'\n",
    "elif 'mpt' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MPTBlock'\n",
    "elif 'pythia' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPTNeoXLayer'        \n",
    "elif 'mistral' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MistralDecoderLayer'\n",
    "else: raise ValueError('Not sure how to set `fsdp_transformer_layer_cls_to_wrap`')\n",
    "    \n",
    "# deepspeed = './ds_configs/ds_zero3_cpu_offload.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/ds_zero3.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/stage3_no_offloading.conf'; fsdp = False # error with loading... something wrong with the config.\n",
    "# fsdp = False; deepspeed = False\n",
    "\n",
    "if fsdp and deepspeed:\n",
    "    raise ValueError('either fsdp or deepspeed, not both')\n",
    "\n",
    "use_lora = False\n",
    "lora_rank = 256 \n",
    "lora_alpha = lora_rank \n",
    "lora_dropout = 0.05\n",
    "if use_lora:\n",
    "    abbr_model_name += f'+lora(r={lora_rank},a={lora_alpha})'\n",
    "load_in_8bit = False\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"Effective batch size {effective_batch_size}\")\n",
    "\n",
    "\n",
    "if nodes == 1:\n",
    "    exe = 'python' if num_gpus==1 else \\\n",
    "        f\"torchrun --nproc_per_node={num_gpus} --master_port=10002\"\n",
    "else:\n",
    "    exe = f\"torchrun --nnodes={nodes} --nproc_per_node={num_gpus} --rdzv-id=$SLURM_JOB_ID --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT\"\n",
    "\n",
    "if test_run:\n",
    "    exe = f\"CUDA_VISIBLE_DEVICES={','.join(map(str, range(num_gpus)))} {exe}\"\n",
    "if test_run and debug_mode:\n",
    "    exe = 'TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO ' + exe\n",
    "    error_file = os.path.join(open_instruct_dir, 'scripts', 'error_file')\n",
    "    exe = f'TORCHELASTIC_ERROR_FILE={error_file} {exe}'\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "options_list = itertools.product(\n",
    "    num_train_epochs_list,\n",
    "    subsample_inds_file_list,\n",
    "    max_train_samples_list,\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "output_dirname_list = []\n",
    "for (num_train_epochs,\n",
    "     subsample_inds_file,\n",
    "     max_train_samples,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{abbr_train_file}\"\n",
    "    if max_train_samples:\n",
    "        output_dirname += f\":{int(max_train_samples/1000)}k\"\n",
    "            \n",
    "    if any(job_name == y for y in ['oi2']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "        \n",
    "    if subsample_inds_file:\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                return f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            else:\n",
    "                return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "            \n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "            \n",
    "    if add_hardwarespec_to_dirname:\n",
    "        output_dirname += \\\n",
    "            ('_fsdp='+fsdp.split(' ')[0] if fsdp else '')+\\\n",
    "            ('_deepspeed='+os.path.basename(deepspeed).split('.')[0] if deepspeed else '')+\\\n",
    "            ('_gradckpt='+str(gradient_checkpointing) if gradient_checkpointing else '')+\\\n",
    "            '_mbsz='+str(per_device_train_batch_size)+\\\n",
    "            '_dtype='+torch_dtype+\\\n",
    "            ('_mp='+str(mixed_precision) if mixed_precision else '_mp=none')+\\\n",
    "            '_seqlen='+str(max_seq_length)+\\\n",
    "            '_nodes='+str(nodes)\n",
    "    if suffix:\n",
    "        output_dirname += suffix\n",
    "    output_dir = os.path.join(open_instruct_dir, 'results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join(open_instruct_dir, 'results', job_name), exist_ok=True)\n",
    "    wandb_run_name = output_dir.replace('results/', '')\n",
    "    \n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {'cd .. && ' if test_run else ''}{exe}\n",
    "        open_instruct/finetune_trainer.py \\\n",
    "        --model_name_or_path={model_name_or_path} \\\n",
    "        --tokenizer_name={model_name_or_path} \\\n",
    "        {'--load_in_8bit' if load_in_8bit else ''} \\\n",
    "        --use_fast_tokenizer=True \\\n",
    "        --train_file={train_file} \\\n",
    "        --max_seq_length={max_seq_length} \\\n",
    "        {'--max_train_samples='+str(max_train_samples) if max_train_samples else ''} \\\n",
    "        {'--use_lora' if use_lora else ''}\n",
    "        {'--lora_rank='+str(lora_rank) if use_lora else ''}\n",
    "        {'--lora_alpha='+str(lora_alpha) if use_lora else ''}\n",
    "        {'--lora_dropout='+str(lora_dropout) if use_lora else ''}\n",
    "        --do_train \\\n",
    "        --preprocessing_num_workers={preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size={per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
    "        --learning_rate=2e-5 \\\n",
    "        --lr_scheduler_type={lr_scheduler_type} \\\n",
    "        --warmup_ratio={warmup_ratio} \\\n",
    "        --weight_decay=0. \\\n",
    "        --optim={optimizer} \\\n",
    "        --evaluation_strategy={evaluation_strategy} \\\n",
    "        {'--eval_steps='+str(eval_steps) if eval_steps else ''} \\\n",
    "        {'--report_to '+str(report_to) if report_to else ''} \\\n",
    "        --run_name {wandb_run_name} \\\n",
    "        --logging_strategy=steps \\\n",
    "        --logging_first_step \\\n",
    "        --logging_steps=1 \\\n",
    "        --save_strategy={save_strategy} \\\n",
    "        --save_steps={save_steps} \\\n",
    "        --save_total_limit={save_total_limit} \\\n",
    "        --num_train_epochs={num_train_epochs} \\\n",
    "        --ddp_timeout=7200 \\\n",
    "        {'--fsdp=\"'+fsdp+'\"' if fsdp else ''}\n",
    "        {'--fsdp_transformer_layer_cls_to_wrap=\"'+fsdp_transformer_layer_cls_to_wrap+'\"' \n",
    "            if fsdp else ''}\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''}\n",
    "        --torch_dtype={torch_dtype} \\\n",
    "        --dataloader_num_workers=8 \\\n",
    "        {f'--{mixed_precision}=True' if mixed_precision else ''} \\\n",
    "        {'--overwrite_output_dir' if overwrite_output_dir else ''} \\\n",
    "        {'--deepspeed='+deepspeed if deepspeed else ''} \\\n",
    "        {'--subsample_inds_file='+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        {'--dataloader_sampler '+str(dataloader_sampler) if dataloader_sampler else ''} \\\n",
    "        --use_flash_attn {'True' if use_flash_attn else 'False'} \\\n",
    "        --low_cpu_mem_usage \\\n",
    "        --output_dir=\"{output_dir}\" \\\n",
    "    \"\"\" \n",
    "    #    --overwrite_cache # if delete a dataset and need to refresh cache\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "    if test_run:\n",
    "        print()\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64':\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12fc2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_sft.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed0c2894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=\n",
      "+ cd ..\n",
      "+ TORCHELASTIC_ERROR_FILE=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/error_file\n",
      "+ TORCH_CPP_LOG_LEVEL=INFO\n",
      "+ NCCL_DEBUG=INFO\n",
      "+ LOGLEVEL=INFO\n",
      "+ CUDA_VISIBLE_DEVICES=0,1\n",
      "+ torchrun --nproc_per_node=2 --master_port=10002 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/dolly/dolly_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=32 --per_device_train_batch_size=2 --gradient_accumulation_steps=32 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=100 --report_to tensorboard --run_name /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi2/jpt_llama-7b_dolly_ep=2 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=100 --save_total_limit=1 --num_train_epochs=2 --ddp_timeout=7200 '--fsdp=full_shard auto_wrap' --fsdp_transformer_layer_cls_to_wrap=LlamaDecoderLayer --gradient_checkpointing --torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --overwrite_output_dir --use_flash_attn True --low_cpu_mem_usage --output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi2/jpt_llama-7b_dolly_ep=2\n",
      "[2024-01-14 16:18:53,802] torch.distributed.run: [WARNING] \n",
      "[2024-01-14 16:18:53,802] torch.distributed.run: [WARNING] *****************************************\n",
      "[2024-01-14 16:18:53,802] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "[2024-01-14 16:18:53,802] torch.distributed.run: [WARNING] *****************************************\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO] Starting elastic_operator with launch configs:\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   entrypoint       : open_instruct/finetune_trainer.py\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   min_nodes        : 1\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   max_nodes        : 1\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   nproc_per_node   : 2\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   run_id           : none\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   rdzv_backend     : static\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   rdzv_endpoint    : 127.0.0.1:10002\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   max_restarts     : 0\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   monitor_interval : 5\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   log_dir          : None\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO]   metrics_cfg      : {}\n",
      "[2024-01-14 16:18:53,803] torch.distributed.launcher.api: [INFO] \n",
      "[2024-01-14 16:18:53,806] torch.distributed.elastic.agent.server.local_elastic_agent: [INFO] log directory set to: /tmp/torchelastic_ksd7enii/none_h8abwftr\n",
      "[2024-01-14 16:18:53,806] torch.distributed.elastic.agent.server.api: [INFO] [default] starting workers for entrypoint: python3.10\n",
      "[2024-01-14 16:18:53,806] torch.distributed.elastic.agent.server.api: [INFO] [default] Rendezvous'ing worker group\n",
      "[I socket.cpp:576] [c10d] The server socket has started to listen on [::]:10002.\n",
      "[I socket.cpp:849] [c10d] The client socket has connected to [localhost]:10002 on [localhost]:53412.\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO] [default] Rendezvous complete for workers. Result:\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   restart_count=0\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   master_addr=127.0.0.1\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   master_port=10002\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   group_rank=0\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   group_world_size=1\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   local_ranks=[0, 1]\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   role_ranks=[0, 1]\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   global_ranks=[0, 1]\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   role_world_sizes=[2, 2]\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO]   global_world_sizes=[2, 2]\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO] \n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.api: [INFO] [default] Starting worker group\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.agent.server.local_elastic_agent: [INFO] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.multiprocessing: [INFO] Setting worker0 reply file to: /tmp/torchelastic_ksd7enii/none_h8abwftr/attempt_0/0/error.json\n",
      "[2024-01-14 16:18:53,809] torch.distributed.elastic.multiprocessing: [INFO] Setting worker1 reply file to: /tmp/torchelastic_ksd7enii/none_h8abwftr/attempt_0/1/error.json\n",
      "[2024-01-14 16:19:02,180] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-14 16:19:02,185] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[I socket.cpp:849] [c10d] The client socket has connected to [localhost]:10002 on [localhost]:55424.\n",
      "[I socket.cpp:849] [c10d] The client socket has connected to [localhost]:10002 on [localhost]:55436.\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/training_args.py:1584: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead \n",
      "  warnings.warn(\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/training_args.py:1584: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead \n",
      "  warnings.warn(\n",
      "Saving args dict to /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi2/jpt_llama-7b_dolly_ep=2.args.json\n",
      "Saving args dict to /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi2/jpt_llama-7b_dolly_ep=2.args.json\n",
      "01/14/2024 16:19:07 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 1distributed training: True, 16-bits training: False\n",
      "01/14/2024 16:19:07 - INFO - __main__ - Training parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=8,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_sampler=RandomSampler,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=7200,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=100.0,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[<FSDPOption.FULL_SHARD: 'full_shard'>, <FSDPOption.AUTO_WRAP: 'auto_wrap'>],\n",
      "fsdp_config={'min_num_params': 0, 'transformer_layer_cls_to_wrap': ['LlamaDecoderLayer'], 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=LlamaDecoderLayer,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=32,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi2/jpt_llama-7b_dolly_ep=2/runs/Jan14_16-19-07_cccxc501,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1.0,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi2/jpt_llama-7b_dolly_ep=2,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=2,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi2/jpt_llama-7b_dolly_ep=2,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=True,\n",
      "save_steps=100,\n",
      "save_strategy=steps,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "01/14/2024 16:19:07 - WARNING - __main__ - Process rank: 1, device: cpu, n_gpu: 1distributed training: True, 16-bits training: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3ab84c08398a775b\n",
      "01/14/2024 16:19:07 - INFO - datasets.builder - Using custom data configuration default-3ab84c08398a775b\n",
      "Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "01/14/2024 16:19:07 - INFO - datasets.info - Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "Generating train split: 14956 examples [00:00, 62021.35 examples/s]\n",
      "Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/dolly/json/default-3ab84c08398a775b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "01/14/2024 16:19:07 - INFO - datasets.builder - Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/dolly/json/default-3ab84c08398a775b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/dolly/json/default-3ab84c08398a775b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/14/2024 16:19:07 - INFO - datasets.info - Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/dolly/json/default-3ab84c08398a775b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "[INFO|configuration_utils.py:715] 2024-01-14 16:19:07,912 >> loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "[INFO|configuration_utils.py:777] 2024-01-14 16:19:07,917 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-14 16:19:07,921 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-14 16:19:07,921 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-14 16:19:07,921 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-14 16:19:07,921 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-14 16:19:07,921 >> loading file tokenizer_config.json\n",
      "[INFO|modeling_utils.py:3118] 2024-01-14 16:19:08,480 >> loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1222] 2024-01-14 16:19:08,481 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "Traceback (most recent call last):\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/open_instruct/finetune_trainer.py\", line 791, in <module>\n",
      "    main()\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/open_instruct/finetune_trainer.py\", line 564, in main\n",
      "Traceback (most recent call last):\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/open_instruct/finetune_trainer.py\", line 791, in <module>\n",
      "    model = AutoModelForCausalLM.from_pretrained(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n",
      "    main()\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/open_instruct/finetune_trainer.py\", line 564, in main\n",
      "    model = AutoModelForCausalLM.from_pretrained(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 3233, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 3233, in from_pretrained\n",
      "    config = cls._check_and_enable_flash_attn_2(config, torch_dtype=torch_dtype, device_map=device_map)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 1273, in _check_and_enable_flash_attn_2\n",
      "    config = cls._check_and_enable_flash_attn_2(config, torch_dtype=torch_dtype, device_map=device_map)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 1273, in _check_and_enable_flash_attn_2\n",
      "    raise ImportError(\n",
      "ImportError: Flash Attention 2 is not available. Please refer to the documentation of https://github.com/Dao-AILab/flash-attention for installing it. Make sure to have at least the version 2.1.0\n",
      "    raise ImportError(\n",
      "ImportError: Flash Attention 2 is not available. Please refer to the documentation of https://github.com/Dao-AILab/flash-attention for installing it. Make sure to have at least the version 2.1.0\n",
      "[2024-01-14 16:19:18,852] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2233944) of binary: /dccstor/data-pruning/miniconda3/envs/open-instruct/bin/python3.10\n",
      "[2024-01-14 16:19:18,857] torch.distributed.elastic.multiprocessing.errors: [INFO] ('local_rank %s FAILED with no error file. Decorate your entrypoint fn with @record for traceback info. See: https://pytorch.org/docs/stable/elastic/errors.html', 0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py\", line 806, in main\n",
      "    run(args)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py\", line 797, in run\n",
      "    elastic_launch(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "open_instruct/finetune_trainer.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2024-01-14_16:19:18\n",
      "  host      : cccxc501.pok.ibm.com\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 2233945)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2024-01-14_16:19:18\n",
      "  host      : cccxc501.pok.ibm.com\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 2233944)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_sft.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831fe55",
   "metadata": {},
   "source": [
    "# eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "499d6f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('alpacafarm_ann=chatgpt_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('alpacafarm_ann=chatgpt_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('alpacafarm_ann=chatgpt_chatfmt', 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "#cmds:  3 \n",
      "\n",
      "python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path \"results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3\" --max_new_tokens 2048 --save_dir \"results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=chatgpt_chatfmt\" --eval_batch_size 5 --annotators_config chatgpt --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype float16\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=chatgpt_chatfmt\",\n",
      "    \"num_cpus\": 21,\n",
      "    \"cpu_mem\": 85,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path \"results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3\" --max_new_tokens 2048 --save_dir \"results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=chatgpt_chatfmt\" --eval_batch_size 5 --annotators_config chatgpt --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype float16\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=chatgpt_chatfmt\",\n",
      "    \"num_cpus\": 21,\n",
      "    \"cpu_mem\": 85,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path \"results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3\" --max_new_tokens 2048 --save_dir \"results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=chatgpt_chatfmt\" --eval_batch_size 5 --annotators_config chatgpt --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype float16\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=chatgpt_chatfmt\",\n",
      "    \"num_cpus\": 21,\n",
      "    \"cpu_mem\": 85,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from gen_cmds_utils import remove_all_symlinks, create_unique_symlinks, get_chat_formatting_function, get_resource_for_task\n",
    "\n",
    "create_symlinks = False\n",
    "include_checkpoints = False\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "use_slow_tokenizer = True\n",
    "\n",
    "\n",
    "task_names = [\n",
    "    'mmlu_s=0',\n",
    "    'mmlu_s=5', \n",
    "    'gsm_s=8',\n",
    "    'gsm_s=8_cot',\n",
    "    'bbh_s=3',\n",
    "    'bbh_s=3_cot', # max_datapoints_per_task=40 -> 40min.\n",
    "    'humaneval',\n",
    "    'tydiqa_s=1_cb', # 3min\n",
    "    'tydiqa_s=1_gp',\n",
    "    # 'toxigen', # ~1.5hr\n",
    "#     'alpacafarm_ann=gpt35:turbo:1106',\n",
    "    # 'alpacafarm_ann=chatgpt', # ~$1 per eval.\n",
    "]\n",
    "task_names_alpacafarm = ['alpacafarm_ann=chatgpt_chatfmt']\n",
    "task_names_chatfmt = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "# ## baselines eval \n",
    "subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "#     'huggyllama/llama-7b', \n",
    "#     'mistralai/Mistral-7B-v0.1',\n",
    "#     'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "#     'NousResearch/Llama-2-7b-hf',\n",
    "#     'NousResearch/Llama-2-7b-chat-hf',\n",
    "#     'HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "#     'HuggingFaceH4/mistral-7b-sft-beta',\n",
    "#     'HuggingFaceH4/zephyr-7b-alpha',\n",
    "#     'HuggingFaceH4/zephyr-7b-beta',\n",
    "#     'codellama/CodeLlama-7b-hf',\n",
    "#     'codellama/CodeLlama-7b-Python-hf',\n",
    "#     'codellama/CodeLlama-7b-Instruct-hf',\n",
    "]]\n",
    "# task_names = task_names + task_names_chatfmt\n",
    "\n",
    "\n",
    "# # oi5\n",
    "# exp_dir = 'results/oi2'\n",
    "# exp_dir = 'results/oi5_tulu_v1_mix:llama-7b/'\n",
    "# exp_dir = 'results/oi5_ultrachat:mistral-7b'\n",
    "# exp_dir = 'results/oi5_ultrachat200k:mistral-7b'\n",
    "# exp_dir = 'results/oi5_ultrachat15:mistral-7b'\n",
    "# exp_dir = 'results/oi5_ultrachat200kv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlm:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlmv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegptv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_tulu_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_open_orca_slim:llama-7b'\n",
    "# exp_dir = 'results/oi5_stanford_alpaca:llama-7b'\n",
    "# exp_dir = 'results/oi5_flan_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_dolly:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b'\n",
    "# exp_dir = 'results/oi6_starcoder_ep=5'\n",
    "# exp_dir = 'results/oi5_starcoder_commentinstr:codellama-7b'\n",
    "# exp_dir = 'results/oi5_starcoder_commentinstrv2:codellama-7b'\n",
    "# exp_dir = 'results/oi5_starcoder_commentinstrv4:codellama-7b'\n",
    "# exp_dir = 'results/oi5_starcoder_commentinstrv5:codellama-7b'\n",
    "# exp_dir = 'results/dpo1'\n",
    "exp_dir = 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2'\n",
    "# subdir_filter_fn = lambda x: 'llama' in x\n",
    "# task_names = task_names + task_names_chatfmt\n",
    "task_names = task_names_alpacafarm\n",
    "# task_names = ['humaneval', 'humaneval_chatfmt']\n",
    "# task_names = ['alpacafarm_ann=gpt35:turbo:1106_chatfmt']\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "num_gpus = 1\n",
    "if arch == 'x86_64': # ccc\n",
    "    gpu_type = 'a100_80gb' # or 'a100_40gb' but might need to change batch size to prevent oom\n",
    "    num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus)\n",
    "    use_vllm = True; torch_dtype = 'bfloat16'\n",
    "else:\n",
    "    gpu_type = 'v100'\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    use_vllm = False; torch_dtype = 'float16'\n",
    "    \n",
    "if len(subdir_path_list)==0:\n",
    "    if create_symlinks:\n",
    "        remove_all_symlinks(exp_dir)\n",
    "    subdir_path_list = []\n",
    "    subdirs = list(os.listdir(exp_dir))\n",
    "    subdirs = filter(subdir_filter_fn, subdirs)\n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(exp_dir, subdir)\n",
    "        if include_checkpoints:\n",
    "            subdir_path_list += glob.glob(os.path.join(subdir_path, 'checkpoint-*'))\n",
    "        if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "            continue\n",
    "        subdir_path_list.append(subdir_path)\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not os.path.islink(subdir_path) and \\\n",
    "                not os.path.isfile(os.path.join(subdir_path, 'eval', task_name, 'metrics.json')):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "                print((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "\n",
    "print('#cmds: ', len(list(task_name_and_model)), '\\n')\n",
    "\n",
    "if create_symlinks:\n",
    "    # create symlink for each directory.\n",
    "    symlink_path_dict = create_unique_symlinks(\n",
    "        list([x[1] for x in task_name_and_model]))\n",
    "    options_list = list(map(lambda x: (x[0], symlink_path_dict[x[1]]), task_name_and_model))\n",
    "else:\n",
    "    options_list = task_name_and_model\n",
    "    \n",
    "    \n",
    "\n",
    "info = {}  \n",
    "cmds = []\n",
    "for task_name, model_name_or_path in options_list:\n",
    "    \n",
    "    use_chat_format = 'chatfmt' in task_name\n",
    "    chat_formatting_function = get_chat_formatting_function(model_name_or_path)\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(model_name_or_path, 'ft_args.json'), 'r') as f:\n",
    "            ft_args = json.load(f)\n",
    "        # note `model_name_or_path` could be anything, e.g., soft links with arbitrary names.\n",
    "        # but `ft_args_model_name_or_path` indicates the finetuned model name.\n",
    "        if 'model_args' in ft_args:\n",
    "            ft_args_model_name_or_path = ft_args['model_args']['model_name_or_path']\n",
    "        else:\n",
    "            ft_args_model_name_or_path = ft_args['model_name_or_path']\n",
    "    except:\n",
    "        ft_args_model_name_or_path = model_name_or_path\n",
    "\n",
    "    batch_size, job_duration = get_resource_for_task(\n",
    "        task_name, ft_args_model_name_or_path)\n",
    "    \n",
    "    job_name = f'eval.{task_name}'\n",
    "    run_id = model_name_or_path\n",
    "    save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "    \n",
    "    if task_name.startswith('mmlu'):\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 5)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.mmlu.run_eval \\\n",
    "            --data_dir data/eval/mmlu \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --ntrain {n_shot} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('gsm'):\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 8)\n",
    "        # open-instruct used 200 examples. use higher amount to get a more accurate number\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.gsm.run_eval \\\n",
    "            --data_dir data/eval/gsm/ \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_num_examples 500 \\\n",
    "            --n_shot {n_shot} \\\n",
    "            --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "            {'--use_vllm' if use_vllm else ''} \\\n",
    "            {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('bbh'):\n",
    "        max_num_examples_per_task = 40\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot <= 3)\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.bbh.run_eval \\\n",
    "            --data_dir data/eval/bbh/ \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "            --n_shot {n_shot} \\\n",
    "            {'--use_vllm' if use_vllm else ''} \\\n",
    "            {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--max_num_examples_per_task '+str(max_num_examples_per_task) if max_num_examples_per_task else ''} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('humaneval'):\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.codex_humaneval.run_eval \\\n",
    "            --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --max_new_tokens 512 \\\n",
    "            --eval_pass_at_ks 1 \\\n",
    "            --unbiased_sampling_size_n 3 \\\n",
    "            --temperature 0.1 \\\n",
    "            {'--use_vllm' if use_vllm else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('tydiqa'):\n",
    "        no_context = 'cb' in task_name\n",
    "        match = re.search(r's=(\\d+)', task_name)\n",
    "        n_shot = int(match.group(1))\n",
    "        assert(n_shot in [0,1])\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.tydiqa.run_eval \\\n",
    "            --data_dir data/eval/tydiqa \\\n",
    "            --n_shot {n_shot} \\\n",
    "            --max_num_examples_per_lang 100 \\\n",
    "            --max_context_length 512 \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            {'--use_vllm' if use_vllm else ''} \\\n",
    "            {'--no_context' if no_context else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('toxigen'):\n",
    "        # max_prompts_per_group=500 (out of 1000) is open-instruct default.\n",
    "        # eval batch size=1 much faster (llama-7b) not sure why.\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.toxigen.run_eval \\\n",
    "            --data_dir data/eval/toxigen \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size 1 \\\n",
    "            --max_prompts_per_group 200 \\\n",
    "            {'--use_vllm' if use_vllm else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    elif task_name.startswith('alpacafarm'):\n",
    "        match = re.search(r'ann=([^_]+)', task_name)\n",
    "        annotators_config = match.group(1)\n",
    "        annotators_config = annotators_config.replace(':', '_')\n",
    "        if not annotators_config in ['chatgpt', 'alpaca_eval_gpt4_0314', 'gpt35_turbo_1106']:\n",
    "            raise ValueError('Just support 2 annotators_config.')\n",
    "        cmd = f\"\"\"\n",
    "        python -m eval.alpaca_farm.run_eval \\\n",
    "            --reference_path alpaca_eval_data \\\n",
    "            --model_name_or_path \"{model_name_or_path}\" \\\n",
    "            --max_new_tokens 2048 \\\n",
    "            --save_dir \"{save_dir}\" \\\n",
    "            --eval_batch_size {batch_size} \\\n",
    "            --annotators_config {annotators_config} \\\n",
    "            {'--use_vllm' if use_vllm else ''} \\\n",
    "            {'--use_chat_format' if use_chat_format else ''} \\\n",
    "            --chat_formatting_function {chat_formatting_function} \\\n",
    "            {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "            --torch_dtype {torch_dtype} \\\n",
    "        \"\"\"\n",
    "    else:\n",
    "        raise ValueError(f'{task_name} not supported.')\n",
    "        \n",
    "        \n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "    print(cmd)\n",
    "    \n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=save_dir,\n",
    "    )\n",
    "    if arch == 'x86_64': # ccc\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859d6d6",
   "metadata": {},
   "source": [
    "# Visualize Eval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b033ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./1223352.out does not have `--save_dir` specified. Probably still running.\n",
      "Move ./1223732.out -> /dccstor/data-pruning/results/baselines/huggyllama/llama-7b/eval/gsm_s=8_cot/1223732.out.lsf\n"
     ]
    }
   ],
   "source": [
    "# if job successfully ran, lsf system will generate a summary in log_dir,\n",
    "# call this function to move lsf summary to save_dir if job is successful.\n",
    "move_lsf_job_summary_to_save_dir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4392e9ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_fmt=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3618: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3619: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ca726 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_ca726_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ca726_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ca726_row0_col2, #T_ca726_row0_col3, #T_ca726_row0_col4, #T_ca726_row0_col5, #T_ca726_row0_col6, #T_ca726_row0_col7, #T_ca726_row0_col8, #T_ca726_row0_col9, #T_ca726_row0_col10, #T_ca726_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ca726_row0_col11, #T_ca726_row0_col12, #T_ca726_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ca726\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ca726_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_ca726_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_ca726_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_ca726_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_ca726_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_ca726_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_ca726_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_ca726_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_ca726_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_ca726_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_ca726_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_ca726_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_ca726_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_ca726_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_ca726_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ca726_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ca726_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_ca726_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_ca726_row0_col2\" class=\"data row0 col2\" >32.8</td>\n",
       "      <td id=\"T_ca726_row0_col3\" class=\"data row0 col3\" >33.5</td>\n",
       "      <td id=\"T_ca726_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_ca726_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_ca726_row0_col6\" class=\"data row0 col6\" >32.1</td>\n",
       "      <td id=\"T_ca726_row0_col7\" class=\"data row0 col7\" >27.4</td>\n",
       "      <td id=\"T_ca726_row0_col8\" class=\"data row0 col8\" >9.7</td>\n",
       "      <td id=\"T_ca726_row0_col9\" class=\"data row0 col9\" >35.4</td>\n",
       "      <td id=\"T_ca726_row0_col10\" class=\"data row0 col10\" >0.0</td>\n",
       "      <td id=\"T_ca726_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_ca726_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_ca726_row0_col13\" class=\"data row0 col13\" >20.8</td>\n",
       "      <td id=\"T_ca726_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc960620e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_feb8b td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_feb8b_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_feb8b_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_feb8b_row0_col2, #T_feb8b_row0_col3, #T_feb8b_row0_col4, #T_feb8b_row0_col5, #T_feb8b_row0_col6, #T_feb8b_row0_col7, #T_feb8b_row0_col8, #T_feb8b_row0_col9, #T_feb8b_row0_col10, #T_feb8b_row0_col11, #T_feb8b_row0_col12, #T_feb8b_row0_col13, #T_feb8b_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_feb8b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_feb8b_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_feb8b_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_feb8b_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_feb8b_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_feb8b_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_feb8b_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_feb8b_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_feb8b_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_feb8b_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_feb8b_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_feb8b_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_feb8b_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_feb8b_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_feb8b_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_feb8b_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_feb8b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_feb8b_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegptv2_ep=2</td>\n",
       "      <td id=\"T_feb8b_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_feb8b_row0_col2\" class=\"data row0 col2\" >43.0</td>\n",
       "      <td id=\"T_feb8b_row0_col3\" class=\"data row0 col3\" >39.6</td>\n",
       "      <td id=\"T_feb8b_row0_col4\" class=\"data row0 col4\" >4.6</td>\n",
       "      <td id=\"T_feb8b_row0_col5\" class=\"data row0 col5\" >10.2</td>\n",
       "      <td id=\"T_feb8b_row0_col6\" class=\"data row0 col6\" >32.4</td>\n",
       "      <td id=\"T_feb8b_row0_col7\" class=\"data row0 col7\" >26.4</td>\n",
       "      <td id=\"T_feb8b_row0_col8\" class=\"data row0 col8\" >6.2</td>\n",
       "      <td id=\"T_feb8b_row0_col9\" class=\"data row0 col9\" >22.3</td>\n",
       "      <td id=\"T_feb8b_row0_col10\" class=\"data row0 col10\" >5.5</td>\n",
       "      <td id=\"T_feb8b_row0_col11\" class=\"data row0 col11\" >52.4</td>\n",
       "      <td id=\"T_feb8b_row0_col12\" class=\"data row0 col12\" >339.1</td>\n",
       "      <td id=\"T_feb8b_row0_col13\" class=\"data row0 col13\" >24.3</td>\n",
       "      <td id=\"T_feb8b_row0_col14\" class=\"data row0 col14\" >-2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc960620e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6448d td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_6448d_row0_col0, #T_6448d_row1_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6448d_row0_col1, #T_6448d_row1_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6448d_row0_col2, #T_6448d_row0_col4, #T_6448d_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6448d_row0_col3, #T_6448d_row0_col5, #T_6448d_row0_col6, #T_6448d_row0_col7, #T_6448d_row0_col8, #T_6448d_row0_col9, #T_6448d_row0_col10, #T_6448d_row0_col11, #T_6448d_row0_col12, #T_6448d_row0_col14, #T_6448d_row1_col2, #T_6448d_row1_col3, #T_6448d_row1_col4, #T_6448d_row1_col5, #T_6448d_row1_col6, #T_6448d_row1_col7, #T_6448d_row1_col8, #T_6448d_row1_col9, #T_6448d_row1_col10, #T_6448d_row1_col11, #T_6448d_row1_col12, #T_6448d_row1_col13, #T_6448d_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6448d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6448d_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_6448d_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_6448d_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_6448d_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_6448d_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_6448d_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_6448d_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_6448d_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_6448d_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_6448d_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_6448d_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_6448d_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_6448d_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_6448d_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_6448d_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6448d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6448d_row0_col0\" class=\"data row0 col0\" >llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_6448d_row0_col1\" class=\"data row0 col1\" >30000</td>\n",
       "      <td id=\"T_6448d_row0_col2\" class=\"data row0 col2\" >42.7</td>\n",
       "      <td id=\"T_6448d_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "      <td id=\"T_6448d_row0_col4\" class=\"data row0 col4\" >6.2</td>\n",
       "      <td id=\"T_6448d_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "      <td id=\"T_6448d_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "      <td id=\"T_6448d_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_6448d_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "      <td id=\"T_6448d_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "      <td id=\"T_6448d_row0_col10\" class=\"data row0 col10\" >nan</td>\n",
       "      <td id=\"T_6448d_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_6448d_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_6448d_row0_col13\" class=\"data row0 col13\" >24.5</td>\n",
       "      <td id=\"T_6448d_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6448d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6448d_row1_col0\" class=\"data row1 col0\" >llama-7b+sharegptv2ep2_ultrafeedback_ep=2</td>\n",
       "      <td id=\"T_6448d_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_6448d_row1_col2\" class=\"data row1 col2\" >42.6</td>\n",
       "      <td id=\"T_6448d_row1_col3\" class=\"data row1 col3\" >41.0</td>\n",
       "      <td id=\"T_6448d_row1_col4\" class=\"data row1 col4\" >5.6</td>\n",
       "      <td id=\"T_6448d_row1_col5\" class=\"data row1 col5\" >10.8</td>\n",
       "      <td id=\"T_6448d_row1_col6\" class=\"data row1 col6\" >23.9</td>\n",
       "      <td id=\"T_6448d_row1_col7\" class=\"data row1 col7\" >26.8</td>\n",
       "      <td id=\"T_6448d_row1_col8\" class=\"data row1 col8\" >5.0</td>\n",
       "      <td id=\"T_6448d_row1_col9\" class=\"data row1 col9\" >20.2</td>\n",
       "      <td id=\"T_6448d_row1_col10\" class=\"data row1 col10\" >0.0</td>\n",
       "      <td id=\"T_6448d_row1_col11\" class=\"data row1 col11\" >53.9</td>\n",
       "      <td id=\"T_6448d_row1_col12\" class=\"data row1 col12\" >424.5</td>\n",
       "      <td id=\"T_6448d_row1_col13\" class=\"data row1 col13\" >23.0</td>\n",
       "      <td id=\"T_6448d_row1_col14\" class=\"data row1 col14\" >-2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc7d74b100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3618: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3619: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2d68a td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_2d68a_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2d68a_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2d68a_row0_col2, #T_2d68a_row0_col3, #T_2d68a_row0_col4, #T_2d68a_row0_col5, #T_2d68a_row0_col6, #T_2d68a_row0_col7, #T_2d68a_row0_col8, #T_2d68a_row0_col9, #T_2d68a_row0_col10, #T_2d68a_row0_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2d68a_row0_col11, #T_2d68a_row0_col12, #T_2d68a_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2d68a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2d68a_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_2d68a_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_2d68a_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_2d68a_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_2d68a_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_2d68a_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_2d68a_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_2d68a_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_2d68a_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_2d68a_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_2d68a_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_2d68a_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_2d68a_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_2d68a_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_2d68a_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2d68a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2d68a_row0_col0\" class=\"data row0 col0\" >llama-7b</td>\n",
       "      <td id=\"T_2d68a_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_2d68a_row0_col2\" class=\"data row0 col2\" >32.8</td>\n",
       "      <td id=\"T_2d68a_row0_col3\" class=\"data row0 col3\" >33.5</td>\n",
       "      <td id=\"T_2d68a_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_2d68a_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_2d68a_row0_col6\" class=\"data row0 col6\" >32.1</td>\n",
       "      <td id=\"T_2d68a_row0_col7\" class=\"data row0 col7\" >27.4</td>\n",
       "      <td id=\"T_2d68a_row0_col8\" class=\"data row0 col8\" >9.7</td>\n",
       "      <td id=\"T_2d68a_row0_col9\" class=\"data row0 col9\" >35.4</td>\n",
       "      <td id=\"T_2d68a_row0_col10\" class=\"data row0 col10\" >0.0</td>\n",
       "      <td id=\"T_2d68a_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_2d68a_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "      <td id=\"T_2d68a_row0_col13\" class=\"data row0 col13\" >20.8</td>\n",
       "      <td id=\"T_2d68a_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc7d728100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9891c td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_9891c_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9891c_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9891c_row0_col2, #T_9891c_row0_col3, #T_9891c_row0_col4, #T_9891c_row0_col5, #T_9891c_row0_col6, #T_9891c_row0_col7, #T_9891c_row0_col8, #T_9891c_row0_col9, #T_9891c_row0_col10, #T_9891c_row0_col11, #T_9891c_row0_col12, #T_9891c_row0_col13, #T_9891c_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9891c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9891c_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_9891c_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_9891c_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_9891c_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_9891c_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_9891c_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_9891c_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_9891c_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_9891c_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_9891c_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_9891c_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_9891c_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_9891c_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_9891c_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_9891c_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9891c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9891c_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegptv2_ep=2</td>\n",
       "      <td id=\"T_9891c_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_9891c_row0_col2\" class=\"data row0 col2\" >43.0</td>\n",
       "      <td id=\"T_9891c_row0_col3\" class=\"data row0 col3\" >39.6</td>\n",
       "      <td id=\"T_9891c_row0_col4\" class=\"data row0 col4\" >4.6</td>\n",
       "      <td id=\"T_9891c_row0_col5\" class=\"data row0 col5\" >10.2</td>\n",
       "      <td id=\"T_9891c_row0_col6\" class=\"data row0 col6\" >32.4</td>\n",
       "      <td id=\"T_9891c_row0_col7\" class=\"data row0 col7\" >26.4</td>\n",
       "      <td id=\"T_9891c_row0_col8\" class=\"data row0 col8\" >6.2</td>\n",
       "      <td id=\"T_9891c_row0_col9\" class=\"data row0 col9\" >22.3</td>\n",
       "      <td id=\"T_9891c_row0_col10\" class=\"data row0 col10\" >5.5</td>\n",
       "      <td id=\"T_9891c_row0_col11\" class=\"data row0 col11\" >52.4</td>\n",
       "      <td id=\"T_9891c_row0_col12\" class=\"data row0 col12\" >339.1</td>\n",
       "      <td id=\"T_9891c_row0_col13\" class=\"data row0 col13\" >24.3</td>\n",
       "      <td id=\"T_9891c_row0_col14\" class=\"data row0 col14\" >-2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc7d74af20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8eda3 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_8eda3_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8eda3_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8eda3_row0_col2, #T_8eda3_row0_col3, #T_8eda3_row0_col4, #T_8eda3_row0_col5, #T_8eda3_row0_col6, #T_8eda3_row0_col7, #T_8eda3_row0_col8, #T_8eda3_row0_col9, #T_8eda3_row0_col10, #T_8eda3_row0_col11, #T_8eda3_row0_col12, #T_8eda3_row0_col13, #T_8eda3_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8eda3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8eda3_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_8eda3_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_8eda3_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_8eda3_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_8eda3_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_8eda3_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_8eda3_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_8eda3_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_8eda3_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_8eda3_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_8eda3_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_8eda3_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm/WR*</th>\n",
       "      <th id=\"T_8eda3_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm/Len</th>\n",
       "      <th id=\"T_8eda3_level0_col13\" class=\"col_heading level0 col13\" >Average</th>\n",
       "      <th id=\"T_8eda3_level0_col14\" class=\"col_heading level0 col14\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8eda3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8eda3_row0_col0\" class=\"data row0 col0\" >llama-7b+sharegptv2ep2_ultrafeedback_ep=2</td>\n",
       "      <td id=\"T_8eda3_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_8eda3_row0_col2\" class=\"data row0 col2\" >42.6</td>\n",
       "      <td id=\"T_8eda3_row0_col3\" class=\"data row0 col3\" >41.0</td>\n",
       "      <td id=\"T_8eda3_row0_col4\" class=\"data row0 col4\" >5.6</td>\n",
       "      <td id=\"T_8eda3_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_8eda3_row0_col6\" class=\"data row0 col6\" >23.9</td>\n",
       "      <td id=\"T_8eda3_row0_col7\" class=\"data row0 col7\" >26.8</td>\n",
       "      <td id=\"T_8eda3_row0_col8\" class=\"data row0 col8\" >5.0</td>\n",
       "      <td id=\"T_8eda3_row0_col9\" class=\"data row0 col9\" >20.2</td>\n",
       "      <td id=\"T_8eda3_row0_col10\" class=\"data row0 col10\" >0.0</td>\n",
       "      <td id=\"T_8eda3_row0_col11\" class=\"data row0 col11\" >53.9</td>\n",
       "      <td id=\"T_8eda3_row0_col12\" class=\"data row0 col12\" >424.5</td>\n",
       "      <td id=\"T_8eda3_row0_col13\" class=\"data row0 col13\" >23.0</td>\n",
       "      <td id=\"T_8eda3_row0_col14\" class=\"data row0 col14\" >-2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ffc7d7d6740>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_sort_rows_by_avg_ranking\n",
    "from llm.evaluate import EvalResults, get_eval_results\n",
    "\n",
    "\n",
    "\n",
    "exp_dir = ''\n",
    "chat_fmt = None\n",
    "sort_rows = True\n",
    "use_normalized_preferred_metric = False\n",
    "\n",
    "\n",
    "# ## investigate code change / package update effect on eval baselines.\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# use_normalized_preferred_metric = False\n",
    "# sort_rows = False\n",
    "# save_dirs = [\n",
    "#     # llama\n",
    "#     ('llama-7b_12.13update_before', '../results/baselines/huggyllama/llama-7b_12.13update_before/'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('llama-7b_10.30update', '../results/baselines/huggyllama/llama-7b_10.30update/'),\n",
    "# #     ('llama-7b_09.23update', '../results/baselines/huggyllama/llama-7b_09.23update/'),\n",
    "# #     ('llama-7b_09.23update_before', '../results/baselines/huggyllama/llama-7b_09.23update_before/'),\n",
    "# #     # llama2\n",
    "#     ('llama2-7b_12.13update_before', '../results/baselines/NousResearch/Llama-2-7b-hf_12.13update_before/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('llama2-7b-chat', '../results/baselines/NousResearch/Llama-2-7b-chat-hf/'),\n",
    "# #     ('llama2-7b_10.30update', '../results/baselines/NousResearch/Llama-2-7b-hf_10.30update/'),\n",
    "# #     ('llama2-7b_original', '../results/baselines/NousResearch/Llama-2-7b-hf_original/'),\n",
    "# #     # mistral\n",
    "# #     ('mistral-7b_10.16update', '../results/baselines/mistralai/Mistral-7B-v0.1_10.16update/'),\n",
    "#     ('mistral-7b-Instruct-v0.1_12.13update_before', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1_12.13update_before'),\n",
    "#     ('mistral-7b-Instruct-v0.1', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     # zephyr\n",
    "#     ('zephyr-7b-beta_12.13update_before', '../results/baselines/HuggingFaceH4/zephyr-7b-beta_12.13update_before'),\n",
    "#     ('zephyr-7b-beta', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "\n",
    "# # baselines\n",
    "# save_dirs = []\n",
    "# save_dirs += [\n",
    "# #     ('gpt2', '../results/baselines/gpt2'),\n",
    "# #     ('gpt2m', '../results/baselines/gpt2-medium'),\n",
    "# #     ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "# #     ('llama2-7b+humanmix', '../results/llama2-7b_humanmix'),\n",
    "# #     ('pythia-1.4b', '../results/baselines/EleutherAI/pythia-1.4b'),\n",
    "# #     ('pythia-2.8b', '../results/baselines/EleutherAI/pythia-2.8b'),\n",
    "# #     ('pythia-6.9b', '../results/baselines/EleutherAI/pythia-6.9b'),\n",
    "# #     ('dolly-v2-7b', '../results/baselines/databricks/dolly-v2-7b'),\n",
    "#     ('mistral-7b-v0.1', '../results/baselines/mistralai/Mistral-7B-v0.1'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b+lima_ep=2', '../results/ft1_ep=2/llama-7b_lima/'),\n",
    "# #     ('mistral-7b+lima_ep=2', '../results/ft1_ep=2/mistral-7b_lima/'), \n",
    "# ]\n",
    "# exp_dir = '../results/oi2/'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "\n",
    "# exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# # exp_dir = '../results/ft2'\n",
    "# # exp_dir = '../results/ft1'\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# # save_dirs = [\n",
    "# #     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "# #     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1/'),\n",
    "# # ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'tuluv1m' in x]\n",
    "\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "# # exp_dir = '../results/oi4'\n",
    "# # exp_dir = '../results/oi4_perf_cross_time'\n",
    "# # exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'\n",
    "# exp_dir = '../results/oi4_flan_v2_vary_subsetsize'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi4_flan2022_1m'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #              ('llama-7b_flan_v2_ep=2', '../results/ft1/llama-7b_flan_v2'),\n",
    "# #              ('llama-7b_humanmix_ep=2', '../results/ft1/llama-7b_humanmix'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "# #              ('llama-7b_cot:flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_cot:flanv2'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# # exp_dir = '../results/oi4_tulu_v1_mix'\n",
    "# exp_dir = '../results/oi4_tulu_v1_mix_ep=3'\n",
    "# use_normalized_preferred_metric = False\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# ###### ultrachat\n",
    "# save_dirs = [\n",
    "#     # baselines \n",
    "#     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "#     ('mistral-7b_ultrachat200k_aftersplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k'),\n",
    "#     ('mistral-7b_ultrachat200k_beforesplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k_beforesplitlongconv'),\n",
    "    \n",
    "#     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     ('mistral-7b_sft-alpha', '../results/baselines/HuggingFaceH4/mistral-7b-sft-alpha'),\n",
    "#     ('mistral-7b-sft-beta', '../results/baselines/HuggingFaceH4/mistral-7b-sft-beta'),\n",
    "#     ('mistral-7b-sft-alpha+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-alpha'),\n",
    "#     ('mistral-7b-sft-beta+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "# # exp_dir = '../results/oi5_ultrachat:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_ultrachat200k:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# exp_dir = '../results/oi5_ultrachat15:mistral-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "# dataset = 'stanford_alpaca'\n",
    "# dataset = 'open_orca_slim'\n",
    "# dataset = 'sharegptv2'\n",
    "# dataset = 'ultrachat200kv2'\n",
    "# dataset = 'wizardlm'\n",
    "# dataset = 'wizardlmv2'\n",
    "# dataset = 'tulu_v2'\n",
    "# dataset = 'flan_v2'\n",
    "# dataset = 'oasst1'\n",
    "# dataset = 'dolly'\n",
    "dataset_list = [\n",
    "    'stanford_alpaca', \n",
    "    'dolly',\n",
    "    'oasst1', \n",
    "    'flan_v2', \n",
    "    'tulu_v2', \n",
    "    'wizardlmv2', \n",
    "    'sharegptv2', \n",
    "    'ultrachat200kv2',\n",
    "]; finetune_type = 'sft'\n",
    "dataset_list = [\n",
    "    'ultrafeedback'\n",
    "]; finetune_type = 'pref'\n",
    "\n",
    "## older\n",
    "# dataset = 'tulu_v1_mix'\n",
    "save_dirs = []\n",
    "save_dirs += [('llama-7b', '../results/baselines/huggyllama/llama-7b'),\n",
    "#              ('llama-7b_lima_ep=5', '../results/oi2/llama-7b_lima_ep=5/'),\n",
    "#              ('llama-7b_lima_ep=10', '../results/oi2/llama-7b_lima_ep=10/'),\n",
    "            ]\n",
    "for dataset in dataset_list:\n",
    "    if dataset == 'tulu_v2':\n",
    "        save_dirs += [('llama-7b_tulu_v2:100k_ep=2', '../results/oi2/llama-7b_tulu_v2:100k_ep=2'),]\n",
    "    elif dataset == 'open_orca_slim':\n",
    "        save_dirs += [('llama-7b_openorcaslim:100k_ep=2', '../results/oi2/llama-7b_openorcaslim:100k_ep=2'),]\n",
    "    elif dataset == 'sharegptv2':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_sharegptv2_ep=2', '../results/oi2/llama-7b_sharegptv2_ep=2'),\n",
    "            ('llama-7b_sharegpt_ep=2', '../results/ft1_ep=2/llama-7b_sharegpt'),]\n",
    "    elif dataset == 'tulu_v1_mix':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "            # oi4_tulu_v1_mix_ep=3 models before transformers update.\n",
    "            # ('llama-7b_tuluv1m:50k_log_prob_decr_<10.16update', '../results/oi4_tulu_v1_mix_ep=3/llama-7b_tuluv1m:50k_log_prob_decr'),\n",
    "        ]\n",
    "    elif dataset == 'ultrafeedback':\n",
    "        exp_dir = f'../results/dpo1/'\n",
    "        save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "    else:\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=2', f'../results/oi2/llama-7b_{dataset}_ep=2'),]\n",
    "    \n",
    "    if finetune_type == 'sft':\n",
    "        exp_dir = f'../results/oi5_{dataset}:llama-7b'\n",
    "    elif finetune_type == 'pref':\n",
    "        exp_dir = f'../results/dpo2_{dataset}:llama-7b+sharegptv2ep2/'\n",
    "    save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'dppmapbd' not in x and 'semdedup' not in x]\n",
    "    \n",
    "    if finetune_type == 'pref':\n",
    "        sft_model_dataset = 'sharegptv2'\n",
    "        save_dirs += [('llama-7b_sharegptv2_ep=2', f'../results/oi2/llama-7b_{sft_model_dataset}_ep=2')]\n",
    "# ## just compare dppmap grad vs. text\n",
    "# save_dirs = [x for x in save_dirs if 'prune:size=10000:ep=10' in x[1] and (\n",
    "#         'random' in x[1] or \n",
    "#         'dppmap' in x[1]\n",
    "#     )\n",
    "# ]\n",
    "#####\n",
    "\n",
    "\n",
    "# ##### code instructions\n",
    "# save_dirs = [\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('codellama-7b', '../results/baselines/codellama/CodeLlama-7b-hf/'),\n",
    "#     ('codellama-7b-instruct', '../results/baselines/codellama/CodeLlama-7b-Python-hf/'),\n",
    "#     ('codellama-7b-python', '../results/baselines/codellama/CodeLlama-7b-Instruct-hf/'),\n",
    "# ]\n",
    "\n",
    "# exp_dir = '../results/oi2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'starcoder' in x]\n",
    "# exp_dir = '../results/oi6_starcoder_ep=5'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstr:codellama-7b'\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstrv2:codellama-7b'\n",
    "# exp_dir = '../results/oi5_starcoder_commentinstrv5:codellama-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "###### \n",
    "\n",
    "from llm.evaluate import detect_oom_evals\n",
    "oom_eval_paths = detect_oom_evals([x for l in [glob.glob(os.path.join(x[1], 'eval/*/*.out')) for x in save_dirs] for x in l])\n",
    "if oom_eval_paths: print(oom_eval_paths)\n",
    "    \n",
    "cols_avg_blacklist = ['AlpacaFarm/Len']\n",
    "\n",
    "# chat_fmt = False\n",
    "chat_fmt = True\n",
    "# chat_fmt = 'both'\n",
    "# chat_fmt = 'auto' # base model no chatfmt, tuned model with chatfmt\n",
    "# chat_fmt = 'mix'  # non-alpacaeval no chatfmt, alpacaeval chatfmt\n",
    "ft_args_fields = {\n",
    "    'run_name': ('run_name',),\n",
    "    'model_name_or_path': ('model_args.model_name_or_path', 'model_name_or_path'),\n",
    "    'subsample_mixture': ('data_args.subsample_mixture',),\n",
    "    'max_train_samples': ('data_args.max_train_samples', 'max_train_samples'),\n",
    "    'train_file': ('data_args.train_file', 'train_file'),\n",
    "}\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'TydiQA/GP', 'Codex-Eval/Pass@1']\n",
    "#     cols = ['MMLU/0-shot', 'GSM/Direct', 'BBH/Direct', 'TydiQA/CB', 'Codex-Eval/Pass@1']\n",
    "\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR']\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT']\n",
    "\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR']\n",
    "#     cols = ['MMLU/0-shot', 'GSM/CoT', 'BBH/CoT', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR']\n",
    "# cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1'] #  'ToxiGen/Acc'\n",
    "cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR*', 'AlpacaFarm/Len'] \n",
    "# cols = ['AlpacaFarm/WR', 'AlpacaFarm/ΔWR', 'AlpacaFarm/Len']\n",
    "# cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR*'] \n",
    "# cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR', 'AlpacaFarm/ΔWR', 'AlpacaFarm/Len'] \n",
    "\n",
    "\n",
    "# cols = [f'BBH {x}' for x in ['reasoning', 'nlu', 'knowledge', 'multilingual']]; cols = [x+'/Direct' for x in cols] + [x+'/CoT' for x in cols]\n",
    "# cols = [f'MMLU {x}' for x in ['STEM', 'humanities', 'social sciences', 'other']]; cols = [x+'/0-shot' for x in cols] + [x+'/5-shot' for x in cols]\n",
    "\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR', 'AlpacaFarm/Rep', 'AlpacaFarm/WR*'] #  'ToxiGen/Acc'\n",
    "#     cols = ['AlpacaFarm/WR', 'AlpacaFarm/Rep', 'AlpacaFarm/WR*']\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR'] #  entire, without tydiqa, which has high variance\n",
    "#     cols = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', ] #  entire, without tydiqa, which has high variance\n",
    "if 'open_orca_slim' in exp_dir:\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'BBH/Direct', 'BBH/CoT']\n",
    "    cols = ['MMLU/0-shot', 'BBH/Direct']\n",
    "if 'starcoder' in exp_dir:\n",
    "    cols = ['Codex-Eval/Pass@1']\n",
    "    chat_fmt = 'both'\n",
    "print(f'chat_fmt={chat_fmt}')\n",
    "df = get_eval_results(save_dirs, chat_fmt=chat_fmt, ft_args_fields=ft_args_fields, use_normalized_preferred_metric=use_normalized_preferred_metric)\n",
    "\n",
    "cols = [x for x in cols if x in df.columns]\n",
    "df = df[list(ft_args_fields.keys()) + cols]\n",
    "if chat_fmt == 'both':\n",
    "    for col_lvl2 in ['', 'chatfmt']:\n",
    "        df[('Average', col_lvl2)] = df[list(set(df.columns) & set([(x, col_lvl2) for x in list(set(cols)-set(cols_avg_blacklist))]))].mean(axis=1)\n",
    "else:\n",
    "    df['Average'] = df[list(set(cols)-set(cols_avg_blacklist))].mean(axis=1)\n",
    "if sort_rows:\n",
    "    df = pd_sort_rows_by_avg_ranking(df); df['ranking'] = -df['ranking']\n",
    "    sort_value_col, sort_value_col_ascending = ('Average', 'chatfmt') if chat_fmt=='both' else 'Average', False\n",
    "#     sort_value_col, sort_value_col_ascending = 'ranking', False\n",
    "    df = df.sort_values(by=sort_value_col, ascending=sort_value_col_ascending)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def compute_total_train_samples(x):\n",
    "    match = re.search(r'size=(\\d+)', x['run_name' if chat_fmt!='both' else ('run_name', '')])\n",
    "    total_train_samples = match.group(1) if match else None\n",
    "    return total_train_samples\n",
    "df.insert(1, 'total_train_samples' if chat_fmt!='both' else ('total_train_samples', ''), df.apply(compute_total_train_samples, axis=1))\n",
    "def extract_dataset_from_train_file(x):\n",
    "    if x is None: return None\n",
    "    x = x.split('/')[-1].split('.jsonl')[0]\n",
    "    if x.endswith('_data'): x = x[:-5]\n",
    "    if x.endswith('_train'): x = x[:-6]\n",
    "    return x\n",
    "df.insert(1, 'dataset' if chat_fmt!='both' else ('dataset', ''), df['train_file'].apply(extract_dataset_from_train_file))\n",
    "df = df.drop('train_file', axis=1)\n",
    "\n",
    "if any(exp_dir.endswith(x) for x in ['ft2']):\n",
    "#     for model_name_contain in ['gpt2', 'llama', 'pythia-1.4b']:\n",
    "#         for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "    for model_name_contain in ['llama']:\n",
    "        for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "#         for total_train_samples in [200000, 400000, 600000]:\n",
    "            dfc = df.copy()\n",
    "            dfc.insert(0, 'total_train_samples',  dfc['subsample_mixture'].apply(\n",
    "                lambda d: sum(list(d.values())) if d else 200000))\n",
    "            dfc = dfc[dfc['total_train_samples'].apply(\n",
    "                lambda x: total_train_samples-20000<x<total_train_samples+20000)]\n",
    "            dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "                lambda x: model_name_contain in x)]\n",
    "            dfc['total_train_samples'] = dfc['total_train_samples'].astype(str)\n",
    "            dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture'])\n",
    "            dfc = dfc.reset_index(drop=True)\n",
    "            if len(dfc):\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .format(precision=2))\n",
    "else:\n",
    "    for model_name_contain in ['llama', 'pythia-1.4b', 'mistral', 'zephyr']:\n",
    "        dfc = df.copy()\n",
    "        dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "            lambda x: model_name_contain in x.lower())]\n",
    "        if not len(dfc): continue\n",
    "        from rosemary import pd_average_col_contains_substr\n",
    "        Ns = sorted(np.unique([int(x) for x in df['total_train_samples'].to_numpy() if x]).tolist())\n",
    "        datasets = sorted(np.unique(df['dataset']).tolist())\n",
    "        for N in Ns+[None]:\n",
    "            for dataset in datasets:\n",
    "                dfc = df.copy()\n",
    "                dfc = dfc[dfc['total_train_samples'].apply(lambda x: int(x) == N if x else True)]\n",
    "                dfc = dfc[dfc['dataset'].apply(lambda x: x == dataset if x else True)]\n",
    "                if not len(dfc): continue\n",
    "                col_runname = 'run_name' if chat_fmt != 'both' else ('run_name', '')\n",
    "                substitute = True\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, '_random_', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=10000:ep=10', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=50000:ep=5', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=3', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=1', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=100000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=200000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=400000', substitute=substitute)\n",
    "                #     dfc = dfc.sort_values(['ranking'], ascending=False)\n",
    "                col = ('Average', 'chatfmt') if chat_fmt == 'both' else 'Average'\n",
    "            #     col = 'AlpacaFarm/WR'\n",
    "            #     col = 'MMLU/0-shot'|\n",
    "            #     col = 'GSM/CoT'\n",
    "            #     col = 'BBH/Direct'\n",
    "            #     col = 'TydiQA/GP'\n",
    "                dfc = dfc.sort_values(by=[col], ascending=False)\n",
    "                dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture', 'max_train_samples', 'dataset'], \n",
    "                               axis=1, level=0 if chat_fmt=='both' else None)\n",
    "                dfc = dfc.reset_index(drop=True)\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .applymap(lambda x: f'max-width: 60ch;', subset=['run_name'])\n",
    "                        .set_table_styles([{'selector': 'td', 'props': [('white-space', 'pre-wrap'), ('word-wrap', 'break-word')]}])\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .applymap(lambda x: 'text-decoration: underline;' \\\n",
    "                                  if x in dfc[list(set(dfc.columns) & set([(x, '') for x in cols]))+[col] if chat_fmt=='both' else cols+[col]].values.flatten() and chat_fmt=='both' else '')\n",
    "                        .format(precision=1))\n",
    "\n",
    "# llama-7b_tulu_v1_mix(paper)\n",
    "# MMLU/0-shot, MMLU/5-shot, GSM/Direct, GSM/CoT, BBH/Direct, BBH/CoT, TydiQA/GP, TydiQA/CB, CodexEval/Pass@1, AlpacaEval(vs.Davinci-003)\n",
    "# 44.8       , 47.1       , 7.0       , 25.0   , 38.5      , 38.5   , 43.5,    , 8.0      , 18.6,           , 48.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "deeba0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n",
      "{0: 'dppmap', 'k': 'rbf', 'gamma': 0.001, 'kmd': 'llama7br512p4096', 'kemb': 'text+embedding'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['run_name',\n",
       " 'nonchat',\n",
       " 'sort_by',\n",
       " 'total_train_samples',\n",
       " 'model_name_or_path',\n",
       " 'subsample_mixture',\n",
       " 'max_train_samples',\n",
       " 'MMLU/0-shot',\n",
       " 'MMLU/5-shot',\n",
       " 'GSM/Direct',\n",
       " 'GSM/CoT',\n",
       " 'BBH/Direct',\n",
       " 'BBH/CoT',\n",
       " 'TydiQA/CB',\n",
       " 'TydiQA/GP',\n",
       " 'Codex-Eval/Pass@1',\n",
       " 'AlpacaFarm/WR*',\n",
       " 'AlpacaFarm/Len',\n",
       " 'Average',\n",
       " 'ranking']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rosemary import parse_kv_from_string\n",
    "\n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', ]\n",
    "\n",
    "def compute_nonchateval_average_performance(row):\n",
    "    L = [row[k] for k in non_chateval_task_names if k in row]\n",
    "    return np.average(L)\n",
    "\n",
    "def parse_prune_subset_size(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'(?<=pace=)([^_]+)', run_name)\n",
    "    if match:\n",
    "        pace = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(pace)\n",
    "        return int(kvs['size'] / kvs['ep'])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_sort_by_from_run_name(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'score=([^_]+)', run_name)\n",
    "    if match:\n",
    "        sort_by = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(sort_by)\n",
    "    else:\n",
    "        kvs = {}\n",
    "    return kvs\n",
    "\n",
    "\n",
    "def parse_sort_by_type(row):\n",
    "    d = row['sort_by']\n",
    "    if 'gamma' in d:\n",
    "        if d['gamma'] == 1e-3:\n",
    "            print(d)\n",
    "    if not d:\n",
    "        return None\n",
    "    if d[0] == 'dppmap':\n",
    "        if d['k']=='vmf' and d['kmd']=='mpnet': #and (d['gamma']==1 or d['gamma'] == 'auto1000'):\n",
    "            return 'vmf+text'\n",
    "        elif d['k']=='rbf' and d['kemb']=='text+embedding' and d['kmd'] == 'llama7br512p4096':\n",
    "            return f\"rbf+text_gamma={d['gamma']}\"\n",
    "        elif d['k']=='vmf' and d['kemb']=='grad+rp+loraB' and d['kmd'] == 'llama7br512p4096':\n",
    "            return f\"vmf+grad_gamma={d['gamma']}\"\n",
    "        else:\n",
    "            return None\n",
    "    elif d[0] == 'random':\n",
    "        return 'random'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "dfc.insert(1, 'sort_by' if chat_fmt!='both' else ('sort_by', ''), dfc.apply(parse_sort_by_from_run_name, axis=1))\n",
    "dfc.insert(1, 'sort_by_type' if chat_fmt!='both' else ('sort_by_type', ''), dfc.apply(parse_sort_by_type, axis=1))\n",
    "dfc.insert(1, 'subset_size' if chat_fmt!='both' else ('subset_size', ''), dfc.apply(parse_prune_subset_size, axis=1))\n",
    "dfc.insert(1, 'nonchat' if chat_fmt!='both' else ('nonchat', ''), dfc.apply(compute_nonchateval_average_performance, axis=1))\n",
    "\n",
    "\n",
    "dfc = dfc[dfc['sort_by_type'].notnull()]\n",
    "startswithstrs = ('rbf+text', 'random')\n",
    "startswithstrs = ('rbf+text_gamma=0.001', 'random', 'vmf+grad_gamma=1')\n",
    "dfc = dfc[dfc.apply(lambda x: x['sort_by_type'].startswith(startswithstrs)\n",
    "                   , axis=1)]\n",
    "dfc['subset_size'] = dfc['subset_size'].apply(lambda x: int(x) if x else x)\n",
    "dfc = dfc[dfc['subset_size']<=10_000]\n",
    "\n",
    "\n",
    "D = dfc.set_index(['sort_by_type', 'dataset', 'subset_size']).to_dict()\n",
    "from dataclasses import dataclass\n",
    "@dataclass(unsafe_hash=True)\n",
    "class DKey:\n",
    "    sort_by_type: str\n",
    "    dataset: str\n",
    "    subset_size: int\n",
    "def convert_key_to_dataclass(d):\n",
    "    return {DKey(*k): v for k, v in d.items()}\n",
    "D = {k: convert_key_to_dataclass(v) for k, v in D.items()}\n",
    "\n",
    "list(D.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "662539cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 21 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "yaxis_type = 'abs'\n",
    "assert(yaxis_type in ['delta_random', 'abs'])\n",
    "datasets = ['flan_v2', 'dolly', 'stanford_alpaca', 'oasst1', 'ultrachat200kv2', 'wizardlmv2', 'sharegptv2']\n",
    "task_names = ['MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR*',]\n",
    "task_names = ['nonchat', 'AlpacaFarm/WR*', 'AlpacaFarm/Len',]\n",
    "# task_names = ['AlpacaFarm/WR*',]\n",
    "\n",
    "\n",
    "ncols = len(datasets)\n",
    "nrows = len(task_names)\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(2*ncols,2*nrows), sharey='row', sharex=True)\n",
    "\n",
    "xs_possible = []\n",
    "\n",
    "for axi, task_name in enumerate(task_names):\n",
    "    d = D[task_name]\n",
    "    for axj, dataset in enumerate(datasets):\n",
    "        ax = axs.reshape(nrows, ncols)[axi, axj]\n",
    "        sort_by_types = sorted(set(x.sort_by_type for x in d.keys()))\n",
    "\n",
    "        for i, sort_by_type in enumerate(sort_by_types):\n",
    "            xs = sorted([x.subset_size for x in d.keys()\n",
    "                         if x.dataset == dataset and x.sort_by_type==sort_by_type])\n",
    "            xs_possible += list(set(xs) - set(xs_possible))\n",
    "            ys = [d[DKey(sort_by_type, dataset, x)] for x in xs]\n",
    "            if yaxis_type == 'delta_random':\n",
    "                ys = [y-d[DKey('vmf+grad+gamma=1', dataset, x)] for x, y in zip(xs, ys)] \n",
    "            ax.plot(xs, ys, 'o-', label=sort_by_type)\n",
    "        \n",
    "#         ax.set_yscale('log')\n",
    "            \n",
    "for axi, task_name in enumerate(task_names):\n",
    "    axs.reshape(nrows, ncols)[axi, 0].set_ylabel('△ '+task_name if yaxis_type.startswith('delta') else task_name, fontsize=13)\n",
    "    axs.reshape(nrows, ncols)[axi, -1].legend(loc='center left', bbox_to_anchor=(1.1, 0.5))\n",
    "for axj, dataset in enumerate(datasets):\n",
    "    axs.reshape(nrows, ncols)[0, axj].set_title(dataset, fontsize=15)\n",
    "    axs.reshape(nrows, ncols)[0, axj].set_xticks(xs_possible, xs_possible)\n",
    "\n",
    "space = 0.05\n",
    "fig.subplots_adjust(wspace=space, hspace=space)  # Adjust the value as needed\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa5fdb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02, 0.1 , 0.2 , 0.4 , 0.8 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.array([1_000, 5_000, 10_000, 20_000, 40_000])\n",
    "xs/50_000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
