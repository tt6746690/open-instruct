{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3da1794b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'x86_64', 'cluster': 'ccc', 'queue': 'alt_7d'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "import re\n",
    "from llm.submit import (\n",
    "    multiline_to_singleline,\n",
    "    submit_job_ccc,\n",
    "    submit_job_aimos,\n",
    "    submit_job,\n",
    "        get_run_statistics)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import datetime\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import base64\n",
    "string_to_alphanumeric = lambda s: base64.urlsafe_b64encode(s.encode('utf-8')).decode('utf-8')\n",
    "alphanumeric_to_string = lambda a: base64.urlsafe_b64decode(a).decode('utf-8')\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm, shell_scripts_template_lsf, get_host_info, move_lsf_job_summary_to_save_dir\n",
    "from note_pruning_analysis import open_instruct_dir\n",
    "import getpass\n",
    "\n",
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "info = get_host_info()\n",
    "info.update({'queue': queue})\n",
    "arch, cluster = info['arch'], info['cluster']\n",
    "print(info)\n",
    "\n",
    "os.environ['TORCHELASTIC_ERROR_FILE'] = os.path.join(os.getcwd(), 'torchelastic_error_file') \n",
    "\n",
    "## jobs submitted in notebook inherits env variables.\n",
    "cache_dir = os.path.normpath(os.path.join(os.getcwd(), '../../../../mitibm2023/cache')) \\\n",
    "    if arch == 'ppc64le' else '/dccstor/data-pruning/cache'\n",
    "os.environ['WANDB_DIR'] = cache_dir\n",
    "os.makedirs(os.environ['WANDB_DIR'], exist_ok=True, mode=0o777)\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_PROJECT'] = 'mitibm'\n",
    "##\n",
    "##\n",
    "\n",
    "shell_scripts_template = shell_scripts_template_slurm \\\n",
    "    if arch == 'ppc64le' else shell_scripts_template_lsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c421d1",
   "metadata": {},
   "source": [
    "# DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c09b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/oi2/llama-7b_sharegptv2_ep=2 using 6 GPUs, 1 batch size per GPU, 1 gradient accumulation steps, 30 effective batch size.\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp7pssto1b', 'job_id': 1354503}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2p8zx1bt', 'job_id': 1354504}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2_mpillk', 'job_id': 1354505}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm\n",
    "debug = False\n",
    "if debug:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'INFO'\n",
    "    os.environ['NCCL_DEBUG'] = 'INFO'\n",
    "else:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'WARNING'\n",
    "    os.environ['NCCL_DEBUG'] = ''\n",
    "num_cpus = 144 if arch == 'ppc64le' else 32\n",
    "cpu_mem =  650 if arch == 'ppc64le' else 64\n",
    "\n",
    "preprocessing_num_workers = 32\n",
    "report_to = 'wandb'\n",
    "mixed_precision = 'bf16' if arch == 'x86_64' else 'fp16'\n",
    "torch_dtype = 'bfloat16' if arch=='x86_64' else 'float32'\n",
    "gradient_checkpointing = True\n",
    "use_fast_tokenizer = True\n",
    "hf_models_dir = 'results/baselines/'\n",
    "resume_from_checkpoint = True # resume from latest checkpoint if exists, otherwise train from scratch\n",
    "num_train_epochs = 2\n",
    "checkpointing_steps = 300 # (50_000 / 32) * 2 / 6 ~= 500 (data size of 50k, bsz=32, ep=2, total save 6 times at most)\n",
    "max_train_steps = None\n",
    "subsample_inds_file_list = [None]\n",
    "dataloader_sampler = 'RandomSampler'\n",
    "overwrite_cache = True\n",
    "\n",
    "\n",
    "# #####\n",
    "# job_name = 'dpo1'\n",
    "\n",
    "# # model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-410m-deduped'; max_seq_length = 2048; abbr_model_name = 'pythia-410m'\n",
    "# # model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "\n",
    "# train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "\n",
    "\n",
    "# M = 60_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 20_000\n",
    "# M = 50_000; pacing_fn_list = [f'prune_size={M}_ep=5']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "    (10_000, 10),\n",
    "#     (30_000, 3),\n",
    "]]\n",
    "\n",
    "gen_output_md = 'llama7br512p4096'\n",
    "# gen_output_md = 'llama7b+sharegptv2ep2+r512p4096'\n",
    "# gen_output_model_name = 'all-mpnet-base-v2'\n",
    "\n",
    "scoring_fn_list = []\n",
    "scoring_fn_list += ['random_s=0']\n",
    "# scoring_fn_list += ['random_s=1']\n",
    "scoring_fn_list += [ \n",
    "    f'dppmap_k=vmf_gamma=1_kmd={gen_output_md}_kemb=grad+rp+loraB',\n",
    "    f'dppmap_k=rbf_gamma=1e-3_kmd={gen_output_md}_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1_kmd=mpnet_kemb=text+embedding',\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'dpo2_{dataset}:{abbr_model_name}'\n",
    "    \n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12\n",
    "# nodes = 2; num_gpus = 1; gpu_type = 'v100'; job_duration = 6; cpu_mem = 100; num_cpus = 32; max_train_steps = 5; checkpointing_steps = 2; report_to = 'tensorboard'\n",
    "    \n",
    "#####\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs = 1 # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "use_deepspeed = True\n",
    "deepspeed_config_file = 'ds_configs/stage3_no_offloading_accelerate.conf'\n",
    "\n",
    "per_device_train_batch_size = 1; total_batch_size = 32\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"{effective_batch_size} effective batch size.\")\n",
    "\n",
    "# reference: https://gist.github.com/pacman100/1cb1f17b2f1b3139a63b764263e70b25\n",
    "launcher = f\"\"\"accelerate launch \\\n",
    "    --mixed_precision {mixed_precision} \\\n",
    "    --num_machines {nodes} \\\n",
    "    --num_processes {num_gpus*nodes} \\\n",
    "    {'--use_deepspeed' if use_deepspeed else ''} \\\n",
    "    {'--deepspeed_config_file '+deepspeed_config_file if use_deepspeed else ''} \\\n",
    "    {'--main_process_ip $master_addr' if use_deepspeed else ''} \\\n",
    "    {'--main_process_port $master_port' if use_deepspeed else ''} \\\n",
    "    {'--machine_rank $SLURM_PROCID' if use_deepspeed else ''} \\\n",
    "    {'--rdzv_backend c10d' if use_deepspeed and nodes>1 else ''} \\\n",
    "    {'--deepspeed_multinode_launcher standard' if use_deepspeed and nodes>1 else ''} \\\n",
    "\"\"\"\n",
    "\n",
    "cmds = []\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    subsample_inds_file_list,\n",
    ")\n",
    "\n",
    "output_dirname_list = []\n",
    "for (subsample_inds_file,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{dataset}\"\n",
    "    if any(job_name == y for y in ['dpo1']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "\n",
    "    if subsample_inds_file:\n",
    "        assert(num_train_epochs==1)\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                s = f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "\n",
    "    if subsample_inds_file is not None:\n",
    "        assert(dataloader_sampler=='SequentialSampler')\n",
    "        assert(num_train_epochs==1)\n",
    "    else:\n",
    "        assert(dataloader_sampler=='RandomSampler')\n",
    "\n",
    "    output_dir = os.path.join('results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join('results', job_name), exist_ok=True)\n",
    "    wandb_run_name = output_dir.replace('results/', '')\n",
    "\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {f'cd .. && CUDA_VISIBLE_DEVICES={os.environ[\"CUDA_VISIBLE_DEVICES\"]} ' if test_run else ''}{launcher}\n",
    "        open_instruct/dpo_tune.py \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --tokenizer_name {model_name_or_path} \\\n",
    "        {'--use_slow_tokenizer' if not  use_fast_tokenizer else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        --train_file {train_file} \\\n",
    "        --max_seq_length {max_seq_length} \\\n",
    "        {'--subsample_inds_file '+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        --dataloader_sampler {dataloader_sampler} \\\n",
    "        --preprocessing_num_workers {preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size {per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
    "        --learning_rate 5e-7 \\\n",
    "        --lr_scheduler_type linear \\\n",
    "        --warmup_ratio 0.1 \\\n",
    "        --weight_decay 0. \\\n",
    "        --num_train_epochs {num_train_epochs} \\\n",
    "        --with_tracking \\\n",
    "        {'--report_to \"'+str(report_to)+'\"' if report_to else ''} \\\n",
    "        --checkpointing_steps {checkpointing_steps} \\\n",
    "        {'--max_train_steps '+str(max_train_steps) if max_train_steps else ''} \\\n",
    "        {'--resume_from_checkpoint' if resume_from_checkpoint else ''} \\\n",
    "        {'--low_cpu_mem_usage' if not use_deepspeed else ''} \\\n",
    "        {'--overwrite_cache' if overwrite_cache else ''} \\\n",
    "        --logging_steps 1 \\\n",
    "        --output_dir {output_dir}\n",
    "    \"\"\"\n",
    "    # if test_run:\n",
    "    #     print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    if test_run:\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64': # ccc\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "        queue=queue,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda1f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prune: {1k@10, 10k@3}, datasets={dolly, stanford_alpaca}, scoring={random, dppmapx2}\n",
    "# need to gen curriculum for 50k sft datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b79b9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_dpo.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce604bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=5\n",
      "+ cd ..\n",
      "+ CUDA_VISIBLE_DEVICES=2,5\n",
      "+ accelerate launch --mixed_precision fp16 --num_machines 1 --num_processes 2 --use_deepspeed --deepspeed_config_file ds_configs/stage3_no_offloading_accelerate.conf open_instruct/dpo_tune.py --model_name_or_path results/baselines/huggyllama/llama-7b --tokenizer_name results/baselines/huggyllama/llama-7b --gradient_checkpointing --train_file data/processed/ultrafeedback/ultrafeedback_data.jsonl --max_seq_length 2048 --preprocessing_num_workers 32 --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --learning_rate 5e-7 --lr_scheduler_type linear --warmup_ratio 0.1 --weight_decay 0. --num_train_epochs 2 --with_tracking --report_to tensorboard --checkpointing_steps 500 --logging_steps 1 --output_dir results/dpo1/jpt_llama-7b_ultrafeedback\n",
      "[2024-01-08 20:41:08,547] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "[2024-01-08 20:41:17,396] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-08 20:41:17,400] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:662:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,611] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 1\n",
      "Local process index: 1\n",
      "Device: cuda:1\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 251.17it/s]\n",
      "01/08/2024 20:41:25 - WARNING - datasets.builder - Found cached dataset json (/gpfs/u/scratch/PTFM/PTFMqngp/huggingface_cache/datasets/json/default-201ebfceee303348/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 252.78it/s]\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:26,493] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 6.74B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.74s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:16<00:00,  8.11s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:43,556] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 13.48B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.60s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "01/08/2024 20:42:20 - INFO - accelerate.accelerator - Updating DeepSpeed's gradient accumulation steps to 16 from 1.\n",
      "[2024-01-08 20:42:20,382] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.1+23a11a39, git-hash=23a11a39, git-branch=master\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 1\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "[2024-01-08 20:42:20,751] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n",
      "[2024-01-08 20:42:20,779] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\n",
      "[2024-01-08 20:42:20,891] [INFO] [utils.py:786:see_memory_usage] Stage 3 initialize beginning\n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 14.16 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.9 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:118:__init__] Reduce bucket size 16777216\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:119:__init__] Prefetch bucket size 15099494\n",
      "[2024-01-08 20:42:20,995] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 13.64 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n",
      "[2024-01-08 20:42:21,139] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.76 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:21,240] [INFO] [utils.py:786:see_memory_usage] Before creating fp16 partitions\n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.4 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:23,090] [INFO] [utils.py:786:see_memory_usage] After creating fp16 partitions: 4\n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.4 GB         CA 14.6 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.99 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,190] [INFO] [utils.py:786:see_memory_usage] Before creating fp32 partitions\n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.39 GB         CA 14.6 GB         Max_CA 15 GB \n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.81 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,742] [INFO] [utils.py:786:see_memory_usage] After creating fp32 partitions\n",
      "[2024-01-08 20:42:23,743] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 26.61 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,744] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 116.15 GB, percent = 16.7%\n",
      "[2024-01-08 20:42:23,836] [INFO] [utils.py:786:see_memory_usage] Before initializing optimizer states\n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 25.94 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 117.28 GB, percent = 16.8%\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 1; 31.75 GiB total capacity; 25.93 GiB already allocated; 3.34 GiB free; 27.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 0; 31.75 GiB total capacity; 25.94 GiB already allocated; 3.21 GiB free; 27.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 409110) of binary: /gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/python3.10\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 964, in launch_command\r\n",
      "    deepspeed_launcher(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 687, in deepspeed_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "open_instruct/dpo_tune.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 409111)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 409110)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_dpo.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c8b",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune_trainer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "19aebd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/baselines/huggyllama/llama-7b using 8 GPUs, 1 batch size per GPU, 16 gradient accumulation steps, Effective batch size 128\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 128,\n",
      "    \"cpu_mem\": 768,\n",
      "    \"num_gpus\": 8,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_wizardlm50k:llama-7b -mem 768g -cores 1x128+8 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=8 --rdzv_backend=c10d --master_port=0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/wizardlm/wizardlm50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=16 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/wizardlm50k/random_s=0/inds_prune_size=60000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=60000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1395067}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 128,\n",
      "    \"cpu_mem\": 768,\n",
      "    \"num_gpus\": 8,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_wizardlm50k:llama-7b -mem 768g -cores 1x128+8 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=8 --rdzv_backend=c10d --master_port=0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/wizardlm/wizardlm50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=16 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/wizardlm50k/dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding/inds_prune_size=60000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1395068}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_wizardlm50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 128,\n",
      "    \"cpu_mem\": 768,\n",
      "    \"num_gpus\": 8,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_wizardlm50k:llama-7b -mem 768g -cores 1x128+8 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=8 --rdzv_backend=c10d --master_port=0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/wizardlm/wizardlm50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=16 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/wizardlm50k/dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB/inds_prune_size=60000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1395069}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "add_hardwarespec_to_dirname = False\n",
    "save_strategy = 'steps'\n",
    "save_steps = 200 if getpass.getuser() in ('PTFMqngp', 'wpq') else 1_000_000\n",
    "save_total_limit = 1\n",
    "preprocessing_num_workers = 32\n",
    "evaluation_strategy = 'no' # set do_eval=False\n",
    "eval_steps = save_steps\n",
    "report_to = 'tensorboard wandb'\n",
    "suffix = None\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0.03\n",
    "dataloader_sampler = None\n",
    "hf_models_dir = 'results/baselines/'\n",
    "subsample_inds_file_list = [None]\n",
    "max_train_samples_list = [None]\n",
    "num_train_epochs_list = [1]\n",
    "scoring_fn_and_pacing_fn = None\n",
    "\n",
    "\n",
    "# ########### sft baselines\n",
    "\n",
    "\n",
    "# job_name = 'oi2'; num_train_epochs_list = [2] \n",
    "# # model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "\n",
    "# # train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca'; \n",
    "# # train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# # train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2'; max_train_samples_list=[100_000]\n",
    "\n",
    "# ## 50k sft datasets\n",
    "# # train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# # train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# # train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "# # train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "\n",
    "# # train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2'; max_train_samples_list=[100_000]\n",
    "# ###########\n",
    "\n",
    "\n",
    "############ pruning runs\n",
    "\n",
    "# model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048; gen_output_md = 'mistral7br512p4096'\n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048; gen_output_md = 'llama7br512p4096'\n",
    "\n",
    "\n",
    "# # 50k sft datasets\n",
    "# dataset = 'flan_v250k'; train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca50k'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "dataset = 'wizardlm50k'; train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "# dataset = 'sharegpt50k'; train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "# dataset = 'ultrachat50k'; train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "\n",
    "# dataset = 'flan_v2'; train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca';\n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# dataset = 'wizardlmv2'; train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2';\n",
    "# dataset = 'sharegptv2'; train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2';\n",
    "# dataset = 'ultrachat200kv2'; train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2';\n",
    "\n",
    "\n",
    "# dataset = 'oasst1'; train_file = 'data/processed/oasst/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# dataset = 'open_orca_slim'; train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; \n",
    "# dataset = 'tulu_v2'; train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2';\n",
    "        \n",
    "# M = 80_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 40_000\n",
    "# M = 40_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 20_000\n",
    "# M = 30_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [\n",
    "    f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "#         (10_000, 10), # 1k\n",
    "#         (30_000, 3),  # 10k\n",
    "        (60_000, 3),  # 20k\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "scoring_fn_list = [\n",
    "    'random_s=0',\n",
    "#     'random_s=1',\n",
    "#     'log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n',\n",
    "#     'ifd_neg', 'log_pmi_neg',\n",
    "#     'numtoks_input_neg', 'numtoks_output_neg', 'numtoks_total_neg',\n",
    "#     f'dppmap_k=vmf_gamma=1_kmd=mpnet', #_kemb=text+embedding',\n",
    "    f'dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding',\n",
    "    f'dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB',\n",
    "]\n",
    "\n",
    "scoring_fn_list += [ # vary kernel embedding model \n",
    "#     f'dppmap_k=vmf_gamma=auto{subset_size}_kmd={kmd}_kemb=grad+rp+loraB'\n",
    "#     for kmd in ['llama7br256p4096', 'llama7br512p4096', 'pythia1br512p4096']\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'oi5_{dataset}:{abbr_model_name}'\n",
    "############ \n",
    "\n",
    "    \n",
    "# add_hardwarespec_to_dirname = True\n",
    "# job_name += '_debug' # wpq debug\n",
    "# max_train_samples_list=[128*2]\n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "debug_mode = test_run\n",
    "\n",
    "if arch == 'x86_64':\n",
    "    nodes = 1; num_gpus = 8; gpu_type = 'a100_80gb'; job_duration = 6\n",
    "    num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus); preprocessing_num_workers = 128 # tok takes quite a bit.\n",
    "    per_device_train_batch_size = 1\n",
    "    gradient_checkpointing = False\n",
    "    mixed_precision = 'bf16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = True \n",
    "    save_model_torch_dtype = 'bfloat16' # typically save fp32 weights, but for disk space sake, convert to bf16.\n",
    "else:\n",
    "    nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_checkpointing = True\n",
    "    mixed_precision = 'fp16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = False\n",
    "    save_model_torch_dtype = None\n",
    "\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs_list = [1] # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "overwrite_output_dir = True if test_run else False # always continue from ckpt if run from cluster.\n",
    "\n",
    "total_batch_size = 128\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "optimizer = 'adamw_hf'\n",
    "\n",
    "deepspeed = ''; fsdp = False if num_gpus == 1 else \"full_shard auto_wrap\" \n",
    "if 'gpt2' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPT2Block'\n",
    "elif 'llama' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'LlamaDecoderLayer'\n",
    "elif 'mpt' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MPTBlock'\n",
    "elif 'pythia' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPTNeoXLayer'        \n",
    "elif 'mistral' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MistralDecoderLayer'\n",
    "else: raise ValueError('Not sure how to set `fsdp_transformer_layer_cls_to_wrap`')\n",
    "    \n",
    "# deepspeed = './ds_configs/ds_zero3_cpu_offload.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/ds_zero3.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/stage3_no_offloading.conf'; fsdp = False # error with loading... something wrong with the config.\n",
    "# fsdp = False; deepspeed = False\n",
    "\n",
    "if fsdp and deepspeed:\n",
    "    raise ValueError('either fsdp or deepspeed, not both')\n",
    "\n",
    "use_lora = False\n",
    "lora_rank = 256 \n",
    "lora_alpha = lora_rank \n",
    "lora_dropout = 0.05\n",
    "if use_lora:\n",
    "    abbr_model_name += f'+lora(r={lora_rank},a={lora_alpha})'\n",
    "load_in_8bit = False\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"Effective batch size {effective_batch_size}\")\n",
    "\n",
    "\n",
    "if nodes == 1:\n",
    "    exe = 'python' if num_gpus==1 else \\\n",
    "        f\"torchrun --nnodes 1 --nproc_per_node={num_gpus} --rdzv_backend=c10d --master_port=0\" # assigns random port. https://github.com/pytorch/pytorch/issues/73320\n",
    "else:\n",
    "    exe = f\"torchrun --nnodes={nodes} --nproc_per_node={num_gpus} --rdzv-id=${'SLURM_JOB_ID' if arch == 'ppcle64' else 'LSB_JOBID'} --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT\"\n",
    "\n",
    "if test_run:\n",
    "    exe = f\"CUDA_VISIBLE_DEVICES={','.join(map(str, range(num_gpus)))} {exe}\"\n",
    "if test_run and debug_mode:\n",
    "    exe = 'TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO ' + exe\n",
    "    error_file = os.path.join(open_instruct_dir, 'scripts', 'error_file')\n",
    "    exe = f'TORCHELASTIC_ERROR_FILE={error_file} {exe}'\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "options_list = itertools.product(\n",
    "    num_train_epochs_list,\n",
    "    subsample_inds_file_list,\n",
    "    max_train_samples_list,\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "output_dirname_list = []\n",
    "for (num_train_epochs,\n",
    "     subsample_inds_file,\n",
    "     max_train_samples,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{abbr_train_file}\"\n",
    "    if max_train_samples:\n",
    "        output_dirname += f\":{int(max_train_samples/1000)}k\"\n",
    "            \n",
    "    if any(job_name == y for y in ['oi2']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "        \n",
    "    if subsample_inds_file:\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                return f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            else:\n",
    "                return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "            \n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "            \n",
    "    if add_hardwarespec_to_dirname:\n",
    "        output_dirname += \\\n",
    "            ('_fsdp='+fsdp.split(' ')[0] if fsdp else '')+\\\n",
    "            ('_deepspeed='+os.path.basename(deepspeed).split('.')[0] if deepspeed else '')+\\\n",
    "            ('_gradckpt='+str(gradient_checkpointing) if gradient_checkpointing else '')+\\\n",
    "            '_mbsz='+str(per_device_train_batch_size)+\\\n",
    "            ('_dtype='+torch_dtype if torch_dtype is not None else '')+\\\n",
    "            ('_mp='+str(mixed_precision) if mixed_precision else '_mp=none')+\\\n",
    "            '_seqlen='+str(max_seq_length)+\\\n",
    "            '_nodes='+str(nodes)+\\\n",
    "            '_ngpus='+str(num_gpus)+\\\n",
    "            ('_fa2' if use_flash_attn else '')\n",
    "    if suffix:\n",
    "        output_dirname += suffix\n",
    "    output_dir = os.path.join(open_instruct_dir, 'results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join(open_instruct_dir, 'results', job_name), exist_ok=True)\n",
    "    if arch == 'x86_64':\n",
    "        wandb_run_name = 'ccc'+output_dir[output_dir.find('results'):][7:] # e.g., ccc/oi2/run_name\n",
    "    else:\n",
    "        wandb_run_name = output_dir.replace('results/', '') # e.g., oi2/run_name\n",
    "    \n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {'cd .. && ' if test_run else ''}{exe}\n",
    "        open_instruct/finetune_trainer.py \\\n",
    "        --model_name_or_path={model_name_or_path} \\\n",
    "        --tokenizer_name={model_name_or_path} \\\n",
    "        {'--load_in_8bit' if load_in_8bit else ''} \\\n",
    "        --use_fast_tokenizer=True \\\n",
    "        --train_file={train_file} \\\n",
    "        --max_seq_length={max_seq_length} \\\n",
    "        {'--max_train_samples='+str(max_train_samples) if max_train_samples else ''} \\\n",
    "        {'--use_lora' if use_lora else ''} \\\n",
    "        {'--lora_rank='+str(lora_rank) if use_lora else ''} \\\n",
    "        {'--lora_alpha='+str(lora_alpha) if use_lora else ''} \\\n",
    "        {'--lora_dropout='+str(lora_dropout) if use_lora else ''} \\\n",
    "        --do_train \\\n",
    "        --preprocessing_num_workers={preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size={per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
    "        --learning_rate=2e-5 \\\n",
    "        --lr_scheduler_type={lr_scheduler_type} \\\n",
    "        --warmup_ratio={warmup_ratio} \\\n",
    "        --weight_decay=0. \\\n",
    "        --optim={optimizer} \\\n",
    "        --evaluation_strategy={evaluation_strategy} \\\n",
    "        {'--eval_steps='+str(eval_steps) if eval_steps else ''} \\\n",
    "        {'--report_to '+str(report_to) if report_to else ''} \\\n",
    "        --run_name {wandb_run_name} \\\n",
    "        --logging_strategy=steps \\\n",
    "        --logging_first_step \\\n",
    "        --logging_steps=1 \\\n",
    "        --save_strategy={save_strategy} \\\n",
    "        --save_steps={save_steps} \\\n",
    "        --save_total_limit={save_total_limit} \\\n",
    "        --num_train_epochs={num_train_epochs} \\\n",
    "        --ddp_timeout=7200 \\\n",
    "        {'--fsdp=\"'+fsdp+'\"' if fsdp else ''} \\\n",
    "        {'--fsdp_transformer_layer_cls_to_wrap=\"'+fsdp_transformer_layer_cls_to_wrap+'\"' \n",
    "            if fsdp else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        {'--torch_dtype='+str(torch_dtype) if torch_dtype else ''} \\\n",
    "        {'--save_model_torch_dtype='+str(save_model_torch_dtype) if save_model_torch_dtype else ''} \\\n",
    "        --dataloader_num_workers=8 \\\n",
    "        {f'--{mixed_precision}=True' if mixed_precision else ''} \\\n",
    "        {f'--tf32=True' if use_tf32 else ''} \\\n",
    "        {'--overwrite_output_dir' if overwrite_output_dir else ''} \\\n",
    "        {'--deepspeed='+deepspeed if deepspeed else ''} \\\n",
    "        {'--subsample_inds_file='+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        {'--dataloader_sampler '+str(dataloader_sampler) if dataloader_sampler else ''} \\\n",
    "        --use_flash_attn {'True' if use_flash_attn else 'False'} \\\n",
    "        --low_cpu_mem_usage \\\n",
    "        --overwrite_cache \\\n",
    "        --output_dir=\"{output_dir}\" \\\n",
    "    \"\"\" \n",
    "    #  --overwrite_cache   # if delete a dataset and need to refresh cache\n",
    "\n",
    "    if test_run:\n",
    "        print()\n",
    "        print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64':\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        queue=queue,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12fc2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_sft.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed0c2894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ cd ..\n",
      "+ TORCHELASTIC_ERROR_FILE=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/error_file\n",
      "+ TORCH_CPP_LOG_LEVEL=INFO\n",
      "+ NCCL_DEBUG=INFO\n",
      "+ LOGLEVEL=INFO\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/oasst1/oasst1_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=32 --per_device_train_batch_size=1 --gradient_accumulation_steps=128 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=200 --report_to tensorboard wandb --run_name /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=200 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --overwrite_output_dir --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl --dataloader_sampler SequentialSampler --use_flash_attn True --low_cpu_mem_usage --overwrite_cache --output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10\n",
      "[2024-01-19 02:04:37,834] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Saving args dict to /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10.args.json\n",
      "01/19/2024 02:04:39 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "01/19/2024 02:04:39 - INFO - __main__ - Training parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=8,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_sampler=SequentialSampler,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=7200,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=200.0,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=128,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10/runs/Jan19_02-04-39_cccxc552,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1.0,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard', 'wandb'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=True,\n",
      "save_steps=200,\n",
      "save_strategy=steps,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=True,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "Using custom data configuration default-b03eccd42e843020\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Using custom data configuration default-b03eccd42e843020\n",
      "Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "[INFO|configuration_utils.py:715] 2024-01-19 02:04:39,135 >> loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "[INFO|configuration_utils.py:777] 2024-01-19 02:04:39,136 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3118] 2024-01-19 02:04:39,229 >> loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1222] 2024-01-19 02:04:39,229 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[WARNING|modeling_utils.py:1304] 2024-01-19 02:04:39,230 >> You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:39,230 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.07it/s]\n",
      "[INFO|modeling_utils.py:3950] 2024-01-19 02:04:41,778 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:3958] 2024-01-19 02:04:41,778 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:749] 2024-01-19 02:04:41,781 >> loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:41,781 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "01/19/2024 02:04:41 - INFO - __main__ - [wpq] model.dtype=torch.bfloat16\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1648] 2024-01-19 02:04:41,845 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spawning 32 processes\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Spawning 32 processes\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 0/33717 [00:Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 22/33717 [00Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   1%| | 361/33717 [0Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):   3%| | 1001/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   5%| | 1719/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   7%| | 2251/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):  12%| | 4021/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  14%|▏| 4841/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  18%|▏| 5957/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32): 100%|█| 33717/33717 \n",
      "Concatenating 32 shards\n",
      "01/19/2024 02:04:55 - INFO - datasets.arrow_dataset - Concatenating 32 shards\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - __main__ - Subsample dataset according to indices: /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl\n",
      "01/19/2024 02:04:56 - INFO - __main__ - subsample_inds_file has 10000 indices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[wpq] Example 0 of train_dataset: \r\n",
      "{'dataset': 'oasst1', 'id': 'oasst1_20480', 'messages': [{'role': 'user', 'content': 'Cómo manejar un carro manual'}, {'role': 'assistant', 'content': 'Lo primero que tienes que hacer, si nunca has conducido un coche manual, es familiarizarte con el embrague y palanca de cambios. Si conduces habitualmente un coche automático, estarás acostumbrado a no utilizar para nada el pie izquierdo ni la palanca del cambio. Encontrarás tres pedales, siendo el embrague el que está situado a la izquierda y el que tendrás que pisar cada vez que cambies de marcha. Por otro lado, la palanca del cambio se ubica siempre en la consola central.\\n\\nPara arrancar un coche manual, es necesario seguir una serie de pasos que, al principio, pueden parecer muchos, pero que, con el tiempo, acabarás haciéndolos sin darte cuenta:\\n\\n1) Comprueba que la palanca del cambio está en punto muerto\\n2) Coloca el pie derecho en el pedal del freno\\n3) Arranca el motor\\n4) Pisa el embrague con el pie izquierdo\\n5) Coloca la palanca del cambio en la primera marcha, sin levantar el pedal del freno\\n6) Suelta el freno de mano\\n7) Suelta el pedal del freno\\nYa estás listo para iniciar la marcha, soltando suavemente el embrague, a medida que aceleras.\\n\\nUna vez que ya estás en marcha, debes hacer un uso correcto del cambio manual para cambiar las marchas de forma correcta. Un uso incorrecto de la caja de cambios manual puede repercutir negativamente en tu seguridad y también afectar gravemente al embrague y a la transmisión, lo que se traduce en serias averías de coste muy elevado. Para evitarlo, te explicamos cómo debes proceder:\\n\\nUna vez que hayas arrancado, pisa el acelerador muy lentamente. Notarás que el régimen del motor aumenta. En ese momento, comienza a soltar suavemente el pedal del embrague. Verás que el motor vuelve a bajar de vueltas. En ese momento, puedes presionar un poco más el acelerador y el coche comenzará a avanzar.\\n\\nAhora llega el momento de meter la segunda marcha. Dependiendo del tipo de coche y combustible, podrás circular a un régimen de giro más bajo o alto. El régimen de giro en coche de gasolina, por lo general, oscila entre loas 2.500 y 3.000 vueltas. Si el motor está sobrealimentado por turbo, te permitirá circular por debajo de ese rango, ya que algunos coches turbos modernos entregan la totalidad de su par motor, incluso por debajo de las 2.000 vueltas.\\n\\nUn coche con motor turbodiésel te permite circular a un régimen muy bajo, por debajo de las 2.000 vueltas, ya que la entrega de par se produce antes que en un motor de gasolina.\\n\\nCuando el coche alcance un régimen de vueltas apropiado, suelta el pedal del acelerador y vuelve a pisar el embrague. Coge la palanca del cambio y baja para meter segunda. Suelta el embrague y presiona nuevamente el acelerador. A partir de aquí, cada vez que quieras cambiar de marcha, deberás repetir el mismo proceso: soltar el acelerador, pisar embrague, meter la marcha, soltar embrague y volver a acelerar.\\n\\n¡Buen viaje!'}], 'input_ids': tensor([    1,   529, 29989,  1792, 29989, 29958,    13, 29907, 29980,  4346,\r\n",
      "          767, 29872,  4758,   443,  1559,   307, 12219,    13, 29966, 29989,\r\n",
      "          465, 22137, 29989, 29958,    13,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'labels': tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:593] 2024-01-19 02:04:57,333 >> Using auto half precision backend\n",
      "[INFO|trainer.py:738] 2024-01-19 02:04:57,494 >> The following columns in the training set don't have a corresponding argument in `LlamaForCausalLM.forward` and have been ignored: messages, id, dataset. If messages, id, dataset are not expected by `LlamaForCausalLM.forward`,  you can safely ignore this message.\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1723] 2024-01-19 02:04:57,514 >> ***** Running training *****\n",
      "[INFO|trainer.py:1724] 2024-01-19 02:04:57,514 >>   Num examples = 10,000\n",
      "[INFO|trainer.py:1725] 2024-01-19 02:04:57,514 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1726] 2024-01-19 02:04:57,514 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:1729] 2024-01-19 02:04:57,514 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1730] 2024-01-19 02:04:57,514 >>   Gradient Accumulation steps = 128\n",
      "[INFO|trainer.py:1731] 2024-01-19 02:04:57,514 >>   Total optimization steps = 78\n",
      "[INFO|trainer.py:1732] 2024-01-19 02:04:57,515 >>   Number of trainable parameters = 6,738,423,808\n",
      "[INFO|integration_utils.py:718] 2024-01-19 02:04:57,519 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "  0%|                                                    | 0/78 [00:00<?, ?it/s][WARNING|logging.py:314] 2024-01-19 02:05:01,563 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,569 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,572 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,576 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,577 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 1.6425, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}         \n",
      "{'loss': 1.7168, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.03}        \n",
      "  3%|█▏                                          | 2/78 [00:42<26:54, 21.24s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash gen_cmds_sft.sh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:177\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:646\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGCONT)\n\u001b[0;32m--> 646\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_sft.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831fe55",
   "metadata": {},
   "source": [
    "# eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "499d6f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt', 'results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt', 'results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt', 'results/oi5_dolly:llama-7b/llama-7b_dolly_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "#cmds:  3 \n",
      "\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_1h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from gen_cmds_utils import remove_all_symlinks, create_unique_symlinks, get_chat_formatting_function, get_resource_for_task, OPENAI_MODEL_LIST\n",
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else \\\n",
    "    ('alt_7d' if task_name.startswith('mtbench') else 'alt_1h')\n",
    "\n",
    "create_symlinks = False\n",
    "include_checkpoints = False\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "use_slow_tokenizer = True\n",
    "definitely_run_mtbench_on_non_alt7b_queue = False\n",
    "launch_one_job_per_model = True\n",
    "\n",
    "task_names = [\n",
    "    'mmlu_s=0',\n",
    "    'mmlu_s=5', \n",
    "    'gsm_s=8',\n",
    "    'gsm_s=8_cot',\n",
    "    'bbh_s=3',\n",
    "    'bbh_s=3_cot', # max_datapoints_per_task=40 -> 40min.\n",
    "    'humaneval',\n",
    "    'tydiqa_s=1_cb', # 3min\n",
    "    'tydiqa_s=1_gp',\n",
    "    # 'toxigen', # ~1.5hr\n",
    "#     'alpacafarm_ann=gpt35:turbo:1106',\n",
    "    # 'alpacafarm_ann=chatgpt', # ~$1 per eval.\n",
    "]\n",
    "task_names_chatfmt = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "\n",
    "task_names_mtbench = ['mtbench_ann=gpt:4:1106:preview_chatfmt'] # ann=gpt:4, ann=gpt:3.5:turbo:1106, gpt:4:1106:preview (gpt4-turbo)\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:3.5:turbo:1106_chatfmt'] # for debug sake, prefer gpt4\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:4_chatfmt']\n",
    "# task_names_alpacafarm = ['alpacafarm_ann=chatgpt_chatfmt']\n",
    "task_names_alpacafarm = ['alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt']\n",
    "task_names_chateval = task_names_mtbench + task_names_alpacafarm\n",
    "\n",
    "\n",
    "# # ## baselines eval \n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "# #     'huggyllama/llama-7b', \n",
    "# #     'mistralai/Mistral-7B-v0.1',\n",
    "# #     'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "# #     'NousResearch/Llama-2-7b-hf',\n",
    "# #     'NousResearch/Llama-2-7b-chat-hf',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-beta',\n",
    "# #     'HuggingFaceH4/zephyr-7b-alpha',\n",
    "#     'HuggingFaceH4/zephyr-7b-beta',\n",
    "# #     'codellama/CodeLlama-7b-hf',\n",
    "# #     'codellama/CodeLlama-7b-Python-hf',\n",
    "# #     'codellama/CodeLlama-7b-Instruct-hf',\n",
    "# ]]\n",
    "# # task_names = task_names + task_names_chatfmt\n",
    "# task_names = task_names_mtbench; definitely_run_mtbench_on_non_alt7b_queue = True\n",
    "\n",
    "# # oi5\n",
    "# exp_dir = 'results/oi2'\n",
    "# exp_dir = 'results/oi5_flan_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_dolly:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlm50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegpt50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b_debug'\n",
    "# exp_dir = 'results/oi5_stanford_alpaca:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlmv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegptv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_ultrachat200kv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_tulu_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_open_orca_slim:llama-7b'\n",
    "# exp_dir = 'results/dpo1'\n",
    "# exp_dir = 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2'\n",
    "exp_dirs = [\n",
    "    'results/oi5_dolly:llama-7b',\n",
    "#     'results/oi5_flan_v250k:llama-7b',\n",
    "#     'results/oi5_stanford_alpaca50k:llama-7b',\n",
    "#     'results/oi5_oasst2:llama-7b',\n",
    "#     'results/oi5_wizardlm50k:llama-7b',\n",
    "#     'results/oi5_sharegpt50k:llama-7b',\n",
    "#     'results/oi5_ultrachat50k:llama-7b',\n",
    "]\n",
    "\n",
    "subdir_filter_fn = lambda x: 'ep=3' in x\n",
    "# task_names = task_names + task_names_chatfmt;\n",
    "task_names = task_names_alpacafarm; definitely_run_mtbench_on_non_alt7b_queue = False\n",
    "# task_names = task_names_mtbench; definitely_run_mtbench_on_non_alt7b_queue = False\n",
    "# task_names = task_names + task_names_chatfmt + task_names_mtbench\n",
    "# task_names = task_names\n",
    "# task_names = ['alpacafarm_ann=gpt35:turbo:1106_chatfmt']\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "num_gpus = 1\n",
    "if arch == 'x86_64': # ccc\n",
    "\n",
    "    if definitely_run_mtbench_on_non_alt7b_queue:\n",
    "        gpu_type = 'v100'; num_cpus = int(32/8*num_gpus); cpu_mem = int(240/8*num_gpus)\n",
    "    else:\n",
    "        gpu_type = 'a100_80gb'; num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus)\n",
    "    use_vllm = True; torch_dtype = 'bfloat16'\n",
    "else:\n",
    "    gpu_type = 'v100'\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    use_vllm = False; torch_dtype = 'float16'\n",
    "    \n",
    "    \n",
    "if len(subdir_path_list)==0:\n",
    "    subdir_path_list = []\n",
    "    for exp_dir in exp_dirs:\n",
    "        if create_symlinks:\n",
    "            remove_all_symlinks(exp_dir)\n",
    "        subdirs = list(os.listdir(exp_dir))\n",
    "        subdirs = filter(subdir_filter_fn, subdirs)\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(exp_dir, subdir)\n",
    "            if include_checkpoints:\n",
    "                subdir_path_list += glob.glob(os.path.join(subdir_path, 'checkpoint-*'))\n",
    "            if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "                continue\n",
    "            subdir_path_list.append(subdir_path)\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not os.path.islink(subdir_path) and \\\n",
    "                not os.path.isfile(os.path.join(subdir_path, 'eval', task_name, 'metrics.json')):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "                print((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "\n",
    "print('#cmds: ', len(list(task_name_and_model)), '\\n')\n",
    "\n",
    "if create_symlinks:\n",
    "    # create symlink for each directory.\n",
    "    symlink_path_dict = create_unique_symlinks(\n",
    "        list([x[1] for x in task_name_and_model]))\n",
    "    options_list = list(map(lambda x: (x[0], symlink_path_dict[x[1]]), task_name_and_model))\n",
    "else:\n",
    "    options_list = task_name_and_model\n",
    "    \n",
    "    \n",
    "dfo = pd.DataFrame(options_list, columns=['task_name', 'model_name_or_path'])\n",
    "model_and_task_list = dfo.groupby('model_name_or_path')['task_name'].agg(list).to_dict()\n",
    "\n",
    "\n",
    "info = {}  \n",
    "cmds = []\n",
    "for model_name_or_path, task_name_list in model_and_task_list.items():\n",
    "    num_tasks = len(task_name_list)\n",
    "    cmds_per_model = []\n",
    "    for i, task_name in enumerate(task_name_list):\n",
    "\n",
    "        use_chat_format = 'chatfmt' in task_name\n",
    "        chat_formatting_function = get_chat_formatting_function(model_name_or_path)\n",
    "\n",
    "        try:\n",
    "            with open(os.path.join(model_name_or_path, 'ft_args.json'), 'r') as f:\n",
    "                ft_args = json.load(f)\n",
    "            # note `model_name_or_path` could be anything, e.g., soft links with arbitrary names.\n",
    "            # but `ft_args_model_name_or_path` indicates the finetuned model name.\n",
    "            if 'model_args' in ft_args:\n",
    "                ft_args_model_name_or_path = ft_args['model_args']['model_name_or_path']\n",
    "            else:\n",
    "                ft_args_model_name_or_path = ft_args['model_name_or_path']\n",
    "        except:\n",
    "            ft_args_model_name_or_path = model_name_or_path\n",
    "\n",
    "        batch_size, job_duration = get_resource_for_task(\n",
    "            task_name, ft_args_model_name_or_path)\n",
    "\n",
    "        job_name = f'eval.{task_name}'\n",
    "        save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "\n",
    "        if task_name.startswith('mmlu'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 5)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.mmlu.run_eval \\\n",
    "                --data_dir data/eval/mmlu \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --ntrain {n_shot} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('gsm'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 8)\n",
    "            # open-instruct used 200 examples. use higher amount to get a more accurate number\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.gsm.run_eval \\\n",
    "                --data_dir data/eval/gsm/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_num_examples 500 \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('bbh'):\n",
    "            max_num_examples_per_task = 40\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 3)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.bbh.run_eval \\\n",
    "                --data_dir data/eval/bbh/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                --n_shot {n_shot} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--max_num_examples_per_task '+str(max_num_examples_per_task) if max_num_examples_per_task else ''} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('humaneval'):\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.codex_humaneval.run_eval \\\n",
    "                --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens 512 \\\n",
    "                --eval_pass_at_ks 1 \\\n",
    "                --unbiased_sampling_size_n 3 \\\n",
    "                --temperature 0.1 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('tydiqa'):\n",
    "            no_context = 'cb' in task_name\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot in [0,1])\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.tydiqa.run_eval \\\n",
    "                --data_dir data/eval/tydiqa \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_num_examples_per_lang 100 \\\n",
    "                --max_context_length 512 \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_context' if no_context else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('toxigen'):\n",
    "            # max_prompts_per_group=500 (out of 1000) is open-instruct default.\n",
    "            # eval batch size=1 much faster (llama-7b) not sure why.\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.toxigen.run_eval \\\n",
    "                --data_dir data/eval/toxigen \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size 1 \\\n",
    "                --max_prompts_per_group 200 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('alpacafarm'):\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            annotators_config = match.group(1)\n",
    "            annotators_config = annotators_config.replace(':', '_')\n",
    "            if not annotators_config in ['chatgpt', 'alpaca_eval_gpt4_0314', 'gpt35_turbo_1106', 'alpaca_eval_gpt4_turbo_fn']:\n",
    "                raise ValueError('Just support 2 annotators_config.')\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.alpaca_farm.run_eval \\\n",
    "                --reference_path alpaca_eval_data \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --max_new_tokens 2048 \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --annotators_config {annotators_config} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('mtbench'):\n",
    "            assert('chatfmt' in task_name)\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            judge_model = match.group(1).replace(':', '-')\n",
    "            if not judge_model in OPENAI_MODEL_LIST:\n",
    "                raise ValueError('fastchat does not support the judge model.')\n",
    "            os.makedirs(save_dir, exist_ok=True) # since not using python file, make the directory now.\n",
    "            fastchat_mtbench_data_dir = os.path.normpath(os.path.join(open_instruct_dir, '../FastChat/fastchat/llm_judge/data'))\n",
    "            question_file = os.path.join(fastchat_mtbench_data_dir, 'mt_bench/question.jsonl')\n",
    "            rating_file = os.path.join(save_dir, f'{judge_model}_single.jsonl')\n",
    "            question_begin, question_end = (0, 1) if False else (None, None)\n",
    "            model_id = os.path.basename(model_name_or_path) if 'results/baselines' in save_dir else 'tulu'\n",
    "            cmd = \"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_model_answer \\\n",
    "                    --model-path {model_name_or_path} \\\n",
    "                    --model-id {model_id} \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --question-file {question_file} \\\n",
    "                    {'--question-begin '+str(question_begin) if question_begin else ''} \\\n",
    "                    {'--question-end '+str(question_end) if question_end else ''} \\\n",
    "                    --max-new-token 2048 \\\n",
    "                    --answer-file {os.path.join(save_dir, 'model_answer.jsonl')} \\\n",
    "                    --dtype {torch_dtype} \\\n",
    "                && \\\n",
    "            \"\"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_judgment \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --judge-file {os.path.join(fastchat_mtbench_data_dir, 'judge_prompts.jsonl')} \\\n",
    "                    --judge-model {judge_model} \\\n",
    "                    --mode single \\\n",
    "                    --question-file {question_file} \\\n",
    "                    --answer-dir {save_dir} \\\n",
    "                    --ref-answer-dir {os.path.join(fastchat_mtbench_data_dir, 'mt_bench/reference_answer')} \\\n",
    "                    --output-file {rating_file} \\\n",
    "                && \\\n",
    "                python -m fastchat.llm_judge.show_result \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --input-file {rating_file} \\\n",
    "                    --mode single \\\n",
    "                    --save-to-json\n",
    "            \"\"\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'{task_name} not supported.')\n",
    "\n",
    "        if test_run:\n",
    "            print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd.strip())]))\n",
    "\n",
    "        cmd = multiline_to_singleline(cmd)\n",
    "        cmds.append(cmd)\n",
    "        cmds_per_model.append(cmd)\n",
    "        \n",
    "        if launch_one_job_per_model:\n",
    "            shell_scripts = shell_scripts_template.format(\n",
    "                conda_env='open-instruct',\n",
    "                cwd=os.path.dirname(os.getcwd()),\n",
    "                cmd=cmd,\n",
    "                log_dir=os.getcwd(),\n",
    "                save_dir=save_dir,\n",
    "            )\n",
    "            if arch == 'x86_64': # ccc\n",
    "                shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "            out = submit_job(\n",
    "                shell_scripts, \n",
    "                job_name=job_name,\n",
    "                num_cpus=num_cpus,\n",
    "                cpu_mem=cpu_mem,\n",
    "                num_gpus=num_gpus,\n",
    "                gpu_type=gpu_type,\n",
    "                test_run=test_run,\n",
    "                job_duration=job_duration,\n",
    "                queue=queue,\n",
    "            )\n",
    "        else:\n",
    "            if i + 1 == num_tasks:\n",
    "                assert(len(cmds_per_model) == num_tasks)\n",
    "                cmd = ' && '.join(cmds_per_model)\n",
    "                if test_run:\n",
    "                    print(cmd)\n",
    "                shell_scripts = shell_scripts_template.format(\n",
    "                    conda_env='open-instruct',\n",
    "                    cwd=os.path.dirname(os.getcwd()),\n",
    "                    cmd=cmd,\n",
    "                    log_dir=os.getcwd(),\n",
    "                    save_dir=os.getcwd(), # just delete afterwards.\n",
    "                )\n",
    "                if arch == 'x86_64': # ccc\n",
    "                    shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "                out = submit_job(\n",
    "                    shell_scripts, \n",
    "                    job_name=f'eval.{os.path.basename(model_name_or_path)}',\n",
    "                    num_cpus=num_cpus,\n",
    "                    cpu_mem=cpu_mem,\n",
    "                    num_gpus=num_gpus,\n",
    "                    gpu_type=gpu_type,\n",
    "                    test_run=test_run,\n",
    "                    job_duration=6,\n",
    "                    queue=None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_6b',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ea7ac978",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_eval.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b3939309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10 --max_new_tokens 2048 --save_dir results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt --eval_batch_size 10 --annotators_config alpaca_eval_gpt4_turbo_fn --use_vllm --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype bfloat16\n",
      "[2024-01-21 21:11:36,716] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:loading data and model...\n",
      "INFO 01-21 21:11:39 llm_engine.py:73] Initializing an LLM engine with config: model='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10', tokenizer='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO 01-21 21:11:39 tokenizer.py:32] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "MegaBlocks not found. Please install it by `pip install megablocks`. Note that MegaBlocks depends on mosaicml-turbo, which only supports Python 3.10 for now.\n",
      "STK not found: please see https://github.com/stanford-futuredata/stk\n",
      "INFO 01-21 21:11:53 llm_engine.py:222] # GPU blocks: 7451, # CPU blocks: 512\n",
      "Processed prompts: 100%|██████████████████████| 805/805 [01:01<00:00, 13.00it/s]\n",
      "INFO:root:Evaluating the llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10-greedy-long outputs.\n",
      "INFO:root:Creating the annotator from `alpaca_eval_gpt4_turbo_fn`.\n",
      "WARNING:root:Saving_path is given but not 'auto', make sure that it's different for different seeds.\n",
      "Annotation chunk:   0%|                                   | 0/7 [00:00<?, ?it/s]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:02<06:07,  2.90s/it]\u001b[A\n",
      "prompt_batches:   2%|▋                          | 3/128 [00:03<01:52,  1.11it/s]\u001b[A\n",
      "prompt_batches:   3%|▊                          | 4/128 [00:06<03:40,  1.78s/it]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/128 [00:11<02:02,  1.04s/it]\u001b[A\n",
      "prompt_batches:   9%|██▍                       | 12/128 [00:14<02:13,  1.15s/it]\u001b[A\n",
      "prompt_batches:  14%|███▋                      | 18/128 [00:14<01:00,  1.81it/s]\u001b[A\n",
      "prompt_batches:  16%|████                      | 20/128 [00:15<01:02,  1.73it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:18<01:16,  1.38it/s]\u001b[A\n",
      "prompt_batches:  18%|████▋                     | 23/128 [00:18<01:08,  1.52it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:21<01:29,  1.16it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/128 [00:21<01:17,  1.31it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:23<01:36,  1.05it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:25<01:27,  1.12it/s]\u001b[A\n",
      "prompt_batches:  25%|██████▌                   | 32/128 [00:29<01:47,  1.12s/it]\u001b[A\n",
      "prompt_batches:  30%|███████▋                  | 38/128 [00:34<01:27,  1.03it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/128 [00:36<01:25,  1.03it/s]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:38<01:15,  1.12it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▎                | 46/128 [00:46<01:56,  1.42s/it]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:47<01:01,  1.21it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▌              | 57/128 [00:49<00:49,  1.43it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▊              | 58/128 [00:50<00:54,  1.29it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 59/128 [00:53<01:04,  1.08it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:54<00:48,  1.36it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▊             | 63/128 [00:55<00:52,  1.23it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 64/128 [00:56<00:56,  1.13it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 65/128 [00:56<00:47,  1.32it/s]\u001b[A\n",
      "prompt_batches:  53%|█████████████▊            | 68/128 [00:58<00:39,  1.53it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [01:11<02:16,  2.36s/it]\u001b[A\n",
      "prompt_batches:  66%|█████████████████▎        | 85/128 [01:11<00:25,  1.69it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:13<00:21,  1.79it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:19<00:37,  1.02it/s]\u001b[A\n",
      "prompt_batches:  78%|███████████████████▌     | 100/128 [01:21<00:16,  1.71it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:25<00:17,  1.45it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:28<00:12,  1.55it/s]\u001b[A\n",
      "prompt_batches:  86%|█████████████████████▍   | 110/128 [01:28<00:10,  1.76it/s]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▎  | 114/128 [01:29<00:06,  2.21it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:30<00:07,  1.70it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_batches:  91%|██████████████████████▊  | 117/128 [01:32<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 119/128 [01:33<00:05,  1.66it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▋ | 121/128 [01:35<00:04,  1.46it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▍| 125/128 [01:36<00:01,  2.04it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 126/128 [01:36<00:01,  1.92it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:37<00:00,  1.31it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 97.8 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  14%|███▊                       | 1/7 [01:37<09:47, 97.89s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:05<12:20,  5.83s/it]\u001b[A\n",
      "prompt_batches:   5%|█▍                         | 7/128 [00:15<03:59,  1.98s/it]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:19<02:12,  1.16s/it]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:19<01:50,  1.02it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:20<01:07,  1.59it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:22<01:22,  1.28it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:23<01:03,  1.63it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/128 [00:24<01:05,  1.56it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:24<00:58,  1.73it/s]\u001b[A\n",
      "prompt_batches:  22%|█████▋                    | 28/128 [00:25<01:02,  1.59it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/128 [00:26<01:06,  1.48it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:26<01:08,  1.42it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▎                   | 31/128 [00:29<01:45,  1.09s/it]\u001b[A\n",
      "prompt_batches:  27%|██████▉                   | 34/128 [00:29<00:52,  1.78it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 36/128 [00:29<00:42,  2.14it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/128 [00:30<00:38,  2.34it/s]\u001b[A\n",
      "prompt_batches:  30%|███████▋                  | 38/128 [00:38<03:11,  2.12s/it]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:40<01:28,  1.04s/it]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:41<00:43,  1.79it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:42<00:36,  2.06it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▏              | 55/128 [00:43<00:40,  1.81it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▌              | 57/128 [00:46<00:54,  1.31it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:47<00:33,  1.97it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 64/128 [00:55<01:15,  1.18s/it]\u001b[A\n",
      "prompt_batches:  56%|██████████████▋           | 72/128 [00:55<00:32,  1.71it/s]\u001b[A\n",
      "prompt_batches:  57%|██████████████▊           | 73/128 [00:56<00:32,  1.71it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 74/128 [01:05<01:23,  1.54s/it]\u001b[A\n",
      "prompt_batches:  67%|█████████████████▍        | 86/128 [01:06<00:24,  1.71it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▋        | 87/128 [01:07<00:23,  1.74it/s]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▉        | 88/128 [01:07<00:21,  1.82it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:08<00:22,  1.76it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:12<00:43,  1.13s/it]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 95/128 [01:13<00:19,  1.67it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:13<00:20,  1.57it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:15<00:25,  1.23it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:17<00:18,  1.44it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:19<00:19,  1.31it/s]\u001b[A\n",
      "prompt_batches:  84%|████████████████████▉    | 107/128 [01:20<00:10,  2.09it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:20<00:10,  1.95it/s]\u001b[A\n",
      "prompt_batches:  86%|█████████████████████▍   | 110/128 [01:22<00:10,  1.67it/s]\u001b[A\n",
      "prompt_batches:  88%|█████████████████████▉   | 112/128 [01:24<00:12,  1.33it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:25<00:07,  1.82it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▋  | 116/128 [01:27<00:08,  1.43it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 117/128 [01:27<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 119/128 [01:28<00:05,  1.71it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▍ | 120/128 [01:30<00:06,  1.17it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:32<00:05,  1.03it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:33<00:00,  1.37it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 93.5 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  29%|███████▋                   | 2/7 [03:11<07:56, 95.40s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:03<07:34,  3.58s/it]\u001b[A\n",
      "prompt_batches:   2%|▍                          | 2/128 [00:06<06:45,  3.22s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/128 [00:07<01:14,  1.60it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/128 [00:08<01:16,  1.54it/s]\u001b[A\n",
      "prompt_batches:   9%|██▏                       | 11/128 [00:09<01:20,  1.45it/s]\u001b[A\n",
      "prompt_batches:   9%|██▍                       | 12/128 [00:10<01:29,  1.30it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:10<01:00,  1.89it/s]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:12<01:07,  1.65it/s]\u001b[A\n",
      "prompt_batches:  13%|███▍                      | 17/128 [00:13<01:10,  1.57it/s]\u001b[A\n",
      "prompt_batches:  14%|███▋                      | 18/128 [00:14<01:21,  1.35it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:15<01:08,  1.57it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:16<01:17,  1.36it/s]\u001b[A\n",
      "prompt_batches:  18%|████▋                     | 23/128 [00:17<01:23,  1.26it/s]\u001b[A\n",
      "prompt_batches:  20%|█████                     | 25/128 [00:18<01:07,  1.53it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:20<01:06,  1.51it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:23<01:22,  1.18it/s]\u001b[A\n",
      "prompt_batches:  26%|██████▋                   | 33/128 [00:23<00:54,  1.75it/s]\u001b[A\n",
      "prompt_batches:  27%|███████                   | 35/128 [00:24<00:48,  1.93it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 36/128 [00:25<00:53,  1.73it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/128 [00:25<00:50,  1.82it/s]\u001b[A\n",
      "prompt_batches:  30%|███████▉                  | 39/128 [00:27<00:51,  1.74it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/128 [00:29<01:28,  1.01s/it]\u001b[A\n",
      "prompt_batches:  34%|████████▉                 | 44/128 [00:30<00:42,  1.97it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████▏                | 45/128 [00:32<01:06,  1.24it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▎                | 46/128 [00:32<00:55,  1.47it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▊                | 48/128 [00:32<00:37,  2.12it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▉                | 49/128 [00:34<01:00,  1.30it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:34<00:39,  1.95it/s]\u001b[A\n",
      "prompt_batches:  42%|██████████▉               | 54/128 [00:38<01:00,  1.22it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▏              | 55/128 [00:39<00:57,  1.28it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▍              | 56/128 [00:40<01:05,  1.09it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 59/128 [00:43<01:06,  1.05it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▌             | 62/128 [00:43<00:40,  1.65it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▊             | 63/128 [00:44<00:40,  1.59it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 65/128 [00:46<00:46,  1.37it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 66/128 [00:46<00:38,  1.61it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▌            | 67/128 [00:46<00:34,  1.78it/s]\u001b[A\n",
      "prompt_batches:  54%|██████████████            | 69/128 [00:47<00:27,  2.11it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [00:49<00:48,  1.18it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▍           | 71/128 [00:50<00:50,  1.13it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▏          | 75/128 [00:51<00:25,  2.05it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▍          | 76/128 [00:54<00:45,  1.14it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████          | 79/128 [00:54<00:28,  1.72it/s]\u001b[A\n",
      "prompt_batches:  63%|████████████████▍         | 81/128 [00:55<00:25,  1.81it/s]\u001b[A\n",
      "prompt_batches:  64%|████████████████▋         | 82/128 [00:57<00:32,  1.42it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 83/128 [01:00<00:55,  1.24s/it]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▉        | 88/128 [01:01<00:22,  1.76it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:02<00:24,  1.60it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 91/128 [01:05<00:33,  1.10it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▋       | 92/128 [01:06<00:35,  1.03it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:07<00:19,  1.63it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:07<00:16,  1.85it/s]\u001b[A\n",
      "prompt_batches:  77%|███████████████████▉      | 98/128 [01:08<00:18,  1.62it/s]\u001b[A\n",
      "prompt_batches:  77%|████████████████████      | 99/128 [01:10<00:25,  1.13it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:11<00:20,  1.29it/s]\u001b[A\n",
      "prompt_batches:  80%|███████████████████▉     | 102/128 [01:12<00:16,  1.55it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 104/128 [01:12<00:14,  1.70it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▌    | 105/128 [01:15<00:22,  1.02it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:16<00:13,  1.53it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▎   | 109/128 [01:17<00:14,  1.33it/s]\u001b[A\n",
      "prompt_batches:  87%|█████████████████████▋   | 111/128 [01:19<00:15,  1.10it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:23<00:11,  1.16it/s]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▋  | 116/128 [01:28<00:18,  1.51s/it]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:29<00:04,  1.36it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:32<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 92.2 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation chunk:  43%|███████████▌               | 3/7 [04:43<06:15, 93.97s/it]INFO:root:Annotating 127 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 127 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/127 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/127 [00:03<07:05,  3.38s/it]\u001b[A\n",
      "prompt_batches:   2%|▍                          | 2/127 [00:04<03:43,  1.79s/it]\u001b[A\n",
      "prompt_batches:   5%|█▎                         | 6/127 [00:04<01:06,  1.81it/s]\u001b[A\n",
      "prompt_batches:   6%|█▍                         | 7/127 [00:06<01:38,  1.22it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/127 [00:06<00:56,  2.05it/s]\u001b[A\n",
      "prompt_batches:   9%|██▎                       | 11/127 [00:10<01:59,  1.03s/it]\u001b[A\n",
      "prompt_batches:  10%|██▋                       | 13/127 [00:11<01:41,  1.12it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/127 [00:12<01:31,  1.24it/s]\u001b[A\n",
      "prompt_batches:  13%|███▍                      | 17/127 [00:14<01:24,  1.30it/s]\u001b[A\n",
      "prompt_batches:  15%|███▉                      | 19/127 [00:15<01:13,  1.48it/s]\u001b[A\n",
      "prompt_batches:  17%|████▎                     | 21/127 [00:15<00:59,  1.77it/s]\u001b[A\n",
      "prompt_batches:  19%|████▉                     | 24/127 [00:18<01:04,  1.59it/s]\u001b[A\n",
      "prompt_batches:  20%|█████▎                    | 26/127 [00:19<01:00,  1.66it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/127 [00:23<01:36,  1.02it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 37/127 [00:24<00:41,  2.16it/s]\u001b[A\n",
      "prompt_batches:  31%|███████▉                  | 39/127 [00:26<00:49,  1.79it/s]\u001b[A\n",
      "prompt_batches:  31%|████████▏                 | 40/127 [00:26<00:44,  1.94it/s]\u001b[A\n",
      "prompt_batches:  33%|████████▌                 | 42/127 [00:27<00:39,  2.17it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████                 | 44/127 [00:27<00:32,  2.56it/s]\u001b[A\n",
      "prompt_batches:  35%|█████████▏                | 45/127 [00:28<00:28,  2.84it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▍                | 46/127 [00:28<00:36,  2.23it/s]\u001b[A\n",
      "prompt_batches:  37%|█████████▌                | 47/127 [00:29<00:42,  1.86it/s]\u001b[A\n",
      "prompt_batches:  38%|█████████▊                | 48/127 [00:31<01:08,  1.15it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▋               | 52/127 [00:32<00:40,  1.87it/s]\u001b[A\n",
      "prompt_batches:  42%|██████████▊               | 53/127 [00:34<00:47,  1.56it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████               | 54/127 [00:35<00:52,  1.40it/s]\u001b[A\n",
      "prompt_batches:  43%|███████████▎              | 55/127 [00:35<00:53,  1.35it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▊              | 58/127 [00:37<00:41,  1.65it/s]\u001b[A\n",
      "prompt_batches:  46%|████████████              | 59/127 [00:37<00:40,  1.68it/s]\u001b[A\n",
      "prompt_batches:  47%|████████████▎             | 60/127 [00:38<00:36,  1.85it/s]\u001b[A\n",
      "prompt_batches:  49%|████████████▋             | 62/127 [00:39<00:43,  1.49it/s]\u001b[A\n",
      "prompt_batches:  50%|████████████▉             | 63/127 [00:42<01:10,  1.10s/it]\u001b[A\n",
      "prompt_batches:  54%|█████████████▉            | 68/127 [00:43<00:28,  2.08it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▎           | 70/127 [00:45<00:41,  1.36it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▌           | 71/127 [00:51<01:21,  1.45s/it]\u001b[A\n",
      "prompt_batches:  59%|███████████████▎          | 75/127 [00:52<00:45,  1.15it/s]\u001b[A\n",
      "prompt_batches:  61%|███████████████▊          | 77/127 [00:53<00:37,  1.32it/s]\u001b[A\n",
      "prompt_batches:  63%|████████████████▍         | 80/127 [00:53<00:24,  1.93it/s]\u001b[A\n",
      "prompt_batches:  64%|████████████████▌         | 81/127 [00:55<00:32,  1.43it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 82/127 [00:56<00:34,  1.32it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▉         | 83/127 [00:56<00:29,  1.50it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▌        | 86/127 [00:56<00:17,  2.41it/s]\u001b[A\n",
      "prompt_batches:  69%|█████████████████▊        | 87/127 [00:58<00:25,  1.54it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 90/127 [01:00<00:22,  1.64it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▊       | 92/127 [01:00<00:18,  1.90it/s]\u001b[A\n",
      "prompt_batches:  73%|███████████████████       | 93/127 [01:01<00:17,  1.94it/s]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▏      | 94/127 [01:01<00:17,  1.93it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▍      | 95/127 [01:02<00:15,  2.08it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 96/127 [01:03<00:23,  1.33it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▊      | 97/127 [01:03<00:18,  1.59it/s]\u001b[A\n",
      "prompt_batches:  78%|████████████████████▎     | 99/127 [01:04<00:15,  1.78it/s]\u001b[A\n",
      "prompt_batches:  80%|███████████████████▉     | 101/127 [01:06<00:16,  1.61it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 102/127 [01:08<00:21,  1.16it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▍    | 104/127 [01:10<00:20,  1.10it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 107/127 [01:10<00:11,  1.69it/s]\u001b[A\n",
      "prompt_batches:  87%|█████████████████████▋   | 110/127 [01:16<00:19,  1.13s/it]\u001b[A\n",
      "prompt_batches:  91%|██████████████████████▊  | 116/127 [01:18<00:07,  1.39it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 121/127 [01:19<00:03,  1.93it/s]\u001b[A\n",
      "prompt_batches:  96%|████████████████████████ | 122/127 [01:21<00:03,  1.47it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 123/127 [01:24<00:03,  1.10it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 127/127 [01:27<00:00,  1.45it/s]\u001b[A\n",
      "INFO:root:Completed 127 examples in 87.5 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation chunk:  57%|███████████████▍           | 4/7 [06:11<04:34, 91.46s/it]INFO:root:Annotating 128 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 128 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/128 [00:04<10:20,  4.88s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/128 [00:07<01:36,  1.25it/s]\u001b[A\n",
      "prompt_batches:   7%|█▉                         | 9/128 [00:07<01:24,  1.41it/s]\u001b[A\n",
      "prompt_batches:  10%|██▋                       | 13/128 [00:08<00:53,  2.16it/s]\u001b[A\n",
      "prompt_batches:  11%|██▊                       | 14/128 [00:10<01:12,  1.57it/s]\u001b[A\n",
      "prompt_batches:  12%|███▎                      | 16/128 [00:10<01:02,  1.80it/s]\u001b[A\n",
      "prompt_batches:  15%|███▊                      | 19/128 [00:12<01:00,  1.79it/s]\u001b[A\n",
      "prompt_batches:  16%|████                      | 20/128 [00:13<01:08,  1.58it/s]\u001b[A\n",
      "prompt_batches:  16%|████▎                     | 21/128 [00:13<00:59,  1.79it/s]\u001b[A\n",
      "prompt_batches:  17%|████▍                     | 22/128 [00:14<00:59,  1.78it/s]\u001b[A\n",
      "prompt_batches:  19%|████▉                     | 24/128 [00:16<01:22,  1.25it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 27/128 [00:17<00:54,  1.86it/s]\u001b[A\n",
      "prompt_batches:  22%|█████▋                    | 28/128 [00:18<00:55,  1.79it/s]\u001b[A\n",
      "prompt_batches:  23%|█████▉                    | 29/128 [00:18<00:57,  1.72it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 30/128 [00:21<01:35,  1.02it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▎                   | 31/128 [00:26<03:17,  2.04s/it]\u001b[A\n",
      "prompt_batches:  32%|████████▎                 | 41/128 [00:29<01:00,  1.44it/s]\u001b[A\n",
      "prompt_batches:  34%|████████▋                 | 43/128 [00:30<00:55,  1.52it/s]\u001b[A\n",
      "prompt_batches:  37%|█████████▌                | 47/128 [00:32<00:51,  1.59it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 51/128 [00:33<00:38,  1.99it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▌               | 52/128 [00:36<00:51,  1.48it/s]\u001b[A\n",
      "prompt_batches:  41%|██████████▊               | 53/128 [00:36<00:52,  1.43it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▍              | 56/128 [00:37<00:38,  1.85it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▊              | 58/128 [00:38<00:31,  2.20it/s]\u001b[A\n",
      "prompt_batches:  47%|████████████▏             | 60/128 [00:45<01:26,  1.26s/it]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 66/128 [00:46<00:42,  1.47it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▌            | 67/128 [00:47<00:47,  1.27it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▏           | 70/128 [00:49<00:39,  1.49it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▋           | 72/128 [00:49<00:32,  1.72it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 74/128 [00:52<00:40,  1.35it/s]\u001b[A\n",
      "prompt_batches:  59%|███████████████▍          | 76/128 [00:52<00:33,  1.55it/s]\u001b[A\n",
      "prompt_batches:  60%|███████████████▋          | 77/128 [00:55<00:46,  1.10it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████          | 79/128 [00:57<00:45,  1.09it/s]\u001b[A\n",
      "prompt_batches:  62%|████████████████▎         | 80/128 [00:57<00:42,  1.14it/s]\u001b[A\n",
      "prompt_batches:  65%|████████████████▊         | 83/128 [00:59<00:34,  1.31it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▋        | 87/128 [01:01<00:24,  1.65it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████        | 89/128 [01:02<00:21,  1.80it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▎       | 90/128 [01:02<00:19,  1.98it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 91/128 [01:05<00:39,  1.07s/it]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 95/128 [01:07<00:22,  1.45it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 96/128 [01:08<00:24,  1.31it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 97/128 [01:09<00:24,  1.27it/s]\u001b[A\n",
      "prompt_batches:  77%|████████████████████      | 99/128 [01:10<00:19,  1.47it/s]\u001b[A\n",
      "prompt_batches:  78%|███████████████████▌     | 100/128 [01:11<00:20,  1.38it/s]\u001b[A\n",
      "prompt_batches:  79%|███████████████████▋     | 101/128 [01:11<00:18,  1.43it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████     | 103/128 [01:12<00:16,  1.54it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 104/128 [01:13<00:17,  1.41it/s]\u001b[A\n",
      "prompt_batches:  82%|████████████████████▌    | 105/128 [01:15<00:22,  1.01it/s]\u001b[A\n",
      "prompt_batches:  84%|█████████████████████    | 108/128 [01:18<00:18,  1.07it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▎   | 109/128 [01:20<00:21,  1.12s/it]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▎  | 114/128 [01:22<00:10,  1.35it/s]\u001b[A\n",
      "prompt_batches:  90%|██████████████████████▍  | 115/128 [01:26<00:15,  1.21s/it]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 122/128 [01:26<00:03,  1.94it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 124/128 [01:28<00:02,  1.81it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 126/128 [01:29<00:01,  1.73it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 128/128 [01:32<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 128 examples in 92.2 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  71%|███████████████████▎       | 5/7 [07:43<03:03, 91.78s/it]INFO:root:Annotating 124 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 124 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                   | 0/124 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   1%|▏                          | 1/124 [00:04<08:16,  4.04s/it]\u001b[A\n",
      "prompt_batches:   5%|█▎                         | 6/124 [00:05<01:25,  1.38it/s]\u001b[A\n",
      "prompt_batches:   6%|█▌                         | 7/124 [00:07<01:57,  1.00s/it]\u001b[A\n",
      "prompt_batches:   6%|█▋                         | 8/124 [00:07<01:38,  1.18it/s]\u001b[A\n",
      "prompt_batches:   8%|██                        | 10/124 [00:08<01:05,  1.73it/s]\u001b[A\n",
      "prompt_batches:  10%|██▌                       | 12/124 [00:10<01:38,  1.14it/s]\u001b[A\n",
      "prompt_batches:  12%|███▏                      | 15/124 [00:11<00:59,  1.84it/s]\u001b[A\n",
      "prompt_batches:  14%|███▌                      | 17/124 [00:13<01:13,  1.46it/s]\u001b[A\n",
      "prompt_batches:  15%|███▉                      | 19/124 [00:15<01:21,  1.28it/s]\u001b[A\n",
      "prompt_batches:  19%|████▊                     | 23/124 [00:16<00:56,  1.80it/s]\u001b[A\n",
      "prompt_batches:  19%|█████                     | 24/124 [00:17<01:09,  1.44it/s]\u001b[A\n",
      "prompt_batches:  21%|█████▍                    | 26/124 [00:20<01:18,  1.25it/s]\u001b[A\n",
      "prompt_batches:  23%|██████                    | 29/124 [00:20<00:57,  1.66it/s]\u001b[A\n",
      "prompt_batches:  25%|██████▌                   | 31/124 [00:22<00:59,  1.57it/s]\u001b[A\n",
      "prompt_batches:  26%|██████▋                   | 32/124 [00:23<01:08,  1.35it/s]\u001b[A\n",
      "prompt_batches:  27%|██████▉                   | 33/124 [00:24<01:03,  1.44it/s]\u001b[A\n",
      "prompt_batches:  28%|███████▎                  | 35/124 [00:26<01:11,  1.24it/s]\u001b[A\n",
      "prompt_batches:  29%|███████▌                  | 36/124 [00:27<01:11,  1.24it/s]\u001b[A\n",
      "prompt_batches:  32%|████████▍                 | 40/124 [00:28<00:42,  1.99it/s]\u001b[A\n",
      "prompt_batches:  33%|████████▌                 | 41/124 [00:29<01:00,  1.38it/s]\u001b[A\n",
      "prompt_batches:  36%|█████████▍                | 45/124 [00:32<00:54,  1.46it/s]\u001b[A\n",
      "prompt_batches:  39%|██████████                | 48/124 [00:33<00:39,  1.92it/s]\u001b[A\n",
      "prompt_batches:  40%|██████████▎               | 49/124 [00:36<01:05,  1.14it/s]\u001b[A\n",
      "prompt_batches:  44%|███████████▎              | 54/124 [00:37<00:37,  1.89it/s]\u001b[A\n",
      "prompt_batches:  45%|███████████▋              | 56/124 [00:38<00:35,  1.89it/s]\u001b[A\n",
      "prompt_batches:  46%|███████████▉              | 57/124 [00:40<00:53,  1.25it/s]\u001b[A\n",
      "prompt_batches:  48%|████████████▎             | 59/124 [00:40<00:39,  1.63it/s]\u001b[A\n",
      "prompt_batches:  50%|█████████████             | 62/124 [00:41<00:31,  1.97it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▏            | 63/124 [00:42<00:35,  1.71it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▍            | 64/124 [00:43<00:35,  1.71it/s]\u001b[A\n",
      "prompt_batches:  52%|█████████████▋            | 65/124 [00:44<00:42,  1.38it/s]\u001b[A\n",
      "prompt_batches:  55%|██████████████▎           | 68/124 [00:45<00:30,  1.85it/s]\u001b[A\n",
      "prompt_batches:  56%|██████████████▍           | 69/124 [00:46<00:27,  1.97it/s]\u001b[A\n",
      "prompt_batches:  57%|██████████████▉           | 71/124 [00:47<00:31,  1.66it/s]\u001b[A\n",
      "prompt_batches:  58%|███████████████           | 72/124 [00:47<00:27,  1.87it/s]\u001b[A\n",
      "prompt_batches:  60%|███████████████▋          | 75/124 [00:54<01:06,  1.35s/it]\u001b[A\n",
      "prompt_batches:  61%|███████████████▉          | 76/124 [00:55<00:54,  1.13s/it]\u001b[A\n",
      "prompt_batches:  65%|████████████████▉         | 81/124 [00:55<00:22,  1.89it/s]\u001b[A\n",
      "prompt_batches:  67%|█████████████████▍        | 83/124 [00:56<00:24,  1.66it/s]\u001b[A\n",
      "prompt_batches:  68%|█████████████████▌        | 84/124 [00:59<00:35,  1.12it/s]\u001b[A\n",
      "prompt_batches:  71%|██████████████████▍       | 88/124 [01:00<00:22,  1.61it/s]\u001b[A\n",
      "prompt_batches:  72%|██████████████████▋       | 89/124 [01:00<00:19,  1.77it/s]\u001b[A\n",
      "prompt_batches:  74%|███████████████████▎      | 92/124 [01:02<00:18,  1.74it/s]\u001b[A\n",
      "prompt_batches:  75%|███████████████████▌      | 93/124 [01:04<00:22,  1.36it/s]\u001b[A\n",
      "prompt_batches:  76%|███████████████████▋      | 94/124 [01:05<00:26,  1.12it/s]\u001b[A\n",
      "prompt_batches:  80%|████████████████████▊     | 99/124 [01:07<00:13,  1.87it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▏    | 100/124 [01:07<00:13,  1.82it/s]\u001b[A\n",
      "prompt_batches:  81%|████████████████████▎    | 101/124 [01:08<00:11,  1.95it/s]\u001b[A\n",
      "prompt_batches:  83%|████████████████████▊    | 103/124 [01:08<00:08,  2.44it/s]\u001b[A\n",
      "prompt_batches:  84%|████████████████████▉    | 104/124 [01:09<00:08,  2.41it/s]\u001b[A\n",
      "prompt_batches:  85%|█████████████████████▏   | 105/124 [01:12<00:19,  1.02s/it]\u001b[A\n",
      "prompt_batches:  89%|██████████████████████▏  | 110/124 [01:16<00:12,  1.11it/s]\u001b[A\n",
      "prompt_batches:  92%|██████████████████████▉  | 114/124 [01:17<00:06,  1.65it/s]\u001b[A\n",
      "prompt_batches:  93%|███████████████████████▏ | 115/124 [01:17<00:05,  1.62it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▍ | 116/124 [01:19<00:05,  1.40it/s]\u001b[A\n",
      "prompt_batches:  94%|███████████████████████▌ | 117/124 [01:19<00:05,  1.38it/s]\u001b[A\n",
      "prompt_batches:  95%|███████████████████████▊ | 118/124 [01:20<00:04,  1.36it/s]\u001b[A\n",
      "prompt_batches:  97%|████████████████████████▏| 120/124 [01:21<00:02,  1.79it/s]\u001b[A\n",
      "prompt_batches:  98%|████████████████████████▌| 122/124 [01:23<00:01,  1.27it/s]\u001b[A\n",
      "prompt_batches: 100%|█████████████████████████| 124/124 [01:24<00:00,  1.47it/s]\u001b[A\n",
      "INFO:root:Completed 124 examples in 84.6 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk:  86%|███████████████████████▏   | 6/7 [09:08<01:29, 89.38s/it]INFO:root:Annotating 37 examples with alpaca_eval_gpt4_turbo_fn\n",
      "INFO:root:Using `openai_completions` on 37 prompts using gpt-4-1106-preview.\n",
      "INFO:root:Kwargs to completion: {'n': 1, 'model': 'gpt-4-1106-preview', 'is_chat': True, 'temperature': 0, 'function_call': {'name': 'make_leaderboard'}, 'functions': [{'name': 'make_leaderboard', 'description': 'Make a leaderboard of models given a list of the models ordered by the preference of their outputs.', 'parameters': {'type': 'object', 'properties': {'ordered_models': {'type': 'array', 'description': 'A list of models ordered by the preference of their outputs', 'items': {'type': 'object', 'properties': {'model': {'type': 'string', 'description': 'The name of the model'}, 'rank': {'type': 'number', 'description': 'Order of preference of the model, 1 has the best output'}}}}}}, 'required': ['ordered_models']}]}. num_procs=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "prompt_batches:   0%|                                    | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches:   3%|▊                           | 1/37 [00:03<02:03,  3.43s/it]\u001b[A\n",
      "prompt_batches:  16%|████▌                       | 6/37 [00:04<00:21,  1.45it/s]\u001b[A\n",
      "prompt_batches:  19%|█████▎                      | 7/37 [00:05<00:19,  1.55it/s]\u001b[A\n",
      "prompt_batches:  24%|██████▊                     | 9/37 [00:07<00:22,  1.26it/s]\u001b[A\n",
      "prompt_batches:  30%|████████                   | 11/37 [00:08<00:17,  1.46it/s]\u001b[A\n",
      "prompt_batches:  32%|████████▊                  | 12/37 [00:11<00:27,  1.08s/it]\u001b[A\n",
      "prompt_batches:  41%|██████████▉                | 15/37 [00:12<00:15,  1.39it/s]\u001b[A\n",
      "prompt_batches:  51%|█████████████▊             | 19/37 [00:12<00:07,  2.40it/s]\u001b[A\n",
      "prompt_batches:  54%|██████████████▌            | 20/37 [00:14<00:10,  1.61it/s]\u001b[A\n",
      "prompt_batches:  59%|████████████████           | 22/37 [00:15<00:08,  1.77it/s]\u001b[A\n",
      "prompt_batches:  65%|█████████████████▌         | 24/37 [00:17<00:10,  1.28it/s]\u001b[A\n",
      "prompt_batches:  70%|██████████████████▉        | 26/37 [00:20<00:10,  1.03it/s]\u001b[A\n",
      "prompt_batches:  84%|██████████████████████▌    | 31/37 [00:21<00:03,  1.68it/s]\u001b[A\n",
      "prompt_batches:  89%|████████████████████████   | 33/37 [00:24<00:02,  1.36it/s]\u001b[A\n",
      "prompt_batches: 100%|███████████████████████████| 37/37 [00:26<00:00,  1.39it/s]\u001b[A\n",
      "INFO:root:Completed 37 examples in 26.8 seconds.\n",
      "INFO:root:Saving all annotations to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "INFO:root:Loading all annotations from results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt/alpaca_eval_annotator_cache.json.\n",
      "Annotation chunk: 100%|███████████████████████████| 7/7 [09:35<00:00, 82.20s/it]\n",
      "/dccstor/data-pruning/wpq/github/mitibm2023/external/alpaca_eval/src/alpaca_eval/metrics.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  series_preferences[series_preferences == 0] = 1.5\n",
      "INFO:root:Saving all results to results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt\n",
      "Price (per-example / total) = 0.0191 / 15.29\n",
      "Time  (per-example / total) = 0.7184 / 574.70\n",
      "                                                                                                                           model  win_rate  standard_error  n_wins  n_wins_base  n_draws  n_total       mode  avg_length  avg_output_tok_length  price\n",
      "0  llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10-greedy-long     19.32            1.39     153          647        5      805  community         607                 172.59  15.29\n",
      "Map: 100%|███████████████████████████| 805/805 [00:00<00:00, 2978.74 examples/s]\n",
      "Filter (num_proc=4): 100%|███████████| 805/805 [00:00<00:00, 4447.74 examples/s]\n",
      "Creating json from Arrow format: 100%|███████████| 1/1 [00:00<00:00, 178.53ba/s]\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python -m eval.alpaca_farm.run_eval --reference_path alpaca_eval_data --model_name_or_path results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3 --max_new_tokens 2048 --save_dir results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=alpaca:eval:gpt4:turbo:fn_chatfmt --eval_batch_size 10 --annotators_config alpaca_eval_gpt4_turbo_fn --use_vllm --use_chat_format --chat_formatting_function eval.templates.create_prompt_with_tulu_chat_format --use_slow_tokenizer --torch_dtype bfloat16\n",
      "[2024-01-21 21:22:39,160] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:loading data and model...\n",
      "INFO 01-21 21:22:41 llm_engine.py:73] Initializing an LLM engine with config: model='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3', tokenizer='results/oi5_dolly:llama-7b/llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)\n",
      "INFO 01-21 21:22:41 tokenizer.py:32] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.\n",
      "MegaBlocks not found. Please install it by `pip install megablocks`. Note that MegaBlocks depends on mosaicml-turbo, which only supports Python 3.10 for now.\n",
      "STK not found: please see https://github.com/stanford-futuredata/stk\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/eval/alpaca_farm/run_eval.py\", line 160, in <module>\n",
      "    main(args)\n",
      "  File \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/eval/alpaca_farm/run_eval.py\", line 38, in main\n",
      "    model = vllm.LLM(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/entrypoints/llm.py\", line 93, in __init__\n",
      "    self.llm_engine = LLMEngine.from_engine_args(engine_args)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 246, in from_engine_args\n",
      "    engine = cls(*engine_configs,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 109, in __init__\n",
      "    self._init_workers(distributed_init_method)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 145, in _init_workers\n",
      "    self._run_workers(\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 750, in _run_workers\n",
      "    self._run_workers_in_batch(workers, method, *args, **kwargs))\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/engine/llm_engine.py\", line 724, in _run_workers_in_batch\n",
      "    output = executor(*args, **kwargs)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/worker/worker.py\", line 72, in load_model\n",
      "    self.model_runner.load_model()\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 36, in load_model\n",
      "    self.model = get_model(self.model_config)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/model_loader.py\", line 124, in get_model\n",
      "    model.load_weights(model_config.model, model_config.download_dir,\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/models/llama.py\", line 335, in load_weights\n",
      "    weight_loader(param, loaded_weight, shard_id)\n",
      "  File \"/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py\", line 303, in weight_loader\n",
      "    param_data.copy_(loaded_weight)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_eval.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859d6d6",
   "metadata": {},
   "source": [
    "# Visualize Eval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b033ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./1387915.out does not have `--save_dir` specified. Probably still running.\n",
      "./1387916.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1387899.out exited with error code. --save_dir=results/oi5_dolly:llama-7b/llama-7b_dolly_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=chatgpt_chatfmt\n"
     ]
    }
   ],
   "source": [
    "# if job successfully ran, lsf system will generate a summary in log_dir,\n",
    "# call this function to move lsf summary to save_dir if job is successful.\n",
    "move_lsf_job_summary_to_save_dir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4392e9ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_fmt=mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_563a3 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_563a3_row0_col0, #T_563a3_row1_col0, #T_563a3_row2_col0, #T_563a3_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_563a3_row0_col1, #T_563a3_row1_col1, #T_563a3_row2_col1, #T_563a3_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_563a3_row0_col2, #T_563a3_row0_col3, #T_563a3_row0_col4, #T_563a3_row0_col5, #T_563a3_row0_col6, #T_563a3_row0_col7, #T_563a3_row0_col8, #T_563a3_row0_col9, #T_563a3_row0_col10, #T_563a3_row0_col12, #T_563a3_row0_col16, #T_563a3_row0_col17, #T_563a3_row1_col10, #T_563a3_row1_col11, #T_563a3_row2_col13, #T_563a3_row2_col14, #T_563a3_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_563a3_row0_col11, #T_563a3_row0_col14, #T_563a3_row0_col15, #T_563a3_row1_col4, #T_563a3_row1_col6, #T_563a3_row1_col8, #T_563a3_row1_col9, #T_563a3_row2_col10, #T_563a3_row3_col2, #T_563a3_row3_col3, #T_563a3_row3_col5, #T_563a3_row3_col7, #T_563a3_row3_col12, #T_563a3_row3_col13, #T_563a3_row3_col16, #T_563a3_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_563a3_row0_col13, #T_563a3_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_563a3_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_563a3_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_563a3_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_563a3_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_563a3_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_563a3_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_563a3_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_563a3_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_563a3_row3_col6, #T_563a3_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_563a3_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_563a3_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_563a3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_563a3_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_563a3_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_563a3_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_563a3_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_563a3_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_563a3_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_563a3_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_563a3_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_563a3_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_563a3_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_563a3_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_563a3_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_563a3_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_563a3_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_563a3_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_563a3_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_563a3_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_563a3_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_563a3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_563a3_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_563a3_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_563a3_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_563a3_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_563a3_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_563a3_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_563a3_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_563a3_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_563a3_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_563a3_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_563a3_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_563a3_row0_col11\" class=\"data row0 col11\" >20.1</td>\n",
       "      <td id=\"T_563a3_row0_col12\" class=\"data row0 col12\" >319.7</td>\n",
       "      <td id=\"T_563a3_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_563a3_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_563a3_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_563a3_row0_col16\" class=\"data row0 col16\" >45.6</td>\n",
       "      <td id=\"T_563a3_row0_col17\" class=\"data row0 col17\" >-15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_563a3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_563a3_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_563a3_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_563a3_row1_col2\" class=\"data row1 col2\" >34.7</td>\n",
       "      <td id=\"T_563a3_row1_col3\" class=\"data row1 col3\" >37.0</td>\n",
       "      <td id=\"T_563a3_row1_col4\" class=\"data row1 col4\" >3.4</td>\n",
       "      <td id=\"T_563a3_row1_col5\" class=\"data row1 col5\" >10.0</td>\n",
       "      <td id=\"T_563a3_row1_col6\" class=\"data row1 col6\" >30.9</td>\n",
       "      <td id=\"T_563a3_row1_col7\" class=\"data row1 col7\" >30.1</td>\n",
       "      <td id=\"T_563a3_row1_col8\" class=\"data row1 col8\" >6.4</td>\n",
       "      <td id=\"T_563a3_row1_col9\" class=\"data row1 col9\" >35.4</td>\n",
       "      <td id=\"T_563a3_row1_col10\" class=\"data row1 col10\" >10.4</td>\n",
       "      <td id=\"T_563a3_row1_col11\" class=\"data row1 col11\" >37.5</td>\n",
       "      <td id=\"T_563a3_row1_col12\" class=\"data row1 col12\" >298.0</td>\n",
       "      <td id=\"T_563a3_row1_col13\" class=\"data row1 col13\" >33.6</td>\n",
       "      <td id=\"T_563a3_row1_col14\" class=\"data row1 col14\" >18.1</td>\n",
       "      <td id=\"T_563a3_row1_col15\" class=\"data row1 col15\" >25.9</td>\n",
       "      <td id=\"T_563a3_row1_col16\" class=\"data row1 col16\" >43.7</td>\n",
       "      <td id=\"T_563a3_row1_col17\" class=\"data row1 col17\" >-20.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_563a3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_563a3_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_563a3_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_563a3_row2_col2\" class=\"data row2 col2\" >33.3</td>\n",
       "      <td id=\"T_563a3_row2_col3\" class=\"data row2 col3\" >37.1</td>\n",
       "      <td id=\"T_563a3_row2_col4\" class=\"data row2 col4\" >4.6</td>\n",
       "      <td id=\"T_563a3_row2_col5\" class=\"data row2 col5\" >9.4</td>\n",
       "      <td id=\"T_563a3_row2_col6\" class=\"data row2 col6\" >31.4</td>\n",
       "      <td id=\"T_563a3_row2_col7\" class=\"data row2 col7\" >28.7</td>\n",
       "      <td id=\"T_563a3_row2_col8\" class=\"data row2 col8\" >7.3</td>\n",
       "      <td id=\"T_563a3_row2_col9\" class=\"data row2 col9\" >35.9</td>\n",
       "      <td id=\"T_563a3_row2_col10\" class=\"data row2 col10\" >7.5</td>\n",
       "      <td id=\"T_563a3_row2_col11\" class=\"data row2 col11\" >33.9</td>\n",
       "      <td id=\"T_563a3_row2_col12\" class=\"data row2 col12\" >172.6</td>\n",
       "      <td id=\"T_563a3_row2_col13\" class=\"data row2 col13\" >38.2</td>\n",
       "      <td id=\"T_563a3_row2_col14\" class=\"data row2 col14\" >20.0</td>\n",
       "      <td id=\"T_563a3_row2_col15\" class=\"data row2 col15\" >29.1</td>\n",
       "      <td id=\"T_563a3_row2_col16\" class=\"data row2 col16\" >34.9</td>\n",
       "      <td id=\"T_563a3_row2_col17\" class=\"data row2 col17\" >-21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_563a3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_563a3_row3_col0\" class=\"data row3 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_563a3_row3_col1\" class=\"data row3 col1\" >10000</td>\n",
       "      <td id=\"T_563a3_row3_col2\" class=\"data row3 col2\" >30.9</td>\n",
       "      <td id=\"T_563a3_row3_col3\" class=\"data row3 col3\" >34.8</td>\n",
       "      <td id=\"T_563a3_row3_col4\" class=\"data row3 col4\" >5.0</td>\n",
       "      <td id=\"T_563a3_row3_col5\" class=\"data row3 col5\" >8.4</td>\n",
       "      <td id=\"T_563a3_row3_col6\" class=\"data row3 col6\" >32.9</td>\n",
       "      <td id=\"T_563a3_row3_col7\" class=\"data row3 col7\" >25.7</td>\n",
       "      <td id=\"T_563a3_row3_col8\" class=\"data row3 col8\" >8.0</td>\n",
       "      <td id=\"T_563a3_row3_col9\" class=\"data row3 col9\" >41.0</td>\n",
       "      <td id=\"T_563a3_row3_col10\" class=\"data row3 col10\" >7.9</td>\n",
       "      <td id=\"T_563a3_row3_col11\" class=\"data row3 col11\" >28.2</td>\n",
       "      <td id=\"T_563a3_row3_col12\" class=\"data row3 col12\" >101.5</td>\n",
       "      <td id=\"T_563a3_row3_col13\" class=\"data row3 col13\" >33.2</td>\n",
       "      <td id=\"T_563a3_row3_col14\" class=\"data row3 col14\" >17.7</td>\n",
       "      <td id=\"T_563a3_row3_col15\" class=\"data row3 col15\" >25.5</td>\n",
       "      <td id=\"T_563a3_row3_col16\" class=\"data row3 col16\" >28.6</td>\n",
       "      <td id=\"T_563a3_row3_col17\" class=\"data row3 col17\" >-23.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee0f05690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_daf59 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_daf59_row0_col0, #T_daf59_row1_col0, #T_daf59_row2_col0, #T_daf59_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_daf59_row0_col1, #T_daf59_row1_col1, #T_daf59_row2_col1, #T_daf59_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_daf59_row0_col2, #T_daf59_row0_col5, #T_daf59_row0_col8, #T_daf59_row0_col9, #T_daf59_row0_col12, #T_daf59_row0_col16, #T_daf59_row0_col17, #T_daf59_row1_col10, #T_daf59_row1_col14, #T_daf59_row2_col3, #T_daf59_row2_col4, #T_daf59_row2_col7, #T_daf59_row2_col11, #T_daf59_row3_col6, #T_daf59_row3_col13, #T_daf59_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row0_col10, #T_daf59_row0_col11, #T_daf59_row0_col13, #T_daf59_row0_col14, #T_daf59_row0_col15, #T_daf59_row1_col2, #T_daf59_row1_col3, #T_daf59_row1_col6, #T_daf59_row1_col7, #T_daf59_row1_col17, #T_daf59_row2_col8, #T_daf59_row2_col9, #T_daf59_row2_col10, #T_daf59_row3_col4, #T_daf59_row3_col5, #T_daf59_row3_col7, #T_daf59_row3_col12, #T_daf59_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row1_col8, #T_daf59_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_daf59_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_daf59_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_daf59\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_daf59_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_daf59_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_daf59_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_daf59_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_daf59_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_daf59_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_daf59_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_daf59_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_daf59_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_daf59_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_daf59_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_daf59_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_daf59_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_daf59_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_daf59_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_daf59_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_daf59_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_daf59_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_daf59_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_daf59_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_daf59_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_daf59_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_daf59_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_daf59_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_daf59_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_daf59_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_daf59_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_daf59_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_daf59_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_daf59_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_daf59_row0_col11\" class=\"data row0 col11\" >20.1</td>\n",
       "      <td id=\"T_daf59_row0_col12\" class=\"data row0 col12\" >319.7</td>\n",
       "      <td id=\"T_daf59_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_daf59_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_daf59_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_daf59_row0_col16\" class=\"data row0 col16\" >45.6</td>\n",
       "      <td id=\"T_daf59_row0_col17\" class=\"data row0 col17\" >-15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daf59_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_daf59_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_daf59_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_daf59_row1_col2\" class=\"data row1 col2\" >36.1</td>\n",
       "      <td id=\"T_daf59_row1_col3\" class=\"data row1 col3\" >35.0</td>\n",
       "      <td id=\"T_daf59_row1_col4\" class=\"data row1 col4\" >4.4</td>\n",
       "      <td id=\"T_daf59_row1_col5\" class=\"data row1 col5\" >10.2</td>\n",
       "      <td id=\"T_daf59_row1_col6\" class=\"data row1 col6\" >31.2</td>\n",
       "      <td id=\"T_daf59_row1_col7\" class=\"data row1 col7\" >30.3</td>\n",
       "      <td id=\"T_daf59_row1_col8\" class=\"data row1 col8\" >8.6</td>\n",
       "      <td id=\"T_daf59_row1_col9\" class=\"data row1 col9\" >42.1</td>\n",
       "      <td id=\"T_daf59_row1_col10\" class=\"data row1 col10\" >11.6</td>\n",
       "      <td id=\"T_daf59_row1_col11\" class=\"data row1 col11\" >26.7</td>\n",
       "      <td id=\"T_daf59_row1_col12\" class=\"data row1 col12\" >277.6</td>\n",
       "      <td id=\"T_daf59_row1_col13\" class=\"data row1 col13\" >35.8</td>\n",
       "      <td id=\"T_daf59_row1_col14\" class=\"data row1 col14\" >19.7</td>\n",
       "      <td id=\"T_daf59_row1_col15\" class=\"data row1 col15\" >27.8</td>\n",
       "      <td id=\"T_daf59_row1_col16\" class=\"data row1 col16\" >42.6</td>\n",
       "      <td id=\"T_daf59_row1_col17\" class=\"data row1 col17\" >-18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daf59_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_daf59_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_daf59_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_daf59_row2_col2\" class=\"data row2 col2\" >36.6</td>\n",
       "      <td id=\"T_daf59_row2_col3\" class=\"data row2 col3\" >39.2</td>\n",
       "      <td id=\"T_daf59_row2_col4\" class=\"data row2 col4\" >5.6</td>\n",
       "      <td id=\"T_daf59_row2_col5\" class=\"data row2 col5\" >9.6</td>\n",
       "      <td id=\"T_daf59_row2_col6\" class=\"data row2 col6\" >33.5</td>\n",
       "      <td id=\"T_daf59_row2_col7\" class=\"data row2 col7\" >33.1</td>\n",
       "      <td id=\"T_daf59_row2_col8\" class=\"data row2 col8\" >7.5</td>\n",
       "      <td id=\"T_daf59_row2_col9\" class=\"data row2 col9\" >37.7</td>\n",
       "      <td id=\"T_daf59_row2_col10\" class=\"data row2 col10\" >10.4</td>\n",
       "      <td id=\"T_daf59_row2_col11\" class=\"data row2 col11\" >28.1</td>\n",
       "      <td id=\"T_daf59_row2_col12\" class=\"data row2 col12\" >263.1</td>\n",
       "      <td id=\"T_daf59_row2_col13\" class=\"data row2 col13\" >38.5</td>\n",
       "      <td id=\"T_daf59_row2_col14\" class=\"data row2 col14\" >19.5</td>\n",
       "      <td id=\"T_daf59_row2_col15\" class=\"data row2 col15\" >29.1</td>\n",
       "      <td id=\"T_daf59_row2_col16\" class=\"data row2 col16\" >42.3</td>\n",
       "      <td id=\"T_daf59_row2_col17\" class=\"data row2 col17\" >-16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daf59_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_daf59_row3_col0\" class=\"data row3 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_daf59_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_daf59_row3_col2\" class=\"data row3 col2\" >36.9</td>\n",
       "      <td id=\"T_daf59_row3_col3\" class=\"data row3 col3\" >37.1</td>\n",
       "      <td id=\"T_daf59_row3_col4\" class=\"data row3 col4\" >3.0</td>\n",
       "      <td id=\"T_daf59_row3_col5\" class=\"data row3 col5\" >9.4</td>\n",
       "      <td id=\"T_daf59_row3_col6\" class=\"data row3 col6\" >34.1</td>\n",
       "      <td id=\"T_daf59_row3_col7\" class=\"data row3 col7\" >30.3</td>\n",
       "      <td id=\"T_daf59_row3_col8\" class=\"data row3 col8\" >8.0</td>\n",
       "      <td id=\"T_daf59_row3_col9\" class=\"data row3 col9\" >40.9</td>\n",
       "      <td id=\"T_daf59_row3_col10\" class=\"data row3 col10\" >10.6</td>\n",
       "      <td id=\"T_daf59_row3_col11\" class=\"data row3 col11\" >26.5</td>\n",
       "      <td id=\"T_daf59_row3_col12\" class=\"data row3 col12\" >260.5</td>\n",
       "      <td id=\"T_daf59_row3_col13\" class=\"data row3 col13\" >40.1</td>\n",
       "      <td id=\"T_daf59_row3_col14\" class=\"data row3 col14\" >18.2</td>\n",
       "      <td id=\"T_daf59_row3_col15\" class=\"data row3 col15\" >29.4</td>\n",
       "      <td id=\"T_daf59_row3_col16\" class=\"data row3 col16\" >41.8</td>\n",
       "      <td id=\"T_daf59_row3_col17\" class=\"data row3 col17\" >-18.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee0f14eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_20328 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_20328_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_20328_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_20328_row0_col2, #T_20328_row0_col3, #T_20328_row0_col4, #T_20328_row0_col5, #T_20328_row0_col6, #T_20328_row0_col7, #T_20328_row0_col8, #T_20328_row0_col9, #T_20328_row0_col10, #T_20328_row0_col11, #T_20328_row0_col12, #T_20328_row0_col13, #T_20328_row0_col14, #T_20328_row0_col15, #T_20328_row0_col16, #T_20328_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_20328\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_20328_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_20328_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_20328_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_20328_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_20328_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_20328_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_20328_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_20328_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_20328_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_20328_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_20328_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_20328_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_20328_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_20328_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_20328_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_20328_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_20328_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_20328_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_20328_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_20328_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_20328_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_20328_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_20328_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_20328_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_20328_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_20328_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_20328_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_20328_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_20328_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_20328_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_20328_row0_col11\" class=\"data row0 col11\" >20.1</td>\n",
       "      <td id=\"T_20328_row0_col12\" class=\"data row0 col12\" >319.7</td>\n",
       "      <td id=\"T_20328_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_20328_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_20328_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_20328_row0_col16\" class=\"data row0 col16\" >45.6</td>\n",
       "      <td id=\"T_20328_row0_col17\" class=\"data row0 col17\" >-15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee0f17a00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fbea7 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_fbea7_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fbea7_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fbea7_row0_col2, #T_fbea7_row0_col3, #T_fbea7_row0_col4, #T_fbea7_row0_col5, #T_fbea7_row0_col6, #T_fbea7_row0_col7, #T_fbea7_row0_col8, #T_fbea7_row0_col9, #T_fbea7_row0_col10, #T_fbea7_row0_col11, #T_fbea7_row0_col12, #T_fbea7_row0_col13, #T_fbea7_row0_col14, #T_fbea7_row0_col15, #T_fbea7_row0_col16, #T_fbea7_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fbea7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fbea7_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_fbea7_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_fbea7_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_fbea7_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_fbea7_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_fbea7_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_fbea7_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_fbea7_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_fbea7_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_fbea7_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_fbea7_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_fbea7_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_fbea7_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_fbea7_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_fbea7_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_fbea7_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_fbea7_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_fbea7_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fbea7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fbea7_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_fbea7_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_fbea7_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_fbea7_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_fbea7_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_fbea7_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_fbea7_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_fbea7_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_fbea7_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_fbea7_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_fbea7_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_fbea7_row0_col11\" class=\"data row0 col11\" >20.1</td>\n",
       "      <td id=\"T_fbea7_row0_col12\" class=\"data row0 col12\" >319.7</td>\n",
       "      <td id=\"T_fbea7_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_fbea7_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_fbea7_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_fbea7_row0_col16\" class=\"data row0 col16\" >45.6</td>\n",
       "      <td id=\"T_fbea7_row0_col17\" class=\"data row0 col17\" >-15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee0f15ff0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d70f8 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_d70f8_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d70f8_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d70f8_row0_col2, #T_d70f8_row0_col3, #T_d70f8_row0_col4, #T_d70f8_row0_col5, #T_d70f8_row0_col6, #T_d70f8_row0_col7, #T_d70f8_row0_col8, #T_d70f8_row0_col9, #T_d70f8_row0_col10, #T_d70f8_row0_col11, #T_d70f8_row0_col12, #T_d70f8_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d70f8_row0_col13, #T_d70f8_row0_col14, #T_d70f8_row0_col15, #T_d70f8_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d70f8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d70f8_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d70f8_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_d70f8_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d70f8_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d70f8_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_d70f8_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_d70f8_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_d70f8_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_d70f8_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d70f8_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d70f8_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d70f8_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_d70f8_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_d70f8_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_d70f8_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_d70f8_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_d70f8_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_d70f8_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d70f8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d70f8_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_d70f8_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_d70f8_row0_col2\" class=\"data row0 col2\" >44.3</td>\n",
       "      <td id=\"T_d70f8_row0_col3\" class=\"data row0 col3\" >45.7</td>\n",
       "      <td id=\"T_d70f8_row0_col4\" class=\"data row0 col4\" >3.0</td>\n",
       "      <td id=\"T_d70f8_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_d70f8_row0_col6\" class=\"data row0 col6\" >36.8</td>\n",
       "      <td id=\"T_d70f8_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_d70f8_row0_col8\" class=\"data row0 col8\" >8.4</td>\n",
       "      <td id=\"T_d70f8_row0_col9\" class=\"data row0 col9\" >43.3</td>\n",
       "      <td id=\"T_d70f8_row0_col10\" class=\"data row0 col10\" >8.5</td>\n",
       "      <td id=\"T_d70f8_row0_col11\" class=\"data row0 col11\" >8.0</td>\n",
       "      <td id=\"T_d70f8_row0_col12\" class=\"data row0 col12\" >101.4</td>\n",
       "      <td id=\"T_d70f8_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_d70f8_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_d70f8_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_d70f8_row0_col16\" class=\"data row0 col16\" >31.4</td>\n",
       "      <td id=\"T_d70f8_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee14af370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9371b td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_9371b_row0_col0, #T_9371b_row1_col0, #T_9371b_row2_col0, #T_9371b_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9371b_row0_col1, #T_9371b_row1_col1, #T_9371b_row2_col1, #T_9371b_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9371b_row0_col2, #T_9371b_row0_col3, #T_9371b_row0_col4, #T_9371b_row0_col5, #T_9371b_row0_col6, #T_9371b_row0_col7, #T_9371b_row0_col8, #T_9371b_row0_col9, #T_9371b_row0_col10, #T_9371b_row0_col11, #T_9371b_row0_col12, #T_9371b_row1_col2, #T_9371b_row1_col3, #T_9371b_row1_col4, #T_9371b_row1_col5, #T_9371b_row1_col6, #T_9371b_row1_col7, #T_9371b_row1_col8, #T_9371b_row1_col9, #T_9371b_row1_col10, #T_9371b_row1_col11, #T_9371b_row1_col12, #T_9371b_row2_col2, #T_9371b_row2_col3, #T_9371b_row2_col4, #T_9371b_row2_col5, #T_9371b_row2_col6, #T_9371b_row2_col7, #T_9371b_row2_col8, #T_9371b_row2_col9, #T_9371b_row2_col10, #T_9371b_row2_col11, #T_9371b_row2_col12, #T_9371b_row2_col14, #T_9371b_row3_col2, #T_9371b_row3_col3, #T_9371b_row3_col4, #T_9371b_row3_col5, #T_9371b_row3_col6, #T_9371b_row3_col7, #T_9371b_row3_col8, #T_9371b_row3_col9, #T_9371b_row3_col10, #T_9371b_row3_col11, #T_9371b_row3_col12, #T_9371b_row3_col13, #T_9371b_row3_col15, #T_9371b_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9371b_row0_col13, #T_9371b_row0_col14, #T_9371b_row0_col15, #T_9371b_row0_col17, #T_9371b_row1_col17, #T_9371b_row2_col17, #T_9371b_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9371b_row0_col16, #T_9371b_row1_col15, #T_9371b_row2_col13, #T_9371b_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9371b_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9371b_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9371b_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9371b_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9371b_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9371b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9371b_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_9371b_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_9371b_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_9371b_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_9371b_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_9371b_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_9371b_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_9371b_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_9371b_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_9371b_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_9371b_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_9371b_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_9371b_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_9371b_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_9371b_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_9371b_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_9371b_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_9371b_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9371b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9371b_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_9371b_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_9371b_row0_col2\" class=\"data row0 col2\" >44.3</td>\n",
       "      <td id=\"T_9371b_row0_col3\" class=\"data row0 col3\" >45.7</td>\n",
       "      <td id=\"T_9371b_row0_col4\" class=\"data row0 col4\" >3.0</td>\n",
       "      <td id=\"T_9371b_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_9371b_row0_col6\" class=\"data row0 col6\" >36.8</td>\n",
       "      <td id=\"T_9371b_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_9371b_row0_col8\" class=\"data row0 col8\" >8.4</td>\n",
       "      <td id=\"T_9371b_row0_col9\" class=\"data row0 col9\" >43.3</td>\n",
       "      <td id=\"T_9371b_row0_col10\" class=\"data row0 col10\" >8.5</td>\n",
       "      <td id=\"T_9371b_row0_col11\" class=\"data row0 col11\" >8.0</td>\n",
       "      <td id=\"T_9371b_row0_col12\" class=\"data row0 col12\" >101.4</td>\n",
       "      <td id=\"T_9371b_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_9371b_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_9371b_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_9371b_row0_col16\" class=\"data row0 col16\" >31.4</td>\n",
       "      <td id=\"T_9371b_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9371b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9371b_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_9371b_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_9371b_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_9371b_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_9371b_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_9371b_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_9371b_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_9371b_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_9371b_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_9371b_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_9371b_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_9371b_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_9371b_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_9371b_row1_col13\" class=\"data row1 col13\" >24.6</td>\n",
       "      <td id=\"T_9371b_row1_col14\" class=\"data row1 col14\" >18.0</td>\n",
       "      <td id=\"T_9371b_row1_col15\" class=\"data row1 col15\" >21.3</td>\n",
       "      <td id=\"T_9371b_row1_col16\" class=\"data row1 col16\" >21.3</td>\n",
       "      <td id=\"T_9371b_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9371b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9371b_row2_col0\" class=\"data row2 col0\" >llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_9371b_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_9371b_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_9371b_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_9371b_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "      <td id=\"T_9371b_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_9371b_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "      <td id=\"T_9371b_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_9371b_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_9371b_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_9371b_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_9371b_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_9371b_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_9371b_row2_col13\" class=\"data row2 col13\" >25.9</td>\n",
       "      <td id=\"T_9371b_row2_col14\" class=\"data row2 col14\" >16.2</td>\n",
       "      <td id=\"T_9371b_row2_col15\" class=\"data row2 col15\" >21.1</td>\n",
       "      <td id=\"T_9371b_row2_col16\" class=\"data row2 col16\" >21.1</td>\n",
       "      <td id=\"T_9371b_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9371b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9371b_row3_col0\" class=\"data row3 col0\" >llama-7b_flan_v250k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_9371b_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_9371b_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
       "      <td id=\"T_9371b_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
       "      <td id=\"T_9371b_row3_col4\" class=\"data row3 col4\" >nan</td>\n",
       "      <td id=\"T_9371b_row3_col5\" class=\"data row3 col5\" >nan</td>\n",
       "      <td id=\"T_9371b_row3_col6\" class=\"data row3 col6\" >nan</td>\n",
       "      <td id=\"T_9371b_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "      <td id=\"T_9371b_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
       "      <td id=\"T_9371b_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
       "      <td id=\"T_9371b_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
       "      <td id=\"T_9371b_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_9371b_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_9371b_row3_col13\" class=\"data row3 col13\" >23.5</td>\n",
       "      <td id=\"T_9371b_row3_col14\" class=\"data row3 col14\" >18.4</td>\n",
       "      <td id=\"T_9371b_row3_col15\" class=\"data row3 col15\" >20.9</td>\n",
       "      <td id=\"T_9371b_row3_col16\" class=\"data row3 col16\" >20.9</td>\n",
       "      <td id=\"T_9371b_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee0e05c30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5d855 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_5d855_row0_col0, #T_5d855_row1_col0, #T_5d855_row2_col0, #T_5d855_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5d855_row0_col1, #T_5d855_row1_col1, #T_5d855_row2_col1, #T_5d855_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5d855_row0_col2, #T_5d855_row0_col3, #T_5d855_row0_col4, #T_5d855_row0_col5, #T_5d855_row0_col6, #T_5d855_row0_col7, #T_5d855_row0_col8, #T_5d855_row0_col9, #T_5d855_row0_col10, #T_5d855_row0_col11, #T_5d855_row0_col12, #T_5d855_row1_col2, #T_5d855_row1_col3, #T_5d855_row1_col4, #T_5d855_row1_col5, #T_5d855_row1_col6, #T_5d855_row1_col7, #T_5d855_row1_col8, #T_5d855_row1_col9, #T_5d855_row1_col10, #T_5d855_row1_col11, #T_5d855_row1_col12, #T_5d855_row2_col2, #T_5d855_row2_col3, #T_5d855_row2_col4, #T_5d855_row2_col5, #T_5d855_row2_col6, #T_5d855_row2_col7, #T_5d855_row2_col8, #T_5d855_row2_col9, #T_5d855_row2_col10, #T_5d855_row2_col11, #T_5d855_row2_col12, #T_5d855_row2_col13, #T_5d855_row3_col2, #T_5d855_row3_col3, #T_5d855_row3_col4, #T_5d855_row3_col5, #T_5d855_row3_col6, #T_5d855_row3_col7, #T_5d855_row3_col8, #T_5d855_row3_col9, #T_5d855_row3_col10, #T_5d855_row3_col11, #T_5d855_row3_col12, #T_5d855_row3_col14, #T_5d855_row3_col15, #T_5d855_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d855_row0_col13, #T_5d855_row0_col14, #T_5d855_row0_col15, #T_5d855_row0_col17, #T_5d855_row1_col17, #T_5d855_row2_col17, #T_5d855_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d855_row0_col16, #T_5d855_row1_col13, #T_5d855_row1_col15, #T_5d855_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d855_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d855_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d855_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5d855_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d855_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5d855\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5d855_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_5d855_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_5d855_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_5d855_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_5d855_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_5d855_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_5d855_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_5d855_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_5d855_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_5d855_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_5d855_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_5d855_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_5d855_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_5d855_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_5d855_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_5d855_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_5d855_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_5d855_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5d855_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5d855_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_5d855_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_5d855_row0_col2\" class=\"data row0 col2\" >44.3</td>\n",
       "      <td id=\"T_5d855_row0_col3\" class=\"data row0 col3\" >45.7</td>\n",
       "      <td id=\"T_5d855_row0_col4\" class=\"data row0 col4\" >3.0</td>\n",
       "      <td id=\"T_5d855_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_5d855_row0_col6\" class=\"data row0 col6\" >36.8</td>\n",
       "      <td id=\"T_5d855_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_5d855_row0_col8\" class=\"data row0 col8\" >8.4</td>\n",
       "      <td id=\"T_5d855_row0_col9\" class=\"data row0 col9\" >43.3</td>\n",
       "      <td id=\"T_5d855_row0_col10\" class=\"data row0 col10\" >8.5</td>\n",
       "      <td id=\"T_5d855_row0_col11\" class=\"data row0 col11\" >8.0</td>\n",
       "      <td id=\"T_5d855_row0_col12\" class=\"data row0 col12\" >101.4</td>\n",
       "      <td id=\"T_5d855_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_5d855_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_5d855_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_5d855_row0_col16\" class=\"data row0 col16\" >31.4</td>\n",
       "      <td id=\"T_5d855_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d855_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5d855_row1_col0\" class=\"data row1 col0\" >llama-7b_flan_v250k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_5d855_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_5d855_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_5d855_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_5d855_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_5d855_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_5d855_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_5d855_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_5d855_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_5d855_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_5d855_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_5d855_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_5d855_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_5d855_row1_col13\" class=\"data row1 col13\" >24.0</td>\n",
       "      <td id=\"T_5d855_row1_col14\" class=\"data row1 col14\" >18.4</td>\n",
       "      <td id=\"T_5d855_row1_col15\" class=\"data row1 col15\" >21.2</td>\n",
       "      <td id=\"T_5d855_row1_col16\" class=\"data row1 col16\" >21.2</td>\n",
       "      <td id=\"T_5d855_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d855_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5d855_row2_col0\" class=\"data row2 col0\" >llama-7b_flan_v250k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_5d855_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_5d855_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_5d855_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_5d855_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "      <td id=\"T_5d855_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_5d855_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "      <td id=\"T_5d855_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_5d855_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_5d855_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_5d855_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_5d855_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_5d855_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_5d855_row2_col13\" class=\"data row2 col13\" >22.1</td>\n",
       "      <td id=\"T_5d855_row2_col14\" class=\"data row2 col14\" >19.0</td>\n",
       "      <td id=\"T_5d855_row2_col15\" class=\"data row2 col15\" >20.6</td>\n",
       "      <td id=\"T_5d855_row2_col16\" class=\"data row2 col16\" >20.6</td>\n",
       "      <td id=\"T_5d855_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d855_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5d855_row3_col0\" class=\"data row3 col0\" >llama-7b_flan_v250k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_5d855_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_5d855_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
       "      <td id=\"T_5d855_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
       "      <td id=\"T_5d855_row3_col4\" class=\"data row3 col4\" >nan</td>\n",
       "      <td id=\"T_5d855_row3_col5\" class=\"data row3 col5\" >nan</td>\n",
       "      <td id=\"T_5d855_row3_col6\" class=\"data row3 col6\" >nan</td>\n",
       "      <td id=\"T_5d855_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "      <td id=\"T_5d855_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
       "      <td id=\"T_5d855_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
       "      <td id=\"T_5d855_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
       "      <td id=\"T_5d855_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_5d855_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_5d855_row3_col13\" class=\"data row3 col13\" >22.6</td>\n",
       "      <td id=\"T_5d855_row3_col14\" class=\"data row3 col14\" >15.9</td>\n",
       "      <td id=\"T_5d855_row3_col15\" class=\"data row3 col15\" >19.2</td>\n",
       "      <td id=\"T_5d855_row3_col16\" class=\"data row3 col16\" >19.2</td>\n",
       "      <td id=\"T_5d855_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee28e3c70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_219e2 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_219e2_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_219e2_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_219e2_row0_col2, #T_219e2_row0_col3, #T_219e2_row0_col4, #T_219e2_row0_col5, #T_219e2_row0_col6, #T_219e2_row0_col7, #T_219e2_row0_col8, #T_219e2_row0_col9, #T_219e2_row0_col10, #T_219e2_row0_col11, #T_219e2_row0_col12, #T_219e2_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_219e2_row0_col13, #T_219e2_row0_col14, #T_219e2_row0_col15, #T_219e2_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_219e2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_219e2_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_219e2_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_219e2_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_219e2_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_219e2_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_219e2_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_219e2_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_219e2_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_219e2_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_219e2_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_219e2_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_219e2_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_219e2_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_219e2_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_219e2_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_219e2_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_219e2_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_219e2_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_219e2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_219e2_row0_col0\" class=\"data row0 col0\" >llama-7b_flan_v250k_ep=2</td>\n",
       "      <td id=\"T_219e2_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_219e2_row0_col2\" class=\"data row0 col2\" >44.3</td>\n",
       "      <td id=\"T_219e2_row0_col3\" class=\"data row0 col3\" >45.7</td>\n",
       "      <td id=\"T_219e2_row0_col4\" class=\"data row0 col4\" >3.0</td>\n",
       "      <td id=\"T_219e2_row0_col5\" class=\"data row0 col5\" >11.8</td>\n",
       "      <td id=\"T_219e2_row0_col6\" class=\"data row0 col6\" >36.8</td>\n",
       "      <td id=\"T_219e2_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_219e2_row0_col8\" class=\"data row0 col8\" >8.4</td>\n",
       "      <td id=\"T_219e2_row0_col9\" class=\"data row0 col9\" >43.3</td>\n",
       "      <td id=\"T_219e2_row0_col10\" class=\"data row0 col10\" >8.5</td>\n",
       "      <td id=\"T_219e2_row0_col11\" class=\"data row0 col11\" >8.0</td>\n",
       "      <td id=\"T_219e2_row0_col12\" class=\"data row0 col12\" >101.4</td>\n",
       "      <td id=\"T_219e2_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_219e2_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_219e2_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_219e2_row0_col16\" class=\"data row0 col16\" >31.4</td>\n",
       "      <td id=\"T_219e2_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee0e06da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ea5c5 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_ea5c5_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ea5c5_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ea5c5_row0_col2, #T_ea5c5_row0_col3, #T_ea5c5_row0_col4, #T_ea5c5_row0_col5, #T_ea5c5_row0_col6, #T_ea5c5_row0_col7, #T_ea5c5_row0_col8, #T_ea5c5_row0_col9, #T_ea5c5_row0_col10, #T_ea5c5_row0_col11, #T_ea5c5_row0_col12, #T_ea5c5_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea5c5_row0_col13, #T_ea5c5_row0_col14, #T_ea5c5_row0_col15, #T_ea5c5_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ea5c5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ea5c5_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_ea5c5_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_ea5c5_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_ea5c5_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_ea5c5_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_ea5c5_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_ea5c5_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_ea5c5_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_ea5c5_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_ea5c5_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_ea5c5_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_ea5c5_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_ea5c5_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_ea5c5_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_ea5c5_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_ea5c5_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_ea5c5_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_ea5c5_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ea5c5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ea5c5_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_ea5c5_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_ea5c5_row0_col2\" class=\"data row0 col2\" >31.3</td>\n",
       "      <td id=\"T_ea5c5_row0_col3\" class=\"data row0 col3\" >34.6</td>\n",
       "      <td id=\"T_ea5c5_row0_col4\" class=\"data row0 col4\" >5.2</td>\n",
       "      <td id=\"T_ea5c5_row0_col5\" class=\"data row0 col5\" >10.2</td>\n",
       "      <td id=\"T_ea5c5_row0_col6\" class=\"data row0 col6\" >32.6</td>\n",
       "      <td id=\"T_ea5c5_row0_col7\" class=\"data row0 col7\" >32.8</td>\n",
       "      <td id=\"T_ea5c5_row0_col8\" class=\"data row0 col8\" >8.9</td>\n",
       "      <td id=\"T_ea5c5_row0_col9\" class=\"data row0 col9\" >31.9</td>\n",
       "      <td id=\"T_ea5c5_row0_col10\" class=\"data row0 col10\" >9.8</td>\n",
       "      <td id=\"T_ea5c5_row0_col11\" class=\"data row0 col11\" >42.9</td>\n",
       "      <td id=\"T_ea5c5_row0_col12\" class=\"data row0 col12\" >278.1</td>\n",
       "      <td id=\"T_ea5c5_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_ea5c5_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_ea5c5_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_ea5c5_row0_col16\" class=\"data row0 col16\" >47.1</td>\n",
       "      <td id=\"T_ea5c5_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee0e060b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dd375 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_dd375_row0_col0, #T_dd375_row1_col0, #T_dd375_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_dd375_row0_col1, #T_dd375_row1_col1, #T_dd375_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_dd375_row0_col2, #T_dd375_row0_col3, #T_dd375_row0_col4, #T_dd375_row0_col5, #T_dd375_row0_col6, #T_dd375_row0_col7, #T_dd375_row0_col8, #T_dd375_row0_col9, #T_dd375_row0_col10, #T_dd375_row0_col11, #T_dd375_row0_col12, #T_dd375_row1_col2, #T_dd375_row1_col3, #T_dd375_row1_col4, #T_dd375_row1_col5, #T_dd375_row1_col6, #T_dd375_row1_col7, #T_dd375_row1_col8, #T_dd375_row1_col9, #T_dd375_row1_col10, #T_dd375_row1_col11, #T_dd375_row1_col12, #T_dd375_row1_col13, #T_dd375_row1_col15, #T_dd375_row1_col16, #T_dd375_row2_col2, #T_dd375_row2_col3, #T_dd375_row2_col4, #T_dd375_row2_col5, #T_dd375_row2_col6, #T_dd375_row2_col7, #T_dd375_row2_col8, #T_dd375_row2_col9, #T_dd375_row2_col10, #T_dd375_row2_col11, #T_dd375_row2_col12, #T_dd375_row2_col14, #T_dd375_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dd375_row0_col13, #T_dd375_row0_col14, #T_dd375_row0_col15, #T_dd375_row0_col17, #T_dd375_row1_col17, #T_dd375_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dd375_row0_col16, #T_dd375_row1_col14, #T_dd375_row2_col13, #T_dd375_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dd375\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dd375_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_dd375_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_dd375_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_dd375_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_dd375_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_dd375_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_dd375_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_dd375_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_dd375_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_dd375_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_dd375_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_dd375_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_dd375_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_dd375_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_dd375_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_dd375_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_dd375_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_dd375_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dd375_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_dd375_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_dd375_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_dd375_row0_col2\" class=\"data row0 col2\" >31.3</td>\n",
       "      <td id=\"T_dd375_row0_col3\" class=\"data row0 col3\" >34.6</td>\n",
       "      <td id=\"T_dd375_row0_col4\" class=\"data row0 col4\" >5.2</td>\n",
       "      <td id=\"T_dd375_row0_col5\" class=\"data row0 col5\" >10.2</td>\n",
       "      <td id=\"T_dd375_row0_col6\" class=\"data row0 col6\" >32.6</td>\n",
       "      <td id=\"T_dd375_row0_col7\" class=\"data row0 col7\" >32.8</td>\n",
       "      <td id=\"T_dd375_row0_col8\" class=\"data row0 col8\" >8.9</td>\n",
       "      <td id=\"T_dd375_row0_col9\" class=\"data row0 col9\" >31.9</td>\n",
       "      <td id=\"T_dd375_row0_col10\" class=\"data row0 col10\" >9.8</td>\n",
       "      <td id=\"T_dd375_row0_col11\" class=\"data row0 col11\" >42.9</td>\n",
       "      <td id=\"T_dd375_row0_col12\" class=\"data row0 col12\" >278.1</td>\n",
       "      <td id=\"T_dd375_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_dd375_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_dd375_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_dd375_row0_col16\" class=\"data row0 col16\" >47.1</td>\n",
       "      <td id=\"T_dd375_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd375_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_dd375_row1_col0\" class=\"data row1 col0\" >llama-7b_oasst2_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_dd375_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_dd375_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_dd375_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_dd375_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_dd375_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_dd375_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_dd375_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_dd375_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_dd375_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_dd375_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_dd375_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_dd375_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_dd375_row1_col13\" class=\"data row1 col13\" >39.5</td>\n",
       "      <td id=\"T_dd375_row1_col14\" class=\"data row1 col14\" >27.6</td>\n",
       "      <td id=\"T_dd375_row1_col15\" class=\"data row1 col15\" >33.6</td>\n",
       "      <td id=\"T_dd375_row1_col16\" class=\"data row1 col16\" >33.6</td>\n",
       "      <td id=\"T_dd375_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd375_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_dd375_row2_col0\" class=\"data row2 col0\" >llama-7b_oasst2_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_dd375_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_dd375_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_dd375_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_dd375_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "      <td id=\"T_dd375_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_dd375_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "      <td id=\"T_dd375_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_dd375_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_dd375_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_dd375_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_dd375_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_dd375_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_dd375_row2_col13\" class=\"data row2 col13\" >39.8</td>\n",
       "      <td id=\"T_dd375_row2_col14\" class=\"data row2 col14\" >27.3</td>\n",
       "      <td id=\"T_dd375_row2_col15\" class=\"data row2 col15\" >33.6</td>\n",
       "      <td id=\"T_dd375_row2_col16\" class=\"data row2 col16\" >33.6</td>\n",
       "      <td id=\"T_dd375_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee0f145e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_133b7 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_133b7_row0_col0, #T_133b7_row1_col0, #T_133b7_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_133b7_row0_col1, #T_133b7_row1_col1, #T_133b7_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_133b7_row0_col2, #T_133b7_row0_col3, #T_133b7_row0_col4, #T_133b7_row0_col5, #T_133b7_row0_col6, #T_133b7_row0_col7, #T_133b7_row0_col8, #T_133b7_row0_col9, #T_133b7_row0_col10, #T_133b7_row0_col11, #T_133b7_row0_col12, #T_133b7_row1_col2, #T_133b7_row1_col3, #T_133b7_row1_col4, #T_133b7_row1_col5, #T_133b7_row1_col6, #T_133b7_row1_col7, #T_133b7_row1_col8, #T_133b7_row1_col9, #T_133b7_row1_col10, #T_133b7_row1_col11, #T_133b7_row1_col12, #T_133b7_row2_col2, #T_133b7_row2_col3, #T_133b7_row2_col4, #T_133b7_row2_col5, #T_133b7_row2_col6, #T_133b7_row2_col7, #T_133b7_row2_col8, #T_133b7_row2_col9, #T_133b7_row2_col10, #T_133b7_row2_col11, #T_133b7_row2_col12, #T_133b7_row2_col13, #T_133b7_row2_col14, #T_133b7_row2_col15, #T_133b7_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_133b7_row0_col13, #T_133b7_row0_col14, #T_133b7_row0_col15, #T_133b7_row0_col17, #T_133b7_row1_col17, #T_133b7_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_133b7_row0_col16, #T_133b7_row1_col13, #T_133b7_row1_col14, #T_133b7_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_133b7_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_133b7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_133b7_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_133b7_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_133b7_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_133b7_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_133b7_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_133b7_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_133b7_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_133b7_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_133b7_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_133b7_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_133b7_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_133b7_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_133b7_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_133b7_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_133b7_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_133b7_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_133b7_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_133b7_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_133b7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_133b7_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_133b7_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_133b7_row0_col2\" class=\"data row0 col2\" >31.3</td>\n",
       "      <td id=\"T_133b7_row0_col3\" class=\"data row0 col3\" >34.6</td>\n",
       "      <td id=\"T_133b7_row0_col4\" class=\"data row0 col4\" >5.2</td>\n",
       "      <td id=\"T_133b7_row0_col5\" class=\"data row0 col5\" >10.2</td>\n",
       "      <td id=\"T_133b7_row0_col6\" class=\"data row0 col6\" >32.6</td>\n",
       "      <td id=\"T_133b7_row0_col7\" class=\"data row0 col7\" >32.8</td>\n",
       "      <td id=\"T_133b7_row0_col8\" class=\"data row0 col8\" >8.9</td>\n",
       "      <td id=\"T_133b7_row0_col9\" class=\"data row0 col9\" >31.9</td>\n",
       "      <td id=\"T_133b7_row0_col10\" class=\"data row0 col10\" >9.8</td>\n",
       "      <td id=\"T_133b7_row0_col11\" class=\"data row0 col11\" >42.9</td>\n",
       "      <td id=\"T_133b7_row0_col12\" class=\"data row0 col12\" >278.1</td>\n",
       "      <td id=\"T_133b7_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_133b7_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_133b7_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_133b7_row0_col16\" class=\"data row0 col16\" >47.1</td>\n",
       "      <td id=\"T_133b7_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_133b7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_133b7_row1_col0\" class=\"data row1 col0\" >llama-7b_oasst2_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_133b7_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_133b7_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_133b7_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_133b7_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_133b7_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_133b7_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_133b7_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_133b7_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_133b7_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_133b7_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_133b7_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_133b7_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_133b7_row1_col13\" class=\"data row1 col13\" >43.2</td>\n",
       "      <td id=\"T_133b7_row1_col14\" class=\"data row1 col14\" >31.6</td>\n",
       "      <td id=\"T_133b7_row1_col15\" class=\"data row1 col15\" >37.4</td>\n",
       "      <td id=\"T_133b7_row1_col16\" class=\"data row1 col16\" >37.4</td>\n",
       "      <td id=\"T_133b7_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_133b7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_133b7_row2_col0\" class=\"data row2 col0\" >llama-7b_oasst2_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_133b7_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_133b7_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_133b7_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_133b7_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "      <td id=\"T_133b7_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_133b7_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "      <td id=\"T_133b7_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_133b7_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_133b7_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_133b7_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_133b7_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_133b7_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_133b7_row2_col13\" class=\"data row2 col13\" >41.6</td>\n",
       "      <td id=\"T_133b7_row2_col14\" class=\"data row2 col14\" >27.3</td>\n",
       "      <td id=\"T_133b7_row2_col15\" class=\"data row2 col15\" >34.5</td>\n",
       "      <td id=\"T_133b7_row2_col16\" class=\"data row2 col16\" >34.5</td>\n",
       "      <td id=\"T_133b7_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee28e13c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d6686 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_d6686_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d6686_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d6686_row0_col2, #T_d6686_row0_col3, #T_d6686_row0_col4, #T_d6686_row0_col5, #T_d6686_row0_col6, #T_d6686_row0_col7, #T_d6686_row0_col8, #T_d6686_row0_col9, #T_d6686_row0_col10, #T_d6686_row0_col11, #T_d6686_row0_col12, #T_d6686_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d6686_row0_col13, #T_d6686_row0_col14, #T_d6686_row0_col15, #T_d6686_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d6686\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d6686_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d6686_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_d6686_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d6686_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d6686_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_d6686_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_d6686_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_d6686_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_d6686_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d6686_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d6686_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d6686_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_d6686_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_d6686_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_d6686_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_d6686_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_d6686_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_d6686_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d6686_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d6686_row0_col0\" class=\"data row0 col0\" >llama-7b_oasst2_ep=2</td>\n",
       "      <td id=\"T_d6686_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_d6686_row0_col2\" class=\"data row0 col2\" >31.3</td>\n",
       "      <td id=\"T_d6686_row0_col3\" class=\"data row0 col3\" >34.6</td>\n",
       "      <td id=\"T_d6686_row0_col4\" class=\"data row0 col4\" >5.2</td>\n",
       "      <td id=\"T_d6686_row0_col5\" class=\"data row0 col5\" >10.2</td>\n",
       "      <td id=\"T_d6686_row0_col6\" class=\"data row0 col6\" >32.6</td>\n",
       "      <td id=\"T_d6686_row0_col7\" class=\"data row0 col7\" >32.8</td>\n",
       "      <td id=\"T_d6686_row0_col8\" class=\"data row0 col8\" >8.9</td>\n",
       "      <td id=\"T_d6686_row0_col9\" class=\"data row0 col9\" >31.9</td>\n",
       "      <td id=\"T_d6686_row0_col10\" class=\"data row0 col10\" >9.8</td>\n",
       "      <td id=\"T_d6686_row0_col11\" class=\"data row0 col11\" >42.9</td>\n",
       "      <td id=\"T_d6686_row0_col12\" class=\"data row0 col12\" >278.1</td>\n",
       "      <td id=\"T_d6686_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_d6686_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_d6686_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_d6686_row0_col16\" class=\"data row0 col16\" >47.1</td>\n",
       "      <td id=\"T_d6686_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee14aee60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9620b td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_9620b_row0_col0, #T_9620b_row1_col0, #T_9620b_row2_col0, #T_9620b_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9620b_row0_col1, #T_9620b_row1_col1, #T_9620b_row2_col1, #T_9620b_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9620b_row0_col2, #T_9620b_row0_col3, #T_9620b_row0_col5, #T_9620b_row0_col7, #T_9620b_row0_col9, #T_9620b_row0_col10, #T_9620b_row0_col13, #T_9620b_row0_col14, #T_9620b_row0_col15, #T_9620b_row0_col16, #T_9620b_row1_col4, #T_9620b_row1_col6, #T_9620b_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9620b_row0_col4, #T_9620b_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row0_col6, #T_9620b_row0_col11, #T_9620b_row0_col12, #T_9620b_row0_col17, #T_9620b_row1_col10, #T_9620b_row1_col11, #T_9620b_row1_col12, #T_9620b_row1_col14, #T_9620b_row1_col17, #T_9620b_row2_col2, #T_9620b_row2_col3, #T_9620b_row2_col7, #T_9620b_row2_col9, #T_9620b_row2_col11, #T_9620b_row2_col12, #T_9620b_row2_col17, #T_9620b_row3_col4, #T_9620b_row3_col5, #T_9620b_row3_col8, #T_9620b_row3_col11, #T_9620b_row3_col12, #T_9620b_row3_col13, #T_9620b_row3_col15, #T_9620b_row3_col16, #T_9620b_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9620b_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9620b_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9620b_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9620b_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9620b_row2_col5, #T_9620b_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9620b_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9620b_row2_col13, #T_9620b_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9620b_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9620b_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9620b_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9620b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9620b_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_9620b_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_9620b_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_9620b_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_9620b_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_9620b_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_9620b_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_9620b_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_9620b_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_9620b_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_9620b_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_9620b_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_9620b_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_9620b_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_9620b_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_9620b_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_9620b_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_9620b_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9620b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9620b_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_9620b_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_9620b_row0_col2\" class=\"data row0 col2\" >39.0</td>\n",
       "      <td id=\"T_9620b_row0_col3\" class=\"data row0 col3\" >38.8</td>\n",
       "      <td id=\"T_9620b_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_9620b_row0_col5\" class=\"data row0 col5\" >16.0</td>\n",
       "      <td id=\"T_9620b_row0_col6\" class=\"data row0 col6\" >29.9</td>\n",
       "      <td id=\"T_9620b_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_9620b_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_9620b_row0_col9\" class=\"data row0 col9\" >34.9</td>\n",
       "      <td id=\"T_9620b_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_9620b_row0_col11\" class=\"data row0 col11\" >45.8</td>\n",
       "      <td id=\"T_9620b_row0_col12\" class=\"data row0 col12\" >279.4</td>\n",
       "      <td id=\"T_9620b_row0_col13\" class=\"data row0 col13\" >54.4</td>\n",
       "      <td id=\"T_9620b_row0_col14\" class=\"data row0 col14\" >36.0</td>\n",
       "      <td id=\"T_9620b_row0_col15\" class=\"data row0 col15\" >45.3</td>\n",
       "      <td id=\"T_9620b_row0_col16\" class=\"data row0 col16\" >48.7</td>\n",
       "      <td id=\"T_9620b_row0_col17\" class=\"data row0 col17\" >-6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9620b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9620b_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_9620b_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_9620b_row1_col2\" class=\"data row1 col2\" >32.9</td>\n",
       "      <td id=\"T_9620b_row1_col3\" class=\"data row1 col3\" >34.7</td>\n",
       "      <td id=\"T_9620b_row1_col4\" class=\"data row1 col4\" >6.8</td>\n",
       "      <td id=\"T_9620b_row1_col5\" class=\"data row1 col5\" >12.0</td>\n",
       "      <td id=\"T_9620b_row1_col6\" class=\"data row1 col6\" >35.0</td>\n",
       "      <td id=\"T_9620b_row1_col7\" class=\"data row1 col7\" >31.4</td>\n",
       "      <td id=\"T_9620b_row1_col8\" class=\"data row1 col8\" >8.9</td>\n",
       "      <td id=\"T_9620b_row1_col9\" class=\"data row1 col9\" >32.1</td>\n",
       "      <td id=\"T_9620b_row1_col10\" class=\"data row1 col10\" >8.7</td>\n",
       "      <td id=\"T_9620b_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_9620b_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_9620b_row1_col13\" class=\"data row1 col13\" >46.0</td>\n",
       "      <td id=\"T_9620b_row1_col14\" class=\"data row1 col14\" >31.8</td>\n",
       "      <td id=\"T_9620b_row1_col15\" class=\"data row1 col15\" >38.9</td>\n",
       "      <td id=\"T_9620b_row1_col16\" class=\"data row1 col16\" >26.6</td>\n",
       "      <td id=\"T_9620b_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9620b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9620b_row2_col0\" class=\"data row2 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_9620b_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_9620b_row2_col2\" class=\"data row2 col2\" >30.9</td>\n",
       "      <td id=\"T_9620b_row2_col3\" class=\"data row2 col3\" >33.0</td>\n",
       "      <td id=\"T_9620b_row2_col4\" class=\"data row2 col4\" >6.4</td>\n",
       "      <td id=\"T_9620b_row2_col5\" class=\"data row2 col5\" >13.6</td>\n",
       "      <td id=\"T_9620b_row2_col6\" class=\"data row2 col6\" >33.5</td>\n",
       "      <td id=\"T_9620b_row2_col7\" class=\"data row2 col7\" >30.7</td>\n",
       "      <td id=\"T_9620b_row2_col8\" class=\"data row2 col8\" >7.3</td>\n",
       "      <td id=\"T_9620b_row2_col9\" class=\"data row2 col9\" >28.3</td>\n",
       "      <td id=\"T_9620b_row2_col10\" class=\"data row2 col10\" >12.2</td>\n",
       "      <td id=\"T_9620b_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_9620b_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_9620b_row2_col13\" class=\"data row2 col13\" >46.4</td>\n",
       "      <td id=\"T_9620b_row2_col14\" class=\"data row2 col14\" >34.0</td>\n",
       "      <td id=\"T_9620b_row2_col15\" class=\"data row2 col15\" >40.2</td>\n",
       "      <td id=\"T_9620b_row2_col16\" class=\"data row2 col16\" >26.4</td>\n",
       "      <td id=\"T_9620b_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9620b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9620b_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_9620b_row3_col1\" class=\"data row3 col1\" >10000</td>\n",
       "      <td id=\"T_9620b_row3_col2\" class=\"data row3 col2\" >31.7</td>\n",
       "      <td id=\"T_9620b_row3_col3\" class=\"data row3 col3\" >37.0</td>\n",
       "      <td id=\"T_9620b_row3_col4\" class=\"data row3 col4\" >6.0</td>\n",
       "      <td id=\"T_9620b_row3_col5\" class=\"data row3 col5\" >9.6</td>\n",
       "      <td id=\"T_9620b_row3_col6\" class=\"data row3 col6\" >31.2</td>\n",
       "      <td id=\"T_9620b_row3_col7\" class=\"data row3 col7\" >33.1</td>\n",
       "      <td id=\"T_9620b_row3_col8\" class=\"data row3 col8\" >7.0</td>\n",
       "      <td id=\"T_9620b_row3_col9\" class=\"data row3 col9\" >30.0</td>\n",
       "      <td id=\"T_9620b_row3_col10\" class=\"data row3 col10\" >11.8</td>\n",
       "      <td id=\"T_9620b_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_9620b_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_9620b_row3_col13\" class=\"data row3 col13\" >43.5</td>\n",
       "      <td id=\"T_9620b_row3_col14\" class=\"data row3 col14\" >31.9</td>\n",
       "      <td id=\"T_9620b_row3_col15\" class=\"data row3 col15\" >37.7</td>\n",
       "      <td id=\"T_9620b_row3_col16\" class=\"data row3 col16\" >25.9</td>\n",
       "      <td id=\"T_9620b_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee14ae290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7b866 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_7b866_row0_col0, #T_7b866_row1_col0, #T_7b866_row2_col0, #T_7b866_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7b866_row0_col1, #T_7b866_row1_col1, #T_7b866_row2_col1, #T_7b866_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7b866_row0_col2, #T_7b866_row0_col3, #T_7b866_row0_col4, #T_7b866_row0_col5, #T_7b866_row0_col9, #T_7b866_row0_col13, #T_7b866_row0_col16, #T_7b866_row1_col14, #T_7b866_row1_col15, #T_7b866_row2_col7, #T_7b866_row3_col6, #T_7b866_row3_col8, #T_7b866_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b866_row0_col6, #T_7b866_row0_col11, #T_7b866_row0_col12, #T_7b866_row0_col17, #T_7b866_row1_col7, #T_7b866_row1_col10, #T_7b866_row1_col11, #T_7b866_row1_col12, #T_7b866_row1_col17, #T_7b866_row2_col8, #T_7b866_row2_col9, #T_7b866_row2_col11, #T_7b866_row2_col12, #T_7b866_row2_col17, #T_7b866_row3_col2, #T_7b866_row3_col3, #T_7b866_row3_col4, #T_7b866_row3_col5, #T_7b866_row3_col11, #T_7b866_row3_col12, #T_7b866_row3_col13, #T_7b866_row3_col14, #T_7b866_row3_col15, #T_7b866_row3_col16, #T_7b866_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b866_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b866_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b866_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b866_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b866_row0_col15, #T_7b866_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b866_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b866_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b866_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b866_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b866_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b866_row1_col8, #T_7b866_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b866_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b866_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b866_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b866_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b866_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b866_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b866_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b866_row2_col10, #T_7b866_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b866_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b866_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7b866_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7b866_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7b866\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7b866_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_7b866_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_7b866_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_7b866_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_7b866_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_7b866_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_7b866_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_7b866_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_7b866_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_7b866_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_7b866_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_7b866_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_7b866_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_7b866_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_7b866_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_7b866_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_7b866_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_7b866_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7b866_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7b866_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_7b866_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_7b866_row0_col2\" class=\"data row0 col2\" >39.0</td>\n",
       "      <td id=\"T_7b866_row0_col3\" class=\"data row0 col3\" >38.8</td>\n",
       "      <td id=\"T_7b866_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_7b866_row0_col5\" class=\"data row0 col5\" >16.0</td>\n",
       "      <td id=\"T_7b866_row0_col6\" class=\"data row0 col6\" >29.9</td>\n",
       "      <td id=\"T_7b866_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_7b866_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_7b866_row0_col9\" class=\"data row0 col9\" >34.9</td>\n",
       "      <td id=\"T_7b866_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_7b866_row0_col11\" class=\"data row0 col11\" >45.8</td>\n",
       "      <td id=\"T_7b866_row0_col12\" class=\"data row0 col12\" >279.4</td>\n",
       "      <td id=\"T_7b866_row0_col13\" class=\"data row0 col13\" >54.4</td>\n",
       "      <td id=\"T_7b866_row0_col14\" class=\"data row0 col14\" >36.0</td>\n",
       "      <td id=\"T_7b866_row0_col15\" class=\"data row0 col15\" >45.3</td>\n",
       "      <td id=\"T_7b866_row0_col16\" class=\"data row0 col16\" >48.7</td>\n",
       "      <td id=\"T_7b866_row0_col17\" class=\"data row0 col17\" >-6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b866_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7b866_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_7b866_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_7b866_row1_col2\" class=\"data row1 col2\" >37.9</td>\n",
       "      <td id=\"T_7b866_row1_col3\" class=\"data row1 col3\" >37.7</td>\n",
       "      <td id=\"T_7b866_row1_col4\" class=\"data row1 col4\" >6.0</td>\n",
       "      <td id=\"T_7b866_row1_col5\" class=\"data row1 col5\" >13.0</td>\n",
       "      <td id=\"T_7b866_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_7b866_row1_col7\" class=\"data row1 col7\" >33.9</td>\n",
       "      <td id=\"T_7b866_row1_col8\" class=\"data row1 col8\" >8.7</td>\n",
       "      <td id=\"T_7b866_row1_col9\" class=\"data row1 col9\" >33.6</td>\n",
       "      <td id=\"T_7b866_row1_col10\" class=\"data row1 col10\" >11.4</td>\n",
       "      <td id=\"T_7b866_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_7b866_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_7b866_row1_col13\" class=\"data row1 col13\" >53.1</td>\n",
       "      <td id=\"T_7b866_row1_col14\" class=\"data row1 col14\" >40.5</td>\n",
       "      <td id=\"T_7b866_row1_col15\" class=\"data row1 col15\" >46.9</td>\n",
       "      <td id=\"T_7b866_row1_col16\" class=\"data row1 col16\" >29.4</td>\n",
       "      <td id=\"T_7b866_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b866_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7b866_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_7b866_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_7b866_row2_col2\" class=\"data row2 col2\" >35.0</td>\n",
       "      <td id=\"T_7b866_row2_col3\" class=\"data row2 col3\" >35.7</td>\n",
       "      <td id=\"T_7b866_row2_col4\" class=\"data row2 col4\" >5.8</td>\n",
       "      <td id=\"T_7b866_row2_col5\" class=\"data row2 col5\" >14.4</td>\n",
       "      <td id=\"T_7b866_row2_col6\" class=\"data row2 col6\" >32.8</td>\n",
       "      <td id=\"T_7b866_row2_col7\" class=\"data row2 col7\" >34.5</td>\n",
       "      <td id=\"T_7b866_row2_col8\" class=\"data row2 col8\" >7.5</td>\n",
       "      <td id=\"T_7b866_row2_col9\" class=\"data row2 col9\" >31.3</td>\n",
       "      <td id=\"T_7b866_row2_col10\" class=\"data row2 col10\" >12.8</td>\n",
       "      <td id=\"T_7b866_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_7b866_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_7b866_row2_col13\" class=\"data row2 col13\" >48.6</td>\n",
       "      <td id=\"T_7b866_row2_col14\" class=\"data row2 col14\" >39.2</td>\n",
       "      <td id=\"T_7b866_row2_col15\" class=\"data row2 col15\" >44.0</td>\n",
       "      <td id=\"T_7b866_row2_col16\" class=\"data row2 col16\" >28.5</td>\n",
       "      <td id=\"T_7b866_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7b866_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7b866_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_7b866_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_7b866_row3_col2\" class=\"data row3 col2\" >33.9</td>\n",
       "      <td id=\"T_7b866_row3_col3\" class=\"data row3 col3\" >35.2</td>\n",
       "      <td id=\"T_7b866_row3_col4\" class=\"data row3 col4\" >5.2</td>\n",
       "      <td id=\"T_7b866_row3_col5\" class=\"data row3 col5\" >11.0</td>\n",
       "      <td id=\"T_7b866_row3_col6\" class=\"data row3 col6\" >34.1</td>\n",
       "      <td id=\"T_7b866_row3_col7\" class=\"data row3 col7\" >34.2</td>\n",
       "      <td id=\"T_7b866_row3_col8\" class=\"data row3 col8\" >8.9</td>\n",
       "      <td id=\"T_7b866_row3_col9\" class=\"data row3 col9\" >32.8</td>\n",
       "      <td id=\"T_7b866_row3_col10\" class=\"data row3 col10\" >14.0</td>\n",
       "      <td id=\"T_7b866_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_7b866_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_7b866_row3_col13\" class=\"data row3 col13\" >45.9</td>\n",
       "      <td id=\"T_7b866_row3_col14\" class=\"data row3 col14\" >35.4</td>\n",
       "      <td id=\"T_7b866_row3_col15\" class=\"data row3 col15\" >40.6</td>\n",
       "      <td id=\"T_7b866_row3_col16\" class=\"data row3 col16\" >27.6</td>\n",
       "      <td id=\"T_7b866_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee14aea40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a9a08 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_a9a08_row0_col0, #T_a9a08_row1_col0, #T_a9a08_row2_col0, #T_a9a08_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a9a08_row0_col1, #T_a9a08_row1_col1, #T_a9a08_row2_col1, #T_a9a08_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a9a08_row0_col2, #T_a9a08_row0_col6, #T_a9a08_row0_col11, #T_a9a08_row0_col12, #T_a9a08_row0_col17, #T_a9a08_row1_col11, #T_a9a08_row1_col12, #T_a9a08_row1_col17, #T_a9a08_row2_col3, #T_a9a08_row2_col4, #T_a9a08_row2_col5, #T_a9a08_row2_col7, #T_a9a08_row2_col11, #T_a9a08_row2_col12, #T_a9a08_row2_col13, #T_a9a08_row2_col17, #T_a9a08_row3_col5, #T_a9a08_row3_col8, #T_a9a08_row3_col9, #T_a9a08_row3_col10, #T_a9a08_row3_col11, #T_a9a08_row3_col12, #T_a9a08_row3_col14, #T_a9a08_row3_col15, #T_a9a08_row3_col16, #T_a9a08_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9a08_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9a08_row0_col4, #T_a9a08_row0_col5, #T_a9a08_row0_col9, #T_a9a08_row0_col10, #T_a9a08_row0_col13, #T_a9a08_row0_col15, #T_a9a08_row0_col16, #T_a9a08_row1_col3, #T_a9a08_row1_col4, #T_a9a08_row1_col6, #T_a9a08_row1_col14, #T_a9a08_row2_col2, #T_a9a08_row2_col8, #T_a9a08_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9a08_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9a08_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9a08_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9a08_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9a08_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9a08_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9a08_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9a08_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9a08_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9a08_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9a08_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9a08_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9a08_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9a08_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9a08_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9a08_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9a08_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9a08_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9a08_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9a08_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9a08_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9a08_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9a08_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a9a08\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a9a08_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_a9a08_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_a9a08_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_a9a08_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_a9a08_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_a9a08_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_a9a08_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_a9a08_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_a9a08_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_a9a08_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_a9a08_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_a9a08_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_a9a08_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_a9a08_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_a9a08_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_a9a08_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_a9a08_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_a9a08_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a9a08_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a9a08_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_a9a08_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_a9a08_row0_col2\" class=\"data row0 col2\" >39.0</td>\n",
       "      <td id=\"T_a9a08_row0_col3\" class=\"data row0 col3\" >38.8</td>\n",
       "      <td id=\"T_a9a08_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_a9a08_row0_col5\" class=\"data row0 col5\" >16.0</td>\n",
       "      <td id=\"T_a9a08_row0_col6\" class=\"data row0 col6\" >29.9</td>\n",
       "      <td id=\"T_a9a08_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_a9a08_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_a9a08_row0_col9\" class=\"data row0 col9\" >34.9</td>\n",
       "      <td id=\"T_a9a08_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_a9a08_row0_col11\" class=\"data row0 col11\" >45.8</td>\n",
       "      <td id=\"T_a9a08_row0_col12\" class=\"data row0 col12\" >279.4</td>\n",
       "      <td id=\"T_a9a08_row0_col13\" class=\"data row0 col13\" >54.4</td>\n",
       "      <td id=\"T_a9a08_row0_col14\" class=\"data row0 col14\" >36.0</td>\n",
       "      <td id=\"T_a9a08_row0_col15\" class=\"data row0 col15\" >45.3</td>\n",
       "      <td id=\"T_a9a08_row0_col16\" class=\"data row0 col16\" >48.7</td>\n",
       "      <td id=\"T_a9a08_row0_col17\" class=\"data row0 col17\" >-6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9a08_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a9a08_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_a9a08_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_a9a08_row1_col2\" class=\"data row1 col2\" >40.0</td>\n",
       "      <td id=\"T_a9a08_row1_col3\" class=\"data row1 col3\" >39.4</td>\n",
       "      <td id=\"T_a9a08_row1_col4\" class=\"data row1 col4\" >6.4</td>\n",
       "      <td id=\"T_a9a08_row1_col5\" class=\"data row1 col5\" >14.4</td>\n",
       "      <td id=\"T_a9a08_row1_col6\" class=\"data row1 col6\" >32.4</td>\n",
       "      <td id=\"T_a9a08_row1_col7\" class=\"data row1 col7\" >34.6</td>\n",
       "      <td id=\"T_a9a08_row1_col8\" class=\"data row1 col8\" >7.8</td>\n",
       "      <td id=\"T_a9a08_row1_col9\" class=\"data row1 col9\" >34.4</td>\n",
       "      <td id=\"T_a9a08_row1_col10\" class=\"data row1 col10\" >11.4</td>\n",
       "      <td id=\"T_a9a08_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_a9a08_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_a9a08_row1_col13\" class=\"data row1 col13\" >51.8</td>\n",
       "      <td id=\"T_a9a08_row1_col14\" class=\"data row1 col14\" >38.8</td>\n",
       "      <td id=\"T_a9a08_row1_col15\" class=\"data row1 col15\" >45.2</td>\n",
       "      <td id=\"T_a9a08_row1_col16\" class=\"data row1 col16\" >29.7</td>\n",
       "      <td id=\"T_a9a08_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9a08_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a9a08_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_a9a08_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_a9a08_row2_col2\" class=\"data row2 col2\" >40.2</td>\n",
       "      <td id=\"T_a9a08_row2_col3\" class=\"data row2 col3\" >37.6</td>\n",
       "      <td id=\"T_a9a08_row2_col4\" class=\"data row2 col4\" >5.6</td>\n",
       "      <td id=\"T_a9a08_row2_col5\" class=\"data row2 col5\" >14.0</td>\n",
       "      <td id=\"T_a9a08_row2_col6\" class=\"data row2 col6\" >32.2</td>\n",
       "      <td id=\"T_a9a08_row2_col7\" class=\"data row2 col7\" >33.5</td>\n",
       "      <td id=\"T_a9a08_row2_col8\" class=\"data row2 col8\" >8.2</td>\n",
       "      <td id=\"T_a9a08_row2_col9\" class=\"data row2 col9\" >32.7</td>\n",
       "      <td id=\"T_a9a08_row2_col10\" class=\"data row2 col10\" >12.4</td>\n",
       "      <td id=\"T_a9a08_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_a9a08_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_a9a08_row2_col13\" class=\"data row2 col13\" >49.6</td>\n",
       "      <td id=\"T_a9a08_row2_col14\" class=\"data row2 col14\" >36.6</td>\n",
       "      <td id=\"T_a9a08_row2_col15\" class=\"data row2 col15\" >43.1</td>\n",
       "      <td id=\"T_a9a08_row2_col16\" class=\"data row2 col16\" >28.8</td>\n",
       "      <td id=\"T_a9a08_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9a08_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a9a08_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_a9a08_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_a9a08_row3_col2\" class=\"data row3 col2\" >39.6</td>\n",
       "      <td id=\"T_a9a08_row3_col3\" class=\"data row3 col3\" >38.6</td>\n",
       "      <td id=\"T_a9a08_row3_col4\" class=\"data row3 col4\" >6.2</td>\n",
       "      <td id=\"T_a9a08_row3_col5\" class=\"data row3 col5\" >14.0</td>\n",
       "      <td id=\"T_a9a08_row3_col6\" class=\"data row3 col6\" >32.3</td>\n",
       "      <td id=\"T_a9a08_row3_col7\" class=\"data row3 col7\" >35.9</td>\n",
       "      <td id=\"T_a9a08_row3_col8\" class=\"data row3 col8\" >7.5</td>\n",
       "      <td id=\"T_a9a08_row3_col9\" class=\"data row3 col9\" >30.6</td>\n",
       "      <td id=\"T_a9a08_row3_col10\" class=\"data row3 col10\" >11.0</td>\n",
       "      <td id=\"T_a9a08_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_a9a08_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_a9a08_row3_col13\" class=\"data row3 col13\" >50.6</td>\n",
       "      <td id=\"T_a9a08_row3_col14\" class=\"data row3 col14\" >35.2</td>\n",
       "      <td id=\"T_a9a08_row3_col15\" class=\"data row3 col15\" >43.0</td>\n",
       "      <td id=\"T_a9a08_row3_col16\" class=\"data row3 col16\" >28.7</td>\n",
       "      <td id=\"T_a9a08_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee14ad6f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_09bbb td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_09bbb_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_09bbb_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_09bbb_row0_col2, #T_09bbb_row0_col3, #T_09bbb_row0_col4, #T_09bbb_row0_col5, #T_09bbb_row0_col6, #T_09bbb_row0_col7, #T_09bbb_row0_col8, #T_09bbb_row0_col9, #T_09bbb_row0_col10, #T_09bbb_row0_col11, #T_09bbb_row0_col12, #T_09bbb_row0_col13, #T_09bbb_row0_col14, #T_09bbb_row0_col15, #T_09bbb_row0_col16, #T_09bbb_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_09bbb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_09bbb_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_09bbb_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_09bbb_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_09bbb_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_09bbb_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_09bbb_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_09bbb_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_09bbb_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_09bbb_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_09bbb_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_09bbb_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_09bbb_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_09bbb_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_09bbb_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_09bbb_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_09bbb_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_09bbb_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_09bbb_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_09bbb_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_09bbb_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_09bbb_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_09bbb_row0_col2\" class=\"data row0 col2\" >39.0</td>\n",
       "      <td id=\"T_09bbb_row0_col3\" class=\"data row0 col3\" >38.8</td>\n",
       "      <td id=\"T_09bbb_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_09bbb_row0_col5\" class=\"data row0 col5\" >16.0</td>\n",
       "      <td id=\"T_09bbb_row0_col6\" class=\"data row0 col6\" >29.9</td>\n",
       "      <td id=\"T_09bbb_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_09bbb_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_09bbb_row0_col9\" class=\"data row0 col9\" >34.9</td>\n",
       "      <td id=\"T_09bbb_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_09bbb_row0_col11\" class=\"data row0 col11\" >45.8</td>\n",
       "      <td id=\"T_09bbb_row0_col12\" class=\"data row0 col12\" >279.4</td>\n",
       "      <td id=\"T_09bbb_row0_col13\" class=\"data row0 col13\" >54.4</td>\n",
       "      <td id=\"T_09bbb_row0_col14\" class=\"data row0 col14\" >36.0</td>\n",
       "      <td id=\"T_09bbb_row0_col15\" class=\"data row0 col15\" >45.3</td>\n",
       "      <td id=\"T_09bbb_row0_col16\" class=\"data row0 col16\" >48.7</td>\n",
       "      <td id=\"T_09bbb_row0_col17\" class=\"data row0 col17\" >-6.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee14acf70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_48998 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_48998_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_48998_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_48998_row0_col2, #T_48998_row0_col3, #T_48998_row0_col4, #T_48998_row0_col5, #T_48998_row0_col6, #T_48998_row0_col7, #T_48998_row0_col8, #T_48998_row0_col9, #T_48998_row0_col10, #T_48998_row0_col11, #T_48998_row0_col12, #T_48998_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_48998_row0_col13, #T_48998_row0_col14, #T_48998_row0_col15, #T_48998_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_48998\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_48998_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_48998_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_48998_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_48998_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_48998_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_48998_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_48998_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_48998_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_48998_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_48998_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_48998_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_48998_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_48998_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_48998_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_48998_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_48998_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_48998_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_48998_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_48998_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_48998_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_48998_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_48998_row0_col2\" class=\"data row0 col2\" >42.2</td>\n",
       "      <td id=\"T_48998_row0_col3\" class=\"data row0 col3\" >42.6</td>\n",
       "      <td id=\"T_48998_row0_col4\" class=\"data row0 col4\" >4.0</td>\n",
       "      <td id=\"T_48998_row0_col5\" class=\"data row0 col5\" >5.0</td>\n",
       "      <td id=\"T_48998_row0_col6\" class=\"data row0 col6\" >33.6</td>\n",
       "      <td id=\"T_48998_row0_col7\" class=\"data row0 col7\" >31.7</td>\n",
       "      <td id=\"T_48998_row0_col8\" class=\"data row0 col8\" >7.2</td>\n",
       "      <td id=\"T_48998_row0_col9\" class=\"data row0 col9\" >33.9</td>\n",
       "      <td id=\"T_48998_row0_col10\" class=\"data row0 col10\" >10.8</td>\n",
       "      <td id=\"T_48998_row0_col11\" class=\"data row0 col11\" >38.1</td>\n",
       "      <td id=\"T_48998_row0_col12\" class=\"data row0 col12\" >146.4</td>\n",
       "      <td id=\"T_48998_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_48998_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_48998_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_48998_row0_col16\" class=\"data row0 col16\" >36.0</td>\n",
       "      <td id=\"T_48998_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee14af460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4501c td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_4501c_row0_col0, #T_4501c_row1_col0, #T_4501c_row2_col0, #T_4501c_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4501c_row0_col1, #T_4501c_row1_col1, #T_4501c_row2_col1, #T_4501c_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4501c_row0_col2, #T_4501c_row0_col3, #T_4501c_row0_col4, #T_4501c_row0_col5, #T_4501c_row0_col6, #T_4501c_row0_col7, #T_4501c_row0_col8, #T_4501c_row0_col9, #T_4501c_row0_col10, #T_4501c_row0_col11, #T_4501c_row0_col12, #T_4501c_row1_col2, #T_4501c_row1_col3, #T_4501c_row1_col4, #T_4501c_row1_col5, #T_4501c_row1_col6, #T_4501c_row1_col7, #T_4501c_row1_col8, #T_4501c_row1_col9, #T_4501c_row1_col10, #T_4501c_row1_col11, #T_4501c_row1_col12, #T_4501c_row2_col2, #T_4501c_row2_col3, #T_4501c_row2_col4, #T_4501c_row2_col5, #T_4501c_row2_col6, #T_4501c_row2_col7, #T_4501c_row2_col8, #T_4501c_row2_col9, #T_4501c_row2_col10, #T_4501c_row2_col11, #T_4501c_row2_col12, #T_4501c_row3_col2, #T_4501c_row3_col3, #T_4501c_row3_col4, #T_4501c_row3_col5, #T_4501c_row3_col6, #T_4501c_row3_col7, #T_4501c_row3_col8, #T_4501c_row3_col9, #T_4501c_row3_col10, #T_4501c_row3_col11, #T_4501c_row3_col12, #T_4501c_row3_col13, #T_4501c_row3_col14, #T_4501c_row3_col15, #T_4501c_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4501c_row0_col13, #T_4501c_row0_col14, #T_4501c_row0_col15, #T_4501c_row0_col17, #T_4501c_row1_col17, #T_4501c_row2_col17, #T_4501c_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4501c_row0_col16, #T_4501c_row1_col13, #T_4501c_row1_col14, #T_4501c_row1_col15, #T_4501c_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4501c_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4501c_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e57058;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4501c_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4501c_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4501c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4501c_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_4501c_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_4501c_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_4501c_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_4501c_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_4501c_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_4501c_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_4501c_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_4501c_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_4501c_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_4501c_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_4501c_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_4501c_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_4501c_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_4501c_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_4501c_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_4501c_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_4501c_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4501c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4501c_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_4501c_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_4501c_row0_col2\" class=\"data row0 col2\" >42.2</td>\n",
       "      <td id=\"T_4501c_row0_col3\" class=\"data row0 col3\" >42.6</td>\n",
       "      <td id=\"T_4501c_row0_col4\" class=\"data row0 col4\" >4.0</td>\n",
       "      <td id=\"T_4501c_row0_col5\" class=\"data row0 col5\" >5.0</td>\n",
       "      <td id=\"T_4501c_row0_col6\" class=\"data row0 col6\" >33.6</td>\n",
       "      <td id=\"T_4501c_row0_col7\" class=\"data row0 col7\" >31.7</td>\n",
       "      <td id=\"T_4501c_row0_col8\" class=\"data row0 col8\" >7.2</td>\n",
       "      <td id=\"T_4501c_row0_col9\" class=\"data row0 col9\" >33.9</td>\n",
       "      <td id=\"T_4501c_row0_col10\" class=\"data row0 col10\" >10.8</td>\n",
       "      <td id=\"T_4501c_row0_col11\" class=\"data row0 col11\" >38.1</td>\n",
       "      <td id=\"T_4501c_row0_col12\" class=\"data row0 col12\" >146.4</td>\n",
       "      <td id=\"T_4501c_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_4501c_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_4501c_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_4501c_row0_col16\" class=\"data row0 col16\" >36.0</td>\n",
       "      <td id=\"T_4501c_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4501c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4501c_row1_col0\" class=\"data row1 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_4501c_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_4501c_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_4501c_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_4501c_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_4501c_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_4501c_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_4501c_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_4501c_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_4501c_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_4501c_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_4501c_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_4501c_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_4501c_row1_col13\" class=\"data row1 col13\" >40.6</td>\n",
       "      <td id=\"T_4501c_row1_col14\" class=\"data row1 col14\" >27.7</td>\n",
       "      <td id=\"T_4501c_row1_col15\" class=\"data row1 col15\" >34.3</td>\n",
       "      <td id=\"T_4501c_row1_col16\" class=\"data row1 col16\" >34.2</td>\n",
       "      <td id=\"T_4501c_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4501c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4501c_row2_col0\" class=\"data row2 col0\" >llama-7b_stanford_alpaca50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_4501c_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_4501c_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_4501c_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_4501c_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "      <td id=\"T_4501c_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_4501c_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "      <td id=\"T_4501c_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_4501c_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_4501c_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_4501c_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_4501c_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_4501c_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_4501c_row2_col13\" class=\"data row2 col13\" >40.6</td>\n",
       "      <td id=\"T_4501c_row2_col14\" class=\"data row2 col14\" >27.5</td>\n",
       "      <td id=\"T_4501c_row2_col15\" class=\"data row2 col15\" >34.1</td>\n",
       "      <td id=\"T_4501c_row2_col16\" class=\"data row2 col16\" >34.1</td>\n",
       "      <td id=\"T_4501c_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4501c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4501c_row3_col0\" class=\"data row3 col0\" >llama-7b_stanford_alpaca50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_4501c_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_4501c_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
       "      <td id=\"T_4501c_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
       "      <td id=\"T_4501c_row3_col4\" class=\"data row3 col4\" >nan</td>\n",
       "      <td id=\"T_4501c_row3_col5\" class=\"data row3 col5\" >nan</td>\n",
       "      <td id=\"T_4501c_row3_col6\" class=\"data row3 col6\" >nan</td>\n",
       "      <td id=\"T_4501c_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "      <td id=\"T_4501c_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
       "      <td id=\"T_4501c_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
       "      <td id=\"T_4501c_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
       "      <td id=\"T_4501c_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_4501c_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_4501c_row3_col13\" class=\"data row3 col13\" >39.5</td>\n",
       "      <td id=\"T_4501c_row3_col14\" class=\"data row3 col14\" >26.6</td>\n",
       "      <td id=\"T_4501c_row3_col15\" class=\"data row3 col15\" >33.1</td>\n",
       "      <td id=\"T_4501c_row3_col16\" class=\"data row3 col16\" >33.1</td>\n",
       "      <td id=\"T_4501c_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee14ac7c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9cbf2 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_9cbf2_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9cbf2_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9cbf2_row0_col2, #T_9cbf2_row0_col3, #T_9cbf2_row0_col4, #T_9cbf2_row0_col5, #T_9cbf2_row0_col6, #T_9cbf2_row0_col7, #T_9cbf2_row0_col8, #T_9cbf2_row0_col9, #T_9cbf2_row0_col10, #T_9cbf2_row0_col11, #T_9cbf2_row0_col12, #T_9cbf2_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9cbf2_row0_col13, #T_9cbf2_row0_col14, #T_9cbf2_row0_col15, #T_9cbf2_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9cbf2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9cbf2_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_9cbf2_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_9cbf2_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_9cbf2_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_9cbf2_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_9cbf2_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_9cbf2_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_9cbf2_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_9cbf2_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_9cbf2_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_9cbf2_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_9cbf2_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_9cbf2_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_9cbf2_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_9cbf2_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_9cbf2_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_9cbf2_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_9cbf2_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9cbf2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9cbf2_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_9cbf2_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_9cbf2_row0_col2\" class=\"data row0 col2\" >42.2</td>\n",
       "      <td id=\"T_9cbf2_row0_col3\" class=\"data row0 col3\" >42.6</td>\n",
       "      <td id=\"T_9cbf2_row0_col4\" class=\"data row0 col4\" >4.0</td>\n",
       "      <td id=\"T_9cbf2_row0_col5\" class=\"data row0 col5\" >5.0</td>\n",
       "      <td id=\"T_9cbf2_row0_col6\" class=\"data row0 col6\" >33.6</td>\n",
       "      <td id=\"T_9cbf2_row0_col7\" class=\"data row0 col7\" >31.7</td>\n",
       "      <td id=\"T_9cbf2_row0_col8\" class=\"data row0 col8\" >7.2</td>\n",
       "      <td id=\"T_9cbf2_row0_col9\" class=\"data row0 col9\" >33.9</td>\n",
       "      <td id=\"T_9cbf2_row0_col10\" class=\"data row0 col10\" >10.8</td>\n",
       "      <td id=\"T_9cbf2_row0_col11\" class=\"data row0 col11\" >38.1</td>\n",
       "      <td id=\"T_9cbf2_row0_col12\" class=\"data row0 col12\" >146.4</td>\n",
       "      <td id=\"T_9cbf2_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_9cbf2_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_9cbf2_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_9cbf2_row0_col16\" class=\"data row0 col16\" >36.0</td>\n",
       "      <td id=\"T_9cbf2_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee14ad8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_61ea6 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_61ea6_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_61ea6_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_61ea6_row0_col2, #T_61ea6_row0_col3, #T_61ea6_row0_col4, #T_61ea6_row0_col5, #T_61ea6_row0_col6, #T_61ea6_row0_col7, #T_61ea6_row0_col8, #T_61ea6_row0_col9, #T_61ea6_row0_col10, #T_61ea6_row0_col11, #T_61ea6_row0_col12, #T_61ea6_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_61ea6_row0_col13, #T_61ea6_row0_col14, #T_61ea6_row0_col15, #T_61ea6_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_61ea6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_61ea6_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_61ea6_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_61ea6_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_61ea6_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_61ea6_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_61ea6_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_61ea6_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_61ea6_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_61ea6_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_61ea6_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_61ea6_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_61ea6_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_61ea6_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_61ea6_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_61ea6_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_61ea6_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_61ea6_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_61ea6_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_61ea6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_61ea6_row0_col0\" class=\"data row0 col0\" >llama-7b_stanford_alpaca50k_ep=2</td>\n",
       "      <td id=\"T_61ea6_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_61ea6_row0_col2\" class=\"data row0 col2\" >42.2</td>\n",
       "      <td id=\"T_61ea6_row0_col3\" class=\"data row0 col3\" >42.6</td>\n",
       "      <td id=\"T_61ea6_row0_col4\" class=\"data row0 col4\" >4.0</td>\n",
       "      <td id=\"T_61ea6_row0_col5\" class=\"data row0 col5\" >5.0</td>\n",
       "      <td id=\"T_61ea6_row0_col6\" class=\"data row0 col6\" >33.6</td>\n",
       "      <td id=\"T_61ea6_row0_col7\" class=\"data row0 col7\" >31.7</td>\n",
       "      <td id=\"T_61ea6_row0_col8\" class=\"data row0 col8\" >7.2</td>\n",
       "      <td id=\"T_61ea6_row0_col9\" class=\"data row0 col9\" >33.9</td>\n",
       "      <td id=\"T_61ea6_row0_col10\" class=\"data row0 col10\" >10.8</td>\n",
       "      <td id=\"T_61ea6_row0_col11\" class=\"data row0 col11\" >38.1</td>\n",
       "      <td id=\"T_61ea6_row0_col12\" class=\"data row0 col12\" >146.4</td>\n",
       "      <td id=\"T_61ea6_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_61ea6_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_61ea6_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_61ea6_row0_col16\" class=\"data row0 col16\" >36.0</td>\n",
       "      <td id=\"T_61ea6_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee30536d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_633f6 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_633f6_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_633f6_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_633f6_row0_col2, #T_633f6_row0_col3, #T_633f6_row0_col4, #T_633f6_row0_col5, #T_633f6_row0_col6, #T_633f6_row0_col7, #T_633f6_row0_col8, #T_633f6_row0_col9, #T_633f6_row0_col10, #T_633f6_row0_col11, #T_633f6_row0_col12, #T_633f6_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_633f6_row0_col13, #T_633f6_row0_col14, #T_633f6_row0_col15, #T_633f6_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_633f6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_633f6_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_633f6_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_633f6_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_633f6_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_633f6_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_633f6_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_633f6_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_633f6_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_633f6_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_633f6_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_633f6_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_633f6_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_633f6_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_633f6_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_633f6_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_633f6_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_633f6_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_633f6_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_633f6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_633f6_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_633f6_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_633f6_row0_col2\" class=\"data row0 col2\" >38.4</td>\n",
       "      <td id=\"T_633f6_row0_col3\" class=\"data row0 col3\" >36.5</td>\n",
       "      <td id=\"T_633f6_row0_col4\" class=\"data row0 col4\" >6.6</td>\n",
       "      <td id=\"T_633f6_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_633f6_row0_col6\" class=\"data row0 col6\" >31.3</td>\n",
       "      <td id=\"T_633f6_row0_col7\" class=\"data row0 col7\" >34.1</td>\n",
       "      <td id=\"T_633f6_row0_col8\" class=\"data row0 col8\" >7.9</td>\n",
       "      <td id=\"T_633f6_row0_col9\" class=\"data row0 col9\" >33.3</td>\n",
       "      <td id=\"T_633f6_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_633f6_row0_col11\" class=\"data row0 col11\" >49.3</td>\n",
       "      <td id=\"T_633f6_row0_col12\" class=\"data row0 col12\" >252.2</td>\n",
       "      <td id=\"T_633f6_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_633f6_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_633f6_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_633f6_row0_col16\" class=\"data row0 col16\" >46.6</td>\n",
       "      <td id=\"T_633f6_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee15af280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_59556 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_59556_row0_col0, #T_59556_row1_col0, #T_59556_row2_col0, #T_59556_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_59556_row0_col1, #T_59556_row1_col1, #T_59556_row2_col1, #T_59556_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_59556_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_59556_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_59556_row0_col4, #T_59556_row0_col5, #T_59556_row0_col9, #T_59556_row0_col16, #T_59556_row1_col13, #T_59556_row1_col14, #T_59556_row1_col15, #T_59556_row2_col2, #T_59556_row2_col3, #T_59556_row2_col7, #T_59556_row2_col8, #T_59556_row3_col5, #T_59556_row3_col6, #T_59556_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_59556_row0_col6, #T_59556_row0_col8, #T_59556_row0_col11, #T_59556_row0_col12, #T_59556_row1_col2, #T_59556_row1_col5, #T_59556_row1_col7, #T_59556_row1_col11, #T_59556_row1_col12, #T_59556_row2_col5, #T_59556_row2_col9, #T_59556_row2_col10, #T_59556_row2_col11, #T_59556_row2_col12, #T_59556_row3_col3, #T_59556_row3_col4, #T_59556_row3_col11, #T_59556_row3_col12, #T_59556_row3_col13, #T_59556_row3_col14, #T_59556_row3_col15, #T_59556_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_59556_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_59556_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_59556_row0_col13, #T_59556_row0_col14, #T_59556_row0_col15, #T_59556_row0_col17, #T_59556_row1_col17, #T_59556_row2_col17, #T_59556_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_59556_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_59556_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_59556_row1_col6, #T_59556_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_59556_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_59556_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_59556_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_59556_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_59556_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f39475;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_59556_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_59556_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_59556_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_59556_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_59556_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_59556_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_59556_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a688;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_59556_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_59556\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_59556_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_59556_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_59556_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_59556_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_59556_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_59556_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_59556_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_59556_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_59556_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_59556_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_59556_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_59556_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_59556_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_59556_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_59556_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_59556_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_59556_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_59556_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_59556_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_59556_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_59556_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_59556_row0_col2\" class=\"data row0 col2\" >38.4</td>\n",
       "      <td id=\"T_59556_row0_col3\" class=\"data row0 col3\" >36.5</td>\n",
       "      <td id=\"T_59556_row0_col4\" class=\"data row0 col4\" >6.6</td>\n",
       "      <td id=\"T_59556_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_59556_row0_col6\" class=\"data row0 col6\" >31.3</td>\n",
       "      <td id=\"T_59556_row0_col7\" class=\"data row0 col7\" >34.1</td>\n",
       "      <td id=\"T_59556_row0_col8\" class=\"data row0 col8\" >7.9</td>\n",
       "      <td id=\"T_59556_row0_col9\" class=\"data row0 col9\" >33.3</td>\n",
       "      <td id=\"T_59556_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_59556_row0_col11\" class=\"data row0 col11\" >49.3</td>\n",
       "      <td id=\"T_59556_row0_col12\" class=\"data row0 col12\" >252.2</td>\n",
       "      <td id=\"T_59556_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_59556_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_59556_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_59556_row0_col16\" class=\"data row0 col16\" >46.6</td>\n",
       "      <td id=\"T_59556_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59556_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_59556_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_59556_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_59556_row1_col2\" class=\"data row1 col2\" >36.7</td>\n",
       "      <td id=\"T_59556_row1_col3\" class=\"data row1 col3\" >35.9</td>\n",
       "      <td id=\"T_59556_row1_col4\" class=\"data row1 col4\" >5.6</td>\n",
       "      <td id=\"T_59556_row1_col5\" class=\"data row1 col5\" >9.4</td>\n",
       "      <td id=\"T_59556_row1_col6\" class=\"data row1 col6\" >33.0</td>\n",
       "      <td id=\"T_59556_row1_col7\" class=\"data row1 col7\" >33.2</td>\n",
       "      <td id=\"T_59556_row1_col8\" class=\"data row1 col8\" >8.3</td>\n",
       "      <td id=\"T_59556_row1_col9\" class=\"data row1 col9\" >31.9</td>\n",
       "      <td id=\"T_59556_row1_col10\" class=\"data row1 col10\" >11.6</td>\n",
       "      <td id=\"T_59556_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_59556_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_59556_row1_col13\" class=\"data row1 col13\" >50.6</td>\n",
       "      <td id=\"T_59556_row1_col14\" class=\"data row1 col14\" >36.7</td>\n",
       "      <td id=\"T_59556_row1_col15\" class=\"data row1 col15\" >43.7</td>\n",
       "      <td id=\"T_59556_row1_col16\" class=\"data row1 col16\" >28.0</td>\n",
       "      <td id=\"T_59556_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59556_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_59556_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_59556_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_59556_row2_col2\" class=\"data row2 col2\" >38.7</td>\n",
       "      <td id=\"T_59556_row2_col3\" class=\"data row2 col3\" >37.5</td>\n",
       "      <td id=\"T_59556_row2_col4\" class=\"data row2 col4\" >6.4</td>\n",
       "      <td id=\"T_59556_row2_col5\" class=\"data row2 col5\" >9.4</td>\n",
       "      <td id=\"T_59556_row2_col6\" class=\"data row2 col6\" >32.8</td>\n",
       "      <td id=\"T_59556_row2_col7\" class=\"data row2 col7\" >35.1</td>\n",
       "      <td id=\"T_59556_row2_col8\" class=\"data row2 col8\" >9.1</td>\n",
       "      <td id=\"T_59556_row2_col9\" class=\"data row2 col9\" >30.3</td>\n",
       "      <td id=\"T_59556_row2_col10\" class=\"data row2 col10\" >8.9</td>\n",
       "      <td id=\"T_59556_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_59556_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_59556_row2_col13\" class=\"data row2 col13\" >44.9</td>\n",
       "      <td id=\"T_59556_row2_col14\" class=\"data row2 col14\" >33.0</td>\n",
       "      <td id=\"T_59556_row2_col15\" class=\"data row2 col15\" >38.9</td>\n",
       "      <td id=\"T_59556_row2_col16\" class=\"data row2 col16\" >27.1</td>\n",
       "      <td id=\"T_59556_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59556_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_59556_row3_col0\" class=\"data row3 col0\" >llama-7b_ultrachat50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_59556_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_59556_row3_col2\" class=\"data row3 col2\" >37.0</td>\n",
       "      <td id=\"T_59556_row3_col3\" class=\"data row3 col3\" >34.9</td>\n",
       "      <td id=\"T_59556_row3_col4\" class=\"data row3 col4\" >5.2</td>\n",
       "      <td id=\"T_59556_row3_col5\" class=\"data row3 col5\" >10.8</td>\n",
       "      <td id=\"T_59556_row3_col6\" class=\"data row3 col6\" >33.2</td>\n",
       "      <td id=\"T_59556_row3_col7\" class=\"data row3 col7\" >34.2</td>\n",
       "      <td id=\"T_59556_row3_col8\" class=\"data row3 col8\" >8.7</td>\n",
       "      <td id=\"T_59556_row3_col9\" class=\"data row3 col9\" >32.1</td>\n",
       "      <td id=\"T_59556_row3_col10\" class=\"data row3 col10\" >12.6</td>\n",
       "      <td id=\"T_59556_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_59556_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_59556_row3_col13\" class=\"data row3 col13\" >44.1</td>\n",
       "      <td id=\"T_59556_row3_col14\" class=\"data row3 col14\" >32.3</td>\n",
       "      <td id=\"T_59556_row3_col15\" class=\"data row3 col15\" >38.2</td>\n",
       "      <td id=\"T_59556_row3_col16\" class=\"data row3 col16\" >26.9</td>\n",
       "      <td id=\"T_59556_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee15aeef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2b835 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_2b835_row0_col0, #T_2b835_row1_col0, #T_2b835_row2_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2b835_row0_col1, #T_2b835_row1_col1, #T_2b835_row2_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2b835_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b835_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #c53334;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b835_row0_col4, #T_2b835_row0_col5, #T_2b835_row0_col7, #T_2b835_row0_col9, #T_2b835_row0_col10, #T_2b835_row0_col16, #T_2b835_row1_col3, #T_2b835_row1_col13, #T_2b835_row1_col15, #T_2b835_row2_col2, #T_2b835_row2_col6, #T_2b835_row2_col8, #T_2b835_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b835_row0_col6, #T_2b835_row0_col8, #T_2b835_row0_col11, #T_2b835_row0_col12, #T_2b835_row1_col2, #T_2b835_row1_col4, #T_2b835_row1_col7, #T_2b835_row1_col9, #T_2b835_row1_col11, #T_2b835_row1_col12, #T_2b835_row1_col14, #T_2b835_row2_col3, #T_2b835_row2_col4, #T_2b835_row2_col5, #T_2b835_row2_col10, #T_2b835_row2_col11, #T_2b835_row2_col12, #T_2b835_row2_col13, #T_2b835_row2_col15, #T_2b835_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b835_row0_col13, #T_2b835_row0_col14, #T_2b835_row0_col15, #T_2b835_row0_col17, #T_2b835_row1_col17, #T_2b835_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b835_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b835_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b835_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b835_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f4c5ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b835_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2b835_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2b835_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2b835\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2b835_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_2b835_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_2b835_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_2b835_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_2b835_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_2b835_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_2b835_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_2b835_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_2b835_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_2b835_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_2b835_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_2b835_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_2b835_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_2b835_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_2b835_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_2b835_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_2b835_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_2b835_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2b835_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2b835_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_2b835_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_2b835_row0_col2\" class=\"data row0 col2\" >38.4</td>\n",
       "      <td id=\"T_2b835_row0_col3\" class=\"data row0 col3\" >36.5</td>\n",
       "      <td id=\"T_2b835_row0_col4\" class=\"data row0 col4\" >6.6</td>\n",
       "      <td id=\"T_2b835_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_2b835_row0_col6\" class=\"data row0 col6\" >31.3</td>\n",
       "      <td id=\"T_2b835_row0_col7\" class=\"data row0 col7\" >34.1</td>\n",
       "      <td id=\"T_2b835_row0_col8\" class=\"data row0 col8\" >7.9</td>\n",
       "      <td id=\"T_2b835_row0_col9\" class=\"data row0 col9\" >33.3</td>\n",
       "      <td id=\"T_2b835_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_2b835_row0_col11\" class=\"data row0 col11\" >49.3</td>\n",
       "      <td id=\"T_2b835_row0_col12\" class=\"data row0 col12\" >252.2</td>\n",
       "      <td id=\"T_2b835_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_2b835_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_2b835_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_2b835_row0_col16\" class=\"data row0 col16\" >46.6</td>\n",
       "      <td id=\"T_2b835_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b835_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2b835_row1_col0\" class=\"data row1 col0\" >llama-7b_ultrachat50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_2b835_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_2b835_row1_col2\" class=\"data row1 col2\" >37.3</td>\n",
       "      <td id=\"T_2b835_row1_col3\" class=\"data row1 col3\" >36.6</td>\n",
       "      <td id=\"T_2b835_row1_col4\" class=\"data row1 col4\" >5.8</td>\n",
       "      <td id=\"T_2b835_row1_col5\" class=\"data row1 col5\" >10.6</td>\n",
       "      <td id=\"T_2b835_row1_col6\" class=\"data row1 col6\" >32.7</td>\n",
       "      <td id=\"T_2b835_row1_col7\" class=\"data row1 col7\" >33.1</td>\n",
       "      <td id=\"T_2b835_row1_col8\" class=\"data row1 col8\" >7.9</td>\n",
       "      <td id=\"T_2b835_row1_col9\" class=\"data row1 col9\" >30.4</td>\n",
       "      <td id=\"T_2b835_row1_col10\" class=\"data row1 col10\" >11.2</td>\n",
       "      <td id=\"T_2b835_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_2b835_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_2b835_row1_col13\" class=\"data row1 col13\" >50.4</td>\n",
       "      <td id=\"T_2b835_row1_col14\" class=\"data row1 col14\" >37.5</td>\n",
       "      <td id=\"T_2b835_row1_col15\" class=\"data row1 col15\" >44.0</td>\n",
       "      <td id=\"T_2b835_row1_col16\" class=\"data row1 col16\" >28.1</td>\n",
       "      <td id=\"T_2b835_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2b835_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_2b835_row2_col0\" class=\"data row2 col0\" >llama-7b_ultrachat50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_2b835_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_2b835_row2_col2\" class=\"data row2 col2\" >38.9</td>\n",
       "      <td id=\"T_2b835_row2_col3\" class=\"data row2 col3\" >34.5</td>\n",
       "      <td id=\"T_2b835_row2_col4\" class=\"data row2 col4\" >5.8</td>\n",
       "      <td id=\"T_2b835_row2_col5\" class=\"data row2 col5\" >9.0</td>\n",
       "      <td id=\"T_2b835_row2_col6\" class=\"data row2 col6\" >33.0</td>\n",
       "      <td id=\"T_2b835_row2_col7\" class=\"data row2 col7\" >33.5</td>\n",
       "      <td id=\"T_2b835_row2_col8\" class=\"data row2 col8\" >8.2</td>\n",
       "      <td id=\"T_2b835_row2_col9\" class=\"data row2 col9\" >31.2</td>\n",
       "      <td id=\"T_2b835_row2_col10\" class=\"data row2 col10\" >10.2</td>\n",
       "      <td id=\"T_2b835_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_2b835_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_2b835_row2_col13\" class=\"data row2 col13\" >49.1</td>\n",
       "      <td id=\"T_2b835_row2_col14\" class=\"data row2 col14\" >37.6</td>\n",
       "      <td id=\"T_2b835_row2_col15\" class=\"data row2 col15\" >43.4</td>\n",
       "      <td id=\"T_2b835_row2_col16\" class=\"data row2 col16\" >27.9</td>\n",
       "      <td id=\"T_2b835_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee14afe50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ca1f0 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_ca1f0_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ca1f0_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ca1f0_row0_col2, #T_ca1f0_row0_col3, #T_ca1f0_row0_col4, #T_ca1f0_row0_col5, #T_ca1f0_row0_col6, #T_ca1f0_row0_col7, #T_ca1f0_row0_col8, #T_ca1f0_row0_col9, #T_ca1f0_row0_col10, #T_ca1f0_row0_col11, #T_ca1f0_row0_col12, #T_ca1f0_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ca1f0_row0_col13, #T_ca1f0_row0_col14, #T_ca1f0_row0_col15, #T_ca1f0_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ca1f0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ca1f0_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_ca1f0_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_ca1f0_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_ca1f0_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_ca1f0_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_ca1f0_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_ca1f0_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_ca1f0_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_ca1f0_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_ca1f0_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_ca1f0_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_ca1f0_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_ca1f0_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_ca1f0_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_ca1f0_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_ca1f0_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_ca1f0_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_ca1f0_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ca1f0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ca1f0_row0_col0\" class=\"data row0 col0\" >llama-7b_ultrachat50k_ep=2</td>\n",
       "      <td id=\"T_ca1f0_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_ca1f0_row0_col2\" class=\"data row0 col2\" >38.4</td>\n",
       "      <td id=\"T_ca1f0_row0_col3\" class=\"data row0 col3\" >36.5</td>\n",
       "      <td id=\"T_ca1f0_row0_col4\" class=\"data row0 col4\" >6.6</td>\n",
       "      <td id=\"T_ca1f0_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_ca1f0_row0_col6\" class=\"data row0 col6\" >31.3</td>\n",
       "      <td id=\"T_ca1f0_row0_col7\" class=\"data row0 col7\" >34.1</td>\n",
       "      <td id=\"T_ca1f0_row0_col8\" class=\"data row0 col8\" >7.9</td>\n",
       "      <td id=\"T_ca1f0_row0_col9\" class=\"data row0 col9\" >33.3</td>\n",
       "      <td id=\"T_ca1f0_row0_col10\" class=\"data row0 col10\" >11.8</td>\n",
       "      <td id=\"T_ca1f0_row0_col11\" class=\"data row0 col11\" >49.3</td>\n",
       "      <td id=\"T_ca1f0_row0_col12\" class=\"data row0 col12\" >252.2</td>\n",
       "      <td id=\"T_ca1f0_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_ca1f0_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_ca1f0_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_ca1f0_row0_col16\" class=\"data row0 col16\" >46.6</td>\n",
       "      <td id=\"T_ca1f0_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee15aea40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_da928 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_da928_row0_col0, #T_da928_row1_col0, #T_da928_row2_col0, #T_da928_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_da928_row0_col1, #T_da928_row1_col1, #T_da928_row2_col1, #T_da928_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_da928_row0_col2, #T_da928_row0_col5, #T_da928_row0_col6, #T_da928_row0_col16, #T_da928_row1_col14, #T_da928_row2_col13, #T_da928_row2_col15, #T_da928_row3_col3, #T_da928_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_da928_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_da928_row0_col4, #T_da928_row0_col7, #T_da928_row0_col8, #T_da928_row0_col9, #T_da928_row0_col10, #T_da928_row0_col11, #T_da928_row0_col12, #T_da928_row1_col2, #T_da928_row1_col3, #T_da928_row1_col7, #T_da928_row1_col8, #T_da928_row1_col9, #T_da928_row1_col10, #T_da928_row1_col11, #T_da928_row1_col12, #T_da928_row1_col13, #T_da928_row2_col6, #T_da928_row2_col7, #T_da928_row2_col8, #T_da928_row2_col9, #T_da928_row2_col10, #T_da928_row2_col11, #T_da928_row2_col12, #T_da928_row3_col5, #T_da928_row3_col7, #T_da928_row3_col8, #T_da928_row3_col9, #T_da928_row3_col10, #T_da928_row3_col11, #T_da928_row3_col12, #T_da928_row3_col14, #T_da928_row3_col15, #T_da928_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_da928_row0_col13, #T_da928_row0_col14, #T_da928_row0_col15, #T_da928_row0_col17, #T_da928_row1_col5, #T_da928_row1_col6, #T_da928_row1_col17, #T_da928_row2_col17, #T_da928_row3_col6, #T_da928_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_da928_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_da928_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_da928_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_da928_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_da928_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_da928_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_da928_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_da928_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_da928_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_da928_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #ea7b60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_da928_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_da928\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_da928_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_da928_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_da928_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_da928_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_da928_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_da928_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_da928_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_da928_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_da928_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_da928_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_da928_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_da928_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_da928_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_da928_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_da928_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_da928_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_da928_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_da928_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_da928_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_da928_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_da928_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_da928_row0_col2\" class=\"data row0 col2\" >35.0</td>\n",
       "      <td id=\"T_da928_row0_col3\" class=\"data row0 col3\" >37.0</td>\n",
       "      <td id=\"T_da928_row0_col4\" class=\"data row0 col4\" >2.8</td>\n",
       "      <td id=\"T_da928_row0_col5\" class=\"data row0 col5\" >13.4</td>\n",
       "      <td id=\"T_da928_row0_col6\" class=\"data row0 col6\" >33.7</td>\n",
       "      <td id=\"T_da928_row0_col7\" class=\"data row0 col7\" >32.5</td>\n",
       "      <td id=\"T_da928_row0_col8\" class=\"data row0 col8\" >7.7</td>\n",
       "      <td id=\"T_da928_row0_col9\" class=\"data row0 col9\" >30.1</td>\n",
       "      <td id=\"T_da928_row0_col10\" class=\"data row0 col10\" >14.6</td>\n",
       "      <td id=\"T_da928_row0_col11\" class=\"data row0 col11\" >47.8</td>\n",
       "      <td id=\"T_da928_row0_col12\" class=\"data row0 col12\" >261.7</td>\n",
       "      <td id=\"T_da928_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_da928_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_da928_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_da928_row0_col16\" class=\"data row0 col16\" >46.9</td>\n",
       "      <td id=\"T_da928_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_da928_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_da928_row1_col0\" class=\"data row1 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_da928_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_da928_row1_col2\" class=\"data row1 col2\" >29.4</td>\n",
       "      <td id=\"T_da928_row1_col3\" class=\"data row1 col3\" >32.9</td>\n",
       "      <td id=\"T_da928_row1_col4\" class=\"data row1 col4\" >4.6</td>\n",
       "      <td id=\"T_da928_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "      <td id=\"T_da928_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_da928_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_da928_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_da928_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_da928_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_da928_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_da928_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_da928_row1_col13\" class=\"data row1 col13\" >43.9</td>\n",
       "      <td id=\"T_da928_row1_col14\" class=\"data row1 col14\" >28.9</td>\n",
       "      <td id=\"T_da928_row1_col15\" class=\"data row1 col15\" >36.4</td>\n",
       "      <td id=\"T_da928_row1_col16\" class=\"data row1 col16\" >29.3</td>\n",
       "      <td id=\"T_da928_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_da928_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_da928_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_da928_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_da928_row2_col2\" class=\"data row2 col2\" >32.6</td>\n",
       "      <td id=\"T_da928_row2_col3\" class=\"data row2 col3\" >35.4</td>\n",
       "      <td id=\"T_da928_row2_col4\" class=\"data row2 col4\" >3.8</td>\n",
       "      <td id=\"T_da928_row2_col5\" class=\"data row2 col5\" >12.8</td>\n",
       "      <td id=\"T_da928_row2_col6\" class=\"data row2 col6\" >33.4</td>\n",
       "      <td id=\"T_da928_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_da928_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_da928_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_da928_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_da928_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_da928_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_da928_row2_col13\" class=\"data row2 col13\" >46.2</td>\n",
       "      <td id=\"T_da928_row2_col14\" class=\"data row2 col14\" >26.6</td>\n",
       "      <td id=\"T_da928_row2_col15\" class=\"data row2 col15\" >36.5</td>\n",
       "      <td id=\"T_da928_row2_col16\" class=\"data row2 col16\" >28.4</td>\n",
       "      <td id=\"T_da928_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_da928_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_da928_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_da928_row3_col1\" class=\"data row3 col1\" >10000</td>\n",
       "      <td id=\"T_da928_row3_col2\" class=\"data row3 col2\" >34.0</td>\n",
       "      <td id=\"T_da928_row3_col3\" class=\"data row3 col3\" >37.8</td>\n",
       "      <td id=\"T_da928_row3_col4\" class=\"data row3 col4\" >4.8</td>\n",
       "      <td id=\"T_da928_row3_col5\" class=\"data row3 col5\" >12.0</td>\n",
       "      <td id=\"T_da928_row3_col6\" class=\"data row3 col6\" >nan</td>\n",
       "      <td id=\"T_da928_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "      <td id=\"T_da928_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
       "      <td id=\"T_da928_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
       "      <td id=\"T_da928_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
       "      <td id=\"T_da928_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_da928_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_da928_row3_col13\" class=\"data row3 col13\" >44.2</td>\n",
       "      <td id=\"T_da928_row3_col14\" class=\"data row3 col14\" >25.9</td>\n",
       "      <td id=\"T_da928_row3_col15\" class=\"data row3 col15\" >35.4</td>\n",
       "      <td id=\"T_da928_row3_col16\" class=\"data row3 col16\" >27.7</td>\n",
       "      <td id=\"T_da928_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee14af8b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d70f4 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_d70f4_row0_col0, #T_d70f4_row1_col0, #T_d70f4_row2_col0, #T_d70f4_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d70f4_row0_col1, #T_d70f4_row1_col1, #T_d70f4_row2_col1, #T_d70f4_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d70f4_row0_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #d44e41;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d70f4_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d70f4_row0_col4, #T_d70f4_row0_col6, #T_d70f4_row0_col7, #T_d70f4_row0_col8, #T_d70f4_row0_col9, #T_d70f4_row0_col10, #T_d70f4_row0_col11, #T_d70f4_row0_col12, #T_d70f4_row1_col7, #T_d70f4_row1_col8, #T_d70f4_row1_col9, #T_d70f4_row1_col10, #T_d70f4_row1_col11, #T_d70f4_row1_col12, #T_d70f4_row2_col7, #T_d70f4_row2_col8, #T_d70f4_row2_col9, #T_d70f4_row2_col10, #T_d70f4_row2_col11, #T_d70f4_row2_col12, #T_d70f4_row2_col13, #T_d70f4_row2_col14, #T_d70f4_row2_col15, #T_d70f4_row3_col2, #T_d70f4_row3_col3, #T_d70f4_row3_col5, #T_d70f4_row3_col7, #T_d70f4_row3_col8, #T_d70f4_row3_col9, #T_d70f4_row3_col10, #T_d70f4_row3_col11, #T_d70f4_row3_col12, #T_d70f4_row3_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d70f4_row0_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d70f4_row0_col13, #T_d70f4_row0_col14, #T_d70f4_row0_col15, #T_d70f4_row0_col17, #T_d70f4_row1_col6, #T_d70f4_row1_col17, #T_d70f4_row2_col17, #T_d70f4_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d70f4_row0_col16, #T_d70f4_row1_col2, #T_d70f4_row1_col3, #T_d70f4_row1_col4, #T_d70f4_row1_col13, #T_d70f4_row1_col15, #T_d70f4_row2_col5, #T_d70f4_row2_col6, #T_d70f4_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d70f4_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d70f4_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d70f4_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d70f4_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #cc403a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d70f4_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d70f4_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d70f4_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d70f4_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dcdddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d70f4_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d70f4_row3_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d70f4_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d70f4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d70f4_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_d70f4_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_d70f4_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_d70f4_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_d70f4_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_d70f4_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_d70f4_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_d70f4_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_d70f4_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_d70f4_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_d70f4_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_d70f4_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_d70f4_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_d70f4_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_d70f4_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_d70f4_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_d70f4_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_d70f4_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d70f4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d70f4_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_d70f4_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_d70f4_row0_col2\" class=\"data row0 col2\" >35.0</td>\n",
       "      <td id=\"T_d70f4_row0_col3\" class=\"data row0 col3\" >37.0</td>\n",
       "      <td id=\"T_d70f4_row0_col4\" class=\"data row0 col4\" >2.8</td>\n",
       "      <td id=\"T_d70f4_row0_col5\" class=\"data row0 col5\" >13.4</td>\n",
       "      <td id=\"T_d70f4_row0_col6\" class=\"data row0 col6\" >33.7</td>\n",
       "      <td id=\"T_d70f4_row0_col7\" class=\"data row0 col7\" >32.5</td>\n",
       "      <td id=\"T_d70f4_row0_col8\" class=\"data row0 col8\" >7.7</td>\n",
       "      <td id=\"T_d70f4_row0_col9\" class=\"data row0 col9\" >30.1</td>\n",
       "      <td id=\"T_d70f4_row0_col10\" class=\"data row0 col10\" >14.6</td>\n",
       "      <td id=\"T_d70f4_row0_col11\" class=\"data row0 col11\" >47.8</td>\n",
       "      <td id=\"T_d70f4_row0_col12\" class=\"data row0 col12\" >261.7</td>\n",
       "      <td id=\"T_d70f4_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_d70f4_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_d70f4_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_d70f4_row0_col16\" class=\"data row0 col16\" >46.9</td>\n",
       "      <td id=\"T_d70f4_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d70f4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d70f4_row1_col0\" class=\"data row1 col0\" >llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_d70f4_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_d70f4_row1_col2\" class=\"data row1 col2\" >35.6</td>\n",
       "      <td id=\"T_d70f4_row1_col3\" class=\"data row1 col3\" >37.6</td>\n",
       "      <td id=\"T_d70f4_row1_col4\" class=\"data row1 col4\" >4.8</td>\n",
       "      <td id=\"T_d70f4_row1_col5\" class=\"data row1 col5\" >13.2</td>\n",
       "      <td id=\"T_d70f4_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "      <td id=\"T_d70f4_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "      <td id=\"T_d70f4_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "      <td id=\"T_d70f4_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "      <td id=\"T_d70f4_row1_col10\" class=\"data row1 col10\" >nan</td>\n",
       "      <td id=\"T_d70f4_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_d70f4_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_d70f4_row1_col13\" class=\"data row1 col13\" >49.2</td>\n",
       "      <td id=\"T_d70f4_row1_col14\" class=\"data row1 col14\" >32.8</td>\n",
       "      <td id=\"T_d70f4_row1_col15\" class=\"data row1 col15\" >41.1</td>\n",
       "      <td id=\"T_d70f4_row1_col16\" class=\"data row1 col16\" >30.6</td>\n",
       "      <td id=\"T_d70f4_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d70f4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d70f4_row2_col0\" class=\"data row2 col0\" >llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_d70f4_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_d70f4_row2_col2\" class=\"data row2 col2\" >35.2</td>\n",
       "      <td id=\"T_d70f4_row2_col3\" class=\"data row2 col3\" >35.4</td>\n",
       "      <td id=\"T_d70f4_row2_col4\" class=\"data row2 col4\" >4.6</td>\n",
       "      <td id=\"T_d70f4_row2_col5\" class=\"data row2 col5\" >14.0</td>\n",
       "      <td id=\"T_d70f4_row2_col6\" class=\"data row2 col6\" >34.5</td>\n",
       "      <td id=\"T_d70f4_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "      <td id=\"T_d70f4_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "      <td id=\"T_d70f4_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "      <td id=\"T_d70f4_row2_col10\" class=\"data row2 col10\" >nan</td>\n",
       "      <td id=\"T_d70f4_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_d70f4_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_d70f4_row2_col13\" class=\"data row2 col13\" >45.9</td>\n",
       "      <td id=\"T_d70f4_row2_col14\" class=\"data row2 col14\" >28.1</td>\n",
       "      <td id=\"T_d70f4_row2_col15\" class=\"data row2 col15\" >37.0</td>\n",
       "      <td id=\"T_d70f4_row2_col16\" class=\"data row2 col16\" >29.3</td>\n",
       "      <td id=\"T_d70f4_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d70f4_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d70f4_row3_col0\" class=\"data row3 col0\" >llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_d70f4_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_d70f4_row3_col2\" class=\"data row3 col2\" >28.5</td>\n",
       "      <td id=\"T_d70f4_row3_col3\" class=\"data row3 col3\" >31.5</td>\n",
       "      <td id=\"T_d70f4_row3_col4\" class=\"data row3 col4\" >3.8</td>\n",
       "      <td id=\"T_d70f4_row3_col5\" class=\"data row3 col5\" >12.0</td>\n",
       "      <td id=\"T_d70f4_row3_col6\" class=\"data row3 col6\" >34.4</td>\n",
       "      <td id=\"T_d70f4_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "      <td id=\"T_d70f4_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
       "      <td id=\"T_d70f4_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
       "      <td id=\"T_d70f4_row3_col10\" class=\"data row3 col10\" >nan</td>\n",
       "      <td id=\"T_d70f4_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_d70f4_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_d70f4_row3_col13\" class=\"data row3 col13\" >46.8</td>\n",
       "      <td id=\"T_d70f4_row3_col14\" class=\"data row3 col14\" >34.8</td>\n",
       "      <td id=\"T_d70f4_row3_col15\" class=\"data row3 col15\" >40.8</td>\n",
       "      <td id=\"T_d70f4_row3_col16\" class=\"data row3 col16\" >29.1</td>\n",
       "      <td id=\"T_d70f4_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee14af460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_90f55 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_90f55_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_90f55_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_90f55_row0_col2, #T_90f55_row0_col3, #T_90f55_row0_col4, #T_90f55_row0_col5, #T_90f55_row0_col6, #T_90f55_row0_col7, #T_90f55_row0_col8, #T_90f55_row0_col9, #T_90f55_row0_col10, #T_90f55_row0_col11, #T_90f55_row0_col12, #T_90f55_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_90f55_row0_col13, #T_90f55_row0_col14, #T_90f55_row0_col15, #T_90f55_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_90f55\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_90f55_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_90f55_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_90f55_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_90f55_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_90f55_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_90f55_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_90f55_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_90f55_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_90f55_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_90f55_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_90f55_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_90f55_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_90f55_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_90f55_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_90f55_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_90f55_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_90f55_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_90f55_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_90f55_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_90f55_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_90f55_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_90f55_row0_col2\" class=\"data row0 col2\" >35.0</td>\n",
       "      <td id=\"T_90f55_row0_col3\" class=\"data row0 col3\" >37.0</td>\n",
       "      <td id=\"T_90f55_row0_col4\" class=\"data row0 col4\" >2.8</td>\n",
       "      <td id=\"T_90f55_row0_col5\" class=\"data row0 col5\" >13.4</td>\n",
       "      <td id=\"T_90f55_row0_col6\" class=\"data row0 col6\" >33.7</td>\n",
       "      <td id=\"T_90f55_row0_col7\" class=\"data row0 col7\" >32.5</td>\n",
       "      <td id=\"T_90f55_row0_col8\" class=\"data row0 col8\" >7.7</td>\n",
       "      <td id=\"T_90f55_row0_col9\" class=\"data row0 col9\" >30.1</td>\n",
       "      <td id=\"T_90f55_row0_col10\" class=\"data row0 col10\" >14.6</td>\n",
       "      <td id=\"T_90f55_row0_col11\" class=\"data row0 col11\" >47.8</td>\n",
       "      <td id=\"T_90f55_row0_col12\" class=\"data row0 col12\" >261.7</td>\n",
       "      <td id=\"T_90f55_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_90f55_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_90f55_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_90f55_row0_col16\" class=\"data row0 col16\" >46.9</td>\n",
       "      <td id=\"T_90f55_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee0e07be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/1771584410.py:387: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/1771584410.py:393: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3819: RuntimeWarning: All-NaN slice encountered\n",
      "  smin = np.nanmin(gmap) if vmin is None else vmin\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pandas/io/formats/style.py:3820: RuntimeWarning: All-NaN slice encountered\n",
      "  smax = np.nanmax(gmap) if vmax is None else vmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_26e08 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_26e08_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_26e08_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_26e08_row0_col2, #T_26e08_row0_col3, #T_26e08_row0_col4, #T_26e08_row0_col5, #T_26e08_row0_col6, #T_26e08_row0_col7, #T_26e08_row0_col8, #T_26e08_row0_col9, #T_26e08_row0_col10, #T_26e08_row0_col11, #T_26e08_row0_col12, #T_26e08_row0_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_26e08_row0_col13, #T_26e08_row0_col14, #T_26e08_row0_col15, #T_26e08_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_26e08\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_26e08_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_26e08_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_26e08_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_26e08_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_26e08_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_26e08_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_26e08_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_26e08_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_26e08_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_26e08_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_26e08_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_26e08_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_26e08_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_26e08_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_26e08_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_26e08_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_26e08_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_26e08_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_26e08_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_26e08_row0_col0\" class=\"data row0 col0\" >llama-7b_wizardlm50k_ep=2</td>\n",
       "      <td id=\"T_26e08_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_26e08_row0_col2\" class=\"data row0 col2\" >35.0</td>\n",
       "      <td id=\"T_26e08_row0_col3\" class=\"data row0 col3\" >37.0</td>\n",
       "      <td id=\"T_26e08_row0_col4\" class=\"data row0 col4\" >2.8</td>\n",
       "      <td id=\"T_26e08_row0_col5\" class=\"data row0 col5\" >13.4</td>\n",
       "      <td id=\"T_26e08_row0_col6\" class=\"data row0 col6\" >33.7</td>\n",
       "      <td id=\"T_26e08_row0_col7\" class=\"data row0 col7\" >32.5</td>\n",
       "      <td id=\"T_26e08_row0_col8\" class=\"data row0 col8\" >7.7</td>\n",
       "      <td id=\"T_26e08_row0_col9\" class=\"data row0 col9\" >30.1</td>\n",
       "      <td id=\"T_26e08_row0_col10\" class=\"data row0 col10\" >14.6</td>\n",
       "      <td id=\"T_26e08_row0_col11\" class=\"data row0 col11\" >47.8</td>\n",
       "      <td id=\"T_26e08_row0_col12\" class=\"data row0 col12\" >261.7</td>\n",
       "      <td id=\"T_26e08_row0_col13\" class=\"data row0 col13\" >nan</td>\n",
       "      <td id=\"T_26e08_row0_col14\" class=\"data row0 col14\" >nan</td>\n",
       "      <td id=\"T_26e08_row0_col15\" class=\"data row0 col15\" >nan</td>\n",
       "      <td id=\"T_26e08_row0_col16\" class=\"data row0 col16\" >46.9</td>\n",
       "      <td id=\"T_26e08_row0_col17\" class=\"data row0 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee15acee0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_sort_rows_by_avg_ranking\n",
    "from llm.evaluate import EvalResults, get_eval_results\n",
    "\n",
    "\n",
    "\n",
    "exp_dir = ''\n",
    "chat_fmt = None\n",
    "sort_rows = True\n",
    "use_normalized_preferred_metric = False\n",
    "\n",
    "\n",
    "# ## investigate code change / package update effect on eval baselines.\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# use_normalized_preferred_metric = False\n",
    "# sort_rows = False\n",
    "# save_dirs = [\n",
    "#     # llama\n",
    "#     ('llama-7b_12.13update_before', '../results/baselines/huggyllama/llama-7b_12.13update_before/'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('llama-7b_10.30update', '../results/baselines/huggyllama/llama-7b_10.30update/'),\n",
    "# #     ('llama-7b_09.23update', '../results/baselines/huggyllama/llama-7b_09.23update/'),\n",
    "# #     ('llama-7b_09.23update_before', '../results/baselines/huggyllama/llama-7b_09.23update_before/'),\n",
    "# #     # llama2\n",
    "#     ('llama2-7b_12.13update_before', '../results/baselines/NousResearch/Llama-2-7b-hf_12.13update_before/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('llama2-7b-chat', '../results/baselines/NousResearch/Llama-2-7b-chat-hf/'),\n",
    "# #     ('llama2-7b_10.30update', '../results/baselines/NousResearch/Llama-2-7b-hf_10.30update/'),\n",
    "# #     ('llama2-7b_original', '../results/baselines/NousResearch/Llama-2-7b-hf_original/'),\n",
    "# #     # mistral\n",
    "# #     ('mistral-7b_10.16update', '../results/baselines/mistralai/Mistral-7B-v0.1_10.16update/'),\n",
    "#     ('mistral-7b-Instruct-v0.1_12.13update_before', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1_12.13update_before'),\n",
    "#     ('mistral-7b-Instruct-v0.1', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     # zephyr\n",
    "#     ('zephyr-7b-beta_12.13update_before', '../results/baselines/HuggingFaceH4/zephyr-7b-beta_12.13update_before'),\n",
    "#     ('zephyr-7b-beta', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "\n",
    "# # baselines\n",
    "# save_dirs = []\n",
    "# save_dirs += [\n",
    "# #     ('gpt2', '../results/baselines/gpt2'),\n",
    "# #     ('gpt2m', '../results/baselines/gpt2-medium'),\n",
    "# #     ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "# #     ('llama2-7b+humanmix', '../results/llama2-7b_humanmix'),\n",
    "# #     ('pythia-1.4b', '../results/baselines/EleutherAI/pythia-1.4b'),\n",
    "# #     ('pythia-2.8b', '../results/baselines/EleutherAI/pythia-2.8b'),\n",
    "# #     ('pythia-6.9b', '../results/baselines/EleutherAI/pythia-6.9b'),\n",
    "# #     ('dolly-v2-7b', '../results/baselines/databricks/dolly-v2-7b'),\n",
    "#     ('mistral-7b-v0.1', '../results/baselines/mistralai/Mistral-7B-v0.1'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b+lima_ep=2', '../results/ft1_ep=2/llama-7b_lima/'),\n",
    "# #     ('mistral-7b+lima_ep=2', '../results/ft1_ep=2/mistral-7b_lima/'), \n",
    "# ]\n",
    "# exp_dir = '../results/oi2/'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "\n",
    "# exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# # exp_dir = '../results/ft2'\n",
    "# # exp_dir = '../results/ft1'\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# # save_dirs = [\n",
    "# #     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "# #     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1/'),\n",
    "# # ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'tuluv1m' in x]\n",
    "\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "# # exp_dir = '../results/oi4'\n",
    "# # exp_dir = '../results/oi4_perf_cross_time'\n",
    "# # exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'\n",
    "# exp_dir = '../results/oi4_flan_v2_vary_subsetsize'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi4_flan2022_1m'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #              ('llama-7b_flan_v2_ep=2', '../results/ft1/llama-7b_flan_v2'),\n",
    "# #              ('llama-7b_humanmix_ep=2', '../results/ft1/llama-7b_humanmix'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "# #              ('llama-7b_cot:flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_cot:flanv2'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# # exp_dir = '../results/oi4_tulu_v1_mix'\n",
    "# exp_dir = '../results/oi4_tulu_v1_mix_ep=3'\n",
    "# use_normalized_preferred_metric = False\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# ###### ultrachat\n",
    "# save_dirs = [\n",
    "#     # baselines \n",
    "#     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "#     ('mistral-7b_ultrachat200k_aftersplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k'),\n",
    "#     ('mistral-7b_ultrachat200k_beforesplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k_beforesplitlongconv'),\n",
    "    \n",
    "#     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     ('mistral-7b_sft-alpha', '../results/baselines/HuggingFaceH4/mistral-7b-sft-alpha'),\n",
    "#     ('mistral-7b-sft-beta', '../results/baselines/HuggingFaceH4/mistral-7b-sft-beta'),\n",
    "#     ('mistral-7b-sft-alpha+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-alpha'),\n",
    "#     ('mistral-7b-sft-beta+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "# # exp_dir = '../results/oi5_ultrachat:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_ultrachat200k:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# exp_dir = '../results/oi5_ultrachat15:mistral-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "# dataset = 'stanford_alpaca'\n",
    "# dataset = 'open_orca_slim'\n",
    "# dataset = 'sharegptv2'\n",
    "# dataset = 'ultrachat200kv2'\n",
    "# dataset = 'wizardlm'\n",
    "# dataset = 'wizardlmv2'\n",
    "# dataset = 'tulu_v2'\n",
    "# dataset = 'flan_v2'\n",
    "# dataset = 'oasst1'\n",
    "# dataset = 'dolly'\n",
    "# dataset_list = [\n",
    "#     'dolly',\n",
    "#     'oasst1', \n",
    "#     'flan_v2', \n",
    "#     'stanford_alpaca', \n",
    "#     'wizardlmv2', \n",
    "#     'sharegptv2', \n",
    "#     'ultrachat200kv2',\n",
    "# ]; finetune_type = 'sft'\n",
    "dataset_list = [\n",
    "    'dolly',\n",
    "#     'oasst1', \n",
    "#     'flan_v250k', \n",
    "#     'stanford_alpaca50k', \n",
    "#     'wizardlm50k', \n",
    "    'sharegpt50k', \n",
    "#     'ultrachat50k',\n",
    "]; finetune_type = 'sft'\n",
    "# dataset_list = [\n",
    "#     'dolly',\n",
    "# #     'oasst1', \n",
    "# #     'flan_v2', \n",
    "# #     'stanford_alpaca', \n",
    "# #     'wizardlmv2', \n",
    "# #     'sharegptv2', \n",
    "# #     'ultrachat200kv2',\n",
    "# ]; finetune_type = 'sft'\n",
    "# dataset_list = [\n",
    "#     'ultrafeedback',\n",
    "# #     'ultrafeedbackfull',\n",
    "# ]; finetune_type = 'pref'\n",
    "dataset_list = [\n",
    "    'dolly',\n",
    "    'flan_v250k',\n",
    "    'stanford_alpaca50k', \n",
    "    'oasst2',\n",
    "    'wizardlm50k', \n",
    "    'sharegpt50k',\n",
    "    'ultrachat50k',\n",
    "]; finetune_type = 'sft'\n",
    "\n",
    "## older\n",
    "# dataset = 'tulu_v1_mix'\n",
    "save_dirs = []\n",
    "save_dirs += [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b'),\n",
    "#     ('llama-7b_lima_ep=5', '../results/oi2/llama-7b_lima_ep=5/'),\n",
    "#     ('llama-7b_lima_ep=10', '../results/oi2/llama-7b_lima_ep=10/'),\n",
    "]\n",
    "for dataset in dataset_list:\n",
    "    if dataset == 'tulu_v2':\n",
    "        save_dirs += [('llama-7b_tulu_v2:100k_ep=2', '../results/oi2/llama-7b_tulu_v2:100k_ep=2'),]\n",
    "    elif dataset == 'open_orca_slim':\n",
    "        save_dirs += [('llama-7b_openorcaslim:100k_ep=2', '../results/oi2/llama-7b_openorcaslim:100k_ep=2'),]\n",
    "    elif dataset == 'sharegptv2':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_sharegptv2_ep=2', '../results/oi2/llama-7b_sharegptv2_ep=2'),\n",
    "            ('llama-7b_sharegpt_ep=2', '../results/ft1_ep=2/llama-7b_sharegpt'),]\n",
    "    elif dataset == 'tulu_v1_mix':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "            # oi4_tulu_v1_mix_ep=3 models before transformers update.\n",
    "            # ('llama-7b_tuluv1m:50k_log_prob_decr_<10.16update', '../results/oi4_tulu_v1_mix_ep=3/llama-7b_tuluv1m:50k_log_prob_decr'),\n",
    "        ]\n",
    "    elif dataset == 'ultrafeedback':\n",
    "        exp_dir = f'../results/dpo1/'\n",
    "        save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "    else:\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=2', f'../results/oi2/llama-7b_{dataset}_ep=2'),]\n",
    "    \n",
    "    if finetune_type == 'sft':\n",
    "        exp_dir = f'../results/oi5_{dataset}:llama-7b'\n",
    "    elif finetune_type == 'pref':\n",
    "        exp_dir = f'../results/dpo2_{dataset}:llama-7b+sharegptv2ep2/'\n",
    "    save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'dppmapbd' not in x and 'semdedup' not in x]\n",
    "    \n",
    "    if finetune_type == 'pref':\n",
    "        sft_model_dataset = 'sharegptv2'\n",
    "        save_dirs += [('llama-7b_sharegptv2_ep=2', f'../results/oi2/llama-7b_{sft_model_dataset}_ep=2')]\n",
    "# ## just compare dppmap grad vs. text\n",
    "# save_dirs = [x for x in save_dirs if 'prune:size=10000:ep=10' in x[1] and (\n",
    "#         'random' in x[1] or \n",
    "#         'dppmap' in x[1]\n",
    "#     )\n",
    "# ]\n",
    "#####\n",
    "\n",
    "\n",
    "# ##### code instructions\n",
    "# save_dirs = [\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('codellama-7b', '../results/baselines/codellama/CodeLlama-7b-hf/'),\n",
    "#     ('codellama-7b-instruct', '../results/baselines/codellama/CodeLlama-7b-Python-hf/'),\n",
    "#     ('codellama-7b-python', '../results/baselines/codellama/CodeLlama-7b-Instruct-hf/'),\n",
    "# ]\n",
    "\n",
    "# exp_dir = '../results/oi2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'starcoder' in x]\n",
    "# exp_dir = '../results/oi6_starcoder_ep=5'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstr:codellama-7b'\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstrv2:codellama-7b'\n",
    "# exp_dir = '../results/oi5_starcoder_commentinstrv5:codellama-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "###### \n",
    "\n",
    "from llm.evaluate import detect_oom_evals\n",
    "oom_eval_paths = detect_oom_evals([x for l in [glob.glob(os.path.join(x[1], 'eval/*/*.out')) for x in save_dirs] for x in l])\n",
    "if oom_eval_paths: print(oom_eval_paths)\n",
    "    \n",
    "cols_avg_blacklist = ['AlpacaFarm/Len']\n",
    "\n",
    "# chat_fmt = False\n",
    "chat_fmt = True\n",
    "chat_fmt = 'both'\n",
    "# chat_fmt = 'auto' # base model no chatfmt, tuned model with chatfmt\n",
    "chat_fmt = 'mix'  # non-alpacaeval no chatfmt, alpacaeval chatfmt\n",
    "alpacafarm_judge = 'chatgpt'\n",
    "mtbench_judge = 'gpt:4:1106:preview'\n",
    "\n",
    "ft_args_fields = {\n",
    "    'run_name': ('run_name',),\n",
    "    'model_name_or_path': ('model_args.model_name_or_path', 'model_name_or_path'),\n",
    "    'subsample_mixture': ('data_args.subsample_mixture',),\n",
    "    'max_train_samples': ('data_args.max_train_samples', 'max_train_samples'),\n",
    "    'train_file': ('data_args.train_file', 'train_file'),\n",
    "}\n",
    "\n",
    "cols = []\n",
    "# cols += [f'AlpacaFarm({alpacafarm_judge})/WR',  f'AlpacaFarm({alpacafarm_judge})/ΔWR', f'AlpacaFarm({alpacafarm_judge})/Rep', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "cols += ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1'] \n",
    "cols += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "cols += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "# cols += [f'MTBench({mtbench_judge})/Turn-1']\n",
    "\n",
    "\n",
    "\n",
    "# cols = [f'BBH {x}' for x in ['reasoning', 'nlu', 'knowledge', 'multilingual']]; cols = [x+'/Direct' for x in cols] + [x+'/CoT' for x in cols]\n",
    "# cols = [f'MMLU {x}' for x in ['STEM', 'humanities', 'social sciences', 'other']]; cols = [x+'/0-shot' for x in cols] + [x+'/5-shot' for x in cols]\n",
    "\n",
    "if 'open_orca_slim' in exp_dir:\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'BBH/Direct', 'BBH/CoT']\n",
    "    cols = ['MMLU/0-shot', 'BBH/Direct']\n",
    "if 'starcoder' in exp_dir:\n",
    "    cols = ['Codex-Eval/Pass@1']\n",
    "    chat_fmt = 'both'\n",
    "print(f'chat_fmt={chat_fmt}')\n",
    "df = get_eval_results(save_dirs, chat_fmt=chat_fmt, ft_args_fields=ft_args_fields, use_normalized_preferred_metric=use_normalized_preferred_metric)\n",
    "\n",
    "cols = [x for x in cols if x in df.columns]\n",
    "df = df[list(ft_args_fields.keys()) + cols]\n",
    "if chat_fmt == 'both':\n",
    "    for col_lvl2 in ['', 'chatfmt']:\n",
    "        df[('Average', col_lvl2)] = df[list(set(df.columns) & set([(x, col_lvl2) for x in list(set(cols)-set(cols_avg_blacklist))]))].mean(axis=1)\n",
    "else:\n",
    "    df['Average'] = df[list(set(cols)-set(cols_avg_blacklist))].mean(axis=1)\n",
    "if sort_rows:\n",
    "    df = pd_sort_rows_by_avg_ranking(df); df['ranking'] = -df['ranking']\n",
    "    sort_value_col, sort_value_col_ascending = ('Average', 'chatfmt') if chat_fmt=='both' else 'Average', False\n",
    "#     sort_value_col, sort_value_col_ascending = 'ranking', False\n",
    "    df = df.sort_values(by=sort_value_col, ascending=sort_value_col_ascending)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def compute_total_train_samples(x):\n",
    "    match = re.search(r'size=(\\d+)', x['run_name' if chat_fmt!='both' else ('run_name', '')])\n",
    "    total_train_samples = match.group(1) if match else None\n",
    "    return total_train_samples\n",
    "df.insert(1, 'total_train_samples' if chat_fmt!='both' else ('total_train_samples', ''), df.apply(compute_total_train_samples, axis=1))\n",
    "def extract_dataset_from_train_file(x):\n",
    "    if x is None: return None\n",
    "    x = x.split('/')[-1].split('.jsonl')[0]\n",
    "    if x.endswith('_data'): x = x[:-5]\n",
    "    if x.endswith('_train'): x = x[:-6]\n",
    "    return x\n",
    "df.insert(1, 'dataset' if chat_fmt!='both' else ('dataset', ''), df['train_file'].apply(extract_dataset_from_train_file))\n",
    "df = df.drop('train_file', axis=1)\n",
    "\n",
    "if any(exp_dir.endswith(x) for x in ['ft2']):\n",
    "#     for model_name_contain in ['gpt2', 'llama', 'pythia-1.4b']:\n",
    "#         for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "    for model_name_contain in ['llama']:\n",
    "        for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "#         for total_train_samples in [200000, 400000, 600000]:\n",
    "            dfc = df.copy()\n",
    "            dfc.insert(0, 'total_train_samples',  dfc['subsample_mixture'].apply(\n",
    "                lambda d: sum(list(d.values())) if d else 200000))\n",
    "            dfc = dfc[dfc['total_train_samples'].apply(\n",
    "                lambda x: total_train_samples-20000<x<total_train_samples+20000)]\n",
    "            dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "                lambda x: model_name_contain in x)]\n",
    "            dfc['total_train_samples'] = dfc['total_train_samples'].astype(str)\n",
    "            dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture'])\n",
    "            dfc = dfc.reset_index(drop=True)\n",
    "            if len(dfc):\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .format(precision=2))\n",
    "else:\n",
    "    for model_name_contain in ['llama', 'pythia-1.4b', 'mistral', 'zephyr']:\n",
    "        dfc = df.copy()\n",
    "        dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "            lambda x: model_name_contain in x.lower())]\n",
    "        if not len(dfc): continue\n",
    "        from rosemary import pd_average_col_contains_substr\n",
    "        Ns = sorted(np.unique([int(x) for x in df['total_train_samples'].to_numpy() if x]).tolist())\n",
    "        datasets = sorted(np.unique([x for x in df['dataset'] if x is not None]).tolist())\n",
    "        for dataset in datasets:\n",
    "            for N in Ns+[None]:\n",
    "                dfc = df.copy()\n",
    "                dfc = dfc[dfc['total_train_samples'].apply(lambda x: int(x) == N if x else True)]\n",
    "                dfc = dfc[dfc['dataset'].apply(lambda x: x == dataset if x else True)]\n",
    "                if not len(dfc): continue\n",
    "                col_runname = 'run_name' if chat_fmt != 'both' else ('run_name', '')\n",
    "                substitute = True\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, '_random_', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=10000:ep=10', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=50000:ep=5', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=3', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=1', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=100000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=200000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=400000', substitute=substitute)\n",
    "                #     dfc = dfc.sort_values(['ranking'], ascending=False)\n",
    "                col = ('Average', 'chatfmt') if chat_fmt == 'both' else 'Average'\n",
    "            #     col = 'AlpacaFarm/WR'\n",
    "            #     col = 'MMLU/0-shot'|\n",
    "            #     col = 'GSM/CoT'\n",
    "            #     col = 'BBH/Direct'\n",
    "            #     col = 'TydiQA/GP'\n",
    "                dfc = dfc.sort_values(by=[col], ascending=False)\n",
    "                dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture', 'max_train_samples', 'dataset'], \n",
    "                               axis=1, level=0 if chat_fmt=='both' else None)\n",
    "                dfc = dfc.reset_index(drop=True)\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .applymap(lambda x: f'max-width: 60ch;', subset=['run_name'])\n",
    "                        .set_table_styles([{'selector': 'td', 'props': [('white-space', 'pre-wrap'), ('word-wrap', 'break-word')]}])\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .applymap(lambda x: 'text-decoration: underline;' \\\n",
    "                                  if x in dfc[list(set(dfc.columns) & set([(x, '') for x in cols]))+[col] if chat_fmt=='both' else cols+[col]].values.flatten() and chat_fmt=='both' else '')\n",
    "                        .format(precision=1))\n",
    "\n",
    "# llama-7b_tulu_v1_mix(paper)\n",
    "# MMLU/0-shot, MMLU/5-shot, GSM/Direct, GSM/CoT, BBH/Direct, BBH/CoT, TydiQA/GP, TydiQA/CB, CodexEval/Pass@1, AlpacaEval(vs.Davinci-003)\n",
    "# 44.8       , 47.1       , 7.0       , 25.0   , 38.5      , 38.5   , 43.5,    , 8.0      , 18.6,           , 48.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "deeba0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_name',\n",
       " 'nonchat',\n",
       " 'sort_by',\n",
       " 'total_train_samples',\n",
       " 'model_name_or_path',\n",
       " 'subsample_mixture',\n",
       " 'max_train_samples',\n",
       " 'MMLU/0-shot',\n",
       " 'MMLU/5-shot',\n",
       " 'GSM/Direct',\n",
       " 'GSM/CoT',\n",
       " 'BBH/Direct',\n",
       " 'BBH/CoT',\n",
       " 'TydiQA/CB',\n",
       " 'TydiQA/GP',\n",
       " 'Codex-Eval/Pass@1',\n",
       " 'AlpacaFarm(chatgpt)/WR*',\n",
       " 'AlpacaFarm(chatgpt)/Len',\n",
       " 'MTBench(gpt:4:1106:preview)/Turn-1',\n",
       " 'MTBench(gpt:4:1106:preview)/Turn-2',\n",
       " 'MTBench(gpt:4:1106:preview)/Rating',\n",
       " 'Average',\n",
       " 'ranking']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rosemary import parse_kv_from_string\n",
    "\n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', ]\n",
    "# non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', ]\n",
    "\n",
    "def compute_nonchateval_average_performance(row):\n",
    "    L = [row[k] for k in non_chateval_task_names if k in row]\n",
    "    return np.average(L)\n",
    "\n",
    "def parse_prune_subset_size(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'(?<=pace=)([^_]+)', run_name)\n",
    "    if match:\n",
    "        pace = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(pace)\n",
    "        subset_size = int(kvs['size'] / kvs['ep'])\n",
    "        return subset_size\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_sort_by_from_run_name(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'score=([^_]+)', run_name)\n",
    "    if match:\n",
    "        sort_by = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(sort_by)\n",
    "    else:\n",
    "        kvs = {}\n",
    "    return kvs\n",
    "\n",
    "\n",
    "def parse_sort_by_type(row):\n",
    "    d = row['sort_by']\n",
    "    if not d:\n",
    "        return None\n",
    "    if d[0] == 'dppmap':\n",
    "        if d['k']=='vmf' and d['kmd']=='mpnet': #and (d['gamma']==1 or d['gamma'] == 'auto1000'):\n",
    "            return 'vmf+text'\n",
    "        elif d['k']=='rbf' and d['kemb']=='text+embedding' and d['kmd'] == 'llama7br512p4096':\n",
    "            return f\"rbf+text_gamma={d['gamma']}\"\n",
    "        elif d['k']=='vmf' and d['kemb']=='grad+rp+loraB' and d['kmd'] == 'llama7br512p4096':\n",
    "            return f\"vmf+grad_gamma={d['gamma']}\"\n",
    "        else:\n",
    "            return None\n",
    "    elif d[0] == 'random':\n",
    "        return 'random'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "dfc.insert(1, 'sort_by' if chat_fmt!='both' else ('sort_by', ''), dfc.apply(parse_sort_by_from_run_name, axis=1))\n",
    "dfc.insert(1, 'sort_by_type' if chat_fmt!='both' else ('sort_by_type', ''), dfc.apply(parse_sort_by_type, axis=1))\n",
    "dfc.insert(1, 'subset_size' if chat_fmt!='both' else ('subset_size', ''), dfc.apply(parse_prune_subset_size, axis=1))\n",
    "dfc.insert(1, 'nonchat' if chat_fmt!='both' else ('nonchat', ''), dfc.apply(compute_nonchateval_average_performance, axis=1))\n",
    "\n",
    "\n",
    "dfc = dfc[dfc['sort_by_type'].notnull()]\n",
    "startswithstrs = ('rbf+text', 'random')\n",
    "startswithstrs = (\n",
    "    'random', \n",
    "    'rbf+text_gamma=0.001', \n",
    "    'vmf+grad_gamma=1',\n",
    "#     'rbf+text_gamma=auto1000', \n",
    "    'vmf+grad_gamma=auto1000',\n",
    ")\n",
    "dfc = dfc[dfc.apply(lambda x: x['sort_by_type'].startswith(startswithstrs)\n",
    "                   , axis=1)]\n",
    "dfc['subset_size'] = dfc['subset_size'].apply(lambda x: int(x) if x else x)\n",
    "# dfc = dfc[dfc['subset_size']>1_000]\n",
    "\n",
    "\n",
    "D = dfc.set_index(['sort_by_type', 'dataset', 'subset_size']).to_dict()\n",
    "from dataclasses import dataclass\n",
    "@dataclass(unsafe_hash=True)\n",
    "class DKey:\n",
    "    sort_by_type: str\n",
    "    dataset: str\n",
    "    subset_size: int\n",
    "def convert_key_to_dataclass(d):\n",
    "    return {DKey(*k): v for k, v in d.items()}\n",
    "D = {k: convert_key_to_dataclass(v) for k, v in D.items()}\n",
    "\n",
    "list(D.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "662539cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1700x1200 with 42 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "yaxis_type = 'abs'\n",
    "# yaxis_type = 'delta_random'\n",
    "assert(yaxis_type in ['delta_random', 'abs'])\n",
    "datasets = ['flan_v2', 'dolly', 'stanford_alpaca', 'oasst1', 'ultrachat200kv2', 'wizardlmv2', 'sharegptv2']\n",
    "task_names = ['nonchat', 'MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR*',]\n",
    "\n",
    "datasets = ['dolly', 'sharegpt50k']\n",
    "datasets = list(np.unique(dfc['dataset']))\n",
    "task_names = []\n",
    "task_names += ['nonchat']\n",
    "# task_names += ['MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1',]\n",
    "task_names += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "# task_names += [f'MTBench({mtbench_judge})/Rating']\n",
    "task_names += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "\n",
    "\n",
    "\n",
    "w = 2\n",
    "ncols = len(datasets)\n",
    "nrows = len(task_names)\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(w*ncols+3,w*nrows), sharey='row', sharex=True)\n",
    "\n",
    "xs_possible = []\n",
    "\n",
    "for axi, task_name in enumerate(task_names):\n",
    "    d = D[task_name]\n",
    "    for axj, dataset in enumerate(datasets):\n",
    "        ax = axs.reshape(nrows, ncols)[axi, axj]\n",
    "        sort_by_types = sorted(set(x.sort_by_type for x in d.keys()))\n",
    "\n",
    "        for i, sort_by_type in enumerate(sort_by_types):\n",
    "            xs = sorted([x.subset_size for x in d.keys()\n",
    "                         if x.dataset == dataset and x.sort_by_type==sort_by_type])\n",
    "            xs_possible += list(set(xs) - set(xs_possible))\n",
    "            ys = [d[DKey(sort_by_type, dataset, x)] for x in xs]\n",
    "            if yaxis_type == 'delta_random':\n",
    "                if not all(DKey('random', dataset, x) in d for x in xs): continue\n",
    "                ys = [y-d[DKey('random', dataset, x)] for x, y in zip(xs, ys)] \n",
    "            if 'random' in sort_by_type:\n",
    "                marker_style = 'o-'\n",
    "            else:\n",
    "                marker_style = 'o-'\n",
    "            ax.plot(xs, ys, marker_style, label=sort_by_type)\n",
    "        \n",
    "#         ax.set_yscale('log')\n",
    "            \n",
    "for axi, task_name in enumerate(task_names):\n",
    "    task_name_shortened = task_name.replace(f'({mtbench_judge})', '').replace(f'({alpacafarm_judge})', '')\n",
    "    axs.reshape(nrows, ncols)[axi, 0].set_ylabel('△ '+task_name_shortened if yaxis_type.startswith('delta') else task_name_shortened, fontsize=13)\n",
    "    axs.reshape(nrows, ncols)[axi, -1].legend(loc='center left', bbox_to_anchor=(1.1, 0.5))\n",
    "for axj, dataset in enumerate(datasets):\n",
    "    axs.reshape(nrows, ncols)[0, axj].set_title(dataset, fontsize=15)\n",
    "    axs.reshape(nrows, ncols)[0, axj].set_xticks(xs_possible, xs_possible)\n",
    "\n",
    "space = 0.05\n",
    "fig.subplots_adjust(wspace=space, hspace=space)  # Adjust the value as needed\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5fdb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e2f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39874bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
