{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3da1794b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'x86_64', 'cluster': 'ccc', 'queue': 'alt_7d'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from rosemary import jpt_setup; jpt_setup()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "import re\n",
    "from llm.submit import (\n",
    "    multiline_to_singleline,\n",
    "    submit_job_ccc,\n",
    "    submit_job_aimos,\n",
    "    submit_job,\n",
    "        get_run_statistics)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shlex\n",
    "import datetime\n",
    "import itertools\n",
    "import glob\n",
    "\n",
    "import base64\n",
    "string_to_alphanumeric = lambda s: base64.urlsafe_b64encode(s.encode('utf-8')).decode('utf-8')\n",
    "alphanumeric_to_string = lambda a: base64.urlsafe_b64decode(a).decode('utf-8')\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm, shell_scripts_template_lsf, get_host_info, move_lsf_job_summary_to_save_dir\n",
    "from note_pruning_analysis import open_instruct_dir\n",
    "import getpass\n",
    "\n",
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "info = get_host_info()\n",
    "info.update({'queue': queue})\n",
    "arch, cluster = info['arch'], info['cluster']\n",
    "print(info)\n",
    "\n",
    "os.environ['TORCHELASTIC_ERROR_FILE'] = os.path.join(os.getcwd(), 'torchelastic_error_file') \n",
    "\n",
    "## jobs submitted in notebook inherits env variables.\n",
    "cache_dir = os.path.normpath(os.path.join(os.getcwd(), '../../../../mitibm2023/cache')) \\\n",
    "    if arch == 'ppc64le' else '/dccstor/data-pruning/cache'\n",
    "os.environ['WANDB_DIR'] = cache_dir\n",
    "os.makedirs(os.environ['WANDB_DIR'], exist_ok=True, mode=0o777)\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "os.environ['WANDB_PROJECT'] = 'mitibm'\n",
    "##\n",
    "##\n",
    "\n",
    "shell_scripts_template = shell_scripts_template_slurm \\\n",
    "    if arch == 'ppc64le' else shell_scripts_template_lsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c421d1",
   "metadata": {},
   "source": [
    "# DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c09b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "{\n",
      "    \"scoring_fn\": \"dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/oi2/llama-7b_sharegptv2_ep=2 using 6 GPUs, 1 batch size per GPU, 1 gradient accumulation steps, 30 effective batch size.\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp7pssto1b', 'job_id': 1354503}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2p8zx1bt', 'job_id': 1354504}]\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"dpo2_ultrafeedback:llama-7b+sharegptv2ep2\",\n",
      "    \"nodes\": 5,\n",
      "    \"num_cpus\": 144,\n",
      "    \"cpu_mem\": 650,\n",
      "    \"num_gpus\": 6,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'sbatch --job-name=dpo2_ultrafeedback:llama-7b+sharegptv2ep2 --partition=el8 --nodes=5 --ntasks-per-node=1 --cpus-per-task=144 --mem=650GB --gres=gpu:6 --output=/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/%J.out --time=6:00:00 /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/tmp2_mpillk', 'job_id': 1354505}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "\n",
    "from llm.submit import shell_scripts_template_slurm\n",
    "debug = False\n",
    "if debug:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'INFO'\n",
    "    os.environ['NCCL_DEBUG'] = 'INFO'\n",
    "else:\n",
    "    os.environ['TORCH_CPP_LOG_LEVEL'] = 'WARNING'\n",
    "    os.environ['NCCL_DEBUG'] = ''\n",
    "num_cpus = 144 if arch == 'ppc64le' else 32\n",
    "cpu_mem =  650 if arch == 'ppc64le' else 64\n",
    "\n",
    "preprocessing_num_workers = 32\n",
    "report_to = 'wandb'\n",
    "mixed_precision = 'bf16' if arch == 'x86_64' else 'fp16'\n",
    "torch_dtype = 'bfloat16' if arch=='x86_64' else 'float32'\n",
    "gradient_checkpointing = True\n",
    "use_fast_tokenizer = True\n",
    "hf_models_dir = 'results/baselines/'\n",
    "resume_from_checkpoint = True # resume from latest checkpoint if exists, otherwise train from scratch\n",
    "num_train_epochs = 2\n",
    "checkpointing_steps = 300 # (50_000 / 32) * 2 / 6 ~= 500 (data size of 50k, bsz=32, ep=2, total save 6 times at most)\n",
    "max_train_steps = None\n",
    "subsample_inds_file_list = [None]\n",
    "dataloader_sampler = 'RandomSampler'\n",
    "overwrite_cache = True\n",
    "\n",
    "\n",
    "# #####\n",
    "# job_name = 'dpo1'\n",
    "\n",
    "# # model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'EleutherAI/pythia-410m-deduped'; max_seq_length = 2048; abbr_model_name = 'pythia-410m'\n",
    "# # model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "\n",
    "# train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "model_name_or_path = 'results/oi2/llama-7b_sharegptv2_ep=2'; max_seq_length = 2048; abbr_model_name = 'llama-7b+sharegptv2ep2'\n",
    "train_file = 'data/processed/ultrafeedback/ultrafeedback_data.jsonl'; dataset = 'ultrafeedback'\n",
    "\n",
    "\n",
    "# M = 60_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 20_000\n",
    "# M = 50_000; pacing_fn_list = [f'prune_size={M}_ep=5']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "    (10_000, 10),\n",
    "#     (30_000, 3),\n",
    "]]\n",
    "\n",
    "gen_output_md = 'llama7br512p4096'\n",
    "# gen_output_md = 'llama7b+sharegptv2ep2+r512p4096'\n",
    "# gen_output_model_name = 'all-mpnet-base-v2'\n",
    "\n",
    "scoring_fn_list = []\n",
    "scoring_fn_list += ['random_s=0']\n",
    "# scoring_fn_list += ['random_s=1']\n",
    "scoring_fn_list += [ \n",
    "    f'dppmap_k=vmf_gamma=1_kmd={gen_output_md}_kemb=grad+rp+loraB',\n",
    "    f'dppmap_k=rbf_gamma=1e-3_kmd={gen_output_md}_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1_kmd=mpnet_kemb=text+embedding',\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'dpo2_{dataset}:{abbr_model_name}'\n",
    "    \n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "# nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 12\n",
    "# nodes = 2; num_gpus = 1; gpu_type = 'v100'; job_duration = 6; cpu_mem = 100; num_cpus = 32; max_train_steps = 5; checkpointing_steps = 2; report_to = 'tensorboard'\n",
    "    \n",
    "#####\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs = 1 # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "use_deepspeed = True\n",
    "deepspeed_config_file = 'ds_configs/stage3_no_offloading_accelerate.conf'\n",
    "\n",
    "per_device_train_batch_size = 1; total_batch_size = 32\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"{effective_batch_size} effective batch size.\")\n",
    "\n",
    "# reference: https://gist.github.com/pacman100/1cb1f17b2f1b3139a63b764263e70b25\n",
    "launcher = f\"\"\"accelerate launch \\\n",
    "    --mixed_precision {mixed_precision} \\\n",
    "    --num_machines {nodes} \\\n",
    "    --num_processes {num_gpus*nodes} \\\n",
    "    {'--use_deepspeed' if use_deepspeed else ''} \\\n",
    "    {'--deepspeed_config_file '+deepspeed_config_file if use_deepspeed else ''} \\\n",
    "    {'--main_process_ip $master_addr' if use_deepspeed else ''} \\\n",
    "    {'--main_process_port $master_port' if use_deepspeed else ''} \\\n",
    "    {'--machine_rank $SLURM_PROCID' if use_deepspeed else ''} \\\n",
    "    {'--rdzv_backend c10d' if use_deepspeed and nodes>1 else ''} \\\n",
    "    {'--deepspeed_multinode_launcher standard' if use_deepspeed and nodes>1 else ''} \\\n",
    "\"\"\"\n",
    "\n",
    "cmds = []\n",
    "\n",
    "\n",
    "options_list = itertools.product(\n",
    "    subsample_inds_file_list,\n",
    ")\n",
    "\n",
    "output_dirname_list = []\n",
    "for (subsample_inds_file,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{dataset}\"\n",
    "    if any(job_name == y for y in ['dpo1']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "\n",
    "    if subsample_inds_file:\n",
    "        assert(num_train_epochs==1)\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                s = f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "\n",
    "    if subsample_inds_file is not None:\n",
    "        assert(dataloader_sampler=='SequentialSampler')\n",
    "        assert(num_train_epochs==1)\n",
    "    else:\n",
    "        assert(dataloader_sampler=='RandomSampler')\n",
    "\n",
    "    output_dir = os.path.join('results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join('results', job_name), exist_ok=True)\n",
    "    wandb_run_name = output_dir.replace('results/', '')\n",
    "\n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {f'cd .. && CUDA_VISIBLE_DEVICES={os.environ[\"CUDA_VISIBLE_DEVICES\"]} ' if test_run else ''}{launcher}\n",
    "        open_instruct/dpo_tune.py \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --tokenizer_name {model_name_or_path} \\\n",
    "        {'--use_slow_tokenizer' if not  use_fast_tokenizer else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        --train_file {train_file} \\\n",
    "        --max_seq_length {max_seq_length} \\\n",
    "        {'--subsample_inds_file '+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        --dataloader_sampler {dataloader_sampler} \\\n",
    "        --preprocessing_num_workers {preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size {per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps {gradient_accumulation_steps} \\\n",
    "        --learning_rate 5e-7 \\\n",
    "        --lr_scheduler_type linear \\\n",
    "        --warmup_ratio 0.1 \\\n",
    "        --weight_decay 0. \\\n",
    "        --num_train_epochs {num_train_epochs} \\\n",
    "        --with_tracking \\\n",
    "        {'--report_to \"'+str(report_to)+'\"' if report_to else ''} \\\n",
    "        --checkpointing_steps {checkpointing_steps} \\\n",
    "        {'--max_train_steps '+str(max_train_steps) if max_train_steps else ''} \\\n",
    "        {'--resume_from_checkpoint' if resume_from_checkpoint else ''} \\\n",
    "        {'--low_cpu_mem_usage' if not use_deepspeed else ''} \\\n",
    "        {'--overwrite_cache' if overwrite_cache else ''} \\\n",
    "        --logging_steps 1 \\\n",
    "        --output_dir {output_dir}\n",
    "    \"\"\"\n",
    "    # if test_run:\n",
    "    #     print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    if test_run:\n",
    "        print(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64': # ccc\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        job_duration=job_duration,\n",
    "        queue=queue,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda1f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prune: {1k@10, 10k@3}, datasets={dolly, stanford_alpaca}, scoring={random, dppmapx2}\n",
    "# need to gen curriculum for 50k sft datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b79b9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_dpo.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce604bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=5\n",
      "+ cd ..\n",
      "+ CUDA_VISIBLE_DEVICES=2,5\n",
      "+ accelerate launch --mixed_precision fp16 --num_machines 1 --num_processes 2 --use_deepspeed --deepspeed_config_file ds_configs/stage3_no_offloading_accelerate.conf open_instruct/dpo_tune.py --model_name_or_path results/baselines/huggyllama/llama-7b --tokenizer_name results/baselines/huggyllama/llama-7b --gradient_checkpointing --train_file data/processed/ultrafeedback/ultrafeedback_data.jsonl --max_seq_length 2048 --preprocessing_num_workers 32 --per_device_train_batch_size 1 --gradient_accumulation_steps 16 --learning_rate 5e-7 --lr_scheduler_type linear --warmup_ratio 0.1 --weight_decay 0. --num_train_epochs 2 --with_tracking --report_to tensorboard --checkpointing_steps 500 --logging_steps 1 --output_dir results/dpo1/jpt_llama-7b_ultrafeedback\n",
      "[2024-01-08 20:41:08,547] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "[2024-01-08 20:41:17,396] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-01-08 20:41:17,400] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "[2024-01-08 20:41:23,297] [INFO] [comm.py:662:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "[2024-01-08 20:41:23,611] [INFO] [comm.py:631:init_distributed] cdb=None\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 1\n",
      "Local process index: 1\n",
      "Device: cuda:1\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "01/08/2024 20:41:23 - INFO - __main__ - Distributed environment: DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'zero_optimization': {'stage': 3, 'overlap_comm': True, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False, 'fp16': {'enabled': True, 'auto_cast': True}}\n",
      "\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 251.17it/s]\n",
      "01/08/2024 20:41:25 - WARNING - datasets.builder - Found cached dataset json (/gpfs/u/scratch/PTFM/PTFMqngp/huggingface_cache/datasets/json/default-201ebfceee303348/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 252.78it/s]\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:26,493] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 6.74B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:11<00:00,  5.74s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:16<00:00,  8.11s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "[2024-01-08 20:41:43,556] [INFO] [partition_parameters.py:326:__exit__] finished initializing model with 13.48B parameters\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.20s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.60s/it]\n",
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "01/08/2024 20:42:20 - INFO - accelerate.accelerator - Updating DeepSpeed's gradient accumulation steps to 16 from 1.\n",
      "[2024-01-08 20:42:20,382] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.1+23a11a39, git-hash=23a11a39, git-branch=master\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 1\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "01/08/2024 20:42:20 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.\n",
      "[2024-01-08 20:42:20,751] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2024-01-08 20:42:20,754] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n",
      "[2024-01-08 20:42:20,779] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
      "[2024-01-08 20:42:20,779] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\n",
      "[2024-01-08 20:42:20,891] [INFO] [utils.py:786:see_memory_usage] Stage 3 initialize beginning\n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 14.16 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,892] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.9 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:118:__init__] Reduce bucket size 16777216\n",
      "[2024-01-08 20:42:20,896] [INFO] [stage3.py:119:__init__] Prefetch bucket size 15099494\n",
      "[2024-01-08 20:42:20,995] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:787:see_memory_usage] MA 13.64 GB         Max_MA 13.64 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:20,996] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n",
      "[2024-01-08 20:42:21,139] [INFO] [utils.py:786:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.76 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,141] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:21,240] [INFO] [utils.py:786:see_memory_usage] Before creating fp16 partitions\n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:787:see_memory_usage] MA 13.4 GB         Max_MA 13.4 GB         CA 16.92 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:21,241] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 102.88 GB, percent = 14.8%\n",
      "[2024-01-08 20:42:23,090] [INFO] [utils.py:786:see_memory_usage] After creating fp16 partitions: 4\n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.4 GB         CA 14.6 GB         Max_CA 17 GB \n",
      "[2024-01-08 20:42:23,091] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.99 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,190] [INFO] [utils.py:786:see_memory_usage] Before creating fp32 partitions\n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:787:see_memory_usage] MA 13.39 GB         Max_MA 13.39 GB         CA 14.6 GB         Max_CA 15 GB \n",
      "[2024-01-08 20:42:23,191] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 91.81 GB, percent = 13.2%\n",
      "[2024-01-08 20:42:23,742] [INFO] [utils.py:786:see_memory_usage] After creating fp32 partitions\n",
      "[2024-01-08 20:42:23,743] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 26.61 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,744] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 116.15 GB, percent = 16.7%\n",
      "[2024-01-08 20:42:23,836] [INFO] [utils.py:786:see_memory_usage] Before initializing optimizer states\n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:787:see_memory_usage] MA 25.94 GB         Max_MA 25.94 GB         CA 29.55 GB         Max_CA 30 GB \n",
      "[2024-01-08 20:42:23,838] [INFO] [utils.py:794:see_memory_usage] CPU Virtual Memory:  used = 117.28 GB, percent = 16.8%\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 1; 31.75 GiB total capacity; 25.93 GiB already allocated; 3.34 GiB free; 27.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 806, in <module>\n",
      "    main()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/open_instruct/dpo_tune.py\", line 646, in main\n",
      "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1198, in prepare\n",
      "    result = self._prepare_deepspeed(*args)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1537, in _prepare_deepspeed\n",
      "    engine, optimizer, _, lr_scheduler = deepspeed.initialize(**kwargs)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/__init__.py\", line 171, in initialize\n",
      "    engine = DeepSpeedEngine(args=args,\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 310, in __init__\n",
      "    self._configure_optimizer(optimizer, model_parameters)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _configure_optimizer\n",
      "    self.optimizer = self._configure_zero_optimizer(basic_optimizer)\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1503, in _configure_zero_optimizer\n",
      "    optimizer = DeepSpeedZeroOptimizer_Stage3(\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 324, in __init__\n",
      "    self._setup_for_real_optimizer()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 421, in _setup_for_real_optimizer\n",
      "    self.initialize_optimizer_states()\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py\", line 892, in initialize_optimizer_states\n",
      "    gradient_buffer = torch.zeros(int(largest_numel), dtype=gradient_dtype, device=self.device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.74 GiB (GPU 0; 31.75 GiB total capacity; 25.94 GiB already allocated; 3.21 GiB free; 27.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 409110) of binary: /gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/python3.10\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 964, in launch_command\r\n",
      "    deepspeed_launcher(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 687, in deepspeed_launcher\r\n",
      "    distrib_run.run(args)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\r\n",
      "    elastic_launch(\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\r\n",
      "    raise ChildFailedError(\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "open_instruct/dpo_tune.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 409111)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2024-01-08_20:42:28\r\n",
      "  host      : dcs068.ccni.rpi.edu\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 409110)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_dpo.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c6c8b",
   "metadata": {},
   "source": [
    "# Finetuning with openinstruct/finetune_trainer.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "19aebd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`\n",
      "{\n",
      "    \"scoring_fn\": \"random_s=0\",\n",
      "    \"gen_output_md\": \"llama7br512p4096\",\n",
      "    \"gen_output_model_name\": \"llama-7b+lora:r=512:a=11585+proj=4096\"\n",
      "}\n",
      "Training results/baselines/huggyllama/llama-7b using 8 GPUs, 1 batch size per GPU, 16 gradient accumulation steps, Effective batch size 128\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"oi5_sharegpt50k:llama-7b\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 128,\n",
      "    \"cpu_mem\": 768,\n",
      "    \"num_gpus\": 8,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_7d\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "[{'args': 'jbsub -queue alt_7d -name oi5_sharegpt50k:llama-7b -mem 768g -cores 1x128+8 -require a100_80gb -out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/%J.out bash -c \\'echo \"Running on $LSB_DJOB_HOSTFILE\"; echo \"======\"; master_addr=$(head -n 1 \"$LSB_DJOB_HOSTFILE\"); master_port=10002; RDZV_ENDPOINT=$master_addr:$master_port; source /dccstor/data-pruning/.profile; conda activate open-instruct; cd /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct; set -e; set -x; echo \"======\"; torchrun --nnodes 1 --nproc_per_node=8 --rdzv_backend=c10d --master_port=0 open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/sharegpt/sharegpt50k_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=128 --per_device_train_batch_size=1 --gradient_accumulation_steps=16 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=1000000 --report_to tensorboard wandb --run_name ccc/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=1000000 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --fsdp=\"full_shard auto_wrap\" --fsdp_transformer_layer_cls_to_wrap=\"LlamaDecoderLayer\" --torch_dtype=float32 --save_model_torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/sharegpt50k/random_s=0/inds_prune_size=30000_ep=3.pkl --dataloader_sampler SequentialSampler --use_flash_attn False --low_cpu_mem_usage --overwrite_cache --output_dir=\"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3\"; [ ! -f \"/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out\" ] && mv /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/$LSB_JOBID*.out /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_sharegpt50k:llama-7b/llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3 ||:; # some job may still be in RUN state due to daemon compiling binaries for the job not exited yet.; # https://www.ibm.com/support/pages/job-kept-run-status-after-job-finished; lsf_job_output=$(bjobs -l $LSB_JOBID 2>&1); if echo \"$lsf_job_output\" | grep -q \"Done successfully.\"; then;   echo \"Job $LSB_JOBID is finished\"; else;   echo \"Job $LSB_JOBID not finished\";   echo \"Output of bjobs -l:\";   echo \"$lsf_job_output\"; fi\\'', 'job_id': 1388918}]\n"
     ]
    }
   ],
   "source": [
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_7d'\n",
    "add_hardwarespec_to_dirname = False\n",
    "save_strategy = 'steps'\n",
    "save_steps = 200 if getpass.getuser() in ('PTFMqngp', 'wpq') else 1_000_000\n",
    "save_total_limit = 1\n",
    "preprocessing_num_workers = 32\n",
    "evaluation_strategy = 'no' # set do_eval=False\n",
    "eval_steps = save_steps\n",
    "report_to = 'tensorboard wandb'\n",
    "suffix = None\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0.03\n",
    "dataloader_sampler = None\n",
    "hf_models_dir = 'results/baselines/'\n",
    "subsample_inds_file_list = [None]\n",
    "max_train_samples_list = [None]\n",
    "num_train_epochs_list = [1]\n",
    "scoring_fn_and_pacing_fn = None\n",
    "\n",
    "\n",
    "# ########### sft baselines\n",
    "\n",
    "\n",
    "# job_name = 'oi2'; num_train_epochs_list = [2] \n",
    "# # model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048\n",
    "# model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048\n",
    "\n",
    "# # train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca'; \n",
    "# # train_file = 'data/processed/oasst1/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# # train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2'; max_train_samples_list=[100_000]\n",
    "\n",
    "# ## 50k sft datasets\n",
    "# # train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# # train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# # train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# # train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# # train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "# # train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "# # train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "\n",
    "# # train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; max_train_samples_list=[100_000]\n",
    "# # train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2'; max_train_samples_list=[100_000]\n",
    "# ###########\n",
    "\n",
    "\n",
    "############ pruning runs\n",
    "\n",
    "# model_name_or_path = hf_models_dir+'mistralai/Mistral-7B-v0.1'; abbr_model_name = 'mistral-7b'; max_seq_length = 2048; gen_output_md = 'mistral7br512p4096'\n",
    "model_name_or_path = hf_models_dir+'huggyllama/llama-7b'; abbr_model_name = 'llama-7b'; max_seq_length = 2048; gen_output_md = 'llama7br512p4096'\n",
    "\n",
    "\n",
    "# # 50k sft datasets\n",
    "# dataset = 'flan_v250k'; train_file = 'data/processed/flan_v2/flan_v250k_data.jsonl'; abbr_train_file = 'flan_v250k';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca50k'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca50k_data.jsonl'; abbr_train_file = 'stanford_alpaca50k'; \n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# dataset = 'wizardlm50k'; train_file = 'data/processed/wizardlm/wizardlm50k_data.jsonl'; abbr_train_file = 'wizardlm50k'\n",
    "dataset = 'sharegpt50k'; train_file = 'data/processed/sharegpt/sharegpt50k_data.jsonl'; abbr_train_file = 'sharegpt50k'\n",
    "# dataset = 'ultrachat50k'; train_file = 'data/processed/ultrachat/ultrachat50k_train_data.jsonl'; abbr_train_file = 'ultrachat50k'\n",
    "\n",
    "\n",
    "# dataset = 'flan_v2'; train_file = 'data/processed/flan_v2/flan_v2_data.jsonl'; abbr_train_file = 'flan_v2';\n",
    "# dataset = 'dolly'; train_file = 'data/processed/dolly/dolly_data.jsonl'; abbr_train_file = 'dolly';\n",
    "# dataset = 'stanford_alpaca'; train_file = 'data/processed/stanford_alpaca/stanford_alpaca_data.jsonl'; abbr_train_file = 'stanford_alpaca';\n",
    "# dataset = 'oasst2'; train_file = 'data/processed/oasst/oasst2_data.jsonl'; abbr_train_file = 'oasst2';\n",
    "# dataset = 'wizardlmv2'; train_file = 'data/processed/wizardlm/wizardlmv2_data.jsonl'; abbr_train_file = 'wizardlmv2';\n",
    "# dataset = 'sharegptv2'; train_file = 'data/processed/sharegpt/sharegptv2_data.jsonl'; abbr_train_file = 'sharegptv2';\n",
    "# dataset = 'ultrachat200kv2'; train_file = 'data/processed/ultrachat/ultrachat200kv2_train_data.jsonl'; abbr_train_file = 'ultrachat200kv2';\n",
    "\n",
    "\n",
    "# dataset = 'oasst1'; train_file = 'data/processed/oasst/oasst1_data.jsonl'; abbr_train_file = 'oasst1';\n",
    "# dataset = 'open_orca_slim'; train_file = 'data/processed/open_orca/open_orca_slim_data.jsonl'; abbr_train_file = 'openorcaslim'; \n",
    "# dataset = 'tulu_v2'; train_file = 'data/processed/tulu_v2/tulu_v2_data.jsonl'; abbr_train_file = 'tulu_v2';\n",
    "        \n",
    "# M = 80_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 40_000\n",
    "# M = 40_000; pacing_fn_list = [f'prune_size={M}_ep=2']; subset_size = 20_000\n",
    "# M = 30_000; pacing_fn_list = [f'prune_size={M}_ep=3']; subset_size = 10_000\n",
    "# M = 20_000; pacing_fn_list = [f'prune_size={M}_ep=4']; subset_size = 5_000\n",
    "# M = 10_000; pacing_fn_list = [f'prune_size={M}_ep=10']; subset_size = 1_000\n",
    "pacing_fn_list = [\n",
    "    f'prune_size={M}_ep={ep}' for M, ep in [\n",
    "#         (10_000, 10),\n",
    "        (30_000, 3),\n",
    "#         (40_000, 2),\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "scoring_fn_list = [\n",
    "    'random_s=0',\n",
    "#     'random_s=1',\n",
    "#     'log_prob_neg', 'el2n_agg=mean', 'grad_loraB_l2n',\n",
    "#     'ifd_neg', 'log_pmi_neg',\n",
    "#     'numtoks_input_neg', 'numtoks_output_neg', 'numtoks_total_neg',\n",
    "#     f'dppmap_k=vmf_gamma=1_kmd=mpnet', #_kemb=text+embedding',\n",
    "#     f'dppmap_k=rbf_gamma=1e-3_kmd=llama7br512p4096_kemb=text+embedding',\n",
    "#     f'dppmap_k=vmf_gamma=1_kmd=llama7br512p4096_kemb=grad+rp+loraB',\n",
    "]\n",
    "\n",
    "scoring_fn_list += [ # vary kernel embedding model \n",
    "#     f'dppmap_k=vmf_gamma=auto{subset_size}_kmd={kmd}_kemb=grad+rp+loraB'\n",
    "#     for kmd in ['llama7br256p4096', 'llama7br512p4096', 'pythia1br512p4096']\n",
    "]\n",
    "scoring_fn_and_pacing_fn = list(itertools.product(scoring_fn_list, pacing_fn_list))\n",
    "\n",
    "\n",
    "job_name = f'oi5_{dataset}:{abbr_model_name}'\n",
    "############ \n",
    "\n",
    "    \n",
    "# add_hardwarespec_to_dirname = True\n",
    "# job_name += '_debug' # wpq debug\n",
    "# max_train_samples_list=[128*2]\n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "debug_mode = test_run\n",
    "\n",
    "if arch == 'x86_64':\n",
    "    nodes = 1; num_gpus = 8; gpu_type = 'a100_80gb'; job_duration = 6\n",
    "    num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus); preprocessing_num_workers = 128 # tok takes quite a bit.\n",
    "    per_device_train_batch_size = 1\n",
    "    gradient_checkpointing = False\n",
    "    mixed_precision = 'bf16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = True \n",
    "    save_model_torch_dtype = 'bfloat16' # typically save fp32 weights, but for disk space sake, convert to bf16.\n",
    "else:\n",
    "    nodes = 5; num_gpus = 6; gpu_type = 'v100'; job_duration = 6\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    per_device_train_batch_size = 2\n",
    "    gradient_checkpointing = True\n",
    "    mixed_precision = 'fp16'; torch_dtype = 'float32'; use_flash_attn = False; use_tf32 = False\n",
    "    save_model_torch_dtype = None\n",
    "\n",
    "\n",
    "\n",
    "if scoring_fn_and_pacing_fn is not None: # pruning runs. \n",
    "    print('Set up data pruning runs. epochs=1, sampler=SequentialSampler, and `subsampe_inds_file`')\n",
    "    num_train_epochs_list = [1] # offload handling of epochs to `generate_curriculum`\n",
    "    dataloader_sampler = 'SequentialSampler'\n",
    "    subsample_inds_file_list = []\n",
    "    for scoring_fn, pacing_fn in scoring_fn_and_pacing_fn:\n",
    "        from note_pruning import get_final_model_name\n",
    "        from note_pruning_analysis import get_full_model_name, curriculum_dir\n",
    "        gen_output_model_name = get_final_model_name(get_full_model_name(gen_output_md), scoring_fn)\n",
    "        print(json.dumps({'scoring_fn': scoring_fn, 'gen_output_md': gen_output_md, 'gen_output_model_name': gen_output_model_name}, indent=4))\n",
    "        p = os.path.join(curriculum_dir, gen_output_model_name, dataset, scoring_fn, 'inds_'+pacing_fn+'.pkl')\n",
    "        if not os.path.isfile(p):\n",
    "            raise ValueError(f'path={p} does not exists for {scoring_fn}')\n",
    "        subsample_inds_file_list.append(p)\n",
    "\n",
    "overwrite_output_dir = True if test_run else False # always continue from ckpt if run from cluster.\n",
    "\n",
    "total_batch_size = 128\n",
    "gradient_accumulation_steps = round(total_batch_size/(num_gpus*nodes)/per_device_train_batch_size)\n",
    "effective_batch_size = per_device_train_batch_size*nodes*num_gpus*gradient_accumulation_steps\n",
    "\n",
    "optimizer = 'adamw_hf'\n",
    "\n",
    "deepspeed = ''; fsdp = False if num_gpus == 1 else \"full_shard auto_wrap\" \n",
    "if 'gpt2' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPT2Block'\n",
    "elif 'llama' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'LlamaDecoderLayer'\n",
    "elif 'mpt' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MPTBlock'\n",
    "elif 'pythia' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'GPTNeoXLayer'        \n",
    "elif 'mistral' in abbr_model_name: fsdp_transformer_layer_cls_to_wrap = 'MistralDecoderLayer'\n",
    "else: raise ValueError('Not sure how to set `fsdp_transformer_layer_cls_to_wrap`')\n",
    "    \n",
    "# deepspeed = './ds_configs/ds_zero3_cpu_offload.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/ds_zero3.json'; fsdp = False\n",
    "# deepspeed = './ds_configs/stage3_no_offloading.conf'; fsdp = False # error with loading... something wrong with the config.\n",
    "# fsdp = False; deepspeed = False\n",
    "\n",
    "if fsdp and deepspeed:\n",
    "    raise ValueError('either fsdp or deepspeed, not both')\n",
    "\n",
    "use_lora = False\n",
    "lora_rank = 256 \n",
    "lora_alpha = lora_rank \n",
    "lora_dropout = 0.05\n",
    "if use_lora:\n",
    "    abbr_model_name += f'+lora(r={lora_rank},a={lora_alpha})'\n",
    "load_in_8bit = False\n",
    "\n",
    "print(f\"Training {model_name_or_path} \"\n",
    "      f\"using {num_gpus} GPUs, \"\n",
    "      f\"{per_device_train_batch_size} batch size per GPU, \"\n",
    "      f\"{gradient_accumulation_steps} gradient accumulation steps, \"\n",
    "      f\"Effective batch size {effective_batch_size}\")\n",
    "\n",
    "\n",
    "if nodes == 1:\n",
    "    exe = 'python' if num_gpus==1 else \\\n",
    "        f\"torchrun --nnodes 1 --nproc_per_node={num_gpus} --rdzv_backend=c10d --master_port=0\" # assigns random port. https://github.com/pytorch/pytorch/issues/73320\n",
    "else:\n",
    "    exe = f\"torchrun --nnodes={nodes} --nproc_per_node={num_gpus} --rdzv-id=${'SLURM_JOB_ID' if arch == 'ppcle64' else 'LSB_JOBID'} --rdzv-backend=c10d --rdzv-endpoint=$RDZV_ENDPOINT\"\n",
    "\n",
    "if test_run:\n",
    "    exe = f\"CUDA_VISIBLE_DEVICES={','.join(map(str, range(num_gpus)))} {exe}\"\n",
    "if test_run and debug_mode:\n",
    "    exe = 'TORCH_CPP_LOG_LEVEL=INFO NCCL_DEBUG=INFO LOGLEVEL=INFO ' + exe\n",
    "    error_file = os.path.join(open_instruct_dir, 'scripts', 'error_file')\n",
    "    exe = f'TORCHELASTIC_ERROR_FILE={error_file} {exe}'\n",
    "\n",
    "if not os.path.isfile(train_file):\n",
    "    print(f'train_file={train_file} does not exists')\n",
    "\n",
    "options_list = itertools.product(\n",
    "    num_train_epochs_list,\n",
    "    subsample_inds_file_list,\n",
    "    max_train_samples_list,\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "output_dirname_list = []\n",
    "for (num_train_epochs,\n",
    "     subsample_inds_file,\n",
    "     max_train_samples,) in options_list:\n",
    "\n",
    "    output_dirname = f\"{abbr_model_name}_{abbr_train_file}\"\n",
    "    if max_train_samples:\n",
    "        output_dirname += f\":{int(max_train_samples/1000)}k\"\n",
    "            \n",
    "    if any(job_name == y for y in ['oi2']):\n",
    "        output_dirname += f'_ep={num_train_epochs}'\n",
    "        \n",
    "    if subsample_inds_file:\n",
    "        def subsample_inds_file_abbr_fn(x):\n",
    "            s = os.path.basename(x).split('.pkl')[0]\n",
    "            if s.startswith('inds_'):\n",
    "                scoring_fn = os.path.basename(os.path.dirname(x)).replace('_', ':')\n",
    "                pacing_fn = s.split('inds_')[-1].replace('_', ':')\n",
    "                return f'score={scoring_fn}_pace={pacing_fn}'\n",
    "            else:\n",
    "                return s\n",
    "        subsample_inds_file_abbr = subsample_inds_file_abbr_fn(subsample_inds_file)\n",
    "        if subsample_inds_file_abbr:\n",
    "            output_dirname += f'_{subsample_inds_file_abbr}'\n",
    "            \n",
    "    if test_run:\n",
    "        output_dirname = 'jpt_'+output_dirname\n",
    "            \n",
    "    if add_hardwarespec_to_dirname:\n",
    "        output_dirname += \\\n",
    "            ('_fsdp='+fsdp.split(' ')[0] if fsdp else '')+\\\n",
    "            ('_deepspeed='+os.path.basename(deepspeed).split('.')[0] if deepspeed else '')+\\\n",
    "            ('_gradckpt='+str(gradient_checkpointing) if gradient_checkpointing else '')+\\\n",
    "            '_mbsz='+str(per_device_train_batch_size)+\\\n",
    "            ('_dtype='+torch_dtype if torch_dtype is not None else '')+\\\n",
    "            ('_mp='+str(mixed_precision) if mixed_precision else '_mp=none')+\\\n",
    "            '_seqlen='+str(max_seq_length)+\\\n",
    "            '_nodes='+str(nodes)+\\\n",
    "            '_ngpus='+str(num_gpus)+\\\n",
    "            ('_fa2' if use_flash_attn else '')\n",
    "    if suffix:\n",
    "        output_dirname += suffix\n",
    "    output_dir = os.path.join(open_instruct_dir, 'results', job_name, output_dirname)\n",
    "    os.makedirs(os.path.join(open_instruct_dir, 'results', job_name), exist_ok=True)\n",
    "    if arch == 'x86_64':\n",
    "        wandb_run_name = 'ccc'+output_dir[output_dir.find('results'):][7:] # e.g., ccc/oi2/run_name\n",
    "    else:\n",
    "        wandb_run_name = output_dir.replace('results/', '') # e.g., oi2/run_name\n",
    "    \n",
    "\n",
    "    cmd = f\"\"\"\n",
    "    {'cd .. && ' if test_run else ''}{exe}\n",
    "        open_instruct/finetune_trainer.py \\\n",
    "        --model_name_or_path={model_name_or_path} \\\n",
    "        --tokenizer_name={model_name_or_path} \\\n",
    "        {'--load_in_8bit' if load_in_8bit else ''} \\\n",
    "        --use_fast_tokenizer=True \\\n",
    "        --train_file={train_file} \\\n",
    "        --max_seq_length={max_seq_length} \\\n",
    "        {'--max_train_samples='+str(max_train_samples) if max_train_samples else ''} \\\n",
    "        {'--use_lora' if use_lora else ''} \\\n",
    "        {'--lora_rank='+str(lora_rank) if use_lora else ''} \\\n",
    "        {'--lora_alpha='+str(lora_alpha) if use_lora else ''} \\\n",
    "        {'--lora_dropout='+str(lora_dropout) if use_lora else ''} \\\n",
    "        --do_train \\\n",
    "        --preprocessing_num_workers={preprocessing_num_workers} \\\n",
    "        --per_device_train_batch_size={per_device_train_batch_size} \\\n",
    "        --gradient_accumulation_steps={gradient_accumulation_steps} \\\n",
    "        --learning_rate=2e-5 \\\n",
    "        --lr_scheduler_type={lr_scheduler_type} \\\n",
    "        --warmup_ratio={warmup_ratio} \\\n",
    "        --weight_decay=0. \\\n",
    "        --optim={optimizer} \\\n",
    "        --evaluation_strategy={evaluation_strategy} \\\n",
    "        {'--eval_steps='+str(eval_steps) if eval_steps else ''} \\\n",
    "        {'--report_to '+str(report_to) if report_to else ''} \\\n",
    "        --run_name {wandb_run_name} \\\n",
    "        --logging_strategy=steps \\\n",
    "        --logging_first_step \\\n",
    "        --logging_steps=1 \\\n",
    "        --save_strategy={save_strategy} \\\n",
    "        --save_steps={save_steps} \\\n",
    "        --save_total_limit={save_total_limit} \\\n",
    "        --num_train_epochs={num_train_epochs} \\\n",
    "        --ddp_timeout=7200 \\\n",
    "        {'--fsdp=\"'+fsdp+'\"' if fsdp else ''} \\\n",
    "        {'--fsdp_transformer_layer_cls_to_wrap=\"'+fsdp_transformer_layer_cls_to_wrap+'\"' \n",
    "            if fsdp else ''} \\\n",
    "        {'--gradient_checkpointing' if gradient_checkpointing  else ''} \\\n",
    "        {'--torch_dtype='+str(torch_dtype) if torch_dtype else ''} \\\n",
    "        {'--save_model_torch_dtype='+str(save_model_torch_dtype) if save_model_torch_dtype else ''} \\\n",
    "        --dataloader_num_workers=8 \\\n",
    "        {f'--{mixed_precision}=True' if mixed_precision else ''} \\\n",
    "        {f'--tf32=True' if use_tf32 else ''} \\\n",
    "        {'--overwrite_output_dir' if overwrite_output_dir else ''} \\\n",
    "        {'--deepspeed='+deepspeed if deepspeed else ''} \\\n",
    "        {'--subsample_inds_file='+subsample_inds_file if subsample_inds_file else ''} \\\n",
    "        {'--dataloader_sampler '+str(dataloader_sampler) if dataloader_sampler else ''} \\\n",
    "        --use_flash_attn {'True' if use_flash_attn else 'False'} \\\n",
    "        --low_cpu_mem_usage \\\n",
    "        --overwrite_cache \\\n",
    "        --output_dir=\"{output_dir}\" \\\n",
    "    \"\"\" \n",
    "    #  --overwrite_cache   # if delete a dataset and need to refresh cache\n",
    "\n",
    "    if test_run:\n",
    "        print()\n",
    "        print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd)]))\n",
    "\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    cmds.append(cmd)\n",
    "\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.path.dirname(os.getcwd()),\n",
    "        cmd=cmd,\n",
    "        log_dir=os.getcwd(),\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    if arch == 'x86_64':\n",
    "        shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=job_name, \n",
    "        nodes=nodes,\n",
    "        num_cpus=num_cpus,\n",
    "        cpu_mem=cpu_mem,\n",
    "        num_gpus=num_gpus,\n",
    "        gpu_type=gpu_type,\n",
    "        test_run=test_run,\n",
    "        queue=queue,\n",
    "        job_duration=job_duration,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12fc2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_sft.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed0c2894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ cd ..\n",
      "+ TORCHELASTIC_ERROR_FILE=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/error_file\n",
      "+ TORCH_CPP_LOG_LEVEL=INFO\n",
      "+ NCCL_DEBUG=INFO\n",
      "+ LOGLEVEL=INFO\n",
      "+ CUDA_VISIBLE_DEVICES=0\n",
      "+ python open_instruct/finetune_trainer.py --model_name_or_path=results/baselines/huggyllama/llama-7b --tokenizer_name=results/baselines/huggyllama/llama-7b --use_fast_tokenizer=True --train_file=data/processed/oasst1/oasst1_data.jsonl --max_seq_length=2048 --do_train --preprocessing_num_workers=32 --per_device_train_batch_size=1 --gradient_accumulation_steps=128 --learning_rate=2e-5 --lr_scheduler_type=linear --warmup_ratio=0.03 --weight_decay=0. --optim=adamw_hf --evaluation_strategy=no --eval_steps=200 --report_to tensorboard wandb --run_name /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10 --logging_strategy=steps --logging_first_step --logging_steps=1 --save_strategy=steps --save_steps=200 --save_total_limit=1 --num_train_epochs=1 --ddp_timeout=7200 --torch_dtype=bfloat16 --dataloader_num_workers=8 --bf16=True --tf32=True --overwrite_output_dir --subsample_inds_file=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl --dataloader_sampler SequentialSampler --use_flash_attn True --low_cpu_mem_usage --overwrite_cache --output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10\n",
      "[2024-01-19 02:04:37,834] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Saving args dict to /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10.args.json\n",
      "01/19/2024 02:04:39 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "01/19/2024 02:04:39 - INFO - __main__ - Training parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=8,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_sampler=SequentialSampler,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=7200,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=200.0,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=128,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10/runs/Jan19_02-04-39_cccxc552,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1.0,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/results/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard', 'wandb'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/oi5_oasst1:llama-7b_debug/jpt_llama-7b_oasst1_score=random:s=0_pace=prune:size=10000:ep=10,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=True,\n",
      "save_steps=200,\n",
      "save_strategy=steps,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=False,\n",
      "tf32=True,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "Using custom data configuration default-b03eccd42e843020\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Using custom data configuration default-b03eccd42e843020\n",
      "Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset Infos from /dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "01/19/2024 02:04:39 - INFO - datasets.builder - Found cached dataset json (/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "01/19/2024 02:04:39 - INFO - datasets.info - Loading Dataset info from /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\n",
      "[INFO|configuration_utils.py:715] 2024-01-19 02:04:39,135 >> loading configuration file results/baselines/huggyllama/llama-7b/config.json\n",
      "[INFO|configuration_utils.py:777] 2024-01-19 02:04:39,136 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"results/baselines/huggyllama/llama-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:39,137 >> loading file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3118] 2024-01-19 02:04:39,229 >> loading weights file results/baselines/huggyllama/llama-7b/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1222] 2024-01-19 02:04:39,229 >> Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
      "[WARNING|modeling_utils.py:1304] 2024-01-19 02:04:39,230 >> You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:39,230 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.07it/s]\n",
      "[INFO|modeling_utils.py:3950] 2024-01-19 02:04:41,778 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:3958] 2024-01-19 02:04:41,778 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at results/baselines/huggyllama/llama-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:749] 2024-01-19 02:04:41,781 >> loading configuration file results/baselines/huggyllama/llama-7b/generation_config.json\n",
      "[INFO|configuration_utils.py:791] 2024-01-19 02:04:41,781 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "01/19/2024 02:04:41 - INFO - __main__ - [wpq] model.dtype=torch.bfloat16\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2020] 2024-01-19 02:04:41,785 >> loading file tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1648] 2024-01-19 02:04:41,845 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32001. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #16 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #17 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #18 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #19 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #20 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #21 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #22 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #23 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #24 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #25 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #26 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #27 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #28 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #29 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #30 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:51 - INFO - datasets.arrow_dataset - Process #31 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spawning 32 processes\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Spawning 32 processes\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 0/33717 [00:Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00000_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00001_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00002_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00003_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   0%| | 22/33717 [00Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00004_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00005_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00006_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00007_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00008_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   1%| | 361/33717 [0Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00009_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00010_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00011_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00012_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00013_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):   3%| | 1001/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00014_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00015_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00016_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00017_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00018_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   5%| | 1719/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00019_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00020_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00021_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00022_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):   7%| | 2251/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00023_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00025_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00024_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00026_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00027_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and reformatting instruction data (num_proc=32):  12%| | 4021/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00028_of_00032.arrow\n",
      "Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00029_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  14%|▏| 4841/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "01/19/2024 02:04:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00030_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32):  18%|▏| 5957/33717 [Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "01/19/2024 02:04:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-34d81440de676221_00031_of_00032.arrow\n",
      "Tokenizing and reformatting instruction data (num_proc=32): 100%|█| 33717/33717 \n",
      "Concatenating 32 shards\n",
      "01/19/2024 02:04:55 - INFO - datasets.arrow_dataset - Concatenating 32 shards\n",
      "Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #0 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00000_of_00016.arrow\n",
      "Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #1 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00001_of_00016.arrow\n",
      "Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #2 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00002_of_00016.arrow\n",
      "Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #3 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00003_of_00016.arrow\n",
      "Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #4 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00004_of_00016.arrow\n",
      "Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #5 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00005_of_00016.arrow\n",
      "Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #6 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00006_of_00016.arrow\n",
      "Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #7 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00007_of_00016.arrow\n",
      "Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #8 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00008_of_00016.arrow\n",
      "Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #9 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00009_of_00016.arrow\n",
      "Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #10 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00010_of_00016.arrow\n",
      "Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #11 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00011_of_00016.arrow\n",
      "Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #12 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00012_of_00016.arrow\n",
      "Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #13 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00013_of_00016.arrow\n",
      "Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #14 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00014_of_00016.arrow\n",
      "Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Process #15 will write at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_00015_of_00016.arrow\n",
      "Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/data/processed/oasst1/json/default-b03eccd42e843020/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-587744e8d3857964_*_of_00016.arrow\n",
      "Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - datasets.arrow_dataset - Concatenating 16 shards\n",
      "01/19/2024 02:04:56 - INFO - __main__ - Subsample dataset according to indices: /dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/curriculum/llama-7b+lora:r=512:a=11585+proj=4096/oasst1/random_s=0/inds_prune_size=10000_ep=10.pkl\n",
      "01/19/2024 02:04:56 - INFO - __main__ - subsample_inds_file has 10000 indices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[wpq] Example 0 of train_dataset: \r\n",
      "{'dataset': 'oasst1', 'id': 'oasst1_20480', 'messages': [{'role': 'user', 'content': 'Cómo manejar un carro manual'}, {'role': 'assistant', 'content': 'Lo primero que tienes que hacer, si nunca has conducido un coche manual, es familiarizarte con el embrague y palanca de cambios. Si conduces habitualmente un coche automático, estarás acostumbrado a no utilizar para nada el pie izquierdo ni la palanca del cambio. Encontrarás tres pedales, siendo el embrague el que está situado a la izquierda y el que tendrás que pisar cada vez que cambies de marcha. Por otro lado, la palanca del cambio se ubica siempre en la consola central.\\n\\nPara arrancar un coche manual, es necesario seguir una serie de pasos que, al principio, pueden parecer muchos, pero que, con el tiempo, acabarás haciéndolos sin darte cuenta:\\n\\n1) Comprueba que la palanca del cambio está en punto muerto\\n2) Coloca el pie derecho en el pedal del freno\\n3) Arranca el motor\\n4) Pisa el embrague con el pie izquierdo\\n5) Coloca la palanca del cambio en la primera marcha, sin levantar el pedal del freno\\n6) Suelta el freno de mano\\n7) Suelta el pedal del freno\\nYa estás listo para iniciar la marcha, soltando suavemente el embrague, a medida que aceleras.\\n\\nUna vez que ya estás en marcha, debes hacer un uso correcto del cambio manual para cambiar las marchas de forma correcta. Un uso incorrecto de la caja de cambios manual puede repercutir negativamente en tu seguridad y también afectar gravemente al embrague y a la transmisión, lo que se traduce en serias averías de coste muy elevado. Para evitarlo, te explicamos cómo debes proceder:\\n\\nUna vez que hayas arrancado, pisa el acelerador muy lentamente. Notarás que el régimen del motor aumenta. En ese momento, comienza a soltar suavemente el pedal del embrague. Verás que el motor vuelve a bajar de vueltas. En ese momento, puedes presionar un poco más el acelerador y el coche comenzará a avanzar.\\n\\nAhora llega el momento de meter la segunda marcha. Dependiendo del tipo de coche y combustible, podrás circular a un régimen de giro más bajo o alto. El régimen de giro en coche de gasolina, por lo general, oscila entre loas 2.500 y 3.000 vueltas. Si el motor está sobrealimentado por turbo, te permitirá circular por debajo de ese rango, ya que algunos coches turbos modernos entregan la totalidad de su par motor, incluso por debajo de las 2.000 vueltas.\\n\\nUn coche con motor turbodiésel te permite circular a un régimen muy bajo, por debajo de las 2.000 vueltas, ya que la entrega de par se produce antes que en un motor de gasolina.\\n\\nCuando el coche alcance un régimen de vueltas apropiado, suelta el pedal del acelerador y vuelve a pisar el embrague. Coge la palanca del cambio y baja para meter segunda. Suelta el embrague y presiona nuevamente el acelerador. A partir de aquí, cada vez que quieras cambiar de marcha, deberás repetir el mismo proceso: soltar el acelerador, pisar embrague, meter la marcha, soltar embrague y volver a acelerar.\\n\\n¡Buen viaje!'}], 'input_ids': tensor([    1,   529, 29989,  1792, 29989, 29958,    13, 29907, 29980,  4346,\r\n",
      "          767, 29872,  4758,   443,  1559,   307, 12219,    13, 29966, 29989,\r\n",
      "          465, 22137, 29989, 29958,    13,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'labels': tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\r\n",
      "         -100,  -100,  -100,  -100,  -100,  3410,  1903,  1489,   712,   260,\r\n",
      "          819,   267,   712, 14557, 29892,  1354, 28456,   756, 13417, 13321,\r\n",
      "          443,  1302,  1173, 12219, 29892,   831,  9985,   466, 11908,   378,\r\n",
      "          560,  7232,  1431,   434,   343,  5112,   273,  1113,   316, 10625,\r\n",
      "         2363, 29889,  6101, 13417,   778,  4760, 14162,   443,  1302,  1173,\r\n",
      "         3345, 22054, 29892, 23673,  1569,  1274,   520,   398,  1182,   912,\r\n",
      "          263,   694, 11824,   279,  1702, 25801,   560,  5036,  5951, 16026,\r\n",
      "         1867,  6836,   425,  5112,   273,  1113,   628, 26007, 29889,  1174,\r\n",
      "         9996,   279,  1569,  9941,  8939,  2122, 29892, 18200,   560,  7232,\r\n",
      "         1431,   434,   560,   712,  7919,  2990,   912,   263,   425,  5951,\r\n",
      "        16026,  1388,   343,   560,   712, 10331, 11964,   712, 20066,   279,\r\n",
      "         9747,  7763,   712, 10625,   583,   316,  8575, 29874, 29889,  7102,\r\n",
      "        16994, 19931, 29892,   425,  5112,   273,  1113,   628, 26007,   409,\r\n",
      "        13069,   983, 26692,   427,   425,  1136,  2963,  6555, 29889,    13,\r\n",
      "           13,  2177, 29874,   564,   661,  4287,   443,  1302,  1173, 12219,\r\n",
      "        29892,   831, 16632,  2628,  7025,   381,  1185,  7080,   316,  2331,\r\n",
      "          359,   712, 29892,   394,  3420,   601, 29892, 19796,  9541,  2265,\r\n",
      "        24312, 29892,  7046,   712, 29892,   378,   560, 13924, 29892, 22998,\r\n",
      "          279,  1569,   447,   455, 21183,   324,   359,  4457,  5424,   371,\r\n",
      "        21052, 29901,    13,    13, 29896, 29897,   422,   558,   434,  2291,\r\n",
      "          712,   425,  5112,   273,  1113,   628, 26007,  7919,   427, 15978,\r\n",
      "          286, 15009,    13, 29906, 29897,  1530,  6400,   560,  5036, 14923,\r\n",
      "         1859,   427,   560,  8939,   284,   628,   285, 26155,    13, 29941,\r\n",
      "        29897,   826,   661,  1113,   560, 10992,    13, 29946, 29897,   349,\r\n",
      "         8069,   560,  7232,  1431,   434,   378,   560,  5036,  5951, 16026,\r\n",
      "         1867,    13, 29945, 29897,  1530,  6400,   425,  5112,   273,  1113,\r\n",
      "          628, 26007,   427,   425,  8633,  8575, 29874, 29892,  4457, 14453,\r\n",
      "          424,   279,   560,  8939,   284,   628,   285, 26155,    13, 29953,\r\n",
      "        29897,  2166,  2554,   560,   285, 26155,   316, 24318,    13, 29955,\r\n",
      "        29897,  2166,  2554,   560,  8939,   284,   628,   285, 26155,    13,\r\n",
      "        29979, 29874,   707,  1569,  1051, 29877,  1702, 21855,   279,   425,\r\n",
      "         8575, 29874, 29892,   899, 29873,  1743,   480,   485,  9936,   560,\r\n",
      "         7232,  1431,   434, 29892,   263,  1612,  1458,   712,  1274,  7367,\r\n",
      "          294, 29889,    13,    13, 29965,  1056,  7763,   712,  9343,   707,\r\n",
      "         1569,   427,  8575, 29874, 29892,  2553,   267, 14557,   443, 17448,\r\n",
      "         1959, 29877,   628, 26007, 12219,  1702, 10625,  4447,  1869,  8575,\r\n",
      "          294,   316,  5954,  1959, 29874, 29889,   853, 17448, 10240, 29877,\r\n",
      "          316,   425,   274,  9919,   316, 10625,  2363, 12219, 11493,   337,\r\n",
      "          546,  7582,   381,  3480,  1926,  2503,   427,  5291,  2377,   332,\r\n",
      "         2368,   343,  6196,  2511,   522,   279,  8310,  9936,   394,  7232,\r\n",
      "         1431,   434,   343,   263,   425, 18750, 11861, 29892,   658,   712,\r\n",
      "          409,  3534, 24551,   427,   724,  3173,  4759,  8577,   316,  3438,\r\n",
      "        29872, 12287, 11858,   912, 29889, 12994,  3415,  3673,   417, 29892,\r\n",
      "          734, 28117, 14054, 28810,  4346,  2553,   267,  6449,   261, 29901,\r\n",
      "           13,    13, 29965,  1056,  7763,   712, 14842,   294,   564,   661,\r\n",
      "        29883,   912, 29892,   282,  8069,   560,  1274,  7367,  3136, 12287,\r\n",
      "          301,   296,  2503, 29889,  2216,   279,  1569,   712,   560,  6367,\r\n",
      "        19933,   628, 10992, 19291, 29874, 29889,  1174, 15371, 14341, 29892,\r\n",
      "          419, 24880,   263,   899, 12637,   480,   485,  9936,   560,  8939,\r\n",
      "          284,   628,  7232,  1431,   434, 29889,  1798,  1569,   712,   560,\r\n",
      "        10992, 22126,   345,   263,   289,  1175,   279,   316, 18679,  2152,\r\n",
      "          294, 29889,  1174, 15371, 14341, 29892,  2653, 11696,  2225,   291,\r\n",
      "          279,   443, 14534,  3627,   560,  1274,  7367,  3136,   343,   560,\r\n",
      "         1302,  1173, 19487, 20484,   263,  1029,  4096,   279, 29889,    13,\r\n",
      "           13, 29909, 15255, 10953, 29874,   560, 14341,   316, 11134,   425,\r\n",
      "        17329,  8575, 29874, 29889, 10034,   355, 17008,   628, 13306,   316,\r\n",
      "         1302,  1173,   343,  4145,   504,  1821, 29892,  2532, 11964, 19308,\r\n",
      "          263,   443,  6367, 19933,   316,   330,  3350,  3627, 13085,   288,\r\n",
      "        20478, 29889,  1260,  6367, 19933,   316,   330,  3350,   427,  1302,\r\n",
      "         1173,   316, 10489,   324,  1099, 29892,  1277,   658,  2498, 29892,\r\n",
      "        15199,  4233,  2637,   658,   294, 29871, 29906, 29889, 29945, 29900,\r\n",
      "        29900,   343, 29871, 29941, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29889,  6101,   560, 10992,  7919,  4166,   284,  2073,   912,\r\n",
      "         1277,  7013,   833, 29892,   734, 14257,   381, 29976, 19308,  1277,\r\n",
      "         2553,  7069,   316, 15371,   364,  4524, 29892,  9343,   712, 20071,\r\n",
      "         1302,  6609,  7013, 27737,  5400,   359,   875,  1727,   273,   425,\r\n",
      "         3001,  2368,   316,   480,   610, 10992, 29892,  1343, 10648,  1277,\r\n",
      "         2553,  7069,   316,  1869, 29871, 29906, 29889, 29900, 29900, 29900,\r\n",
      "        18679,  2152,   294, 29889,    13,    13,  2525,  1302,  1173,   378,\r\n",
      "        10992,  7013, 29890, 12143,   743,   295,   734,  3635,   568, 19308,\r\n",
      "          263,   443,  6367, 19933, 12287, 13085, 29892,  1277,  2553,  7069,\r\n",
      "          316,  1869, 29871, 29906, 29889, 29900, 29900, 29900, 18679,  2152,\r\n",
      "          294, 29892,  9343,   712,   425,   875,  1727, 29874,   316,   610,\r\n",
      "          409,  7738, 12971,   712,   427,   443, 10992,   316, 10489,   324,\r\n",
      "         1099, 29889,    13,    13, 29907, 29884,  1743,   560,  1302,  1173,\r\n",
      "        10747,   749,   443,  6367, 19933,   316, 18679,  2152,   294, 11712,\r\n",
      "         1631,   912, 29892,   480,  2554,   560,  8939,   284,   628,  1274,\r\n",
      "         7367,  3136,   343, 22126,   345,   263, 20066,   279,   560,  7232,\r\n",
      "         1431,   434, 29889,   315, 21317,   425,  5112,   273,  1113,   628,\r\n",
      "        26007,   343,   289,  9919,  1702, 11134, 17329, 29889,  2166,  2554,\r\n",
      "          560,  7232,  1431,   434,   343,  2225, 16017,  8005, 29894,  2503,\r\n",
      "          560,  1274,  7367,  3136, 29889,   319,  8019,   316, 10592, 29983,\r\n",
      "        29892,  9747,  7763,   712,   439,   631,   294, 10625,  4447,   316,\r\n",
      "         8575, 29874, 29892,   316,   495,  1569, 21159,   381,   560, 11329,\r\n",
      "        14177, 29877, 29901,   899, 12637,   560,  1274,  7367,  3136, 29892,\r\n",
      "        20066,   279,  7232,  1431,   434, 29892, 11134,   425,  8575, 29874,\r\n",
      "        29892,   899, 12637,  7232,  1431,   434,   343,  1700,   369,   263,\r\n",
      "         1274,  7367,   279, 29889,    13,    13, 30180,  3727,   264,  3025,\r\n",
      "         1324, 29991,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:593] 2024-01-19 02:04:57,333 >> Using auto half precision backend\n",
      "[INFO|trainer.py:738] 2024-01-19 02:04:57,494 >> The following columns in the training set don't have a corresponding argument in `LlamaForCausalLM.forward` and have been ignored: messages, id, dataset. If messages, id, dataset are not expected by `LlamaForCausalLM.forward`,  you can safely ignore this message.\n",
      "/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1723] 2024-01-19 02:04:57,514 >> ***** Running training *****\n",
      "[INFO|trainer.py:1724] 2024-01-19 02:04:57,514 >>   Num examples = 10,000\n",
      "[INFO|trainer.py:1725] 2024-01-19 02:04:57,514 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1726] 2024-01-19 02:04:57,514 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:1729] 2024-01-19 02:04:57,514 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1730] 2024-01-19 02:04:57,514 >>   Gradient Accumulation steps = 128\n",
      "[INFO|trainer.py:1731] 2024-01-19 02:04:57,514 >>   Total optimization steps = 78\n",
      "[INFO|trainer.py:1732] 2024-01-19 02:04:57,515 >>   Number of trainable parameters = 6,738,423,808\n",
      "[INFO|integration_utils.py:718] 2024-01-19 02:04:57,519 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "  0%|                                                    | 0/78 [00:00<?, ?it/s][WARNING|logging.py:314] 2024-01-19 02:05:01,563 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,569 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,570 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,572 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,576 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "[WARNING|logging.py:314] 2024-01-19 02:05:01,577 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 1.6425, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}         \n",
      "{'loss': 1.7168, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.03}        \n",
      "  3%|█▏                                          | 2/78 [00:42<26:54, 21.24s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash gen_cmds_sft.sh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/IPython/utils/_process_posix.py:177\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m/dccstor/data-pruning/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pexpect/pty_spawn.py:646\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGCONT)\n\u001b[0;32m--> 646\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_sft.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831fe55",
   "metadata": {},
   "source": [
    "# eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "499d6f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mmlu_s=0', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=5', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=random:s=0_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=5', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3')\n",
      "('mmlu_s=0', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=5', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('humaneval', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=0_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('mmlu_s=5_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('gsm_s=8_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('bbh_s=3_cot_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('humaneval_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_cb_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "('tydiqa_s=1_gp_chatfmt', 'results/oi5_wizardlm50k:llama-7b/llama-7b_wizardlm50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10')\n",
      "#cmds:  108 \n",
      "\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"eval.tydiqa_s=1_gp_chatfmt\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"cpu_mem\": 96,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"a100_80gb\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"alt_6h\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from gen_cmds_utils import remove_all_symlinks, create_unique_symlinks, get_chat_formatting_function, get_resource_for_task, OPENAI_MODEL_LIST\n",
    "queue = None if getpass.getuser() in ('PTFMqngp', 'wpq') else \\\n",
    "    ('alt_7d' if task_name.startswith('mtbench') else 'alt_1h')\n",
    "\n",
    "create_symlinks = False\n",
    "include_checkpoints = False\n",
    "eval_rest = True\n",
    "subdir_path_list = []\n",
    "subdir_filter_fn = lambda x: True\n",
    "use_slow_tokenizer = True\n",
    "definitely_run_mtbench_on_non_alt7b_queue = False\n",
    "launch_one_job_per_model = True\n",
    "\n",
    "task_names = [\n",
    "    'mmlu_s=0',\n",
    "    'mmlu_s=5', \n",
    "    'gsm_s=8',\n",
    "    'gsm_s=8_cot',\n",
    "    'bbh_s=3',\n",
    "    'bbh_s=3_cot', # max_datapoints_per_task=40 -> 40min.\n",
    "    'humaneval',\n",
    "    'tydiqa_s=1_cb', # 3min\n",
    "    'tydiqa_s=1_gp',\n",
    "    # 'toxigen', # ~1.5hr\n",
    "#     'alpacafarm_ann=gpt35:turbo:1106',\n",
    "    # 'alpacafarm_ann=chatgpt', # ~$1 per eval.\n",
    "]\n",
    "task_names_chatfmt = [x+'_chatfmt' for x in task_names]\n",
    "\n",
    "\n",
    "task_names_mtbench = ['mtbench_ann=gpt:4:1106:preview_chatfmt'] # ann=gpt:4, ann=gpt:3.5:turbo:1106, gpt:4:1106:preview (gpt4-turbo)\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:3.5:turbo:1106_chatfmt'] # for debug sake, prefer gpt4\n",
    "# task_names_mtbench = ['mtbench_ann=gpt:4_chatfmt']\n",
    "task_names_alpacafarm = ['alpacafarm_ann=chatgpt_chatfmt']\n",
    "task_names_chateval = task_names_mtbench + task_names_alpacafarm\n",
    "\n",
    "\n",
    "# # ## baselines eval \n",
    "# subdir_path_list = [os.path.join('results/baselines', x) for x in [\n",
    "# #     'huggyllama/llama-7b', \n",
    "# #     'mistralai/Mistral-7B-v0.1',\n",
    "# #     'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "# #     'NousResearch/Llama-2-7b-hf',\n",
    "# #     'NousResearch/Llama-2-7b-chat-hf',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "# #     'HuggingFaceH4/mistral-7b-sft-beta',\n",
    "# #     'HuggingFaceH4/zephyr-7b-alpha',\n",
    "#     'HuggingFaceH4/zephyr-7b-beta',\n",
    "# #     'codellama/CodeLlama-7b-hf',\n",
    "# #     'codellama/CodeLlama-7b-Python-hf',\n",
    "# #     'codellama/CodeLlama-7b-Instruct-hf',\n",
    "# ]]\n",
    "# # task_names = task_names + task_names_chatfmt\n",
    "# task_names = task_names_mtbench; definitely_run_mtbench_on_non_alt7b_queue = True\n",
    "\n",
    "# # oi5\n",
    "# exp_dir = 'results/oi2'\n",
    "# exp_dir = 'results/oi5_flan_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_dolly:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlm50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegpt50k:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b'\n",
    "# exp_dir = 'results/oi5_oasst1:llama-7b_debug'\n",
    "# exp_dir = 'results/oi5_stanford_alpaca:llama-7b'\n",
    "# exp_dir = 'results/oi5_wizardlmv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_sharegptv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_ultrachat200kv2:llama-7b'\n",
    "# exp_dir = 'results/oi5_tulu_v2:llama-7b'\n",
    "# exp_dir = 'results/oi5_open_orca_slim:llama-7b'\n",
    "# exp_dir = 'results/dpo1'\n",
    "# exp_dir = 'results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2'\n",
    "exp_dirs = [\n",
    "#     'results/oi5_dolly:llama-7b',\n",
    "#     'results/oi5_flan_v250k:llama-7b',\n",
    "#     'results/oi5_stanford_alpaca50k:llama-7b',\n",
    "#     'results/oi5_oasst2:llama-7b',\n",
    "    'results/oi5_wizardlm50k:llama-7b',\n",
    "#     'results/oi5_sharegpt50k:llama-7b',\n",
    "#     'results/oi5_ultrachat50k:llama-7b',\n",
    "]\n",
    "\n",
    "# subdir_filter_fn = lambda x: 'sharegpt' in x\n",
    "task_names = task_names + task_names_chatfmt; launch_one_job_per_model = False\n",
    "# task_names = task_names_alpacafarm; definitely_run_mtbench_on_non_alt7b_queue = False\n",
    "# task_names = task_names_mtbench; definitely_run_mtbench_on_non_alt7b_queue = False\n",
    "# task_names = task_names + task_names_chatfmt + task_names_mtbench\n",
    "# task_names = task_names\n",
    "# task_names = ['alpacafarm_ann=gpt35:turbo:1106_chatfmt']\n",
    "\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "num_gpus = 1\n",
    "if arch == 'x86_64': # ccc\n",
    "\n",
    "    if definitely_run_mtbench_on_non_alt7b_queue:\n",
    "        gpu_type = 'v100'; num_cpus = int(32/8*num_gpus); cpu_mem = int(240/8*num_gpus)\n",
    "    else:\n",
    "        gpu_type = 'a100_80gb'; num_cpus = int(128/8*num_gpus); cpu_mem = int(768/8*num_gpus)\n",
    "    use_vllm = True; torch_dtype = 'bfloat16'\n",
    "else:\n",
    "    gpu_type = 'v100'\n",
    "    num_cpus = int(128/6*num_gpus); cpu_mem = int(512/6*num_gpus)\n",
    "    use_vllm = False; torch_dtype = 'float16'\n",
    "    \n",
    "    \n",
    "if len(subdir_path_list)==0:\n",
    "    subdir_path_list = []\n",
    "    for exp_dir in exp_dirs:\n",
    "        if create_symlinks:\n",
    "            remove_all_symlinks(exp_dir)\n",
    "        subdirs = list(os.listdir(exp_dir))\n",
    "        subdirs = filter(subdir_filter_fn, subdirs)\n",
    "        for subdir in subdirs:\n",
    "            subdir_path = os.path.join(exp_dir, subdir)\n",
    "            if include_checkpoints:\n",
    "                subdir_path_list += glob.glob(os.path.join(subdir_path, 'checkpoint-*'))\n",
    "            if not os.path.isfile(os.path.join(subdir_path, 'config.json')): # skip runs not yet finished\n",
    "                continue\n",
    "            subdir_path_list.append(subdir_path)\n",
    "\n",
    "if eval_rest:\n",
    "    task_name_and_model = []\n",
    "    for subdir_path in subdir_path_list:\n",
    "        for task_name in task_names:\n",
    "            if not os.path.islink(subdir_path) and \\\n",
    "                not os.path.isfile(os.path.join(subdir_path, 'eval', task_name, 'metrics.json')):\n",
    "                task_name_and_model.append((task_name, subdir_path))\n",
    "                print((task_name, subdir_path))\n",
    "else:\n",
    "    task_name_and_model = list(itertools.product(task_names, subdir_path_list))\n",
    "    \n",
    "\n",
    "print('#cmds: ', len(list(task_name_and_model)), '\\n')\n",
    "\n",
    "if create_symlinks:\n",
    "    # create symlink for each directory.\n",
    "    symlink_path_dict = create_unique_symlinks(\n",
    "        list([x[1] for x in task_name_and_model]))\n",
    "    options_list = list(map(lambda x: (x[0], symlink_path_dict[x[1]]), task_name_and_model))\n",
    "else:\n",
    "    options_list = task_name_and_model\n",
    "    \n",
    "    \n",
    "dfo = pd.DataFrame(options_list, columns=['task_name', 'model_name_or_path'])\n",
    "model_and_task_list = dfo.groupby('model_name_or_path')['task_name'].agg(list).to_dict()\n",
    "\n",
    "\n",
    "info = {}  \n",
    "cmds = []\n",
    "for model_name_or_path, task_name_list in model_and_task_list.items():\n",
    "    num_tasks = len(task_name_list)\n",
    "    cmds_per_model = []\n",
    "    for i, task_name in enumerate(task_name_list):\n",
    "\n",
    "        use_chat_format = 'chatfmt' in task_name\n",
    "        chat_formatting_function = get_chat_formatting_function(model_name_or_path)\n",
    "\n",
    "        try:\n",
    "            with open(os.path.join(model_name_or_path, 'ft_args.json'), 'r') as f:\n",
    "                ft_args = json.load(f)\n",
    "            # note `model_name_or_path` could be anything, e.g., soft links with arbitrary names.\n",
    "            # but `ft_args_model_name_or_path` indicates the finetuned model name.\n",
    "            if 'model_args' in ft_args:\n",
    "                ft_args_model_name_or_path = ft_args['model_args']['model_name_or_path']\n",
    "            else:\n",
    "                ft_args_model_name_or_path = ft_args['model_name_or_path']\n",
    "        except:\n",
    "            ft_args_model_name_or_path = model_name_or_path\n",
    "\n",
    "        batch_size, job_duration = get_resource_for_task(\n",
    "            task_name, ft_args_model_name_or_path)\n",
    "\n",
    "        job_name = f'eval.{task_name}'\n",
    "        save_dir = f'{model_name_or_path}/eval/{task_name}'\n",
    "\n",
    "        if task_name.startswith('mmlu'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 5)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.mmlu.run_eval \\\n",
    "                --data_dir data/eval/mmlu \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --ntrain {n_shot} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('gsm'):\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 8)\n",
    "            # open-instruct used 200 examples. use higher amount to get a more accurate number\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.gsm.run_eval \\\n",
    "                --data_dir data/eval/gsm/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_num_examples 500 \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('bbh'):\n",
    "            max_num_examples_per_task = 40\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot <= 3)\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.bbh.run_eval \\\n",
    "                --data_dir data/eval/bbh/ \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens {512 if arch=='x86_64' else 256} \\\n",
    "                --n_shot {n_shot} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_cot' if 'cot' not in task_name else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--max_num_examples_per_task '+str(max_num_examples_per_task) if max_num_examples_per_task else ''} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('humaneval'):\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.codex_humaneval.run_eval \\\n",
    "                --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --max_new_tokens 512 \\\n",
    "                --eval_pass_at_ks 1 \\\n",
    "                --unbiased_sampling_size_n 3 \\\n",
    "                --temperature 0.1 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('tydiqa'):\n",
    "            no_context = 'cb' in task_name\n",
    "            match = re.search(r's=(\\d+)', task_name)\n",
    "            n_shot = int(match.group(1))\n",
    "            assert(n_shot in [0,1])\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.tydiqa.run_eval \\\n",
    "                --data_dir data/eval/tydiqa \\\n",
    "                --n_shot {n_shot} \\\n",
    "                --max_num_examples_per_lang 100 \\\n",
    "                --max_context_length 512 \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--no_context' if no_context else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('toxigen'):\n",
    "            # max_prompts_per_group=500 (out of 1000) is open-instruct default.\n",
    "            # eval batch size=1 much faster (llama-7b) not sure why.\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.toxigen.run_eval \\\n",
    "                --data_dir data/eval/toxigen \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size 1 \\\n",
    "                --max_prompts_per_group 200 \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('alpacafarm'):\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            annotators_config = match.group(1)\n",
    "            annotators_config = annotators_config.replace(':', '_')\n",
    "            if not annotators_config in ['chatgpt', 'alpaca_eval_gpt4_0314', 'gpt35_turbo_1106']:\n",
    "                raise ValueError('Just support 2 annotators_config.')\n",
    "            cmd = f\"\"\"\n",
    "            python -m eval.alpaca_farm.run_eval \\\n",
    "                --reference_path alpaca_eval_data \\\n",
    "                --model_name_or_path \"{model_name_or_path}\" \\\n",
    "                --max_new_tokens 2048 \\\n",
    "                --save_dir \"{save_dir}\" \\\n",
    "                --eval_batch_size {batch_size} \\\n",
    "                --annotators_config {annotators_config} \\\n",
    "                {'--use_vllm' if use_vllm else ''} \\\n",
    "                {'--use_chat_format' if use_chat_format else ''} \\\n",
    "                --chat_formatting_function {chat_formatting_function} \\\n",
    "                {'--use_slow_tokenizer' if use_slow_tokenizer else ''} \\\n",
    "                --torch_dtype {torch_dtype} \\\n",
    "            \"\"\"\n",
    "        elif task_name.startswith('mtbench'):\n",
    "            assert('chatfmt' in task_name)\n",
    "            match = re.search(r'ann=([^_]+)', task_name)\n",
    "            judge_model = match.group(1).replace(':', '-')\n",
    "            if not judge_model in OPENAI_MODEL_LIST:\n",
    "                raise ValueError('fastchat does not support the judge model.')\n",
    "            os.makedirs(save_dir, exist_ok=True) # since not using python file, make the directory now.\n",
    "            fastchat_mtbench_data_dir = os.path.normpath(os.path.join(open_instruct_dir, '../FastChat/fastchat/llm_judge/data'))\n",
    "            question_file = os.path.join(fastchat_mtbench_data_dir, 'mt_bench/question.jsonl')\n",
    "            rating_file = os.path.join(save_dir, f'{judge_model}_single.jsonl')\n",
    "            question_begin, question_end = (0, 1) if False else (None, None)\n",
    "            model_id = os.path.basename(model_name_or_path) if 'results/baselines' in save_dir else 'tulu'\n",
    "            cmd = \"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_model_answer \\\n",
    "                    --model-path {model_name_or_path} \\\n",
    "                    --model-id {model_id} \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --question-file {question_file} \\\n",
    "                    {'--question-begin '+str(question_begin) if question_begin else ''} \\\n",
    "                    {'--question-end '+str(question_end) if question_end else ''} \\\n",
    "                    --max-new-token 2048 \\\n",
    "                    --answer-file {os.path.join(save_dir, 'model_answer.jsonl')} \\\n",
    "                    --dtype {torch_dtype} \\\n",
    "                && \\\n",
    "            \"\"\"\n",
    "            cmd += f\"\"\"\n",
    "                python -m fastchat.llm_judge.gen_judgment \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --judge-file {os.path.join(fastchat_mtbench_data_dir, 'judge_prompts.jsonl')} \\\n",
    "                    --judge-model {judge_model} \\\n",
    "                    --mode single \\\n",
    "                    --question-file {question_file} \\\n",
    "                    --answer-dir {save_dir} \\\n",
    "                    --ref-answer-dir {os.path.join(fastchat_mtbench_data_dir, 'mt_bench/reference_answer')} \\\n",
    "                    --output-file {rating_file} \\\n",
    "                && \\\n",
    "                python -m fastchat.llm_judge.show_result \\\n",
    "                    --bench-name mt_bench \\\n",
    "                    --input-file {rating_file} \\\n",
    "                    --mode single \\\n",
    "                    --save-to-json\n",
    "            \"\"\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'{task_name} not supported.')\n",
    "\n",
    "        if test_run:\n",
    "            print('\\n'+' \\\\\\n\\t'.join([x.strip() for x in re.split(r'\\s{3,}', cmd.strip())]))\n",
    "\n",
    "        cmd = multiline_to_singleline(cmd)\n",
    "        cmds.append(cmd)\n",
    "        cmds_per_model.append(cmd)\n",
    "        \n",
    "        if launch_one_job_per_model:\n",
    "            shell_scripts = shell_scripts_template.format(\n",
    "                conda_env='open-instruct',\n",
    "                cwd=os.path.dirname(os.getcwd()),\n",
    "                cmd=cmd,\n",
    "                log_dir=os.getcwd(),\n",
    "                save_dir=save_dir,\n",
    "            )\n",
    "            if arch == 'x86_64': # ccc\n",
    "                shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "            out = submit_job(\n",
    "                shell_scripts, \n",
    "                job_name=job_name,\n",
    "                num_cpus=num_cpus,\n",
    "                cpu_mem=cpu_mem,\n",
    "                num_gpus=num_gpus,\n",
    "                gpu_type=gpu_type,\n",
    "                test_run=test_run,\n",
    "                job_duration=job_duration,\n",
    "                queue=queue,\n",
    "            )\n",
    "        else:\n",
    "            if i + 1 == num_tasks:\n",
    "                assert(len(cmds_per_model) == num_tasks)\n",
    "                cmd = ' && '.join(cmds_per_model)\n",
    "                if test_run:\n",
    "                    print(cmd)\n",
    "                shell_scripts = shell_scripts_template.format(\n",
    "                    conda_env='open-instruct',\n",
    "                    cwd=os.path.dirname(os.getcwd()),\n",
    "                    cmd=cmd,\n",
    "                    log_dir=os.getcwd(),\n",
    "                    save_dir=os.getcwd(), # just delete afterwards.\n",
    "                )\n",
    "                if arch == 'x86_64': # ccc\n",
    "                    shell_scripts = re.sub('~/.profile', '/dccstor/data-pruning/.profile', shell_scripts)\n",
    "                out = submit_job(\n",
    "                    shell_scripts, \n",
    "                    job_name=f'eval.{os.path.basename(model_name_or_path)}',\n",
    "                    num_cpus=num_cpus,\n",
    "                    cpu_mem=cpu_mem,\n",
    "                    num_gpus=num_gpus,\n",
    "                    gpu_type=gpu_type,\n",
    "                    test_run=test_run,\n",
    "                    job_duration=6,\n",
    "                    queue=None if getpass.getuser() in ('PTFMqngp', 'wpq') else 'alt_6b',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea7ac978",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_cmds_eval.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')[-1]\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3939309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ CUDA_VISIBLE_DEVICES=1\n",
      "+ python -m fastchat.llm_judge.gen_model_answer --model-path results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3 --model-id tulu --bench-name mt_bench --question-file /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl --max-new-token 2048 --answer-file results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/model_answer.jsonl --dtype float16\n",
      "[2024-01-21 02:03:12,731] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Output to results/dpo2_ultrafeedback:llama-7b+sharegptv2ep2/llama-7b+sharegptv2ep2_ultrafeedback_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3/eval/mtbench_ann=gpt:4:1106:preview_chatfmt/model_answer.jsonl\n",
      "Loading checkpoint shards:   0%|                          | 0/6 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "!bash gen_cmds_eval.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859d6d6",
   "metadata": {},
   "source": [
    "# Visualize Eval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b033ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./1387915.out does not have `--save_dir` specified. Probably still running.\n",
      "./1387916.out does not have `--save_dir` specified. Probably still running.\n",
      "Job ./1387899.out exited with error code. --save_dir=results/oi5_dolly:llama-7b/llama-7b_dolly_score=random:s=0_pace=prune:size=30000:ep=3/eval/alpacafarm_ann=chatgpt_chatfmt\n"
     ]
    }
   ],
   "source": [
    "# if job successfully ran, lsf system will generate a summary in log_dir,\n",
    "# call this function to move lsf summary to save_dir if job is successful.\n",
    "move_lsf_job_summary_to_save_dir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4392e9ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_fmt=mix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/2846006903.py:382: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/2846006903.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_345b8 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_345b8_row0_col0, #T_345b8_row1_col0, #T_345b8_row2_col0, #T_345b8_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_345b8_row0_col1, #T_345b8_row1_col1, #T_345b8_row2_col1, #T_345b8_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_345b8_row0_col2, #T_345b8_row0_col3, #T_345b8_row0_col4, #T_345b8_row0_col5, #T_345b8_row0_col6, #T_345b8_row0_col7, #T_345b8_row0_col8, #T_345b8_row0_col9, #T_345b8_row0_col10, #T_345b8_row0_col12, #T_345b8_row0_col16, #T_345b8_row0_col17, #T_345b8_row1_col10, #T_345b8_row1_col11, #T_345b8_row2_col13, #T_345b8_row2_col14, #T_345b8_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row0_col11, #T_345b8_row0_col14, #T_345b8_row0_col15, #T_345b8_row1_col4, #T_345b8_row1_col6, #T_345b8_row1_col8, #T_345b8_row1_col9, #T_345b8_row2_col10, #T_345b8_row3_col2, #T_345b8_row3_col3, #T_345b8_row3_col5, #T_345b8_row3_col7, #T_345b8_row3_col12, #T_345b8_row3_col13, #T_345b8_row3_col16, #T_345b8_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row0_col13, #T_345b8_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #d65244;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row1_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row2_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row3_col6, #T_345b8_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_345b8_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_345b8_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_345b8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_345b8_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_345b8_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_345b8_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_345b8_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_345b8_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_345b8_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_345b8_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_345b8_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_345b8_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_345b8_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_345b8_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_345b8_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_345b8_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_345b8_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_345b8_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_345b8_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_345b8_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_345b8_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_345b8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_345b8_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_345b8_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_345b8_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_345b8_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_345b8_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_345b8_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_345b8_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_345b8_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_345b8_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_345b8_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_345b8_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_345b8_row0_col11\" class=\"data row0 col11\" >20.1</td>\n",
       "      <td id=\"T_345b8_row0_col12\" class=\"data row0 col12\" >319.7</td>\n",
       "      <td id=\"T_345b8_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_345b8_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_345b8_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_345b8_row0_col16\" class=\"data row0 col16\" >45.6</td>\n",
       "      <td id=\"T_345b8_row0_col17\" class=\"data row0 col17\" >-7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_345b8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_345b8_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_345b8_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_345b8_row1_col2\" class=\"data row1 col2\" >34.7</td>\n",
       "      <td id=\"T_345b8_row1_col3\" class=\"data row1 col3\" >37.0</td>\n",
       "      <td id=\"T_345b8_row1_col4\" class=\"data row1 col4\" >3.4</td>\n",
       "      <td id=\"T_345b8_row1_col5\" class=\"data row1 col5\" >10.0</td>\n",
       "      <td id=\"T_345b8_row1_col6\" class=\"data row1 col6\" >30.9</td>\n",
       "      <td id=\"T_345b8_row1_col7\" class=\"data row1 col7\" >30.1</td>\n",
       "      <td id=\"T_345b8_row1_col8\" class=\"data row1 col8\" >6.4</td>\n",
       "      <td id=\"T_345b8_row1_col9\" class=\"data row1 col9\" >35.4</td>\n",
       "      <td id=\"T_345b8_row1_col10\" class=\"data row1 col10\" >10.4</td>\n",
       "      <td id=\"T_345b8_row1_col11\" class=\"data row1 col11\" >37.5</td>\n",
       "      <td id=\"T_345b8_row1_col12\" class=\"data row1 col12\" >298.0</td>\n",
       "      <td id=\"T_345b8_row1_col13\" class=\"data row1 col13\" >33.6</td>\n",
       "      <td id=\"T_345b8_row1_col14\" class=\"data row1 col14\" >18.1</td>\n",
       "      <td id=\"T_345b8_row1_col15\" class=\"data row1 col15\" >25.9</td>\n",
       "      <td id=\"T_345b8_row1_col16\" class=\"data row1 col16\" >43.7</td>\n",
       "      <td id=\"T_345b8_row1_col17\" class=\"data row1 col17\" >-10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_345b8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_345b8_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_345b8_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_345b8_row2_col2\" class=\"data row2 col2\" >33.3</td>\n",
       "      <td id=\"T_345b8_row2_col3\" class=\"data row2 col3\" >37.1</td>\n",
       "      <td id=\"T_345b8_row2_col4\" class=\"data row2 col4\" >4.6</td>\n",
       "      <td id=\"T_345b8_row2_col5\" class=\"data row2 col5\" >9.4</td>\n",
       "      <td id=\"T_345b8_row2_col6\" class=\"data row2 col6\" >31.4</td>\n",
       "      <td id=\"T_345b8_row2_col7\" class=\"data row2 col7\" >28.7</td>\n",
       "      <td id=\"T_345b8_row2_col8\" class=\"data row2 col8\" >7.3</td>\n",
       "      <td id=\"T_345b8_row2_col9\" class=\"data row2 col9\" >35.9</td>\n",
       "      <td id=\"T_345b8_row2_col10\" class=\"data row2 col10\" >7.5</td>\n",
       "      <td id=\"T_345b8_row2_col11\" class=\"data row2 col11\" >33.9</td>\n",
       "      <td id=\"T_345b8_row2_col12\" class=\"data row2 col12\" >172.6</td>\n",
       "      <td id=\"T_345b8_row2_col13\" class=\"data row2 col13\" >38.2</td>\n",
       "      <td id=\"T_345b8_row2_col14\" class=\"data row2 col14\" >20.0</td>\n",
       "      <td id=\"T_345b8_row2_col15\" class=\"data row2 col15\" >29.1</td>\n",
       "      <td id=\"T_345b8_row2_col16\" class=\"data row2 col16\" >34.9</td>\n",
       "      <td id=\"T_345b8_row2_col17\" class=\"data row2 col17\" >-10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_345b8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_345b8_row3_col0\" class=\"data row3 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_345b8_row3_col1\" class=\"data row3 col1\" >10000</td>\n",
       "      <td id=\"T_345b8_row3_col2\" class=\"data row3 col2\" >30.9</td>\n",
       "      <td id=\"T_345b8_row3_col3\" class=\"data row3 col3\" >34.8</td>\n",
       "      <td id=\"T_345b8_row3_col4\" class=\"data row3 col4\" >5.0</td>\n",
       "      <td id=\"T_345b8_row3_col5\" class=\"data row3 col5\" >8.4</td>\n",
       "      <td id=\"T_345b8_row3_col6\" class=\"data row3 col6\" >32.9</td>\n",
       "      <td id=\"T_345b8_row3_col7\" class=\"data row3 col7\" >25.7</td>\n",
       "      <td id=\"T_345b8_row3_col8\" class=\"data row3 col8\" >8.0</td>\n",
       "      <td id=\"T_345b8_row3_col9\" class=\"data row3 col9\" >41.0</td>\n",
       "      <td id=\"T_345b8_row3_col10\" class=\"data row3 col10\" >7.9</td>\n",
       "      <td id=\"T_345b8_row3_col11\" class=\"data row3 col11\" >28.2</td>\n",
       "      <td id=\"T_345b8_row3_col12\" class=\"data row3 col12\" >101.5</td>\n",
       "      <td id=\"T_345b8_row3_col13\" class=\"data row3 col13\" >33.2</td>\n",
       "      <td id=\"T_345b8_row3_col14\" class=\"data row3 col14\" >17.7</td>\n",
       "      <td id=\"T_345b8_row3_col15\" class=\"data row3 col15\" >25.5</td>\n",
       "      <td id=\"T_345b8_row3_col16\" class=\"data row3 col16\" >28.6</td>\n",
       "      <td id=\"T_345b8_row3_col17\" class=\"data row3 col17\" >-11.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee2397760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/2846006903.py:382: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/2846006903.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8e13a td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_8e13a_row0_col0, #T_8e13a_row1_col0, #T_8e13a_row2_col0, #T_8e13a_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8e13a_row0_col1, #T_8e13a_row1_col1, #T_8e13a_row2_col1, #T_8e13a_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8e13a_row0_col2, #T_8e13a_row0_col3, #T_8e13a_row0_col5, #T_8e13a_row0_col7, #T_8e13a_row0_col9, #T_8e13a_row0_col10, #T_8e13a_row0_col13, #T_8e13a_row0_col14, #T_8e13a_row0_col15, #T_8e13a_row0_col16, #T_8e13a_row1_col4, #T_8e13a_row1_col6, #T_8e13a_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e13a_row0_col4, #T_8e13a_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row0_col6, #T_8e13a_row0_col11, #T_8e13a_row0_col12, #T_8e13a_row0_col17, #T_8e13a_row1_col10, #T_8e13a_row1_col11, #T_8e13a_row1_col12, #T_8e13a_row1_col14, #T_8e13a_row1_col17, #T_8e13a_row2_col2, #T_8e13a_row2_col3, #T_8e13a_row2_col7, #T_8e13a_row2_col9, #T_8e13a_row2_col11, #T_8e13a_row2_col12, #T_8e13a_row2_col17, #T_8e13a_row3_col4, #T_8e13a_row3_col5, #T_8e13a_row3_col8, #T_8e13a_row3_col11, #T_8e13a_row3_col12, #T_8e13a_row3_col13, #T_8e13a_row3_col15, #T_8e13a_row3_col16, #T_8e13a_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e13a_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e13a_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e13a_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e13a_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e13a_row2_col5, #T_8e13a_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e13a_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e13a_row2_col13, #T_8e13a_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e13a_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8e13a_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8e13a_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8e13a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8e13a_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_8e13a_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_8e13a_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_8e13a_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_8e13a_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_8e13a_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_8e13a_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_8e13a_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_8e13a_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_8e13a_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_8e13a_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_8e13a_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_8e13a_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_8e13a_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_8e13a_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_8e13a_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_8e13a_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_8e13a_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8e13a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8e13a_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_8e13a_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_8e13a_row0_col2\" class=\"data row0 col2\" >39.0</td>\n",
       "      <td id=\"T_8e13a_row0_col3\" class=\"data row0 col3\" >38.8</td>\n",
       "      <td id=\"T_8e13a_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_8e13a_row0_col5\" class=\"data row0 col5\" >16.0</td>\n",
       "      <td id=\"T_8e13a_row0_col6\" class=\"data row0 col6\" >29.9</td>\n",
       "      <td id=\"T_8e13a_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_8e13a_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_8e13a_row0_col9\" class=\"data row0 col9\" >34.9</td>\n",
       "      <td id=\"T_8e13a_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_8e13a_row0_col11\" class=\"data row0 col11\" >45.8</td>\n",
       "      <td id=\"T_8e13a_row0_col12\" class=\"data row0 col12\" >279.4</td>\n",
       "      <td id=\"T_8e13a_row0_col13\" class=\"data row0 col13\" >54.4</td>\n",
       "      <td id=\"T_8e13a_row0_col14\" class=\"data row0 col14\" >36.0</td>\n",
       "      <td id=\"T_8e13a_row0_col15\" class=\"data row0 col15\" >45.3</td>\n",
       "      <td id=\"T_8e13a_row0_col16\" class=\"data row0 col16\" >48.7</td>\n",
       "      <td id=\"T_8e13a_row0_col17\" class=\"data row0 col17\" >-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e13a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8e13a_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_8e13a_row1_col1\" class=\"data row1 col1\" >10000</td>\n",
       "      <td id=\"T_8e13a_row1_col2\" class=\"data row1 col2\" >32.9</td>\n",
       "      <td id=\"T_8e13a_row1_col3\" class=\"data row1 col3\" >34.7</td>\n",
       "      <td id=\"T_8e13a_row1_col4\" class=\"data row1 col4\" >6.8</td>\n",
       "      <td id=\"T_8e13a_row1_col5\" class=\"data row1 col5\" >12.0</td>\n",
       "      <td id=\"T_8e13a_row1_col6\" class=\"data row1 col6\" >35.0</td>\n",
       "      <td id=\"T_8e13a_row1_col7\" class=\"data row1 col7\" >31.4</td>\n",
       "      <td id=\"T_8e13a_row1_col8\" class=\"data row1 col8\" >8.9</td>\n",
       "      <td id=\"T_8e13a_row1_col9\" class=\"data row1 col9\" >32.1</td>\n",
       "      <td id=\"T_8e13a_row1_col10\" class=\"data row1 col10\" >8.7</td>\n",
       "      <td id=\"T_8e13a_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_8e13a_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_8e13a_row1_col13\" class=\"data row1 col13\" >46.0</td>\n",
       "      <td id=\"T_8e13a_row1_col14\" class=\"data row1 col14\" >31.8</td>\n",
       "      <td id=\"T_8e13a_row1_col15\" class=\"data row1 col15\" >38.9</td>\n",
       "      <td id=\"T_8e13a_row1_col16\" class=\"data row1 col16\" >26.6</td>\n",
       "      <td id=\"T_8e13a_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e13a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8e13a_row2_col0\" class=\"data row2 col0\" >score=random:s=\\d_pace=prune:size=10000:ep=10_avg (N=1)</td>\n",
       "      <td id=\"T_8e13a_row2_col1\" class=\"data row2 col1\" >10000</td>\n",
       "      <td id=\"T_8e13a_row2_col2\" class=\"data row2 col2\" >30.9</td>\n",
       "      <td id=\"T_8e13a_row2_col3\" class=\"data row2 col3\" >33.0</td>\n",
       "      <td id=\"T_8e13a_row2_col4\" class=\"data row2 col4\" >6.4</td>\n",
       "      <td id=\"T_8e13a_row2_col5\" class=\"data row2 col5\" >13.6</td>\n",
       "      <td id=\"T_8e13a_row2_col6\" class=\"data row2 col6\" >33.5</td>\n",
       "      <td id=\"T_8e13a_row2_col7\" class=\"data row2 col7\" >30.7</td>\n",
       "      <td id=\"T_8e13a_row2_col8\" class=\"data row2 col8\" >7.3</td>\n",
       "      <td id=\"T_8e13a_row2_col9\" class=\"data row2 col9\" >28.3</td>\n",
       "      <td id=\"T_8e13a_row2_col10\" class=\"data row2 col10\" >12.2</td>\n",
       "      <td id=\"T_8e13a_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_8e13a_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_8e13a_row2_col13\" class=\"data row2 col13\" >46.4</td>\n",
       "      <td id=\"T_8e13a_row2_col14\" class=\"data row2 col14\" >34.0</td>\n",
       "      <td id=\"T_8e13a_row2_col15\" class=\"data row2 col15\" >40.2</td>\n",
       "      <td id=\"T_8e13a_row2_col16\" class=\"data row2 col16\" >26.4</td>\n",
       "      <td id=\"T_8e13a_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e13a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8e13a_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=10000:ep=10</td>\n",
       "      <td id=\"T_8e13a_row3_col1\" class=\"data row3 col1\" >10000</td>\n",
       "      <td id=\"T_8e13a_row3_col2\" class=\"data row3 col2\" >31.7</td>\n",
       "      <td id=\"T_8e13a_row3_col3\" class=\"data row3 col3\" >37.0</td>\n",
       "      <td id=\"T_8e13a_row3_col4\" class=\"data row3 col4\" >6.0</td>\n",
       "      <td id=\"T_8e13a_row3_col5\" class=\"data row3 col5\" >9.6</td>\n",
       "      <td id=\"T_8e13a_row3_col6\" class=\"data row3 col6\" >31.2</td>\n",
       "      <td id=\"T_8e13a_row3_col7\" class=\"data row3 col7\" >33.1</td>\n",
       "      <td id=\"T_8e13a_row3_col8\" class=\"data row3 col8\" >7.0</td>\n",
       "      <td id=\"T_8e13a_row3_col9\" class=\"data row3 col9\" >30.0</td>\n",
       "      <td id=\"T_8e13a_row3_col10\" class=\"data row3 col10\" >11.8</td>\n",
       "      <td id=\"T_8e13a_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_8e13a_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_8e13a_row3_col13\" class=\"data row3 col13\" >43.5</td>\n",
       "      <td id=\"T_8e13a_row3_col14\" class=\"data row3 col14\" >31.9</td>\n",
       "      <td id=\"T_8e13a_row3_col15\" class=\"data row3 col15\" >37.7</td>\n",
       "      <td id=\"T_8e13a_row3_col16\" class=\"data row3 col16\" >25.9</td>\n",
       "      <td id=\"T_8e13a_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee23966e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/2846006903.py:382: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/2846006903.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8ad24 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_8ad24_row0_col0, #T_8ad24_row1_col0, #T_8ad24_row2_col0, #T_8ad24_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8ad24_row0_col1, #T_8ad24_row1_col1, #T_8ad24_row2_col1, #T_8ad24_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8ad24_row0_col2, #T_8ad24_row0_col5, #T_8ad24_row0_col8, #T_8ad24_row0_col9, #T_8ad24_row0_col12, #T_8ad24_row0_col16, #T_8ad24_row0_col17, #T_8ad24_row1_col10, #T_8ad24_row1_col14, #T_8ad24_row2_col3, #T_8ad24_row2_col4, #T_8ad24_row2_col7, #T_8ad24_row2_col11, #T_8ad24_row3_col6, #T_8ad24_row3_col13, #T_8ad24_row3_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row0_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row0_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #cf453c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8ad24_row0_col10, #T_8ad24_row0_col11, #T_8ad24_row0_col13, #T_8ad24_row0_col14, #T_8ad24_row0_col15, #T_8ad24_row1_col2, #T_8ad24_row1_col3, #T_8ad24_row1_col6, #T_8ad24_row1_col7, #T_8ad24_row2_col8, #T_8ad24_row2_col9, #T_8ad24_row2_col10, #T_8ad24_row3_col4, #T_8ad24_row3_col5, #T_8ad24_row3_col7, #T_8ad24_row3_col12, #T_8ad24_row3_col16, #T_8ad24_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8ad24_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8ad24_row1_col8, #T_8ad24_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8ad24_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8ad24_row1_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row1_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8ad24_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8ad24_row1_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8ad24_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row1_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row2_col12 {\n",
       "  text-align: left;\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row2_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #eed0c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8ad24_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8ad24_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8ad24_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8ad24_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_8ad24_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row3_col11 {\n",
       "  text-align: left;\n",
       "  background-color: #ee8669;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_8ad24_row3_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8ad24\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8ad24_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_8ad24_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_8ad24_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_8ad24_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_8ad24_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_8ad24_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_8ad24_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_8ad24_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_8ad24_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_8ad24_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_8ad24_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_8ad24_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_8ad24_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_8ad24_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_8ad24_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_8ad24_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_8ad24_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_8ad24_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8ad24_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8ad24_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_8ad24_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_8ad24_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_8ad24_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_8ad24_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_8ad24_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_8ad24_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_8ad24_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_8ad24_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_8ad24_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_8ad24_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_8ad24_row0_col11\" class=\"data row0 col11\" >20.1</td>\n",
       "      <td id=\"T_8ad24_row0_col12\" class=\"data row0 col12\" >319.7</td>\n",
       "      <td id=\"T_8ad24_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_8ad24_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_8ad24_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_8ad24_row0_col16\" class=\"data row0 col16\" >45.6</td>\n",
       "      <td id=\"T_8ad24_row0_col17\" class=\"data row0 col17\" >-7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ad24_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8ad24_row1_col0\" class=\"data row1 col0\" >llama-7b_dolly_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_8ad24_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_8ad24_row1_col2\" class=\"data row1 col2\" >36.1</td>\n",
       "      <td id=\"T_8ad24_row1_col3\" class=\"data row1 col3\" >35.0</td>\n",
       "      <td id=\"T_8ad24_row1_col4\" class=\"data row1 col4\" >4.4</td>\n",
       "      <td id=\"T_8ad24_row1_col5\" class=\"data row1 col5\" >10.2</td>\n",
       "      <td id=\"T_8ad24_row1_col6\" class=\"data row1 col6\" >31.2</td>\n",
       "      <td id=\"T_8ad24_row1_col7\" class=\"data row1 col7\" >30.3</td>\n",
       "      <td id=\"T_8ad24_row1_col8\" class=\"data row1 col8\" >8.6</td>\n",
       "      <td id=\"T_8ad24_row1_col9\" class=\"data row1 col9\" >42.1</td>\n",
       "      <td id=\"T_8ad24_row1_col10\" class=\"data row1 col10\" >11.6</td>\n",
       "      <td id=\"T_8ad24_row1_col11\" class=\"data row1 col11\" >26.7</td>\n",
       "      <td id=\"T_8ad24_row1_col12\" class=\"data row1 col12\" >277.6</td>\n",
       "      <td id=\"T_8ad24_row1_col13\" class=\"data row1 col13\" >35.8</td>\n",
       "      <td id=\"T_8ad24_row1_col14\" class=\"data row1 col14\" >19.7</td>\n",
       "      <td id=\"T_8ad24_row1_col15\" class=\"data row1 col15\" >27.8</td>\n",
       "      <td id=\"T_8ad24_row1_col16\" class=\"data row1 col16\" >42.6</td>\n",
       "      <td id=\"T_8ad24_row1_col17\" class=\"data row1 col17\" >-8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ad24_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8ad24_row2_col0\" class=\"data row2 col0\" >llama-7b_dolly_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_8ad24_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_8ad24_row2_col2\" class=\"data row2 col2\" >36.6</td>\n",
       "      <td id=\"T_8ad24_row2_col3\" class=\"data row2 col3\" >39.2</td>\n",
       "      <td id=\"T_8ad24_row2_col4\" class=\"data row2 col4\" >5.6</td>\n",
       "      <td id=\"T_8ad24_row2_col5\" class=\"data row2 col5\" >9.6</td>\n",
       "      <td id=\"T_8ad24_row2_col6\" class=\"data row2 col6\" >33.5</td>\n",
       "      <td id=\"T_8ad24_row2_col7\" class=\"data row2 col7\" >33.1</td>\n",
       "      <td id=\"T_8ad24_row2_col8\" class=\"data row2 col8\" >7.5</td>\n",
       "      <td id=\"T_8ad24_row2_col9\" class=\"data row2 col9\" >37.7</td>\n",
       "      <td id=\"T_8ad24_row2_col10\" class=\"data row2 col10\" >10.4</td>\n",
       "      <td id=\"T_8ad24_row2_col11\" class=\"data row2 col11\" >28.1</td>\n",
       "      <td id=\"T_8ad24_row2_col12\" class=\"data row2 col12\" >263.1</td>\n",
       "      <td id=\"T_8ad24_row2_col13\" class=\"data row2 col13\" >38.5</td>\n",
       "      <td id=\"T_8ad24_row2_col14\" class=\"data row2 col14\" >19.5</td>\n",
       "      <td id=\"T_8ad24_row2_col15\" class=\"data row2 col15\" >29.1</td>\n",
       "      <td id=\"T_8ad24_row2_col16\" class=\"data row2 col16\" >42.3</td>\n",
       "      <td id=\"T_8ad24_row2_col17\" class=\"data row2 col17\" >-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ad24_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8ad24_row3_col0\" class=\"data row3 col0\" >llama-7b_dolly_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_8ad24_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_8ad24_row3_col2\" class=\"data row3 col2\" >36.9</td>\n",
       "      <td id=\"T_8ad24_row3_col3\" class=\"data row3 col3\" >37.1</td>\n",
       "      <td id=\"T_8ad24_row3_col4\" class=\"data row3 col4\" >3.0</td>\n",
       "      <td id=\"T_8ad24_row3_col5\" class=\"data row3 col5\" >9.4</td>\n",
       "      <td id=\"T_8ad24_row3_col6\" class=\"data row3 col6\" >34.1</td>\n",
       "      <td id=\"T_8ad24_row3_col7\" class=\"data row3 col7\" >30.3</td>\n",
       "      <td id=\"T_8ad24_row3_col8\" class=\"data row3 col8\" >8.0</td>\n",
       "      <td id=\"T_8ad24_row3_col9\" class=\"data row3 col9\" >40.9</td>\n",
       "      <td id=\"T_8ad24_row3_col10\" class=\"data row3 col10\" >10.6</td>\n",
       "      <td id=\"T_8ad24_row3_col11\" class=\"data row3 col11\" >26.5</td>\n",
       "      <td id=\"T_8ad24_row3_col12\" class=\"data row3 col12\" >260.5</td>\n",
       "      <td id=\"T_8ad24_row3_col13\" class=\"data row3 col13\" >40.1</td>\n",
       "      <td id=\"T_8ad24_row3_col14\" class=\"data row3 col14\" >18.2</td>\n",
       "      <td id=\"T_8ad24_row3_col15\" class=\"data row3 col15\" >29.4</td>\n",
       "      <td id=\"T_8ad24_row3_col16\" class=\"data row3 col16\" >41.8</td>\n",
       "      <td id=\"T_8ad24_row3_col17\" class=\"data row3 col17\" >-8.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee2394790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/2846006903.py:382: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/2846006903.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2fabc td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_2fabc_row0_col0, #T_2fabc_row1_col0, #T_2fabc_row2_col0, #T_2fabc_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2fabc_row0_col1, #T_2fabc_row1_col1, #T_2fabc_row2_col1, #T_2fabc_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2fabc_row0_col2, #T_2fabc_row0_col3, #T_2fabc_row0_col4, #T_2fabc_row0_col5, #T_2fabc_row0_col9, #T_2fabc_row0_col13, #T_2fabc_row0_col16, #T_2fabc_row1_col14, #T_2fabc_row1_col15, #T_2fabc_row2_col7, #T_2fabc_row3_col6, #T_2fabc_row3_col8, #T_2fabc_row3_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2fabc_row0_col6, #T_2fabc_row0_col11, #T_2fabc_row0_col12, #T_2fabc_row0_col17, #T_2fabc_row1_col7, #T_2fabc_row1_col10, #T_2fabc_row1_col11, #T_2fabc_row1_col12, #T_2fabc_row1_col17, #T_2fabc_row2_col8, #T_2fabc_row2_col9, #T_2fabc_row2_col11, #T_2fabc_row2_col12, #T_2fabc_row2_col17, #T_2fabc_row3_col2, #T_2fabc_row3_col3, #T_2fabc_row3_col4, #T_2fabc_row3_col5, #T_2fabc_row3_col11, #T_2fabc_row3_col12, #T_2fabc_row3_col13, #T_2fabc_row3_col14, #T_2fabc_row3_col15, #T_2fabc_row3_col16, #T_2fabc_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2fabc_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2fabc_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2fabc_row0_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2fabc_row0_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2fabc_row0_col15, #T_2fabc_row2_col14 {\n",
       "  text-align: left;\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2fabc_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2fabc_row1_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2fabc_row1_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2fabc_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2fabc_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2fabc_row1_col8, #T_2fabc_row1_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2fabc_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #f6bea4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2fabc_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2fabc_row2_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2fabc_row2_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2fabc_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2fabc_row2_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2fabc_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2fabc_row2_col10, #T_2fabc_row2_col15 {\n",
       "  text-align: left;\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2fabc_row2_col13 {\n",
       "  text-align: left;\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2fabc_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2fabc_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2fabc_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2fabc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2fabc_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_2fabc_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_2fabc_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_2fabc_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_2fabc_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_2fabc_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_2fabc_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_2fabc_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_2fabc_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_2fabc_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_2fabc_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_2fabc_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_2fabc_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_2fabc_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_2fabc_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_2fabc_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_2fabc_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_2fabc_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2fabc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2fabc_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_2fabc_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_2fabc_row0_col2\" class=\"data row0 col2\" >39.0</td>\n",
       "      <td id=\"T_2fabc_row0_col3\" class=\"data row0 col3\" >38.8</td>\n",
       "      <td id=\"T_2fabc_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_2fabc_row0_col5\" class=\"data row0 col5\" >16.0</td>\n",
       "      <td id=\"T_2fabc_row0_col6\" class=\"data row0 col6\" >29.9</td>\n",
       "      <td id=\"T_2fabc_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_2fabc_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_2fabc_row0_col9\" class=\"data row0 col9\" >34.9</td>\n",
       "      <td id=\"T_2fabc_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_2fabc_row0_col11\" class=\"data row0 col11\" >45.8</td>\n",
       "      <td id=\"T_2fabc_row0_col12\" class=\"data row0 col12\" >279.4</td>\n",
       "      <td id=\"T_2fabc_row0_col13\" class=\"data row0 col13\" >54.4</td>\n",
       "      <td id=\"T_2fabc_row0_col14\" class=\"data row0 col14\" >36.0</td>\n",
       "      <td id=\"T_2fabc_row0_col15\" class=\"data row0 col15\" >45.3</td>\n",
       "      <td id=\"T_2fabc_row0_col16\" class=\"data row0 col16\" >48.7</td>\n",
       "      <td id=\"T_2fabc_row0_col17\" class=\"data row0 col17\" >-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fabc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2fabc_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_2fabc_row1_col1\" class=\"data row1 col1\" >30000</td>\n",
       "      <td id=\"T_2fabc_row1_col2\" class=\"data row1 col2\" >37.9</td>\n",
       "      <td id=\"T_2fabc_row1_col3\" class=\"data row1 col3\" >37.7</td>\n",
       "      <td id=\"T_2fabc_row1_col4\" class=\"data row1 col4\" >6.0</td>\n",
       "      <td id=\"T_2fabc_row1_col5\" class=\"data row1 col5\" >13.0</td>\n",
       "      <td id=\"T_2fabc_row1_col6\" class=\"data row1 col6\" >30.6</td>\n",
       "      <td id=\"T_2fabc_row1_col7\" class=\"data row1 col7\" >33.9</td>\n",
       "      <td id=\"T_2fabc_row1_col8\" class=\"data row1 col8\" >8.7</td>\n",
       "      <td id=\"T_2fabc_row1_col9\" class=\"data row1 col9\" >33.6</td>\n",
       "      <td id=\"T_2fabc_row1_col10\" class=\"data row1 col10\" >11.4</td>\n",
       "      <td id=\"T_2fabc_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_2fabc_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_2fabc_row1_col13\" class=\"data row1 col13\" >53.1</td>\n",
       "      <td id=\"T_2fabc_row1_col14\" class=\"data row1 col14\" >40.5</td>\n",
       "      <td id=\"T_2fabc_row1_col15\" class=\"data row1 col15\" >46.9</td>\n",
       "      <td id=\"T_2fabc_row1_col16\" class=\"data row1 col16\" >29.4</td>\n",
       "      <td id=\"T_2fabc_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fabc_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_2fabc_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_2fabc_row2_col1\" class=\"data row2 col1\" >30000</td>\n",
       "      <td id=\"T_2fabc_row2_col2\" class=\"data row2 col2\" >35.0</td>\n",
       "      <td id=\"T_2fabc_row2_col3\" class=\"data row2 col3\" >35.7</td>\n",
       "      <td id=\"T_2fabc_row2_col4\" class=\"data row2 col4\" >5.8</td>\n",
       "      <td id=\"T_2fabc_row2_col5\" class=\"data row2 col5\" >14.4</td>\n",
       "      <td id=\"T_2fabc_row2_col6\" class=\"data row2 col6\" >32.8</td>\n",
       "      <td id=\"T_2fabc_row2_col7\" class=\"data row2 col7\" >34.5</td>\n",
       "      <td id=\"T_2fabc_row2_col8\" class=\"data row2 col8\" >7.5</td>\n",
       "      <td id=\"T_2fabc_row2_col9\" class=\"data row2 col9\" >31.3</td>\n",
       "      <td id=\"T_2fabc_row2_col10\" class=\"data row2 col10\" >12.8</td>\n",
       "      <td id=\"T_2fabc_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_2fabc_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_2fabc_row2_col13\" class=\"data row2 col13\" >48.6</td>\n",
       "      <td id=\"T_2fabc_row2_col14\" class=\"data row2 col14\" >39.2</td>\n",
       "      <td id=\"T_2fabc_row2_col15\" class=\"data row2 col15\" >44.0</td>\n",
       "      <td id=\"T_2fabc_row2_col16\" class=\"data row2 col16\" >28.5</td>\n",
       "      <td id=\"T_2fabc_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2fabc_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_2fabc_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=30000:ep=3</td>\n",
       "      <td id=\"T_2fabc_row3_col1\" class=\"data row3 col1\" >30000</td>\n",
       "      <td id=\"T_2fabc_row3_col2\" class=\"data row3 col2\" >33.9</td>\n",
       "      <td id=\"T_2fabc_row3_col3\" class=\"data row3 col3\" >35.2</td>\n",
       "      <td id=\"T_2fabc_row3_col4\" class=\"data row3 col4\" >5.2</td>\n",
       "      <td id=\"T_2fabc_row3_col5\" class=\"data row3 col5\" >11.0</td>\n",
       "      <td id=\"T_2fabc_row3_col6\" class=\"data row3 col6\" >34.1</td>\n",
       "      <td id=\"T_2fabc_row3_col7\" class=\"data row3 col7\" >34.2</td>\n",
       "      <td id=\"T_2fabc_row3_col8\" class=\"data row3 col8\" >8.9</td>\n",
       "      <td id=\"T_2fabc_row3_col9\" class=\"data row3 col9\" >32.8</td>\n",
       "      <td id=\"T_2fabc_row3_col10\" class=\"data row3 col10\" >14.0</td>\n",
       "      <td id=\"T_2fabc_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_2fabc_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_2fabc_row3_col13\" class=\"data row3 col13\" >45.9</td>\n",
       "      <td id=\"T_2fabc_row3_col14\" class=\"data row3 col14\" >35.4</td>\n",
       "      <td id=\"T_2fabc_row3_col15\" class=\"data row3 col15\" >40.6</td>\n",
       "      <td id=\"T_2fabc_row3_col16\" class=\"data row3 col16\" >27.6</td>\n",
       "      <td id=\"T_2fabc_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee2396aa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/2846006903.py:382: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/2846006903.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_43021 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_43021_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_43021_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_43021_row0_col2, #T_43021_row0_col3, #T_43021_row0_col4, #T_43021_row0_col5, #T_43021_row0_col6, #T_43021_row0_col7, #T_43021_row0_col8, #T_43021_row0_col9, #T_43021_row0_col10, #T_43021_row0_col11, #T_43021_row0_col12, #T_43021_row0_col13, #T_43021_row0_col14, #T_43021_row0_col15, #T_43021_row0_col16, #T_43021_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_43021\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_43021_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_43021_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_43021_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_43021_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_43021_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_43021_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_43021_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_43021_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_43021_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_43021_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_43021_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_43021_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_43021_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_43021_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_43021_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_43021_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_43021_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_43021_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_43021_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_43021_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_43021_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_43021_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_43021_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_43021_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_43021_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_43021_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_43021_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_43021_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_43021_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_43021_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_43021_row0_col11\" class=\"data row0 col11\" >20.1</td>\n",
       "      <td id=\"T_43021_row0_col12\" class=\"data row0 col12\" >319.7</td>\n",
       "      <td id=\"T_43021_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_43021_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_43021_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_43021_row0_col16\" class=\"data row0 col16\" >45.6</td>\n",
       "      <td id=\"T_43021_row0_col17\" class=\"data row0 col17\" >-7.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee2394550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/2846006903.py:382: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/2846006903.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a5747 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_a5747_row0_col0, #T_a5747_row1_col0, #T_a5747_row2_col0, #T_a5747_row3_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a5747_row0_col1, #T_a5747_row1_col1, #T_a5747_row2_col1, #T_a5747_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a5747_row0_col2, #T_a5747_row0_col3, #T_a5747_row0_col6, #T_a5747_row0_col11, #T_a5747_row0_col12, #T_a5747_row0_col13, #T_a5747_row0_col14, #T_a5747_row0_col15, #T_a5747_row0_col17, #T_a5747_row1_col3, #T_a5747_row1_col11, #T_a5747_row1_col12, #T_a5747_row1_col13, #T_a5747_row1_col14, #T_a5747_row1_col15, #T_a5747_row1_col17, #T_a5747_row2_col3, #T_a5747_row2_col4, #T_a5747_row2_col5, #T_a5747_row2_col7, #T_a5747_row2_col11, #T_a5747_row2_col12, #T_a5747_row2_col13, #T_a5747_row2_col14, #T_a5747_row2_col15, #T_a5747_row2_col17, #T_a5747_row3_col3, #T_a5747_row3_col5, #T_a5747_row3_col8, #T_a5747_row3_col9, #T_a5747_row3_col10, #T_a5747_row3_col11, #T_a5747_row3_col12, #T_a5747_row3_col13, #T_a5747_row3_col14, #T_a5747_row3_col15, #T_a5747_row3_col16, #T_a5747_row3_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a5747_row0_col4, #T_a5747_row0_col5, #T_a5747_row0_col9, #T_a5747_row0_col10, #T_a5747_row0_col16, #T_a5747_row1_col4, #T_a5747_row1_col6, #T_a5747_row2_col2, #T_a5747_row2_col8, #T_a5747_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a5747_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a5747_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a5747_row1_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e36b54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a5747_row1_col5 {\n",
       "  text-align: left;\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a5747_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a5747_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a5747_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a5747_row1_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a5747_row1_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a5747_row2_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #cd423b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a5747_row2_col9 {\n",
       "  text-align: left;\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a5747_row2_col10 {\n",
       "  text-align: left;\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a5747_row2_col16 {\n",
       "  text-align: left;\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a5747_row3_col2 {\n",
       "  text-align: left;\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a5747_row3_col4 {\n",
       "  text-align: left;\n",
       "  background-color: #f49a7b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a5747_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: #c12b30;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a5747\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a5747_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_a5747_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_a5747_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_a5747_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_a5747_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_a5747_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_a5747_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_a5747_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_a5747_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_a5747_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_a5747_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_a5747_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_a5747_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_a5747_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_a5747_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_a5747_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_a5747_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_a5747_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a5747_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a5747_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_a5747_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_a5747_row0_col2\" class=\"data row0 col2\" >39.0</td>\n",
       "      <td id=\"T_a5747_row0_col3\" class=\"data row0 col3\" >38.8</td>\n",
       "      <td id=\"T_a5747_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_a5747_row0_col5\" class=\"data row0 col5\" >16.0</td>\n",
       "      <td id=\"T_a5747_row0_col6\" class=\"data row0 col6\" >29.9</td>\n",
       "      <td id=\"T_a5747_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_a5747_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_a5747_row0_col9\" class=\"data row0 col9\" >34.9</td>\n",
       "      <td id=\"T_a5747_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_a5747_row0_col11\" class=\"data row0 col11\" >45.8</td>\n",
       "      <td id=\"T_a5747_row0_col12\" class=\"data row0 col12\" >279.4</td>\n",
       "      <td id=\"T_a5747_row0_col13\" class=\"data row0 col13\" >54.4</td>\n",
       "      <td id=\"T_a5747_row0_col14\" class=\"data row0 col14\" >36.0</td>\n",
       "      <td id=\"T_a5747_row0_col15\" class=\"data row0 col15\" >45.3</td>\n",
       "      <td id=\"T_a5747_row0_col16\" class=\"data row0 col16\" >48.7</td>\n",
       "      <td id=\"T_a5747_row0_col17\" class=\"data row0 col17\" >-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a5747_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a5747_row1_col0\" class=\"data row1 col0\" >llama-7b_sharegpt50k_score=dppmap:k=vmf:gamma=1:kmd=llama7br512p4096:kemb=grad+rp+loraB_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_a5747_row1_col1\" class=\"data row1 col1\" >60000</td>\n",
       "      <td id=\"T_a5747_row1_col2\" class=\"data row1 col2\" >40.0</td>\n",
       "      <td id=\"T_a5747_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "      <td id=\"T_a5747_row1_col4\" class=\"data row1 col4\" >6.4</td>\n",
       "      <td id=\"T_a5747_row1_col5\" class=\"data row1 col5\" >14.4</td>\n",
       "      <td id=\"T_a5747_row1_col6\" class=\"data row1 col6\" >32.4</td>\n",
       "      <td id=\"T_a5747_row1_col7\" class=\"data row1 col7\" >34.6</td>\n",
       "      <td id=\"T_a5747_row1_col8\" class=\"data row1 col8\" >7.8</td>\n",
       "      <td id=\"T_a5747_row1_col9\" class=\"data row1 col9\" >34.4</td>\n",
       "      <td id=\"T_a5747_row1_col10\" class=\"data row1 col10\" >11.4</td>\n",
       "      <td id=\"T_a5747_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_a5747_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "      <td id=\"T_a5747_row1_col13\" class=\"data row1 col13\" >nan</td>\n",
       "      <td id=\"T_a5747_row1_col14\" class=\"data row1 col14\" >nan</td>\n",
       "      <td id=\"T_a5747_row1_col15\" class=\"data row1 col15\" >nan</td>\n",
       "      <td id=\"T_a5747_row1_col16\" class=\"data row1 col16\" >22.7</td>\n",
       "      <td id=\"T_a5747_row1_col17\" class=\"data row1 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a5747_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a5747_row2_col0\" class=\"data row2 col0\" >llama-7b_sharegpt50k_score=random:s=0_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_a5747_row2_col1\" class=\"data row2 col1\" >60000</td>\n",
       "      <td id=\"T_a5747_row2_col2\" class=\"data row2 col2\" >40.2</td>\n",
       "      <td id=\"T_a5747_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_a5747_row2_col4\" class=\"data row2 col4\" >5.6</td>\n",
       "      <td id=\"T_a5747_row2_col5\" class=\"data row2 col5\" >14.0</td>\n",
       "      <td id=\"T_a5747_row2_col6\" class=\"data row2 col6\" >32.2</td>\n",
       "      <td id=\"T_a5747_row2_col7\" class=\"data row2 col7\" >33.5</td>\n",
       "      <td id=\"T_a5747_row2_col8\" class=\"data row2 col8\" >8.2</td>\n",
       "      <td id=\"T_a5747_row2_col9\" class=\"data row2 col9\" >32.7</td>\n",
       "      <td id=\"T_a5747_row2_col10\" class=\"data row2 col10\" >12.4</td>\n",
       "      <td id=\"T_a5747_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_a5747_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "      <td id=\"T_a5747_row2_col13\" class=\"data row2 col13\" >nan</td>\n",
       "      <td id=\"T_a5747_row2_col14\" class=\"data row2 col14\" >nan</td>\n",
       "      <td id=\"T_a5747_row2_col15\" class=\"data row2 col15\" >nan</td>\n",
       "      <td id=\"T_a5747_row2_col16\" class=\"data row2 col16\" >22.4</td>\n",
       "      <td id=\"T_a5747_row2_col17\" class=\"data row2 col17\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a5747_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a5747_row3_col0\" class=\"data row3 col0\" >llama-7b_sharegpt50k_score=dppmap:k=rbf:gamma=1e-3:kmd=llama7br512p4096:kemb=text+embedding_pace=prune:size=60000:ep=3</td>\n",
       "      <td id=\"T_a5747_row3_col1\" class=\"data row3 col1\" >60000</td>\n",
       "      <td id=\"T_a5747_row3_col2\" class=\"data row3 col2\" >39.6</td>\n",
       "      <td id=\"T_a5747_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
       "      <td id=\"T_a5747_row3_col4\" class=\"data row3 col4\" >6.2</td>\n",
       "      <td id=\"T_a5747_row3_col5\" class=\"data row3 col5\" >14.0</td>\n",
       "      <td id=\"T_a5747_row3_col6\" class=\"data row3 col6\" >32.3</td>\n",
       "      <td id=\"T_a5747_row3_col7\" class=\"data row3 col7\" >35.9</td>\n",
       "      <td id=\"T_a5747_row3_col8\" class=\"data row3 col8\" >7.5</td>\n",
       "      <td id=\"T_a5747_row3_col9\" class=\"data row3 col9\" >30.6</td>\n",
       "      <td id=\"T_a5747_row3_col10\" class=\"data row3 col10\" >11.0</td>\n",
       "      <td id=\"T_a5747_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_a5747_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_a5747_row3_col13\" class=\"data row3 col13\" >nan</td>\n",
       "      <td id=\"T_a5747_row3_col14\" class=\"data row3 col14\" >nan</td>\n",
       "      <td id=\"T_a5747_row3_col15\" class=\"data row3 col15\" >nan</td>\n",
       "      <td id=\"T_a5747_row3_col16\" class=\"data row3 col16\" >22.1</td>\n",
       "      <td id=\"T_a5747_row3_col17\" class=\"data row3 col17\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee2397f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/2846006903.py:382: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/2846006903.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5b430 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_5b430_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5b430_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5b430_row0_col2, #T_5b430_row0_col3, #T_5b430_row0_col4, #T_5b430_row0_col5, #T_5b430_row0_col6, #T_5b430_row0_col7, #T_5b430_row0_col8, #T_5b430_row0_col9, #T_5b430_row0_col10, #T_5b430_row0_col11, #T_5b430_row0_col12, #T_5b430_row0_col13, #T_5b430_row0_col14, #T_5b430_row0_col15, #T_5b430_row0_col16, #T_5b430_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5b430\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5b430_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_5b430_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_5b430_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_5b430_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_5b430_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_5b430_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_5b430_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_5b430_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_5b430_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_5b430_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_5b430_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_5b430_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_5b430_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_5b430_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_5b430_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_5b430_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_5b430_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_5b430_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5b430_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5b430_row0_col0\" class=\"data row0 col0\" >llama-7b_dolly_ep=2</td>\n",
       "      <td id=\"T_5b430_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_5b430_row0_col2\" class=\"data row0 col2\" >38.5</td>\n",
       "      <td id=\"T_5b430_row0_col3\" class=\"data row0 col3\" >38.5</td>\n",
       "      <td id=\"T_5b430_row0_col4\" class=\"data row0 col4\" >5.4</td>\n",
       "      <td id=\"T_5b430_row0_col5\" class=\"data row0 col5\" >10.8</td>\n",
       "      <td id=\"T_5b430_row0_col6\" class=\"data row0 col6\" >34.0</td>\n",
       "      <td id=\"T_5b430_row0_col7\" class=\"data row0 col7\" >31.3</td>\n",
       "      <td id=\"T_5b430_row0_col8\" class=\"data row0 col8\" >9.0</td>\n",
       "      <td id=\"T_5b430_row0_col9\" class=\"data row0 col9\" >44.0</td>\n",
       "      <td id=\"T_5b430_row0_col10\" class=\"data row0 col10\" >10.4</td>\n",
       "      <td id=\"T_5b430_row0_col11\" class=\"data row0 col11\" >20.1</td>\n",
       "      <td id=\"T_5b430_row0_col12\" class=\"data row0 col12\" >319.7</td>\n",
       "      <td id=\"T_5b430_row0_col13\" class=\"data row0 col13\" >34.0</td>\n",
       "      <td id=\"T_5b430_row0_col14\" class=\"data row0 col14\" >16.8</td>\n",
       "      <td id=\"T_5b430_row0_col15\" class=\"data row0 col15\" >25.5</td>\n",
       "      <td id=\"T_5b430_row0_col16\" class=\"data row0 col16\" >45.6</td>\n",
       "      <td id=\"T_5b430_row0_col17\" class=\"data row0 col17\" >-7.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee2396ce0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3413947/2846006903.py:382: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  display(dfc\n",
      "/tmp/ipykernel_3413947/2846006903.py:388: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  .applymap(lambda x: 'text-decoration: underline;' \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c6180 td {\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "#T_c6180_row0_col0 {\n",
       "  max-width: 60ch;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c6180_row0_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c6180_row0_col2, #T_c6180_row0_col3, #T_c6180_row0_col4, #T_c6180_row0_col5, #T_c6180_row0_col6, #T_c6180_row0_col7, #T_c6180_row0_col8, #T_c6180_row0_col9, #T_c6180_row0_col10, #T_c6180_row0_col11, #T_c6180_row0_col12, #T_c6180_row0_col13, #T_c6180_row0_col14, #T_c6180_row0_col15, #T_c6180_row0_col16, #T_c6180_row0_col17 {\n",
       "  text-align: left;\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c6180\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c6180_level0_col0\" class=\"col_heading level0 col0\" >run_name</th>\n",
       "      <th id=\"T_c6180_level0_col1\" class=\"col_heading level0 col1\" >total_train_samples</th>\n",
       "      <th id=\"T_c6180_level0_col2\" class=\"col_heading level0 col2\" >MMLU/0-shot</th>\n",
       "      <th id=\"T_c6180_level0_col3\" class=\"col_heading level0 col3\" >MMLU/5-shot</th>\n",
       "      <th id=\"T_c6180_level0_col4\" class=\"col_heading level0 col4\" >GSM/Direct</th>\n",
       "      <th id=\"T_c6180_level0_col5\" class=\"col_heading level0 col5\" >GSM/CoT</th>\n",
       "      <th id=\"T_c6180_level0_col6\" class=\"col_heading level0 col6\" >BBH/Direct</th>\n",
       "      <th id=\"T_c6180_level0_col7\" class=\"col_heading level0 col7\" >BBH/CoT</th>\n",
       "      <th id=\"T_c6180_level0_col8\" class=\"col_heading level0 col8\" >TydiQA/CB</th>\n",
       "      <th id=\"T_c6180_level0_col9\" class=\"col_heading level0 col9\" >TydiQA/GP</th>\n",
       "      <th id=\"T_c6180_level0_col10\" class=\"col_heading level0 col10\" >Codex-Eval/Pass@1</th>\n",
       "      <th id=\"T_c6180_level0_col11\" class=\"col_heading level0 col11\" >AlpacaFarm(chatgpt)/WR*</th>\n",
       "      <th id=\"T_c6180_level0_col12\" class=\"col_heading level0 col12\" >AlpacaFarm(chatgpt)/Len</th>\n",
       "      <th id=\"T_c6180_level0_col13\" class=\"col_heading level0 col13\" >MTBench(gpt:4:1106:preview)/Turn-1</th>\n",
       "      <th id=\"T_c6180_level0_col14\" class=\"col_heading level0 col14\" >MTBench(gpt:4:1106:preview)/Turn-2</th>\n",
       "      <th id=\"T_c6180_level0_col15\" class=\"col_heading level0 col15\" >MTBench(gpt:4:1106:preview)/Rating</th>\n",
       "      <th id=\"T_c6180_level0_col16\" class=\"col_heading level0 col16\" >Average</th>\n",
       "      <th id=\"T_c6180_level0_col17\" class=\"col_heading level0 col17\" >ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c6180_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c6180_row0_col0\" class=\"data row0 col0\" >llama-7b_sharegpt50k_ep=2</td>\n",
       "      <td id=\"T_c6180_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "      <td id=\"T_c6180_row0_col2\" class=\"data row0 col2\" >39.0</td>\n",
       "      <td id=\"T_c6180_row0_col3\" class=\"data row0 col3\" >38.8</td>\n",
       "      <td id=\"T_c6180_row0_col4\" class=\"data row0 col4\" >6.4</td>\n",
       "      <td id=\"T_c6180_row0_col5\" class=\"data row0 col5\" >16.0</td>\n",
       "      <td id=\"T_c6180_row0_col6\" class=\"data row0 col6\" >29.9</td>\n",
       "      <td id=\"T_c6180_row0_col7\" class=\"data row0 col7\" >34.4</td>\n",
       "      <td id=\"T_c6180_row0_col8\" class=\"data row0 col8\" >8.0</td>\n",
       "      <td id=\"T_c6180_row0_col9\" class=\"data row0 col9\" >34.9</td>\n",
       "      <td id=\"T_c6180_row0_col10\" class=\"data row0 col10\" >13.2</td>\n",
       "      <td id=\"T_c6180_row0_col11\" class=\"data row0 col11\" >45.8</td>\n",
       "      <td id=\"T_c6180_row0_col12\" class=\"data row0 col12\" >279.4</td>\n",
       "      <td id=\"T_c6180_row0_col13\" class=\"data row0 col13\" >54.4</td>\n",
       "      <td id=\"T_c6180_row0_col14\" class=\"data row0 col14\" >36.0</td>\n",
       "      <td id=\"T_c6180_row0_col15\" class=\"data row0 col15\" >45.3</td>\n",
       "      <td id=\"T_c6180_row0_col16\" class=\"data row0 col16\" >48.7</td>\n",
       "      <td id=\"T_c6180_row0_col17\" class=\"data row0 col17\" >-4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14aee23979d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import pd_sort_rows_by_avg_ranking\n",
    "from llm.evaluate import EvalResults, get_eval_results\n",
    "\n",
    "\n",
    "\n",
    "exp_dir = ''\n",
    "chat_fmt = None\n",
    "sort_rows = True\n",
    "use_normalized_preferred_metric = False\n",
    "\n",
    "\n",
    "# ## investigate code change / package update effect on eval baselines.\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# use_normalized_preferred_metric = False\n",
    "# sort_rows = False\n",
    "# save_dirs = [\n",
    "#     # llama\n",
    "#     ('llama-7b_12.13update_before', '../results/baselines/huggyllama/llama-7b_12.13update_before/'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('llama-7b_10.30update', '../results/baselines/huggyllama/llama-7b_10.30update/'),\n",
    "# #     ('llama-7b_09.23update', '../results/baselines/huggyllama/llama-7b_09.23update/'),\n",
    "# #     ('llama-7b_09.23update_before', '../results/baselines/huggyllama/llama-7b_09.23update_before/'),\n",
    "# #     # llama2\n",
    "#     ('llama2-7b_12.13update_before', '../results/baselines/NousResearch/Llama-2-7b-hf_12.13update_before/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('llama2-7b-chat', '../results/baselines/NousResearch/Llama-2-7b-chat-hf/'),\n",
    "# #     ('llama2-7b_10.30update', '../results/baselines/NousResearch/Llama-2-7b-hf_10.30update/'),\n",
    "# #     ('llama2-7b_original', '../results/baselines/NousResearch/Llama-2-7b-hf_original/'),\n",
    "# #     # mistral\n",
    "# #     ('mistral-7b_10.16update', '../results/baselines/mistralai/Mistral-7B-v0.1_10.16update/'),\n",
    "#     ('mistral-7b-Instruct-v0.1_12.13update_before', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1_12.13update_before'),\n",
    "#     ('mistral-7b-Instruct-v0.1', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     # zephyr\n",
    "#     ('zephyr-7b-beta_12.13update_before', '../results/baselines/HuggingFaceH4/zephyr-7b-beta_12.13update_before'),\n",
    "#     ('zephyr-7b-beta', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "\n",
    "# # baselines\n",
    "# save_dirs = []\n",
    "# save_dirs += [\n",
    "# #     ('gpt2', '../results/baselines/gpt2'),\n",
    "# #     ('gpt2m', '../results/baselines/gpt2-medium'),\n",
    "# #     ('llama-7b_humanmix', '../results/ft1/llama-7b_humanmix'),\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "# #     ('llama2-7b+humanmix', '../results/llama2-7b_humanmix'),\n",
    "# #     ('pythia-1.4b', '../results/baselines/EleutherAI/pythia-1.4b'),\n",
    "# #     ('pythia-2.8b', '../results/baselines/EleutherAI/pythia-2.8b'),\n",
    "# #     ('pythia-6.9b', '../results/baselines/EleutherAI/pythia-6.9b'),\n",
    "# #     ('dolly-v2-7b', '../results/baselines/databricks/dolly-v2-7b'),\n",
    "#     ('mistral-7b-v0.1', '../results/baselines/mistralai/Mistral-7B-v0.1'),\n",
    "# ]\n",
    "\n",
    "\n",
    "# save_dirs = [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#     ('llama-7b+lima_ep=2', '../results/ft1_ep=2/llama-7b_lima/'),\n",
    "# #     ('mistral-7b+lima_ep=2', '../results/ft1_ep=2/mistral-7b_lima/'), \n",
    "# ]\n",
    "# exp_dir = '../results/oi2/'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "\n",
    "# exp_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/doremi/results/drm2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# # exp_dir = '../results/ft2'\n",
    "# # exp_dir = '../results/ft1'\n",
    "# exp_dir = '../results/ft1_ep=2'\n",
    "# # save_dirs = [\n",
    "# #     ('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "# #     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1/'),\n",
    "# # ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#               [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'tuluv1m' in x]\n",
    "\n",
    "# exp_dir = '../results/oi3'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/')]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in \n",
    "#              glob.glob(os.path.join(exp_dir, 'llama-7b_all:600k_humanmix', 'checkpoint-*'))]\n",
    "\n",
    "# # exp_dir = '../results/oi4'\n",
    "# # exp_dir = '../results/oi4_perf_cross_time'\n",
    "# # exp_dir = '../results/oi4_flanv2_prune_with_hmv1_model'\n",
    "# exp_dir = '../results/oi4_flan_v2_vary_subsetsize'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# exp_dir = '../results/oi4_flan2022_1m'\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "# #              ('llama-7b_flan_v2_ep=2', '../results/ft1/llama-7b_flan_v2'),\n",
    "# #              ('llama-7b_humanmix_ep=2', '../results/ft1/llama-7b_humanmix'),\n",
    "#              ('llama-7b_flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_flan_v2'),\n",
    "#              ('llama-7b_humanmix_ep=1', '../results/ft1_ep=1/llama-7b_hmv1'),\n",
    "# #              ('llama-7b_cot:flan_v2_ep=1', '../results/ft1_ep=1/llama-7b_cot:flanv2'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "\n",
    "# # exp_dir = '../results/oi4_tulu_v1_mix'\n",
    "# exp_dir = '../results/oi4_tulu_v1_mix_ep=3'\n",
    "# use_normalized_preferred_metric = False\n",
    "# save_dirs = [('llama-7b', '../results/baselines/huggyllama/llama-7b/'),\n",
    "#              ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "#             ]\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "\n",
    "# ###### ultrachat\n",
    "# save_dirs = [\n",
    "#     # baselines \n",
    "#     ('mistral-7b', '../results/baselines/mistralai/Mistral-7B-v0.1/'),\n",
    "#     ('mistral-7b_ultrachat200k_aftersplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k'),\n",
    "#     ('mistral-7b_ultrachat200k_beforesplitlongconv_ep=2', '../results/ft1_ep=2/mistral-7b_ultrachat200k_beforesplitlongconv'),\n",
    "    \n",
    "#     ('mistral-7b-Instruct', '../results/baselines/mistralai/Mistral-7B-Instruct-v0.1'),\n",
    "#     ('mistral-7b_sft-alpha', '../results/baselines/HuggingFaceH4/mistral-7b-sft-alpha'),\n",
    "#     ('mistral-7b-sft-beta', '../results/baselines/HuggingFaceH4/mistral-7b-sft-beta'),\n",
    "#     ('mistral-7b-sft-alpha+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-alpha'),\n",
    "#     ('mistral-7b-sft-beta+dpo', '../results/baselines/HuggingFaceH4/zephyr-7b-beta'),\n",
    "# ]\n",
    "# # exp_dir = '../results/oi5_ultrachat:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_ultrachat200k:mistral-7b'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# exp_dir = '../results/oi5_ultrachat15:mistral-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "#####\n",
    "# dataset = 'stanford_alpaca'\n",
    "# dataset = 'open_orca_slim'\n",
    "# dataset = 'sharegptv2'\n",
    "# dataset = 'ultrachat200kv2'\n",
    "# dataset = 'wizardlm'\n",
    "# dataset = 'wizardlmv2'\n",
    "# dataset = 'tulu_v2'\n",
    "# dataset = 'flan_v2'\n",
    "# dataset = 'oasst1'\n",
    "# dataset = 'dolly'\n",
    "# dataset_list = [\n",
    "#     'dolly',\n",
    "#     'oasst1', \n",
    "#     'flan_v2', \n",
    "#     'stanford_alpaca', \n",
    "#     'wizardlmv2', \n",
    "#     'sharegptv2', \n",
    "#     'ultrachat200kv2',\n",
    "# ]; finetune_type = 'sft'\n",
    "dataset_list = [\n",
    "    'dolly',\n",
    "#     'oasst1', \n",
    "#     'flan_v250k', \n",
    "#     'stanford_alpaca50k', \n",
    "#     'wizardlm50k', \n",
    "    'sharegpt50k', \n",
    "#     'ultrachat50k',\n",
    "]; finetune_type = 'sft'\n",
    "# dataset_list = [\n",
    "#     'dolly',\n",
    "# #     'oasst1', \n",
    "# #     'flan_v2', \n",
    "# #     'stanford_alpaca', \n",
    "# #     'wizardlmv2', \n",
    "# #     'sharegptv2', \n",
    "# #     'ultrachat200kv2',\n",
    "# ]; finetune_type = 'sft'\n",
    "# dataset_list = [\n",
    "#     'ultrafeedback',\n",
    "# #     'ultrafeedbackfull',\n",
    "# ]; finetune_type = 'pref'\n",
    "dataset_list = [\n",
    "    'dolly',\n",
    "    'sharegpt50k',\n",
    "]; finetune_type = 'sft'\n",
    "\n",
    "## older\n",
    "# dataset = 'tulu_v1_mix'\n",
    "save_dirs = []\n",
    "save_dirs += [\n",
    "#     ('llama-7b', '../results/baselines/huggyllama/llama-7b'),\n",
    "#     ('llama-7b_lima_ep=5', '../results/oi2/llama-7b_lima_ep=5/'),\n",
    "#     ('llama-7b_lima_ep=10', '../results/oi2/llama-7b_lima_ep=10/'),\n",
    "]\n",
    "for dataset in dataset_list:\n",
    "    if dataset == 'tulu_v2':\n",
    "        save_dirs += [('llama-7b_tulu_v2:100k_ep=2', '../results/oi2/llama-7b_tulu_v2:100k_ep=2'),]\n",
    "    elif dataset == 'open_orca_slim':\n",
    "        save_dirs += [('llama-7b_openorcaslim:100k_ep=2', '../results/oi2/llama-7b_openorcaslim:100k_ep=2'),]\n",
    "    elif dataset == 'sharegptv2':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_sharegptv2_ep=2', '../results/oi2/llama-7b_sharegptv2_ep=2'),\n",
    "            ('llama-7b_sharegpt_ep=2', '../results/ft1_ep=2/llama-7b_sharegpt'),]\n",
    "    elif dataset == 'tulu_v1_mix':\n",
    "        save_dirs += [\n",
    "            ('llama-7b_tuluv1_mix_ep=2', '../results/ft1_ep=2/llama-7b_tuluv1m'),\n",
    "            # oi4_tulu_v1_mix_ep=3 models before transformers update.\n",
    "            # ('llama-7b_tuluv1m:50k_log_prob_decr_<10.16update', '../results/oi4_tulu_v1_mix_ep=3/llama-7b_tuluv1m:50k_log_prob_decr'),\n",
    "        ]\n",
    "    elif dataset == 'ultrafeedback':\n",
    "        exp_dir = f'../results/dpo1/'\n",
    "        save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "    else:\n",
    "        save_dirs += [(f'llama-7b_{dataset}_ep=2', f'../results/oi2/llama-7b_{dataset}_ep=2'),]\n",
    "    \n",
    "    if finetune_type == 'sft':\n",
    "        exp_dir = f'../results/oi5_{dataset}:llama-7b'\n",
    "    elif finetune_type == 'pref':\n",
    "        exp_dir = f'../results/dpo2_{dataset}:llama-7b+sharegptv2ep2/'\n",
    "    save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'dppmapbd' not in x and 'semdedup' not in x]\n",
    "    \n",
    "    if finetune_type == 'pref':\n",
    "        sft_model_dataset = 'sharegptv2'\n",
    "        save_dirs += [('llama-7b_sharegptv2_ep=2', f'../results/oi2/llama-7b_{sft_model_dataset}_ep=2')]\n",
    "# ## just compare dppmap grad vs. text\n",
    "# save_dirs = [x for x in save_dirs if 'prune:size=10000:ep=10' in x[1] and (\n",
    "#         'random' in x[1] or \n",
    "#         'dppmap' in x[1]\n",
    "#     )\n",
    "# ]\n",
    "#####\n",
    "\n",
    "\n",
    "# ##### code instructions\n",
    "# save_dirs = [\n",
    "#     ('llama2-7b', '../results/baselines/NousResearch/Llama-2-7b-hf/'),\n",
    "#     ('codellama-7b', '../results/baselines/codellama/CodeLlama-7b-hf/'),\n",
    "#     ('codellama-7b-instruct', '../results/baselines/codellama/CodeLlama-7b-Python-hf/'),\n",
    "#     ('codellama-7b-python', '../results/baselines/codellama/CodeLlama-7b-Instruct-hf/'),\n",
    "# ]\n",
    "\n",
    "# exp_dir = '../results/oi2'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)] if 'starcoder' in x]\n",
    "# exp_dir = '../results/oi6_starcoder_ep=5'\n",
    "# # save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstr:codellama-7b'\n",
    "# # exp_dir = '../results/oi5_starcoder_commentinstrv2:codellama-7b'\n",
    "# exp_dir = '../results/oi5_starcoder_commentinstrv5:codellama-7b'\n",
    "# save_dirs += [(os.path.basename(x), x) for x in [os.path.join(exp_dir, x) for x in os.listdir(exp_dir)]]\n",
    "# #####\n",
    "\n",
    "\n",
    "###### \n",
    "\n",
    "from llm.evaluate import detect_oom_evals\n",
    "oom_eval_paths = detect_oom_evals([x for l in [glob.glob(os.path.join(x[1], 'eval/*/*.out')) for x in save_dirs] for x in l])\n",
    "if oom_eval_paths: print(oom_eval_paths)\n",
    "    \n",
    "cols_avg_blacklist = ['AlpacaFarm/Len']\n",
    "\n",
    "# chat_fmt = False\n",
    "chat_fmt = True\n",
    "chat_fmt = 'both'\n",
    "# chat_fmt = 'auto' # base model no chatfmt, tuned model with chatfmt\n",
    "chat_fmt = 'mix'  # non-alpacaeval no chatfmt, alpacaeval chatfmt\n",
    "alpacafarm_judge = 'chatgpt'\n",
    "mtbench_judge = 'gpt:4:1106:preview'\n",
    "\n",
    "ft_args_fields = {\n",
    "    'run_name': ('run_name',),\n",
    "    'model_name_or_path': ('model_args.model_name_or_path', 'model_name_or_path'),\n",
    "    'subsample_mixture': ('data_args.subsample_mixture',),\n",
    "    'max_train_samples': ('data_args.max_train_samples', 'max_train_samples'),\n",
    "    'train_file': ('data_args.train_file', 'train_file'),\n",
    "}\n",
    "\n",
    "cols = []\n",
    "# cols += [f'AlpacaFarm({alpacafarm_judge})/WR',  f'AlpacaFarm({alpacafarm_judge})/ΔWR', f'AlpacaFarm({alpacafarm_judge})/Rep', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "cols += ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1'] \n",
    "cols += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "cols += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "# cols += [f'MTBench({mtbench_judge})/Turn-1']\n",
    "\n",
    "\n",
    "\n",
    "# cols = [f'BBH {x}' for x in ['reasoning', 'nlu', 'knowledge', 'multilingual']]; cols = [x+'/Direct' for x in cols] + [x+'/CoT' for x in cols]\n",
    "# cols = [f'MMLU {x}' for x in ['STEM', 'humanities', 'social sciences', 'other']]; cols = [x+'/0-shot' for x in cols] + [x+'/5-shot' for x in cols]\n",
    "\n",
    "if 'open_orca_slim' in exp_dir:\n",
    "    cols = ['MMLU/0-shot', 'MMLU/5-shot', 'BBH/Direct', 'BBH/CoT']\n",
    "    cols = ['MMLU/0-shot', 'BBH/Direct']\n",
    "if 'starcoder' in exp_dir:\n",
    "    cols = ['Codex-Eval/Pass@1']\n",
    "    chat_fmt = 'both'\n",
    "print(f'chat_fmt={chat_fmt}')\n",
    "df = get_eval_results(save_dirs, chat_fmt=chat_fmt, ft_args_fields=ft_args_fields, use_normalized_preferred_metric=use_normalized_preferred_metric)\n",
    "\n",
    "cols = [x for x in cols if x in df.columns]\n",
    "df = df[list(ft_args_fields.keys()) + cols]\n",
    "if chat_fmt == 'both':\n",
    "    for col_lvl2 in ['', 'chatfmt']:\n",
    "        df[('Average', col_lvl2)] = df[list(set(df.columns) & set([(x, col_lvl2) for x in list(set(cols)-set(cols_avg_blacklist))]))].mean(axis=1)\n",
    "else:\n",
    "    df['Average'] = df[list(set(cols)-set(cols_avg_blacklist))].mean(axis=1)\n",
    "if sort_rows:\n",
    "    df = pd_sort_rows_by_avg_ranking(df); df['ranking'] = -df['ranking']\n",
    "    sort_value_col, sort_value_col_ascending = ('Average', 'chatfmt') if chat_fmt=='both' else 'Average', False\n",
    "#     sort_value_col, sort_value_col_ascending = 'ranking', False\n",
    "    df = df.sort_values(by=sort_value_col, ascending=sort_value_col_ascending)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def compute_total_train_samples(x):\n",
    "    match = re.search(r'size=(\\d+)', x['run_name' if chat_fmt!='both' else ('run_name', '')])\n",
    "    total_train_samples = match.group(1) if match else None\n",
    "    return total_train_samples\n",
    "df.insert(1, 'total_train_samples' if chat_fmt!='both' else ('total_train_samples', ''), df.apply(compute_total_train_samples, axis=1))\n",
    "def extract_dataset_from_train_file(x):\n",
    "    if x is None: return None\n",
    "    x = x.split('/')[-1].split('.jsonl')[0]\n",
    "    if x.endswith('_data'): x = x[:-5]\n",
    "    if x.endswith('_train'): x = x[:-6]\n",
    "    return x\n",
    "df.insert(1, 'dataset' if chat_fmt!='both' else ('dataset', ''), df['train_file'].apply(extract_dataset_from_train_file))\n",
    "df = df.drop('train_file', axis=1)\n",
    "\n",
    "if any(exp_dir.endswith(x) for x in ['ft2']):\n",
    "#     for model_name_contain in ['gpt2', 'llama', 'pythia-1.4b']:\n",
    "#         for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "    for model_name_contain in ['llama']:\n",
    "        for total_train_samples in [10000, 50000, 100000, 200000]:\n",
    "#         for total_train_samples in [200000, 400000, 600000]:\n",
    "            dfc = df.copy()\n",
    "            dfc.insert(0, 'total_train_samples',  dfc['subsample_mixture'].apply(\n",
    "                lambda d: sum(list(d.values())) if d else 200000))\n",
    "            dfc = dfc[dfc['total_train_samples'].apply(\n",
    "                lambda x: total_train_samples-20000<x<total_train_samples+20000)]\n",
    "            dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "                lambda x: model_name_contain in x)]\n",
    "            dfc['total_train_samples'] = dfc['total_train_samples'].astype(str)\n",
    "            dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture'])\n",
    "            dfc = dfc.reset_index(drop=True)\n",
    "            if len(dfc):\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .format(precision=2))\n",
    "else:\n",
    "    for model_name_contain in ['llama', 'pythia-1.4b', 'mistral', 'zephyr']:\n",
    "        dfc = df.copy()\n",
    "        dfc = dfc[dfc['model_name_or_path'].apply(\n",
    "            lambda x: model_name_contain in x.lower())]\n",
    "        if not len(dfc): continue\n",
    "        from rosemary import pd_average_col_contains_substr\n",
    "        Ns = sorted(np.unique([int(x) for x in df['total_train_samples'].to_numpy() if x]).tolist())\n",
    "        datasets = sorted(np.unique([x for x in df['dataset'] if x is not None]).tolist())\n",
    "        for N in Ns+[None]:\n",
    "            for dataset in datasets:\n",
    "                dfc = df.copy()\n",
    "                dfc = dfc[dfc['total_train_samples'].apply(lambda x: int(x) == N if x else True)]\n",
    "                dfc = dfc[dfc['dataset'].apply(lambda x: x == dataset if x else True)]\n",
    "                if not len(dfc): continue\n",
    "                col_runname = 'run_name' if chat_fmt != 'both' else ('run_name', '')\n",
    "                substitute = True\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, '_random_', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=10000:ep=10', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=50000:ep=5', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=3', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=150000:ep=1', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=100000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=200000', substitute=substitute)\n",
    "                dfc = pd_average_col_contains_substr(dfc, col_runname, 'score=random:s=\\d_pace=prune:size=400000', substitute=substitute)\n",
    "                #     dfc = dfc.sort_values(['ranking'], ascending=False)\n",
    "                col = ('Average', 'chatfmt') if chat_fmt == 'both' else 'Average'\n",
    "            #     col = 'AlpacaFarm/WR'\n",
    "            #     col = 'MMLU/0-shot'|\n",
    "            #     col = 'GSM/CoT'\n",
    "            #     col = 'BBH/Direct'\n",
    "            #     col = 'TydiQA/GP'\n",
    "                dfc = dfc.sort_values(by=[col], ascending=False)\n",
    "                dfc = dfc.drop(columns=['model_name_or_path', 'subsample_mixture', 'max_train_samples', 'dataset'], \n",
    "                               axis=1, level=0 if chat_fmt=='both' else None)\n",
    "                dfc = dfc.reset_index(drop=True)\n",
    "                display(dfc\n",
    "                        .style\n",
    "                        .applymap(lambda x: f'max-width: 60ch;', subset=['run_name'])\n",
    "                        .set_table_styles([{'selector': 'td', 'props': [('white-space', 'pre-wrap'), ('word-wrap', 'break-word')]}])\n",
    "                        .set_properties(**{'text-align': 'left'})\n",
    "                        .background_gradient(cmap ='coolwarm')\n",
    "                        .applymap(lambda x: 'text-decoration: underline;' \\\n",
    "                                  if x in dfc[list(set(dfc.columns) & set([(x, '') for x in cols]))+[col] if chat_fmt=='both' else cols+[col]].values.flatten() and chat_fmt=='both' else '')\n",
    "                        .format(precision=1))\n",
    "\n",
    "# llama-7b_tulu_v1_mix(paper)\n",
    "# MMLU/0-shot, MMLU/5-shot, GSM/Direct, GSM/CoT, BBH/Direct, BBH/CoT, TydiQA/GP, TydiQA/CB, CodexEval/Pass@1, AlpacaEval(vs.Davinci-003)\n",
    "# 44.8       , 47.1       , 7.0       , 25.0   , 38.5      , 38.5   , 43.5,    , 8.0      , 18.6,           , 48.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeba0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rosemary import parse_kv_from_string\n",
    "\n",
    "non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'TydiQA/CB', 'TydiQA/GP', 'Codex-Eval/Pass@1', ]\n",
    "# non_chateval_task_names = ['MMLU/0-shot', 'MMLU/5-shot', 'GSM/Direct', 'GSM/CoT', 'BBH/Direct', 'BBH/CoT', 'Codex-Eval/Pass@1', ]\n",
    "\n",
    "def compute_nonchateval_average_performance(row):\n",
    "    L = [row[k] for k in non_chateval_task_names if k in row]\n",
    "    return np.average(L)\n",
    "\n",
    "def parse_prune_subset_size(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'(?<=pace=)([^_]+)', run_name)\n",
    "    if match:\n",
    "        pace = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(pace)\n",
    "        return int(kvs['size'] / kvs['ep'])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_sort_by_from_run_name(row):\n",
    "    run_name = row['run_name']\n",
    "    match = re.search(r'score=([^_]+)', run_name)\n",
    "    if match:\n",
    "        sort_by = match.group(1).replace(':', '_')\n",
    "        kvs = parse_kv_from_string(sort_by)\n",
    "    else:\n",
    "        kvs = {}\n",
    "    return kvs\n",
    "\n",
    "\n",
    "def parse_sort_by_type(row):\n",
    "    d = row['sort_by']\n",
    "    if not d:\n",
    "        return None\n",
    "    if d[0] == 'dppmap':\n",
    "        if d['k']=='vmf' and d['kmd']=='mpnet': #and (d['gamma']==1 or d['gamma'] == 'auto1000'):\n",
    "            return 'vmf+text'\n",
    "        elif d['k']=='rbf' and d['kemb']=='text+embedding' and d['kmd'] == 'llama7br512p4096':\n",
    "            return f\"rbf+text_gamma={d['gamma']}\"\n",
    "        elif d['k']=='vmf' and d['kemb']=='grad+rp+loraB' and d['kmd'] == 'llama7br512p4096':\n",
    "            return f\"vmf+grad_gamma={d['gamma']}\"\n",
    "        else:\n",
    "            return None\n",
    "    elif d[0] == 'random':\n",
    "        return 'random'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "dfc.insert(1, 'sort_by' if chat_fmt!='both' else ('sort_by', ''), dfc.apply(parse_sort_by_from_run_name, axis=1))\n",
    "dfc.insert(1, 'sort_by_type' if chat_fmt!='both' else ('sort_by_type', ''), dfc.apply(parse_sort_by_type, axis=1))\n",
    "dfc.insert(1, 'subset_size' if chat_fmt!='both' else ('subset_size', ''), dfc.apply(parse_prune_subset_size, axis=1))\n",
    "dfc.insert(1, 'nonchat' if chat_fmt!='both' else ('nonchat', ''), dfc.apply(compute_nonchateval_average_performance, axis=1))\n",
    "\n",
    "\n",
    "dfc = dfc[dfc['sort_by_type'].notnull()]\n",
    "startswithstrs = ('rbf+text', 'random')\n",
    "startswithstrs = (\n",
    "    'random', \n",
    "    'rbf+text_gamma=0.001', \n",
    "    'vmf+grad_gamma=1',\n",
    "#     'rbf+text_gamma=auto1000', \n",
    "    'vmf+grad_gamma=auto1000',\n",
    ")\n",
    "dfc = dfc[dfc.apply(lambda x: x['sort_by_type'].startswith(startswithstrs)\n",
    "                   , axis=1)]\n",
    "dfc['subset_size'] = dfc['subset_size'].apply(lambda x: int(x) if x else x)\n",
    "dfc = dfc[dfc['subset_size']<=10_000]\n",
    "\n",
    "\n",
    "D = dfc.set_index(['sort_by_type', 'dataset', 'subset_size']).to_dict()\n",
    "from dataclasses import dataclass\n",
    "@dataclass(unsafe_hash=True)\n",
    "class DKey:\n",
    "    sort_by_type: str\n",
    "    dataset: str\n",
    "    subset_size: int\n",
    "def convert_key_to_dataclass(d):\n",
    "    return {DKey(*k): v for k, v in d.items()}\n",
    "D = {k: convert_key_to_dataclass(v) for k, v in D.items()}\n",
    "\n",
    "list(D.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "662539cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x800 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "yaxis_type = 'abs'\n",
    "# yaxis_type = 'delta_random'\n",
    "assert(yaxis_type in ['delta_random', 'abs'])\n",
    "datasets = ['flan_v2', 'dolly', 'stanford_alpaca', 'oasst1', 'ultrachat200kv2', 'wizardlmv2', 'sharegptv2']\n",
    "task_names = ['nonchat', 'MMLU/0-shot', 'GSM/CoT', 'BBH/Direct', 'TydiQA/GP', 'Codex-Eval/Pass@1', 'AlpacaFarm/WR*',]\n",
    "\n",
    "datasets = ['dolly', 'sharegpt50k']\n",
    "task_names = []\n",
    "task_names += ['nonchat']\n",
    "# task_names += [f'MTBench({mtbench_judge})/Turn-1',  f'MTBench({mtbench_judge})/Turn-2', f'MTBench({mtbench_judge})/Rating']\n",
    "task_names += [f'MTBench({mtbench_judge})/Rating']\n",
    "task_names += [f'AlpacaFarm({alpacafarm_judge})/WR*', f'AlpacaFarm({alpacafarm_judge})/Len']\n",
    "\n",
    "\n",
    "\n",
    "w = 2\n",
    "ncols = len(datasets)\n",
    "nrows = len(task_names)\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(w*ncols+3,w*nrows), sharey='row', sharex=True)\n",
    "\n",
    "xs_possible = []\n",
    "\n",
    "for axi, task_name in enumerate(task_names):\n",
    "    d = D[task_name]\n",
    "    for axj, dataset in enumerate(datasets):\n",
    "        ax = axs.reshape(nrows, ncols)[axi, axj]\n",
    "        sort_by_types = sorted(set(x.sort_by_type for x in d.keys()))\n",
    "\n",
    "        for i, sort_by_type in enumerate(sort_by_types):\n",
    "            xs = sorted([x.subset_size for x in d.keys()\n",
    "                         if x.dataset == dataset and x.sort_by_type==sort_by_type])\n",
    "            xs_possible += list(set(xs) - set(xs_possible))\n",
    "            ys = [d[DKey(sort_by_type, dataset, x)] for x in xs]\n",
    "            if yaxis_type == 'delta_random':\n",
    "                if not all(DKey('random', dataset, x) in d for x in xs): continue\n",
    "                ys = [y-d[DKey('random', dataset, x)] for x, y in zip(xs, ys)] \n",
    "            if 'random' in sort_by_type:\n",
    "                marker_style = 'o-'\n",
    "            else:\n",
    "                marker_style = 'o-'\n",
    "            ax.plot(xs, ys, marker_style, label=sort_by_type)\n",
    "        \n",
    "#         ax.set_yscale('log')\n",
    "            \n",
    "for axi, task_name in enumerate(task_names):\n",
    "    task_name_shortened = task_name.replace(f'({mtbench_judge})', '').replace(f'({alpacafarm_judge})', '')\n",
    "    axs.reshape(nrows, ncols)[axi, 0].set_ylabel('△ '+task_name_shortened if yaxis_type.startswith('delta') else task_name_shortened, fontsize=13)\n",
    "    axs.reshape(nrows, ncols)[axi, -1].legend(loc='center left', bbox_to_anchor=(1.1, 0.5))\n",
    "for axj, dataset in enumerate(datasets):\n",
    "    axs.reshape(nrows, ncols)[0, axj].set_title(dataset, fontsize=15)\n",
    "    axs.reshape(nrows, ncols)[0, axj].set_xticks(xs_possible, xs_possible)\n",
    "\n",
    "space = 0.05\n",
    "fig.subplots_adjust(wspace=space, hspace=space)  # Adjust the value as needed\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5fdb69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e2f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39874bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
