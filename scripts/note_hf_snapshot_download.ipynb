{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7862ef",
   "metadata": {},
   "source": [
    "goal: save hf models from remote to local disk, so that I can populate the directory with evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff898065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "from huggingface_hub import snapshot_download\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba55cb6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8b44db73894df7b9e5a6f0d237285c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4159cea4044843999d0a8d2355339f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)5e2c6/.gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfa2fdfcee741f6a0f3776a53e4ec26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53caf91844ef4684a44ec3f44a47da97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)6d5e2c6/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7bbbf204ad4b52a4937f2170361bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ba76d5e2c6/README.md:   0%|          | 0.00/90.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f4a70cf29b4718bafc2709bb30fd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e348a7bf8af44d3fa6f19c78546730e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)76d5e2c6/config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c86d7b23b3498e870b4354f3c1febb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbba6befcca470a98da3db9e80cfc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)5e2c6/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c4e711145d4689b8bd5eef2c3a838d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474a2df53c7c4ab380ee8e9c627390a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a915c9535074eab927dbc9f19a91c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049e6ba966ea4f10a1fce49da24fb17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ba76d5e2c6/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d8f8c9171d463a8bec4b790775b431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0667b031b27f4095a3dd487db9f33175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82fecfbb1a0b434eb9d7bd590af45090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0980d279d0/README.md:   0%|          | 0.00/68.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741f6c3f82b5422dbbae9ff5f786db33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db53ad64b1364f6caa50f47c25e98075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)279d0/.gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a61ea261e944139bca560d3f4b16560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading weight.bin:   0%|          | 0.00/551M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347cf82cade94741a2b24e2d5f7af0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ackage/Manifest.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca145f908d94aa4903194e6bdb7adf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d932d2020872408ebbf76ef55c0631bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/275M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6db8bb0d2340bfbecaefefdfef9ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.onnx:   0%|          | 0.00/547M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa2d24a36314f8f9c3091953aad31cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)80d279d0/config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5677a7093c402cb44251c6f4286af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.mlmodel:   0%|          | 0.00/136k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a51b7663bd4df1852c6406022cb86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb46115eb45440cafa73a58ac2fa259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7827ff446c104191a593856a2840b90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/373 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be600f6cfeb4bc09248c36342e00cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0980d279d0/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d140ee0efaca40a8b4ac0265694f5525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)279d0/tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edeb15d53524457820257fe85d314f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/275M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8562dffd514adfa99e7d9fe3b0dd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0d279d0/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "save_dir = '../results/baselines/'\n",
    "repo_ids = [\n",
    "    # encoder-decoder\n",
    "    # t5\n",
    "    't5-small',\n",
    "    't5-base',\n",
    "    't5-large',\n",
    "    't5-3b',\n",
    "    't5-11b',\n",
    "#     # flan-t5\n",
    "    'google/flan-t5-small',\n",
    "    'google/flan-t5-base',\n",
    "    'google/flan-t5-large',\n",
    "    'google/flan-t5-xl'\n",
    "    'google/flan-t5-xxl',\n",
    "#     # decoder-only\n",
    "#     # 124M, 355M, 774M, 1.5B\n",
    "    'gpt2',\n",
    "    'gpt2-medium',\n",
    "    'gpt2-large',\n",
    "    'gpt2-xl',\n",
    "#     # open-source\n",
    "    'huggyllama/llama-7b',\n",
    "    'NousResearch/Llama-2-7b-hf'\n",
    "    'mosaicml/mpt-7b',\n",
    "    # pythia\n",
    "    'EleutherAI/pythia-70m',\n",
    "    'EleutherAI/pythia-160m',\n",
    "    'EleutherAI/pythia-410m',\n",
    "    'EleutherAI/pythia-1b',\n",
    "    'EleutherAI/pythia-1.4b',\n",
    "    'EleutherAI/pythia-2.8b',\n",
    "    'EleutherAI/pythia-6.9b',\n",
    "    'EleutherAI/pythia-12b',\n",
    "    # instruction tuned pythia\n",
    "    'databricks/dolly-v2-7b',\n",
    "    # \n",
    "    'allenai/open-instruct-cot-7b',\n",
    "    'allenai/open-instruct-flan-v2-7b',\n",
    "    'allenai/open-instruct-dolly-7b',\n",
    "    'allenai/open-instruct-oasst1-7b',\n",
    "    'allenai/open-instruct-human-mix-7b',\n",
    "    'allenai/tulu-7b',\n",
    "]\n",
    "repo_ids = [\n",
    "#     'mistralai/Mistral-7B-v0.1',\n",
    "#     'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "#     'HuggingFaceH4/mistral-7b-sft-alpha',  # sft(ultrachat1.5m)\n",
    "#     'HuggingFaceH4/mistral-7b-sft-beta', # sft(ultrachat200k)\n",
    "#     'HuggingFaceH4/zephyr-7b-alpha', # sft(ultrachat1.5m)+dpo\n",
    "#     'HuggingFaceH4/zephyr-7b-beta',  # sft(ultrachat200k)+dpo\n",
    "]\n",
    "repo_ids = [\n",
    "#     'sentence-transformers/all-mpnet-base-v2',\n",
    "    'BAAI/bge-large-en-v1.5',\n",
    "    'jinaai/jina-embeddings-v2-base-en',\n",
    "]\n",
    "\n",
    "for repo_id in repo_ids:\n",
    "    snapshot_download(repo_id=repo_id, local_dir=os.path.join(save_dir, repo_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d0ff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beaker_configs\tenv.yml  model_licenses  requirements.txt\r\n",
      "data\t\teval\t open_instruct\t results\r\n",
      "Dockerfile\timages\t quantize\t scripts\r\n",
      "ds_configs\tLICENSE  README.md\t weight-diff-requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"SirNeural/flan_v2\", \n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=\"../data/raw_train/flan2022\",\n",
    "    local_dir_use_symlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb3bed8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5f6d4f03174646ac903ca79acb1898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecbde5f5b7c4075af8ece102ce63917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)56cac/.gitattributes:   0%|          | 0.00/2.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d983f899fb8f4540be1d65805a4852d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e5b2356cac/README.md:   0%|          | 0.00/4.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929c67f9d5924425a78176c8f2898689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)f92756993583.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd182f07727421dbc0849d790d06fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)d8309148a71f.parquet:   0%|          | 0.00/80.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b15b0081924e378bf4655c228bdb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fb894be3e50b.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8810ecc1d2b548f6b0992cab02e9e8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ac4afe5b93f4.parquet:   0%|          | 0.00/81.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abccd19ee0b4f7f887ad62c4131fae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ed25cfae92c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ec5705e05a4a7bbc1d7d065cf8b576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)04bcb6ae68c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e299ccee224459ca64367e9343795a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)75b92a2f48fd.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ccace6092c440a8221a3122e32a14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)402e417f35ca.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/data/raw_train/ultrachat_200k'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "repo_id = 'HuggingFaceH4/ultrachat_200k'\n",
    "local_dir = '../data/raw_train/ultrachat_200k'\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=repo_id, \n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05abbdf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='results/baselines/HuggingFaceH4/zephyr-7b-beta_fixtok', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='left', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<unk>', '<s>', '</s>', '<pad>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaTokenizerFast, AutoTokenizer, AddedToken\n",
    "\n",
    "\n",
    "for model_name_or_path in [\n",
    "    'results/baselines/huggyllama/llama-7b',\n",
    "    'results/baselines/NousResearch/Llama-2-7b-hf',\n",
    "    'results/baselines/mistralai/Mistral-7B-v0.1',\n",
    "    'results/baselines/HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "    'results/baselines/HuggingFaceH4/mistral-7b-sft-beta',\n",
    "    'results/baselines/HuggingFaceH4/zephyr-7b-alpha',\n",
    "    'results/baselines/HuggingFaceH4/zephyr-7b-beta',\n",
    "]:\n",
    "\n",
    "    tokenizer_kwargs = {\"use_fast\": True,}\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, **tokenizer_kwargs)\n",
    "    \n",
    "    num_added_tokens = tokenizer.add_special_tokens({\n",
    "        \"bos_token\": AddedToken(\"<s>\", normalized=False, special=True),\n",
    "        \"eos_token\": AddedToken(\"</s>\", normalized=False, special=True),\n",
    "        \"unk_token\": AddedToken(\"<unk>\", normalized=False, special=True),\n",
    "        \"pad_token\": AddedToken(\"<pad>\", normalized=False, special=True),\n",
    "    })\n",
    "\n",
    "    tmp_tok_path = os.path.join(\n",
    "        os.path.dirname(model_name_or_path),\n",
    "        os.path.basename(model_name_or_path)+'_fixtok')\n",
    "    \n",
    "    tokenizer.save_pretrained(tmp_tok_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tmp_tok_path, **tokenizer_kwargs)\n",
    "\n",
    "    for s, s_tokenized in [\n",
    "        (\"Hi<s>Hey</s>sir<unk>what<pad><pad>\", \n",
    "        ['▁Hi', '<s>', '▁Hey', '</s>', '▁sir', '<unk>', '▁what', '<pad>', '<pad>']),\n",
    "    ]:\n",
    "        assert(tokenizer.tokenize(s, add_special_tokens=False)==s_tokenized)\n",
    "\n",
    "    \n",
    "tokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31428670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_added_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd86dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/../data/raw_train/ultrachat_200k/HuggingFaceH4___parquet/HuggingFaceH4--ultrachat_200k-75c6e299e27d1db5/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'prompt_id', 'messages'],\n",
       "    num_rows: 207865\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "ds = load_dataset(\n",
    "    'HuggingFaceH4/ultrachat_200k',\n",
    "    cache_dir='../data/raw_train/ultrachat',\n",
    "    split='train_sft')\n",
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
