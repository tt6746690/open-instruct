{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7862ef",
   "metadata": {},
   "source": [
    "goal: save hf models from remote to local disk, so that I can populate the directory with evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff898065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "from huggingface_hub import snapshot_download\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba55cb6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210e5eeb026b4f09b2e040f6eb9e34b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c64057ec694e9f889ebc1e4a351b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287af7776a82421a86e43d8a0c42668a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b682d16edc1468fae492a1e6c5cc147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf1d44c507e461fbbe55f6d4b31065e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/183 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a973707414df44468c668b1cda5ecc8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0ceafd454d4f2ca71fe559fd662a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a87d9102784faf90e16bc5c11a1f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f852b1638976497da0368bbb2f248088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d520d8783ae844718f41203bae1c2af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62fcc439be5e4380b632b310759e6763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd043a226d94e7abc49ddaa4359bc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d05b4ed72d241a485e109907eebc3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "save_dir = '../results/baselines/'\n",
    "repo_ids = [\n",
    "    # encoder-decoder\n",
    "    # t5\n",
    "    't5-small',\n",
    "    't5-base',\n",
    "    't5-large',\n",
    "    't5-3b',\n",
    "    't5-11b',\n",
    "#     # flan-t5\n",
    "    'google/flan-t5-small',\n",
    "    'google/flan-t5-base',\n",
    "    'google/flan-t5-large',\n",
    "    'google/flan-t5-xl'\n",
    "    'google/flan-t5-xxl',\n",
    "#     # decoder-only\n",
    "#     # 124M, 355M, 774M, 1.5B\n",
    "    'gpt2',\n",
    "    'gpt2-medium',\n",
    "    'gpt2-large',\n",
    "    'gpt2-xl',\n",
    "    # mpt\n",
    "    'mosaicml/mpt-7b',\n",
    "    # llama\n",
    "    'huggyllama/llama-7b',\n",
    "    'NousResearch/Llama-2-7b-hf',\n",
    "    'NousResearch/Llama-2-7b-chat-hf',\n",
    "    'NousResearch/Llama-2-13b-hf',\n",
    "    # codellama \n",
    "    'codellama/CodeLlama-7b-hf',\n",
    "    'codellama/CodeLlama-7b-Python-hf',\n",
    "    'codellama/CodeLlama-7b-Instruct-hf',\n",
    "    # pythia\n",
    "    'EleutherAI/pythia-70m',\n",
    "    'EleutherAI/pythia-160m',\n",
    "    'EleutherAI/pythia-410m',\n",
    "    'EleutherAI/pythia-1b',\n",
    "    'EleutherAI/pythia-1.4b',\n",
    "    'EleutherAI/pythia-2.8b',\n",
    "    'EleutherAI/pythia-6.9b',\n",
    "    'EleutherAI/pythia-12b',\n",
    "    # instruction tuned pythia\n",
    "    'databricks/dolly-v2-7b',\n",
    "    # \n",
    "    'allenai/open-instruct-cot-7b',\n",
    "    'allenai/open-instruct-flan-v2-7b',\n",
    "    'allenai/open-instruct-dolly-7b',\n",
    "    'allenai/open-instruct-oasst1-7b',\n",
    "    'allenai/open-instruct-human-mix-7b',\n",
    "    'allenai/tulu-7b',\n",
    "    # sota chat instuct models\n",
    "    'mistralai/Mistral-7B-v0.1',\n",
    "    'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "    'HuggingFaceH4/mistral-7b-sft-alpha',  # sft(ultrachat1.5m)\n",
    "    'HuggingFaceH4/mistral-7b-sft-beta', # sft(ultrachat200k)\n",
    "    'HuggingFaceH4/zephyr-7b-alpha', # sft(ultrachat1.5m)+dpo\n",
    "    'HuggingFaceH4/zephyr-7b-beta',  # sft(ultrachat200k)+dpo\n",
    "    # embedding models\n",
    "    'sentence-transformers/all-mpnet-base-v2',\n",
    "    'BAAI/bge-large-en-v1.5',\n",
    "    'jinaai/jina-embeddings-v2-base-en',\n",
    "]\n",
    "\n",
    "repo_ids = [\n",
    "#     'deepseek-ai/deepseek-coder-6.7b-base',\n",
    "    'unsloth/llama-2-7b',\n",
    "]\n",
    "\n",
    "for repo_id in repo_ids:\n",
    "    snapshot_download(repo_id=repo_id, local_dir=os.path.join(save_dir, repo_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab49509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'results/baselines/unsloth/'\n",
    "config = AutoConfig.from_pretrained(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d0ff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beaker_configs\tenv.yml  model_licenses  requirements.txt\r\n",
      "data\t\teval\t open_instruct\t results\r\n",
      "Dockerfile\timages\t quantize\t scripts\r\n",
      "ds_configs\tLICENSE  README.md\t weight-diff-requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"SirNeural/flan_v2\", \n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=\"../data/raw_train/flan2022\",\n",
    "    local_dir_use_symlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb3bed8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5f6d4f03174646ac903ca79acb1898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecbde5f5b7c4075af8ece102ce63917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)56cac/.gitattributes:   0%|          | 0.00/2.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d983f899fb8f4540be1d65805a4852d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e5b2356cac/README.md:   0%|          | 0.00/4.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929c67f9d5924425a78176c8f2898689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)f92756993583.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd182f07727421dbc0849d790d06fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)d8309148a71f.parquet:   0%|          | 0.00/80.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b15b0081924e378bf4655c228bdb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fb894be3e50b.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8810ecc1d2b548f6b0992cab02e9e8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ac4afe5b93f4.parquet:   0%|          | 0.00/81.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abccd19ee0b4f7f887ad62c4131fae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ed25cfae92c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ec5705e05a4a7bbc1d7d065cf8b576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)04bcb6ae68c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e299ccee224459ca64367e9343795a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)75b92a2f48fd.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ccace6092c440a8221a3122e32a14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)402e417f35ca.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/data/raw_train/ultrachat_200k'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "repo_id = 'HuggingFaceH4/ultrachat_200k'\n",
    "local_dir = '../data/raw_train/ultrachat_200k'\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=repo_id, \n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6551f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05abbdf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CodeLlamaTokenizerFast(name_or_path='codellama/CodeLlama-7b-Instruct-hf_fixtok', vocab_size=32016, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['▁<PRE>', '▁<MID>', '▁<SUF>', '▁<EOT>', '▁<PRE>', '▁<MID>', '▁<SUF>', '▁<EOT>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32007: AddedToken(\"▁<PRE>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32008: AddedToken(\"▁<SUF>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32009: AddedToken(\"▁<MID>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32010: AddedToken(\"▁<EOT>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32016: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaTokenizerFast, AutoTokenizer, AddedToken\n",
    "\n",
    "\n",
    "for model_name_or_path in [\n",
    "#     'results/baselines/huggyllama/llama-7b',\n",
    "#     'results/baselines/NousResearch/Llama-2-7b-hf',\n",
    "#     'results/baselines/NousResearch/Llama-2-13b-hf',\n",
    "    'results/baselines/codellama/CodeLlama-7b-hf',\n",
    "    'results/baselines/codellama/CodeLlama-7b-Python-hf',\n",
    "    'results/baselines/codellama/CodeLlama-7b-Instruct-hf',\n",
    "#     'results/baselines/mistralai/Mistral-7B-v0.1',\n",
    "#     'results/baselines/HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "#     'results/baselines/HuggingFaceH4/mistral-7b-sft-beta',\n",
    "#     'results/baselines/HuggingFaceH4/zephyr-7b-alpha',\n",
    "#     'results/baselines/HuggingFaceH4/zephyr-7b-beta',\n",
    "#     'results/baselines/unsloth/llama-2-7b',\n",
    "]:\n",
    "\n",
    "    tokenizer_kwargs = {\"use_fast\": True,}\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, **tokenizer_kwargs)\n",
    "    \n",
    "    num_added_tokens = tokenizer.add_special_tokens({\n",
    "        \"bos_token\": AddedToken(\"<s>\", normalized=False, special=True),\n",
    "        \"eos_token\": AddedToken(\"</s>\", normalized=False, special=True),\n",
    "        \"unk_token\": AddedToken(\"<unk>\", normalized=False, special=True),\n",
    "        \"pad_token\": AddedToken(\"<pad>\", normalized=False, special=True),\n",
    "    })\n",
    "\n",
    "    tmp_tok_path = os.path.join(\n",
    "        os.path.dirname(model_name_or_path),\n",
    "        os.path.basename(model_name_or_path)+'_fixtok')\n",
    "    \n",
    "    tokenizer.save_pretrained(tmp_tok_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tmp_tok_path, **tokenizer_kwargs)\n",
    "\n",
    "    for s, s_tokenized in [\n",
    "        (\"Hi<s>Hey</s>sir<unk>what<pad><pad>\", \n",
    "        ['▁Hi', '<s>', '▁Hey', '</s>', '▁sir', '<unk>', '▁what', '<pad>', '<pad>']),\n",
    "    ]:\n",
    "        assert(tokenizer.tokenize(s, add_special_tokens=False)==s_tokenized)\n",
    "\n",
    "    \n",
    "tokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31428670",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39misnan(param)):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;66;03m# Found a parameter with NaN values\u001b[39;00m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m contains NaN values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd86dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/../data/raw_train/ultrachat_200k/HuggingFaceH4___parquet/HuggingFaceH4--ultrachat_200k-75c6e299e27d1db5/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'prompt_id', 'messages'],\n",
       "    num_rows: 207865\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "ds = load_dataset(\n",
    "    'HuggingFaceH4/ultrachat_200k',\n",
    "    cache_dir='../data/raw_train/ultrachat',\n",
    "    split='train_sft')\n",
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
