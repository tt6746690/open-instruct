{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7862ef",
   "metadata": {},
   "source": [
    "goal: save hf models from remote to local disk, so that I can populate the directory with evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff898065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "from huggingface_hub import snapshot_download\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba55cb6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1797643b5e904110b8c1b04c04171417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 21 files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709feabb68a94f89a98d78b42cc0dba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/10.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297320d87a1540a9b9f031efd85ed690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527e470669cd4681997ec7a764573209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading USE_POLICY.md:   0%|          | 0.00/4.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3406a76512eb4e7bb0476a5ec8dafe33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/175 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072ad5eb94504499ab2cc0647b3eb120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c6f09ade584c65a832044549b9e2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading LICENSE.txt:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f987d134a34b12971c5ca41d01f22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbdd04d28b6b4282bee1c5f433a960cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nsible-Use-Guide.pdf:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72febc6e084f4ee8b9631d0b0f5f1456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2587f95afb70420e967d923401a5bcb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/6.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1710ca94d92466c86b7f123054d2839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00006.bin:   0%|          | 0.00/9.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bafb3cdea64f9b91715611f2f28562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00006.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75ceaa9ae134cdea6e857f147dcfb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6054114999164f808c230ccb260dfb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00005-of-00006.bin:   0%|          | 0.00/9.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9e9e9c542e45928e5a8efcf6ee2f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00003-of-00006.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f863697e39a44f54a13ade0cc5374d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00004-of-00006.bin:   0%|          | 0.00/9.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9bbbda08d14c3397ab0c75858169e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00006-of-00006.bin:   0%|          | 0.00/2.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2542d709a53948f99abbb18c9e44c688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0db89fd88dd46d4a764fc0b6184c123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f48b4d70f2e4fb7ab05c3e483bd31cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba84a125433d4944a80f7d68dd40791a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "save_dir = '../results/baselines/'\n",
    "repo_ids = [\n",
    "    # encoder-decoder\n",
    "    # t5\n",
    "    't5-small',\n",
    "    't5-base',\n",
    "    't5-large',\n",
    "    't5-3b',\n",
    "    't5-11b',\n",
    "#     # flan-t5\n",
    "    'google/flan-t5-small',\n",
    "    'google/flan-t5-base',\n",
    "    'google/flan-t5-large',\n",
    "    'google/flan-t5-xl'\n",
    "    'google/flan-t5-xxl',\n",
    "#     # decoder-only\n",
    "#     # 124M, 355M, 774M, 1.5B\n",
    "    'gpt2',\n",
    "    'gpt2-medium',\n",
    "    'gpt2-large',\n",
    "    'gpt2-xl',\n",
    "    # mpt\n",
    "    'mosaicml/mpt-7b',\n",
    "    # llama\n",
    "    'huggyllama/llama-7b',\n",
    "    'NousResearch/Llama-2-7b-hf',\n",
    "    'NousResearch/Llama-2-7b-chat-hf',\n",
    "    # codellama \n",
    "    'codellama/CodeLlama-7b-hf',\n",
    "    'codellama/CodeLlama-7b-Python-hf',\n",
    "    'codellama/CodeLlama-7b-Instruct-hf',\n",
    "    # pythia\n",
    "    'EleutherAI/pythia-70m',\n",
    "    'EleutherAI/pythia-160m',\n",
    "    'EleutherAI/pythia-410m',\n",
    "    'EleutherAI/pythia-1b',\n",
    "    'EleutherAI/pythia-1.4b',\n",
    "    'EleutherAI/pythia-2.8b',\n",
    "    'EleutherAI/pythia-6.9b',\n",
    "    'EleutherAI/pythia-12b',\n",
    "    # instruction tuned pythia\n",
    "    'databricks/dolly-v2-7b',\n",
    "    # \n",
    "    'allenai/open-instruct-cot-7b',\n",
    "    'allenai/open-instruct-flan-v2-7b',\n",
    "    'allenai/open-instruct-dolly-7b',\n",
    "    'allenai/open-instruct-oasst1-7b',\n",
    "    'allenai/open-instruct-human-mix-7b',\n",
    "    'allenai/tulu-7b',\n",
    "    # sota chat instuct models\n",
    "    'mistralai/Mistral-7B-v0.1',\n",
    "    'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "    'HuggingFaceH4/mistral-7b-sft-alpha',  # sft(ultrachat1.5m)\n",
    "    'HuggingFaceH4/mistral-7b-sft-beta', # sft(ultrachat200k)\n",
    "    'HuggingFaceH4/zephyr-7b-alpha', # sft(ultrachat1.5m)+dpo\n",
    "    'HuggingFaceH4/zephyr-7b-beta',  # sft(ultrachat200k)+dpo\n",
    "    # embedding models\n",
    "    'sentence-transformers/all-mpnet-base-v2',\n",
    "    'BAAI/bge-large-en-v1.5',\n",
    "    'jinaai/jina-embeddings-v2-base-en',\n",
    "]\n",
    "\n",
    "repo_ids = [\n",
    "#     'deepseek-ai/deepseek-coder-6.7b-base',\n",
    "    'NousResearch/Llama-2-13b-hf',\n",
    "]\n",
    "\n",
    "for repo_id in repo_ids:\n",
    "    snapshot_download(repo_id=repo_id, local_dir=os.path.join(save_dir, repo_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d0ff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beaker_configs\tenv.yml  model_licenses  requirements.txt\r\n",
      "data\t\teval\t open_instruct\t results\r\n",
      "Dockerfile\timages\t quantize\t scripts\r\n",
      "ds_configs\tLICENSE  README.md\t weight-diff-requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"SirNeural/flan_v2\", \n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=\"../data/raw_train/flan2022\",\n",
    "    local_dir_use_symlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb3bed8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5f6d4f03174646ac903ca79acb1898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecbde5f5b7c4075af8ece102ce63917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)56cac/.gitattributes:   0%|          | 0.00/2.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d983f899fb8f4540be1d65805a4852d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e5b2356cac/README.md:   0%|          | 0.00/4.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929c67f9d5924425a78176c8f2898689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)f92756993583.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd182f07727421dbc0849d790d06fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)d8309148a71f.parquet:   0%|          | 0.00/80.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b15b0081924e378bf4655c228bdb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fb894be3e50b.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8810ecc1d2b548f6b0992cab02e9e8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ac4afe5b93f4.parquet:   0%|          | 0.00/81.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abccd19ee0b4f7f887ad62c4131fae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ed25cfae92c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ec5705e05a4a7bbc1d7d065cf8b576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)04bcb6ae68c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e299ccee224459ca64367e9343795a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)75b92a2f48fd.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ccace6092c440a8221a3122e32a14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)402e417f35ca.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/data/raw_train/ultrachat_200k'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "repo_id = 'HuggingFaceH4/ultrachat_200k'\n",
    "local_dir = '../data/raw_train/ultrachat_200k'\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=repo_id, \n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05abbdf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='results/baselines/HuggingFaceH4/zephyr-7b-beta_fixtok', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='left', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<unk>', '<s>', '</s>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaTokenizerFast, AutoTokenizer, AddedToken\n",
    "\n",
    "\n",
    "for model_name_or_path in [\n",
    "    'results/baselines/huggyllama/llama-7b',\n",
    "    'results/baselines/NousResearch/Llama-2-7b-hf',\n",
    "    'results/baselines/NousResearch/Llama-2-13b-hf',\n",
    "    'results/baselines/mistralai/Mistral-7B-v0.1',\n",
    "    'results/baselines/HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "    'results/baselines/HuggingFaceH4/mistral-7b-sft-beta',\n",
    "    'results/baselines/HuggingFaceH4/zephyr-7b-alpha',\n",
    "    'results/baselines/HuggingFaceH4/zephyr-7b-beta',\n",
    "]:\n",
    "\n",
    "    tokenizer_kwargs = {\"use_fast\": True,}\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, **tokenizer_kwargs)\n",
    "    \n",
    "    num_added_tokens = tokenizer.add_special_tokens({\n",
    "        \"bos_token\": AddedToken(\"<s>\", normalized=False, special=True),\n",
    "        \"eos_token\": AddedToken(\"</s>\", normalized=False, special=True),\n",
    "        \"unk_token\": AddedToken(\"<unk>\", normalized=False, special=True),\n",
    "        \"pad_token\": AddedToken(\"<pad>\", normalized=False, special=True),\n",
    "    })\n",
    "\n",
    "    tmp_tok_path = os.path.join(\n",
    "        os.path.dirname(model_name_or_path),\n",
    "        os.path.basename(model_name_or_path)+'_fixtok')\n",
    "    \n",
    "    tokenizer.save_pretrained(tmp_tok_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tmp_tok_path, **tokenizer_kwargs)\n",
    "\n",
    "    for s, s_tokenized in [\n",
    "        (\"Hi<s>Hey</s>sir<unk>what<pad><pad>\", \n",
    "        ['▁Hi', '<s>', '▁Hey', '</s>', '▁sir', '<unk>', '▁what', '<pad>', '<pad>']),\n",
    "    ]:\n",
    "        assert(tokenizer.tokenize(s, add_special_tokens=False)==s_tokenized)\n",
    "\n",
    "    \n",
    "tokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31428670",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39misnan(param)):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;66;03m# Found a parameter with NaN values\u001b[39;00m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m contains NaN values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd86dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/../data/raw_train/ultrachat_200k/HuggingFaceH4___parquet/HuggingFaceH4--ultrachat_200k-75c6e299e27d1db5/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'prompt_id', 'messages'],\n",
       "    num_rows: 207865\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "ds = load_dataset(\n",
    "    'HuggingFaceH4/ultrachat_200k',\n",
    "    cache_dir='../data/raw_train/ultrachat',\n",
    "    split='train_sft')\n",
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
