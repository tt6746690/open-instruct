{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7862ef",
   "metadata": {},
   "source": [
    "goal: save hf models from remote to local disk, so that I can populate the directory with evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff898065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "from huggingface_hub import snapshot_download\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba55cb6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfe4581aaef45a2aabc18f793136a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a6f164d21d44aab9c2f34bd69413b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c355499c2d764214a2c1cec64e0dfe7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading USE_POLICY.md:   0%|          | 0.00/4.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f488ff68f24d8986f850eb9b8cb491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba17d1b011c145fbbd25495475fbab74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/179 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e954822d0d4cbf9be23dabafe09678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee7a0fe55574d2b8e39268bbd058c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading LICENSE.txt:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98dbbb76775c430ca44e8ecea276799d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/10.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346fd1213c0243d49667cf12be700bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a5ead66d9040ab89350b30575b493e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b55c2c3848347e5814a712caa80c901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac991c4175fa4607aaed8669f3144f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a542f65968e54f2e9723e74932cb782f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62afdb61cf7449aa91764d5e9203551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98433d8dbeeb41408b3052dd516d2d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560c66a8111649b08becf5ee2d5ea632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00003.bin:   0%|          | 0.00/9.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d1777116a245959c6d7b2a1f7fd5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00003-of-00003.bin:   0%|          | 0.00/7.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c353edef22a74fff95ca756442e4f564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00003.bin:   0%|          | 0.00/9.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0cc643dbdd4911a646112b14bae646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "save_dir = '../results/baselines/'\n",
    "repo_ids = [\n",
    "    # encoder-decoder\n",
    "    # t5\n",
    "    't5-small',\n",
    "    't5-base',\n",
    "    't5-large',\n",
    "    't5-3b',\n",
    "    't5-11b',\n",
    "#     # flan-t5\n",
    "    'google/flan-t5-small',\n",
    "    'google/flan-t5-base',\n",
    "    'google/flan-t5-large',\n",
    "    'google/flan-t5-xl'\n",
    "    'google/flan-t5-xxl',\n",
    "#     # decoder-only\n",
    "#     # 124M, 355M, 774M, 1.5B\n",
    "    'gpt2',\n",
    "    'gpt2-medium',\n",
    "    'gpt2-large',\n",
    "    'gpt2-xl',\n",
    "    # mpt\n",
    "    'mosaicml/mpt-7b',\n",
    "    # llama\n",
    "    'huggyllama/llama-7b',\n",
    "    'NousResearch/Llama-2-7b-hf'\n",
    "    # codellama \n",
    "    'codellama/CodeLlama-7b-hf',\n",
    "    'codellama/CodeLlama-7b-Python-hf',\n",
    "    'codellama/CodeLlama-7b-Instruct-hf',\n",
    "    # pythia\n",
    "    'EleutherAI/pythia-70m',\n",
    "    'EleutherAI/pythia-160m',\n",
    "    'EleutherAI/pythia-410m',\n",
    "    'EleutherAI/pythia-1b',\n",
    "    'EleutherAI/pythia-1.4b',\n",
    "    'EleutherAI/pythia-2.8b',\n",
    "    'EleutherAI/pythia-6.9b',\n",
    "    'EleutherAI/pythia-12b',\n",
    "    # instruction tuned pythia\n",
    "    'databricks/dolly-v2-7b',\n",
    "    # \n",
    "    'allenai/open-instruct-cot-7b',\n",
    "    'allenai/open-instruct-flan-v2-7b',\n",
    "    'allenai/open-instruct-dolly-7b',\n",
    "    'allenai/open-instruct-oasst1-7b',\n",
    "    'allenai/open-instruct-human-mix-7b',\n",
    "    'allenai/tulu-7b',\n",
    "    # sota chat instuct models\n",
    "    'mistralai/Mistral-7B-v0.1',\n",
    "    'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "    'HuggingFaceH4/mistral-7b-sft-alpha',  # sft(ultrachat1.5m)\n",
    "    'HuggingFaceH4/mistral-7b-sft-beta', # sft(ultrachat200k)\n",
    "    'HuggingFaceH4/zephyr-7b-alpha', # sft(ultrachat1.5m)+dpo\n",
    "    'HuggingFaceH4/zephyr-7b-beta',  # sft(ultrachat200k)+dpo\n",
    "    # embedding models\n",
    "    'sentence-transformers/all-mpnet-base-v2',\n",
    "    'BAAI/bge-large-en-v1.5',\n",
    "    'jinaai/jina-embeddings-v2-base-en',\n",
    "]\n",
    "\n",
    "repo_ids = [\n",
    "#     'deepseek-ai/deepseek-coder-6.7b-base',\n",
    "    'NousResearch/Llama-2-7b-chat-hf',\n",
    "]\n",
    "\n",
    "for repo_id in repo_ids:\n",
    "    snapshot_download(repo_id=repo_id, local_dir=os.path.join(save_dir, repo_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d0ff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beaker_configs\tenv.yml  model_licenses  requirements.txt\r\n",
      "data\t\teval\t open_instruct\t results\r\n",
      "Dockerfile\timages\t quantize\t scripts\r\n",
      "ds_configs\tLICENSE  README.md\t weight-diff-requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"SirNeural/flan_v2\", \n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=\"../data/raw_train/flan2022\",\n",
    "    local_dir_use_symlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb3bed8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5f6d4f03174646ac903ca79acb1898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecbde5f5b7c4075af8ece102ce63917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)56cac/.gitattributes:   0%|          | 0.00/2.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d983f899fb8f4540be1d65805a4852d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e5b2356cac/README.md:   0%|          | 0.00/4.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929c67f9d5924425a78176c8f2898689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)f92756993583.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd182f07727421dbc0849d790d06fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)d8309148a71f.parquet:   0%|          | 0.00/80.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b15b0081924e378bf4655c228bdb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fb894be3e50b.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8810ecc1d2b548f6b0992cab02e9e8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ac4afe5b93f4.parquet:   0%|          | 0.00/81.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abccd19ee0b4f7f887ad62c4131fae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ed25cfae92c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ec5705e05a4a7bbc1d7d065cf8b576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)04bcb6ae68c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e299ccee224459ca64367e9343795a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)75b92a2f48fd.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ccace6092c440a8221a3122e32a14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)402e417f35ca.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/data/raw_train/ultrachat_200k'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "repo_id = 'HuggingFaceH4/ultrachat_200k'\n",
    "local_dir = '../data/raw_train/ultrachat_200k'\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=repo_id, \n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05abbdf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='results/baselines/HuggingFaceH4/zephyr-7b-beta_fixtok', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='left', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<unk>', '<s>', '</s>', '<pad>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaTokenizerFast, AutoTokenizer, AddedToken\n",
    "\n",
    "\n",
    "for model_name_or_path in [\n",
    "    'results/baselines/huggyllama/llama-7b',\n",
    "    'results/baselines/NousResearch/Llama-2-7b-hf',\n",
    "    'results/baselines/mistralai/Mistral-7B-v0.1',\n",
    "    'results/baselines/HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "    'results/baselines/HuggingFaceH4/mistral-7b-sft-beta',\n",
    "    'results/baselines/HuggingFaceH4/zephyr-7b-alpha',\n",
    "    'results/baselines/HuggingFaceH4/zephyr-7b-beta',\n",
    "]:\n",
    "\n",
    "    tokenizer_kwargs = {\"use_fast\": True,}\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, **tokenizer_kwargs)\n",
    "    \n",
    "    num_added_tokens = tokenizer.add_special_tokens({\n",
    "        \"bos_token\": AddedToken(\"<s>\", normalized=False, special=True),\n",
    "        \"eos_token\": AddedToken(\"</s>\", normalized=False, special=True),\n",
    "        \"unk_token\": AddedToken(\"<unk>\", normalized=False, special=True),\n",
    "        \"pad_token\": AddedToken(\"<pad>\", normalized=False, special=True),\n",
    "    })\n",
    "\n",
    "    tmp_tok_path = os.path.join(\n",
    "        os.path.dirname(model_name_or_path),\n",
    "        os.path.basename(model_name_or_path)+'_fixtok')\n",
    "    \n",
    "    tokenizer.save_pretrained(tmp_tok_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tmp_tok_path, **tokenizer_kwargs)\n",
    "\n",
    "    for s, s_tokenized in [\n",
    "        (\"Hi<s>Hey</s>sir<unk>what<pad><pad>\", \n",
    "        ['▁Hi', '<s>', '▁Hey', '</s>', '▁sir', '<unk>', '▁what', '<pad>', '<pad>']),\n",
    "    ]:\n",
    "        assert(tokenizer.tokenize(s, add_special_tokens=False)==s_tokenized)\n",
    "\n",
    "    \n",
    "tokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31428670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_added_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd86dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/../data/raw_train/ultrachat_200k/HuggingFaceH4___parquet/HuggingFaceH4--ultrachat_200k-75c6e299e27d1db5/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'prompt_id', 'messages'],\n",
       "    num_rows: 207865\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "ds = load_dataset(\n",
    "    'HuggingFaceH4/ultrachat_200k',\n",
    "    cache_dir='../data/raw_train/ultrachat',\n",
    "    split='train_sft')\n",
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
