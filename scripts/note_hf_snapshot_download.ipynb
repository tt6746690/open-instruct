{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7862ef",
   "metadata": {},
   "source": [
    "goal: save hf models from remote to local disk, so that I can populate the directory with evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff898065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "from huggingface_hub import snapshot_download\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba55cb6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5c22519ec349b1b88cab74fbd5fde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e7a374bf314701808c85c767b1dc5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0cdb299753/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bda56fc0f64b54861da2090bab9eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0429c75c1e4822960154fc09db498a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)db299753/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce3c4daa8c848b48aca61a7125f0b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)753/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551275abbfb64c7a9276ad55b2481943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b299753/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259d8032013e4afcb4caf963d4f48600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35e58eead87441db98d5d36fc3214fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)99753/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa02fb3dff34498bb4cea426f34b2cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edcc853de2544923ae31545443f3114c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac1d826b079498a8154fe10a367b4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)9753/train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "save_dir = '../results/baselines/'\n",
    "repo_ids = [\n",
    "    # encoder-decoder\n",
    "    # t5\n",
    "    't5-small',\n",
    "    't5-base',\n",
    "    't5-large',\n",
    "    't5-3b',\n",
    "    't5-11b',\n",
    "#     # flan-t5\n",
    "    'google/flan-t5-small',\n",
    "    'google/flan-t5-base',\n",
    "    'google/flan-t5-large',\n",
    "    'google/flan-t5-xl'\n",
    "    'google/flan-t5-xxl',\n",
    "#     # decoder-only\n",
    "#     # 124M, 355M, 774M, 1.5B\n",
    "    'gpt2',\n",
    "    'gpt2-medium',\n",
    "    'gpt2-large',\n",
    "    'gpt2-xl',\n",
    "#     # open-source\n",
    "    'huggyllama/llama-7b',\n",
    "    'NousResearch/Llama-2-7b-hf'\n",
    "    'mosaicml/mpt-7b',\n",
    "    # pythia\n",
    "    'EleutherAI/pythia-70m',\n",
    "    'EleutherAI/pythia-160m',\n",
    "    'EleutherAI/pythia-410m',\n",
    "    'EleutherAI/pythia-1b',\n",
    "    'EleutherAI/pythia-1.4b',\n",
    "    'EleutherAI/pythia-2.8b',\n",
    "    'EleutherAI/pythia-6.9b',\n",
    "    'EleutherAI/pythia-12b',\n",
    "    # instruction tuned pythia\n",
    "    'databricks/dolly-v2-7b',\n",
    "    # \n",
    "    'allenai/open-instruct-cot-7b',\n",
    "    'allenai/open-instruct-flan-v2-7b',\n",
    "    'allenai/open-instruct-dolly-7b',\n",
    "    'allenai/open-instruct-oasst1-7b',\n",
    "    'allenai/open-instruct-human-mix-7b',\n",
    "    'allenai/tulu-7b',\n",
    "]\n",
    "repo_ids = [\n",
    "#     'mistralai/Mistral-7B-v0.1',\n",
    "#     'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "#     'HuggingFaceH4/mistral-7b-sft-alpha',  # sft(ultrachat1.5m)\n",
    "#     'HuggingFaceH4/mistral-7b-sft-beta', # sft(ultrachat200k)\n",
    "#     'HuggingFaceH4/zephyr-7b-alpha', # sft(ultrachat1.5m)+dpo\n",
    "#     'HuggingFaceH4/zephyr-7b-beta',  # sft(ultrachat200k)+dpo\n",
    "]\n",
    "repo_ids = [\n",
    "    'sentence-transformers/all-mpnet-base-v2',\n",
    "]\n",
    "\n",
    "for repo_id in repo_ids:\n",
    "    snapshot_download(repo_id=repo_id, local_dir=os.path.join(save_dir, repo_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d0ff8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beaker_configs\tenv.yml  model_licenses  requirements.txt\r\n",
      "data\t\teval\t open_instruct\t results\r\n",
      "Dockerfile\timages\t quantize\t scripts\r\n",
      "ds_configs\tLICENSE  README.md\t weight-diff-requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"SirNeural/flan_v2\", \n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=\"../data/raw_train/flan2022\",\n",
    "    local_dir_use_symlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb3bed8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5f6d4f03174646ac903ca79acb1898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecbde5f5b7c4075af8ece102ce63917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)56cac/.gitattributes:   0%|          | 0.00/2.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d983f899fb8f4540be1d65805a4852d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e5b2356cac/README.md:   0%|          | 0.00/4.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929c67f9d5924425a78176c8f2898689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)f92756993583.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd182f07727421dbc0849d790d06fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)d8309148a71f.parquet:   0%|          | 0.00/80.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b15b0081924e378bf4655c228bdb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fb894be3e50b.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8810ecc1d2b548f6b0992cab02e9e8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ac4afe5b93f4.parquet:   0%|          | 0.00/81.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abccd19ee0b4f7f887ad62c4131fae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ed25cfae92c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ec5705e05a4a7bbc1d7d065cf8b576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)04bcb6ae68c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e299ccee224459ca64367e9343795a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)75b92a2f48fd.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ccace6092c440a8221a3122e32a14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)402e417f35ca.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/data/raw_train/ultrachat_200k'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "repo_id = 'HuggingFaceH4/ultrachat_200k'\n",
    "local_dir = '../data/raw_train/ultrachat_200k'\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=repo_id, \n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05abbdf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='results/baselines/HuggingFaceH4/zephyr-7b-beta_fixtok', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='left', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<unk>', '<s>', '</s>', '<pad>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaTokenizerFast, AutoTokenizer, AddedToken\n",
    "\n",
    "\n",
    "for model_name_or_path in [\n",
    "    'results/baselines/huggyllama/llama-7b',\n",
    "    'results/baselines/NousResearch/Llama-2-7b-hf',\n",
    "    'results/baselines/mistralai/Mistral-7B-v0.1',\n",
    "    'results/baselines/HuggingFaceH4/mistral-7b-sft-alpha',\n",
    "    'results/baselines/HuggingFaceH4/mistral-7b-sft-beta',\n",
    "    'results/baselines/HuggingFaceH4/zephyr-7b-alpha',\n",
    "    'results/baselines/HuggingFaceH4/zephyr-7b-beta',\n",
    "]:\n",
    "\n",
    "    tokenizer_kwargs = {\"use_fast\": True,}\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, **tokenizer_kwargs)\n",
    "    \n",
    "    num_added_tokens = tokenizer.add_special_tokens({\n",
    "        \"bos_token\": AddedToken(\"<s>\", normalized=False, special=True),\n",
    "        \"eos_token\": AddedToken(\"</s>\", normalized=False, special=True),\n",
    "        \"unk_token\": AddedToken(\"<unk>\", normalized=False, special=True),\n",
    "        \"pad_token\": AddedToken(\"<pad>\", normalized=False, special=True),\n",
    "    })\n",
    "\n",
    "    tmp_tok_path = os.path.join(\n",
    "        os.path.dirname(model_name_or_path),\n",
    "        os.path.basename(model_name_or_path)+'_fixtok')\n",
    "    \n",
    "    tokenizer.save_pretrained(tmp_tok_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tmp_tok_path, **tokenizer_kwargs)\n",
    "\n",
    "    for s, s_tokenized in [\n",
    "        (\"Hi<s>Hey</s>sir<unk>what<pad><pad>\", \n",
    "        ['▁Hi', '<s>', '▁Hey', '</s>', '▁sir', '<unk>', '▁what', '<pad>', '<pad>']),\n",
    "    ]:\n",
    "        assert(tokenizer.tokenize(s, add_special_tokens=False)==s_tokenized)\n",
    "\n",
    "    \n",
    "tokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31428670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_added_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd86dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/../data/raw_train/ultrachat_200k/HuggingFaceH4___parquet/HuggingFaceH4--ultrachat_200k-75c6e299e27d1db5/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'prompt_id', 'messages'],\n",
       "    num_rows: 207865\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "ds = load_dataset(\n",
    "    'HuggingFaceH4/ultrachat_200k',\n",
    "    cache_dir='../data/raw_train/ultrachat',\n",
    "    split='train_sft')\n",
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
