set -e
set -x
CUDA_VISIBLE_DEVICES=0 python note_llama_embeddings.py --dataset=mix_redundant --model_name_or_path=../results/baselines/huggyllama/llama-7b --shuffle --compute_grad --use_lora --lora_rank=512 --lora_alpha=11585 --compute_grad_embeddings --grad_randproj_components 4096 --max_seq_len=2048 --encode_fn_type=sft --text_pooling_type=meanpool --torch_dtype=float16 --save_dir=/dccstor/data-pruning/wpq/github/mitibm2023/external/open-instruct/scripts/model_outputs/sft/llama-7b+lora:r=512:a=11585+proj=4096