{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf2dd69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/__init__.py:25: UserWarning: Install `torch` for functionalities dependent on torch\n",
      "  warn(f'Install `torch` for functionalities dependent on torch')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,5\n",
      "5\n",
      "Wed Nov 22 23:01:41 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000004:04:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    64W / 300W |  31643MiB / 32510MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000004:05:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    63W / 300W |  31645MiB / 32510MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000004:06:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    63W / 300W |  31635MiB / 32510MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000035:03:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    64W / 300W |  32107MiB / 32510MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000035:04:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    38W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000035:05:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    37W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    683105      C   ...da3/envs/lavis/bin/python    31639MiB |\n",
      "|    1   N/A  N/A    683106      C   ...da3/envs/lavis/bin/python    31639MiB |\n",
      "|    2   N/A  N/A    683107      C   ...da3/envs/lavis/bin/python    31629MiB |\n",
      "|    3   N/A  N/A    683108      C   ...da3/envs/lavis/bin/python    32101MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from rosemary import jpt_parse_args, jpt_setup, jpt_in_notebook; jpt_setup()\n",
    "\n",
    "if jpt_in_notebook():\n",
    "    import os\n",
    "    print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \\\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'].split(',')[1]\n",
    "    # '0,1,2,3,4,5'\n",
    "    print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "    \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf384bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_run = False\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.ultrachat15.dppmapbd_nc=200_k=vmf_gamma=0.3_kmd=mpnet\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 64,\n",
      "    \"cpu_mem\": 256,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python note_pruning.py --dataset ultrachat15 --sort_by dppmapbd_nc=200_k=vmf_gamma=0.3_kmd=mpnet --model_name all-mpnet-base-v2 --encode_fn_type input --save_dir /gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/all-mpnet-base-v2/ultrachat15\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.ultrachat15.dppmapbd_nc=200_k=vmf_gamma=1.0_kmd=mpnet\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 64,\n",
      "    \"cpu_mem\": 256,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": false,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "python note_pruning.py --dataset ultrachat15 --sort_by dppmapbd_nc=200_k=vmf_gamma=1.0_kmd=mpnet --model_name all-mpnet-base-v2 --encode_fn_type input --save_dir /gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/all-mpnet-base-v2/ultrachat15\n",
      "#cmds:  2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "from rosemary import jpt_in_notebook\n",
    "from llm.submit import submit_job, multiline_to_singleline, shell_scripts_template_slurm\n",
    "\n",
    "log_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/'\n",
    "\n",
    "test_run = 1\n",
    "test_run = bool(test_run)\n",
    "\n",
    "# model_name = 'llama-7b'; encode_fn_type = 'sft'; md = 'llama7b'\n",
    "# model_name = 'llama-7b+lora:r=256:a=256'; encode_fn_type = 'sft'; md = 'llama7b'\n",
    "# model_name = 'mistral-7b+lora:r=256:a=256'; encode_fn_type = 'sft'; md = 'mistral7b'\n",
    "model_name = 'all-mpnet-base-v2'; encode_fn_type = 'input'; md = 'mpnet'\n",
    "# model_name = 'bge-large-en-v1.5'; encode_fn_type = 'input'; md = 'bge'\n",
    "\n",
    "\n",
    "sort_by_list = [\n",
    "    f'dppmapbd_nc=200_k=vmf_gamma={gamma}_kmd=mpnet' \n",
    "    for gamma in [.3, 1., 3., 10., 15.]] # [.3, 1., 3., 10., 15.]\n",
    "# sort_by_list += [f'dppmapbd_nc=200_k=lin_kmd=mpnet']\n",
    "# sort_by_list = [\n",
    "#     f'dppmap_theta={theta}_k=vmf_gamma=3.0_kmd=mpnet_q=log+prob_qmd=mistral7b' for theta in [0, .3, .6, .9, .95]\n",
    "# ]\n",
    "\n",
    "\n",
    "# nc_list = [100, 500, 1000]\n",
    "# nc_list = [100, 200, 300, 400, 500, 600]\n",
    "# sort_by_list = [\n",
    "#     f'semdedup_cl=kmeansfaisscd_md={md}_dist=cd_emb={emb}_nc={nc}'\n",
    "#     for nc in nc_list\n",
    "#     for emb in ['text+embedding', 'grad+rp+loraB'] # 'grad+rp+loraB' \n",
    "# ]\n",
    "\n",
    "# sort_by_list = [\n",
    "#     'random_s=0', 'random_s=1', 'random_s=2',\n",
    "#     'log_prob', 'logit_margin', 'el2n_agg=mean',\n",
    "#     'grad_loraB_l2n', 'numtoks'\n",
    "# ]\n",
    "# sort_by_list += [\n",
    "# #     'kmeansl2_emb=grad+rp+loraB_nc=300',\n",
    "# #     'kmeansl2_emb=grad+rp+loraB_nc=1000',\n",
    "#     'kmeansl2_emb=grad+rp+loraB_nc=3000',\n",
    "# #     'kmeansl2_emb=text+embedding_nc=300',\n",
    "#     'kmeansl2_emb=text+embedding_nc=1000',\n",
    "# #     'kmeansl2_emb=text+embedding_nc=3000',\n",
    "# ]\n",
    "# sort_by_list = ['numtoks']\n",
    "\n",
    "# sort_by_list += [\n",
    "#     'dppmap_emb=grad+rp+loraB_k=Kcos', \n",
    "#     'dppmap_emb=text+embedding_k=Kcos', \n",
    "#     'dppmap_emb=grad+rp+loraB_k=Kcosp', \n",
    "#     'dppmap_emb=text+embedding_k=Kcosp',\n",
    "#     'dppmap_emb=grad+rp+loraB_k=Kcos1np', \n",
    "#     'dppmap_emb=text+embedding_k=Kcos1np',\n",
    "# ]\n",
    "# dataset_list = ['lima']\n",
    "# dataset_list = ['flan2022_1m']\n",
    "# dataset_list = ['tulu_v1_mix']\n",
    "# dataset_list = ['ultrachat']\n",
    "dataset_list = ['ultrachat15']\n",
    "# dataset_list = ['wizardlm']\n",
    "# dataset_list = ['sharegpt']\n",
    "\n",
    "\n",
    "# sort_by_list = [\n",
    "#  'log_prob',\n",
    "#  'el2n_agg=mean',\n",
    "#  'el2n_agg=l2n',\n",
    "#  'logit_margin',\n",
    "# ]\n",
    "# if 'lora' in model_name:\n",
    "#     sort_by_list += ['grad_loraB_l2n']\n",
    "# else:\n",
    "#     sort_by_list += ['grad_all_l2n', 'grad_qkv_l2n', 'grad_mlp_l2n', 'grad_last_l2n',]\n",
    "# sort_by_list = ['kmeansl2_emb=grad+rp+loraB_nc=30',\n",
    "#                 'kmeansl2_emb=text+embedding_nc=30']\n",
    "# dataset_list = ['lima']\n",
    "\n",
    "\n",
    "# model_name = 'pythia-1b-deduped'\n",
    "# model_name = 'pythia-1b-deduped+lora:r=256:a=256'\n",
    "# dataset_list = ['cot', 'dolly', 'flan_v2', 'lima', 'oasst1']\n",
    "# # sort_by_list = ['random_s=0', \n",
    "# #                 'log_prob', 'logit_margin', 'el2n_agg=mean', 'el2n_agg=l2n', \n",
    "# #                 'kmeansl2_nc=3000', 'kmeanscd_nc=3000',\n",
    "# #                 'grad_loraB_l2n',\n",
    "# #                 'grad_all_l2n', 'grad_qkv_l2n', 'grad_mlp_l2n', 'grad_last_l2n',\n",
    "# #                ]\n",
    "# sort_by_list = ['grad_loraB_l2n']\n",
    "\n",
    "from note_pruning_analysis import data_inds_dir\n",
    "\n",
    "options_list = itertools.product(dataset_list, sort_by_list)\n",
    "\n",
    "print('test_run =',test_run)\n",
    "cmds = []\n",
    "for dataset, sort_by in options_list:\n",
    "    save_dir = os.path.join(data_inds_dir, model_name, dataset)\n",
    "    cmd = f\"\"\"\n",
    "     python note_pruning.py \\\n",
    "        --dataset {dataset} \\\n",
    "        --sort_by {sort_by} \\\n",
    "        --model_name {model_name} \\\n",
    "        --encode_fn_type {encode_fn_type} \\\n",
    "        --save_dir {save_dir} \\\n",
    "    \"\"\".strip()\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    shell_scripts = shell_scripts_template_slurm.format(\n",
    "        conda_env='open-instruct',\n",
    "        cwd=os.getcwd(),\n",
    "        cmd=cmd,\n",
    "        log_dir=log_dir,\n",
    "        save_dir=save_dir)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=f'prune.{dataset}.{sort_by}', \n",
    "        nodes=1,\n",
    "        num_cpus=64, # 32\n",
    "        cpu_mem=256, # 128\n",
    "        num_gpus=1,\n",
    "        gpu_type='v100',\n",
    "        test_run=test_run,\n",
    "        job_duration=6,\n",
    "    )\n",
    "    cmds.append(cmd)\n",
    "    print(cmd)\n",
    "        \n",
    "print('#cmds: ', len(cmds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54834c41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/__init__.py:25: UserWarning: Install `torch` for functionalities dependent on torch\n",
      "  warn(f'Install `torch` for functionalities dependent on torch')\n",
      "{\n",
      "  \"dataset\": \"ultrachat15\",\n",
      "  \"sort_by\": \"dppmapbd_nc=200_k=vmf_gamma=0.3_kmd=mpnet\",\n",
      "  \"model_name\": \"all-mpnet-base-v2\",\n",
      "  \"save_dir\": \"/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/all-mpnet-base-v2/ultrachat15\",\n",
      "  \"encode_fn_type\": \"input\",\n",
      "  \"test_run\": false\n",
      "}\n",
      "Calling note_pruning_dpp.compute_dppmap with kwargs={\n",
      "    \"dppmap_type\": \"dppmapbd\",\n",
      "    \"dataset\": \"ultrachat15\",\n",
      "    \"kernel_type\": \"vmf\",\n",
      "    \"kernel_embed_model\": \"mpnet\",\n",
      "    \"kernel_embed_type\": \"text_embedding\",\n",
      "    \"kernel_kwargs\": {\n",
      "        \"gamma\": 0.3\n",
      "    },\n",
      "    \"quality_score_type\": null,\n",
      "    \"quality_score_embed_model\": null,\n",
      "    \"theta\": 0.0,\n",
      "    \"device\": \"cuda\",\n",
      "    \"max_length\": 2192\n",
      "}\n",
      "dppmapbd: cluster = 0 / 200\n",
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/note_pruning_dpp.py:199: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /tmp/pytorch/aten/src/ATen/native/TensorShape.cpp:3582.)\n",
      "  S = X@Y.T\n",
      "100%|███████████████████████████████████████| 2191/2191 [00:54<00:00, 40.10it/s]\n",
      "dppmapbd: cluster = 1 / 200\n",
      "100%|██████████████████████████████████████| 2191/2191 [00:14<00:00, 151.32it/s]\n",
      "dppmapbd: cluster = 2 / 200\n",
      "100%|███████████████████████████████████████| 2191/2191 [00:26<00:00, 83.27it/s]\n",
      "dppmapbd: cluster = 3 / 200\n",
      "100%|██████████████████████████████████████| 2191/2191 [00:20<00:00, 109.29it/s]\n",
      "dppmapbd: cluster = 4 / 200\n",
      "100%|██████████████████████████████████████| 2191/2191 [00:13<00:00, 163.26it/s]\n",
      "dppmapbd: cluster = 5 / 200\n",
      "100%|██████████████████████████████████████| 2191/2191 [00:05<00:00, 408.34it/s]\n",
      "dppmapbd: cluster = 6 / 200\n",
      "100%|██████████████████████████████████████| 2191/2191 [00:05<00:00, 403.63it/s]\n",
      "dppmapbd: cluster = 7 / 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 python note_pruning.py --dataset ultrachat15 --sort_by dppmapbd_nc=200_k=vmf_gamma=1.0_kmd=mpnet --model_name all-mpnet-base-v2 --encode_fn_type input --save_dir /gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/all-mpnet-base-v2/ultrachat15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('note_pruning_run_cmds.sh', 'w') as f:\n",
    "    s = 'set -e\\nset -x\\n'\n",
    "    devices = os.environ['CUDA_VISIBLE_DEVICES']\n",
    "    devices = 1\n",
    "    s += '\\n\\n'.join([f\"CUDA_VISIBLE_DEVICES={devices} \"+x for x in cmds])\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3363aa87",
   "metadata": {},
   "source": [
    "### Generate curriculum from pre-computed scores (via `note_pruning.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a25a293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save inds (length = 100000) to curriculum/all-mpnet-base-v2/ultrachat15/semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=200_neg/inds_prune_size=100000_ep=2.pkl\n",
      "save inds (length = 100000) to curriculum/all-mpnet-base-v2/ultrachat15/semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=1000/inds_prune_size=100000_ep=2.pkl\n",
      "save inds (length = 100000) to curriculum/all-mpnet-base-v2/ultrachat15/semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=1000_neg/inds_prune_size=100000_ep=2.pkl\n",
      "save inds (length = 100000) to curriculum/all-mpnet-base-v2/ultrachat15/semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=600/inds_prune_size=100000_ep=2.pkl\n",
      "save inds (length = 100000) to curriculum/all-mpnet-base-v2/ultrachat15/semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=600_neg/inds_prune_size=100000_ep=2.pkl\n",
      "save inds (length = 100000) to curriculum/all-mpnet-base-v2/ultrachat15/dppmapbd_nc=200_k=lin_kmd=mpnet/inds_prune_size=100000_ep=2.pkl\n",
      "save inds (length = 100000) to curriculum/all-mpnet-base-v2/ultrachat15/semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=100_neg/inds_prune_size=100000_ep=2.pkl\n",
      "save inds (length = 100000) to curriculum/all-mpnet-base-v2/ultrachat15/semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=400_neg/inds_prune_size=100000_ep=2.pkl\n",
      "save inds (length = 100000) to curriculum/all-mpnet-base-v2/ultrachat15/semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=500_neg/inds_prune_size=100000_ep=2.pkl\n",
      "save inds (length = 100000) to curriculum/all-mpnet-base-v2/ultrachat15/semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=100/inds_prune_size=100000_ep=2.pkl\n",
      "save inds (length = 100000) to curriculum/all-mpnet-base-v2/ultrachat15/semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=500/inds_prune_size=100000_ep=2.pkl\n",
      "save inds (length = 100000) to curriculum/all-mpnet-base-v2/ultrachat15/semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=400/inds_prune_size=100000_ep=2.pkl\n",
      "save inds (length = 100000) to curriculum/all-mpnet-base-v2/ultrachat15/semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=200/inds_prune_size=100000_ep=2.pkl\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from note_curriculum import (\n",
    "    get_curriculum_scores,\n",
    "    get_curriculum,\n",
    "    generate_curriculum,\n",
    "    generate_curriculum_forall_scoring_fn,\n",
    "    scores_path_to_attrs,\n",
    "    np_random_choice_maximize_noreplacement,\n",
    "    plt_curriculum,\n",
    ")\n",
    "from note_pruning_analysis import assets_dir\n",
    "\n",
    "# model_name = 'llama-7b'; dataset = 'tulu_v1_mix'; M = 150_000\n",
    "# model_name = 'llama-7b'; dataset = 'sharegpt'; M = 150_000\n",
    "\n",
    "## mistral+ultrachat\n",
    "# model_name = 'mistral-7b'; dataset = 'ultrachat200k'; M = 50_000\n",
    "# model_name = 'mistral-7b'; dataset = 'ultrachat15'; M = 100_000\n",
    "\n",
    "## semdedup\n",
    "# model_name = 'llama-7b'; dataset = 'wizardlm'; M = 100_000\n",
    "# model_name = 'all-mpnet-base-v2'; dataset = 'wizardlm'; M = 100_000\n",
    "# model_name = 'bge-large-en-v1.5'; dataset = 'wizardlm'; M = 100_000\n",
    "model_name = 'all-mpnet-base-v2'; dataset = 'ultrachat15'; M = 100_000\n",
    "# model_name = 'mistral-7b'; dataset = 'ultrachat15'; M = 100_000\n",
    "\n",
    "\n",
    "pacing_fn_list = [\n",
    "#     f'prune_size={M}_ep=1',\n",
    "    f'prune_size={M}_ep=2',\n",
    "#     f'prune_size={M}_ep=3',\n",
    "#     f'singlestep_size={M}_startingfrac=0.1',\n",
    "#     f'singlestep_size={M}_startingfrac=0.05',\n",
    "#     f'fep_size={M}_nsteps=5_startingfrac=0.05_inc=1.5',\n",
    "]\n",
    "\n",
    "output_list = generate_curriculum_forall_scoring_fn(\n",
    "    model_name, dataset, pacing_fn_list, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774da90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772cdbf7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from note_curriculum import get_curriculum_scores, generate_curriculum, plt_curriculum\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_name = 'mistral-7b'; dataset = 'ultrachat'; M =  50_000\n",
    "# model_name = 'llama-7b'; dataset = 'tulu_v1_mix'; M = 150_000\n",
    "\n",
    "\n",
    "paths = glob.glob('curriculum/*/*/*/scores.pkl')\n",
    "paths = [x for x in paths if 'llama' in x and 'tulu_v1_mix' in x and 'log_prob_neg' in x]\n",
    "path = paths[0]\n",
    "\n",
    "verbose = True\n",
    "print(path)\n",
    "pacing_fn = f'prune_size={M}_ep=3'\n",
    "# pacing_fn = f'singlestep_size={M}_startingfrac=0.1'\n",
    "# pacing_fn = f'singlestep_size={M}_startingfrac=0.2'\n",
    "# pacing_fn = f'singlestep_size={M}_startingfrac=0.3'\n",
    "# pacing_fn = f'fep_size={M}_nsteps=5_startingfrac=0.1_inc=2'\n",
    "# pacing_fn = f'fep_size={M}_nsteps=5_startingfrac=0.1_inc=1.5'\n",
    "# pacing_fn = f'fep_size={M}_nsteps=5_startingfrac=0.2_inc=1.5'\n",
    "# pacing_fn = f'fep_size={M}_nsteps=5_startingfrac=0.1_inc=1.5'\n",
    "\n",
    "pacing_fn_list = [\n",
    "    f'prune_size={M}_ep=3',\n",
    "    f'singlestep_size={M}_startingfrac=0.05',\n",
    "#     f'singlestep_size={M}_startingfrac=0.1',\n",
    "#     f'singlestep_size={M}_startingfrac=0.2',\n",
    "#     f'singlestep_size={M}_startingfrac=0.3',\n",
    "#     f'fep_size={M}_nsteps=5_startingfrac=0.1_inc=1.5',\n",
    "#     f'fep_size={M}_nsteps=5_startingfrac=0.1_inc=2',\n",
    "#     f'fep_size={M}_nsteps=5_startingfrac=0.1_inc=3',\n",
    "    f'fep_size={M}_nsteps=5_startingfrac=0.05_inc=1.5',\n",
    "    f'fep_size={M}_nsteps=5_startingfrac=0.05_inc=2',\n",
    "#     f'fep_size={M}_nsteps=5_startingfrac=0.05_inc=3',\n",
    "#     f'fep_size={M}_nsteps=5_startingfrac=0.05_inc=1.25'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "nrows = len(pacing_fn_list)\n",
    "fig, axs = plt.subplots(nrows, 3, figsize=(15,3*nrows), sharey=False, gridspec_kw={'width_ratios': [2,.5,.5]})\n",
    "\n",
    "for i, pacing_fn in enumerate(pacing_fn_list):\n",
    "\n",
    "    plt_kwargs = generate_curriculum(path, pacing_fn, verbose=True, save_output=False)\n",
    "    output = plt_kwargs.pop('output')\n",
    "    plt_kwargs.update({'fig': fig, 'axs': axs[i]})\n",
    "    plt_curriculum(**plt_kwargs)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "save_plt = 0\n",
    "if save_plt:\n",
    "    model_name, dataset, scoring_fn = output['model_name'], output['dataset'], output['scoring_fn']\n",
    "    save_path = os.path.join(\n",
    "        assets_dir, f'note_curriculum_{model_name}:{dataset}:{scoring_fn}.png')\n",
    "    fig.savefig(save_path, bbox_inches='tight', dpi=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82473d",
   "metadata": {},
   "source": [
    "### main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c1891b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm \n",
    "\n",
    "import pyarrow\n",
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "\n",
    "from note_pruning import (\n",
    "    save_to_pickle,\n",
    "    save_sorted_inds,\n",
    "    sort_kmeans_dist_to_cluster_centers,\n",
    "    sort_dpp_map,\n",
    "    save_prune_results,\n",
    "    sort_dpp_map_memefficient,\n",
    ")\n",
    "from note_pruning_analysis import get_lm_output\n",
    "from note_pruning_dpp import torch_vmf_kernel, torch_rbf_kernel\n",
    "from functools import partial\n",
    "from rosemary import parse_kv_from_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c45b5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultrachat15 all-mpnet-base-v2 dppmap_emb=text+embedding_k=Kcos\n",
      "data_inds/input/all-mpnet-base-v2/ultrachat15\n"
     ]
    }
   ],
   "source": [
    "test_run = False\n",
    "dataset = 'tulu_v1_human_mix'\n",
    "dataset = 'tulu_v2_human_mix'\n",
    "dataset = 'flan_v2'\n",
    "dataset = 'lima'\n",
    "dataset = 'flan2022_1m'\n",
    "dataset = 'tulu_v1_mix'\n",
    "dataset = 'lima'\n",
    "dataset = 'ultrachat200k'\n",
    "dataset = 'wizardlm'\n",
    "dataset = 'ultrachat15'\n",
    "\n",
    "# sort_by = 'random_s=0'\n",
    "# sort_by = 'kmeansl2_nc=3000'\n",
    "# sort_by = 'kmeanscd_nc=3000'\n",
    "# sort_by = 'log_prob'\n",
    "# sort_by = 'dppmap_k=Kcos'\n",
    "# sort_by = 'dppmap_k=Kcos1np'\n",
    "# sort_by = 'el2n'\n",
    "# sort_by = 'grad_norm'\n",
    "# sort_by = 'kmeansl2_emb=grad+rp+loraB_nc=3000'\n",
    "# sort_by = 'kmeansl2_emb=text+embedding_nc=3000'\n",
    "sort_by = 'dppmap_emb=text+embedding_k=Kcos'\n",
    "# sort_by = 'logit_margin'\n",
    "# rhov1: mistral-7b base-tuned(ultrachat200k_beforesplitlongconv)\n",
    "# sort_by = 'rhov1'\n",
    "# sort_by = 'numtoks'\n",
    "# sort_by = 'semdedup_cl=kmeansfaisscd_md=mpnet_dist=cd_emb=text+embedding_nc=200'\n",
    "\n",
    "# used for generating model output.\n",
    "# model_name = 'llama-7b'; encode_fn_type = 'sft'\n",
    "# model_name = 'llama-7b_ft=hmv1'; encode_fn_type = 'sft'\n",
    "# model_name = 'llama-7b+lora:r=256:a=256'; encode_fn_type = 'sft'\n",
    "# model_name = 'mistral-7b+lora:r=256:a=256'; encode_fn_type = 'sft'\n",
    "model_name = 'all-mpnet-base-v2'; encode_fn_type = 'input'\n",
    "# model_name = 'bge-large-en-v1.5'; encode_fn_type = 'input'\n",
    "\n",
    "# model_name = 'mistral-7b+lora:r=256:a=256__rho__mistral-7b-ultrachat200k-v1+lora:r=256:a=256'\n",
    "\n",
    "\n",
    "save_dir = f\"data_inds/\"\n",
    "save_dir = os.path.join(save_dir, '' if encode_fn_type=='sft' else encode_fn_type, model_name, dataset)\n",
    "os.makedirs(save_dir, exist_ok=True) \n",
    "\n",
    "print(dataset, model_name, sort_by)\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d78b90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'utf-8' codec can't decode byte 0xe2 in position 68208: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 90650: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 67269-67270: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 83845-83846: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 68285-68286: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 93620: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 81925-81926: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 107547-107548: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 80949-80950: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 84842: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 69580: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 83214: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 92946: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 103397-103398: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 93313-93314: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 67637-67638: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 83540: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 82890: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 91340: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 68310: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 66671-66672: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 106576: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 91060: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 70297-70298: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 105282: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 86785-86786: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 83247-83248: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 97819-97820: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 99776: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 97515-97516: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 114356: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 176608-176609: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 31634: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 46224: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 85708-85709: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 84408: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 83785-83786: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 38826-38827: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 37302: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 84699: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 44650: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 108406-108407: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 35344: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 44852-44853: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 89593-89594: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 45201: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 38012: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 37388: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 43612: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 93183: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 48937: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 29269-29270: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 99586-99587: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 35288-35289: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 84878: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 83866: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 82879-82880: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 69263-69264: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 82548: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 85163-85164: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 83434: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 100691-100692: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 36919-36920: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 84501-84502: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 40546-40547: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 93276: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 50684: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 85054: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 37341: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 35892-35893: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 38877-38878: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 39631: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 37767: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 83757-83758: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 47989-47990: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 32113-32114: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 38474: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 84432: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 101311-101312: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 35889-35890: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 84476: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 85124: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 82234: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 81883-81884: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 81909-81910: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 51305-51306: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 40417-40418: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 42570: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 82207-82208: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 83205-83206: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 49038: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 44538-44539: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 82881-82882: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 50110: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 49686: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 36291-36292: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 52303-52304: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 78345-78346: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 109708-109709: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 37125-37126: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 35266: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 85728: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 34055-34056: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 84501-84502: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 84405-84406: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 40875: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 81884: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 48773-48774: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 48424: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 80253-80254: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 80912: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 86349-86350: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 42008-42009: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 51655-51656: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 84501-84502: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 85378: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 81585-81586: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 37982-37983: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 55219-55220: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 83503-83504: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 83853-83854: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 39088-39089: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 32848-32849: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 51332: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 42583: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 42578: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 50036: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 51306: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 29316-29317: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 36431: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 83854: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 86025-86026: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 103927-103928: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 41857-41858: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 84756: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 84729-84730: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 99136-99137: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 39576: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 51656: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 55193-55194: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 42338: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 107487-107488: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 31512-31513: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 83828: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 81262: invalid continuation byte \n",
      " Re-try reading bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'utf-8' codec can't decode byte 0xe0 in position 118030: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 81560: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 36092: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 81261-81262: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 77380: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 82587-82588: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 64119-64120: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 83205-83206: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 81915-81916: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 84208: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 86446: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 84178: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 84856: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 82239-82240: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 86775-86776: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 67360: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 109532: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 82524: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 105545-105546: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 65624: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 107498: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 110440: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 94609-94610: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 101088: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 107215-107216: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 66690: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 106287-106288: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 105017-105018: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 104975-104976: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 109203-109204: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 67706: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 106279-106280: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 104360: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 103644: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 68327-68328: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 83550: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 68295-68296: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 67945-67946: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 68943-68944: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 62768: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 78022: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 68978: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 49306-49307: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 81517-81518: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 151860: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 33336: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 95163: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 51973-51974: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe0 in position 83312: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 89278-89279: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 85146: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 105296: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 85801-85802: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 97210: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 71862: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 49434: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 80957-80958: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 105603-105604: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 72858: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 69644: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 106954: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 65064: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 95912: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 101768: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 70880: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 70263-70264: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 95937-95938: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 68301-68302: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 94888: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 104957-104958: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 70869-70870: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 72191-72192: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 68300: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 110147-110148: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 94276: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 104642: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 105614: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 94640: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 93319-93320: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 67050: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 68292: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 65669-65670: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 102360: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 70527-70528: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 96585-96586: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 70222: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 107839-107840: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 71202: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 65052: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 66400: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 65077-65078: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 68909-68910: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 70543-70544: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 68301-68302: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 85780: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 68582: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 101033-101034: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 83803-83804: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 84784: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 73146: invalid continuation byte \n",
      " Re-try reading bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'utf-8' codec can't decode byte 0xe2 in position 100086: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 85105-85106: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 81243-81244: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 107858: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 84440: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 71173-71174: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 83188: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 103595-103596: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 85079-85080: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 69230: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 83809-83810: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 85079-85080: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 81542: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 83458: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 86369-86370: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 84128: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 70174: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 104563-104564: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 85077-85078: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 86059-86060: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 102636: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 84203-84204: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 72205-72206: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode bytes in position 102073-102074: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 82250: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 83870: invalid continuation byte \n",
      " Re-try reading bytes\n",
      "'utf-8' codec can't decode byte 0xe2 in position 69638: invalid continuation byte \n",
      " Re-try reading bytes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from glob import glob\n",
    "\n",
    "paths = glob('results/*/*/eval/*/*.out')\n",
    "\n",
    "\n",
    "def read_text(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return f.read()\n",
    "    \n",
    "def read_text_bytes(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return f.read().decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "oom_eval_paths = []\n",
    "for path in paths:\n",
    "    try:\n",
    "        s = read_text(path)\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(e, '\\n Re-try reading bytes')\n",
    "        s = read_text_bytes(path)\n",
    "    if 'CUDA out of memory' in s:\n",
    "        oom_eval_paths.append(path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91570dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results/oi4_tulu_v1_mix_ep=3/llama-7b_tuluv1m:50k_random_s=1/eval/alpacafarm_ann=chatgpt_chatfmt/1096790.out',\n",
       " 'results/oi5_ultrachat15:mistral-7b/mistral-7b_ultrachat15_score=random:s=0_pace=prune:size=100000:ep=2/eval/gsm_s=8_cot_chatfmt/1170623.out',\n",
       " 'results/oi5_ultrachat15:mistral-7b/mistral-7b_ultrachat15_score=random:s=0_pace=prune:size=100000:ep=2/eval/humaneval_chatfmt/1170626.out',\n",
       " 'results/oi3/llama-7b_all:100k/eval/tydiqa_s=1_gp_chatfmt/798768.out',\n",
       " 'results/oi3/llama-7b_all:100k/eval/tydiqa_s=1_gp/815636.out',\n",
       " 'results/oi3/llama-7b_all:400k_humanmix/eval/tydiqa_s=1_gp_chatfmt/930364.out',\n",
       " 'results/oi3/llama-7b_all:400k_humanmix/eval/tydiqa_s=1_gp/930355.out',\n",
       " 'results/oi3/llama-7b_all:600k_humanmix/eval/tydiqa_s=1_gp_chatfmt/933798.out',\n",
       " 'results/oi3/llama-7b_all:600k_humanmix/eval/tydiqa_s=1_gp/933789.out',\n",
       " 'results/oi3/llama-7b_all:200k_humanmix/eval/tydiqa_s=1_gp_chatfmt/823171.out',\n",
       " 'results/oi3/llama-7b_all:200k_humanmix/eval/tydiqa_s=1_gp/826095.out']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in oom_eval_paths if 'ft1_ep2' in x or 'oi' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f821f610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on dcs254\n",
      "======\n",
      "+ echo ======\n",
      "======\n",
      "+ srun python -m eval.codex_humaneval.run_eval --data_file data/eval/codex_humaneval/HumanEval.jsonl.gz --model_name_or_path results/ft1_ep=2/llama-7b_cot --save_dir results/ft1_ep=2/llama-7b_cot/eval/humaneval --eval_batch_size 10 --eval_pass_at_ks 1 --unbiased_sampling_size_n 1 --temperature 0.1\n",
      "[2023-10-27 23:43:55,364] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Number of examples: 164\n",
      "Loading model and tokenizer...\n",
      "\r",
      "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\r",
      "Loading checkpoint shards:  33%|███▎      | 1/3 [00:08<00:17,  8.63s/it]\r",
      "Loading checkpoint shards:  67%|██████▋   | 2/3 [00:16<00:08,  8.38s/it]\r",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:22<00:00,  7.27s/it]\r",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:22<00:00,  7.59s/it]\n",
      "Sampling iter: 0 / 1\n",
      "\r",
      "Generating Completions:   0%|          | 0/164 [00:00<?, ?it/s]\r",
      "Generating Completions:   6%|▌         | 10/164 [00:59<15:18,  5.97s/it]\r",
      "Generating Completions:  12%|█▏        | 20/164 [01:56<13:55,  5.80s/it]\r",
      "Generating Completions:  18%|█▊        | 30/164 [02:53<12:51,  5.76s/it]\r",
      "Generating Completions:  24%|██▍       | 40/164 [03:53<12:02,  5.83s/it]\r",
      "Generating Completions:  30%|███       | 50/164 [04:49<10:58,  5.77s/it]\r",
      "Generating Completions:  37%|███▋      | 60/164 [05:45<09:54,  5.71s/it]\r",
      "Generating Completions:  43%|████▎     | 70/164 [06:45<09:06,  5.82s/it]\r",
      "Generating Completions:  49%|████▉     | 80/164 [07:45<08:12,  5.87s/it]\r",
      "Generating Completions:  55%|█████▍    | 90/164 [08:44<07:13,  5.86s/it]\r",
      "Generating Completions:  61%|██████    | 100/164 [09:43<06:16,  5.88s/it]\r",
      "Generating Completions:  67%|██████▋   | 110/164 [10:42<05:17,  5.89s/it]\r",
      "Generating Completions:  73%|███████▎  | 120/164 [11:42<04:20,  5.92s/it]\r",
      "Generating Completions:  79%|███████▉  | 130/164 [12:44<03:23,  6.00s/it]\r",
      "Generating Completions:  85%|████████▌ | 140/164 [13:41<02:22,  5.92s/it]\r",
      "Generating Completions:  91%|█████████▏| 150/164 [14:39<01:22,  5.88s/it]\r",
      "Generating Completions:  98%|█████████▊| 160/164 [15:38<00:23,  5.90s/it]\r",
      "Generating Completions: 100%|██████████| 164/164 [16:29<00:00,  6.90s/it]\r",
      "Generating Completions: 100%|██████████| 164/164 [16:29<00:00,  6.04s/it]\n",
      "Reading samples...\n",
      "\r",
      "0it [00:00, ?it/s]\r",
      "164it [00:00, 20605.89it/s]\n",
      "Running test suites...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\r",
      "  0%|          | 0/164 [00:00<?, ?it/s]\r",
      "  1%|          | 1/164 [00:00<00:33,  4.82it/s]\r",
      "  1%|          | 2/164 [00:00<00:28,  5.69it/s]\r",
      "  2%|▏         | 4/164 [00:00<00:17,  8.93it/s]\r",
      "  4%|▍         | 7/164 [00:00<00:16,  9.73it/s]\r",
      "  7%|▋         | 11/164 [00:01<00:11, 12.96it/s]\r",
      "  9%|▊         | 14/164 [00:01<00:11, 12.90it/s]\r",
      " 10%|▉         | 16/164 [00:01<00:10, 13.62it/s]\r",
      " 12%|█▏        | 19/164 [00:01<00:10, 14.19it/s]\r",
      " 13%|█▎        | 21/164 [00:01<00:10, 13.74it/s]\r",
      " 15%|█▍        | 24/164 [00:01<00:08, 16.28it/s]\r",
      " 16%|█▌        | 26/164 [00:02<00:09, 14.09it/s]\r",
      " 17%|█▋        | 28/164 [00:02<00:10, 13.51it/s]\r",
      " 19%|█▉        | 31/164 [00:02<00:08, 16.22it/s]\r",
      " 20%|██        | 33/164 [00:02<00:07, 16.99it/s]\r",
      " 21%|██▏       | 35/164 [00:02<00:09, 13.98it/s]\r",
      " 24%|██▍       | 39/164 [00:02<00:08, 14.89it/s]\r",
      " 26%|██▌       | 42/164 [00:03<00:07, 15.87it/s]\r",
      " 27%|██▋       | 44/164 [00:03<00:07, 15.94it/s]\r",
      " 28%|██▊       | 46/164 [00:03<00:07,huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 14.84it/s]\r",
      " 29%|██▉       | 48/164 [00:03<00:07, 15.90it/s]\r",
      " 30%|███       | 50/164 [00:03<00:08, 14.04it/s]\r",
      " 33%|███▎      | 54/164 [00:03<00:07, 15.71it/s]\r",
      " 35%|███▍      | 57/164 [00:04<00:06, 15.71it/s]\r",
      " 36%|███▌      | 59/164 [00:04<00:06, 15.90it/s]\r",
      " 37%|███▋      | 61/164 [00:04<00:06, 16.61it/s]\r",
      " 39%|███▉      | 64/164 [00:04<00:06, 14.88it/s]\r",
      " 41%|████▏     | 68/164 [00:04<00:05, 16.17it/s]\r",
      " 43%|████▎     | 70/164 [00:04<00:06, 14.81it/s]\r",
      " 44%|████▍     | 72/164 [00:05<00:06, 14.08it/s]\r",
      " 46%|████▌     | 75/164 [00:05<00:05, 16.30it/s]\r",
      " 47%|████▋     | 77/164 [00:05<00:05, 15.04it/s]\r",
      " 49%|████▉     | 80/164 [00:05<00:05, 14.71it/s]\r",
      " 51%|█████     | 84/164 [00:05<00:05, 15.05it/s]\r",
      " 53%|█████▎    | 87/164 [00:05<00:04, 16.89it/s]\r",
      " 54%|█████▍    | 89/164 [00:06<00:04, 15.56it/s]\r",
      " 56%|█████▌    | 92/164 [00:06<00:04, 14.74it/s]\r",
      " 58%|█████huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "    | 95/164 [00:06<00:04, 14.84it/s]\r",
      " 60%|██████    | 99/164 [00:06<00:03, 17.62it/s]\r",
      " 62%|██████▏   | 101/164 [00:06<00:03, 16.02it/s]\r",
      " 63%|██████▎   | 103/164 [00:06<00:03, 16.17it/s]\r",
      " 64%|██████▍   | 105/164 [00:07<00:04, 13.89it/s]\r",
      " 66%|██████▌   | 108/164 [00:07<00:03, 15.16it/s]\r",
      " 67%|██████▋   | 110/164 [00:07<00:03, 14.74it/s]\r",
      " 68%|██████▊   | 112/164 [00:07<00:03, 14.65it/s]\r",
      " 70%|███████   | 115/164 [00:07<00:02, 17.28it/s]\r",
      " 71%|███████▏  | 117/164 [00:07<00:02, 16.96it/s]\r",
      " 73%|███████▎  | 120/164 [00:08<00:03, 14.48it/s]\r",
      " 75%|███████▌  | 123/164 [00:08<00:02, 16.11it/s]\r",
      " 77%|███████▋  | 126/164 [00:08<00:02, 16.01it/s]\r",
      " 78%|███████▊  | 128/164 [00:08<00:02, 16.21it/s]\r",
      " 79%|███████▉  | 130/164 [00:08<00:02, 16.99it/s]\r",
      " 81%|████████  | 133/164 [00:08<00:01, 15.86it/s]\r",
      " 82%|██huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "█████▏ | 135/164 [00:08<00:01, 16.70it/s]\r",
      " 84%|████████▍ | 138/164 [00:09<00:01, 14.60it/s]\r",
      " 85%|████████▌ | 140/164 [00:09<00:01, 15.02it/s]\r",
      " 87%|████████▋ | 143/164 [00:09<00:01, 15.21it/s]\r",
      " 88%|████████▊ | 145/164 [00:09<00:01, 16.04it/s]\r",
      " 90%|█████████ | 148/164 [00:09<00:01, 14.21it/s]\r",
      " 91%|█████████▏| 150/164 [00:10<00:00, 14.39it/s]\r",
      " 93%|█████████▎| 153/164 [00:10<00:00, 16.80it/s]\r",
      " 95%|█████████▍| 155/164 [00:10<00:00, 15.23it/s]\r",
      " 96%|█████████▌| 157/164 [00:10<00:00, 15.62it/s]\r",
      " 98%|█████████▊| 161/164 [00:10<00:00, 14.81it/s]\r",
      "100%|██████████| 164/164 [00:10<00:00, 15.21it/s]\n",
      "Writing results to results/ft1_ep=2/llama-7b_cot/eval/humaneval/codex_eval_predictions.jsonl_results.jsonl...\n",
      "\r",
      "  0%|          | 0/164 [00:00<?, ?it/s]\r",
      "100%|██████████| 164/164 [00:00<00:00, 26319.72it/s]\n",
      "{'pass@1': 0.09146341463414634}\n",
      "+ '[' '!' -f '/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/1108380*.out' ']'\n",
      "+ mv /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts/1108380.out results/ft1_ep=2/llama-7b_cot/eval/humaneval\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'results/ft1_ep=2/llama-7b_cot/eval/humaneval/1108380.out'\n",
    "\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    s = f.read()\n",
    "    print(s.decode('utf-8', 'ignore'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d19df030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "path = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/results/oi5_ultrachat15:mistral-7b/mistral-7b_ultrachat15_score=random:s=0_pace=prune:size=100000:ep=2/eval/humaneval_chatfmt/1170626.out'\n",
    "with open(path, 'r') as f:\n",
    "    s = f.read()\n",
    "    print('CUDA out of memory' in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c46bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/all-mpnet-base-v2/ultrachat15/dppmapbd_nc=200_k=lin_kmd=mpnet_incr.pkl'\n",
    "\n",
    "with open(p, 'rb') as f:\n",
    "    d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a300311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'ultrachat15',\n",
       " 'kernel_type': 'lin',\n",
       " 'kernel_embed_model': 'mpnet',\n",
       " 'kernel_embed_type': 'text_embedding',\n",
       " 'kernel_kwargs': {},\n",
       " 'quality_score_type': None,\n",
       " 'quality_score_embed_model': None,\n",
       " 'theta': 0.0,\n",
       " 'max_length': 5000,\n",
       " 'M': 156326,\n",
       " 'time_elapsed': 2720.3869178295135,\n",
       " 'marginal_gains': [1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  1.0000001192092896,\n",
       "  0.8123492002487183,\n",
       "  0.8117892742156982,\n",
       "  0.8112695217132568,\n",
       "  0.8054290413856506,\n",
       "  0.805306613445282,\n",
       "  0.8022041916847229,\n",
       "  0.8013613224029541,\n",
       "  0.7971450686454773,\n",
       "  0.7963024973869324,\n",
       "  0.7960312962532043,\n",
       "  0.7959518432617188,\n",
       "  0.7959139347076416,\n",
       "  0.7950664758682251,\n",
       "  0.7947534918785095,\n",
       "  0.7932345271110535,\n",
       "  0.7931765913963318,\n",
       "  0.7916399240493774,\n",
       "  0.7909712195396423,\n",
       "  0.7899060249328613,\n",
       "  0.7895697951316833,\n",
       "  0.7894363403320312,\n",
       "  0.7894212007522583,\n",
       "  0.7890614867210388,\n",
       "  0.7887179851531982,\n",
       "  0.7875495553016663,\n",
       "  0.7866621613502502,\n",
       "  0.7866500616073608,\n",
       "  0.7865906953811646,\n",
       "  0.7862882018089294,\n",
       "  0.7856961488723755,\n",
       "  0.7849829196929932,\n",
       "  0.7844580411911011,\n",
       "  0.7843946218490601,\n",
       "  0.7839798927307129,\n",
       "  0.7836154699325562,\n",
       "  0.7835582494735718,\n",
       "  0.7831377983093262,\n",
       "  0.7830443382263184,\n",
       "  0.7828894257545471,\n",
       "  0.7828719019889832,\n",
       "  0.7828202247619629,\n",
       "  0.7827571630477905,\n",
       "  0.7826712131500244,\n",
       "  0.7812480926513672,\n",
       "  0.7792050838470459,\n",
       "  0.7789320945739746,\n",
       "  0.7785361409187317,\n",
       "  0.7778763771057129,\n",
       "  0.7770763635635376,\n",
       "  0.7769322395324707,\n",
       "  0.7767530083656311,\n",
       "  0.776664674282074,\n",
       "  0.776660680770874,\n",
       "  0.776657223701477,\n",
       "  0.7766105532646179,\n",
       "  0.7758132219314575,\n",
       "  0.7748655080795288,\n",
       "  0.7741360664367676,\n",
       "  0.7737739682197571,\n",
       "  0.7736561894416809,\n",
       "  0.7736322283744812,\n",
       "  0.7736201286315918,\n",
       "  0.7734328508377075,\n",
       "  0.7728645205497742,\n",
       "  0.7726534008979797,\n",
       "  0.7724579572677612,\n",
       "  0.7719916105270386,\n",
       "  0.7714974880218506,\n",
       "  0.7710883617401123,\n",
       "  0.7704271078109741,\n",
       "  0.7700357437133789,\n",
       "  0.7698387503623962,\n",
       "  0.7698051929473877,\n",
       "  0.7694361805915833,\n",
       "  0.7688809633255005,\n",
       "  0.7685224413871765,\n",
       "  0.7684521675109863,\n",
       "  0.7683480978012085,\n",
       "  0.7683208584785461,\n",
       "  0.7679001688957214,\n",
       "  0.7673598527908325,\n",
       "  0.7664251923561096,\n",
       "  0.7661042213439941,\n",
       "  0.7656095623970032,\n",
       "  0.7655656337738037,\n",
       "  0.7645195126533508,\n",
       "  0.7643999457359314,\n",
       "  0.7639104127883911,\n",
       "  0.763279914855957,\n",
       "  0.7632484436035156,\n",
       "  0.7627708911895752,\n",
       "  0.7624697685241699,\n",
       "  0.7621398568153381,\n",
       "  0.762107789516449,\n",
       "  0.7612152099609375,\n",
       "  0.7600671052932739,\n",
       "  0.7598949670791626,\n",
       "  0.7596549987792969,\n",
       "  0.7587254047393799,\n",
       "  0.7586336135864258,\n",
       "  0.7582406997680664,\n",
       "  0.7577880024909973,\n",
       "  0.7575744986534119,\n",
       "  0.7570842504501343,\n",
       "  0.7568975687026978,\n",
       "  0.7568355202674866,\n",
       "  0.7567195892333984,\n",
       "  0.7562997341156006,\n",
       "  0.7561086416244507,\n",
       "  0.7554587125778198,\n",
       "  0.7548398971557617,\n",
       "  0.754376232624054,\n",
       "  0.753639817237854,\n",
       "  0.7532118558883667,\n",
       "  0.7531861066818237,\n",
       "  0.7527675032615662,\n",
       "  0.7507656216621399,\n",
       "  0.7503394484519958,\n",
       "  0.7501344084739685,\n",
       "  0.7499633431434631,\n",
       "  0.7499528527259827,\n",
       "  0.7498839497566223,\n",
       "  0.7494857311248779,\n",
       "  0.7491798400878906,\n",
       "  0.749008059501648,\n",
       "  0.7486647963523865,\n",
       "  0.7480641603469849,\n",
       "  0.7474400997161865,\n",
       "  0.7474155426025391,\n",
       "  0.7473381161689758,\n",
       "  0.7449120879173279,\n",
       "  0.7447989583015442,\n",
       "  0.744635820388794,\n",
       "  0.7441517114639282,\n",
       "  0.7438124418258667,\n",
       "  0.7427961826324463,\n",
       "  0.7427411079406738,\n",
       "  0.7421047687530518,\n",
       "  0.7417625188827515,\n",
       "  0.7415422201156616,\n",
       "  0.7413860559463501,\n",
       "  0.7411262392997742,\n",
       "  0.7405387759208679,\n",
       "  0.7404780387878418,\n",
       "  0.7396993637084961,\n",
       "  0.7393414974212646,\n",
       "  0.7392888069152832,\n",
       "  0.7391756772994995,\n",
       "  0.7382607460021973,\n",
       "  0.7378798723220825,\n",
       "  0.7378653287887573,\n",
       "  0.7368608713150024,\n",
       "  0.7361279129981995,\n",
       "  0.7345104813575745,\n",
       "  0.7344621419906616,\n",
       "  0.7340987920761108,\n",
       "  0.7337923049926758,\n",
       "  0.7336124181747437,\n",
       "  0.7335172891616821,\n",
       "  0.7333277463912964,\n",
       "  0.733250617980957,\n",
       "  0.7331027388572693,\n",
       "  0.7322680950164795,\n",
       "  0.7320602536201477,\n",
       "  0.7318660020828247,\n",
       "  0.7309752702713013,\n",
       "  0.7306176424026489,\n",
       "  0.7292516231536865,\n",
       "  0.7282631397247314,\n",
       "  0.7279672026634216,\n",
       "  0.7278729677200317,\n",
       "  0.7276192903518677,\n",
       "  0.7274675369262695,\n",
       "  0.7267767786979675,\n",
       "  0.7264411449432373,\n",
       "  0.7255892753601074,\n",
       "  0.7251955270767212,\n",
       "  0.7244755029678345,\n",
       "  0.7233916521072388,\n",
       "  0.7226523756980896,\n",
       "  0.7224738597869873,\n",
       "  0.71988844871521,\n",
       "  0.7192991375923157,\n",
       "  0.7191058993339539,\n",
       "  0.7177798748016357,\n",
       "  0.7156883478164673,\n",
       "  0.715651273727417,\n",
       "  0.7146040201187134,\n",
       "  0.7135666608810425,\n",
       "  0.711240291595459,\n",
       "  0.7095244526863098,\n",
       "  0.7080656290054321,\n",
       "  0.7078169584274292,\n",
       "  0.7070926427841187,\n",
       "  0.7058001756668091,\n",
       "  0.705114483833313,\n",
       "  0.7049531936645508,\n",
       "  0.7035114765167236,\n",
       "  0.7031276226043701,\n",
       "  0.6991469860076904,\n",
       "  0.6981070637702942,\n",
       "  0.6939809918403625,\n",
       "  0.692781388759613,\n",
       "  0.6902945637702942,\n",
       "  0.6895624995231628,\n",
       "  0.6879377365112305,\n",
       "  0.6861090660095215,\n",
       "  0.6847432255744934,\n",
       "  0.684520423412323,\n",
       "  0.6839355230331421,\n",
       "  0.682722806930542,\n",
       "  0.6826887726783752,\n",
       "  0.682253360748291,\n",
       "  0.681918203830719,\n",
       "  0.6815922260284424,\n",
       "  0.6798034310340881,\n",
       "  0.6795718669891357,\n",
       "  0.6786986589431763,\n",
       "  0.678686797618866,\n",
       "  0.6784867644309998,\n",
       "  0.6782974004745483,\n",
       "  0.6782387495040894,\n",
       "  0.6780797243118286,\n",
       "  0.6776147484779358,\n",
       "  0.6774331331253052,\n",
       "  0.6765519380569458,\n",
       "  0.6763375401496887,\n",
       "  0.6759716272354126,\n",
       "  0.6753011345863342,\n",
       "  0.6751965284347534,\n",
       "  0.6751289963722229,\n",
       "  0.6750935316085815,\n",
       "  0.6747627258300781,\n",
       "  0.6739170551300049,\n",
       "  0.6734111905097961,\n",
       "  0.6732934713363647,\n",
       "  0.6732417345046997,\n",
       "  0.6729149222373962,\n",
       "  0.6723736524581909,\n",
       "  0.6718138456344604,\n",
       "  0.6712599396705627,\n",
       "  0.6712321043014526,\n",
       "  0.670783281326294,\n",
       "  0.6707811951637268,\n",
       "  0.670768678188324,\n",
       "  0.6707479357719421,\n",
       "  0.6696741580963135,\n",
       "  0.6686987280845642,\n",
       "  0.6683434247970581,\n",
       "  0.667431652545929,\n",
       "  0.6673640608787537,\n",
       "  0.6670992374420166,\n",
       "  0.6667523980140686,\n",
       "  0.6665175557136536,\n",
       "  0.6663458943367004,\n",
       "  0.6659395694732666,\n",
       "  0.6652445197105408,\n",
       "  0.6651524305343628,\n",
       "  0.6649965643882751,\n",
       "  0.6649899482727051,\n",
       "  0.6649186015129089,\n",
       "  0.6648454666137695,\n",
       "  0.6646436452865601,\n",
       "  0.6645111441612244,\n",
       "  0.6639174222946167,\n",
       "  0.6638494729995728,\n",
       "  0.6636480093002319,\n",
       "  0.6634426116943359,\n",
       "  0.6631425023078918,\n",
       "  0.6627967953681946,\n",
       "  0.6625491380691528,\n",
       "  0.6621697545051575,\n",
       "  0.662057101726532,\n",
       "  0.6620291471481323,\n",
       "  0.6614082455635071,\n",
       "  0.6611829400062561,\n",
       "  0.6610583066940308,\n",
       "  0.6608752012252808,\n",
       "  0.6604427099227905,\n",
       "  0.6603883504867554,\n",
       "  0.6603343486785889,\n",
       "  0.659589409828186,\n",
       "  0.6593499779701233,\n",
       "  0.6593345403671265,\n",
       "  0.6590344905853271,\n",
       "  0.6589711308479309,\n",
       "  0.658854067325592,\n",
       "  0.6587492227554321,\n",
       "  0.6587309241294861,\n",
       "  0.6585012078285217,\n",
       "  0.6584789752960205,\n",
       "  0.6584080457687378,\n",
       "  0.6582443714141846,\n",
       "  0.6580228805541992,\n",
       "  0.6576796174049377,\n",
       "  0.6572971343994141,\n",
       "  0.6571518778800964,\n",
       "  0.6564900279045105,\n",
       "  0.6560183763504028,\n",
       "  0.655697762966156,\n",
       "  0.6556878685951233,\n",
       "  0.6555132269859314,\n",
       "  0.6554758548736572,\n",
       "  0.6549957990646362,\n",
       "  0.6549897789955139,\n",
       "  0.6544795036315918,\n",
       "  0.6536946296691895,\n",
       "  0.6536495685577393,\n",
       "  0.6528082489967346,\n",
       "  0.6527683734893799,\n",
       "  0.652747392654419,\n",
       "  0.6526826620101929,\n",
       "  0.6522572040557861,\n",
       "  0.652152419090271,\n",
       "  0.6515539884567261,\n",
       "  0.6513702869415283,\n",
       "  0.6509362459182739,\n",
       "  0.6509077548980713,\n",
       "  0.6507759094238281,\n",
       "  0.6506481170654297,\n",
       "  0.6506187915802002,\n",
       "  0.6503986120223999,\n",
       "  0.6502984166145325,\n",
       "  0.6493493914604187,\n",
       "  0.6489288210868835,\n",
       "  0.6487839818000793,\n",
       "  0.6476472616195679,\n",
       "  0.6473922729492188,\n",
       "  0.6472859382629395,\n",
       "  0.6468515992164612,\n",
       "  0.6468358039855957,\n",
       "  0.6462010741233826,\n",
       "  0.6460068821907043,\n",
       "  0.6458647847175598,\n",
       "  0.6457588076591492,\n",
       "  0.6455461382865906,\n",
       "  0.645503044128418,\n",
       "  0.6454548835754395,\n",
       "  0.6453184485435486,\n",
       "  0.645247220993042,\n",
       "  0.6452074646949768,\n",
       "  0.6448016166687012,\n",
       "  0.6439568996429443,\n",
       "  0.6438513994216919,\n",
       "  0.6438343524932861,\n",
       "  0.6436047554016113,\n",
       "  0.6434279084205627,\n",
       "  0.6433160305023193,\n",
       "  0.6429879665374756,\n",
       "  0.6422000527381897,\n",
       "  0.6418346762657166,\n",
       "  0.6417667269706726,\n",
       "  0.641584575176239,\n",
       "  0.641321063041687,\n",
       "  0.6412383317947388,\n",
       "  0.6410683393478394,\n",
       "  0.6407798528671265,\n",
       "  0.6405868530273438,\n",
       "  0.6403722167015076,\n",
       "  0.6400673389434814,\n",
       "  0.6399561166763306,\n",
       "  0.6396497488021851,\n",
       "  0.6391652226448059,\n",
       "  0.6391512155532837,\n",
       "  0.63832688331604,\n",
       "  0.6373955011367798,\n",
       "  0.6372988224029541,\n",
       "  0.6370611190795898,\n",
       "  0.6360180974006653,\n",
       "  0.63588947057724,\n",
       "  0.6352264881134033,\n",
       "  0.6350457668304443,\n",
       "  0.635028600692749,\n",
       "  0.6347554326057434,\n",
       "  0.6334417462348938,\n",
       "  0.6331512331962585,\n",
       "  0.6328946948051453,\n",
       "  0.6328584551811218,\n",
       "  0.6325697302818298,\n",
       "  0.6323431134223938,\n",
       "  0.6320512294769287,\n",
       "  0.6314841508865356,\n",
       "  0.6309006214141846,\n",
       "  0.629518985748291,\n",
       "  0.6292481422424316,\n",
       "  0.6292372345924377,\n",
       "  0.6290795803070068,\n",
       "  0.6290165185928345,\n",
       "  0.6288279294967651,\n",
       "  0.6286507844924927,\n",
       "  0.6273902654647827,\n",
       "  0.6272802352905273,\n",
       "  0.627023458480835,\n",
       "  0.6259909868240356,\n",
       "  0.6255408525466919,\n",
       "  0.6251052021980286,\n",
       "  0.6250168681144714,\n",
       "  0.6248559355735779,\n",
       "  0.6242483854293823,\n",
       "  0.6241468787193298,\n",
       "  0.6230785846710205,\n",
       "  0.6229435205459595,\n",
       "  0.6228816509246826,\n",
       "  0.6228240132331848,\n",
       "  0.6227281093597412,\n",
       "  0.622621476650238,\n",
       "  0.6222023963928223,\n",
       "  0.6217816472053528,\n",
       "  0.6213788986206055,\n",
       "  0.6212574243545532,\n",
       "  0.621075451374054,\n",
       "  0.6204918026924133,\n",
       "  0.6204147934913635,\n",
       "  0.6201665997505188,\n",
       "  0.619199812412262,\n",
       "  0.6191263794898987,\n",
       "  0.6186176538467407,\n",
       "  0.618291437625885,\n",
       "  0.6182202100753784,\n",
       "  0.6180969476699829,\n",
       "  0.6176018118858337,\n",
       "  0.617302656173706,\n",
       "  0.6164803504943848,\n",
       "  0.6163232326507568,\n",
       "  0.6157808899879456,\n",
       "  0.6150462031364441,\n",
       "  0.6149373054504395,\n",
       "  0.6149294376373291,\n",
       "  0.6147043108940125,\n",
       "  0.6143850684165955,\n",
       "  0.614332377910614,\n",
       "  0.6140469312667847,\n",
       "  0.6136743426322937,\n",
       "  0.6135565042495728,\n",
       "  0.6135429739952087,\n",
       "  0.6134145259857178,\n",
       "  0.6132369041442871,\n",
       "  0.6132108569145203,\n",
       "  0.6129624247550964,\n",
       "  0.612523078918457,\n",
       "  0.6124220490455627,\n",
       "  0.611785888671875,\n",
       "  0.611564576625824,\n",
       "  0.6115121245384216,\n",
       "  0.6112866997718811,\n",
       "  0.6112123131752014,\n",
       "  0.6110973954200745,\n",
       "  0.6108584403991699,\n",
       "  0.610783040523529,\n",
       "  0.6105964779853821,\n",
       "  0.6103082299232483,\n",
       "  0.6101773381233215,\n",
       "  0.6099721193313599,\n",
       "  0.609933078289032,\n",
       "  0.6098952889442444,\n",
       "  0.6090731024742126,\n",
       "  0.6089727878570557,\n",
       "  0.6088561415672302,\n",
       "  0.6086350679397583,\n",
       "  0.6080118417739868,\n",
       "  0.6080074310302734,\n",
       "  0.6077989339828491,\n",
       "  0.6075606942176819,\n",
       "  0.6074473261833191,\n",
       "  0.606846809387207,\n",
       "  0.6068456172943115,\n",
       "  0.6066318154335022,\n",
       "  0.6065545082092285,\n",
       "  0.605699896812439,\n",
       "  0.6056972146034241,\n",
       "  0.6053441166877747,\n",
       "  0.6052483916282654,\n",
       "  0.6052055954933167,\n",
       "  0.6044135093688965,\n",
       "  0.6040577292442322,\n",
       "  0.6038832068443298,\n",
       "  0.6037384867668152,\n",
       "  0.6034810543060303,\n",
       "  0.6034520864486694,\n",
       "  0.6029839515686035,\n",
       "  0.6028992533683777,\n",
       "  0.60289067029953,\n",
       "  0.60288405418396,\n",
       "  0.6028062701225281,\n",
       "  0.6025227904319763,\n",
       "  0.6025053262710571,\n",
       "  0.6024678349494934,\n",
       "  0.6023980379104614,\n",
       "  0.6023372411727905,\n",
       "  0.6022199988365173,\n",
       "  0.6021907925605774,\n",
       "  0.6018751859664917,\n",
       "  0.6018500924110413,\n",
       "  0.6017597913742065,\n",
       "  0.6017310619354248,\n",
       "  0.6017174124717712,\n",
       "  0.6016212701797485,\n",
       "  0.6016212105751038,\n",
       "  0.6015763282775879,\n",
       "  0.6010196208953857,\n",
       "  0.6006483435630798,\n",
       "  0.600067675113678,\n",
       "  0.599884569644928,\n",
       "  0.5997202396392822,\n",
       "  0.5996575355529785,\n",
       "  0.599643886089325,\n",
       "  0.5992947220802307,\n",
       "  0.5987473726272583,\n",
       "  0.5986915826797485,\n",
       "  0.5986336469650269,\n",
       "  0.5985642075538635,\n",
       "  0.5984970331192017,\n",
       "  0.5984786748886108,\n",
       "  0.5984700322151184,\n",
       "  0.5983644127845764,\n",
       "  0.5980654358863831,\n",
       "  0.5979488492012024,\n",
       "  0.5978109836578369,\n",
       "  0.5977602005004883,\n",
       "  0.5977193713188171,\n",
       "  0.5974829196929932,\n",
       "  0.5971953272819519,\n",
       "  0.5971052050590515,\n",
       "  0.5969613194465637,\n",
       "  0.5967328548431396,\n",
       "  0.5966336727142334,\n",
       "  0.596618115901947,\n",
       "  0.5962784290313721,\n",
       "  0.5962254405021667,\n",
       "  0.5958545207977295,\n",
       "  0.595511257648468,\n",
       "  0.5953877568244934,\n",
       "  0.5952022671699524,\n",
       "  0.5947505831718445,\n",
       "  0.5944199562072754,\n",
       "  0.5943041443824768,\n",
       "  0.5942533016204834,\n",
       "  0.5941264629364014,\n",
       "  0.594018816947937,\n",
       "  0.593996524810791,\n",
       "  0.593722939491272,\n",
       "  0.593720018863678,\n",
       "  0.5935482382774353,\n",
       "  0.5935426950454712,\n",
       "  0.5935109853744507,\n",
       "  0.5931676030158997,\n",
       "  0.5930956602096558,\n",
       "  0.5930697917938232,\n",
       "  0.5930445194244385,\n",
       "  0.5930213332176208,\n",
       "  0.5928650498390198,\n",
       "  0.5928277969360352,\n",
       "  0.5927877426147461,\n",
       "  0.5927082896232605,\n",
       "  0.5926774740219116,\n",
       "  0.592538058757782,\n",
       "  0.5925206542015076,\n",
       "  0.592207133769989,\n",
       "  0.5921745300292969,\n",
       "  0.5920947194099426,\n",
       "  0.5920321345329285,\n",
       "  0.5919961929321289,\n",
       "  0.5919320583343506,\n",
       "  0.5918777585029602,\n",
       "  0.5915263891220093,\n",
       "  0.5914506912231445,\n",
       "  0.5913540124893188,\n",
       "  0.5909945964813232,\n",
       "  0.5907231569290161,\n",
       "  0.590674877166748,\n",
       "  0.5902305245399475,\n",
       "  0.5901203751564026,\n",
       "  0.5896891355514526,\n",
       "  0.5895953178405762,\n",
       "  0.5895828008651733,\n",
       "  0.5894420742988586,\n",
       "  0.5894128680229187,\n",
       "  0.5893966555595398,\n",
       "  0.589262068271637,\n",
       "  0.5892483592033386,\n",
       "  0.5892221927642822,\n",
       "  0.5890563130378723,\n",
       "  0.5890114307403564,\n",
       "  0.5888891220092773,\n",
       "  0.5887909531593323,\n",
       "  0.5886784195899963,\n",
       "  0.5885656476020813,\n",
       "  0.5884273052215576,\n",
       "  0.5883529782295227,\n",
       "  0.5879517197608948,\n",
       "  0.5877617597579956,\n",
       "  0.5874988436698914,\n",
       "  0.5872371196746826,\n",
       "  0.5870068073272705,\n",
       "  0.5865179896354675,\n",
       "  0.5865068435668945,\n",
       "  0.5864179730415344,\n",
       "  0.5861166715621948,\n",
       "  0.5852702856063843,\n",
       "  0.5851866006851196,\n",
       "  0.5851582288742065,\n",
       "  0.585135281085968,\n",
       "  0.5850432515144348,\n",
       "  0.5846912264823914,\n",
       "  0.5846626162528992,\n",
       "  0.5845491290092468,\n",
       "  0.584435224533081,\n",
       "  0.5841747522354126,\n",
       "  0.584014356136322,\n",
       "  0.5839369297027588,\n",
       "  0.583655059337616,\n",
       "  0.5835827589035034,\n",
       "  0.5833621621131897,\n",
       "  0.5828259587287903,\n",
       "  0.5828137993812561,\n",
       "  0.5820630788803101,\n",
       "  0.5817930698394775,\n",
       "  0.5817267894744873,\n",
       "  0.5815499424934387,\n",
       "  0.5813272595405579,\n",
       "  0.5812544226646423,\n",
       "  0.5811597108840942,\n",
       "  0.5809612274169922,\n",
       "  0.5806896090507507,\n",
       "  0.5806053280830383,\n",
       "  0.5805299878120422,\n",
       "  0.5804675221443176,\n",
       "  0.5804078578948975,\n",
       "  0.5802463889122009,\n",
       "  0.580228865146637,\n",
       "  0.5801951289176941,\n",
       "  0.5799973011016846,\n",
       "  0.5797430872917175,\n",
       "  0.5795133709907532,\n",
       "  0.5793846249580383,\n",
       "  0.5793662667274475,\n",
       "  0.579171895980835,\n",
       "  0.5791325569152832,\n",
       "  0.5790451765060425,\n",
       "  0.5789316296577454,\n",
       "  0.5786938071250916,\n",
       "  0.5786170959472656,\n",
       "  0.5782204866409302,\n",
       "  0.5782026052474976,\n",
       "  0.577970564365387,\n",
       "  0.5779093503952026,\n",
       "  0.5778087377548218,\n",
       "  0.5777808427810669,\n",
       "  0.5777778029441833,\n",
       "  0.5776692032814026,\n",
       "  0.5776147246360779,\n",
       "  0.5775758624076843,\n",
       "  0.5775454044342041,\n",
       "  0.5772880911827087,\n",
       "  0.5772318243980408,\n",
       "  0.5768574476242065,\n",
       "  0.5767978429794312,\n",
       "  0.5767794847488403,\n",
       "  0.5765765905380249,\n",
       "  0.576509952545166,\n",
       "  0.5760360956192017,\n",
       "  0.5759510397911072,\n",
       "  0.5757244229316711,\n",
       "  0.5753459930419922,\n",
       "  0.5752031803131104,\n",
       "  0.5750458836555481,\n",
       "  0.5747792720794678,\n",
       "  0.5747696161270142,\n",
       "  0.5747472047805786,\n",
       "  0.5745410323143005,\n",
       "  0.5743861794471741,\n",
       "  0.5742793083190918,\n",
       "  0.5742197036743164,\n",
       "  0.5741978883743286,\n",
       "  0.5741351246833801,\n",
       "  0.5740963816642761,\n",
       "  0.5739673972129822,\n",
       "  0.5737103223800659,\n",
       "  0.5736680626869202,\n",
       "  0.5735785961151123,\n",
       "  0.5734403133392334,\n",
       "  0.5734164714813232,\n",
       "  0.573208749294281,\n",
       "  0.5731598138809204,\n",
       "  0.5731448531150818,\n",
       "  0.5731233954429626,\n",
       "  0.5730860233306885,\n",
       "  0.5728374719619751,\n",
       "  0.5727053880691528,\n",
       "  0.5726790428161621,\n",
       "  0.572546660900116,\n",
       "  0.572487473487854,\n",
       "  0.5724850296974182,\n",
       "  0.5722787976264954,\n",
       "  0.5719143748283386,\n",
       "  0.5719091296195984,\n",
       "  0.5718123316764832,\n",
       "  0.5716658234596252,\n",
       "  0.5714951157569885,\n",
       "  0.571248471736908,\n",
       "  0.5710853934288025,\n",
       "  0.5709591507911682,\n",
       "  0.5709487199783325,\n",
       "  0.5708621740341187,\n",
       "  0.5708059668540955,\n",
       "  0.5707257390022278,\n",
       "  0.5702478885650635,\n",
       "  0.5702336430549622,\n",
       "  0.5701412558555603,\n",
       "  0.5701122283935547,\n",
       "  0.5700876712799072,\n",
       "  0.5699726343154907,\n",
       "  0.5699328780174255,\n",
       "  0.5698642730712891,\n",
       "  0.5697228908538818,\n",
       "  0.5696991682052612,\n",
       "  0.5695789456367493,\n",
       "  0.569564938545227,\n",
       "  0.5689805746078491,\n",
       "  0.5689254999160767,\n",
       "  0.5688270926475525,\n",
       "  0.568794846534729,\n",
       "  0.5681249499320984,\n",
       "  0.5681066513061523,\n",
       "  0.5680025219917297,\n",
       "  0.5678889155387878,\n",
       "  0.5673791766166687,\n",
       "  0.567249059677124,\n",
       "  0.567085325717926,\n",
       "  0.5670475363731384,\n",
       "  0.5670313835144043,\n",
       "  0.566980242729187,\n",
       "  0.5669133067131042,\n",
       "  0.5667738318443298,\n",
       "  0.5666520595550537,\n",
       "  0.5666131377220154,\n",
       "  0.5665630102157593,\n",
       "  0.5663766860961914,\n",
       "  0.5662742257118225,\n",
       "  0.5661702156066895,\n",
       "  0.5661088824272156,\n",
       "  0.5660109519958496,\n",
       "  0.5657640099525452,\n",
       "  0.5656776428222656,\n",
       "  0.5654951333999634,\n",
       "  0.5654077529907227,\n",
       "  0.5654001235961914,\n",
       "  0.565031111240387,\n",
       "  0.5645856857299805,\n",
       "  0.5645594596862793,\n",
       "  0.5643457770347595,\n",
       "  0.5643318891525269,\n",
       "  0.5640138387680054,\n",
       "  0.5639414191246033,\n",
       "  0.5638139843940735,\n",
       "  0.5637289881706238,\n",
       "  0.5634346604347229,\n",
       "  0.5632578730583191,\n",
       "  0.5626857280731201,\n",
       "  0.5625016093254089,\n",
       "  0.5624372959136963,\n",
       "  0.56238853931427,\n",
       "  0.5618645548820496,\n",
       "  0.5618566870689392,\n",
       "  0.5617740154266357,\n",
       "  0.5615959763526917,\n",
       "  0.5615730881690979,\n",
       "  0.5614902377128601,\n",
       "  0.5614238381385803,\n",
       "  0.5613688230514526,\n",
       "  0.5613577961921692,\n",
       "  0.5613362789154053,\n",
       "  0.5611866116523743,\n",
       "  0.5611416697502136,\n",
       "  0.5608086585998535,\n",
       "  0.5607795119285583,\n",
       "  0.5606881380081177,\n",
       "  0.5605886578559875,\n",
       "  0.5603779554367065,\n",
       "  0.5602818727493286,\n",
       "  0.5602024793624878,\n",
       "  0.5600829124450684,\n",
       "  0.560033917427063,\n",
       "  0.5598711371421814,\n",
       "  0.5597405433654785,\n",
       "  0.559647798538208,\n",
       "  0.5596469640731812,\n",
       "  0.5596227645874023,\n",
       "  0.559617817401886,\n",
       "  0.5595923662185669,\n",
       "  0.5595129728317261,\n",
       "  0.5594978928565979,\n",
       "  0.5592536330223083,\n",
       "  0.5592048764228821,\n",
       "  0.5590677857398987,\n",
       "  0.558830976486206,\n",
       "  0.5586096048355103,\n",
       "  0.5584961175918579,\n",
       "  0.5584637522697449,\n",
       "  0.5584615468978882,\n",
       "  ...]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f985baf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143000\n"
     ]
    }
   ],
   "source": [
    "d = get_lm_output(dataset, model_name, encode_fn_type=encode_fn_type, return_text_embedding=True)\n",
    "if test_run:\n",
    "    d = {k: v[:1000] for k, v in d.items()}\n",
    "    \n",
    "# some entries are nan, impute with mean value.\n",
    "N = d['text_embedding'].shape[0]\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "0f792932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling note_pruning_dpp.compute_dppmap with kwargs={\n",
      "    \"dppmap_type\": \"dppmapbd\",\n",
      "    \"dataset\": \"wizardlm\",\n",
      "    \"kernel_type\": \"vmf\",\n",
      "    \"kernel_embed_model\": \"mpnet\",\n",
      "    \"kernel_embed_type\": \"text_embedding\",\n",
      "    \"kernel_kwargs\": {\n",
      "        \"gamma\": 0.3\n",
      "    },\n",
      "    \"quality_score_type\": null,\n",
      "    \"quality_score_embed_model\": null,\n",
      "    \"theta\": 0.0,\n",
      "    \"device\": \"cuda\",\n",
      "    \"max_length\": 2250\n",
      "}\n",
      "dppmapbd: cluster = 0 / 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1526/1538 [00:52<00:00, 28.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop on dᵢ^2 = -3.0898661407263717e-08. len(inds)=1527 / 1539\n",
      "Rank datapoints with dppmapbd_nc=200_k=vmf_gamma=0.3_kmd=mpnet took 53.88 seconds.\n"
     ]
    }
   ],
   "source": [
    "## the copy in `note_pruning.py` is most up to date\n",
    "\n",
    "pkl_extra = {}\n",
    "inds = None\n",
    "\n",
    "# sort_by = 'dppmap_theta=.5_k=vmf_gamma=1.0_kmd=mpnet_q=log+prob_qmd=llama7b'\n",
    "\n",
    "\n",
    "# sort_by = 'dppmap_k=vmf_gamma=1.0_kmd=mpnet'\n",
    "# sort_by = 'dppmap_k=vmf_gamma=0.3_kmd=mpnet'\n",
    "# sort_by = 'dppmap_k=vmf_gamma=3.0_kmd=mpnet'\n",
    "# sort_by = 'dppmap_theta=.5_k=vmf_gamma=3.0_kmd=mpnet_q=log+prob_qmd=mistral7b'\n",
    "\n",
    "sort_by = 'dppmapbd_nc=200_k=vmf_gamma=0.3_kmd=mpnet'\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "if any(sort_by.startswith(x) for x in [\n",
    "        'log_prob', \n",
    "        'el2n',  # el2n_agg={l2n|mean}\n",
    "        'logit_margin', \n",
    "        'grad',  # grad_{loraB|qkv|all|last}_l2n\n",
    "    ]):\n",
    "    if sort_by not in d:\n",
    "        print(f'sort_by={sort_by} not in model output: ({dataset}, {model_name})')\n",
    "    S = np.nan_to_num(d[sort_by], nan=np.nanmean(d[sort_by])).squeeze()\n",
    "elif sort_by.startswith('random'):\n",
    "    match = re.search(r's=(\\d+)', sort_by)\n",
    "    seed = int(match.group(1))\n",
    "    np.random.seed(seed)\n",
    "    S = np.random.rand(N)\n",
    "    assert(S.shape == np.unique(S).shape)\n",
    "if sort_by.startswith('kmeans'):\n",
    "    dist_fn = 'l2' if sort_by.startswith('kmeansl2') else 'cd'\n",
    "    match = re.search(r'nc=(\\d+)', sort_by)\n",
    "    n_clusters = int(match.group(1)) if match else None\n",
    "    match = re.search(r'emb=([^_]+)', sort_by)\n",
    "    embed_type = re.sub(r'[+]', '_', match.group(1)) if match else 'text_embedding'\n",
    "    if embed_type not in set(d.keys()).intersection(set(['text_embedding', 'grad_rp_loraB'])):\n",
    "        raise ValueError(f'Invalid embed_type = {embed_type}')\n",
    "    emb = d[embed_type]\n",
    "    print(f'Running kmeans(n_clusters={n_clusters}) {{ {embed_type} }} to compute {\"euclidean\" if dist_fn == \"l2\" else \"cosine\"} distance to cluster centers.')\n",
    "    S, kms = sort_kmeans_dist_to_cluster_centers(emb, n_clusters, dist_fn=dist_fn)\n",
    "    pkl_extra['kmeans'] = kms\n",
    "elif sort_by.startswith('semdedup'):\n",
    "    import note_pruning_clustering\n",
    "    kvs = parse_kv_from_string(sort_by)\n",
    "    md = kvs['md']\n",
    "    if (md == 'mpnet' and model_name != 'all-mpnet-base-v2') or \\\n",
    "        (md == 'bge' and model_name != 'bge-large-en-v1.5') or \\\n",
    "        (md == 'llama7b' and not model_name.lower().startswith('llama-7b')) or \\\n",
    "        (md == 'mistral7b' and not model_name.lower().startswith('mistral-7b')):\n",
    "        raise ValueError(f'md={md} does not match with model_name={model_name}')\n",
    "    clustering_fn = create_string_from_kv(\n",
    "        {k: v for k, v in kvs.items() if k in ['cl', 'nc', 'bsz', 'ms', 'emb']})\n",
    "    dist = kvs['dist']\n",
    "    assert(dist in ['cd', 'l2'])\n",
    "    embed_type = re.sub(r'[+]', '_', kvs['emb'])\n",
    "    save_dir_clustering = os.path.join('clustering', encode_fn_type, model_name, dataset, clustering_fn)\n",
    "    os.makedirs(save_dir_clustering, exist_ok=True)\n",
    "    # normalize embeddings to unit norm if the model that generated the embeddings does the \n",
    "    # same, e.g., mpnet, bge, or if using spherical kmeans clustering.\n",
    "    if any(x in model_name for x in ['mpnet', 'bge']) or 'kmeansfaisscd' in clustering_fn:\n",
    "        normalize_embeddings = True\n",
    "    else:\n",
    "        normalize_embeddings = False\n",
    "    kwargs = {\n",
    "        'model_name': model_name,\n",
    "        'dataset': dataset,\n",
    "        'encode_fn_type': encode_fn_type,\n",
    "        'clustering_fn': clustering_fn,\n",
    "        'embed_type': embed_type,\n",
    "        'normalize_embeddings': normalize_embeddings,\n",
    "        'first_N': None,\n",
    "        'save_dir': save_dir_clustering,\n",
    "    }\n",
    "    print(f'Calling note_pruning_clustering.main with kwargs={json.dumps(kwargs, indent=4)}')\n",
    "    X, Y, C = note_pruning_clustering.main(**kwargs)\n",
    "    print('Apply SemDeDup to discard duplicates.')\n",
    "    S = note_pruning_clustering.semdedup(X, Y, dist=dist, device='cuda')\n",
    "elif sort_by.startswith('dpp_'):\n",
    "    match = re.search(r'k=(\\w+)', sort_by)\n",
    "    kernel_type = match.group(1) if match else None\n",
    "    match = re.search(r'emb=([^_]+)', sort_by)\n",
    "    embed_type = re.sub(r'[+]', '_', match.group(1)) if match else 'text_embedding'\n",
    "    if embed_type not in set(d.keys()).intersection(set(['text_embedding', 'grad_rp_loraB'])):\n",
    "        raise ValueError(f'Invalid embed_type = {embed_type}')\n",
    "    emb = d[embed_type]\n",
    "    log_prob = d['log_prob']\n",
    "    inds = sort_dpp_map_memefficient(emb, log_prob, kernel_type=kernel_type, torch_compile=False)\n",
    "elif sort_by.startswith('dppmap_'):\n",
    "    import note_pruning_dpp\n",
    "    kvs = parse_kv_from_string(sort_by)\n",
    "    if kvs['k'] == 'vmf':\n",
    "        kernel_kwargs = {'gamma': kvs['gamma']}\n",
    "    elif kvs['k'] == 'rbf':\n",
    "        kernel_kwargs = {'sigma': kvs['sigma']}\n",
    "    else:\n",
    "        kernel_kwargs = {}\n",
    "    kwargs = {\n",
    "        'dppmap_type': 'dppmap',\n",
    "        'dataset': dataset,\n",
    "        'kernel_type': kvs['k'],\n",
    "        'kernel_embed_model': kvs['kmd'],\n",
    "        'kernel_embed_type': re.sub(r'[+]', '_', kvs['kemb']) if 'kemb' in kvs else 'text_embedding',\n",
    "        'kernel_kwargs': kernel_kwargs,\n",
    "        'quality_score_type': re.sub(r'[+]', '_', kvs['q']) if 'q' in kvs else None,\n",
    "        'quality_score_embed_model': kvs.get('qmd', None),\n",
    "        'theta': kvs.get('theta', 0.), # defaults to just diversity no quality\n",
    "        'device': 'cuda',\n",
    "        'max_length': 50, #min(50_000, .5*N), # balance finish job within 6 hrs with wanting to prune a lot\n",
    "    }\n",
    "    print(f'Calling note_pruning_dpp.compute_dppmap with kwargs={json.dumps(kwargs, indent=4)}')\n",
    "    S, output = note_pruning_dpp.compute_dppmap(**kwargs)\n",
    "    pkl_extra['info'] = output\n",
    "elif sort_by.startswith('dppmapbd'):\n",
    "    import note_pruning_clustering\n",
    "    import note_pruning_dpp\n",
    "    kvs = parse_kv_from_string(sort_by)\n",
    "    md = kvs['kmd']\n",
    "    if (md == 'mpnet' and model_name != 'all-mpnet-base-v2') or \\\n",
    "        (md == 'bge' and model_name != 'bge-large-en-v1.5') or \\\n",
    "        (md == 'llama7b' and not model_name.lower().startswith('llama-7b')) or \\\n",
    "        (md == 'mistral7b' and not model_name.lower().startswith('mistral-7b')):\n",
    "        raise ValueError(f'md={md} does not match with model_name={model_name}')\n",
    "    if kvs['k'] == 'vmf':\n",
    "        kernel_kwargs = {'gamma': kvs['gamma']}\n",
    "    elif kvs['k'] == 'rbf':\n",
    "        kernel_kwargs = {'sigma': kvs['sigma']}\n",
    "    else:\n",
    "        kernel_kwargs = {}\n",
    "    kwargs = {\n",
    "        'dppmap_type': 'dppmapbd',\n",
    "        'dataset': dataset,\n",
    "        'kernel_type': kvs['k'],\n",
    "        'kernel_embed_model': kvs['kmd'],\n",
    "        'kernel_embed_type': re.sub(r'[+]', '_', kvs['kemb']) if 'kemb' in kvs else 'text_embedding',\n",
    "        'kernel_kwargs': kernel_kwargs,\n",
    "        'quality_score_type': re.sub(r'[+]', '_', kvs['q']) if 'q' in kvs else None,\n",
    "        'quality_score_embed_model': kvs.get('qmd', None),\n",
    "        'theta': kvs.get('theta', 0.), # defaults to just diversity no quality\n",
    "        'device': 'cuda',\n",
    "        'max_length': int(.6*N / kvs['nc']), \n",
    "    }\n",
    "    clustering_fn = create_string_from_kv({\n",
    "        'cl': kvs.get('cl', 'kmeansfaisscd'),\n",
    "        'md': kvs['kmd'],\n",
    "        'emb': kvs['kemb'] if 'kemb' in kvs else 'text+embedding',\n",
    "        'nc': kvs['nc'],\n",
    "    })\n",
    "    save_dir_clustering = os.path.join(\n",
    "        'clustering', encode_fn_type, model_name, dataset, clustering_fn)\n",
    "    os.makedirs(save_dir_clustering, exist_ok=True)\n",
    "    clustering_data_path = os.path.join(save_dir_clustering, 'data.pkl')\n",
    "    if not os.path.isfile(clustering_data_path):\n",
    "        normalize_embeddings = True if \\\n",
    "            (any(x in model_name for x in ['mpnet', 'bge']) or 'kmeansfaisscd' in clustering_fn) else False\n",
    "        kwargs_clustering = {\n",
    "            'model_name': model_name,\n",
    "            'dataset': dataset,\n",
    "            'encode_fn_type': encode_fn_type,\n",
    "            'clustering_fn': clustering_fn,\n",
    "            'embed_type': kwargs['kernel_embed_type'],\n",
    "            'normalize_embeddings': normalize_embeddings,\n",
    "            'first_N': None,\n",
    "            'save_dir': save_dir_clustering,\n",
    "        }\n",
    "        print(f'Calling note_pruning_clustering.main with kwargs={json.dumps(kwargs_clustering, indent=4)}')\n",
    "        X, Y, C = note_pruning_clustering.main(**kwargs_clustering)\n",
    "    else:\n",
    "        with open(clustering_data_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        Y = data['Y']\n",
    "    print(f'Calling note_pruning_dpp.compute_dppmap with kwargs={json.dumps(kwargs, indent=4)}')\n",
    "    kwargs.update({'Y': Y})\n",
    "    S, output = note_pruning_dpp.compute_dppmap(**kwargs)\n",
    "    pkl_extra['info'] = output\n",
    "elif sort_by.startswith('rho'):\n",
    "    if sort_by == 'rhov1':\n",
    "        model_names = ['mistral-7b+lora:r=256:a=256',\n",
    "                       'mistral-7b-ultrachat200k-v1+lora:r=256:a=256']\n",
    "        assert(model_name == model_names[0])\n",
    "    else:\n",
    "        raise ValueError(f'sort_by={sort_by} not implemented.')\n",
    "    assert(len(model_names) == 2)\n",
    "    ds = []\n",
    "    for x in model_names:\n",
    "        ds.append(get_lm_output(dataset, x, return_text_embedding=False, fill_nan=False))\n",
    "    ks = [set(d.keys()) for d in ds]\n",
    "    ks = ks[0] & ks[1]\n",
    "    for k in ks:\n",
    "        S0 = ds[0][k]\n",
    "        S1 = ds[1][k]\n",
    "        # handle nan entries properly.\n",
    "        nan_mask = np.logical_or(np.isnan(S0), np.isnan(S1))\n",
    "        S = np.subtract(S0, S1)\n",
    "        S[nan_mask] = np.nan\n",
    "        S = S.squeeze()\n",
    "        save_prune_results(save_dir, None, S, {}, f'{sort_by}_{k}', model_name, dataset)\n",
    "elif sort_by.startswith('numtoks'):\n",
    "    from transformers import AutoTokenizer\n",
    "    from note_pruning_analysis import get_dataset_token_lengths\n",
    "    if 'llama' in model_name or 'mistral' in model_name:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/results/baselines/huggyllama/llama-7b',\n",
    "            use_fast=False, # use_fast sometimes cause error.\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('Need to supply appropriate tokenizer to count token lengths,')\n",
    "    d = get_dataset_token_lengths(dataset, tokenizer)\n",
    "\n",
    "    d['total_len'] = d['input_len'] + d['output_len']\n",
    "    for k in ['input', 'output', 'total']:\n",
    "        S = d[f'{k}_len']\n",
    "        save_prune_results(save_dir, None, S, {}, f'{sort_by}_{k}', model_name, dataset)\n",
    "\n",
    "        \n",
    "t1 = time.time()\n",
    "print(f'Rank datapoints with {sort_by} took {t1-t0:.2f} seconds.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c9b5b429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# from note_pruning import save_prune_results\n",
    "if not any(sort_by.startswith(x) for x in ['rho', 'numtoks']):\n",
    "    save_prune_results(save_dir, inds, S, pkl_extra, sort_by, model_name, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ebd77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec32921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8895c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea377f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
