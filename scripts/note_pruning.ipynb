{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf384bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.flan_v2.prob\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.flan_v2.kmeansl2_nc=300\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.flan_v2.kmeansl2_nc=1000\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.flan_v2.kmeansl2_nc=3000\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.flan_v2.dppmap_k=Kcos\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.flan_v2.dppmap_k=Kcosp\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.flan_v2.dppmap_k=Kcos1np\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v1_human_mix.prob\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v1_human_mix.kmeansl2_nc=300\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v1_human_mix.kmeansl2_nc=1000\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v1_human_mix.kmeansl2_nc=3000\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v1_human_mix.dppmap_k=Kcos\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v1_human_mix.dppmap_k=Kcosp\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v1_human_mix.dppmap_k=Kcos1np\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v2_human_mix.prob\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v2_human_mix.kmeansl2_nc=300\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v2_human_mix.kmeansl2_nc=1000\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v2_human_mix.kmeansl2_nc=3000\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v2_human_mix.dppmap_k=Kcos\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v2_human_mix.dppmap_k=Kcosp\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n",
      "\n",
      "Submiting job with:\n",
      "{\n",
      "    \"job_name\": \"prune.tulu_v2_human_mix.dppmap_k=Kcos1np\",\n",
      "    \"nodes\": 1,\n",
      "    \"num_cpus\": 32,\n",
      "    \"cpu_mem\": 128,\n",
      "    \"num_gpus\": 1,\n",
      "    \"gpu_type\": \"v100\",\n",
      "    \"test_run\": true,\n",
      "    \"queue\": \"el8\",\n",
      "    \"num_jobs\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from rosemary import jpt_in_notebook\n",
    "from llm.submit import submit_job, multiline_to_singleline\n",
    "\n",
    "shell_scripts_template = \"\"\"\n",
    "echo \"Running on $SLURM_JOB_NODELIST\"\n",
    "echo \"======\"\n",
    "\n",
    "master_addr=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\" | head -n 1)\n",
    "master_port=10002\n",
    "RDZV_ENDPOINT=$master_addr:$master_port\n",
    "\n",
    "source ~/.profile\n",
    "conda activate open-instruct\n",
    "cd /gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/scripts\n",
    "\n",
    "set -e\n",
    "set -x\n",
    "echo \"======\"\n",
    "srun {cmd}\n",
    "\n",
    "[ ! -f \"{log_dir}/$SLURM_JOB_ID*.out\" ] && mv {log_dir}/$SLURM_JOB_ID*.out {save_dir}\n",
    "\"\"\"\n",
    "\n",
    "model_name = 'llama-7b'\n",
    "model_name_or_path = '../results/baselines/huggyllama/llama-7b'\n",
    "\n",
    "model_name = 'llama-7b_tulu_v1_human_mix'\n",
    "model_name_or_path = '../results/ft1/llama-7b_humanmix'\n",
    "\n",
    "test_run = True\n",
    "save_dir = f\"/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/{model_name}/\"\n",
    "log_dir = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/'\n",
    "\n",
    "    \n",
    "dataset_list = ['flan_v2', 'tulu_v1_human_mix'] # 'tulu_v2_human_mix'\n",
    "sort_by_list = [\n",
    "    'prob',\n",
    "    'kmeansl2_nc=300', 'kmeansl2_nc=1000', 'kmeansl2_nc=3000',\n",
    "    'dppmap_k=Kcos', 'dppmap_k=Kcosp', 'dppmap_k=Kcos1np', \n",
    "]\n",
    "\n",
    "options_list = itertools.product(dataset_list, sort_by_list)\n",
    "\n",
    "    \n",
    "for dataset, sort_by in options_list:\n",
    "    cmd = f\"\"\"\n",
    "     python note_pruning.py \\\n",
    "        --dataset {dataset} \\\n",
    "        --sort_by {sort_by} \\\n",
    "        --model_name_or_path {model_name_or_path} \\\n",
    "        --save_dir {save_dir} \\\n",
    "    \"\"\".strip()\n",
    "    cmd = multiline_to_singleline(cmd)\n",
    "    shell_scripts = shell_scripts_template.format(\n",
    "        cmd=cmd, log_dir=log_dir, save_dir=save_dir)\n",
    "    out = submit_job(\n",
    "        shell_scripts, \n",
    "        job_name=f'prune.{dataset}.{sort_by}', \n",
    "        nodes=1,\n",
    "        num_cpus=32,\n",
    "        cpu_mem=128,\n",
    "        num_gpus=1,\n",
    "        gpu_type='v100',\n",
    "        test_run=test_run,\n",
    "        job_duration=6,\n",
    "    )\n",
    "    if not test_run:\n",
    "        print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea9f3fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python note_pruning.py --dataset tulu_v2_human_mix --sort_by dppmap_k=Kcos1np --model_name_or_path ../results/ft1/llama-7b_humanmix --save_dir /gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b_tulu_v1_human_mix/\n"
     ]
    }
   ],
   "source": [
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bf2dd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import jpt_parse_args, jpt_setup, jpt_in_notebook; jpt_setup()\n",
    "\n",
    "if jpt_in_notebook():\n",
    "    import os\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3,4,5'\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1891b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm \n",
    "\n",
    "import pyarrow\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from note_explore_data_pruning import (\n",
    "    save_to_pickle,\n",
    "    save_sorted_inds,\n",
    "    sort_kmeans_l2_to_prototypes,\n",
    "    sort_dpp_map,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2c45b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = True\n",
    "dataset = 'tulu_v1_human_mix'\n",
    "\n",
    "# sort_by = 'kmeansl2_nc=100'\n",
    "# sort_by = 'prob'\n",
    "# sort_by = 'dppmap_k=Kcos'\n",
    "# sort_by = 'dppmap_k=Kcos1np'\n",
    "\n",
    "save_dir = f'/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/data_inds/llama-7b/{dataset}/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "lm_output_dir = \"/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/llama-7b_outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f985baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = os.path.join(lm_output_dir, f'{dataset}.pkl')\n",
    "with open(save_path, 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "# some entries are nan, impute with mean value.\n",
    "d['log_probs'] = np.nan_to_num(d['log_probs'], nan=np.nanmean(d['log_probs']))\n",
    "text_embeddings = d['text_embeddings']\n",
    "log_probs = d['log_probs'].squeeze()\n",
    "\n",
    "if test_run:\n",
    "    text_embeddings = text_embeddings[:1000]\n",
    "    log_probs = log_probs[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0f792932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast_map_dpp iterations =  100\n",
      "fast_map_dpp iterations =  200\n",
      "fast_map_dpp iterations =  300\n",
      "fast_map_dpp iterations =  400\n",
      "fast_map_dpp iterations =  500\n",
      "fast_map_dpp iterations =  600\n",
      "fast_map_dpp iterations =  700\n",
      "fast_map_dpp iterations =  800\n",
      "fast_map_dpp iterations =  900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if sort_by.startswith('kmeansl2'):\n",
    "    match = re.search(r'(?<=\\=)\\d+', sort_by)\n",
    "    n_clusters = int(match.group()) if match else None\n",
    "    S = sort_kmeans_l2_to_prototypes(text_embeddings, n_clusters)\n",
    "elif sort_by == 'prob':\n",
    "    S = log_probs\n",
    "elif sort_by.startswith('dpp'):\n",
    "    match = re.search(r'k=(\\w+)', sort_by)\n",
    "    kernel_type = match.group(1) if match else None  \n",
    "    inds = sort_dpp_map(text_embeddings, log_probs, kernel_type=kernel_type)\n",
    "\n",
    "if not test_run:\n",
    "    if sort_by.startswith('dpp'):\n",
    "        save_to_pickle(\n",
    "            save_path=os.path.join(save_dir, f'{sort_by}.pkl'),\n",
    "            output={'inds': inds})\n",
    "    else:\n",
    "        save_sorted_inds(save_dir, S, sort_by, reverse=False)\n",
    "        save_sorted_inds(save_dir, S, sort_by, reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c9ebd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec32921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
