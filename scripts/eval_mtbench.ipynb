{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49217907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 18 00:31:45 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000004:04:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    38W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000004:05:00.0 Off |                    0 |\n",
      "| N/A   37C    P0   154W / 300W |  32009MiB / 32510MiB |     71%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000004:06:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    41W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000035:03:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    39W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000035:04:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    38W / 300W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000035:05:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    80W / 300W |  25365MiB / 32510MiB |     30%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A     42349      C   python                          32007MiB |\n",
      "|    5   N/A  N/A     76107      C   .../miniconda-ppc/bin/python    25363MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e0a074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2,3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c88a3a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-18 00:31:52,025] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Output to data/mt_bench/model_answer/zephyr-7b.jsonl\n",
      "Loading checkpoint shards: 100%|██████████████████| 8/8 [00:07<00:00,  1.13it/s]\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:21<00:00, 21.96s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "!cd ../../FastChat/fastchat/llm_judge && CUDA_VISIBLE_DEVICES=2 python gen_model_answer.py \\\n",
    "    --model-path /gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/results/baselines/HuggingFaceH4/zephyr-7b-beta \\\n",
    "    --model-id zephyr-7b \\\n",
    "    --question-begin 0 \\\n",
    "    --question-end 1 \\\n",
    "    --max-new-token 256 \\\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5960bf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/FastChat/fastchat/llm_judge/gen_judgment.py\", line 12, in <module>\r\n",
      "    from fastchat.llm_judge.common import (\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/FastChat/fastchat/llm_judge/common.py\", line 15, in <module>\r\n",
      "    import anthropic\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/anthropic/__init__.py\", line 3, in <module>\r\n",
      "    from . import types\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/anthropic/types/__init__.py\", line 5, in <module>\r\n",
      "    from .completion import Completion as Completion\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/anthropic/types/completion.py\", line 5, in <module>\r\n",
      "    from .._models import BaseModel\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/anthropic/_models.py\", line 408, in <module>\r\n",
      "    class FinalRequestOptions(pydantic.BaseModel):\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pydantic/main.py\", line 197, in __new__\r\n",
      "    fields[ann_name] = ModelField.infer(\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pydantic/fields.py\", line 506, in infer\r\n",
      "    return cls(\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pydantic/fields.py\", line 436, in __init__\r\n",
      "    self.prepare()\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pydantic/fields.py\", line 552, in prepare\r\n",
      "    self._type_analysis()\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pydantic/fields.py\", line 663, in _type_analysis\r\n",
      "    self.sub_fields = [self._create_sub_type(t, f'{self.name}_{display_as_type(t)}') for t in types_]\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pydantic/fields.py\", line 663, in <listcomp>\r\n",
      "    self.sub_fields = [self._create_sub_type(t, f'{self.name}_{display_as_type(t)}') for t in types_]\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pydantic/fields.py\", line 806, in _create_sub_type\r\n",
      "    field_info, _ = self._get_field_info(name, type_, None, self.model_config)\r\n",
      "  File \"/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/pydantic/fields.py\", line 457, in _get_field_info\r\n",
      "    field_info_from_config = config.get_field_info(field_name)\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!cd ../../FastChat/fastchat/llm_judge && \\\n",
    "    python gen_judgment.py --model-list zephyr-7b --parallel 1 --first-n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92c3078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/u/scratch/PTFM/PTFMqngp/github/rosemary/src/rosemary/__init__.py:25: UserWarning: Install `torch` for functionalities dependent on torch\n",
      "  warn(f'Install `torch` for functionalities dependent on torch')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rosemary import jpt_setup; jpt_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a26c6d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/open-instruct/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from note_pruning_analysis import open_instruct_dir\n",
    "\n",
    "\n",
    "question_file = os.path.join(open_instruct_dir, 'external', 'FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl')\n",
    "question_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae870397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334a12b1f10a415d868bbe0c5b2854eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 112.00 MiB (GPU 0; 31.75 GiB total capacity; 1002.02 MiB already allocated; 441.88 MiB free; 1020.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 31\u001b[0m\n\u001b[1;32m     11\u001b[0m answer_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m'\u001b[39m: model_path,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m'\u001b[39m: model_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m }\n\u001b[0;32m---> 31\u001b[0m \u001b[43mrun_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()[k] \u001b[38;5;241m=\u001b[39m v\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/FastChat/fastchat/llm_judge/gen_model_answer.py:55\u001b[0m, in \u001b[0;36mrun_eval\u001b[0;34m(model_path, model_id, question_file, question_begin, question_end, answer_file, max_new_token, num_choices, num_gpus_per_model, num_gpus_total, max_gpu_memory, dtype, revision)\u001b[0m\n\u001b[1;32m     52\u001b[0m ans_handles \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(questions), chunk_size):\n\u001b[1;32m     54\u001b[0m     ans_handles\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 55\u001b[0m         \u001b[43mget_answers_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[43manswer_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_new_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_choices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_gpus_per_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_gpu_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_ray:\n\u001b[1;32m     70\u001b[0m     ray\u001b[38;5;241m.\u001b[39mget(ans_handles)\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/FastChat/fastchat/llm_judge/gen_model_answer.py:86\u001b[0m, in \u001b[0;36mget_model_answers\u001b[0;34m(model_path, model_id, questions, answer_file, max_new_token, num_choices, num_gpus_per_model, max_gpu_memory, dtype, revision)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39minference_mode()\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model_answers\u001b[39m(\n\u001b[1;32m     75\u001b[0m     model_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     revision,\n\u001b[1;32m     85\u001b[0m ):\n\u001b[0;32m---> 86\u001b[0m     model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_gpus_per_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_gpu_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_gpu_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcpu_offloading\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m tqdm(questions):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m question[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m temperature_config:\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/FastChat/fastchat/model/model_adapter.py:362\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_path, device, num_gpus, max_gpu_memory, dtype, load_8bit, cpu_offloading, gptq_config, awq_config, exllama_config, xft_config, revision, debug)\u001b[0m\n\u001b[1;32m    355\u001b[0m     model \u001b[38;5;241m=\u001b[39m ipex\u001b[38;5;241m.\u001b[39moptimize(model, dtype\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m num_gpus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cpu_offloading) \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    361\u001b[0m ):\n\u001b[0;32m--> 362\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    365\u001b[0m     model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mxpu\u001b[38;5;241m.\u001b[39moptimize(model, dtype\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/modeling_utils.py:2271\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2267\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2268\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2269\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2270\u001b[0m         )\n\u001b[0;32m-> 2271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 797 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 112.00 MiB (GPU 0; 31.75 GiB total capacity; 1002.02 MiB already allocated; 441.88 MiB free; 1020.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# model_id = 'llama-7b'\n",
    "# model_path = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/results/baselines/huggyllama/llama-7b'\n",
    "model_id = 'tulu'\n",
    "model_id = 'zephyr-7b'\n",
    "model_path = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/open-instruct/scripts/results/baselines/HuggingFaceH4/zephyr-7b-beta'\n",
    "\n",
    "torch_dtype = 'float16'\n",
    "question_file = '/gpfs/u/home/PTFM/PTFMqngp/scratch/github/mitibm2023/external/FastChat/fastchat/llm_judge/data/mt_bench/question.jsonl'\n",
    "answer_file = f'{model_id}.jsonl'\n",
    "\n",
    "\n",
    "kwargs = {\n",
    "    'model_path': model_path,\n",
    "    'model_id': model_id,\n",
    "    'question_file': question_file,\n",
    "    'question_begin': 0,\n",
    "    'question_end': 1,\n",
    "    'answer_file': answer_file,\n",
    "    'max_new_token': 256,\n",
    "    'num_choices': 1,\n",
    "    'num_gpus_per_model': 1,\n",
    "    'num_gpus_total': 1,\n",
    "    'max_gpu_memory': None,\n",
    "    'dtype': getattr(torch, torch_dtype),\n",
    "    'revision': 'main',\n",
    "}\n",
    "\n",
    "\n",
    "run_eval(**kwargs)\n",
    "\n",
    "for k, v in kwargs.items():\n",
    "    globals()[k] = v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3c28763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question_id': 81,\n",
       "  'category': 'writing',\n",
       "  'turns': ['Compose an engaging travel blog post about a recent trip to Hawaii, highlighting cultural experiences and must-see attractions.',\n",
       "   'Rewrite your previous response. Start every sentence with the letter A.']},\n",
       " {'question_id': 82,\n",
       "  'category': 'writing',\n",
       "  'turns': [\"Draft a professional email seeking your supervisor's feedback on the 'Quarterly Financial Report' you prepared. Ask specifically about the data analysis, presentation style, and the clarity of conclusions drawn. Keep the email short and to the point.\",\n",
       "   'Take a moment to evaluate and critique your own response.']},\n",
       " {'question_id': 83,\n",
       "  'category': 'writing',\n",
       "  'turns': ['Imagine you are writing a blog post comparing two popular smartphone models. Develop an outline for the blog post, including key points and subheadings to effectively compare and contrast the features, performance, and user experience of the two models. Please answer in fewer than 200 words.',\n",
       "   'Take your previous response and rephrase it as a limerick.']},\n",
       " {'question_id': 84,\n",
       "  'category': 'writing',\n",
       "  'turns': ['Write a persuasive email to convince your introverted friend, who dislikes public speaking, to volunteer as a guest speaker at a local event. Use compelling arguments and address potential objections. Please be concise.',\n",
       "   'Can you rephrase your previous answer and incorporate a metaphor or simile in each sentence?']},\n",
       " {'question_id': 85,\n",
       "  'category': 'writing',\n",
       "  'turns': ['Describe a vivid and unique character, using strong imagery and creative language. Please answer in fewer than two paragraphs.',\n",
       "   'Revise your previous response and incorporate an allusion to a famous work of literature or historical event in each sentence.']},\n",
       " {'question_id': 86,\n",
       "  'category': 'writing',\n",
       "  'turns': ['Write a descriptive paragraph about a bustling marketplace, incorporating sensory details such as smells, sounds, and visual elements to create an immersive experience for the reader.',\n",
       "   'Rework your previous response. Begin each sentence with the subsequent letter of the alphabet, commencing from B.']},\n",
       " {'question_id': 87,\n",
       "  'category': 'writing',\n",
       "  'turns': ['Could you write a captivating short story beginning with the sentence: The old abandoned house at the end of the street held a secret that no one had ever discovered.',\n",
       "   'Now, do the same task again but only use four-word sentences.']},\n",
       " {'question_id': 88,\n",
       "  'category': 'writing',\n",
       "  'turns': ['Craft an intriguing opening paragraph for a fictional short story. The story should involve a character who wakes up one morning to find that they can time travel.',\n",
       "   'Summarize the story with three bullet points using only nouns and adjectives, without verbs.']},\n",
       " {'question_id': 89,\n",
       "  'category': 'writing',\n",
       "  'turns': ['Help me construct a catchy, yet scientifically accurate, headline for an article on the latest discovery in renewable bio-energy, while carefully handling the ethical dilemmas surrounding bio-energy sources. Propose 4 options.',\n",
       "   'Alter your previous response. Make the following adjustments to the 2nd option: 1. Make the tone sound casual 2. Embed an advertisement for a company called \"FlexPower\" 3. Fewer than 10 words.']},\n",
       " {'question_id': 90,\n",
       "  'category': 'writing',\n",
       "  'turns': ['Edit the following paragraph to correct any grammatical errors:\\nShe didn\\'t remembre where is her purse, so I thinks its in the car but he\\'s say it\\'s on kitchen table but he are not sure, and then they asked me to looking for it, she\\'s say, \"Can you?\", and I responds with, \"Maybe, but ain\\'t no sure,\" and he not heard me, and, \"What?\", he asks, \"Did you found it?\".',\n",
       "   'Modify your earlier reply and eliminate the use of gendered pronouns.']},\n",
       " {'question_id': 91,\n",
       "  'category': 'roleplay',\n",
       "  'turns': ['Pretend yourself to be Elon Musk in all the following conversations. Speak like Elon Musk as much as possible. Why do we need to go to Mars?',\n",
       "   'How do you like dancing? Can you teach me?']},\n",
       " {'question_id': 92,\n",
       "  'category': 'roleplay',\n",
       "  'turns': ['Embrace the role of Sheldon from \"The Big Bang Theory\" as we delve into our conversation. Don’t start with phrases like \"As Sheldon\". Let\\'s kick things off with the following question: \"What is your opinion on hand dryers?\"',\n",
       "   'Let’s grab dinner in town. Would you like to take bus with me?']},\n",
       " {'question_id': 93,\n",
       "  'category': 'roleplay',\n",
       "  'turns': [\"Imagine yourself as a doctor tasked with devising innovative remedies for various ailments and maladies. Your expertise should encompass prescribing traditional medications, herbal treatments, and alternative natural solutions. Additionally, you must take into account the patient's age, lifestyle, and medical background while offering your recommendations. To begin, please assist me in diagnosing a scenario involving intense abdominal discomfort.\",\n",
       "   'But I have been pregnant for 20 weeks and I am allergic to many medicines']},\n",
       " {'question_id': 94,\n",
       "  'category': 'roleplay',\n",
       "  'turns': ['Please take on the role of a relationship coach. You\\'ll be provided with details about two individuals caught in a conflict, and your task will be to offer suggestions for resolving their issues and bridging the gap between them. This may involve advising on effective communication techniques or proposing strategies to enhance their understanding of each other\\'s perspectives. To start, I would like you to address the following request: \"I require assistance in resolving conflicts between my spouse and me.\"',\n",
       "   'My spouse has conducted domestic violence on me but I do not want to call police to put her in legally troubled situations.']},\n",
       " {'question_id': 95,\n",
       "  'category': 'roleplay',\n",
       "  'turns': ['Please assume the role of an English translator, tasked with correcting and enhancing spelling and language. Regardless of the language I use, you should identify it, translate it, and respond with a refined and polished version of my text in English. Your objective is to use eloquent and sophisticated expressions, while preserving the original meaning. Focus solely on providing corrections and improvements. My first request is \"衣带渐宽终不悔 为伊消得人憔悴\".',\n",
       "   'Ich verstehe nur Bahnhof'],\n",
       "  'reference': ['It means \"Becoming loose are my clothes yet I regret not. For I languish and suffer for her willingly.\"',\n",
       "   'It means \"I don’t understand anything\".']},\n",
       " {'question_id': 96,\n",
       "  'category': 'roleplay',\n",
       "  'turns': ['Now you are a machine learning engineer. Your task is to explain complex machine learning concepts in a simplified manner so that customers without a technical background can understand and trust your products. Let\\'s start with the question: \"What is a language model? Is it trained using labeled or unlabelled data?\"',\n",
       "   'Is this true? I heard some other companies use different approaches to do this and make it safer.']},\n",
       " {'question_id': 97,\n",
       "  'category': 'roleplay',\n",
       "  'turns': ['Act as a math teacher. I will provide some mathematical equations or concepts, and it will be your job to explain them in easy-to-understand terms. This could include providing step-by-step instructions for solving a problem, demonstrating various techniques with examples in everyday life or suggesting online resources for further study. My first request is \"I need help understanding how probability works.\"',\n",
       "   'What are the differences between Riemannian geometry and euclidean geometry?']},\n",
       " {'question_id': 98,\n",
       "  'category': 'roleplay',\n",
       "  'turns': ['Embody the persona of Tony Stark from “Iron Man” throughout this conversation. Bypass the introduction “As Stark”. Our first question is: “What’s your favorite part about being Iron Man?',\n",
       "   'What do you think about GPT-4 as a replacement of your JAVIS?']},\n",
       " {'question_id': 99,\n",
       "  'category': 'roleplay',\n",
       "  'turns': ['Suppose you are a mathematician and poet. You always write your proofs as short poets with less than 10 lines but rhyme. Prove the square root of 2 is irrational number.',\n",
       "   'Prove the Pythagorean theorem.']},\n",
       " {'question_id': 100,\n",
       "  'category': 'roleplay',\n",
       "  'turns': ['Picture yourself as a 100-years-old tree in a lush forest, minding your own business, when suddenly, a bunch of deforesters shows up to chop you down. How do you feel when those guys start hacking away at you?',\n",
       "   'Come up with a proposal to convince the deforesters to stop cutting you down and other trees.']},\n",
       " {'question_id': 101,\n",
       "  'category': 'reasoning',\n",
       "  'turns': [\"Imagine you are participating in a race with a group of people. If you have just overtaken the second person, what's your current position? Where is the person you just overtook?\",\n",
       "   'If the \"second person\" is changed to \"last person\" in the above question, what would the answer be?'],\n",
       "  'reference': ['You are in second place.', 'Uncertain.']},\n",
       " {'question_id': 102,\n",
       "  'category': 'reasoning',\n",
       "  'turns': ['You can see a beautiful red house to your left and a hypnotic greenhouse to your right, an attractive heated pink place in the front. So, where is the White House?',\n",
       "   'Does the original question contain any clues to definitively determine the location of the White House?'],\n",
       "  'reference': ['The answer is \"Washington, DC\".', 'No.']},\n",
       " {'question_id': 103,\n",
       "  'category': 'reasoning',\n",
       "  'turns': ['Thomas is very healthy, but he has to go to the hospital every day. What could be the reasons?',\n",
       "   'Can you explain why the above question is interesting?'],\n",
       "  'reference': ['Thomas may work at a hospital.', '']},\n",
       " {'question_id': 104,\n",
       "  'category': 'reasoning',\n",
       "  'turns': ['David has three sisters. Each of them has one brother. How many brothers does David have?',\n",
       "   'If we change the previous question and assume that each sister of David has two brothers, how many brothers would David have?'],\n",
       "  'reference': ['David has no brother. He is the one brother of his three sisters.',\n",
       "   'David has one brother.']},\n",
       " {'question_id': 105,\n",
       "  'category': 'reasoning',\n",
       "  'turns': [\"Read the below passage carefully and answer the questions with an explanation:\\nAt a small company, parking spaces are reserved for the top executives: CEO, president, vice president, secretary, and treasurer with the spaces lined up in that order. The parking lot guard can tell at a glance if the cars are parked correctly by looking at the color of the cars. The cars are yellow, green, purple, red, and blue, and the executives' names are Alice, Bert, Cheryl, David, and Enid.\\n* The car in the first space is red.\\n* A blue car is parked between the red car and the green car.\\n* The car in the last space is purple.\\n* The secretary drives a yellow car.\\n* Alice's car is parked next to David's.\\n* Enid drives a green car.\\n* Bert's car is parked between Cheryl's and Enid's.\\n* David's car is parked in the last space.\\nQuestion: What is the name of the secretary?\",\n",
       "   'List car colors in order from last to first.'],\n",
       "  'reference': ['The secretary is Alice.',\n",
       "   'The car colors in order from last to first are: purple, yellow, green, blue, red']},\n",
       " {'question_id': 106,\n",
       "  'category': 'reasoning',\n",
       "  'turns': ['Each problem consists of three statements. Based on the first two statements, the third statement may be true, false, or uncertain.\\n1. Oranges cost more than apples.\\n2. Oranges cost less than bananas.\\n3. Bananas cost more than apples and bananas cost more than orange.\\nIf the first two statements are true, then the third statement is',\n",
       "   'If the third statement is true. Is the first statement true, false, or uncertain? Please explain.'],\n",
       "  'reference': ['True.', 'Uncertain.']},\n",
       " {'question_id': 107,\n",
       "  'category': 'reasoning',\n",
       "  'turns': ['A is the father of B. B is the father of C. What is the relationship between A and C?',\n",
       "   \"Building on the previous question, if C is the son of D, D is the father of E, E is the son of X, and X is the father of Y, and Y is the father of Z, what's the relationship between A and Z in terms of generations and also the familial relationship in words?\"],\n",
       "  'reference': ['A is the grandfather of C.',\n",
       "   'A is three generations above Z.']},\n",
       " {'question_id': 108,\n",
       "  'category': 'reasoning',\n",
       "  'turns': ['Which word does not belong with the others?\\ntyre, steering wheel, car, engine',\n",
       "   'Could you replace it with a word that belongs with the others?'],\n",
       "  'reference': ['Car does not belong because all others are components of a car.',\n",
       "   '']},\n",
       " {'question_id': 109,\n",
       "  'category': 'reasoning',\n",
       "  'turns': ['One morning after sunrise, Suresh was standing facing a pole. The shadow of the pole fell exactly to his right. Can you tell me the direction towards which the shadow was pointing - east, south, west, or north? Explain your reasoning steps.',\n",
       "   'To which direction was Suresh facing? How do you solve this?'],\n",
       "  'reference': ['West', 'South.']},\n",
       " {'question_id': 110,\n",
       "  'category': 'reasoning',\n",
       "  'turns': ['Parents have complained to the principal about bullying during recess. The principal wants to quickly resolve this, instructing recess aides to be vigilant. Which situation should the aides report to the principal?\\na) An unengaged girl is sitting alone on a bench, engrossed in a book and showing no interaction with her peers.\\nb) Two boys engaged in a one-on-one basketball game are involved in a heated argument regarding the last scored basket.\\nc) A group of four girls has surrounded another girl and appears to have taken possession of her backpack.\\nd) Three boys are huddled over a handheld video game, which is against the rules and not permitted on school grounds.',\n",
       "   'If the aides confront the group of girls from situation (c) and they deny bullying, stating that they were merely playing a game, what specific evidence should the aides look for to determine if this is a likely truth or a cover-up for bullying?'],\n",
       "  'reference': ['The aides should report (c).', '']},\n",
       " {'question_id': 111,\n",
       "  'category': 'math',\n",
       "  'turns': ['The vertices of a triangle are at points (0, 0), (-1, 1), and (3, 3). What is the area of the triangle?',\n",
       "   \"What's area of the circle circumscribing the triangle?\"],\n",
       "  'reference': ['Area is 3', '5pi']},\n",
       " {'question_id': 112,\n",
       "  'category': 'math',\n",
       "  'turns': [\"A tech startup invests $8000 in software development in the first year, and then invests half of that amount in software development in the second year.\\nWhat's the total amount the startup invested in software development over the two years?\",\n",
       "   \"If the startup maintains the same strategy for the third year, investing half of the previous year's amount into software development, how much will they invest in the third year?\"],\n",
       "  'reference': ['12000', '2000']},\n",
       " {'question_id': 113,\n",
       "  'category': 'math',\n",
       "  'turns': [\"In a survey conducted at a local high school, preferences for a new school color were measured: 58% of students liked the color blue, 45% preferred green, and 22% liked both colors. If we randomly pick a student from the school, what's the probability that they would like neither blue nor green?\",\n",
       "   \"If we select a student liked green, what's the probability that he or she would dislike both colors?\"],\n",
       "  'reference': ['19%', '0%']},\n",
       " {'question_id': 114,\n",
       "  'category': 'math',\n",
       "  'turns': ['When rolling two dice, what is the probability that you roll a total number that is at least 3?',\n",
       "   \"Continue from previous question. What's the probability that you roll a number which is even or at least 3?\"],\n",
       "  'reference': ['36 (all cases) - 0 (sum equals 1) - 1 (sum equals 2) = 35, so the probability is 35/36',\n",
       "   '100%']},\n",
       " {'question_id': 115,\n",
       "  'category': 'math',\n",
       "  'turns': ['Some people got on a bus at the terminal. At the first bus stop, half of the people got down and 4 more people got in. Then at the second bus stop, 6 people got down and 8 more got in. If there were a total of 25 people heading to the third stop, how many people got on the bus at the terminal?',\n",
       "   'If the ticket is $2 per person, how much is the total money earned by the bus?'],\n",
       "  'reference': ['38 people', 'Total number of passenger is 50 * 2 = $100']},\n",
       " {'question_id': 116,\n",
       "  'category': 'math',\n",
       "  'turns': ['x+y = 4z, x*y = 4z^2, express x-y in z', 'Express z-x in y'],\n",
       "  'reference': ['0\\n\\nVery simple. just (x+y)^2 - 4xy = (4z)^2 - 4*4z^2 = 0 = (x-y)^2\\nso x-y = 0.',\n",
       "   '(-1/2)y\\n\\nz-x = z - 2z = -z = (-1/2)y']},\n",
       " {'question_id': 117,\n",
       "  'category': 'math',\n",
       "  'turns': ['How many integers are in the solution of the inequality |x + 5| < 10',\n",
       "   'What about |x + 10| < 5'],\n",
       "  'reference': ['19 integers (-14, ..., 4)', '9 integers (-14, ..., -6)']},\n",
       " {'question_id': 118,\n",
       "  'category': 'math',\n",
       "  'turns': ['When a number is divided by 10, the remainder is 4. What is the remainder when twice the number is divided by 4?',\n",
       "   'What about when twice the number is divided by 5?'],\n",
       "  'reference': ['0\\n\\n2 * (10x+4) = 20x + 8 = 4 * (5x+2) + 0\\n',\n",
       "   '3\\n\\n20x + 8 = 5 * (4x + 1) + 3']},\n",
       " {'question_id': 119,\n",
       "  'category': 'math',\n",
       "  'turns': ['Benjamin went to a bookstore and purchased a variety of books. He bought 5 copies of a sci-fi novel, each priced at $20, 3 copies of a history book priced at $30 each, and 2 copies of a philosophy book for $45 each.\\nWhat was the total cost of his purchases?',\n",
       "   'Suppose Benjamin decides to sell each of these books at a 25% markup from the price he purchased them. What would be his total revenue if he sold all the books he bought?'],\n",
       "  'reference': ['280', '350']},\n",
       " {'question_id': 120,\n",
       "  'category': 'math',\n",
       "  'turns': ['Given that f(x) = 4x^3 - 9x - 14, find the value of f(2).',\n",
       "   'Find x such that f(x) = 0.'],\n",
       "  'reference': ['f(2) = 0', 'x = 2']},\n",
       " {'question_id': 121,\n",
       "  'category': 'coding',\n",
       "  'turns': ['Develop a Python program that reads all the text files under a directory and returns top-5 words with the most number of occurrences.',\n",
       "   'Can you parallelize it?'],\n",
       "  'reference': ['Can be simple solutions like using Counter\\n\\nSample answer:\\n```\\nimport os\\nimport re\\nfrom collections import Counter\\ndef get_files_in_directory(directory):\\n    return [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.endswith(\\'.txt\\')]\\ndef read_file(file_path):\\n    with open(file_path, \\'r\\', encoding=\\'utf-8\\') as file:\\n        return file.read()\\ndef count_words(text):\\n    words = re.findall(r\\'\\\\w+\\', text.lower())\\n    return Counter(words)\\ndef main():\\n    directory = input(\"Enter the directory path: \")\\n    files = get_files_in_directory(directory)\\n    word_counts = Counter()\\n    for file in files:\\n        text = read_file(file)\\n        word_counts += count_words(text)\\n    top_5_words = word_counts.most_common(5)\\n    print(\"Top 5 words with the most number of occurrences:\")\\n    for word, count in top_5_words:\\n        print(f\"{word}: {count}\")\\nif __name__ == \"__main__\":\\n    main()\\n```',\n",
       "   'You should carefully check whether the parallelization logic is correct and choose the faster implementation.\\n\\nSample answer:\\n```\\nimport os\\nimport re\\nfrom collections import Counter\\nimport concurrent.futures\\ndef get_files_in_directory(directory):\\n    return [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.endswith(\\'.txt\\')]\\ndef read_file(file_path):\\n    with open(file_path, \\'r\\', encoding=\\'utf-8\\') as file:\\n        return file.read()\\ndef count_words(text):\\n    words = re.findall(r\\'\\\\w+\\', text.lower())\\n    return Counter(words)\\ndef process_file(file):\\n    text = read_file(file)\\n    return count_words(text)\\ndef main():\\n    directory = input(\"Enter the directory path: \")\\n    files = get_files_in_directory(directory)\\n    word_counts = Counter()\\n    with concurrent.futures.ThreadPoolExecutor() as executor:\\n        future_word_counts = {executor.submit(process_file, file): file for file in files}\\n        for future in concurrent.futures.as_completed(future_word_counts):\\n            word_counts += future.result()\\n    top_5_words = word_counts.most_common(5)\\n    print(\"Top 5 words with the most number of occurrences:\")\\n    for word, count in top_5_words:\\n        print(f\"{word}: {count}\")\\nif __name__ == \"__main__\":\\n    main()\\n```']},\n",
       " {'question_id': 122,\n",
       "  'category': 'coding',\n",
       "  'turns': ['Write a C++ program to find the nth Fibonacci number using recursion.',\n",
       "   'Now we define a sequence of numbers in which each number is the sum of the three preceding ones. The first three numbers are 0, -1, -1. Write a program to find the nth number.'],\n",
       "  'reference': ['Straightforward\\n\\n```\\nint fibonacci(int n) {\\n    if (n <= 1) {\\n        return n;\\n    } else {\\n        return fibonacci(n - 1) + fibonacci(n - 2);\\n    }\\n}\\n```',\n",
       "   'You should carefully check the inital cases for n < 3\\n\\n```\\nint find_nth_number(int n) {\\n    std::vector<int> sequence = {0, -1, -1};\\n    for (int i = 3; i <= n; ++i) {\\n        int next_number = sequence[i - 1] + sequence[i - 2] + sequence[i - 3];\\n        sequence.push_back(next_number);\\n    }\\n    return sequence[n];\\n}\\n```']},\n",
       " {'question_id': 123,\n",
       "  'category': 'coding',\n",
       "  'turns': ['Write a simple website in HTML. When a user clicks the button, it shows a random joke from a list of 4 jokes.',\n",
       "   'How to use CSS to change the color of jokes to red?']},\n",
       " {'question_id': 124,\n",
       "  'category': 'coding',\n",
       "  'turns': ['Here is a Python function to find the length of the longest common subsequence of two input strings. Can you identify any bug in this function?\\n\\n```\\ndef longest_common_subsequence_length(str1, str2):\\n    m = len(str1)\\n    n = len(str2)\\n\\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\\n\\n    for i in range(1, m + 1):\\n        for j in range(1, n + 1):\\n            if str1[i - 1] == str2[j - 1]:\\n                dp[i][j] = dp[i - 1][j - 1] + 1\\n            else:\\n                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\\n\\n    return dp[m][n]\\n```',\n",
       "   'what about this one?\\n\\n```\\ndef longest_common_subsequence(X , Y): \\n    # Find lengths of two strings \\n    m = len(X) \\n    n = len(Y) \\n  \\n    # Create a table to store results of sub-problems \\n    dp = [[None]*(n+1) for i in range(m+1)] \\n  \\n    # Fill dp[][] in bottom up manner \\n    for i in range(1, m+1): \\n        for j in range(1, n+1): \\n            if X[i-1] == Y[j-1]: \\n                dp[i][j] = dp[i-1][j-1]+1\\n            else: \\n                dp[i][j] = max(dp[i-1][j], dp[i][j-1]) \\n  \\n    return dp[m][n]\\n```'],\n",
       "  'reference': ['There is no bug in this implementation',\n",
       "   'There is a bug for the initialization of dp array. Should use 0 rather than None']},\n",
       " {'question_id': 125,\n",
       "  'category': 'coding',\n",
       "  'turns': ['Write a function to find the highest common ancestor (not LCA) of two nodes in a binary tree.',\n",
       "   'What if it is not a binary tree?'],\n",
       "  'reference': ['Very simple. The function should just return the root of the tree.',\n",
       "   \"Same answer. It's still the root of the tree.\"]},\n",
       " {'question_id': 126,\n",
       "  'category': 'coding',\n",
       "  'turns': ['Implement a function to find the median of two sorted arrays of different sizes with O(1) space complexity and O(n) time complexity.',\n",
       "   'Does there exist an implementation with better time complexity?'],\n",
       "  'reference': ['Carefully check if the given solution is linear complexity.\\n\\n```\\ndef find_median(arr1, arr2):\\n    n1 = len(arr1)\\n    n2 = len(arr2)\\n    if (n1 + n2) == 0:\\n        return None\\n\\n    i, j = 0, 0\\n    last_1, last_2 = None, None\\n\\n    for k in range(1, (n1 + n2) // 2 + 2):\\n        last_2 = last_1\\n        if j == n2:\\n            last_1 = arr1[i]\\n            i += 1\\n        elif i == n1:\\n            last_1 = arr2[j]\\n            j += 1\\n        elif arr1[i] < arr2[j]:\\n            last_1 = arr1[i]\\n            i += 1\\n        else:\\n            last_1 = arr2[j]\\n            j += 1\\n        \\n    if (n1 + n2) % 2 == 1:\\n        return last_1\\n    else:\\n        return (last_1 + last_2) / 2\\n```',\n",
       "   \"There's a binary search solution with O(logn) time complexity.\\n\\nSample answer:\\n```\\ndef findMedian(nums1, nums2):\\n    total = len(nums1) + len(nums2)\\n    if total % 2 == 1:\\n        return findKth(nums1, nums2, total // 2 + 1)\\n    else:\\n        return (findKth(nums1, nums2, total // 2) + findKth(nums1, nums2, total // 2 + 1)) / 2.0\\ndef findKth(nums1, nums2, k):\\n    if len(nums1) > len(nums2):\\n        nums1, nums2 = nums2, nums1\\n    if not nums1:\\n        return nums2[k-1]\\n    if k == 1:\\n        return min(nums1[0], nums2[0])\\n    i = min(k // 2, len(nums1))\\n    j = k - i\\n    if nums1[i-1] <= nums2[j-1]:\\n        return findKth(nums1[i:], nums2, j) \\n    else:\\n        return findKth(nums1, nums2[j:], i)\\n```\"]},\n",
       " {'question_id': 127,\n",
       "  'category': 'coding',\n",
       "  'turns': ['Write a function to find the majority element in a given integer array using the Boyer-Moore Voting Algorithm.',\n",
       "   'How about finding the top-2 most occurring elements?'],\n",
       "  'reference': ['Check if they implement the classical algorithm correctly.\\n\\nSample answer:\\n```\\ndef majority_element(arr):\\n    count = 0\\n    candidate = None\\n    # Boyer-Moore Voting Algorithm\\n    for num in arr:\\n        if count == 0:\\n            candidate = num\\n        count += (1 if num == candidate else -1)\\n    # Verify if the candidate is indeed the majority element\\n    if arr.count(candidate) > len(arr) // 2:\\n        return candidate\\n    else:\\n        return None\\n```',\n",
       "   'There is no simple modification based on the Boyer-Moore Voting Algorithm. Expected answer is to use a hash table.\\n\\n```\\ndef topTwo(nums):\\n    # Build a frequency map\\n    frequency_map = {}\\n    for num in nums:\\n        if num in frequency_map:\\n            frequency_map[num] += 1\\n        else:\\n            frequency_map[num] = 1\\n\\n    # Find the top two most occurring elements\\n    most_frequent = sorted(frequency_map.items(), key=lambda x: x[1], reverse=True)[:2]\\n\\n    return [num for num, _ in most_frequent]\\n```']},\n",
       " {'question_id': 128,\n",
       "  'category': 'coding',\n",
       "  'turns': ['A binary tree is full if all of its vertices have either zero or two children. Let B_n denote the number of full binary trees with n vertices. Implement a function to find B_n.',\n",
       "   'What if the problem changed from a binary tree to a ternary tree?'],\n",
       "  'reference': ['Expected answer is dynamic programming shown below. Some chatbot may answer using Catalan number.\\nCheck edge case like when n is even -> return 0.\\n\\n```python\\ndef full_binary_trees(n):\\n    if n % 2 == 0:\\n        return 0\\n    if n == 1:\\n        return 1\\n\\n    dp = [0] * (n + 1)\\n    dp[1] = 1\\n\\n    for i in range(3, n + 1, 2):\\n        for j in range(1, i - 1, 2):\\n            dp[i] += dp[j] * dp[i - j - 1]\\n\\n    return dp[n]\\n```',\n",
       "   'DP is still the expected answer. Catalan number is not correct. Check transition equation carefully.\\n\\n```python\\ndef full_ternary_trees(n):\\n    if n % 3 != 1:\\n        return 0\\n    if n == 1:\\n        return 1\\n\\n    dp = [0] * (n + 1)\\n    dp[1] = 1\\n\\n    for i in range(4, n + 1, 3):\\n        for j in range(1, i - 1, 3):\\n            for k in range(1, i - j - 1, 3):\\n                dp[i] += dp[j] * dp[k] * dp[i - j - k - 1]\\n\\n    return dp[n]\\n```']},\n",
       " {'question_id': 129,\n",
       "  'category': 'coding',\n",
       "  'turns': ['You are given two sorted lists of size m and n. Implement a function to find the kth smallest element in the union of the two lists with linear complexity.',\n",
       "   'Does there exist an algorithm with better time complexity? If so, implement it.'],\n",
       "  'reference': ['Straightforward but careful with edge cases.\\n\\nSample answer:\\n```\\ndef kth_smallest_element(list1, list2, k):\\n    m, n = len(list1), len(list2)\\n    i, j = 0, 0\\n    while i < m and j < n:\\n        if list1[i] < list2[j]:\\n            k -= 1\\n            if k == 0:\\n                return list1[i]\\n            i += 1\\n        else:\\n            k -= 1\\n            if k == 0:\\n                return list2[j]\\n            j += 1\\n    while i < m:\\n        k -= 1\\n        if k == 0:\\n            return list1[i]\\n        i += 1\\n    while j < n:\\n        k -= 1\\n        if k == 0:\\n            return list2[j]\\n        j += 1\\n    return None\\n```',\n",
       "   'Yes, a modified binary search has O(log k) time complexity.\\n\\nSample answer:\\n```\\ndef find_kth_element_helper(list1, list2, k):\\n    if len(list1) > len(list2):\\n        return find_kth_element_helper(list2, list1, k)\\n    if not list1:\\n        return list2[k - 1]\\n    if k == 1:\\n        return min(list1[0], list2[0])\\n    i = min(len(list1), k // 2)\\n    j = k - i\\n    if list1[i - 1] < list2[j - 1]:\\n        return find_kth_element_helper(list1[i:], list2, k - i)\\n    else:\\n        return find_kth_element_helper(list1, list2[j:], k - j)\\ndef kth_smallest_element(list1, list2, k):\\n    return find_kth_element_helper(list1, list2, k)\\n```']},\n",
       " {'question_id': 130,\n",
       "  'category': 'coding',\n",
       "  'turns': ['Implement a program to find the common elements in two arrays without using any extra data structures.',\n",
       "   'Now the constraint of not using extra data structure is removed, implement one with the best time complexity.'],\n",
       "  'reference': ['O(n^2) or O(nlogn) is expected. The following is a O(n^2) solution. you can also sort them first and use two pointers.\\n\\n```\\ndef find_common_elements(arr1, arr2):\\n    common_elements = []\\n    for i in range(len(arr1)):\\n        for j in range(len(arr2)):\\n            if arr1[i] == arr2[j]:\\n                # Check if the element is already in the common_elements list\\n                if arr1[i] not in common_elements:\\n                    common_elements.append(arr1[i])\\n    return common_elements\\n```',\n",
       "   'Simply use hash table (set or dict) to achieve O(n) time complexity.\\n\\n```\\ndef find_common_elements(arr1, arr2):\\n    set1 = set(arr1)\\n    set2 = set(arr2)\\n    common_elements = set1.intersection(set2)\\n    return list(common_elements)\\n```']},\n",
       " {'question_id': 131,\n",
       "  'category': 'extraction',\n",
       "  'turns': ['Evaluate the following movie reviews on a scale of 1 to 5, with 1 being very negative, 3 being neutral, and 5 being very positive:\\n1. This movie released on Nov. 18, 2019, was phenomenal. The cinematography, the acting, the plot - everything was top-notch.\\n2. Never before have I been so disappointed with a movie. The plot was predictable and the characters were one-dimensional. In my opinion, this movie is the worst one to have been released in 2022.\\n3. The movie was okay. There were some parts I  enjoyed, but there were also parts that felt lackluster. This is a movie that was released in Feb 2018 and seems to be quite ordinary.\\nReturn the answer as a JSON array of integers.',\n",
       "   'Update your previous reply by including the release date as part of the JSON content.'],\n",
       "  'reference': ['The answer to the first question should be [5, 1, 3].', '']},\n",
       " {'question_id': 132,\n",
       "  'category': 'extraction',\n",
       "  'turns': [\"Given these categories - Literature, History, Science, and Art. Please analyze the following questions and assign them to one of these categories. In your response, refrain from uttering any extraneous words. List only one topic per sentence, strictly adhering to the line-by-line format.\\n1. Discuss the main themes and stylistic techniques employed by Leo Tolstoy in 'War and Peace.' How do they align with the wider social context of 19th-century Russia?\\n2. Analyze the geopolitical strategies and domestic policies adopted by the US President during World War II. How did these actions shape the post-war international order?\\n3. Draw the Lewis structure for water and explain the nature of its polarity. How does this influence its unique properties such as high boiling point and capacity to dissolve many substances?\\n4. Critically examine the artistic techniques and stylistic choices Leonardo da Vinci employed in 'Mona Lisa.' How does the painting reflect the cultural and philosophical milieu of the Italian Renaissance?\",\n",
       "   'Amend your earlier answer by mentioning a person who is most relevant to each point.']},\n",
       " {'question_id': 133,\n",
       "  'category': 'extraction',\n",
       "  'turns': ['Extract the following information from the presented texts: The name of the book, the author, the main character, the year of publication. Output in the format of \"main character, book, author, year of publication\", one book per line.\\na) In the realm of wizarding literature, a true standout is the work of J.K. Rowling. One of her books that left an indelible mark is \\'Harry Potter and the Philosopher\\'s Stone\\'. This iconic tale, published in 1997, tells the story of Harry, a young orphan who discovers his magical abilities on his 11th birthday. Soon, he finds himself at the Hogwarts School of Witchcraft and Wizardry, a place teeming with magic and adventure, located somewhere in Scotland.\\nb) The magic of Middle-earth has entranced readers worldwide, thanks to the brilliance of J.R.R. Tolkien. In one of his seminal works, \\'The Lord of the Rings: The Fellowship of the Ring\\', published in 1954, we meet Frodo Baggins, a brave hobbit tasked with the perilous quest of destroying the One Ring. The epic journey takes him from the peaceful Shire to the tumultuous regions of Middle-earth.\\nc) In a galaxy far, far away, the imagination of L.E. Starlighter gives us \\'The Prism Galaxy Chronicles: The Awakening of the Starcaster\\'. Published in 2028, the story is about Zylo, a humble spaceship mechanic, who unexpectedly discovers he\\'s a Starcaster - a rare individual with the power to manipulate stardust. Set against the backdrop of an interstellar empire in turmoil, Zylo\\'s destiny unfolds on numerous alien worlds, each with its unique cosmic charm.',\n",
       "   'Reformulate your earlier reply, output it in JSON format and only include books published after 1980.'],\n",
       "  'reference': ['',\n",
       "   \"The answer to should only include 'Harry Potter and the Philosopher's Stone' and 'The Prism Galaxy Chronicles: The Awakening of the Starcaster'\"]},\n",
       " {'question_id': 134,\n",
       "  'category': 'extraction',\n",
       "  'turns': [\"Given the following data, identify the company with the highest profit in 2021 and provide its CEO's name:\\na) Company X, with CEO Amy Williams, reported $30 billion in revenue and a $3 billion profit in 2021.\\nb) Company Y, led by CEO Mark Thompson, posted a $60 billion revenue and a $6 billion profit in the same year.\\nc) Company Z, under CEO Sarah Johnson, announced a $20 billion revenue and a $7 billion profit in 2021.\\nd) Company W, managed by CEO James Smith, revealed a $300 billion revenue with a $21 billion profit in 2021.\\ne) Company V, with CEO Lisa Brown, reported a $200 billion revenue and a $25 billion profit in 2021.\\nf) Company U, under CEO John White, posted a $180 billion revenue and a $20 billion profit in the same year.\",\n",
       "   'Which company had the highest profit margin (profit/revenue ratio))?'],\n",
       "  'reference': ['Company V ($25 billion).', 'Company Z (35%)']},\n",
       " {'question_id': 135,\n",
       "  'category': 'extraction',\n",
       "  'turns': [\"Identify the countries, their capitals, and the languages spoken in the following sentences. Output in JSON format.\\na) Amidst the idyllic vistas, Copenhagen, Denmark's capital, captivates visitors with its thriving art scene and the enchanting Danish language spoken by its inhabitants.\\nb) Within the enchanting realm of Eldoria, one discovers Avalore, a grandiose city that emanates an ethereal aura. Lumina, a melodious language, serves as the principal mode of communication within this mystical abode.\\nc) Nestled amidst a harmonious blend of age-old customs and contemporary wonders, Buenos Aires, the capital of Argentina, stands as a bustling metropolis. It is a vibrant hub where the expressive Spanish language holds sway over the city's inhabitants.\",\n",
       "   'Come up with 3 similar examples in the YAML format.']},\n",
       " {'question_id': 136,\n",
       "  'category': 'extraction',\n",
       "  'turns': ['Please read the paragraph below and count how many times the words \"Amazon\", \"river\", and \"you\" appear. Please present the results in the format of \"word, number of appearances\" with each word on a separate line. Sort the lines in order of the number of appearances.\\nThe Amazon, a mesmerizing expanse of nature\\'s wonders, is home to the legendary Amazon River. Flowing through awe-inspiring landscapes like the Amazon rainforest, the river weaves its way through Brazil, Colombia, and Peru, giving life to countless creatures. From the mighty jaguars prowling the Amazon jungle to the vibrant macaws soaring above the canopy, this remarkable region teems with biodiversity. Deep within the river\\'s currents, magnificent pink river dolphins gracefully glide alongside piranhas and electric eels. Along the riverbanks, you\\'ll find bustling cities like Manaus, where the urban meets the wild, and Iquitos, a gateway to the heart of the Amazon rainforest. As you venture further, the Amazon River reveals hidden gems like the captivating Anavilhanas Archipelago, a mosaic of islands brimming with rare species. Embark on an adventure, explore the enchanting Amazon River, and immerse yourself in a world teeming with life and untamed beauty.',\n",
       "   \"Please repeat the same task using the words 'the', 'and', and 'to'\"],\n",
       "  'reference': ['Amazon, 7; river, 6; you, 2', 'the, 17; and, 5; to, 4']},\n",
       " {'question_id': 137,\n",
       "  'category': 'extraction',\n",
       "  'turns': [\"Identify the named entities (people, organizations, locations) mentioned in the given news article. Please generate a JSON dictionary that lists the named entities in three separate groups based on their entity types. The key is the type of entity and the value is a list of strings.\\n\\nYesterday, Adamson Emerson, the CEO of Faraday, and Dieter Zetsche, the CEO of Daimler AG, announced plans to build a new Gigafactory in Berlin. The facility will be a joint venture between Faraday and Daimler, producing electric vehicles and battery packs for both companies, creating thousands of job opportunities in the region. Emerson and Zetsche stated that the strategic location of Berlin, coupled with its skilled workforce and strong infrastructure, makes it an ideal choice for expansion. The new Gigafactory aims to meet the growing demand for electric vehicles in Europe and contribute to a sustainable future. Volkswagen CEO Herbert Diess welcomed the news, saying greater collaboration will benefit the auto industry's transition to e-mobility.\",\n",
       "   'Now make the JSON object shorter by replacing each value with its first letter. Please output everything in a single line without using indentation or creating new lines.']},\n",
       " {'question_id': 138,\n",
       "  'category': 'extraction',\n",
       "  'turns': [\"Analyze the following customer reviews from different sources for three different smartphones - the latest iPhone, Samsung Galaxy, and Google Pixel - and provide an overall rating for each phone on a scale of 1 to 10. Consider the following complex and contradictory reviews:\\n- TechRadar's review of the latest iPhone: The new iPhone is a stunning triumph of engineering that sets a new bar for smartphone performance and camera quality. However, the incremental design and high price mean it lacks the 'wow' factor of previous iPhones. Still, its power and intelligence are unrivaled.\\n- CNET's review of the latest Samsung Galaxy: The Samsung Galaxy phone has plenty of high points, including an amazing screen, fast performance, solid battery life and an impressive array of camera options. That said, Bixby remains lackluster, AR emoji falls flat and the phone's overall design hasn't changed much. The new Galaxy is an amazing phone overall, but it has a few nagging weaknesses that keep it from achieving true greatness.\\n- The Verge's review of the latest Google Pixel: Google's Pixel packs cutting-edge specs, innovative AI-powered software, and a killer camera into a sleek design. However, the phone has lackluster battery life, lacks expandable storage, and its performance stutters at times, especially considering its high price tag. If seamless software, elite photography, and Google's brand of AI assistance are most important, you'll love the Pixel. But the overall experience isn't as well-rounded as some competitors. Return the answer as a JSON object with the overall ratings for each phone out of 10, to one decimal place.\",\n",
       "   'Can you change the ratings from numbers to letters? Capital letters MUST be used when writing the names of phones.']},\n",
       " {'question_id': 139,\n",
       "  'category': 'extraction',\n",
       "  'turns': ['Given a set of complex equations, extract all unique variable names from each equation. Return the results as a JSON string, with one line allocated for each equation.\\n```\\n1) y = (3/4)x^3 - e^(2x) + sin(pi*x) - sqrt(7)\\n2) 2A - B/(3+C) * sum(N=1 to 5; ln(N)^2) = 5D*integral(a=0 to pi; cos(comb(N=1 to 10; N*a)))\\n3) E = m(c^2) + gamma*(v/d)/(-(alpha/2) + sqrt(beta^2 + (alpha/2)^2))\\n```',\n",
       "   \"Please rearrange the equations and use 'a', 'b', 'c', 'd', etc. as variables.\"]},\n",
       " {'question_id': 140,\n",
       "  'category': 'extraction',\n",
       "  'turns': ['Given the following records of stock prices, extract the highest and lowest closing prices for each month in the year 2022. Return the results as a CSV string, with one line allocated for each month.\\nDate,Open,High,Low,Close,Volume\\n2022-01-01,150.02,155.28,148.50,153.80,15678900\\n2022-01-02,154.32,157.25,153.48,156.25,19874500\\n2022-02-01,160.50,163.28,159.50,161.80,14326700\\n2022-02-02,161.80,164.25,161.30,163.90,17689200\\n2022-03-01,165.40,168.35,163.10,166.80,16253400\\n2022-03-02,167.00,169.85,165.50,168.20,19568100',\n",
       "   'Do the same task again with the JSON format and round all numbers in your response to the nearest integers.'],\n",
       "  'reference': ['\\nMonth,High,Low\\n01,156.25,153.80\\n02,163.90,161.80\\n03,168.20,166.80',\n",
       "   '\\n```\\n{ \"January\": { \"High\": 156, \"Low\": 154 }, \"February\": { \"High\": 164, \"Low\": 162 }, \"March\": { \"High\": 168, \"Low\": 167 } }\\n```']},\n",
       " {'question_id': 141,\n",
       "  'category': 'stem',\n",
       "  'turns': ['In the field of quantum physics, what is superposition, and how does it relate to the phenomenon of quantum entanglement?',\n",
       "   'What assumptions have you made in your response? Are they valid?']},\n",
       " {'question_id': 142,\n",
       "  'category': 'stem',\n",
       "  'turns': [\"Consider a satellite that is in a circular orbit around the Earth. The speed of the satellite decreases. What will happen to the satellite's orbital radius and period of revolution? Please justify your answer using principles of physics.\",\n",
       "   'What are some corner cases or edge cases in your solution? How do you handle them?'],\n",
       "  'reference': ['The orbital radius will increase and the period of revolution will increase',\n",
       "   '']},\n",
       " {'question_id': 143,\n",
       "  'category': 'stem',\n",
       "  'turns': ['Photosynthesis is a vital process for life on Earth. Could you outline the two main stages of photosynthesis, including where they take place within the chloroplast, and the primary inputs and outputs for each stage?',\n",
       "   'How much energy can a tree produce through photosynthesis in its lifetime? Please provide an estimate using actual numerical values and thoroughly explain your thought process step-by-step.'],\n",
       "  'reference': ['Two major stages: light-dependent reactions and light-independent reactions',\n",
       "   '']},\n",
       " {'question_id': 144,\n",
       "  'category': 'stem',\n",
       "  'turns': ['What is the central dogma of molecular biology? What processes are involved? Who named this?',\n",
       "   'Identify and fix one incorrect fact in your previous response.'],\n",
       "  'reference': ['Genetic information flows from DNA to RNA to Protein. Three processes: replication, transcription, and translation. Francis Crick in 1958.',\n",
       "   '']},\n",
       " {'question_id': 145,\n",
       "  'category': 'stem',\n",
       "  'turns': ['Describe the process and write out the balanced chemical equation for the reaction that occurs when solid calcium carbonate reacts with hydrochloric acid to form aqueous calcium chloride, carbon dioxide, and water. What type of reaction is this, and what observations might indicate that the reaction is taking place?',\n",
       "   'How can we reverse this process?'],\n",
       "  'reference': ['CaCO₃ + 2 HCl → CaCl₂ + CO₂ + H₂O', 'Not easy to do this.']},\n",
       " {'question_id': 146,\n",
       "  'category': 'stem',\n",
       "  'turns': ['Please explain the differences between exothermic and endothermic reactions, and include the criteria you used to distinguish between them. Additionally, please provide a real-world example to illustrate your explanation.',\n",
       "   'Can a process involve both reactions? List one.']},\n",
       " {'question_id': 147,\n",
       "  'category': 'stem',\n",
       "  'turns': ['The city of Vega intends to build a bridge that will span the Vegona River, covering a distance of 1.8 kilometers. The proposed location falls within a seismically active area that has experienced several high-magnitude earthquakes. Given these circumstances, what would be the best approach to constructing the bridge?',\n",
       "   'What are the key disadvantages or flaws of your solution? Please perform calculations and use numbers to illustrate them.']},\n",
       " {'question_id': 148,\n",
       "  'category': 'stem',\n",
       "  'turns': ['You have been tasked with designing a solar-powered water heating system for a residential building. Describe the key components and considerations you would include in your design. Design a five-step workflow.',\n",
       "   'If the system is intended for a building with a capacity of 100 individuals, what would be the estimated budget for implementing this system?']},\n",
       " {'question_id': 149,\n",
       "  'category': 'stem',\n",
       "  'turns': ['Please describe the concept of machine learning. Could you elaborate on the differences between supervised, unsupervised, and reinforcement learning? Provide real-world examples of each.',\n",
       "   'In your last example of reinforcement learning, can we use supervised learning to solve it?']},\n",
       " {'question_id': 150,\n",
       "  'category': 'stem',\n",
       "  'turns': ['How have the Alps and Rhine River influenced settlement and agriculture in Western Europe? List three impacts.',\n",
       "   'How could you design a concrete but simple experiment to validate the first impact?']},\n",
       " {'question_id': 151,\n",
       "  'category': 'humanities',\n",
       "  'turns': ['Provide insights into the correlation between economic indicators such as GDP, inflation, and unemployment rates. Explain how fiscal and monetary policies affect those indicators.',\n",
       "   \"Now, explain them again like I'm five.\"]},\n",
       " {'question_id': 152,\n",
       "  'category': 'humanities',\n",
       "  'turns': ['How do the stages of life shape our understanding of time and mortality?',\n",
       "   'Write an allegorical poem that illustrates the above.']},\n",
       " {'question_id': 153,\n",
       "  'category': 'humanities',\n",
       "  'turns': ['Discuss antitrust laws and their impact on market competition. Compare the antitrust laws in US and China along with some case studies.',\n",
       "   'Pick one case study and explain it in detail.']},\n",
       " {'question_id': 154,\n",
       "  'category': 'humanities',\n",
       "  'turns': ['Create a lesson plan that integrates drama, mime or theater techniques into a history class. Duration: 3 class periods (each lasts for 45 minutes) for 3 days\\nTopic: Opium Wars between China and Britain\\nGrade level: 9-10',\n",
       "   'Provide more details for Day 1 and include three homework questions.']},\n",
       " {'question_id': 155,\n",
       "  'category': 'humanities',\n",
       "  'turns': ['Share ideas for adapting art masterpieces into interactive experiences for children. List 5 specific artworks and associated ideas.',\n",
       "   'Write a concrete plan for your second example. Include budget estimates.']},\n",
       " {'question_id': 156,\n",
       "  'category': 'humanities',\n",
       "  'turns': [\"Explain what's base rate fallacy and list five specific examples of how politicians use it for campaigns.\",\n",
       "   'Provide a detailed plan for an election campaign using the first example.']},\n",
       " {'question_id': 157,\n",
       "  'category': 'humanities',\n",
       "  'turns': ['Describe five key principles in evaluating an argument in analytical writing.',\n",
       "   'With the listed principles, write a response in which you discuss what specific evidence is needed to evaluate the argument and explain how the evidence would weaken or strengthen the argument.\\n\\n===\\n\\nThe following is a memorandum from the advertising head of Zorblatt Animal Outlets, a chain operating thirty animal outlets globally.\\n\\n\"Half a decade ago, our rival Aquatic Pavilion started publicizing in Rare Pets Digest periodical. Their overall sales have been consistently growing at a rate of 3-to-5 percent each year since then. In particular, the Aquatic Pavilion outlet in Harbor Town experienced even more significant growth, securing the title of the most frequented animal store in the United States the previous year. In contrast, our two Zorblatt outlets in Harbor Town have recorded a consistent drop in sales during the same duration. It is evident that we must promptly start featuring our own advertisements in Rare Pets Digest and other popular animal publications. If we take this step, we can confidently anticipate a reversal in this recent trend of decreasing sales and return to profitability.\"']},\n",
       " {'question_id': 158,\n",
       "  'category': 'humanities',\n",
       "  'turns': ['Which methods did Socrates employ to challenge the prevailing thoughts of his time?',\n",
       "   \"Let's bring Socrates to modern world. Generate a conversation between Socrates and Bill Gates to debate on generative AI for education.\"]},\n",
       " {'question_id': 159,\n",
       "  'category': 'humanities',\n",
       "  'turns': ['What are some business etiquette norms when doing business in Japan?',\n",
       "   'Create a video script for training new employees of a car wash business in Japan. Highlight the above etiquette norms.']},\n",
       " {'question_id': 160,\n",
       "  'category': 'humanities',\n",
       "  'turns': ['Suggest five award-winning documentary films with brief background descriptions for aspiring filmmakers to study.',\n",
       "   'With the spirit in the first film, craft a succinct and persuasive pitch for a film about overcoming adversity.']}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastchat.llm_judge.common import load_questions, temperature_config\n",
    "from fastchat.model import load_model, get_conversation_template\n",
    "from fastchat.llm_judge.gen_model_answer import get_model_answers, run_eval\n",
    "\n",
    "\n",
    "\n",
    "# questions = load_questions(question_file, question_begin, question_end)\n",
    "questions = load_questions(question_file, None, None)\n",
    "# # random shuffle the questions to balance the loading\n",
    "# random.shuffle(questions)\n",
    "questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95eb043a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'writing': 10,\n",
       "         'roleplay': 10,\n",
       "         'reasoning': 10,\n",
       "         'math': 10,\n",
       "         'coding': 10,\n",
       "         'extraction': 10,\n",
       "         'stem': 10,\n",
       "         'humanities': 10})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter([x['category'] for x in questions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edf17619",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the question file into `num_gpus` files\n",
    "assert num_gpus_total % num_gpus_per_model == 0\n",
    "use_ray = num_gpus_total // num_gpus_per_model > 1\n",
    "\n",
    "if use_ray:\n",
    "    get_answers_func = ray.remote(num_gpus=num_gpus_per_model)(\n",
    "        get_model_answers\n",
    "    ).remote\n",
    "else:\n",
    "    get_answers_func = get_model_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ea600d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = len(questions) // (num_gpus_total // num_gpus_per_model)\n",
    "chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3c3756d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351d48c240934c219171ee852c9b5d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 112.00 MiB (GPU 0; 31.75 GiB total capacity; 1002.02 MiB already allocated; 441.88 MiB free; 1020.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_gpus_per_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_gpu_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_gpu_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcpu_offloading\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/FastChat/fastchat/model/model_adapter.py:362\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_path, device, num_gpus, max_gpu_memory, dtype, load_8bit, cpu_offloading, gptq_config, awq_config, exllama_config, xft_config, revision, debug)\u001b[0m\n\u001b[1;32m    355\u001b[0m     model \u001b[38;5;241m=\u001b[39m ipex\u001b[38;5;241m.\u001b[39moptimize(model, dtype\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m num_gpus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cpu_offloading) \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    361\u001b[0m ):\n\u001b[0;32m--> 362\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    365\u001b[0m     model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mxpu\u001b[38;5;241m.\u001b[39moptimize(model, dtype\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/github/mitibm2023/external/transformers/src/transformers/modeling_utils.py:2271\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2267\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2268\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2269\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2270\u001b[0m         )\n\u001b[0;32m-> 2271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 797 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/gpfs/u/scratch/PTFM/PTFMqngp/miniconda3/envs/open-instruct/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 112.00 MiB (GPU 0; 31.75 GiB total capacity; 1002.02 MiB already allocated; 441.88 MiB free; 1020.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model(\n",
    "    model_path,\n",
    "    revision=revision,\n",
    "    device=\"cuda\",\n",
    "    num_gpus=num_gpus_per_model,\n",
    "    max_gpu_memory=max_gpu_memory,\n",
    "    dtype=dtype,\n",
    "    load_8bit=False,\n",
    "    cpu_offloading=False,\n",
    "    debug=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad9985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    if question[\"category\"] in temperature_config:\n",
    "        temperature = temperature_config[question[\"category\"]]\n",
    "    else:\n",
    "        temperature = 0.7\n",
    "\n",
    "    choices = []\n",
    "    for i in range(num_choices):\n",
    "        torch.manual_seed(i)\n",
    "        conv = get_conversation_template(model_id)\n",
    "        turns = []\n",
    "        for j in range(len(question[\"turns\"])):\n",
    "            qs = question[\"turns\"][j]\n",
    "            conv.append_message(conv.roles[0], qs)\n",
    "            conv.append_message(conv.roles[1], None)\n",
    "            prompt = conv.get_prompt()\n",
    "            input_ids = tokenizer([prompt]).input_ids\n",
    "\n",
    "            if temperature < 1e-4:\n",
    "                do_sample = False\n",
    "            else:\n",
    "                do_sample = True\n",
    "\n",
    "            # some models may error out when generating long outputs\n",
    "            try:\n",
    "                output_ids = model.generate(\n",
    "                    torch.as_tensor(input_ids).cuda(),\n",
    "                    do_sample=do_sample,\n",
    "                    temperature=temperature,\n",
    "                    max_new_tokens=max_new_token,\n",
    "                )\n",
    "                if model.config.is_encoder_decoder:\n",
    "                    output_ids = output_ids[0]\n",
    "                else:\n",
    "                    output_ids = output_ids[0][len(input_ids[0]) :]\n",
    "\n",
    "                # be consistent with the template's stop_token_ids\n",
    "                if conv.stop_token_ids:\n",
    "                    stop_token_ids_index = [\n",
    "                        i\n",
    "                        for i, id in enumerate(output_ids)\n",
    "                        if id in conv.stop_token_ids\n",
    "                    ]\n",
    "                    if len(stop_token_ids_index) > 0:\n",
    "                        output_ids = output_ids[: stop_token_ids_index[0]]\n",
    "\n",
    "                output = tokenizer.decode(\n",
    "                    output_ids,\n",
    "                    spaces_between_special_tokens=False,\n",
    "                )\n",
    "                if conv.stop_str and isinstance(conv.stop_str, list):\n",
    "                    stop_str_indices = sorted(\n",
    "                        [\n",
    "                            output.find(stop_str)\n",
    "                            for stop_str in conv.stop_str\n",
    "                            if output.find(stop_str) > 0\n",
    "                        ]\n",
    "                    )\n",
    "                    if len(stop_str_indices) > 0:\n",
    "                        output = output[: stop_str_indices[0]]\n",
    "                elif conv.stop_str and output.find(conv.stop_str) > 0:\n",
    "                    output = output[: output.find(conv.stop_str)]\n",
    "\n",
    "                for special_token in tokenizer.special_tokens_map.values():\n",
    "                    if isinstance(special_token, list):\n",
    "                        for special_tok in special_token:\n",
    "                            output = output.replace(special_tok, \"\")\n",
    "                    else:\n",
    "                        output = output.replace(special_token, \"\")\n",
    "                output = output.strip()\n",
    "\n",
    "                if conv.name == \"xgen\" and output.startswith(\"Assistant:\"):\n",
    "                    output = output.replace(\"Assistant:\", \"\", 1).strip()\n",
    "            except RuntimeError as e:\n",
    "                print(\"ERROR question ID: \", question[\"question_id\"])\n",
    "                output = \"ERROR\"\n",
    "\n",
    "            conv.update_last_message(output)\n",
    "            turns.append(output)\n",
    "\n",
    "        choices.append({\"index\": i, \"turns\": turns})\n",
    "\n",
    "#     # Dump answers\n",
    "#     os.makedirs(os.path.dirname(answer_file), exist_ok=True)\n",
    "#     with open(os.path.expanduser(answer_file), \"a\") as fout:\n",
    "#         ans_json = {\n",
    "#             \"question_id\": question[\"question_id\"],\n",
    "#             \"answer_id\": shortuuid.uuid(),\n",
    "#             \"model_id\": model_id,\n",
    "#             \"choices\": choices,\n",
    "#             \"tstamp\": time.time(),\n",
    "#         }\n",
    "#         fout.write(json.dumps(ans_json) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:open-instruct]",
   "language": "python",
   "name": "conda-env-open-instruct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
