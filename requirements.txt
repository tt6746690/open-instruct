# wpq: added torch version
--extra-index-url https://download.pytorch.org/whl/cu118
torch==2.0.0+cu118
sentencepiece
datasets
deepspeed==0.9.1
# accelerate==0.18.0
git+https://github.com/huggingface/accelerate.git@e06e7b35e7c49563ed70f31b78126bf70b0252b9  # this version fixes a bug about gradient accumulation in 0.18.0 
git+https://github.com/huggingface/peft.git@49a20c16dcd9de5716feee717e8eb742efb9eff9
bitsandbytes==0.37.2
evaluate==0.4.0
tokenizers==0.13.3
protobuf==3.20.0
transformers>=4.28.1
openai
tiktoken
rouge_score
wandb
gradio
markupsafe==2.0.1
termcolor
jsonlines
mecab-python3
unidic-lite
einops
# wpq: gives cuda version 12.1 mismatch with version pytorch is compiled with (11.8) error and it doesn't seem to be an easy fix.
# open-instruct uses flash-attn for llama model. so fix this if I need to use llama for anything.
# flash-attn
auto-gptq
fire
# alpaca-farm eval - my fork with some fixes.
git+https://github.com/hamishivi/alpaca_farm.git
# for human eval web app
flask
# wpq: for mosaicml/mpt-7b
triton-pre-mlir@git+https://github.com/vchiley/triton.git@triton_pre_mlir_sm90#subdirectory=python
# wpq: for open-instuct logging
tensorboard
## wpq: for jpt_setup()
omegaconf